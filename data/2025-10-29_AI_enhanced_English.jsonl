{"id": "2510.23775", "categories": ["cs.CV", "cs.AI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.23775", "abs": "https://arxiv.org/abs/2510.23775", "authors": ["Aryan Mathur", "Asaduddin Ahmed", "Pushti Amit Vasoya", "Simeon Kandan Sonar", "Yasir Z", "Madesh Kuppusamy"], "title": "Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices", "comment": null, "summary": "The increasing realism of AI-generated imagery poses challenges for verifying\nvisual authenticity. We present an explainable image authenticity detection\nsystem that combines a lightweight convolutional classifier\n(\"Faster-Than-Lies\") with a Vision-Language Model (Qwen2-VL-7B) to classify,\nlocalize, and explain artifacts in 32x32 images. Our model achieves 96.5%\naccuracy on the extended CiFAKE dataset augmented with adversarial\nperturbations and maintains an inference time of 175ms on 8-core CPUs, enabling\ndeployment on local or edge devices. Using autoencoder-based reconstruction\nerror maps, we generate artifact localization heatmaps, which enhance\ninterpretability for both humans and the VLM. We further categorize 70 visual\nartifact types into eight semantic groups and demonstrate explainable text\ngeneration for each detected anomaly. This work highlights the feasibility of\ncombining visual and linguistic reasoning for interpretable authenticity\ndetection in low-resolution imagery and outlines potential cross-domain\napplications in forensics, industrial inspection, and social media moderation.", "AI": {"tldr": "An explainable, efficient system combining a lightweight CNN and a vision-language model to detect, localize, and explain artifacts in low-res AI-generated images, achieving high accuracy and edge deployment viability.", "motivation": "As AI-generated imagery becomes more realistic, verifying authenticity and providing explanations becomes harder, especially for small images. The work aims to enable interpretable detection via visual and linguistic reasoning on edge devices.", "method": "Fuse a lightweight classifier 'Faster-Than-Lies' with Qwen2-VL-7B VLM to classify and localize artifacts in 32x32 images. Use autoencoder reconstruction error maps to generate artifact localization heatmaps. Group 70 artifact types into eight semantic categories and produce explainable text for detected anomalies.", "result": "96.5% accuracy on extended CiFAKE with adversarial perturbations; 175 ms inference on 8-core CPUs; suitable for local/edge deployment; interpretable heatmaps; text explanations for anomalies; supports cross-domain applications.", "conclusion": "Demonstrates feasibility of combining visual and linguistic reasoning for interpretable authenticity detection in low-resolution imagery and suggests cross-domain uses in forensics, industrial inspection, and social media moderation."}}
{"id": "2510.23785", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23785", "abs": "https://arxiv.org/abs/2510.23785", "authors": ["Md Tanvir Hossain", "Akif Islam", "Mohd Ruhul Ameen"], "title": "CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting", "comment": "6 pages, 2 tables, 6 figures. Submitted to IEEE 5th International\n  Conference on Electrical, Computer and Telecommunication Engineering (ICECTE\n  2025)", "summary": "Humans can effortlessly count diverse objects by perceiving visual repetition\nand structural relationships rather than relying on class identity. However,\nmost existing counting models fail to replicate this ability; they often\nmiscount when objects exhibit complex shapes, internal symmetry, or overlapping\ncomponents. In this work, we introduce CountFormer, a transformer-based\nframework that learns to recognize repetition and structural coherence for\nclass-agnostic object counting. Built upon the CounTR architecture, our model\nreplaces its visual encoder with the self-supervised foundation model DINOv2,\nwhich produces richer and spatially consistent feature representations. We\nfurther incorporate positional embedding fusion to preserve geometric\nrelationships before decoding these features into density maps through a\nlightweight convolutional decoder. Evaluated on the FSC-147 dataset, our model\nachieves performance comparable to current state-of-the-art methods while\ndemonstrating superior accuracy on structurally intricate or densely packed\nscenes. Our findings indicate that integrating foundation models such as DINOv2\nenables counting systems to approach human-like structural perception,\nadvancing toward a truly general and exemplar-free counting paradigm.", "AI": {"tldr": "CountFormer adapts a CounTR-like transformer to use DINOv2 features and positional fusion for class-agnostic counting, achieving competitive results and improved accuracy on complex, densely packed scenes.", "motivation": "Humans count by recognizing visual repetition and structural coherence; current counting models often miscount when objects have complex shapes, symmetry, or overlap. The work aims to emulate human-like structural perception in a general, exemplar-free counting framework.", "method": "Replace CounTR's visual encoder with DINOv2 (self-supervised) to obtain richer, spatially consistent features; add positional embedding fusion to preserve geometry; use a lightweight convolutional decoder to map features to density maps; evaluate on FSC-147.", "result": "The model achieves performance comparable to state-of-the-art methods and shows superior accuracy on structurally intricate or densely packed scenes, indicating that foundation-model features help approach human-like counting.", "conclusion": "Integrating foundation models such as DINOv2 enables more general, exemplar-free counting by emphasizing repetition and structural coherence, advancing toward human-like counting capabilities."}}
{"id": "2510.23798", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23798", "abs": "https://arxiv.org/abs/2510.23798", "authors": ["Gauthier Grimmer", "Romain Wenger", "Cl\u00e9ment Flint", "Germain Forestier", "Gilles Rixhon", "Valentin Chardon"], "title": "A geometric and deep learning reproducible pipeline for monitoring floating anthropogenic debris in urban rivers using in situ cameras", "comment": null, "summary": "The proliferation of floating anthropogenic debris in rivers has emerged as a\npressing environmental concern, exerting a detrimental influence on\nbiodiversity, water quality, and human activities such as navigation and\nrecreation. The present study proposes a novel methodological framework for the\nmonitoring the aforementioned waste, utilising fixed, in-situ cameras. This\nstudy provides two key contributions: (i) the continuous quantification and\nmonitoring of floating debris using deep learning and (ii) the identification\nof the most suitable deep learning model in terms of accuracy and inference\nspeed under complex environmental conditions. These models are tested in a\nrange of environmental conditions and learning configurations, including\nexperiments on biases related to data leakage. Furthermore, a geometric model\nis implemented to estimate the actual size of detected objects from a 2D image.\nThis model takes advantage of both intrinsic and extrinsic characteristics of\nthe camera. The findings of this study underscore the significance of the\ndataset constitution protocol, particularly with respect to the integration of\nnegative images and the consideration of temporal leakage. In conclusion, the\nfeasibility of metric object estimation using projective geometry coupled with\nregression corrections is demonstrated. This approach paves the way for the\ndevelopment of robust, low-cost, automated monitoring systems for urban aquatic\nenvironments.", "AI": {"tldr": "Fixed-camera deep learning pipeline for continuous river debris monitoring, with model comparison under complex conditions and a projective-geometry size estimation scheme; emphasizes dataset design and leakage handling for robust, low-cost automation.", "motivation": "Floating debris harms biodiversity, water quality, navigation, and recreation. Current monitoring is limited and costly; there is a need for continuous, automatic debris monitoring using inexpensive fixed cameras in urban aquatic environments.", "method": "Deploy fixed, in-situ cameras to capture debris; evaluate multiple deep learning models for debris detection with attention to accuracy and inference speed under diverse environmental conditions; examine data leakage biases and dataset design, including negative images and temporal leakage; implement a geometric model using camera intrinsic and extrinsic parameters to estimate actual object size from 2D detections; apply regression corrections to improve size estimates.", "result": "Demonstrates feasibility of metric (size) estimation from image data via projective geometry with corrections; identifies the importance of dataset constitution, including negative samples and temporal leakage, and selects suitable models balancing accuracy and speed under varying conditions.", "conclusion": "The framework supports robust, low-cost, automated debris monitoring in urban aquatic environments, enabling continuous quantification and sizing of floating debris with scalable deployment."}}
{"id": "2510.23816", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23816", "abs": "https://arxiv.org/abs/2510.23816", "authors": ["Forouzan Fallah", "Wenwen Li", "Chia-Yu Hsu", "Hyunho Lee", "Yezhou Yang"], "title": "RareFlow: Physics-Aware Flow-Matching for Cross-Sensor Super-Resolution of Rare-Earth Features", "comment": null, "summary": "Super-resolution (SR) for remote sensing imagery often fails under\nout-of-distribution (OOD) conditions, such as rare geomorphic features captured\nby diverse sensors, producing visually plausible but physically inaccurate\nresults. We present RareFlow, a physics-aware SR framework designed for OOD\nrobustness. RareFlow's core is a dual-conditioning architecture. A Gated\nControlNet preserves fine-grained geometric fidelity from the low-resolution\ninput, while textual prompts provide semantic guidance for synthesizing complex\nfeatures. To ensure physically sound outputs, we introduce a multifaceted loss\nfunction that enforces both spectral and radiometric consistency with sensor\nproperties. Furthermore, the framework quantifies its own predictive\nuncertainty by employing a stochastic forward pass approach; the resulting\noutput variance directly identifies unfamiliar inputs, mitigating feature\nhallucination. We validate RareFlow on a new, curated benchmark of multi-sensor\nsatellite imagery. In blind evaluations, geophysical experts rated our model's\noutputs as approaching the fidelity of ground truth imagery, significantly\noutperforming state-of-the-art baselines. This qualitative superiority is\ncorroborated by quantitative gains in perceptual metrics, including a nearly\n40\\% reduction in FID. RareFlow provides a robust framework for high-fidelity\nsynthesis in data-scarce scientific domains and offers a new paradigm for\ncontrolled generation under severe domain shift.", "AI": {"tldr": "A physics-aware dual-conditioning SR framework (RareFlow) for remote sensing under out-of-distribution conditions, combining Gate ControlNet for geometry and text prompts for semantics, with spectral/radiometric losses and stochastic uncertainty, achieving near-ground-truth fidelity and ~40% FID reduction.", "motivation": "SR in remote sensing under diverse sensors and rare geomorphic features suffers hallucinations; need physically plausible outputs and uncertainty estimation under domain shift; enable robust, data-scarce scientific imaging.", "method": "Dual-conditioning network: Gate ControlNet preserves geometry from LR input; textual prompts guide semantic content. Multifold loss enforcing spectral/radiometric consistency with sensor properties. Stochastic forward passes to quantify predictive uncertainty; outputs variance identifies unfamiliar inputs.", "result": "Expert blind evaluations rate outputs close to ground truth and surpass baselines; quantitative perceptual metrics improve; ~40% reduction in FID; validation on new multi-sensor satellite benchmark.", "conclusion": "RareFlow provides robust, physics-aware SR under severe domain shift, enabling controlled generation and uncertainty quantification in data-scarce scientific domains."}}
{"id": "2510.23763", "categories": ["cs.RO", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23763", "abs": "https://arxiv.org/abs/2510.23763", "authors": ["Siyin Wang", "Jinlan Fu", "Feihong Liu", "Xinzhe He", "Huangxuan Wu", "Junhao Shi", "Kexin Huang", "Zhaoye Fei", "Jingjing Gong", "Zuxuan Wu", "Yugang Jiang", "See-Kiong Ng", "Tat-Seng Chua", "Xipeng Qiu"], "title": "RoboOmni: Proactive Robot Manipulation in Omni-modal Context", "comment": null, "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have driven rapid\nprogress in Vision-Language-Action (VLA) models for robotic manipulation.\nAlthough effective in many scenarios, current approaches largely rely on\nexplicit instructions, whereas in real-world interactions, humans rarely issue\ninstructions directly. Effective collaboration requires robots to infer user\nintentions proactively. In this work, we introduce cross-modal contextual\ninstructions, a new setting where intent is derived from spoken dialogue,\nenvironmental sounds, and visual cues rather than explicit commands. To address\nthis new setting, we present RoboOmni, a Perceiver-Thinker-Talker-Executor\nframework based on end-to-end omni-modal LLMs that unifies intention\nrecognition, interaction confirmation, and action execution. RoboOmni fuses\nauditory and visual signals spatiotemporally for robust intention recognition,\nwhile supporting direct speech interaction. To address the absence of training\ndata for proactive intention recognition in robotic manipulation, we build\nOmniAction, comprising 140k episodes, 5k+ speakers, 2.4k event sounds, 640\nbackgrounds, and six contextual instruction types. Experiments in simulation\nand real-world settings show that RoboOmni surpasses text- and ASR-based\nbaselines in success rate, inference speed, intention recognition, and\nproactive assistance.", "AI": {"tldr": "RoboOmni enables proactive intention recognition for robotic manipulation by fusing cross-modal cues in an omni-modal LLM framework and introducing OmniAction dataset.", "motivation": "In real-world human-robot collaboration, users seldom issue explicit commands; robots need to infer intent from dialogue, sounds, and visuals to provide proactive assistance.", "method": "Propose RoboOmni (Perceiver-Thinker-Talker-Executor) architecture that fuses audio-visual signals via end-to-end omni-modal LLMs; introduce OmniAction dataset with 140k episodes, 5k+ speakers, 2.4k event sounds, 640 backgrounds, and six contextual instruction types.", "result": "Outperforms text- and ASR-based baselines in simulation and real-world tests on success rate, inference speed, intention recognition, and proactive assistance.", "conclusion": "Shows that proactive intention recognition is feasible in robotic manipulation using cross-modal cues and omni-modal LLMs; OmniAction provides essential training data for such tasks."}}
{"id": "2510.23691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23691", "abs": "https://arxiv.org/abs/2510.23691", "authors": ["Zihao Wang", "Xujing Li", "Yining Ye", "Junjie Fang", "Haoming Wang", "Longxiang Liu", "Shihao Liang", "Junting Lu", "Zhiyong Wu", "Jiazhan Feng", "Wanjun Zhong", "Zili Li", "Yu Wang", "Yu Miao", "Bo Zhou", "Yuanfan Li", "Hao Wang", "Zhongkai Zhao", "Faming Wu", "Zhengxuan Jiang", "Weihao Tan", "Heyuan Yao", "Shi Yan", "Xiangyang Li", "Yitao Liang", "Yujia Qin", "Guang Shi"], "title": "Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents", "comment": null, "summary": "We present Game-TARS, a generalist game agent trained with a unified,\nscalable action space anchored to human-aligned native keyboard-mouse inputs.\nUnlike API- or GUI-based approaches, this paradigm enables large-scale\ncontinual pre-training across heterogeneous domains, including OS, web, and\nsimulation games. Game-TARS is pre-trained on over 500B tokens with diverse\ntrajectories and multimodal data. Key techniques include a decaying continual\nloss to reduce causal confusion and an efficient Sparse-Thinking strategy that\nbalances reasoning depth and inference cost. Experiments show that Game-TARS\nachieves about 2 times the success rate over the previous sota model on\nopen-world Minecraft tasks, is close to the generality of fresh humans in\nunseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet\nin FPS benchmarks. Scaling results on training-time and test-time confirm that\nthe unified action space sustains improvements when scaled to cross-game and\nmultimodal data. Our results demonstrate that simple, scalable action\nrepresentations combined with large-scale pre-training provide a promising path\ntoward generalist agents with broad computer-use abilities.", "AI": {"tldr": "Unified, keyboard-mouse anchored action space enabling scalable pretraining across OS/web/simulation games; yields strong generalist performance and competitive benchmarks.", "motivation": "Address limitations of API/GUI-based agents and enable broad computer-use abilities through a simple, scalable action representation; support large-scale continual pretraining across heterogeneous domains.", "method": "Introduce a unified action space anchored to native keyboard-mouse inputs. Pretrain on 500B tokens with diverse trajectories and multimodal data. Apply a decaying continual loss to reduce causal confusion and a Sparse-Thinking strategy to balance reasoning depth and inference cost. Evaluate across cross-domain tasks (OS, web, simulation games) and scale across cross-game/multimodal data.", "result": "About 2x the success rate over prior SOTA on open-world Minecraft tasks; approaching human generality in unseen web 3D games; outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet in FPS benchmarks. Scaling confirms sustained gains when expanding to cross-game and multimodal data.", "conclusion": "Simple, scalable action representations combined with large-scale pre-training offer a promising path toward generalist agents with broad computer-use abilities."}}
{"id": "2510.23617", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23617", "abs": "https://arxiv.org/abs/2510.23617", "authors": ["Phuong Q. Dao", "Mark Roantree", "Vuong M. Ngo"], "title": "An Enhanced Dual Transformer Contrastive Network for Multimodal Sentiment Analysis", "comment": "The paper has been accepted for presentation at the MEDES 2025\n  conference", "summary": "Multimodal Sentiment Analysis (MSA) seeks to understand human emotions by\njointly analyzing data from multiple modalities typically text and images\noffering a richer and more accurate interpretation than unimodal approaches. In\nthis paper, we first propose BERT-ViT-EF, a novel model that combines powerful\nTransformer-based encoders BERT for textual input and ViT for visual input\nthrough an early fusion strategy. This approach facilitates deeper cross-modal\ninteractions and more effective joint representation learning. To further\nenhance the model's capability, we propose an extension called the Dual\nTransformer Contrastive Network (DTCN), which builds upon BERT-ViT-EF. DTCN\nincorporates an additional Transformer encoder layer after BERT to refine\ntextual context (before fusion) and employs contrastive learning to align text\nand image representations, fostering robust multimodal feature learning.\nEmpirical results on two widely used MSA benchmarks MVSA-Single and TumEmo\ndemonstrate the effectiveness of our approach. DTCN achieves best accuracy\n(78.4%) and F1-score (78.3%) on TumEmo, and delivers competitive performance on\nMVSA-Single, with 76.6% accuracy and 75.9% F1-score. These improvements\nhighlight the benefits of early fusion and deeper contextual modeling in\nTransformer-based multimodal sentiment analysis.", "AI": {"tldr": "Introduces BERT-ViT-EF for early fused multimodal sentiment analysis using BERT and ViT, extended by DTCN with a post-BERT Transformer and contrastive learning; achieves top results on TumEmo and competitive results on MVSA-Single.", "motivation": "To improve multimodal sentiment analysis by enabling deeper cross-modal interactions and richer textual context through transformer-based architectures and alignment between modalities.", "method": "1) BERT-ViT-EF uses early fusion of text (BERT) and image (ViT) features. 2) DTCN adds an additional Transformer layer after BERT to refine textual context before fusion and employs a contrastive objective to align text and image representations.", "result": "On TumEmo, 78.4% accuracy and 78.3% F1; on MVSA-Single, 76.6% accuracy and 75.9% F1. DTCN achieves best results on TumEmo and competitive performance on MVSA-Single.", "conclusion": "Early fusion and deeper contextual modeling in Transformer-based MSA yield improved performance, with cross-modal alignment via contrastive learning enhancing multimodal feature learning."}}
{"id": "2510.23880", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.23880", "abs": "https://arxiv.org/abs/2510.23880", "authors": ["Hanke Chen", "Yuan Liu", "Minchen Li"], "title": "TRELLISWorld: Training-Free World Generation from Object Generators", "comment": null, "summary": "Text-driven 3D scene generation holds promise for a wide range of\napplications, from virtual prototyping to AR/VR and simulation. However,\nexisting methods are often constrained to single-object generation, require\ndomain-specific training, or lack support for full 360-degree viewability. In\nthis work, we present a training-free approach to 3D scene synthesis by\nrepurposing general-purpose text-to-3D object diffusion models as modular tile\ngenerators. We reformulate scene generation as a multi-tile denoising problem,\nwhere overlapping 3D regions are independently generated and seamlessly blended\nvia weighted averaging. This enables scalable synthesis of large, coherent\nscenes while preserving local semantic control. Our method eliminates the need\nfor scene-level datasets or retraining, relies on minimal heuristics, and\ninherits the generalization capabilities of object-level priors. We demonstrate\nthat our approach supports diverse scene layouts, efficient generation, and\nflexible editing, establishing a simple yet powerful foundation for\ngeneral-purpose, language-driven 3D scene construction.", "AI": {"tldr": "A training-free, tile-based diffusion approach to language-driven 3D scene generation using 3D object priors as modular generators.", "motivation": "To enable scalable, coherent 3D scene synthesis without scene-level datasets or retraining, addressing limitations of single-object generation and restricted viewability while supporting language-driven control.", "method": "Partition the scene into overlapping 3D tiles and generate each tile independently with pre-trained text-to-3D object diffusion models acting as modular generators. Blend overlapping tiles via weighted averaging to ensure seamless transitions. No scene-level retraining is required; relies on general object priors and minimal heuristics to produce large, coherent scenes with 360-degree viewability and editable components.", "result": "Demonstrates diverse scene layouts, efficient generation, and flexible editing. Produces scalable, coherent 3D scenes that preserve local semantics and support 360-degree viewability without scene-level training.", "conclusion": "A simple yet powerful tile-based, training-free framework for general-purpose, language-driven 3D scene construction. It obviates scene-level datasets and retraining and provides a flexible foundation for future enhancements and broader applications."}}
{"id": "2510.23860", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23860", "abs": "https://arxiv.org/abs/2510.23860", "authors": ["Hyung Chan Cho", "Go-Eum Cha", "Yanfu Liu", "Sooyeon Jeong"], "title": "Motivating Students' Self-study with Goal Reminder and Emotional Support", "comment": "RO-MAN 2025 accepted paper", "summary": "While the efficacy of social robots in supporting people in learning tasks\nhas been extensively investigated, their potential impact in assisting students\nin self-studying contexts has not been investigated much. This study explores\nhow a social robot can act as a peer study companion for college students\nduring self-study tasks by delivering task-oriented goal reminder and positive\nemotional support. We conducted an exploratory Wizard-of-Oz study to explore\nhow these robotic support behaviors impacted students' perceived focus,\nproductivity, and engagement in comparison to a robot that only provided\nphysical presence (control). Our study results suggest that participants in the\ngoal reminder and the emotional support conditions reported greater ease of\nuse, with the goal reminder condition additionally showing a higher willingness\nto use the robot in future study sessions. Participants' satisfaction with the\nrobot was correlated with their perception of the robot as a social other, and\nthis perception was found to be a predictor for their level of goal achievement\nin the self-study task. These findings highlight the potential of socially\nassistive robots to support self-study through both functional and emotional\nengagement.", "AI": {"tldr": "Social robots acting as peer study companions (goal reminders and emotional support) improved perceived ease of use and willingness to reuse in self-study tasks, beyond mere presence, with social perception predicting goal achievement.", "motivation": "Addresses a gap in research on robots aiding self-directed learning (as opposed to structured classroom tasks) by evaluating functional (goal reminders) and emotional (positive support) contributions of socially assistive robots during self-study.", "method": "Exploratory Wizard-of-Oz study with college students comparing three conditions: goal-reminder, emotional-support, and control (presence-only). Measured perceived focus, productivity, engagement, ease of use, willingness to reuse, and satisfaction; assessed the relationship between perceived sociality and goal achievement.", "result": "Participants in the goal-reminder and emotional-support conditions reported greater ease of use; the goal-reminder condition also showed higher willingness to use the robot in future sessions. Satisfaction with the robot correlated with viewing it as a social others, and this social perception predicted goal achievement in the self-study task.", "conclusion": "Socially assistive robots can support self-study through both functional (reminders) and emotional (support) engagement, suggesting design considerations for future self-directed learning tools to enhance usability and outcomes."}}
{"id": "2510.23734", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23734", "abs": "https://arxiv.org/abs/2510.23734", "authors": ["Eamon Duede"], "title": "AI and the Decentering of Disciplinary Creativity", "comment": null, "summary": "This paper examines the role of artificial intelligence in scientific\nproblem-solving, with a focus on its implications for disciplinary creativity.\nDrawing on recent work in the philosophy of creativity, I distinguish between\ncreative approaches and creative products, and introduce the concept of\ndisciplinary creativity -the creative application of discipline-specific\nexpertise to a valued problem within that field. Through two cases in\nmathematics, I show that while computation can extend disciplinary creativity,\ncertain approaches involving AI can serve to displace it. This displacement has\nthe potential to alter (and, perhaps, diminish) the value of scientific\npursuit.", "AI": {"tldr": "AI can both enhance and threaten disciplinary creativity: computation can extend problem-solving within a field, but some AI approaches risk displacing domain-specific expertise and potentially diminishing scientific value.", "motivation": "To clarify how creativity should be understood in science by distinguishing creative approaches from products and introducing disciplinary creativity, then assess how AI affects this in mathematics.", "method": "Philosophical analysis drawing on recent work on creativity, plus two mathematical case studies to compare computational and AI-driven approaches to problem-solving.", "result": "Computation can extend disciplinary creativity; however, certain AI approaches may displace it, potentially altering or diminishing the value of scientific pursuit.", "conclusion": "AI's impact is dual\u2014augmentation and displacement. The value of scientific inquiry depends on integrating AI tools in ways that preserve and enhance disciplinary creativity rather than erode it."}}
{"id": "2510.23621", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23621", "abs": "https://arxiv.org/abs/2510.23621", "authors": ["Alexandre Benoit"], "title": "Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields", "comment": "78 pages, 21 figures", "summary": "Machine-learning force fields can deliver accurate molecular dynamics (MD) at\nhigh computational cost. For SO(3)-equivariant models such as MACE, there is\nlittle systematic evidence on whether reduced-precision arithmetic and\nGPU-optimized kernels can cut this cost without harming physical fidelity. This\nthesis aims to make MACE cheaper and faster while preserving accuracy by\nidentifying computational bottlenecks and evaluating low-precision execution\npolicies. We profile MACE end-to-end and per block, compare the e3nn and NVIDIA\ncuEquivariance backends, and assess FP64/FP32/BF16/FP16 settings (with FP32\naccumulation) for inference, short NVT and long NPT water simulations, and toy\ntraining runs under reproducible, steady-state timing. cuEquivariance reduces\ninference latency by about $3\\times$. Casting only linear layers to BF16/FP16\nwithin an FP32 model yields roughly 4x additional speedups, while energies and\nthermodynamic observables in NVT/NPT MD remain within run-to-run variability.\nHalf-precision weights during training degrade force RMSE. Mixing e3nn and cuEq\nmodules without explicit adapters causes representation mismatches. Fused\nequivariant kernels and mixed-precision inference can substantially accelerate\nstate-of-the-art force fields with negligible impact on downstream MD. A\npractical policy is to use cuEquivariance with FP32 by default and enable\nBF16/FP16 for linear layers (keeping FP32 accumulations) for maximum\nthroughput, while training remains in FP32. Further gains are expected on\nAmpere/Hopper GPUs (TF32/BF16) and from kernel-level FP16/BF16 paths and\npipeline fusion.", "AI": {"tldr": "Evaluates how low-precision arithmetic and GPU backends affect MACE SO(3)-equivariant ML force fields for MD. Finds cuEquivariance plus selective BF16/FP16 on linear layers can dramatically speed up inference with negligible loss in MD fidelity; training with half-precision harms force accuracy. Provides a practical deployment policy and points to further gains on newer GPUs and kernel optimizations.", "motivation": "Reduce the computational cost of machine-learning force fields (MD) while preserving physical fidelity, especially for SO(3)-equivariant models like MACE, and assess the impact of precision and backend choices.", "method": "Profile MACE end-to-end and per block; compare e3nn versus NVIDIA cuEquivariance backends; evaluate FP64/FP32/BF16/FP16 (with FP32 accumulation) for inference, short NVT and long NPT water MD, and toy training runs, under reproducible timing; analyze results.", "result": "cuEquivariance reduces inference latency by ~3x. Casting only linear layers to BF16/FP16 within an FP32 model yields ~4x additional speedups; MD observables remain within run-to-run variability. Training with half-precision weights degrades force RMSE. Mixing e3nn and cuEq modules without adapters causes representation mismatches. Fused equivariant kernels and mixed-precision inference can substantially accelerate state-of-the-art force fields with negligible impact on MD. Practical policy: use cuEquivariance with FP32 by default and enable BF16/FP16 for linear layers (with FP32 accumulations); training remains FP32. Additional gains expected on Ampere/Hopper GPUs (TF32/BF16) and from kernel-level FP16/BF16 paths and pipeline fusion.", "conclusion": "The study provides a practical set of guidelines to accelerate MACE-driven MD workflows with minimal fidelity loss, highlights the trade-offs of reduced-precision training, and points to hardware and kernel optimizations as a route for further speedups."}}
{"id": "2510.23894", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23894", "abs": "https://arxiv.org/abs/2510.23894", "authors": ["Jinxin Zhou", "Jiachen Jiang", "Zhihui Zhu"], "title": "Improving Visual Discriminability of CLIP for Training-Free Open-Vocabulary Semantic Segmentation", "comment": "23 pages, 10 figures, 14 tables", "summary": "Extending CLIP models to semantic segmentation remains challenging due to the\nmisalignment between their image-level pre-training objectives and the\npixel-level visual understanding required for dense prediction. While prior\nefforts have achieved encouraging results by reorganizing the final layer and\nfeatures, they often inherit the global alignment bias of preceding layers,\nleading to suboptimal segmentation performance. In this work, we propose\nLHT-CLIP, a novel training-free framework that systematically exploits the\nvisual discriminability of CLIP across layer, head, and token levels. Through\ncomprehensive analysis, we reveal three key insights: (i) the final layers\nprimarily strengthen image-text alignment with sacrifice of visual\ndiscriminability (e.g., last 3 layers in ViT-B/16 and 8 layers in ViT-L/14),\npartly due to the emergence of anomalous tokens; (ii) a subset of attention\nheads (e.g., 10 out of 144 in ViT-B/16) display consistently strong visual\ndiscriminability across datasets; (iii) abnormal tokens display sparse and\nconsistent activation pattern compared to normal tokens. Based on these\nfindings, we propose three complementary techniques: semantic-spatial\nreweighting, selective head enhancement, and abnormal token replacement to\neffectively restore visual discriminability and improve segmentation\nperformance without any additional training, auxiliary pre-trained networks, or\nextensive hyperparameter tuning. Extensive experiments on 8 common semantic\nsegmentation benchmarks demonstrate that LHT-CLIP achieves state-of-the-art\nperformance across diverse scenarios, highlighting its effectiveness and\npracticality for real-world deployment.", "AI": {"tldr": "LHT-CLIP is a training-free framework that boosts CLIP-based semantic segmentation by rebalancing discriminability across layers, heads, and tokens, achieving state-of-the-art results without extra training.", "motivation": "CLIP's image-level pretraining aligns poorly with pixel-level dense prediction, and the final layers' emphasis on image-text alignment can degrade visual discriminability. The paper investigates internal CLIP representations to identify components that retain discriminability for segmentation.", "method": "Three complementary techniques\u2014semantic-spatial reweighting, selective head enhancement, and abnormal token replacement\u2014are applied in a training-free manner based on analysis showing: (i) final layers emphasize image-text alignment at the expense of visual discriminability; (ii) a subset of attention heads consistently exhibit strong visual discriminability; (iii) abnormal tokens have sparse, consistent activation patterns. No additional training or external networks are used.", "result": "Extensive experiments on 8 semantic segmentation benchmarks show state-of-the-art performance across diverse scenarios without any training or extra networks, demonstrating practicality for real-world deployment.", "conclusion": "By exploiting intra-CLIP discriminability across layers, heads, and tokens, LHT-CLIP closes the gap between CLIP pretraining and dense segmentation tasks in a training-free manner, offering an effective and practical solution for real-world semantic segmentation."}}
{"id": "2510.23902", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23902", "abs": "https://arxiv.org/abs/2510.23902", "authors": ["Jans Solano", "Diego Quiroz"], "title": "Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped", "comment": "Accepted at the IROS 2025 Workshop on Wheeled-Legged Robots", "summary": "Wheeled-legged robots combine the efficiency of wheels with the obstacle\nnegotiation of legs, yet many state-of-the-art systems rely on costly actuators\nand sensors, and fall-recovery is seldom integrated, especially for\nwheeled-legged morphologies. This work presents a recovery-aware\nvisual-inertial navigation system on a low-cost wheeled quadruped. The proposed\nsystem leverages vision-based perception from a depth camera and deep\nreinforcement learning policies for robust locomotion and autonomous recovery\nfrom falls across diverse terrains. Simulation experiments show agile mobility\nwith low-torque actuators over irregular terrain and reliably recover from\nexternal perturbations and self-induced failures. We further show goal directed\nnavigation in structured indoor spaces with low-cost perception. Overall, this\napproach lowers the barrier to deploying autonomous navigation and robust\nlocomotion policies in budget-constrained robotic platforms.", "AI": {"tldr": "A low-cost wheeled quadruped uses depth-sensor vision and deep reinforcement learning to achieve recovery-aware navigation, enabling robust locomotion and autonomous fall recovery on diverse terrains, including indoor navigation, with low-cost perception.", "motivation": "Wheeled-legged robots offer efficiency and obstacle negotiation, but current systems rely on costly actuators/sensors and lack integrated fall recovery. The work targets budget platforms by enabling recovery-aware navigation.", "method": "A recovery-aware visual-inertial navigation system using depth-camera perception combined with deep reinforcement learning policies for robust locomotion and autonomous recovery from falls. Evaluation includes simulation across irregular terrains and goal-directed indoor navigation with inexpensive sensing.", "result": "Demonstrates agile mobility with low-torque actuators on irregular terrain and reliable recovery from external perturbations and self-induced failures; shows goal-directed indoor navigation with budget perception.", "conclusion": "The approach lowers barriers to deploying autonomous navigation and robust locomotion policies on budget robotic platforms."}}
{"id": "2510.23744", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23744", "abs": "https://arxiv.org/abs/2510.23744", "authors": ["Eline M. Bovy", "Caleb Probine", "Marnix Suilen", "Ufuk Topcu", "Nils Jansen"], "title": "Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability", "comment": "Accepted at NeurIPS 2025", "summary": "Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete\nmodel uncertainty. ME-POMDPs represent a finite set of POMDPs that share the\nsame state, action, and observation spaces, but may arbitrarily vary in their\ntransition, observation, and reward models. Such models arise, for instance,\nwhen multiple domain experts disagree on how to model a problem. The goal is to\nfind a single policy that is robust against any choice of POMDP within the set,\ni.e., a policy that maximizes the worst-case reward across all POMDPs. We\ngeneralize and expand on existing work in the following way. First, we show\nthat ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which\nwe call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any\narbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its\ntransition and reward functions or only in its observation and reward\nfunctions, while preserving (optimal) policies. We then devise exact and\napproximate (point-based) algorithms to compute robust policies for AB-POMDPs,\nand thus ME-POMDPs. We demonstrate that we can compute policies for standard\nPOMDP benchmarks extended to the multi-environment setting.", "AI": {"tldr": "Proposes robust planning under model uncertainty by extending POMDPs to multiple environments (ME-POMDPs) and adversarial-belief POMDPs (AB-POMDPs); develops reductions between variants and offers exact and approximate algorithms to compute robust policies, validated on standard benchmarks extended to multi-environment settings.", "motivation": "Real-world problems often involve disagreement among domain experts leading to varied models. A single policy that performs well under worst-case model selection is desirable.", "method": "Introduce AB-POMDPs with adversarial belief sets; prove reductions showing ME-POMDPs can be transformed to restricted variants (varying only transitions/rewards or only observations/rewards); develop exact and point-based approximate algorithms to compute robust policies; extend standard POMDP benchmarks to multi-environment settings.", "result": "Formal framework for robust policies under model uncertainty; reductions that preserve optimal policies; algorithms (exact and point-based) to compute policies; empirical demonstrations on standard benchmarks extended to multiple environments.", "conclusion": "The work generalizes ME-POMDPs to AB-POMDPs, enabling robust policy computation under structured model uncertainty, with practical algorithms and empirical validation on benchmarks."}}
{"id": "2510.23622", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.23622", "abs": "https://arxiv.org/abs/2510.23622", "authors": ["Alyssa Gerhart", "Balaji Iyangar"], "title": "Adversarially-Aware Architecture Design for Robust Medical AI Systems", "comment": null, "summary": "Adversarial attacks pose a severe risk to AI systems used in healthcare,\ncapable of misleading models into dangerous misclassifications that can delay\ntreatments or cause misdiagnoses. These attacks, often imperceptible to human\nperception, threaten patient safety, particularly in underserved populations.\nOur study explores these vulnerabilities through empirical experimentation on a\ndermatological dataset, where adversarial methods significantly reduce\nclassification accuracy. Through detailed threat modeling, experimental\nbenchmarking, and model evaluation, we demonstrate both the severity of the\nthreat and the partial success of defenses like adversarial training and\ndistillation. Our results show that while defenses reduce attack success rates,\nthey must be balanced against model performance on clean data. We conclude with\na call for integrated technical, ethical, and policy-based approaches to build\nmore resilient, equitable AI in healthcare.", "AI": {"tldr": "Adversarial attacks threaten healthcare AI systems by causing dangerous misclassifications; defenses offer partial mitigation but degrade performance on clean data; calls for a holistic, ethics-informed resilience approach.", "motivation": "Safeguard patient safety and equity in AI-based healthcare by understanding vulnerabilities and strengthening defenses.", "method": "Empirical study on a dermatological dataset with adversarial attacks; includes threat modeling, benchmarking, and model evaluation; assesses defenses such as adversarial training and distillation.", "result": "Adversarial methods substantially reduce classification accuracy; defenses lower attack success but at cost to clean-data performance; defenses are only partially effective, highlighting trade-offs between robustness and accuracy.", "conclusion": "Advocates integrated technical, ethical, and policy-based strategies to build more resilient and equitable healthcare AI."}}
{"id": "2510.23907", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23907", "abs": "https://arxiv.org/abs/2510.23907", "authors": ["Eddison Pham", "Prisha Priyadarshini", "Adrian Maliackel", "Kanishk Bandi", "Cristian Meo", "Kevin Zhu"], "title": "DynaStride: Dynamic Stride Windowing with MMCoT for Instructional Multi-Scene Captioning", "comment": "16 pages, 15 figures, 5 Tables, submitted to AAAI AI4ED Workshop 2026", "summary": "Scene-level captioning in instructional videos can enhance learning by\nrequiring an understanding of both visual cues and temporal structure. By\naligning visual cues with textual guidance, this understanding supports\nprocedural learning and multimodal reasoning, providing a richer context for\nskill acquisition. However, captions that fail to capture this structure may\nlack coherence and quality, which can create confusion and undermine the\nvideo's educational intent. To address this gap, we introduce DynaStride, a\npipeline to generate coherent, scene-level captions without requiring manual\nscene segmentation. Using the YouCookII dataset's scene annotations, DynaStride\nperforms adaptive frame sampling and multimodal windowing to capture key\ntransitions within each scene. It then employs a multimodal chain-of-thought\nprocess to produce multiple action-object pairs, which are refined and fused\nusing a dynamic stride window selection algorithm that adaptively balances\ntemporal context and redundancy. The final scene-level caption integrates\nvisual semantics and temporal reasoning in a single instructional caption.\nEmpirical evaluations against strong baselines, including VLLaMA3 and GPT-4o,\ndemonstrate consistent gains on both N-gram-based metrics (BLEU, METEOR) and\nsemantic similarity measures (BERTScore, CLIPScore). Qualitative analyses\nfurther show that DynaStride produces captions that are more temporally\ncoherent and informative, suggesting a promising direction for improving\nAI-powered instructional content generation.", "AI": {"tldr": "DynaStride yields coherent scene-level captions for instructional videos without manual scene segmentation, via adaptive sampling, multimodal reasoning, and dynamic stride fusion, and outperforms strong baselines on BLEU, METEOR, BERTScore, and CLIPScore.", "motivation": "Captions that miss temporal structure can hinder learning; there is a need to align visual cues with textual guidance to support procedural learning and multimodal reasoning in instructional videos.", "method": "The pipeline leverages YouCookII scene annotations to perform adaptive frame sampling and multimodal windowing to capture key scene transitions, uses a multimodal chain-of-thought to generate multiple action-object pairs, refines and fuses these with a dynamic stride window selection algorithm that balances temporal context and redundancy, and produces a final scene-level caption integrating visual semantics and temporal reasoning.", "result": "Empirical evaluations against strong baselines (e.g., VLLaMA3 and GPT-4o) show consistent gains on BLEU, METEOR, BERTScore, and CLIPScore; qualitative analyses indicate improved temporal coherence and informativeness of the captions.", "conclusion": "DynaStride is a promising direction for AI-powered instructional content generation, enabling coherent scene-level captions without manual segmentation and better aligning visuals with textual guidance for instructional learning."}}
{"id": "2510.23928", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23928", "abs": "https://arxiv.org/abs/2510.23928", "authors": ["Raman Jha", "Yang Zhou", "Giuseppe Loianno"], "title": "Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments", "comment": "Under Review for ROBOVIS 2026", "summary": "In this paper, we propose an adaptive keyframe selection method for improved\n3D scene reconstruction in dynamic environments. The proposed method integrates\ntwo complementary modules: an error-based selection module utilizing\nphotometric and structural similarity (SSIM) errors, and a momentum-based\nupdate module that dynamically adjusts keyframe selection thresholds according\nto scene motion dynamics. By dynamically curating the most informative frames,\nour approach addresses a key data bottleneck in real-time perception. This\nallows for the creation of high-quality 3D world representations from a\ncompressed data stream, a critical step towards scalable robot learning and\ndeployment in complex, dynamic environments. Experimental results demonstrate\nsignificant improvements over traditional static keyframe selection strategies,\nsuch as fixed temporal intervals or uniform frame skipping. These findings\nhighlight a meaningful advancement toward adaptive perception systems that can\ndynamically respond to complex and evolving visual scenes. We evaluate our\nproposed adaptive keyframe selection module on two recent state-of-the-art 3D\nreconstruction networks, Spann3r and CUT3R, and observe consistent improvements\nin reconstruction quality across both frameworks. Furthermore, an extensive\nablation study confirms the effectiveness of each individual component in our\nmethod, underlining their contribution to the overall performance gains.", "AI": {"tldr": "Adaptive keyframe selection for dynamic 3D scene reconstruction using two modules: error-based frame selection leveraging photometric and SSIM errors, and a momentum-based updater that tunes selection thresholds by scene motion; yields better reconstruction than fixed-interval strategies and improves two leading 3D reconstructions networks (Spann3r and CUT3R).", "motivation": "Address data bottlenecks in real-time perception and enable scalable robot learning by compressing data streams while maintaining high-quality 3D world representations in dynamic environments.", "method": "Two-module approach: (1) error-based selection using photometric error and SSIM to pick informative frames; (2) momentum-based update to adapt selection thresholds to motion dynamics; evaluate by integrating with Spann3r and CUT3R and performing ablations to isolate component contributions.", "result": "Significant improvements over traditional fixed-interval or uniform skipping strategies; consistent reconstruction quality gains across both networks; ablation studies confirm the contribution of each component.", "conclusion": "Adaptive, dynamic keyframe selection advances perceptual systems able to respond to evolving scenes and supports scalable, real-time 3D reconstruction in complex environments."}}
{"id": "2510.23746", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23746", "abs": "https://arxiv.org/abs/2510.23746", "authors": ["Laura Mismetti", "Marvin Alberts", "Andreas Krause", "Mara Graziani"], "title": "Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra", "comment": null, "summary": "Tandem Mass Spectrometry enables the identification of unknown compounds in\ncrucial fields such as metabolomics, natural product discovery and\nenvironmental analysis. However, current methods rely on database matching from\npreviously observed molecules, or on multi-step pipelines that require\nintermediate fragment or fingerprint prediction. This makes finding the correct\nmolecule highly challenging, particularly for compounds absent from reference\ndatabases. We introduce a framework that, by leveraging test-time tuning,\nenhances the learning of a pre-trained transformer model to address this gap,\nenabling end-to-end de novo molecular structure generation directly from the\ntandem mass spectra and molecular formulae, bypassing manual annotations and\nintermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on\ntwo popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.\nTest-time tuning on experimental spectra allows the model to dynamically adapt\nto novel spectra, and the relative performance gain over conventional\nfine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground\ntruth, the generated molecular candidates remain structurally accurate,\nproviding valuable guidance for human interpretation and more reliable\nidentification.", "AI": {"tldr": "A test-time tuned transformer framework enables end-to-end de novo molecular structure generation directly from tandem MS data and molecular formulas, surpassing DiffMS on NPLIB1 and MassSpecGym with notable gains and robustness to novel spectra.", "motivation": "Current tandem MS-based identification relies on database matching or multi-step pipelines, which struggle for compounds not in reference databases. There is a need for end-to-end de novo generation from spectra (and formulas) without intermediate annotations.", "method": "Pre-trained transformer model subjected to test-time tuning using tandem mass spectra and molecular formulae to generate molecular structures directly, bypassing fragment/fingerprint prediction and manual annotations; evaluated on NPLIB1 and MassSpecGym.", "result": "Outperforms the de facto state-of-the-art DiffMS by 100% on NPLIB1 and 20% on MassSpecGym; test-time tuning yields a 62% relative gain over conventional fine-tuning on MassSpecGym; generated candidates remain structurally accurate when not exact, aiding human interpretation.", "conclusion": "Test-time tuning improves end-to-end de novo molecular structure generation from tandem MS data, reducing reliance on databases, and providing robust, structurally accurate candidates to assist identification in metabolomics, natural product discovery, and environmental analysis."}}
{"id": "2510.23624", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23624", "abs": "https://arxiv.org/abs/2510.23624", "authors": ["Tiago Mendon\u00e7a dos Santos", "Rafael Izbicki", "Lu\u00eds Gustavo Esteves"], "title": "DiNo and RanBu: Lightweight Predictions from Shallow Random Forests", "comment": null, "summary": "Random Forest ensembles are a strong baseline for tabular prediction tasks,\nbut their reliance on hundreds of deep trees often results in high inference\nlatency and memory demands, limiting deployment in latency-sensitive or\nresource-constrained environments. We introduce DiNo (Distance with Nodes) and\nRanBu (Random Bushes), two shallow-forest methods that convert a small set of\ndepth-limited trees into efficient, distance-weighted predictors. DiNo measures\ncophenetic distances via the most recent common ancestor of observation pairs,\nwhile RanBu applies kernel smoothing to Breiman's classical proximity measure.\nBoth approaches operate entirely after forest training: no additional trees are\ngrown, and tuning of the single bandwidth parameter $h$ requires only\nlightweight matrix-vector operations. Across three synthetic benchmarks and 25\npublic datasets, RanBu matches or exceeds the accuracy of full-depth random\nforests-particularly in high-noise settings-while reducing training plus\ninference time by up to 95\\%. DiNo achieves the best bias-variance trade-off in\nlow-noise regimes at a modest computational cost. Both methods extend directly\nto quantile regression, maintaining accuracy with substantial speed gains. The\nimplementation is available as an open-source R/C++ package at\nhttps://github.com/tiagomendonca/dirf. We focus on structured tabular random\nsamples (i.i.d.), leaving extensions to other modalities for future work.", "AI": {"tldr": "Two shallow-forest methods (DiNo and RanBu) convert a small set of depth-limited trees into fast, distance-weighted predictors, achieving similar or better accuracy than full random forests with large speedups; extendable to quantile regression; open-source.", "motivation": "Reduce inference latency and memory usage of random forests on tabular data, enabling deployment in latency-sensitive or resource-constrained environments, while preserving accuracy, especially under noise.", "method": "DiNo measures cophenetic distances via the most recent common ancestor of observation pairs; RanBu applies kernel smoothing to Breiman's proximity. Both methods operate post-training: no new trees are grown, require tuning a single bandwidth h, and rely on lightweight matrix-vector operations.", "result": "RanBu matches or exceeds the accuracy of full-depth random forests, particularly in high-noise settings, with up to 95% reduction in training and inference time. DiNo provides a favorable bias-variance trade-off in low-noise regimes at a modest computational cost. Both extend to quantile regression with substantial speed gains. Tested on three synthetic benchmarks and 25 public datasets.", "conclusion": "These methods offer efficient, accurate alternatives to deep random forests for structured tabular data, enabling deployment in resource-constrained settings; an open-source R/C++ package is available, with future work including extensions to other modalities."}}
{"id": "2510.23929", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23929", "abs": "https://arxiv.org/abs/2510.23929", "authors": ["Emily Kim", "Julieta Martinez", "Timur Bagautdinov", "Jessica Hodgins"], "title": "TurboPortrait3D: Single-step diffusion-based fast portrait novel-view synthesis", "comment": null, "summary": "We introduce TurboPortrait3D: a method for low-latency novel-view synthesis\nof human portraits. Our approach builds on the observation that existing\nimage-to-3D models for portrait generation, while capable of producing\nrenderable 3D representations, are prone to visual artifacts, often lack of\ndetail, and tend to fail at fully preserving the identity of the subject. On\nthe other hand, image diffusion models excel at generating high-quality images,\nbut besides being computationally expensive, are not grounded in 3D and thus\nare not directly capable of producing multi-view consistent outputs. In this\nwork, we demonstrate that image-space diffusion models can be used to\nsignificantly enhance the quality of existing image-to-avatar methods, while\nmaintaining 3D-awareness and running with low-latency. Our method takes a\nsingle frontal image of a subject as input, and applies a feedforward\nimage-to-avatar generation pipeline to obtain an initial 3D representation and\ncorresponding noisy renders. These noisy renders are then fed to a single-step\ndiffusion model which is conditioned on input image(s), and is specifically\ntrained to refine the renders in a multi-view consistent way. Moreover, we\nintroduce a novel effective training strategy that includes pre-training on a\nlarge corpus of synthetic multi-view data, followed by fine-tuning on\nhigh-quality real images. We demonstrate that our approach both qualitatively\nand quantitatively outperforms current state-of-the-art for portrait novel-view\nsynthesis, while being efficient in time.", "AI": {"tldr": "TurboPortrait3D blends an image-to-3D avatar pipeline with a single-step image-space diffusion refinement to produce low-latency, multi-view-consistent portrait renders, trained with synthetic pretraining and real-image fine-tuning, claiming state-of-the-art quality and efficiency.", "motivation": "Existing image-to-3D portrait methods suffer from artifacts, detail loss, and identity drift; diffusion models offer high-quality outputs but are expensive and not inherently 3D-consistent. A hybrid approach aims to combine 3D grounding with diffusion-based refinement to achieve better quality, identity preservation, and low latency.", "method": "Generate an initial 3D representation and noisy renders from a single frontal image using a feedforward image-to-avatar pipeline. Refine these renders with a single-step, view-conditioned diffusion model trained to enforce multi-view consistency and realism. Training strategy: pre-train on synthetic multi-view data, then fine-tune on high-quality real images. Output is a refined, multi-view-consistent 3D portrait with low latency.", "result": "Qualitative and quantitative improvements over current state-of-the-art in portrait novel-view synthesis. Demonstrates better detail, identity preservation, and consistency, with efficient runtime suited for practical use.", "conclusion": "A practical, efficient framework for 3D-aware portrait synthesis that leverages diffusion-based refinement to enhance image-to-3D outputs, achieving superior quality and 3D consistency while maintaining low latency."}}
{"id": "2510.23954", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23954", "abs": "https://arxiv.org/abs/2510.23954", "authors": ["Pejman Kheradmand", "Behnam Moradkhani", "Raghavasimhan Sankaranarayanan", "Kent K. Yamamoto", "Tanner J. Zachem", "Patrick J. Codd", "Yash Chitalia", "Pierre E. Dupont"], "title": "A Comprehensive General Model of Tendon-Actuated Concentric Tube Robots with Multiple Tubes and Tendons", "comment": null, "summary": "Tendon-actuated concentric tube mechanisms combine the advantages of\ntendon-driven continuum robots and concentric tube robots while addressing\ntheir respective limitations. They overcome the restricted degrees of freedom\noften seen in tendon-driven designs, and mitigate issues such as snapping\ninstability associated with concentric tube robots. However, a complete and\ngeneral mechanical model for these systems remains an open problem. In this\nwork, we propose a Cosserat rod-based framework for modeling the general case\nof $n$ concentric tubes, each actuated by $m_i$ tendons, where $i = \\{1,\n\\ldots, n\\}$. The model allows each tube to twist and elongate while enforcing\na shared centerline for bending. We validate the proposed framework through\nexperiments with two-tube and three tube assemblies under various tendon\nrouting configurations, achieving tip prediction errors $<4\\%$ of the robot's\ntotal length. We further demonstrate the model's generality by applying it to\nexisting robots in the field, where maximum tip deviations remain around $5\\%$\nof the total length. This model provides a foundation for accurate shape\nestimation and control of advanced tendon-actuated concentric tube robots.", "AI": {"tldr": "Cosserat-rod based modeling framework for tendon-actuated concentric tube robots with multiple tubes, validated experimentally, achieving low tip errors and generalizable to existing robots.", "motivation": "Address the lack of a complete, general mechanical model for tendon-actuated concentric tube mechanisms, enabling accurate shape estimation and control while overcoming limitations of tendon-driven and concentric tube robots.", "method": "Develop a Cosserat rod-based framework for n concentric tubes, each with m_i actuated tendons; allow twisting and elongation; enforce a shared centerline for bending; validate with 2-tube and 3-tube experiments across various tendon routings, then test on existing robots.", "result": "Tip prediction errors <4% of the robot length for two- and three-tube assemblies; maximum tip deviations around 5% when applied to existing robots, demonstrating generality and accuracy.", "conclusion": "Provides a general, accurate model foundation for shape estimation and control of tendon-actuated concentric tube robots, applicable to diverse configurations and existing devices."}}
{"id": "2510.23772", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23772", "abs": "https://arxiv.org/abs/2510.23772", "authors": ["Vivek Veeriah", "Federico Barbero", "Marcus Chiam", "Xidong Feng", "Michael Dennis", "Ryan Pachauri", "Thomas Tumiel", "Johan Obando-Ceron", "Jiaxin Shi", "Shaobo Hou", "Satinder Singh", "Nenad Toma\u0161ev", "Tom Zahavy"], "title": "Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions", "comment": "Accepted at the Creative AI Track, NeurIPS 2025", "summary": "The rapid advancement of Generative AI has raised significant questions\nregarding its ability to produce creative and novel outputs. Our recent work\ninvestigates this question within the domain of chess puzzles and presents an\nAI system designed to generate puzzles characterized by aesthetic appeal,\nnovelty, counter-intuitive and unique solutions. We briefly discuss our method\nbelow and refer the reader to the technical paper for more details. To assess\nour system's creativity, we presented a curated booklet of AI-generated puzzles\nto three world-renowned experts: International Master for chess compositions\nAmatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All\nthree are noted authors on chess aesthetics and the evolving role of computers\nin the game. They were asked to select their favorites and explain what made\nthem appealing, considering qualities such as their creativity, level of\nchallenge, or aesthetic design.", "AI": {"tldr": "A study evaluating the creativity of AI-generated chess puzzles via expert evaluation of a curated set.", "motivation": "To determine whether Generative AI can produce creative, novel chess puzzles with appealing aesthetics, novelty, and unique solutions.", "method": "Develop an AI puzzle generator; generate puzzles with intended aesthetic/novelty criteria; assemble a curated booklet; present to three renowned chess composition experts (Amatzia Avni, Jonathan Levitt, Matthew Sadler); collect their favorite puzzles and explanations focusing on creativity, challenge, and design.", "result": "Experts selected favorites and provided qualitative explanations; the abstract reports qualitative feedback rather than quantitative metrics; detailed results are in the technical paper.", "conclusion": "The abstract suggests the approach is exploratory and qualitative, illustrating a path to assessing AI creativity in chess puzzles; further technical details and results are in the cited paper."}}
{"id": "2510.23626", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23626", "abs": "https://arxiv.org/abs/2510.23626", "authors": ["Shuang Geng", "Wenli Zhang", "Jiaheng Xie", "Rui Wang", "Sudha Ram"], "title": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media", "comment": "Presented at SWAIB2025 and HICSS2026", "summary": "Social media user-generated content (UGC) provides real-time, self-reported\nindicators of mental health conditions such as depression, offering a valuable\nsource for predictive analytics. While prior studies integrate medical\nknowledge to improve prediction accuracy, they overlook the opportunity to\nsimultaneously expand such knowledge through predictive processes. We develop a\nClosed-Loop Large Language Model (LLM)-Knowledge Graph framework that\nintegrates prediction and knowledge expansion in an iterative learning cycle.\nIn the knowledge-aware depression detection phase, the LLM jointly performs\ndepression detection and entity extraction, while the knowledge graph\nrepresents and weights these entities to refine prediction performance. In the\nknowledge refinement and expansion phase, new entities, relationships, and\nentity types extracted by the LLM are incorporated into the knowledge graph\nunder expert supervision, enabling continual knowledge evolution. Using\nlarge-scale UGC, the framework enhances both predictive accuracy and medical\nunderstanding. Expert evaluations confirmed the discovery of clinically\nmeaningful symptoms, comorbidities, and social triggers complementary to\nexisting literature. We conceptualize and operationalize\nprediction-through-learning and learning-through-prediction as mutually\nreinforcing processes, advancing both methodological and theoretical\nunderstanding in predictive analytics. The framework demonstrates the\nco-evolution of computational models and domain knowledge, offering a\nfoundation for adaptive, data-driven knowledge systems applicable to other\ndynamic risk monitoring contexts.", "AI": {"tldr": "A closed-loop LLM\u2013knowledge graph framework for depression risk detection from social media UGC that jointly detects depression and extracts entities, uses a knowledge graph to refine predictions, and iteratively expands knowledge under expert supervision, achieving improved prediction and richer clinical understanding through prediction-learning cycles.", "motivation": "Despite incorporating medical knowledge for accuracy, prior work misses opportunities to expand medical knowledge via predictive processes; there is a need for adaptive, co-evolving knowledge systems for dynamic mental health monitoring.", "method": "Two-phase loop: (1) knowledge-aware depression detection where the LLM jointly detects depression and extracts entities, building and weighting a knowledge graph to refine predictions. (2) knowledge refinement and expansion where the LLM outputs new entities, relationships, and entity types that experts then incorporate into the KG for continual evolution.", "result": "Applied to large-scale user-generated content, the framework achieves improved predictive accuracy and deeper medical understanding; expert evaluations identify clinically meaningful symptoms, comorbidities, and social triggers that complement existing literature.", "conclusion": "Introduces and operationalizes prediction-through-learning and learning-through-prediction as mutually reinforcing processes; demonstrates co-evolution of computational models and domain knowledge; provides a foundation for adaptive, data-driven knowledge systems for dynamic risk monitoring and extends to other domains."}}
{"id": "2510.23930", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23930", "abs": "https://arxiv.org/abs/2510.23930", "authors": ["Xirui Jin", "Renbiao Jin", "Boying Li", "Danping Zou", "Wenxian Yu"], "title": "PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors", "comment": "Accepted by NeurIPS 2025. Project page: https://planargs.github.io", "summary": "Three-dimensional Gaussian Splatting (3DGS) has recently emerged as an\nefficient representation for novel-view synthesis, achieving impressive visual\nquality. However, in scenes dominated by large and low-texture regions, common\nin indoor environments, the photometric loss used to optimize 3DGS yields\nambiguous geometry and fails to recover high-fidelity 3D surfaces. To overcome\nthis limitation, we introduce PlanarGS, a 3DGS-based framework tailored for\nindoor scene reconstruction. Specifically, we design a pipeline for\nLanguage-Prompted Planar Priors (LP3) that employs a pretrained vision-language\nsegmentation model and refines its region proposals via cross-view fusion and\ninspection with geometric priors. 3D Gaussians in our framework are optimized\nwith two additional terms: a planar prior supervision term that enforces planar\nconsistency, and a geometric prior supervision term that steers the Gaussians\ntoward the depth and normal cues. We have conducted extensive experiments on\nstandard indoor benchmarks. The results show that PlanarGS reconstructs\naccurate and detailed 3D surfaces, consistently outperforming state-of-the-art\nmethods by a large margin. Project page: https://planargs.github.io", "AI": {"tldr": "PlanarGS enhances 3D Gaussian Splatting for indoor scenes by injecting language-guided planar priors and geometric cues, yielding accurate, high-detail surfaces and large gains over state-of-the-art methods.", "motivation": "Photometric loss in 3D Gaussian Splatting struggles in large, low-texture indoor regions, producing ambiguous geometry; there is a need for explicit priors to guide surface reconstruction.", "method": "Introduce LP3 (Language-Prompted Planar Priors) using a pretrained vision-language segmentation model to propose planar regions, refined via cross-view fusion and geometric priors. Optimize 3D Gaussians with two additional supervision terms: planar prior supervision enforcing planar consistency, and geometric prior supervision aligning depth and normals with the Gaussians.", "result": "Extensive experiments on standard indoor benchmarks show PlanarGS reconstructs accurate and detailed 3D surfaces and consistently outperforms state-of-the-art methods by a large margin.", "conclusion": "PlanarGS demonstrates that incorporating planar priors and geometric cues into 3D Gaussian Splatting is effective for indoor scene reconstruction, suggesting a promising direction for integrating high-level priors into neural implicit representations."}}
{"id": "2510.23963", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23963", "abs": "https://arxiv.org/abs/2510.23963", "authors": ["Hiroki Ishikawa", "Kyosuke Ishibashi", "Ko Yamamoto"], "title": "Adaptive-twist Soft Finger Mechanism for Grasping by Wrapping", "comment": null, "summary": "This paper presents a soft robot finger capable of adaptive-twist deformation\nto grasp objects by wrapping them. For a soft hand to grasp and pick-up one\nobject from densely contained multiple objects, a soft finger requires the\nadaptive-twist deformation function in both in-plane and out-of-plane\ndirections. The function allows the finger to be inserted deeply into a limited\ngap among objects. Once inserted, the soft finger requires appropriate control\nof grasping force normal to contact surface, thereby maintaining the twisted\ndeformation. In this paper, we refer to this type of grasping as grasping by\nwrapping. To achieve these two functions by a single actuation source, we\npropose a variable stiffness mechanism that can adaptively change the stiffness\nas the pressure is higher. We conduct a finite element analysis (FEA) on the\nproposed mechanism and determine its design parameter based on the FEA result.\nUsing the developed soft finger, we report basic experimental results and\ndemonstrations on grasping various objects.", "AI": {"tldr": "A soft robot finger with adaptive-twist deformation and a single, pressure-controlled variable stiffness actuation enables wrapping-based grasping in cluttered environments; validated via FEA and basic experiments.", "motivation": "Grasping in dense object scenes requires fingers that can twist in both in-plane and out-of-plane directions, insert deeply into gaps, and apply controlled normal force to maintain the twist, all from a single actuation source.", "method": "Introduce a variable stiffness mechanism that increases stiffness with higher pressure; perform finite element analysis to determine design parameters; fabricate the soft finger and demonstrate grasping of various objects through wrapping.", "result": "FEA-guided design parameters obtained; basic experimental demonstrations show the finger can wrap and grasp diverse objects, including insertion into tight gaps and maintaining deformation during grasp.", "conclusion": "A single-actuation, variable-stiffness soft finger enabling adaptive-twist, wrap-based grasping in cluttered environments; potential for more robust soft grippers; future work could optimize performance and range of objects."}}
{"id": "2510.23807", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23807", "abs": "https://arxiv.org/abs/2510.23807", "authors": ["Hamid R. Tizhoosh"], "title": "Why Foundation Models in Pathology Are Failing", "comment": null, "summary": "In non-medical domains, foundation models (FMs) have revolutionized computer\nvision and language processing through large-scale self-supervised and\nmultimodal learning. Consequently, their rapid adoption in computational\npathology was expected to deliver comparable breakthroughs in cancer diagnosis,\nprognostication, and multimodal retrieval. However, recent systematic\nevaluations reveal fundamental weaknesses: low diagnostic accuracy, poor\nrobustness, geometric instability, heavy computational demands, and concerning\nsafety vulnerabilities. This short paper examines these shortcomings and argues\nthat they stem from deeper conceptual mismatches between the assumptions\nunderlying generic foundation modeling in mainstream AI and the intrinsic\ncomplexity of human tissue. Seven interrelated causes are identified:\nbiological complexity, ineffective self-supervision, overgeneralization,\nexcessive architectural complexity, lack of domain-specific innovation,\ninsufficient data, and a fundamental design flaw related to tissue patch size.\nThese findings suggest that current pathology foundation models remain\nconceptually misaligned with the nature of tissue morphology and call for a\nfundamental rethinking of the paradigm itself.", "AI": {"tldr": "Foundations models in computational pathology underperform due to seven root causes tied to tissue complexity, calling for a paradigm rethink.", "motivation": "To diagnose why generic foundation modeling fails in pathology and to guide principled improvements aligned with tissue morphology.", "method": "Conceptual critique that identifies and enumerates seven interrelated causes behind observed weaknesses.", "result": "Seven root causes: biological complexity, ineffective self-supervision, overgeneralization, excessive architectural complexity, lack of domain-specific innovation, insufficient data, and a fundamental design flaw related to tissue patch size. These causes explain low accuracy, poor robustness, geometric instability, high compute, and safety concerns, indicating misalignment with tissue morphology.", "conclusion": "Current pathology foundation models are conceptually misaligned with tissue morphology, necessitating a fundamental paradigm rethink rather than incremental fixes."}}
{"id": "2510.23629", "categories": ["cs.LG", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.23629", "abs": "https://arxiv.org/abs/2510.23629", "authors": ["Nuo Chen", "Zehua Li", "Keqin Bao", "Junyang Lin", "Dayiheng Liu"], "title": "Chain of Execution Supervision Promotes General Reasoning in Large Language Models", "comment": null, "summary": "Building robust and general reasoning ability is a central goal in the\ndevelopment of large language models (LLMs). Recent efforts increasingly turn\nto code as a rich training source, given its inherent logical structure and\ndiverse reasoning paradigms such as divide-and-conquer, topological ordering,\nand enumeration. However, reasoning in code is often expressed implicitly and\nentangled with syntactic or implementation noise, making direct training on raw\ncode suboptimal.To address this, we introduce TracePile, a large-scale corpus\nof 2.6 million samples that transforms code execution into explicit,\nstep-by-step chain-of-thought-style rationales, which we call Chain of\nExecution (CoE). The corpus spans domains including mathematics, classical\nalgorithms and algorithmic competition, and is enriched with variable-tracing\nquestions and code rewritings to enhance logical granularity and code\ndiversity. We evaluate TracePile using three training setups:\ncontinue-pretraining, instruction tuning after pretraining, and two-stage\nfinetuning. Experiments across four base models (LLaMA 3, LLaMA 3.1, Qwen-2.5,\nand Qwen-2.5 Coder) and 20 benchmarks covering math, code, logic, and\nalgorithms demonstrate consistent improvements. Notably, TracePile boosts\nLLaMA3.1-8B by 7.1\\% on average across nine math datasets and delivers clear\ngains on LiveCodeBench, CRUX, and MMLU under two-stage fine-tuning.", "AI": {"tldr": "TracePile introduces a 2.6M-sample corpus that converts code execution into explicit, step-by-step Chain of Execution (CoE) rationales to bolster robust reasoning in LLMs. It spans math, algorithms, and coding domains, and uses variable-tracing and code rewriting to enhance granularity. Across four base models and 20 benchmarks, it yields consistent gains, notably +7.1% average on math for LLaMA3.1-8B and improvements on LiveCodeBench, CRUX, and MMLU with two-stage fine-tuning.", "motivation": "Code contains rich logic but reasoning is often implicit and noisy; explicit CoE derived from code execution could disentangle reasoning from syntax and noise, enabling scalable improvements in general reasoning for LLMs.", "method": "Construct TracePile by transforming code execution traces into Chain of Execution (CoE) rationales; include domains such as math, classical algorithms, and algorithmic competition; add variable-tracing questions and code rewritings to increase logical granularity and diversity; evaluate with continue-pretraining, instruction tuning after pretraining, and two-stage finetuning across four base models (LLaMA 3, LLaMA 3.1, Qwen-2.5, Qwen-2.5 Coder) on 20 benchmarks spanning math, code, logic, and algorithms.", "result": "TracePile yields consistent improvements across models and benchmarks; for example, LLaMA3.1-8B shows an average +7.1% gain on nine math datasets; two-stage fine-tuning yields clear gains on LiveCodeBench, CRUX, and MMLU.", "conclusion": "Explicitly tracing code execution as CoE is a viable pathway to enhance reasoning in LLMs, with large gains under structured fine-tuning; the dataset's breadth and multi-domain focus support broader generalization of reasoning abilities."}}
{"id": "2510.23943", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23943", "abs": "https://arxiv.org/abs/2510.23943", "authors": ["Diana Aldana", "Jo\u00e3o Paulo Lima", "Daniel Csillag", "Daniel Perazzo", "Haoan Feng", "Luiz Velho", "Tiago Novello"], "title": "Adaptive Training of INRs via Pruning and Densification", "comment": null, "summary": "Encoding input coordinates with sinusoidal functions into multilayer\nperceptrons (MLPs) has proven effective for implicit neural representations\n(INRs) of low-dimensional signals, enabling the modeling of high-frequency\ndetails. However, selecting appropriate input frequencies and architectures\nwhile managing parameter redundancy remains an open challenge, often addressed\nthrough heuristics and heavy hyperparameter optimization schemes. In this\npaper, we introduce AIRe ($\\textbf{A}$daptive $\\textbf{I}$mplicit neural\n$\\textbf{Re}$presentation), an adaptive training scheme that refines the INR\narchitecture over the course of optimization. Our method uses a neuron pruning\nmechanism to avoid redundancy and input frequency densification to improve\nrepresentation capacity, leading to an improved trade-off between network size\nand reconstruction quality. For pruning, we first identify less-contributory\nneurons and apply a targeted weight decay to transfer their information to the\nremaining neurons, followed by structured pruning. Next, the densification\nstage adds input frequencies to spectrum regions where the signal underfits,\nexpanding the representational basis. Through experiments on images and SDFs,\nwe show that AIRe reduces model size while preserving, or even improving,\nreconstruction quality. Code and pretrained models will be released for public\nuse.", "AI": {"tldr": "AIRe is an adaptive training scheme for implicit neural representations (INRs) that prunes neurons and densifies input frequencies during training to reduce model size while maintaining or improving reconstruction quality in low-dimensional signal modeling.", "motivation": "INRs for encoding coordinates suffer from redundancy in parameters and a need to hand-tune input frequencies and architectures; current approaches rely on heuristics and expensive hyperparameter optimization. An adaptive method could automatically balance model size and expressiveness.", "method": "AIRe uses a two-stage adaptive training process: (1) pruning stage identifies less-contributory neurons and applies targeted weight decay to transfer their information to remaining neurons, followed by structured pruning to remove redundancies; (2) densification stage adds input frequencies to spectrum regions where the signal underfits, expanding the representational basis. The scheme refines the INR architecture during optimization to optimize the size-quality trade-off.", "result": "Experiments on images and signed distance functions (SDFs) show AIRe reduces model size while preserving or improving reconstruction quality compared to baselines.", "conclusion": "Adaptive pruning and input frequency densification during training yield more efficient INRs, achieving a better size-to-quality trade-off; code and pretrained models are planned for release."}}
{"id": "2510.23988", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.23988", "abs": "https://arxiv.org/abs/2510.23988", "authors": ["Phuc Nguyen Xuan", "Thanh Nguyen Canh", "Huu-Hung Nguyen", "Nak Young Chong", "Xiem HoangVan"], "title": "A Survey on Collaborative SLAM with 3D Gaussian Splatting", "comment": null, "summary": "This survey comprehensively reviews the evolving field of multi-robot\ncollaborative Simultaneous Localization and Mapping (SLAM) using 3D Gaussian\nSplatting (3DGS). As an explicit scene representation, 3DGS has enabled\nunprecedented real-time, high-fidelity rendering, ideal for robotics. However,\nits use in multi-robot systems introduces significant challenges in maintaining\nglobal consistency, managing communication, and fusing data from heterogeneous\nsources. We systematically categorize approaches by their architecture --\ncentralized, distributed -- and analyze core components like multi-agent\nconsistency and alignment, communication-efficient, Gaussian representation,\nsemantic distillation, fusion and pose optimization, and real-time scalability.\nIn addition, a summary of critical datasets and evaluation metrics is provided\nto contextualize performance. Finally, we identify key open challenges and\nchart future research directions, including lifelong mapping, semantic\nassociation and mapping, multi-model for robustness, and bridging the Sim2Real\ngap.", "AI": {"tldr": "Systematic survey of multi-robot SLAM with 3D Gaussian Splatting (3DGS): taxonomy, components, datasets, metrics, and open challenges with future directions.", "motivation": "3DGS enables real-time, high-fidelity scene representations for robotics, but multi-robot SLAM must tackle global consistency, communication, and heterogeneous data fusion. A unified taxonomy and benchmarks are needed to guide design and evaluation.", "method": "Conduct a structured literature review, categorizing approaches into centralized and distributed architectures. Analyze core components such as multi-agent consistency and alignment, communication efficiency, Gaussian representations, semantic distillation, fusion and pose optimization, and real-time scalability. Compile critical datasets and evaluation metrics, and synthesize insights to identify open challenges and future research directions.", "result": "Provides a comprehensive taxonomy and comparative insights across centralized and distributed multi-robot 3DGS SLAM methods. Summarizes representative datasets and metrics, highlights design trade-offs, and pinpoints gaps in lifelong mapping, semantic association, multi-model robustness, and sim-to-real bridging.", "conclusion": "3DGS-based multi-robot SLAM is promising for real-time, scalable perception; advancing lifelong mapping, semantic grounding, robustness to model heterogeneity, and sim-to-real transfer will be key to practical deployment."}}
{"id": "2510.23822", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23822", "abs": "https://arxiv.org/abs/2510.23822", "authors": ["Zhenyu Zhang", "Tianyi Chen", "Weiran Xu", "Alex Pentland", "Jiaxin Pei"], "title": "ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents", "comment": null, "summary": "Long-horizon tasks requiring multi-step reasoning and dynamic re-planning\nremain challenging for large language models (LLMs). Sequential prompting\nmethods are prone to context drift, loss of goal information, and recurrent\nfailure cycles, while hierarchical prompting methods often weaken cross-level\ncontinuity or incur substantial runtime overhead. We introduce ReCAP (Recursive\nContext-Aware Reasoning and Planning), a hierarchical framework with shared\ncontext for reasoning and planning in LLMs. ReCAP combines three key\nmechanisms: (i) plan-ahead decomposition, in which the model generates a full\nsubtask list, executes the first item, and refines the remainder; (ii)\nstructured re-injection of parent plans, maintaining consistent multi-level\ncontext during recursive return; and (iii) memory-efficient execution, bounding\nthe active prompt so costs scale linearly with task depth. Together these\nmechanisms align high-level goals with low-level actions, reduce redundant\nprompting, and preserve coherent context updates across recursion. Experiments\ndemonstrate that ReCAP substantially improves subgoal alignment and success\nrates on various long-horizon reasoning benchmarks, achieving a 32% gain on\nsynchronous Robotouille and a 29% improvement on asynchronous Robotouille under\nthe strict pass@1 protocol.", "AI": {"tldr": "A hierarchical, context-aware planning framework (ReCAP) for LLMs that uses plan-ahead decomposition, recursive context reinjection, and memory-efficient execution to improve long-horizon reasoning, achieving notable gains on Robotouille tasks.", "motivation": "Long-horizon tasks that require multi-step reasoning suffer from context drift, loss of goal information, and recurrent failure cycles when using sequential prompting. Hierarchical prompting often breaks cross-level continuity or incurs high runtime overhead. There is a need for a framework that preserves context across recursion while maintaining efficiency.", "method": "ReCAP introduces three mechanisms: (i) plan-ahead decomposition: generate a full subtask list, execute the first item, and refine the remainder; (ii) structured re-injection of parent plans: maintain consistent multi-level context during recursive return; (iii) memory-efficient execution: bound the active prompt so costs scale linearly with task depth. The framework also emphasizes shared context for reasoning and planning and aims to align high-level goals with low-level actions.", "result": "Experiments show substantial improvements in subgoal alignment and success rates on long-horizon benchmarks: a 32% gain on the synchronous Robotouille task and a 29% improvement on the asynchronous Robotouille task under the strict pass@1 protocol.", "conclusion": "ReCAP effectively aligns high-level goals with low-level actions, reduces redundant prompting, and preserves coherent context updates across recursion. It is memory-efficient and scales with task depth, demonstrating strong performance gains on challenging long-horizon reasoning benchmarks."}}
{"id": "2510.23630", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23630", "abs": "https://arxiv.org/abs/2510.23630", "authors": ["Ninghui Feng", "Yiyan Qi"], "title": "NUM2EVENT: Interpretable Event Reasoning from Numerical time-series", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated impressive multimodal\nreasoning capabilities, yet their understanding of purely numerical time-series\nsignals remains limited. Existing approaches mainly focus on forecasting or\ntrend description, without uncovering the latent events that drive numerical\nchanges or explaining the reasoning process behind them. In this work, we\nintroduce the task of number-to-event reasoning and decoding, which aims to\ninfer interpretable structured events from numerical inputs, even when current\ntext is unavailable. To address the data scarcity and semantic alignment\nchallenges, we propose a reasoning-aware framework that integrates an\nagent-guided event extractor (AGE), a marked multivariate Hawkes-based\nsynthetic generator (EveDTS), and a two-stage fine-tuning pipeline combining a\ntime-series encoder with a structured decoder. Our model explicitly reasons\nover numerical changes, generates intermediate explanations, and outputs\nstructured event hypotheses. Experiments on multi-domain datasets show that our\nmethod substantially outperforms strong LLM baselines in event-level precision\nand recall. These results suggest a new direction for bridging quantitative\nreasoning and semantic understanding, enabling LLMs to explain and predict\nevents directly from numerical dynamics.", "AI": {"tldr": "Introduces number-to-event reasoning for numerical time-series, proposing AGE, EveDTS, and a two-stage fine-tuning pipeline, achieving better event-level precision/recall than LLM baselines.", "motivation": "LLMs struggle to understand purely numerical time-series and to infer interpretable latent events from numerical changes; existing work focuses on forecasting without revealing underlying drivers or reasoning, and data scarcity/semantic alignment hinder learning.", "method": "Agent-guided Event Extractor (AGE) to identify candidate events; a marked multivariate Hawkes-based synthetic generator (EveDTS) to create aligned training data; a two-stage fine-tuning pipeline combining a time-series encoder with a structured decoder to generate explanations and structured event hypotheses.", "result": "Experimental evaluation on multi-domain datasets shows substantial improvements in event-level precision and recall over strong LLM baselines.", "conclusion": "Proposes a novel framework that unites quantitative reasoning with semantic interpretation, enabling LLMs to explain and predict events directly from numerical dynamics."}}
{"id": "2510.23956", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23956", "abs": "https://arxiv.org/abs/2510.23956", "authors": ["Alejandro Escontrela", "Shrinu Kushagra", "Sjoerd van Steenkiste", "Yulia Rubanova", "Aleksander Holynski", "Kelsey Allen", "Kevin Murphy", "Thomas Kipf"], "title": "Neural USD: An object-centric framework for iterative editing and control", "comment": "22 pages, 16 figures, 1 table", "summary": "Amazing progress has been made in controllable generative modeling,\nespecially over the last few years. However, some challenges remain. One of\nthem is precise and iterative object editing. In many of the current methods,\ntrying to edit the generated image (for example, changing the color of a\nparticular object in the scene or changing the background while keeping other\nelements unchanged) by changing the conditioning signals often leads to\nunintended global changes in the scene. In this work, we take the first steps\nto address the above challenges. Taking inspiration from the Universal Scene\nDescriptor (USD) standard developed in the computer graphics community, we\nintroduce the \"Neural Universal Scene Descriptor\" or Neural USD. In this\nframework, we represent scenes and objects in a structured, hierarchical\nmanner. This accommodates diverse signals, minimizes model-specific\nconstraints, and enables per-object control over appearance, geometry, and\npose. We further apply a fine-tuning approach which ensures that the above\ncontrol signals are disentangled from one another. We evaluate several design\nconsiderations for our framework, demonstrating how Neural USD enables\niterative and incremental workflows. More information at:\nhttps://escontrela.me/neural_usd .", "AI": {"tldr": "Neural USD introduces a structured, USD-inspired scene descriptor for per-object editing in generative models, enabling disentangled control over appearance, geometry, and pose via fine-tuning, supporting iterative workflows.", "motivation": "To address imprecise editing and unintended global changes when conditioning generative models, and to enable fine-grained, per-object control in a flexible, hierarchical representation.", "method": "Propose Neural USD: a hierarchical, object-centric scene representation inspired by USD; supports diverse conditioning signals; aims to minimize model-specific constraints; implement fine-tuning to disentangle control signals across appearance, geometry, and pose; evaluate design choices and demonstrate iterative, incremental editing workflows.", "result": "Through design considerations and experiments, the approach demonstrates that Neural USD can support iterative, per-object editing workflows with disentangled controls, enabling more precise edits without widespread unintended changes.", "conclusion": "Neural USD provides a practical framework for structured, per-object controllable generation, combining a USD-like scene graph with targeted fine-tuning to disentangle controls, facilitating iterative editing pipelines."}}
{"id": "2510.23997", "categories": ["cs.RO", "I.2.9"], "pdf": "https://arxiv.org/pdf/2510.23997", "abs": "https://arxiv.org/abs/2510.23997", "authors": ["Stanley Wu", "Mohamad H. Danesh", "Simon Li", "Hanna Yurchyk", "Amin Abyaneh", "Anas El Houssaini", "David Meger", "Hsiu-Chin Lin"], "title": "VOCALoco: Viability-Optimized Cost-aware Adaptive Locomotion", "comment": "Accepted in IEEE Robotics and Automation Letters (RAL), 2025. 8\n  pages, 9 figures", "summary": "Recent advancements in legged robot locomotion have facilitated traversal\nover increasingly complex terrains. Despite this progress, many existing\napproaches rely on end-to-end deep reinforcement learning (DRL), which poses\nlimitations in terms of safety and interpretability, especially when\ngeneralizing to novel terrains. To overcome these challenges, we introduce\nVOCALoco, a modular skill-selection framework that dynamically adapts\nlocomotion strategies based on perceptual input. Given a set of pre-trained\nlocomotion policies, VOCALoco evaluates their viability and energy-consumption\nby predicting both the safety of execution and the anticipated cost of\ntransport over a fixed planning horizon. This joint assessment enables the\nselection of policies that are both safe and energy-efficient, given the\nobserved local terrain. We evaluate our approach on staircase locomotion tasks,\ndemonstrating its performance in both simulated and real-world scenarios using\na quadrupedal robot. Empirical results show that VOCALoco achieves improved\nrobustness and safety during stair ascent and descent compared to a\nconventional end-to-end DRL policy", "AI": {"tldr": "VOCALoco is a modular skill-selection framework for legged locomotion that chooses among pre-trained policies based on predicted safety and energy cost, improving safety and efficiency on stair locomotion in simulation and on a real quadruped, addressing safety/interpretability gaps of end-to-end DRL.", "motivation": "End-to-end DRL approaches in legged locomotion often lack explicit safety guarantees and interpretability and may not generalize well to novel terrains; a modular framework can provide safer, more transparent policy selection using perceptual input.", "method": "Given a set of pre-trained locomotion policies, VOCALoco predicts both the safety of executing each policy and the anticipated energy cost over a fixed planning horizon, then selects policies that balance safety and energy efficiency based on observed local terrain.", "result": "In staircase locomotion tasks, VOCALoco demonstrated improved robustness and safety during both ascent and descent, validated in simulation and on a real quadruped, compared to a conventional end-to-end DRL policy.", "conclusion": "A modular sensor-informed policy selection approach can enhance safety, robustness, and energy-aware locomotion, offering interpretability and better generalization over terrains relative to end-to-end DRL."}}
{"id": "2510.23824", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23824", "abs": "https://arxiv.org/abs/2510.23824", "authors": ["Murad Ismayilov", "Edwin Meriaux", "Shuo Wen", "Gregory Dudek"], "title": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models", "comment": "Accepted at MIT URTC 2025", "summary": "Coordinating multiple autonomous agents in shared environments under\ndecentralized conditions is a long-standing challenge in robotics and\nartificial intelligence. This work addresses the problem of decentralized goal\nassignment for multi-agent path planning, where agents independently generate\nranked preferences over goals based on structured representations of the\nenvironment, including grid visualizations and scenario data. After this\nreasoning phase, agents exchange their goal rankings, and assignments are\ndetermined by a fixed, deterministic conflict-resolution rule (e.g., agent\nindex ordering), without negotiation or iterative coordination. We\nsystematically compare greedy heuristics, optimal assignment, and large\nlanguage model (LLM)-based agents in fully observable grid-world settings. Our\nresults show that LLM-based agents, when provided with well-designed prompts\nand relevant quantitative information, can achieve near-optimal makespans and\nconsistently outperform traditional heuristics. These findings underscore the\npotential of language models for decentralized goal assignment in multi-agent\npath planning and highlight the importance of information structure in such\nsystems.", "AI": {"tldr": "Decentralized goal assignment in multi-agent path planning via rank-based preferences and fixed conflict resolution, where LLM-based agents\u2014given well-structured prompts and quantitative info\u2014achieve near-optimal makespans and outperform traditional heuristics in grid-world settings.", "motivation": "Address the challenge of coordinating many autonomous agents without centralized negotiation by enabling decentralized goal assignment through local reasoning, explicit goal preferences, and deterministic conflict resolution; also assess the value of language models in MAPF decision-making.", "method": "Agents generate ranked goal preferences from structured environment representations (grid visualizations and scenario data). They exchange these rankings and assign goals via a fixed, deterministic conflict-resolution rule (e.g., agent index ordering). The study compares greedy heuristics, optimal assignment, and large language model (LLM)-based agents in fully observable grid-worlds, using prompts augmented with relevant quantitative information.", "result": "LLM-based agents, with well-designed prompts and relevant data, achieve near-optimal makespans and consistently outperform traditional heuristics; the quality of information structure substantially influences performance.", "conclusion": "Language models are promising for decentralized goal assignment in multi-agent path planning, but success hinges on careful information structuring and prompt design; further exploration of LLM-based decentralized planning is warranted."}}
{"id": "2510.23631", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23631", "abs": "https://arxiv.org/abs/2510.23631", "authors": ["Yuxuan Tang", "Yifan Feng"], "title": "Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling", "comment": null, "summary": "Alignment of large language models (LLMs) has predominantly relied on\npairwise preference optimization, where annotators select the better of two\nresponses to a prompt. While simple, this approach overlooks the opportunity to\nlearn from richer forms of human feedback, such as multiwise comparisons and\ntop-$k$ rankings. We propose Ranked Choice Preference Optimization (RCPO), a\nunified framework that bridges preference optimization with (ranked) choice\nmodeling via maximum likelihood estimation. The framework is flexible,\nsupporting both utility-based and rank-based choice models. It subsumes several\nexisting pairwise methods (e.g., DPO, SimPO), while providing principled\ntraining objectives for richer feedback formats. We instantiate this framework\nwith two representative ranked choice models (Multinomial Logit and\nMallows-RMJ). Empirical studies on Llama-3-8B-Instruct and Gemma-2-9B-it across\nAlpacaEval 2 and Arena-Hard benchmarks show that RCPO consistently outperforms\ncompetitive baselines. RCPO shows how directly leveraging ranked preference\ndata, combined with the right choice models, yields more effective alignment.\nIt offers a versatile and extensible foundation for incorporating (ranked)\nchoice modeling into LLM training.", "AI": {"tldr": "RCPO is a unified framework that extends pairwise alignment methods to ranked (multiwise/top-k) preferences using maximum likelihood over choice models, showing empirical gains on Llama-3 and Gemma models across multiple benchmarks.", "motivation": "Current LLM alignment relies on simple pairwise preferences. Richer human feedback (multiwise and top-k rankings) can improve learning but requires principled objectives and modeling.", "method": "Introduce RCPO that connects preference optimization with ranked-choice modeling using maximum likelihood. It supports utility-based (e.g., Multinomial Logit) and rank-based (e.g., Mallows-RMJ) models, subsumes pairwise methods like DPO/SimPO, and provides training objectives for richer feedback. Instantiated with MNL and Mallows-RMJ and evaluated on Llama-3-8B-Instruct and Gemma-2-9B-it across AlpacaEval 2 and Arena-Hard.", "result": "RCPO consistently outperforms competitive baselines on the tested benchmarks, demonstrating that directly leveraging ranked preference data with suitable choice models yields more effective alignment.", "conclusion": "Ranked preference data, when paired with appropriate choice models, offer a versatile and extensible foundation for improving LLM alignment, with RCPO serving as a unified framework to incorporate ranked (multiwise/top-k) feedback into training."}}
{"id": "2510.23960", "categories": ["cs.CV", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.23960", "abs": "https://arxiv.org/abs/2510.23960", "authors": ["Peiyang Xu", "Minzhou Pan", "Zhaorun Chen", "Shuang Yang", "Chaowei Xiao", "Bo Li"], "title": "SafeVision: Efficient Image Guardrail with Robust Policy Adherence and Explainability", "comment": "42 pages, 9 figures", "summary": "With the rapid proliferation of digital media, the need for efficient and\ntransparent safeguards against unsafe content is more critical than ever.\nTraditional image guardrail models, constrained by predefined categories, often\nmisclassify content due to their pure feature-based learning without semantic\nreasoning. Moreover, these models struggle to adapt to emerging threats,\nrequiring costly retraining for new threats. To address these limitations, we\nintroduce SafeVision, a novel image guardrail that integrates human-like\nreasoning to enhance adaptability and transparency. Our approach incorporates\nan effective data collection and generation framework, a policy-following\ntraining pipeline, and a customized loss function. We also propose a diverse QA\ngeneration and training strategy to enhance learning effectiveness. SafeVision\ndynamically aligns with evolving safety policies at inference time, eliminating\nthe need for retraining while ensuring precise risk assessments and\nexplanations. Recognizing the limitations of existing unsafe image benchmarks,\nwhich either lack granularity or cover limited risks, we introduce VisionHarm,\na high-quality dataset comprising two subsets: VisionHarm Third-party\n(VisionHarm-T) and VisionHarm Comprehensive(VisionHarm-C), spanning diverse\nharmful categories. Through extensive experiments, we show that SafeVision\nachieves state-of-the-art performance on different benchmarks. SafeVision\noutperforms GPT-4o by 8.6% on VisionHarm-T and by 15.5% on VisionHarm-C, while\nbeing over 16x faster. SafeVision sets a comprehensive, policy-following, and\nexplainable image guardrail with dynamic adaptation to emerging threats.", "AI": {"tldr": "SafeVision is a dynamic, policy-aligned image guardrail with explainable reasoning and a high-quality harm dataset; it avoids retraining, adapts to new threats, and outperforms baseline models while being faster.", "motivation": "Current guardrails rely on static features and predefined categories, leading to misclassification and poor adaptability to emerging threats; need for transparency and policy-driven adaptability without retraining.", "method": "Data collection/generation framework, policy-following training pipeline, customized loss, diverse QA generation/training strategy, and inference-time policy alignment; introduces VisionHarm-T and VisionHarm-C datasets; performance evaluations.", "result": "Achieves state-of-the-art on VisionHarm benchmarks; outperforms GPT-4o by 8.6% (VisionHarm-T) and 15.5% (VisionHarm-C) and is over 16x faster.", "conclusion": "SafeVision provides a comprehensive, explainable, policy-following image guardrail that dynamically adapts to evolving threats without retraining."}}
{"id": "2510.24029", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY", "q-bio.NC", "I.2.9; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.24029", "abs": "https://arxiv.org/abs/2510.24029", "authors": ["Andrew Gerstenslager", "Bekarys Dukenbaev", "Ali A. Minai"], "title": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model", "comment": "8 pages, 9 figures, Presented at the 2025 International Joint\n  Conference on Neural Networks, Rome, July 2025", "summary": "Boundary Vector Cells (BVCs) are a class of neurons in the brains of\nvertebrates that encode environmental boundaries at specific distances and\nallocentric directions, playing a central role in forming place fields in the\nhippocampus. Most computational BVC models are restricted to two-dimensional\n(2D) environments, making them prone to spatial ambiguities in the presence of\nhorizontal symmetries in the environment. To address this limitation, we\nincorporate vertical angular sensitivity into the BVC framework, thereby\nenabling robust boundary detection in three dimensions, and leading to\nsignificantly more accurate spatial localization in a biologically-inspired\nrobot model.\n  The proposed model processes LiDAR data to capture vertical contours, thereby\ndisambiguating locations that would be indistinguishable under a purely 2D\nrepresentation. Experimental results show that in environments with minimal\nvertical variation, the proposed 3D model matches the performance of a 2D\nbaseline; yet, as 3D complexity increases, it yields substantially more\ndistinct place fields and markedly reduces spatial aliasing. These findings\nshow that adding a vertical dimension to BVC-based localization can\nsignificantly enhance navigation and mapping in real-world 3D spaces while\nretaining performance parity in simpler, near-planar scenarios.", "AI": {"tldr": "Extends Boundary Vector Cells to 3D by adding vertical angular sensitivity and LiDAR-based vertical contours, improving place-field distinctiveness and reducing spatial aliasing in 3D spaces while matching 2D performance in near-planar environments.", "motivation": "2D BVC models suffer from spatial ambiguities under horizontal symmetry and lack robust performance in 3D environments; a 3D BVC framework could improve localization/navigation in real-world spaces.", "method": "Integrates vertical angular sensitivity into BVCs and processes LiDAR data to capture vertical contours. Implemented in a biologically-inspired robot model. Compares a 3D BVC model to a 2D baseline across environments with varying vertical variation.", "result": "In environments with minimal vertical variation, 3D BVC performance matches the 2D baseline. As vertical complexity increases, the 3D model yields more distinct place fields and significantly reduces spatial aliasing, enhancing localization.", "conclusion": "Incorporating the vertical dimension into BVC-based localization improves navigation and mapping in 3D spaces while preserving parity with 2D performance in near-planar scenarios."}}
{"id": "2510.23856", "categories": ["cs.AI", "68Txx"], "pdf": "https://arxiv.org/pdf/2510.23856", "abs": "https://arxiv.org/abs/2510.23856", "authors": ["Segev Shlomov", "Alon Oved", "Sami Marreed", "Ido Levy", "Offer Akrabi", "Avi Yaeli", "\u0141ukasz Str\u0105k", "Elizabeth Koumpan", "Yinon Goldshtein", "Eilam Shapira", "Nir Mashkif", "Asaf Adi"], "title": "From Benchmarks to Business Impact: Deploying IBM Generalist Agent in Enterprise Production", "comment": "AAAI Conference on Artificial Intelligence", "summary": "Agents are rapidly advancing in automating digital work, but enterprises face\na harder challenge: moving beyond prototypes to deployed systems that deliver\nmeasurable business value. This path is complicated by fragmented frameworks,\nslow development, and the absence of standardized evaluation practices.\nGeneralist agents have emerged as a promising direction, excelling on academic\nbenchmarks and offering flexibility across task types, applications, and\nmodalities. Yet, evidence of their use in production enterprise settings\nremains limited. This paper reports IBM's experience developing and piloting\nthe Computer Using Generalist Agent (CUGA), which has been open-sourced for the\ncommunity (https://github.com/cuga-project/cuga-agent). CUGA adopts a\nhierarchical planner--executor architecture with strong analytical foundations,\nachieving state-of-the-art performance on AppWorld and WebArena. Beyond\nbenchmarks, it was evaluated in a pilot within the Business-Process-Outsourcing\ntalent acquisition domain, addressing enterprise requirements for scalability,\nauditability, safety, and governance. To support assessment, we introduce\nBPO-TA, a 26-task benchmark spanning 13 analytics endpoints. In preliminary\nevaluations, CUGA approached the accuracy of specialized agents while\nindicating potential for reducing development time and cost. Our contribution\nis twofold: presenting early evidence of generalist agents operating at\nenterprise scale, and distilling technical and organizational lessons from this\ninitial pilot. We outline requirements and next steps for advancing\nresearch-grade architectures like CUGA into robust, enterprise-ready systems.", "AI": {"tldr": "IBM's Computer Using Generalist Agent (CUGA) shows promise for enterprise-scale generalist agents: open-sourced, hierarchical planner\u2013executor design, strong benchmarks (AppWorld/WebArena), and a pilot in BPO talent acquisition (BPO-TA) with a 26-task analytics benchmark. Preliminary results approach specialized agents in accuracy and hint at reduced development effort, with lessons toward enterprise-grade deployment.", "motivation": "Enterprises struggle to move from prototypes to deployed, measurable AI systems amid fragmented frameworks, slow development, and lacking standardized evaluation; there is a need for scalable, auditable, safe, governance-friendly, generalist agents in production.", "method": "Develop and open-source CUGA with a hierarchical planner\u2013executor architecture; evaluate on academic benchmarks (AppWorld and WebArena); pilot in Business-Process-Outsourcing Talent Acquisition (BPO-TA) domain; create a 26-task BPO-TA benchmark spanning 13 analytics endpoints.", "result": "CUGA achieves state-of-the-art performance on AppWorld and WebArena; in a BPO-TA pilot, its accuracy approaches that of specialized agents; suggests potential to reduce development time and cost; introduces the 26-task BPO-TA benchmark and reports enterprise-focused evaluation.", "conclusion": "First evidence that generalist agents can operate at enterprise scale; extracts technical and organizational lessons from the pilot; outlines requirements and next steps to evolve research-grade architectures like CUGA into robust, enterprise-ready systems."}}
{"id": "2510.23632", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23632", "abs": "https://arxiv.org/abs/2510.23632", "authors": ["Guozhong Li", "Muhannad Alhumaidi", "Spiros Skiadopoulos", "Panos Kalnis"], "title": "LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data Compression", "comment": null, "summary": "The rapid growth of high-resolution scientific simulations and observation\nsystems is generating massive spatiotemporal datasets, making efficient,\nerror-bounded compression increasingly important. Meanwhile, decoder-only large\nlanguage models (LLMs) have demonstrated remarkable capabilities in modeling\ncomplex sequential data. In this paper, we propose LLMCOMP, a novel lossy\ncompression paradigm that leverages decoder-only large LLMs to model scientific\ndata. LLMCOMP first quantizes 3D fields into discrete tokens, arranges them via\nZ-order curves to preserve locality, and applies coverage-guided sampling to\nenhance training efficiency. An autoregressive transformer is then trained with\nspatial-temporal embeddings to model token transitions. During compression, the\nmodel performs top-k prediction, storing only rank indices and fallback\ncorrections to ensure strict error bounds. Experiments on multiple reanalysis\ndatasets show that LLMCOMP consistently outperforms state-of-the-art\ncompressors, achieving up to 30% higher compression ratios under strict error\nbounds. These results highlight the potential of LLMs as general-purpose\ncompressors for high-fidelity scientific data.", "AI": {"tldr": "LLMCOMP uses decoder-only LLMs to perform lossy, error-bounded compression of high-res scientific data by tokenizing 3D fields, ordering with Z-order, training an autoregressive transformer with spatial-temporal embeddings, and performing top-k predictions with rank indices and corrections; it outperforms state-of-the-art by up to 30% in compression ratio under strict error bounds.", "motivation": "The growth of high-resolution simulations and observations yields massive spatiotemporal data; there is a need for efficient, error-bounded compression. Traditional compressors may be limited; leveraging decoder-only LLMs promises powerful sequence modeling for data compression.", "method": "Quantize 3D fields into discrete tokens; arrange tokens with Z-order curves to preserve locality; use coverage-guided sampling to improve training efficiency; train an autoregressive transformer with spatial-temporal embeddings to model token transitions; during compression, perform top-k prediction, storing only rank indices and fallback corrections to maintain strict error bounds.", "result": "Experiments on multiple reanalysis datasets show LLMCOMP outperforms state-of-the-art compressors, achieving up to 30% higher compression ratios under strict error bounds.", "conclusion": "LLMs can serve as general-purpose compressors for high-fidelity scientific data, enabling efficient storage with guaranteed error bounds."}}
{"id": "2510.23968", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23968", "abs": "https://arxiv.org/abs/2510.23968", "authors": ["Andriy Myronenko", "Dong Yang", "Baris Turkbey", "Mariam Aboian", "Sena Azamat", "Esra Akcicek", "Hongxu Yin", "Pavlo Molchanov", "Marc Edgar", "Yufan He", "Pengfei Guo", "Yucheng Tang", "Daguang Xu"], "title": "Reasoning Visual Language Model for Chest X-Ray Analysis", "comment": "NV-Reason-CXR-3B", "summary": "Vision-language models (VLMs) have shown strong promise for medical image\nanalysis, but most remain opaque, offering predictions without the transparent,\nstepwise reasoning clinicians rely on. We present a framework that brings\nchain-of-thought (CoT) reasoning to chest X-ray interpretation. Inspired by\nreasoning-first training paradigms, our approach is designed to learn how\nexperts reason, not just what they conclude, by aligning intermediate steps\nwith observable image evidence and radiology workflow. Beyond accuracy, the\nexplicit reasoning traces support clinical auditability: they reveal why a\nconclusion was reached, which alternatives were considered, and where\nuncertainty remains, enabling quality assurance, error analysis, and safer\nhuman-AI collaboration.\n  Our model couples high-fidelity visual encoding with a two-stage training\nrecipe: a reasoning-style supervised fine-tuning (SFT) followed by\nreinforcement learning (RL) that uses verifiable rewards over a list of X-ray\nabnormalities. The model outputs reasoning that mirrors radiologists systematic\nthought process, uncertainty, and differential diagnosis. In\nout-of-distribution evaluation, the approach achieves competitive multi-label\nclassification while improving interpretability. In a reader study with expert\nradiologists, full reasoning traces increased confidence, supported error\nauditing, and reduced time to finalize reports. We release code and the model\nNV-Reason-CXR-3B to support community progress toward trustworthy, explainable\nAI in chest radiography and other medical imaging tasks where reasoning quality\nis as critical as prediction quality.", "AI": {"tldr": "A vision-language model with chain-of-thought reasoning for chest X-ray interpretation, enabling interpretable, audit-friendly decisions via a two-stage training (reasoning-style SFT + RL) that outputs radiologist-like reasoning traces. Demonstrates competitive accuracy and improved interpretability; reader study shows increased confidence and faster reporting; model NV-Reason-CXR-3B released.", "motivation": "Address opacity and lack of stepwise reasoning in medical VLMs. Provide transparent, auditable reasoning aligned with radiologist workflow to improve trust, safety, and human-AI collaboration.", "method": "Two-stage training: (1) reasoning-style supervised fine-tuning (SFT) to encode expert-like reasoning, and (2) reinforcement learning with verifiable rewards over a defined list of X-ray abnormalities. The model performs high-fidelity visual encoding and outputs chain-of-thought style reasoning traces that reflect radiologists' systematic approach, uncertainty, and differential diagnoses.", "result": "In-distribution multi-label classification is competitive; interpretability and auditability improved. A reader study with expert radiologists showed full reasoning traces increased confidence, aided error auditing, and reduced time to finalize reports.", "conclusion": "NV-Reason-CXR-3B released to support explainable AI in chest radiography; demonstrates that reasoning quality complements prediction quality and can extend to other medical imaging tasks where explainability and auditability are crucial."}}
{"id": "2510.24052", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24052", "abs": "https://arxiv.org/abs/2510.24052", "authors": ["Jongsuk Kim", "Jaeyoung Lee", "Gyojin Han", "Dongjae Lee", "Minki Jeong", "Junmo Kim"], "title": "SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration", "comment": null, "summary": "Recent advancements in deep learning and the availability of high-quality\nreal-world driving datasets have propelled end-to-end autonomous driving.\nDespite this progress, relying solely on real-world data limits the variety of\ndriving scenarios for training. Synthetic scenario generation has emerged as a\npromising solution to enrich the diversity of training data; however, its\napplication within E2E AD models remains largely unexplored. This is primarily\ndue to the absence of a designated ego vehicle and the associated sensor\ninputs, such as camera or LiDAR, typically provided in real-world scenarios. To\naddress this gap, we introduce SynAD, the first framework designed to enhance\nreal-world E2E AD models using synthetic data. Our method designates the agent\nwith the most comprehensive driving information as the ego vehicle in a\nmulti-agent synthetic scenario. We further project path-level scenarios onto\nmaps and employ a newly developed Map-to-BEV Network to derive bird's-eye-view\nfeatures without relying on sensor inputs. Finally, we devise a training\nstrategy that effectively integrates these map-based synthetic data with real\ndriving data. Experimental results demonstrate that SynAD effectively\nintegrates all components and notably enhances safety performance. By bridging\nsynthetic scenario generation and E2E AD, SynAD paves the way for more\ncomprehensive and robust autonomous driving models.", "AI": {"tldr": "SynAD introduces a framework to leverage synthetic driving scenarios to improve end-to-end autonomous driving (E2E AD) by designating an ego vehicle in multi-agent synthetic data, projecting path-level scenarios onto maps, and using a Map-to-BEV Network to extract BEV features without sensor inputs, followed by a training strategy that fuses synthetic map-based data with real-world data to improve safety.", "motivation": "Real-world driving data alone lacks scenario diversity; synthetic data can expand coverage of rare or dangerous situations but E2E AD models typically lack ego-vehicle inputs in synthetic setups, hindering integration. The work aims to bridge synthetic scenario generation with E2E AD by creating ego-aware synthetic data and map-based representations.", "method": "- Identify the agent with the most comprehensive driving information as the ego vehicle in synthetic multi-agent scenes. - Project path-level scenarios onto maps. - Develop a Map-to-BEV Network to obtain bird's-eye-view features without camera/LiDAR inputs. - Propose a training strategy to integrate map-based synthetic data with real driving data for E2E AD training.", "result": "Experimental results show that SynAD successfully integrates all components and leads to notable improvements in safety performance of real-world E2E AD models when augmented with synthetic data.", "conclusion": "SynAD bridges synthetic scenario generation and end-to-end autonomous driving by providing an essential framework and components (ego designation, map-based BEV features, integration strategy) that enable effective use of synthetic data to enhance safety and robustness of E2E AD models."}}
{"id": "2510.23881", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23881", "abs": "https://arxiv.org/abs/2510.23881", "authors": ["Xidong Feng", "Vivek Veeriah", "Marcus Chiam", "Michael Dennis", "Ryan Pachauri", "Thomas Tumiel", "Federico Barbero", "Johan Obando-Ceron", "Jiaxin Shi", "Satinder Singh", "Shaobo Hou", "Nenad Toma\u0161ev", "Tom Zahavy"], "title": "Generating Creative Chess Puzzles", "comment": null, "summary": "While Generative AI rapidly advances in various domains, generating truly\ncreative, aesthetic, and counter-intuitive outputs remains a challenge. This\npaper presents an approach to tackle these difficulties in the domain of chess\npuzzles. We start by benchmarking Generative AI architectures, and then\nintroduce an RL framework with novel rewards based on chess engine search\nstatistics to overcome some of those shortcomings. The rewards are designed to\nenhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.\nOur RL approach dramatically increases counter-intuitive puzzle generation by\n10x, from 0.22\\% (supervised) to 2.5\\%, surpassing existing dataset rates\n(2.1\\%) and the best Lichess-trained model (0.4\\%). Our puzzles meet novelty\nand diversity benchmarks, retain aesthetic themes, and are rated by human\nexperts as more creative, enjoyable, and counter-intuitive than composed book\npuzzles, even approaching classic compositions. Our final outcome is a curated\nbooklet of these AI-generated puzzles, which is acknowledged for creativity by\nthree world-renowned experts.", "AI": {"tldr": "RL-guided generation of chess puzzles using engine-statistics rewards yields highly counter-intuitive, novel, and diverse puzzles, surpassing datasets and models; culminates in a creative AI-generated puzzle booklet.", "motivation": "Generative AI struggles with true creativity and counter-intuitiveness; chess puzzles require novelty, aesthetic coherence, and realism; aim to push AI beyond standard supervised generation to produce more engaging puzzles.", "method": "Benchmark various Generative AI architectures; implement a reinforcement learning framework with novel rewards based on chess engine search statistics that promote puzzle uniqueness, counter-intuitiveness, diversity, and realism; train to optimize these objectives; evaluate with dataset comparisons and human expert ratings.", "result": "Counter-intuitive puzzle generation increased by 10x from 0.22% to 2.5%; exceeds dataset rate of 2.1% and best Lichess-trained model at 0.4%; puzzles satisfy novelty and diversity benchmarks; human experts rate them as more creative, enjoyable, and counter-intuitive than composed book puzzles; final product is a curated AI-puzzle booklet acknowledged for creativity by three experts.", "conclusion": "Demonstrates that RL-based generation with engine-informed rewards can produce high-creativity chess puzzles approaching classical compositions; supports automated creation of high-quality, creative puzzle content and provides a viable pipeline for puzzle book curation."}}
{"id": "2510.23633", "categories": ["cs.LG", "cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.23633", "abs": "https://arxiv.org/abs/2510.23633", "authors": ["Xun Su", "Hiroyuki Kasai"], "title": "Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models", "comment": "9 pages", "summary": "Pretrained diffusion models have demonstrated strong capabilities in\nzero-shot inverse problem solving by incorporating observation information into\nthe generation process of the diffusion models. However, this presents an\ninherent dilemma: excessive integration can disrupt the generative process,\nwhile insufficient integration fails to emphasize the constraints imposed by\nthe inverse problem. To address this, we propose \\emph{Noise Combination\nSampling}, a novel method that synthesizes an optimal noise vector from a noise\nsubspace to approximate the measurement score, replacing the noise term in the\nstandard Denoising Diffusion Probabilistic Models process. This enables\nconditional information to be naturally embedded into the generation process\nwithout reliance on step-wise hyperparameter tuning. Our method can be applied\nto a wide range of inverse problem solvers, including image compression, and,\nparticularly when the number of generation steps $T$ is small, achieves\nsuperior performance with negligible computational overhead, significantly\nimproving robustness and stability.", "AI": {"tldr": "Introduces Noise Combination Sampling (NCS) for diffusion-based inverse problems, synthesizing an optimal noise in a subspace to approximate the measurement score, enabling conditional information embedding with reduced tuning and improved robustness, especially for small generation steps (T).", "motivation": "In zero-shot inverse problem solving with pretrained diffusion models, excessive integration of observation data can disrupt generation, while insufficient integration fails to enforce problem constraints. A method is needed to incorporate measurement information without destabilizing the generative process.", "method": "Proposes Noise Combination Sampling: construct a noise vector from a subspace to approximate the measurement score, replacing the standard noise term in the DDPM process, so conditional information is naturally embedded during generation without step-wise hyperparameter tuning.", "result": "When the number of generation steps T is small, it achieves superior performance with negligible computational overhead, and improves robustness and stability across inverse problems (e.g., image compression).", "conclusion": "Noise Combination Sampling provides a general, efficient mechanism to integrate observation constraints into diffusion-based inverse problem solvers without extensive hyperparameter tuning, broadly enhancing performance and stability."}}
{"id": "2510.23978", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23978", "abs": "https://arxiv.org/abs/2510.23978", "authors": ["Kazutoshi Akita", "Norimichi Ukita"], "title": "Efficient Cost-and-Quality Controllable Arbitrary-scale Super-resolution with Fourier Constraints", "comment": "9 pages", "summary": "Cost-and-Quality (CQ) controllability in arbitrary-scale super-resolution is\ncrucial. Existing methods predict Fourier components one by one using a\nrecurrent neural network. However, this approach leads to performance\ndegradation and inefficiency due to independent prediction. This paper proposes\npredicting multiple components jointly to improve both quality and efficiency.", "AI": {"tldr": "Jointly predicting multiple Fourier components for CQ-controllable arbitrary-scale SR improves quality and efficiency over independent predictions.", "motivation": "The CQ controllability problem in arbitrary-scale super-resolution is important, but existing RNN-based methods that predict Fourier components one by one suffer performance degradation and inefficiency due to independent predictions.", "method": "Predict multiple Fourier components jointly rather than predicting them sequentially.", "result": "The approach aims to improve both reconstruction quality and computational efficiency by joint prediction of components.", "conclusion": "Jointly predicting multiple Fourier components is a promising approach to enhance cost-and-quality controllability in arbitrary-scale super-resolution."}}
{"id": "2510.24055", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24055", "abs": "https://arxiv.org/abs/2510.24055", "authors": ["Xiucheng Zhang", "Yang Jiang", "Hongwei Qing", "Jiashuo Bai"], "title": "Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation", "comment": "8 pages", "summary": "Perceptual ambiguity and task conflict limit multitask robotic manipulation\nvia imitation learning. We propose a framework combining a Language-Conditioned\nVisual Representation (LCVR) module and a Language-conditioned\nMixture-ofExperts Density Policy (LMoE-DP). LCVR resolves perceptual\nambiguities by grounding visual features with language instructions, enabling\ndifferentiation between visually similar tasks. To mitigate task conflict,\nLMoE-DP uses a sparse expert architecture to specialize in distinct, multimodal\naction distributions, stabilized by gradient modulation. On real-robot\nbenchmarks, LCVR boosts Action Chunking with Transformers (ACT) and Diffusion\nPolicy (DP) success rates by 33.75% and 25%, respectively. The full framework\nachieves a 79% average success, outperforming the advanced baseline by 21%. Our\nwork shows that combining semantic grounding and expert specialization enables\nrobust, efficient multi-task manipulation", "AI": {"tldr": "A framework combines a Language-Conditioned Visual Representation (LCVR) with a Language-conditioned Mixture-of-Experts Density Policy (LMoE-DP) to address perceptual ambiguity and task conflict in multitask imitation-learning-based robotic manipulation. It grounds visual features with language to disambiguate tasks and uses sparse experts to specialize action distributions, yielding strong real-robot performance gains.", "motivation": "Perceptual ambiguity and conflicting objectives across multiple tasks limit the effectiveness of multitask imitation learning in robotic manipulation. Grounding perception with language and introducing expert specialization can improve disambiguation and reduce interference between tasks.", "method": "Introduce LCVR to ground visual representations with language instructions, resolving perceptual ambiguities; implement LMoE-DP, a sparse expert density policy conditioned on language, with gradient modulation to stabilize training and encourage specialization across multimodal action distributions.", "result": "On real-robot benchmarks, LCVR improves Action Chunking with Transformers (ACT) and Diffusion Policy (DP) success rates by 33.75% and 25% respectively. The full framework achieves 79% average success, outperforming an advanced baseline by 21%.", "conclusion": "Combining semantic grounding with expert specialization enables robust and efficient multi-task manipulation via imitation learning."}}
{"id": "2510.23882", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23882", "abs": "https://arxiv.org/abs/2510.23882", "authors": ["Adil Rasheed", "Oscar Ravik", "Omer San"], "title": "Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins", "comment": null, "summary": "This work investigates the use of digital twins for dynamical system modeling\nand control, integrating physics-based, data-driven, and hybrid approaches with\nboth traditional and AI-driven controllers. Using a miniature greenhouse as a\ntest platform, four predictive models Linear, Physics-Based Modeling (PBM),\nLong Short Term Memory (LSTM), and Hybrid Analysis and Modeling (HAM) are\ndeveloped and compared under interpolation and extrapolation scenarios. Three\ncontrol strategies Model Predictive Control (MPC), Reinforcement Learning (RL),\nand Large Language Model (LLM) based control are also implemented to assess\ntrade-offs in precision, adaptability, and implementation effort. Results show\nthat in modeling HAM provides the most balanced performance across accuracy,\ngeneralization, and computational efficiency, while LSTM achieves high\nprecision at greater resource cost. Among controllers, MPC delivers robust and\npredictable performance, RL demonstrates strong adaptability, and LLM-based\ncontrollers offer flexible human-AI interaction when coupled with predictive\ntools.", "AI": {"tldr": "Digital twins for dynamical systems combining four predictive models (Linear, PBM, LSTM, HAM) with three controllers (MPC, RL, LLM-based) in a miniature greenhouse. HAM offers the best balance across accuracy, generalization, and efficiency; LSTM excels in precision at higher cost; MPC is robust and predictable; RL is adaptable; LLM-based control enables flexible human\u2013AI interaction when paired with predictors.", "motivation": "Address the integration of physics-based, data-driven, and hybrid modeling with traditional and AI-driven controllers for dynamical systems. Evaluate trade-offs under interpolation and extrapolation using a controlled test platform (miniature greenhouse).", "method": "Develop four predictive models (Linear, Physics-Based Modeling PBM, Long Short-Term Memory LSTM, and Hybrid Analysis and Modeling HAM) and three controllers (Model Predictive Control MPC, Reinforcement Learning RL, and a Large Language Model (LLM) based controller). Evaluate performance under interpolation and extrapolation scenarios, focusing on accuracy, generalization, computational efficiency, adaptability, and implementation effort.", "result": "HAM provides the most balanced performance in terms of accuracy, generalization, and computational efficiency; LSTM achieves high precision but at greater resource cost; MPC yields robust and predictable control; RL shows strong adaptability; LLM-based controllers offer flexible human\u2013AI interaction when integrated with predictive tools.", "conclusion": "Hybrid HAM modeling is a favorable compromise for digital twins in dynamical system control, delivering balanced accuracy and efficiency with good generalization. LSTM is suitable for precision but incurs higher costs; MPC remains a strong default for robustness; RL and LLM-based approaches hold promise for adaptability and human-in-the-loop control, respectively."}}
{"id": "2510.23634", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23634", "abs": "https://arxiv.org/abs/2510.23634", "authors": ["Soutrik Sarangi", "Yonatan Sverdlov", "Nadav Dym", "Abir De"], "title": "Monotone and Separable Set Functions: Characterizations and Neural Models", "comment": null, "summary": "Motivated by applications for set containment problems, we consider the\nfollowing fundamental problem: can we design set-to-vector functions so that\nthe natural partial order on sets is preserved, namely $S\\subseteq T \\text{ if\nand only if } F(S)\\leq F(T) $. We call functions satisfying this property\nMonotone and Separating (MAS) set functions. % We establish lower and upper\nbounds for the vector dimension necessary to obtain MAS functions, as a\nfunction of the cardinality of the multisets and the underlying ground set. In\nthe important case of an infinite ground set, we show that MAS functions do not\nexist, but provide a model called our which provably enjoys a relaxed MAS\nproperty we name \"weakly MAS\" and is stable in the sense of Holder continuity.\nWe also show that MAS functions can be used to construct universal models that\nare monotone by construction and can approximate all monotone set functions.\nExperimentally, we consider a variety of set containment tasks. The experiments\nshow the benefit of using our our model, in comparison with standard set models\nwhich do not incorporate set containment as an inductive bias. Our code is\navailable in https://github.com/yonatansverdlov/Monotone-Embedding.", "AI": {"tldr": "Proposes and analyzes monotone and separating (MAS) set-to-vector functions that preserve subset containment: S \u2286 T iff F(S) \u2264 F(T). Derives dimension bounds and a nonexistence result for infinite ground sets, and introduces a 'our' model with a relaxed weakly MAS property and H\u00f6lder continuity. Shows MAS can yield universal monotone models that approximate all monotone set functions; empirical results show gains over standard set models; code released.", "motivation": "To design vector embeddings of sets that preserve the natural subset containment relation, enabling reliable set containment tasks.", "method": "Theoretical bounds on the vector dimension needed for MAS; impossibility result for infinite ground sets; introduce a pragmatic model (the 'our' model) that achieves weakly MAS with H\u00f6lder stability; construct universal monotone models based on MAS; empirical evaluation on set containment tasks comparing against standard models.", "result": "Finite ground sets admit MAS functions with dimension bounds; infinite ground sets do not admit MAS; a weakly MAS model with H\u00f6lder continuity is proposed; MAS-based universal monotone models can approximate all monotone set functions; experiments show empirical advantages over standard set models.", "conclusion": "MAS-based embeddings provide a principled inductive bias for set containment; the weakly MAS model offers a practical, stable alternative for infinite domains; code is publicly available for reproduction."}}
{"id": "2510.23981", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23981", "abs": "https://arxiv.org/abs/2510.23981", "authors": ["Jiaqi Yan", "Ruilong Ren", "Jingren Liu", "Shuning Xu", "Ling Wang", "Yiheng Wang", "Yun Wang", "Long Zhang", "Xiangyu Chen", "Changzhi Sun", "Jixiang Luo", "Dell Zhang", "Hao Sun", "Chi Zhang", "Xuelong Li"], "title": "TeleEgo: Benchmarking Egocentric AI Assistants in the Wild", "comment": null, "summary": "Egocentric AI assistants in real-world settings must process multi-modal\ninputs (video, audio, text), respond in real time, and retain evolving\nlong-term memory. However, existing benchmarks typically evaluate these\nabilities in isolation, lack realistic streaming scenarios, or support only\nshort-term tasks. We introduce \\textbf{TeleEgo}, a long-duration, streaming,\nomni-modal benchmark for evaluating egocentric AI assistants in realistic daily\ncontexts. The dataset features over 14 hours per participant of synchronized\negocentric video, audio, and text across four domains: work \\& study, lifestyle\n\\& routines, social activities, and outings \\& culture. All data is aligned on\na unified global timeline and includes high-quality visual narrations and\nspeech transcripts, curated through human refinement.TeleEgo defines 12\ndiagnostic subtasks across three core capabilities: Memory (recalling past\nevents), Understanding (interpreting the current moment), and Cross-Memory\nReasoning (linking distant events). It contains 3,291 human-verified QA items\nspanning multiple question formats (single-choice, binary, multi-choice, and\nopen-ended), evaluated strictly in a streaming setting. We propose two key\nmetrics -- Real-Time Accuracy and Memory Persistence Time -- to jointly assess\ncorrectness, temporal responsiveness, and long-term retention. TeleEgo provides\na realistic and comprehensive evaluation to advance the development of\npractical AI assistants.", "AI": {"tldr": "TeleEgo introduces a long-duration, streaming, omni-modal benchmark for egocentric AI assistants, featuring 14 hours per participant of synchronized video, audio, and text across four real-world domains, with 12 diagnostic subtasks and 3,291 QA items evaluated in a streaming setting. Two metrics, Real-Time Accuracy and Memory Persistence Time, measure correctness, responsiveness, and long-term retention.", "motivation": "Current benchmarks evaluate egocentric AI components in isolation and lack realistic streaming, long-term memory integration in daily-life contexts; there is a need for a unified benchmark that tests memory, understanding, and cross-memory reasoning over extended periods.", "method": "Data collection of long-duration egocentric multimodal recordings with human-refined visual narrations and transcripts; alignment on a global timeline; formulation of 12 diagnostic subtasks across Memory, Understanding, and Cross-Memory Reasoning; generation of 3,291 QA items in multiple formats; development of two streaming-oriented evaluation metrics (Real-Time Accuracy, Memory Persistence Time).", "result": "Proposes TeleEgo dataset and evaluation protocol for egocentric AI in streaming settings; introduces 12 subtasks and 3,291 QA items; defines Real-Time Accuracy and Memory Persistence Time metrics; no experimental results reported in abstract.", "conclusion": "TeleEgo offers a realistic, comprehensive benchmark to drive development of practical egocentric AI assistants capable of multi-modal processing, real-time response, and long-term memory integration in everyday contexts."}}
{"id": "2510.24067", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24067", "abs": "https://arxiv.org/abs/2510.24067", "authors": ["Tianyi Ding", "Ronghao Zheng", "Senlin Zhang", "Meiqin Liu"], "title": "Balanced Collaborative Exploration via Distributed Topological Graph Voronoi Partition", "comment": null, "summary": "This work addresses the collaborative multi-robot autonomous online\nexploration problem, particularly focusing on distributed exploration planning\nfor dynamically balanced exploration area partition and task allocation among a\nteam of mobile robots operating in obstacle-dense non-convex environments.\n  We present a novel topological map structure that simultaneously\ncharacterizes both spatial connectivity and global exploration completeness of\nthe environment. The topological map is updated incrementally to utilize known\nspatial information for updating reachable spaces, while exploration targets\nare planned in a receding horizon fashion under global coverage guidance.\n  A distributed weighted topological graph Voronoi algorithm is introduced\nimplementing balanced graph space partitions of the fused topological maps.\nTheoretical guarantees are provided for distributed consensus convergence and\nequitable graph space partitions with constant bounds.\n  A local planner optimizes the visitation sequence of exploration targets\nwithin the balanced partitioned graph space to minimize travel distance, while\ngenerating safe, smooth, and dynamically feasible motion trajectories.\n  Comprehensive benchmarking against state-of-the-art methods demonstrates\nsignificant improvements in exploration efficiency, completeness, and workload\nbalance across the robot team.", "AI": {"tldr": "Distributed topological mapping and Voronoi-based partitioning enable balanced, efficient multi-robot exploration with provable consensus in cluttered, non-convex environments.", "motivation": "Need for scalable multi-robot exploration that maintains coverage, balances workload, and handles dynamic, obstacle-dense spaces; existing methods struggle with partition fairness and global completeness.", "method": "Incremental topological map capturing spatial connectivity and exploration completeness; receding-horizon target planning under global guidance; distributed weighted topological graph Voronoi algorithm for balanced partitions; local planner optimizes exploration target visitation and generates safe trajectories; theoretical guarantees on consensus convergence and equitable partitions; benchmarking against state-of-the-art.", "result": "Proves distributed consensus convergence and equitable graph partitions with constant bounds; empirical benchmarking shows significant improvements in exploration efficiency, completeness, and workload balance.", "conclusion": "The proposed framework provides a scalable, provably balanced, and efficient approach to collaborative exploration in challenging environments, combining topological mapping, Voronoi-based partitioning, and receding-horizon planning to realize improved performance."}}
{"id": "2510.23883", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23883", "abs": "https://arxiv.org/abs/2510.23883", "authors": ["Shrestha Datta", "Shahriar Kabir Nahin", "Anshuman Chhabra", "Prasant Mohapatra"], "title": "Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges", "comment": null, "summary": "Agentic AI systems powered by large language models (LLMs) and endowed with\nplanning, tool use, memory, and autonomy, are emerging as powerful, flexible\nplatforms for automation. Their ability to autonomously execute tasks across\nweb, software, and physical environments creates new and amplified security\nrisks, distinct from both traditional AI safety and conventional software\nsecurity. This survey outlines a taxonomy of threats specific to agentic AI,\nreviews recent benchmarks and evaluation methodologies, and discusses defense\nstrategies from both technical and governance perspectives. We synthesize\ncurrent research and highlight open challenges, aiming to support the\ndevelopment of secure-by-design agent systems.", "AI": {"tldr": "A survey of agentic AI security: taxonomy of agentic threats, benchmarks, defense strategies, and governance for secure-by-design systems.", "motivation": "Agentic LLM-powered systems autonomously operate across domains, creating new security risks beyond traditional AI safety and software security; a structured understanding and defenses are needed.", "method": "Literature survey and synthesis; development of a threat taxonomy; review of existing benchmarks/evaluation methodologies; analysis of defense strategies from technical and governance perspectives.", "result": "Provides a taxonomy of agentic-AI threats; surveys benchmarks and evaluation methods; summarizes defensive approaches; identifies open challenges; proposes secure-by-design guidelines.", "conclusion": "Secure-by-design agent systems require integrated technical and governance measures; this work consolidates state-of-the-art and points to future research directions."}}
{"id": "2510.23635", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23635", "abs": "https://arxiv.org/abs/2510.23635", "authors": ["Andrea Bontempelli", "Matteo Busso", "Leonardo Javier Malcotti", "Fausto Giunchiglia"], "title": "Help the machine to help you: an evaluation in the wild of egocentric data cleaning via skeptical learning", "comment": null, "summary": "Any digital personal assistant, whether used to support task performance,\nanswer questions, or manage work and daily life, including fitness schedules,\nrequires high-quality annotations to function properly. However, user\nannotations, whether actively produced or inferred from context (e.g., data\nfrom smartphone sensors), are often subject to errors and noise. Previous\nresearch on Skeptical Learning (SKEL) addressed the issue of noisy labels by\ncomparing offline active annotations with passive data, allowing for an\nevaluation of annotation accuracy. However, this evaluation did not include\nconfirmation from end-users, the best judges of their own context. In this\nstudy, we evaluate SKEL's performance in real-world conditions with actual\nusers who can refine the input labels based on their current perspectives and\nneeds. The study involves university students using the iLog mobile application\non their devices over a period of four weeks. The results highlight the\nchallenges of finding the right balance between user effort and data quality,\nas well as the potential benefits of using SKEL, which include reduced\nannotation effort and improved quality of collected data.", "AI": {"tldr": "Real-world evaluation of Skeptical Learning (SKEL) with end-user confirmation over four weeks using an iLog app, revealing a trade-off between user effort and data quality, and showing SKEL\u2019s potential to reduce annotation effort while improving data quality.", "motivation": "To test SKEL under realistic conditions with end-user input, addressing the earlier lack of user-confirmed annotations and evaluating how well SKEL preserves annotation accuracy when users refine labels.", "method": "Longitudinal field study with university students over four weeks using the iLog mobile app. Participants provide/refine input labels and data from smartphone context; SKEL performance is assessed in real-world conditions, focusing on annotation accuracy, user effort, and data quality.", "result": "Findings highlight the challenge of balancing user effort and data quality in annotations. SKEL shows potential benefits, including reduced annotation effort and improved quality of collected data, when end-user confirmation is incorporated.", "conclusion": "Incorporating end-user input in SKEL\u2019s evaluation demonstrates its promise for reducing labeling effort and enhancing data quality in real-world settings, while underscoring the need to optimize the effort\u2013quality trade-off."}}
{"id": "2510.24000", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24000", "abs": "https://arxiv.org/abs/2510.24000", "authors": ["Heethanjan Kanagalingam", "Thenukan Pathmanathan", "Mokeeshan Vathanakumar", "Tharmakulasingam Mukunthan"], "title": "AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization", "comment": null, "summary": "Diabetic retinopathy (DR) is a leading cause of vision loss worldwide, yet\nearly and accurate detection can significantly improve treatment outcomes.\nWhile numerous Deep learning (DL) models have been developed to predict DR from\nfundus images, many face challenges in maintaining robustness due to\ndistributional variations caused by differences in acquisition devices,\ndemographic disparities, and imaging conditions. This paper addresses this\ncritical limitation by proposing a novel DR classification approach, a method\ncalled AdvBlur. Our method integrates adversarial blurred images into the\ndataset and employs a dual-loss function framework to address domain\ngeneralization. This approach effectively mitigates the impact of unseen\ndistributional variations, as evidenced by comprehensive evaluations across\nmultiple datasets. Additionally, we conduct extensive experiments to explore\nthe effects of factors such as camera type, low-quality images, and dataset\nsize. Furthermore, we perform ablation studies on blurred images and the loss\nfunction to ensure the validity of our choices. The experimental results\ndemonstrate the effectiveness of our proposed method, achieving competitive\nperformance compared to state-of-the-art domain generalization DR models on\nunseen external datasets.", "AI": {"tldr": "AdvBlur uses adversarial blur augmentation and a dual-loss objective to improve domain generalization in diabetic retinopathy (DR) classification, achieving competitive performance on unseen external datasets and demonstrating robustness across varied imaging conditions.", "motivation": "DR DL models struggle with distributional shifts due to device differences, demographics, and imaging conditions; robust generalization to unseen data is required for reliable DR screening.", "method": "Inject adversarially blurred images into the training dataset and optimize with a dual-loss framework to enhance cross-domain generalization.", "result": "Demonstrates mitigation of unseen distributional variations and competitive performance compared to state-of-the-art domain-generalization DR models on external datasets; supported by ablation studies on blur, loss functions, camera types, image quality, and dataset size.", "conclusion": "AdvBlur is an effective approach for robust DR classification under distribution shifts, validated by comprehensive experiments across multiple datasets and ablation studies."}}
{"id": "2510.24069", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24069", "abs": "https://arxiv.org/abs/2510.24069", "authors": ["Sangmin Kim", "Hajun Kim", "Gijeong Kim", "Min-Gyu Kim", "Hae-Won Park"], "title": "Dynamically-Consistent Trajectory Optimization for Legged Robots via Contact Point Decomposition", "comment": "8 pages, 4 figures, IEEE ROBOTICS AND AUTOMATION LETTERS. PREPRINT\n  VERSION. ACCEPTED OCTOBER, 2025", "summary": "To generate reliable motion for legged robots through trajectory\noptimization, it is crucial to simultaneously compute the robot's path and\ncontact sequence, as well as accurately consider the dynamics in the problem\nformulation. In this paper, we present a phase-based trajectory optimization\nthat ensures the feasibility of translational dynamics and friction cone\nconstraints throughout the entire trajectory. Specifically, our approach\nleverages the superposition properties of linear differential equations to\ndecouple the translational dynamics for each contact point, which operates\nunder different phase sequences. Furthermore, we utilize the differentiation\nmatrix of B{\\'e}zier polynomials to derive an analytical relationship between\nthe robot's position and force, thereby ensuring the consistent satisfaction of\ntranslational dynamics. Additionally, by exploiting the convex closure property\nof B{\\'e}zier polynomials, our method ensures compliance with friction cone\nconstraints. Using the aforementioned approach, the proposed trajectory\noptimization framework can generate dynamically reliable motions with various\ngait sequences for legged robots. We validate our framework using a quadruped\nrobot model, focusing on the feasibility of dynamics and motion generation.", "AI": {"tldr": "Phase-based trajectory optimization for legged robots that decouples translational dynamics by contact using linear superposition, and enforces dynamics and friction constraints via B\u00e9zier polynomial differentiation matrices and convexity.", "motivation": "To ensure dynamically feasible legged motions by jointly optimizing trajectory and contact sequence with accurate dynamics and friction constraints.", "method": "1) Decompose translational dynamics per contact via superposition of linear differential equations, across different phase sequences. 2) Use differentiation matrices of B\u00e9zier polynomials to link position and contact forces analytically, ensuring dynamic consistency. 3) Exploit convex closure property of B\u00e9zier polynomials to satisfy friction cone constraints along the trajectory. 4) Validate on a quadruped model focusing on dynamics feasibility and motion generation across gait sequences.", "result": "A trajectory optimization framework that can generate dynamically reliable motions for legged robots with various gait sequences; demonstrated feasibility for dynamics and motion generation on a quadruped model.", "conclusion": "The approach offers a mathematically tractable and vibration-free way to enforce dynamic feasibility and friction constraints through phase-based decoupling and B\u00e9zier-based relations, enabling reliable gait-aware motion planning for legged robots."}}
{"id": "2510.23925", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23925", "abs": "https://arxiv.org/abs/2510.23925", "authors": ["Guohao Sun", "Hang Hua", "Jian Wang", "Jiebo Luo", "Sohail Dianat", "Majid Rabbani", "Raghuveer Rao", "Zhiqiang Tao"], "title": "Latent Chain-of-Thought for Visual Reasoning", "comment": "NeurIPS 2025", "summary": "Chain-of-thought (CoT) reasoning is critical for improving the\ninterpretability and reliability of Large Vision-Language Models (LVLMs).\nHowever, existing training algorithms such as SFT, PPO, and GRPO may not\ngeneralize well across unseen reasoning tasks and heavily rely on a biased\nreward model. To address this challenge, we reformulate reasoning in LVLMs as\nposterior inference and propose a scalable training algorithm based on\namortized variational inference. By leveraging diversity-seeking reinforcement\nlearning algorithms, we introduce a novel sparse reward function for\ntoken-level learning signals that encourage diverse, high-likelihood latent\nCoT, overcoming deterministic sampling limitations and avoiding reward hacking.\nAdditionally, we implement a Bayesian inference-scaling strategy that replaces\ncostly Best-of-N and Beam Search with a marginal likelihood to efficiently rank\noptimal rationales and answers. We empirically demonstrate that the proposed\nmethod enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in\nterms of effectiveness, generalization, and interpretability.", "AI": {"tldr": "Reformulates LVLM chain-of-thought as posterior inference, using amortized variational inference and diversity-seeking RL with sparse token-level rewards; employs Bayesian marginal likelihood ranking to select rationales and answers; yields improved effectiveness, generalization, and interpretability across seven reasoning benchmarks.", "motivation": "Current CoT training methods (SFT, PPO, GRPO) struggle to generalize to unseen reasoning tasks and rely on biased reward models; a scalable, robust training framework for reasoning in LVLMs is needed.", "method": "Formulate reasoning as posterior inference and optimize via amortized variational inference. Introduce diversity-seeking reinforcement learning with a sparse token-level reward to encourage diverse, high-likelihood latent CoT while avoiding deterministic sampling pitfalls and reward hacking. Replace costly Best-of-N/Beam Search with a Bayesian inference-scaling strategy that ranks rationales and answers using marginal likelihood.", "result": "Empirically demonstrate state-of-the-art improvements for LVLMs on seven reasoning benchmarks in effectiveness, generalization, and interpretability.", "conclusion": "The proposed variational-inference-based, diversity-aware LVLM training framework provides scalable, robust improvements in reasoning performance and interpretability, reducing reliance on biased rewards and sampling bottlenecks."}}
{"id": "2510.23636", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23636", "abs": "https://arxiv.org/abs/2510.23636", "authors": ["Thaweerath Phisannupawong", "Joshua Julian Damanik", "Han-Lim Choi"], "title": "Flight Delay Prediction via Cross-Modality Adaptation of Large Language Models and Aircraft Trajectory Representation", "comment": "Preprint submitted to Aerospace Science and Technology (Elsevier) for\n  possible publication", "summary": "Flight delay prediction has become a key focus in air traffic management, as\ndelays highlight inefficiencies that impact overall network performance. This\npaper presents a lightweight large language model-based multimodal flight delay\nprediction, formulated from the perspective of air traffic controllers\nmonitoring aircraft delay after entering the terminal area. The approach\nintegrates trajectory representations with textual aeronautical information,\nincluding flight information, weather reports, and aerodrome notices, by\nadapting trajectory data into the language modality to capture airspace\nconditions. Experimental results show that the model consistently achieves\nsub-minute prediction error by effectively leveraging contextual information\nrelated to the sources of delay. The framework demonstrates that linguistic\nunderstanding, when combined with cross-modality adaptation of trajectory\ninformation, enhances delay prediction. Moreover, the approach shows\npracticality and scalability for real-world operations, supporting real-time\nupdates that refine predictions upon receiving new operational information.", "AI": {"tldr": "A lightweight LLM-based multimodal framework for real-time flight delay prediction that converts trajectory data into language and fuses it with textual data (weather, flight information, NOTAMs) to achieve sub-minute accuracy and real-time updates.", "motivation": "Delays degrade air-traffic efficiency; current approaches often underutilize cross-modal information and real-time context; a scalable, real-time solution context for air traffic controllers monitoring terminal-area delays is needed.", "method": "Proposes adapting trajectory representations into the language modality and integrating textual aeronautical information (flight data, weather reports, aerodrome NOTAMs) to form a multimodal input for a lightweight LLM, enabling cross-modality understanding and real-time updates.", "result": "Achieves sub-minute prediction error; effectively leverages contextual information about delay sources; demonstrates practicality and scalability for real-world, real-time operations with updates as new information arrives.", "conclusion": "Linguistic understanding combined with cross-modality adaptation of trajectory information enhances delay prediction and yields a practical, scalable framework for real-time ATC operations."}}
{"id": "2510.24009", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24009", "abs": "https://arxiv.org/abs/2510.24009", "authors": ["Yuan Jin", "Antonio Pepe", "Gian Marco Melito", "Yuxuan Chen", "Yunsu Byeon", "Hyeseong Kim", "Kyungwon Kim", "Doohyun Park", "Euijoon Choi", "Dosik Hwang", "Andriy Myronenko", "Dong Yang", "Yufan He", "Daguang Xu", "Ayman El-Ghotni", "Mohamed Nabil", "Hossam El-Kady", "Ahmed Ayyad", "Amr Nasr", "Marek Wodzinski", "Henning M\u00fcller", "Hyeongyu Kim", "Yejee Shin", "Abbas Khan", "Muhammad Asad", "Alexander Zolotarev", "Caroline Roney", "Anthony Mathur", "Martin Benning", "Gregory Slabaugh", "Theodoros Panagiotis Vagenas", "Konstantinos Georgas", "George K. Matsopoulos", "Jihan Zhang", "Zhen Zhang", "Liqin Huang", "Christian Mayer", "Heinrich M\u00e4chler", "Jan Egger"], "title": "Towards the Automatic Segmentation, Modeling and Meshing of the Aortic Vessel Tree from Multicenter Acquisitions: An Overview of the SEG.A. 2023 Segmentation of the Aorta Challenge", "comment": null, "summary": "The automated analysis of the aortic vessel tree (AVT) from computed\ntomography angiography (CTA) holds immense clinical potential, but its\ndevelopment has been impeded by a lack of shared, high-quality data. We\nlaunched the SEG.A. challenge to catalyze progress in this field by introducing\na large, publicly available, multi-institutional dataset for AVT segmentation.\nThe challenge benchmarked automated algorithms on a hidden test set, with\nsubsequent optional tasks in surface meshing for computational simulations. Our\nfindings reveal a clear convergence on deep learning methodologies, with 3D\nU-Net architectures dominating the top submissions. A key result was that an\nensemble of the highest-ranking algorithms significantly outperformed\nindividual models, highlighting the benefits of model fusion. Performance was\nstrongly linked to algorithmic design, particularly the use of customized\npost-processing steps, and the characteristics of the training data. This\ninitiative not only establishes a new performance benchmark but also provides a\nlasting resource to drive future innovation toward robust, clinically\ntranslatable tools.", "AI": {"tldr": "A multi-institutional SEG.A. challenge released a large public AVT segmentation dataset from CTA; 3D U-Net models dominate top results, with ensemble methods outperforming single models; post-processing and data characteristics crucial; dataset serves as a shared benchmark to push toward clinically translatable AVT analysis.", "motivation": "Lack of shared, high-quality data hindered automated analysis of the aortic vessel tree (AVT) from CTA. The SEG.A. challenge provides a large, public, multi-institutional dataset and a benchmark to accelerate progress toward robust, clinically usable AVT segmentation.", "method": "Launch of the SEG.A. challenge with a large, publicly available AVT segmentation dataset. The benchmark evaluated algorithms on a hidden test set and included optional surface-meshing tasks for simulations. The field converged on deep learning, notably 3D U-Nets, with an ensemble of top-performing models outperforming individual models. Customized post-processing and training data characteristics were key factors.", "result": "Top submissions were dominated by 3D U-Net architectures; an ensemble of the highest-ranking models significantly outperformed single models. Performance correlated with algorithm design, post-processing steps, and the nature of the training data, revealing the importance of data and design choices in AVT segmentation.", "conclusion": "The SEG.A. initiative establishes a new performance benchmark and a lasting resource for advancing robust, clinically translatable AVT analysis tools, underscoring the value of data sharing and model fusion in this domain."}}
{"id": "2510.24108", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24108", "abs": "https://arxiv.org/abs/2510.24108", "authors": ["Zhenxin Li", "Wenhao Yao", "Zi Wang", "Xinglong Sun", "Jingde Chen", "Nadine Chang", "Maying Shen", "Jingyu Song", "Zuxuan Wu", "Shiyi Lan", "Jose M. Alvarez"], "title": "ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring", "comment": null, "summary": "End-to-end autonomous driving maps raw sensor inputs directly into\nego-vehicle trajectories to avoid cascading errors from perception modules and\nto leverage rich semantic cues. Existing frameworks largely rely on Imitation\nLearning (IL), which can be limited by sub-optimal expert demonstrations and\ncovariate shift during deployment. On the other hand, Reinforcement Learning\n(RL) has recently shown potential in scaling up with simulations, but is\ntypically confined to low-dimensional symbolic inputs (e.g. 3D objects and\nmaps), falling short of full end-to-end learning from raw sensor data. We\nintroduce ZTRS (Zero-Imitation End-to-End Autonomous Driving with Trajectory\nScoring), a framework that combines the strengths of both worlds: sensor inputs\nwithout losing information and RL training for robust planning. To the best of\nour knowledge, ZTRS is the first framework that eliminates IL entirely by only\nlearning from rewards while operating directly on high-dimensional sensor data.\nZTRS utilizes offline reinforcement learning with our proposed Exhaustive\nPolicy Optimization (EPO), a variant of policy gradient tailored for enumerable\nactions and rewards. ZTRS demonstrates strong performance across three\nbenchmarks: Navtest (generic real-world open-loop planning), Navhard (open-loop\nplanning in challenging real-world and synthetic scenarios), and HUGSIM\n(simulated closed-loop driving). Specifically, ZTRS achieves the\nstate-of-the-art result on Navhard and outperforms IL-based baselines on\nHUGSIM. Code will be available at https://github.com/woxihuanjiangguo/ZTRS.", "AI": {"tldr": "A novel offline RL framework for end-to-end autonomous driving that learns directly from high-dimensional sensor data without imitation learning, using Exhaustive Policy Optimization (EPO) to optimize on enumerable actions/rewards, achieving strong results across multiple benchmarks.", "motivation": "Overcome limitations of imitation learning (sub-optimal demonstrations, covariate shift) and traditional RL limits (reliance on low-dimensional inputs) by enabling end-to-end learning from raw sensor data while maintaining robust planning.", "method": "Introduce ZTRS (Zero-Imitation End-to-End Autonomous Driving with Trajectory Scoring) that uses offline reinforcement learning with Exhaustive Policy Optimization (EPO), a policy-gradient variant tailored for enumerable actions and rewards, operating directly on high-dimensional sensor inputs and circumventing imitation learning entirely.", "result": "Achieves state-of-the-art performance on Navhard and outperforms IL-based baselines on HUGSIM; demonstrates strong performance across three benchmarks (Navtest, Navhard, HUGSIM). Code will be released at the provided repository link.", "conclusion": "ZTRS is the first framework to eliminate imitation learning entirely for end-to-end autonomous driving by learning from rewards on high-dimensional sensor data, highlighting the viability of offline RL with tailored policy optimization for real-world driving tasks."}}
{"id": "2510.23942", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23942", "abs": "https://arxiv.org/abs/2510.23942", "authors": ["Sridhar Mahadevan"], "title": "Decentralized Causal Discovery using Judo Calculus", "comment": "54 pages", "summary": "We describe a theory and implementation of an intuitionistic decentralized\nframework for causal discovery using judo calculus, which is formally defined\nas j-stable causal inference using j-do-calculus in a topos of sheaves. In\nreal-world applications -- from biology to medicine and social science --\ncausal effects depend on regime (age, country, dose, genotype, or lab\nprotocol). Our proposed judo calculus formalizes this context dependence\nformally as local truth: a causal claim is proven true on a cover of regimes,\nnot everywhere at once. The Lawvere-Tierney modal operator j chooses which\nregimes are relevant; j-stability means the claim holds constructively and\nconsistently across that family. We describe an algorithmic and implementation\nframework for judo calculus, combining it with standard score-based,\nconstraint-based, and gradient-based causal discovery methods. We describe\nexperimental results on a range of domains, from synthetic to real-world\ndatasets from biology and economics. Our experimental results show the\ncomputational efficiency gained by the decentralized nature of sheaf-theoretic\ncausal discovery, as well as improved performance over classical causal\ndiscovery methods.", "AI": {"tldr": "A theory and implementation of judo calculus for intuitionistic, decentralized causal discovery using j-do-calculus in a topos of sheaves, enabling regime-specific local truths and j-stability; integrates with standard discovery methods and reports efficiency and improved accuracy across synthetic and real-world data.", "motivation": "Causal effects depend on regime (age, country, dose, genotype, lab protocol). Global causal claims are unreliable; a formal, regime-aware framework is needed, leveraging topos theory and intuitionistic logic to model local truths and decentralization.", "method": "Formalize judo calculus on j-do-calculus within a topos of sheaves, using a Lawvere\u2013Tierney modal operator j to select relevant regimes and enforce j-stability (constructed truth across covers). Implement a decentralized framework that combines judo with score-based, constraint-based, and gradient-based causal discovery methods; provide algorithmic and software implementation; evaluate on synthetic and real-world datasets.", "result": "Decentralized, sheaf-theoretic approach yields computational efficiency and improved performance over classical causal discovery methods; effective across domains from biology to economics, handling regime-dependent causal claims.", "conclusion": "The judo calculus offers a rigorous, scalable framework for regime-aware causal discovery, uniting intuitionistic logic, topos theory, and standard discovery techniques; future work may broaden applicability, refine scalability, and explore broader logical foundations."}}
{"id": "2510.23637", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.23637", "abs": "https://arxiv.org/abs/2510.23637", "authors": ["Job Petrov\u010di\u010d", "David Eliecer Narvaez Denis", "Ljup\u010do Todorovski"], "title": "Combining Textual and Structural Information for Premise Selection in Lean", "comment": null, "summary": "Premise selection is a key bottleneck for scaling theorem proving in large\nformal libraries. Yet existing language-based methods often treat premises in\nisolation, ignoring the web of dependencies that connects them. We present a\ngraph-augmented approach that combines dense text embeddings of Lean\nformalizations with graph neural networks over a heterogeneous dependency graph\ncapturing both state--premise and premise--premise relations. On the LeanDojo\nBenchmark, our method outperforms the ReProver language-based baseline by over\n25% across standard retrieval metrics. These results demonstrate the power of\nrelational information for more effective premise selection.", "AI": {"tldr": "A graph-augmented premise selection method combining dense sentence embeddings with a heterogeneous dependency graph and GNNs outperforms a language-based baseline on LeanDojo by >25%.", "motivation": "Premise selection is a bottleneck in scaling automated theorem proving. Language-based methods often treat premises independently and ignore dependencies among lemmas/theorems. Incorporating relational structure can improve retrieval accuracy.", "method": "Integrates dense textual embeddings of Lean formalizations with a graph neural network operating over a heterogeneous dependency graph that encodes both state\u2013premise and premise\u2013premise relations. The model leverages both textual content and relational structure to select relevant premises.", "result": "On the LeanDojo Benchmark, the proposed graph-augmented method surpasses the ReProver baseline by more than 25% across standard retrieval metrics.", "conclusion": "Incorporating relational information through a graph-augmented framework significantly enhances premise selection, demonstrating the value of combining textual representations with structured dependencies in theorem proving."}}
{"id": "2510.24010", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24010", "abs": "https://arxiv.org/abs/2510.24010", "authors": ["Mirali Purohit", "Bimal Gajera", "Vatsal Malaviya", "Irish Mehta", "Kunal Kasodekar", "Jacob Adler", "Steven Lu", "Umaa Rebbapragada", "Hannah Kerner"], "title": "Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks", "comment": "Accepted at NeurIPS 2025", "summary": "Foundation models have enabled rapid progress across many specialized domains\nby leveraging large-scale pre-training on unlabeled data, demonstrating strong\ngeneralization to a variety of downstream tasks. While such models have gained\nsignificant attention in fields like Earth Observation, their application to\nMars science remains limited. A key enabler of progress in other domains has\nbeen the availability of standardized benchmarks that support systematic\nevaluation. In contrast, Mars science lacks such benchmarks and standardized\nevaluation frameworks, which have limited progress toward developing foundation\nmodels for Martian tasks. To address this gap, we introduce Mars-Bench, the\nfirst benchmark designed to systematically evaluate models across a broad range\nof Mars-related tasks using both orbital and surface imagery. Mars-Bench\ncomprises 20 datasets spanning classification, segmentation, and object\ndetection, focused on key geologic features such as craters, cones, boulders,\nand frost. We provide standardized, ready-to-use datasets and baseline\nevaluations using models pre-trained on natural images, Earth satellite data,\nand state-of-the-art vision-language models. Results from all analyses suggest\nthat Mars-specific foundation models may offer advantages over general-domain\ncounterparts, motivating further exploration of domain-adapted pre-training.\nMars-Bench aims to establish a standardized foundation for developing and\ncomparing machine learning models for Mars science. Our data, models, and code\nare available at: https://mars-bench.github.io/.", "AI": {"tldr": "Mars-Bench is the first standardized benchmark for Mars ML tasks, featuring 20 datasets across classification, segmentation, and object detection; baseline results suggest Mars-specific foundation models may outperform general-domain models; data, models, and code are available at mars-bench.github.io.", "motivation": "To address the lack of standardized benchmarks for Mars science, which hampers progress in developing foundation models and enabling systematic evaluation across Mars-related tasks.", "method": "Assemble 20 datasets spanning orbital and surface imagery focused on key geologic features (craters, cones, boulders, frost); provide ready-to-use datasets and baselines using models pre-trained on natural images, Earth satellite data, and vision-language models.", "result": "Initial analyses indicate Mars-specific foundation models may offer advantages over general-domain counterparts, highlighting the value of domain-adapted pre-training.", "conclusion": "Mars-Bench provides a standardized platform for developing and comparing ML models for Mars science and encourages domain-specific pre-training; data, models, and code are publicly available at the project site."}}
{"id": "2510.24109", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24109", "abs": "https://arxiv.org/abs/2510.24109", "authors": ["Wenbin Ding", "Jun Chen", "Mingjia Chen", "Fei Xie", "Qi Mao", "Philip Dames"], "title": "PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI", "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has marked a\nsignificant breakthrough in Artificial Intelligence (AI), ushering in a new era\nof Human-centered Artificial Intelligence (HAI). HAI aims to better serve human\nwelfare and needs, thereby placing higher demands on the intelligence level of\nrobots, particularly in aspects such as natural language interaction, complex\ntask planning, and execution. Intelligent agents powered by LLMs have opened up\nnew pathways for realizing HAI. However, existing LLM-based embodied agents\noften lack the ability to plan and execute complex natural language control\ntasks online. This paper explores the implementation of intelligent robotic\nmanipulating agents based on Vision-Language Models (VLMs) in the physical\nworld. We propose a novel embodied agent framework for robots, which comprises\na human-robot voice interaction module, a vision-language agent module and an\naction execution module. The vision-language agent itself includes a\nvision-based task planner, a natural language instruction converter, and a task\nperformance feedback evaluator. Experimental results demonstrate that our agent\nachieves a 28\\% higher average task success rate in both simulated and real\nenvironments compared to approaches relying solely on LLM+CLIP, significantly\nimproving the execution success rate of high-level natural language instruction\ntasks.", "AI": {"tldr": "An embodied robot agent framework using vision-language models to plan and execute high-level natural language tasks online, achieving 28% higher task success than LLM+CLIP baselines in both simulated and real environments.", "motivation": "To advance human-centered AI by enabling robots to understand, plan, and execute natural-language tasks more reliably, addressing limitations of existing LLM-based embodied agents in online planning and execution.", "method": "Proposes an embodied robot framework with modules: (1) human-robot voice interaction, (2) vision-language agent including a vision-based task planner, an NL instruction converter, and a task performance feedback evaluator, and (3) an action execution module. The system integrates Vision-Language Models to enable online planning and action.", "result": "Empirical evaluation shows a 28% higher average task success rate than LLM+CLIP baselines in both simulated and real environments, notably improving high-level NL instruction execution.", "conclusion": "The proposed Vision-Language embodied agent effectively enhances online planning and execution of natural-language tasks in robotics, contributing to more capable and reliable Human-centered AI; future work may explore broader tasks, real-time robustness, and scalability."}}
{"id": "2510.23965", "categories": ["cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23965", "abs": "https://arxiv.org/abs/2510.23965", "authors": ["Aymane El Gadarri", "Ali Aouad", "Vivek F. Farias"], "title": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity", "comment": null, "summary": "Traditional LLM alignment methods are vulnerable to heterogeneity in human\npreferences. Fitting a na\\\"ive probabilistic model to pairwise comparison data\n(say over prompt-completion pairs) yields an inconsistent estimate of the\npopulation-average utility -a canonical measure of social welfare. We propose a\nnew method, dubbed the sign estimator, that provides a simple, provably\nconsistent, and efficient estimator by replacing cross-entropy with binary\nclassification loss in the aggregation step. This simple modification recovers\nconsistent ordinal alignment under mild assumptions and achieves the first\npolynomial finite-sample error bounds in this setting. In realistic simulations\nof LLM alignment using digital twins, the sign estimator substantially reduces\npreference distortion over a panel of simulated personas, cutting (angular)\nestimation error by nearly 35% and decreasing disagreement with true population\npreferences from 12% to 8% compared to standard RLHF. Our method also compares\nfavorably to panel data heuristics that explicitly model user heterogeneity and\nrequire tracking individual-level preference data-all while maintaining the\nimplementation simplicity of existing LLM alignment pipelines.", "AI": {"tldr": "A simple, consistent estimator for LLM alignment called the sign estimator uses binary classification loss in aggregation instead of cross-entropy, yielding provable consistency and finite-sample guarantees for ordinal alignment under heterogeneous preferences, with strong simulated performance gains over standard RLHF.", "motivation": "Traditional LLM alignment with pairwise data and naive probabilistic models yields inconsistent estimates of population-average utility due to heterogeneity in human preferences. A simple, provably consistent method is needed that can handle heterogeneity while remaining easy to implement.", "method": "Introduce the sign estimator that substitutes binary classification loss for cross-entropy in the aggregation step when fitting to pairwise comparison data. Prove consistency under mild assumptions and establish polynomial finite-sample error bounds. Validate via simulations with digital-twin personas to model heterogeneous users.", "result": "The sign estimator substantially reduces preference distortion in simulations, cutting angular estimation error by about 35% and lowering disagreement with true population preferences from 12% to 8% compared with standard RLHF. It also outperforms panel-data heuristics that model user heterogeneity and require tracking individual-level data, all while preserving the simplicity of existing LLM alignment pipelines.", "conclusion": "The sign estimator offers a simple, provably consistent approach to ordinal alignment under heterogeneous preferences, with finite-sample guarantees and notable practical gains in simulated settings, making it a strong candidate for incorporation into LLM alignment workflows."}}
{"id": "2510.23639", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.23639", "abs": "https://arxiv.org/abs/2510.23639", "authors": ["Jonathan Amar", "Edward Liu", "Alessandra Breschi", "Liangliang Zhang", "Pouya Kheradpour", "Sylvia Li", "Lisa Soleymani Lehmann", "Alessandro Giulianelli", "Matt Edwards", "Yugang Jia", "David Nola", "Raghav Mani", "Pankaj Vats", "Jesse Tetreault", "T. J. Chen", "Cory Y. McLean"], "title": "Integrating Genomics into Multimodal EHR Foundation Models", "comment": null, "summary": "This paper introduces an innovative Electronic Health Record (EHR) foundation\nmodel that integrates Polygenic Risk Scores (PRS) as a foundational data\nmodality, moving beyond traditional EHR-only approaches to build more holistic\nhealth profiles. Leveraging the extensive and diverse data from the All of Us\n(AoU) Research Program, this multimodal framework aims to learn complex\nrelationships between clinical data and genetic predispositions. The\nmethodology extends advancements in generative AI to the EHR foundation model\nspace, enhancing predictive capabilities and interpretability. Evaluation on\nAoU data demonstrates the model's predictive value for the onset of various\nconditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay\nbetween PRS and EHR data. The work also explores transfer learning for custom\nclassification tasks, showcasing the architecture's versatility and efficiency.\nThis approach is pivotal for unlocking new insights into disease prediction,\nproactive health management, risk stratification, and personalized treatment\nstrategies, laying the groundwork for more personalized, equitable, and\nactionable real-world evidence generation in healthcare.", "AI": {"tldr": "A multimodal EHR foundation model that integrates Polygenic Risk Scores (PRS) with clinical data to improve prediction and interpretation of health outcomes, especially Type 2 Diabetes (T2D), using All of Us data; explores transfer learning and personalized medicine implications.", "motivation": "To move beyond EHR-only models by incorporating genetic predispositions, thereby enhancing predictive accuracy, interpretability, and equitable real-world evidence generation in healthcare.", "method": "Develop a multimodal EHR foundation model that uses PRS as a data modality alongside traditional clinical data; train and evaluate on All of Us data with generative AI techniques to learn complex relationships and improve prediction; investigate transfer learning for task-specific classification.", "result": "The model demonstrates predictive value for the onset of various conditions, notably Type 2 Diabetes, and reveals interactions between PRS and EHR data; transfer learning shows versatility and efficiency for custom tasks.", "conclusion": "The work lays groundwork for personalized, proactive health management, risk stratification, and equitable real-world evidence generation, advancing toward more personalized healthcare across diverse populations."}}
{"id": "2510.24034", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24034", "abs": "https://arxiv.org/abs/2510.24034", "authors": ["Yufan Liu", "Wanqian Zhang", "Huashan Chen", "Lin Wang", "Xiaojun Jia", "Zheng Lin", "Weiping Wang"], "title": "AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts", "comment": "Accepted by ICCV 2025", "summary": "Despite rapid advancements in text-to-image (T2I) models, their safety\nmechanisms are vulnerable to adversarial prompts, which maliciously generate\nunsafe images. Current red-teaming methods for proactively assessing such\nvulnerabilities usually require white-box access to T2I models, and rely on\ninefficient per-prompt optimization, as well as inevitably generate\nsemantically meaningless prompts easily blocked by filters. In this paper, we\npropose APT (AutoPrompT), a black-box framework that leverages large language\nmodels (LLMs) to automatically generate human-readable adversarial suffixes for\nbenign prompts. We first introduce an alternating optimization-finetuning\npipeline between adversarial suffix optimization and fine-tuning the LLM\nutilizing the optimized suffix. Furthermore, we integrates a dual-evasion\nstrategy in optimization phase, enabling the bypass of both perplexity-based\nfilter and blacklist word filter: (1) we constrain the LLM generating\nhuman-readable prompts through an auxiliary LLM perplexity scoring, which\nstarkly contrasts with prior token-level gibberish, and (2) we also introduce\nbanned-token penalties to suppress the explicit generation of banned-tokens in\nblacklist. Extensive experiments demonstrate the excellent red-teaming\nperformance of our human-readable, filter-resistant adversarial prompts, as\nwell as superior zero-shot transferability which enables instant adaptation to\nunseen prompts and exposes critical vulnerabilities even in commercial APIs\n(e.g., Leonardo.Ai.).", "AI": {"tldr": "Introduces APT, a black-box red-teaming framework that uses LLMs to craft human-readable adversarial suffixes for benign prompts, bypassing safety filters through dual-evasion (perplexity-based constraint and banned-token penalties) and alternating optimization/LLM fine-tuning; shows strong red-teaming performance and cross-model transferability, including to commercial APIs.", "motivation": "Current safety testing of text-to-image models relies on white-box access or prompts that are semantically meaningless and easily blocked by filters. There is a need for scalable, black-box red-teaming that yields human-readable adversarial prompts and transfers across models.", "method": "An alternating optimization-finetuning pipeline between adversarial suffix optimization and fine-tuning the LLM with the optimized suffix. A dual-evasion strategy: (1) constrain the LLM via an auxiliary perplexity scoring to keep prompts human-readable (avoiding gibberish); (2) apply banned-token penalties to suppress explicit generation of blacklist terms. Operates in a black-box setting and evaluates transferability across unseen prompts and models.", "result": "Experiments show that the proposed prompts are highly effective at red-teaming, remain human-readable and resistant to filters, and transfer zero-shot to unseen prompts and models, exposing vulnerabilities even in commercial APIs (e.g., Leonardo.Ai).", "conclusion": "APT provides a practical black-box red-teaming framework for T2I safety evaluation using LLM-generated adversarial suffixes. It highlights the security risks of current API ecosystems and suggests directions for more robust defenses and improved filtering."}}
{"id": "2510.24118", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24118", "abs": "https://arxiv.org/abs/2510.24118", "authors": ["Haotian Zhou", "Xiaole Wang", "He Li", "Fusheng Sun", "Shengyu Guo", "Guolei Qi", "Jianghuan Xu", "Huijing Zhao"], "title": "LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation", "comment": null, "summary": "Navigating to a designated goal using visual information is a fundamental\ncapability for intelligent robots. Most classical visual navigation methods are\nrestricted to single-goal, single-modality, and closed set goal settings. To\naddress the practical demands of multi-modal, open-vocabulary goal queries and\nmulti-goal visual navigation, we propose LagMemo, a navigation system that\nleverages a language 3D Gaussian Splatting memory. During exploration, LagMemo\nconstructs a unified 3D language memory. With incoming task goals, the system\nqueries the memory, predicts candidate goal locations, and integrates a local\nperception-based verification mechanism to dynamically match and validate goals\nduring navigation. For fair and rigorous evaluation, we curate GOAT-Core, a\nhigh-quality core split distilled from GOAT-Bench tailored to multi-modal\nopen-vocabulary multi-goal visual navigation. Experimental results show that\nLagMemo's memory module enables effective multi-modal open-vocabulary goal\nlocalization, and that LagMemo outperforms state-of-the-art methods in\nmulti-goal visual navigation. Project page:\nhttps://weekgoodday.github.io/lagmemo", "AI": {"tldr": "LagMemo introduces a 3D language memory built on language-augmented Gaussian splatting to support open-vocabulary, multi-goal visual navigation, coupled with a curated GOAT-Core evaluation suite.", "motivation": "Classical visual navigation is limited to single-goal, single-modality, and closed-set queries. Real-world robotic tasks require multi-modal (text, images), open vocabulary, and multi-goal navigation; a unified memory facilitates flexible goal querying during navigation.", "method": "During exploration LagMemo constructs a unified 3D memory using language-guided 3D Gaussian splatting. Upon receiving task goals, it queries the memory to predict candidate goal locations and applies a local perception-based verification to confirm goals during navigation. The authors also create GOAT-Core, a multi-modal, open-vocabulary, multi-goal core-split distilled from GOAT-Bench to enable fair evaluation.", "result": "Experiments show that the memory module enables effective multi-modal open-vocabulary goal localization and LagMemo outperforms state-of-the-art methods in multi-goal visual navigation.", "conclusion": "A memory-augmented navigation approach with open-vocabulary language grounding substantially improves multi-goal navigation performance and provides a new benchmarking resource for rigorous evaluation."}}
{"id": "2510.23989", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23989", "abs": "https://arxiv.org/abs/2510.23989", "authors": ["Shangde Gao", "Zelin Xu", "Zhe Jiang"], "title": "Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance", "comment": null, "summary": "Shifts in individual movement patterns following disruptive events can reveal\nchanging demands for community resources. However, predicting such shifts\nbefore disruptive events remains challenging for several reasons. First,\nmeasures are lacking for individuals' heterogeneous social infrastructure\nresilience (SIR), which directly influences their movement patterns, and\ncommonly used features are often limited or unavailable at scale, e.g.,\nsociodemographic characteristics. Second, the complex interactions between\nindividual movement patterns and spatial contexts have not been sufficiently\ncaptured. Third, individual-level movement may be spatially sparse and not\nwell-suited to traditional decision-making methods for movement predictions.\nThis study incorporates individuals' SIR into a conditioned deep learning model\nto capture the complex relationships between individual movement patterns and\nlocal spatial context using large-scale, sparse individual-level data. Our\nexperiments demonstrate that incorporating individuals' SIR and spatial context\ncan enhance the model's ability to predict post-event individual movement\npatterns. The conditioned model can capture the divergent shifts in movement\npatterns among individuals who exhibit similar pre-event patterns but differ in\nSIR.", "AI": {"tldr": "A conditioned deep learning model incorporating individuals' social infrastructure resilience (SIR) and local spatial context to predict post-disruption movement patterns from sparse, large-scale data.", "motivation": "Shifts in individual movement after disruptive events reveal resource demands, but predicting these shifts is hard due to lack of measures for heterogeneous SIR, limited features, complex movement\u2013space interactions, and sparse data at the individual level.", "method": "Develop a conditioned deep learning model that inputs individuals' SIR and local spatial context to capture nonlinear relationships between pre- and post-event movement patterns in large-scale, sparse datasets.", "result": "Experiments indicate that incorporating SIR and spatial context improves post-event movement prediction and enables the model to capture divergent shifts among individuals with similar pre-event patterns but differing SIR.", "conclusion": "Integrating heterogeneous SIR with spatial context in a conditioned model enhances predictive performance and understanding of mobility responses to disruptive events."}}
{"id": "2510.23640", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23640", "abs": "https://arxiv.org/abs/2510.23640", "authors": ["Zihao Jing", "Yan Sun", "Yan Yi Li", "Sugitha Janarthanan", "Alana Deng", "Pingzhao Hu"], "title": "Structure-Aware Fusion with Progressive Injection for Multimodal Molecular Representation Learning", "comment": "Accepted by NeurIPS 2025", "summary": "Multimodal molecular models often suffer from 3D conformer unreliability and\nmodality collapse, limiting their robustness and generalization. We propose\nMuMo, a structured multimodal fusion framework that addresses these challenges\nin molecular representation through two key strategies. To reduce the\ninstability of conformer-dependent fusion, we design a Structured Fusion\nPipeline (SFP) that combines 2D topology and 3D geometry into a unified and\nstable structural prior. To mitigate modality collapse caused by naive fusion,\nwe introduce a Progressive Injection (PI) mechanism that asymmetrically\nintegrates this prior into the sequence stream, preserving modality-specific\nmodeling while enabling cross-modal enrichment. Built on a state space\nbackbone, MuMo supports long-range dependency modeling and robust information\npropagation. Across 29 benchmark tasks from Therapeutics Data Commons (TDC) and\nMoleculeNet, MuMo achieves an average improvement of 2.7% over the\nbest-performing baseline on each task, ranking first on 22 of them, including a\n27% improvement on the LD50 task. These results validate its robustness to 3D\nconformer noise and the effectiveness of multimodal fusion in molecular\nrepresentation. The code is available at: github.com/selmiss/MuMo.", "AI": {"tldr": "MuMo is a structured multimodal fusion framework for molecular representation that tackles 3D conformer unreliability and modality collapse via a Structured Fusion Pipeline and Progressive Injection, achieving state-of-the-art performance across 29 benchmarks.", "motivation": "Multimodal molecular models suffer from unstable conformation-dependent fusion and modality collapse, limiting robustness and generalization; a stable, integrated prior and asymmetric fusion strategy can improve performance.", "method": "1) Structured Fusion Pipeline (SFP) combines 2D topology and 3D geometry into a unified structural prior; 2) Progressive Injection (PI) asymmetrically injects this prior into the sequence stream to preserve modality-specific modeling while enabling cross-modal enrichment; 3) implemented on a state-space backbone for long-range dependencies.", "result": "On 29 benchmark tasks from Therapeutics Data Commons (TDC) and MoleculeNet, MuMo improves by 2.7% on average over the best baseline, ranks first on 22 tasks, including a 27% gain on the LD50 task; demonstrates robustness to 3D conformer noise; code released at github.com/selmiss/MuMo.", "conclusion": "MuMo effectively mitigates 3D conformer unreliability and modality collapse, yielding robust multimodal molecular representations and state-of-the-art results on diverse benchmarks."}}
{"id": "2510.24036", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24036", "abs": "https://arxiv.org/abs/2510.24036", "authors": ["Xingyu Liu", "Kun Ming Goh"], "title": "ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning", "comment": "3 pages, 5 figures, 1 table", "summary": "Convolutional Neural Networks (CNNs) has revolutionized computer vision, but\ntraining very deep networks has been challenging due to the vanishing gradient\nproblem. This paper explores Residual Networks (ResNet), introduced by He et\nal. (2015), which overcomes this limitation by using skip connections. ResNet\nenables the training of networks with hundreds of layers by allowing gradients\nto flow directly through shortcut connections that bypass intermediate layers.\nIn our implementation on the CIFAR-10 dataset, ResNet-18 achieves 89.9%\naccuracy compared to 84.1% for a traditional deep CNN of similar depth, while\nalso converging faster and training more stably.", "AI": {"tldr": "Residual Networks enable training of very deep CNNs by using skip connections, achieving higher accuracy and faster, more stable training on CIFAR-10 (ResNet-18 at 89.9% vs 84.1% for a comparable-depth baseline).", "motivation": "Address the vanishing/exploding gradient problem that makes training very deep CNNs difficult, aiming to train networks with hundreds of layers.", "method": "Introduce residual blocks with identity-based skip connections (ResNet); implement ResNet-18 and evaluate on CIFAR-10, comparing against a traditional deep CNN of similar depth.", "result": "On CIFAR-10, ResNet-18 achieves 89.9% accuracy, outperforming a traditional deep CNN of similar depth which achieves 84.1%; training converges faster and more stably.", "conclusion": "Skip connections enable training of substantially deeper networks and yield better performance and training dynamics on standard vision benchmarks."}}
{"id": "2510.24194", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24194", "abs": "https://arxiv.org/abs/2510.24194", "authors": ["Ev Zisselman", "Mirco Mutti", "Shelly Francis-Meretzki", "Elisei Shafer", "Aviv Tamar"], "title": "Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames", "comment": null, "summary": "Behavioral cloning is a simple yet effective technique for learning\nsequential decision-making from demonstrations. Recently, it has gained\nprominence as the core of foundation models for the physical world, where\nachieving generalization requires countless demonstrations of a multitude of\ntasks. Typically, a human expert with full information on the task demonstrates\na (nearly) optimal behavior. In this paper, we propose to hide some of the\ntask's information from the demonstrator. This ``blindfolded'' expert is\ncompelled to employ non-trivial exploration to solve the task. We show that\ncloning the blindfolded expert generalizes better to unseen tasks than its\nfully-informed counterpart. We conduct experiments of real-world robot peg\ninsertion tasks with (limited) human demonstrations, alongside videogames from\nthe Procgen benchmark. Additionally, we support our findings with theoretical\nanalysis, which confirms that the generalization error scales with\n$\\sqrt{I/m}$, where $I$ measures the amount of task information available to\nthe demonstrator, and $m$ is the number of demonstrated tasks. Both theory and\npractice indicate that cloning blindfolded experts generalizes better with\nfewer demonstrated tasks. Project page with videos and code:\nhttps://sites.google.com/view/blindfoldedexperts/home", "AI": {"tldr": "Cloning a blindfolded (information-limited) expert improves generalization in imitation learning with few demonstrations, supported by theory (generalization error ~ sqrt(I/m)) and experiments on robot peg-insertion and Procgen games.", "motivation": "Imitation learning often requires many demonstrations to generalize to unseen tasks. Fully informed, expert demonstrations can overfit to task specifics. The paper proposes hiding information from the demonstrator to induce exploration and improve data efficiency and generalization.", "method": "Introduce a 'blindfolded' expert who has limited task information. The expert must explore non-trivially to solve tasks. Train a behavioral cloning model to imitate this expert. Provide theoretical analysis showing generalization error scales as sqrt(I/m). Validate with experiments on real robotics (peg-insertion with limited human demonstrations) and Procgen video games.", "result": "Cloning blindfolded experts generalizes better to unseen tasks than cloning fully-informed experts, especially with fewer demonstrated tasks. Empirical results on real-world robot tasks and Procgen benchmarks align with the theoretical bound.", "conclusion": "Hiding task information from demonstrators acts as a regularizer that improves data-efficient generalization in imitation learning. Theoretical and empirical results support that generalization error scales with sqrt(I/m), advocating for information-constrained demonstrations in practice."}}
{"id": "2510.24013", "categories": ["cs.AI", "cs.LG", "cs.NE", "math.CO", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.24013", "abs": "https://arxiv.org/abs/2510.24013", "authors": ["\u0130brahim O\u011fuz \u00c7etinkaya", "\u0130. Esra B\u00fcy\u00fcktahtak\u0131n", "Parshin Shojaee", "Chandan K. Reddy"], "title": "Discovering Heuristics with Large Language Models (LLMs) for Mixed-Integer Programs: Single-Machine Scheduling", "comment": null, "summary": "Our study contributes to the scheduling and combinatorial optimization\nliterature with new heuristics discovered by leveraging the power of Large\nLanguage Models (LLMs). We focus on the single-machine total tardiness (SMTT)\nproblem, which aims to minimize total tardiness by sequencing n jobs on a\nsingle processor without preemption, given processing times and due dates. We\ndevelop and benchmark two novel LLM-discovered heuristics, the EDD Challenger\n(EDDC) and MDD Challenger (MDDC), inspired by the well-known Earliest Due Date\n(EDD) and Modified Due Date (MDD) rules. In contrast to prior studies that\nemployed simpler rule-based heuristics, we evaluate our LLM-discovered\nalgorithms using rigorous criteria, including optimality gaps and solution time\nderived from a mixed-integer programming (MIP) formulation of SMTT. We compare\ntheir performance against state-of-the-art heuristics and exact methods across\nvarious job sizes (20, 100, 200, and 500 jobs). For instances with more than\n100 jobs, exact methods such as MIP and dynamic programming become\ncomputationally intractable. Up to 500 jobs, EDDC improves upon the classic EDD\nrule and another widely used algorithm in the literature. MDDC consistently\noutperforms traditional heuristics and remains competitive with exact\napproaches, particularly on larger and more complex instances. This study shows\nthat human-LLM collaboration can produce scalable, high-performing heuristics\nfor NP-hard constrained combinatorial optimization, even under limited\nresources when effectively configured.", "AI": {"tldr": "LLM-discovered SMTT heuristics (EDD Challenger and MDD Challenger) outperform classical rules and rival exact methods on large instances, demonstrating effective human\u2013LLM collaboration for NP-hard scheduling.", "motivation": "Address the NP-hard single-machine total tardiness problem by exploring whether LLM-driven rule discovery can yield scalable, high-quality heuristics beyond simple heuristics.", "method": "Develop two LLM-discovered heuristics, EDDC and MDDC, inspired by EDD and MDD. Evaluate against state-of-the-art heuristics and exact methods via MIP/DP across job sizes 20, 100, 200, 500, using optimality gaps and runtimes.", "result": "EDD C improves upon EDD; MDD C outperforms traditional heuristics and remains competitive with exact methods on larger instances; exact methods become intractable beyond ~100 jobs. Performance measured by optimality gaps and solution times.", "conclusion": "Human\u2013LLM collaboration can yield scalable, high-performing heuristics for NP-hard constrained optimization under resource constraints."}}
{"id": "2510.23641", "categories": ["cs.LG", "cs.AI", "hep-ex", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2510.23641", "abs": "https://arxiv.org/abs/2510.23641", "authors": ["Aaron Wang", "Zihan Zhao", "Subash Katel", "Vivekanand Gyanchand Sahu", "Elham E Khoda", "Abhijith Gandrakota", "Jennifer Ngadiuba", "Richard Cavanaugh", "Javier Duarte"], "title": "Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging", "comment": null, "summary": "Transformers are very effective in capturing both global and local\ncorrelations within high-energy particle collisions, but they present\ndeployment challenges in high-data-throughput environments, such as the CERN\nLHC. The quadratic complexity of transformer models demands substantial\nresources and increases latency during inference. In order to address these\nissues, we introduce the Spatially Aware Linear Transformer (SAL-T), a\nphysics-inspired enhancement of the linformer architecture that maintains\nlinear attention. Our method incorporates spatially aware partitioning of\nparticles based on kinematic features, thereby computing attention between\nregions of physical significance. Additionally, we employ convolutional layers\nto capture local correlations, informed by insights from jet physics. In\naddition to outperforming the standard linformer in jet classification tasks,\nSAL-T also achieves classification results comparable to full-attention\ntransformers, while using considerably fewer resources with lower latency\nduring inference. Experiments on a generic point cloud classification dataset\n(ModelNet10) further confirm this trend. Our code is available at\nhttps://github.com/aaronw5/SAL-T4HEP.", "AI": {"tldr": "SAL-T is a linear-attention transformer variant for high-energy physics that uses physics-informed spatial partitioning and local convolutions to maintain linear complexity while achieving competitive accuracy with full-attention models.", "motivation": "To address the quadratic complexity of transformers in high-throughput environments like the CERN LHC, enabling faster inference without sacrificing performance.", "method": "Introduce Spatially Aware Linear Transformer (SAL-T): partition particles spatially based on kinematic features to compute attention between physically significant regions; incorporate convolutional layers to capture local correlations informed by jet physics; build on the linformer architecture to maintain linear attention; validate on jet classification and ModelNet10; release code at the provided URL.", "result": "SAL-T outperforms standard linformer in jet classification and achieves accuracy comparable to full-attention transformers, while using markedly fewer resources and exhibiting lower inference latency. Experiments on ModelNet10 further corroborate the linear-attention trend.", "conclusion": "SAL-T demonstrates a practical, resource-efficient transformer design for high-energy physics and 3D data, combining physics-informed partitioning with local convolutions to maintain performance with linear complexity; supports deployment in high-throughput experiments and provides a usable codebase."}}
{"id": "2510.24037", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24037", "abs": "https://arxiv.org/abs/2510.24037", "authors": ["Shufan Shen", "Junshu Sun", "Shuhui Wang", "Qingming Huang"], "title": "Kernelized Sparse Fine-Tuning with Bi-level Parameter Competition for Vision Models", "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) aims to adapt pre-trained vision\nmodels to downstream tasks. Among PEFT paradigms, sparse tuning achieves\nremarkable performance by adjusting only the weights most relevant to\ndownstream tasks, rather than densely tuning the entire weight matrix. Current\nmethods follow a two-stage paradigm. First, it locates task-relevant weights by\ngradient information, which overlooks the parameter adjustments during\nfine-tuning and limits the performance. Second, it updates only the located\nweights by applying a sparse mask to the gradient of the weight matrix, which\nresults in high memory usage due to the storage of all weight matrices in the\noptimizer. In this paper, we propose a one-stage method named SNELLA to\novercome the above limitations. For memory usage, SNELLA selectively updates\nthe weight matrix by adding it to another sparse matrix that is merged by two\nlow-rank learnable matrices. We extend the low-rank decomposition by\nintroducing nonlinear kernel functions, thereby increasing the rank of the\nresulting merged matrix to prevent the interdependency among weight updates,\nenabling better adaptation to downstream tasks. For locating task-relevant\nweights, we propose an adaptive bi-level sparsity allocation mechanism that\nencourages weights to compete across and inside layers based on their\nimportance scores in an end-to-end manner. Extensive experiments are conducted\non classification, segmentation, and generation tasks using different\npre-trained vision models. The results show that SNELLA achieves SOTA\nperformance with low memory usage. Notably, SNELLA obtains 1.8% (91.9% v.s.\n90.1%) higher Top-1 accuracy on the FGVC benchmark compared to SPT-LoRA.\nCompared to previous methods, SNELLA achieves a memory reduction of 31.1%-39.9%\nacross models with parameter scales from 86M to 632M. Our source codes are\navailable at https://github.com/ssfgunner/SNELL.", "AI": {"tldr": "SNELLA is a one-stage, memory-efficient sparse fine-tuning method for vision models that merges weight updates into a sparse matrix via low-rank learnable components and nonlinear kernels, with adaptive bi-level sparsity to locate task-relevant weights; achieves state-of-the-art results with substantial memory savings.", "motivation": "Two-stage sparse tuning methods overlook parameter updates during fine-tuning and incur high memory usage due to storing full-precision optimizer state and weight matrices. There is a need for an end-to-end, memory-efficient one-stage approach that accounts for parameter updates and efficiently locates task-relevant weights.", "method": "1) Memory-efficient update: merge the target weight matrix with another sparse matrix formed by two low-rank learnable matrices, extended by nonlinear kernel functions to increase rank and reduce interdependency among updates. 2) Adaptive bi-level sparsity allocation: end-to-end mechanism that allows weights to compete across and within layers based on importance scores to locate task-relevant weights.", "result": "Extensive experiments across classification, segmentation, and generation on various pre-trained vision models show SNELLA achieves state-of-the-art performance with lower memory usage. It achieves a 1.8% absolute Top-1 accuracy gain on FGVC benchmark compared to SPT-LoRA (91.9% vs 90.1%). Relative to prior methods, SNELLA reduces memory by 31.1%-39.9% across models ranging from 86M to 632M parameters.", "conclusion": "SNELLA provides a competitive, memory-efficient one-stage alternative to existing PEFT methods, delivering higher accuracy with significantly reduced memory. Source code is available at the provided GitHub URL."}}
{"id": "2510.24257", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24257", "abs": "https://arxiv.org/abs/2510.24257", "authors": ["Ziqi Ma", "Changda Tian", "Yue Gao"], "title": "Manipulate as Human: Learning Task-oriented Manipulation Skills by Adversarial Motion Priors", "comment": null, "summary": "In recent years, there has been growing interest in developing robots and\nautonomous systems that can interact with human in a more natural and intuitive\nway. One of the key challenges in achieving this goal is to enable these\nsystems to manipulate objects and tools in a manner that is similar to that of\nhumans. In this paper, we propose a novel approach for learning human-style\nmanipulation skills by using adversarial motion priors, which we name HMAMP.\nThe approach leverages adversarial networks to model the complex dynamics of\ntool and object manipulation, as well as the aim of the manipulation task. The\ndiscriminator is trained using a combination of real-world data and simulation\ndata executed by the agent, which is designed to train a policy that generates\nrealistic motion trajectories that match the statistical properties of human\nmotion. We evaluated HMAMP on one challenging manipulation task: hammering, and\nthe results indicate that HMAMP is capable of learning human-style manipulation\nskills that outperform current baseline methods. Additionally, we demonstrate\nthat HMAMP has potential for real-world applications by performing real robot\narm hammering tasks. In general, HMAMP represents a significant step towards\ndeveloping robots and autonomous systems that can interact with humans in a\nmore natural and intuitive way, by learning to manipulate tools and objects in\na manner similar to how humans do.", "AI": {"tldr": "A framework (HMAMP) learns human-style manipulation using adversarial motion priors; it uses a discriminator trained on real-world and simulated agent data to shape a policy that generates realistic, human-like motion, demonstrated on hammering with outperformance of baselines and feasibility for real-robot use.", "motivation": "To enable more natural and intuitive human\u2013robot interaction by allowing robots to manipulate tools and objects in human-like ways, addressing the challenge of capturing complex human motion dynamics and tool/object manipulation. Adversarial priors are proposed to capture statistical properties of human motion.", "method": "An adversarial learning setup where a discriminator is trained on a mix of real human motion data and robot-simulated trajectories to encourage a policy to produce human-like trajectories. The policy learns to generate motion that matches the statistical properties of human manipulation, demonstrated on a hammering task, with real-robot hammering demonstrations.", "result": "The HMAMP approach learns human-style manipulation skills and outperforms current baselines on the hammering task, and shows potential for real-world robot arm hammering demonstrations.", "conclusion": "HMAMP offers a meaningful step toward more natural human\u2013robot interaction by enabling human-like manipulation of tools and objects. The work demonstrates practical potential, though future work may address broader task generalization and data efficiency for real-world deployment."}}
{"id": "2510.24028", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24028", "abs": "https://arxiv.org/abs/2510.24028", "authors": ["Tingyue Pan", "Mingyue Cheng", "Shilong Zhang", "Zhiding Liu", "Xiaoyu Tao", "Yucong Luo", "Jintao Zhang", "Qi Liu"], "title": "OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting", "comment": null, "summary": "Cross-domain time series forecasting is a valuable task in various web\napplications. Despite its rapid advancement, achieving effective generalization\nacross heterogeneous time series data remains a significant challenge. Existing\nmethods have made progress by extending single-domain models, yet often fall\nshort when facing domain-specific trend shifts and inconsistent periodic\npatterns. We argue that a key limitation lies in treating temporal series as\nundifferentiated sequence, without explicitly decoupling their inherent\nstructural components. To address this, we propose OneCast, a structured and\nmodular forecasting framework that decomposes time series into seasonal and\ntrend components, each modeled through tailored generative pathways.\nSpecifically, the seasonal component is captured by a lightweight projection\nmodule that reconstructs periodic patterns via interpretable basis functions.\nIn parallel, the trend component is encoded into discrete tokens at segment\nlevel via a semantic-aware tokenizer, and subsequently inferred through a\nmasked discrete diffusion mechanism. The outputs from both branches are\ncombined to produce a final forecast that captures seasonal patterns while\ntracking domain-specific trends. Extensive experiments across eight domains\ndemonstrate that OneCast mostly outperforms state-of-the-art baselines.", "AI": {"tldr": "OneCast is a modular cross-domain time-series forecasting framework that decouples seasonal and trend components using interpretable basis functions and a discrete-token diffusion model, delivering strong cross-domain performance across eight domains.", "motivation": "Cross-domain forecasting across heterogeneous time series suffers from domain-specific trend shifts and inconsistent periodic patterns. Treating series as a single undifferentiated sequence fails to capture structural components, hindering generalization.", "method": "Decompose time series into two branches: (1) seasonal component via a lightweight projection module that reconstructs periodic patterns using interpretable basis functions; (2) trend component via a semantic-aware tokenizer that encodes segment-level discrete tokens, inferred with a masked discrete diffusion mechanism. The two outputs are fused for the final forecast.", "result": "Empirical evaluation across eight domains shows OneCast mostly outperforms state-of-the-art baselines.", "conclusion": "A structurally decomposed, modular approach that explicitly models seasonal and trend components improves cross-domain forecasting performance and generalization."}}
{"id": "2510.23649", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23649", "abs": "https://arxiv.org/abs/2510.23649", "authors": ["Tenghui Li", "Guoxu Zhou", "Xuyang Zhao", "Yuning Qiu", "Qibin Zhao"], "title": "Efficient Low Rank Attention for Long-Context Inference in Large Language Models", "comment": null, "summary": "As the length of input text grows, the key-value (KV) cache in LLMs imposes\nprohibitive GPU memory costs and limits long-context inference on resource\nconstrained devices. Existing approaches, such as KV quantization and pruning,\nreduce memory usage but suffer from numerical precision loss or suboptimal\nretention of key-value pairs. We introduce Low Rank Query and Key attention\n(LRQK), a two-stage framework that jointly decomposes the full-precision query\nand key matrices into compact rank-\\(r\\) factors during the prefill stage, and\nthen uses these low-dimensional projections to compute proxy attention scores\nin \\(\\mathcal{O}(lr)\\) time at each decode step. By selecting only the\ntop-\\(k\\) tokens and a small fixed set of recent tokens, LRQK employs a mixed\nGPU-CPU cache with a hit-and-miss mechanism that transfers only missing\nfull-precision KV pairs, thereby preserving exact attention outputs while\nreducing CPU-GPU data movement. Extensive experiments on the RULER and\nLongBench benchmarks with LLaMA-3-8B and Qwen2.5-7B demonstrate that LRQK\nmatches or surpasses leading sparse-attention methods in long context settings,\nwhile delivering significant memory savings with minimal loss in accuracy. Our\ncode is available at https://github.com/tenghuilee/LRQK.", "AI": {"tldr": "LRQK is a two-stage Long-Context KV cache framework that factorizes query/key matrices into low-rank factors to enable efficient attention computation and selective KV transfers, achieving memory savings with minimal accuracy loss on long-context benchmarks.", "motivation": "Long-context inference in LLMs is constrained by the GPU memory cost of storing and accessing the KV cache. Existing KV compression (quantization/pruning) sacrifices precision or key-value retention, limiting long-context performance.", "method": "During prefill, decompose full-precision query and key matrices into compact rank-r factors. During decoding, compute proxy attention scores in O(l r) using these factors. Use a top-k + small recent token subset with a mixed GPU-CPU cache and a hit/miss policy that transfers only missing full-precision KV pairs, preserving exact attention outputs while reducing data movement.", "result": "Empirical evaluations on RULER and LongBench with LLaMA-3-8B and Qwen2.5-7B show LRQK matches or surpasses leading sparse-attention methods in long-context scenarios, delivering significant memory savings with minimal accuracy loss.", "conclusion": "LRQK provides an effective, memory-efficient long-context attention mechanism by combining low-rank factorization with selective KV transfers; the authors release code for reproducibility."}}
{"id": "2510.24038", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24038", "abs": "https://arxiv.org/abs/2510.24038", "authors": ["Xingyu Zhu", "Beier Zhu", "Shuo Wang", "Kesen Zhao", "Hanwang Zhang"], "title": "Enhancing CLIP Robustness via Cross-Modality Alignment", "comment": "NeurIPS 2025 Spotlight", "summary": "Vision-language models (VLMs) such as CLIP demonstrate strong generalization\nin zero-shot classification but remain highly vulnerable to adversarial\nperturbations. Existing methods primarily focus on adversarial fine-tuning or\nprompt optimization; they often overlook the gaps in CLIP's encoded features,\nwhich is shown as the text and image features lie far apart from each other.\nThis misalignment is significantly amplified under adversarial perturbations,\nleading to severe degradation in classification performance. To address this\nproblem, we propose Cross-modality Alignment, dubbed COLA, an optimal\ntransport-based framework that explicitly addresses adversarial misalignment by\nrestoring both global image-text alignment and local structural consistency in\nthe feature space. (1) COLA first projects adversarial image embeddings onto a\nsubspace spanned by class text features, effectively filtering out non-semantic\ndistortions while preserving discriminative information. (2) It then models\nimages and texts as discrete distributions over multiple augmented views and\nrefines their alignment via OT, with the subspace projection seamlessly\nintegrated into the cost computation. This design ensures stable cross-modal\nalignment even under adversarial conditions. COLA is training-free and\ncompatible with existing fine-tuned models. Extensive evaluations across 14\nzero-shot classification benchmarks demonstrate the effectiveness of COLA,\nespecially with an average improvement of 6.7% on ImageNet and its variants\nunder PGD adversarial attacks, while maintaining high accuracy on clean\nsamples.", "AI": {"tldr": "COLA is a training-free, optimal transport\u2013based cross-modal alignment framework that defends CLIP-style models against adversarial perturbations by projecting image embeddings into a class-text subspace and refining image-text alignment via OT, achieving notable robustness with minimal clean-accuracy loss.", "motivation": "Vision-language models like CLIP generalize well in zero-shot settings but suffer from a misalignment between image and text features that worsens under adversarial perturbations, causing severe performance degradation.", "method": "1) Project adversarial image embeddings onto a subspace spanned by class text features to filter non-semantic distortions while preserving discriminative information. 2) Model images and texts as discrete distributions over multiple augmented views and refine their alignment via optimal transport (OT), with the subspace projection integrated into the OT cost. The approach is training-free and compatible with existing fine-tuned models.", "result": "Extensive evaluations over 14 zero-shot benchmarks show COLA provides an average improvement of 6.7% on ImageNet and variants under PGD adversarial attacks, while maintaining high accuracy on clean samples.", "conclusion": "COLA delivers stable cross-modal alignment under adversarial conditions by combining subspace filtering with OT-based alignment, offering robustness without retraining and be readily plugged into existing models."}}
{"id": "2510.24261", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24261", "abs": "https://arxiv.org/abs/2510.24261", "authors": ["Jingyi Tian", "Le Wang", "Sanping Zhou", "Sen Wang", "Jiayi Li", "Gang Hua"], "title": "DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation", "comment": "Accepted to NeurIPS 2025", "summary": "Learning generalizable robotic manipulation policies remains a key challenge\ndue to the scarcity of diverse real-world training data. While recent\napproaches have attempted to mitigate this through self-supervised\nrepresentation learning, most either rely on 2D vision pretraining paradigms\nsuch as masked image modeling, which primarily focus on static semantics or\nscene geometry, or utilize large-scale video prediction models that emphasize\n2D dynamics, thus failing to jointly learn the geometry, semantics, and\ndynamics required for effective manipulation. In this paper, we present\nDynaRend, a representation learning framework that learns 3D-aware and\ndynamics-informed triplane features via masked reconstruction and future\nprediction using differentiable volumetric rendering. By pretraining on\nmulti-view RGB-D video data, DynaRend jointly captures spatial geometry, future\ndynamics, and task semantics in a unified triplane representation. The learned\nrepresentations can be effectively transferred to downstream robotic\nmanipulation tasks via action value map prediction. We evaluate DynaRend on two\nchallenging benchmarks, RLBench and Colosseum, as well as in real-world robotic\nexperiments, demonstrating substantial improvements in policy success rate,\ngeneralization to environmental perturbations, and real-world applicability\nacross diverse manipulation tasks.", "AI": {"tldr": "DynaRend learns 3D-aware, dynamics-informed triplane representations from multi-view RGB-D video using masked reconstruction and future prediction with differentiable volumetric rendering. These representations are transferred to robotic manipulation tasks via action-value map predictions, improving generalization and real-world applicability.", "motivation": "Scarcity of diverse real-world training data for manipulation; existing methods rely on static 2D pretraining or 2D dynamics models that miss joint geometry, semantics, and dynamics necessary for manipulation.", "method": "Pretrain on multi-view RGB-D video to learn 3D-aware, dynamics-informed triplane features via masked reconstruction and future prediction, using differentiable volumetric rendering. Transfer to downstream tasks through action value map prediction for policy learning.", "result": "Significant improvements in policy success rate, better generalization under environmental perturbations, and demonstrated real-world applicability across diverse manipulation tasks on RLBench, Colosseum, and real-world experiments.", "conclusion": "A unified representation that jointly encodes geometry, semantics, and dynamics enables more effective and generalizable robotic manipulation policies, with strong transfer to downstream tasks."}}
{"id": "2510.24031", "categories": ["cs.AI", "cs.CR", "H.3.3, I.2.7, I.5.3, I.2.5,"], "pdf": "https://arxiv.org/pdf/2510.24031", "abs": "https://arxiv.org/abs/2510.24031", "authors": ["Peng Cai", "Reza Ryan", "Nickson M. Karie"], "title": "LLMLogAnalyzer: A Clustering-Based Log Analysis Chatbot using Large Language Models", "comment": "33 pages, 10 figures", "summary": "System logs are a cornerstone of cybersecurity, supporting proactive breach\nprevention and post-incident investigations. However, analyzing vast amounts of\ndiverse log data remains significantly challenging, as high costs, lack of\nin-house expertise, and time constraints make even basic analysis difficult for\nmany organizations. This study introduces LLMLogAnalyzer, a clustering-based\nlog analysis chatbot that leverages Large Language Models (LLMs) and Machine\nLearning (ML) algorithms to simplify and streamline log analysis processes.\nThis innovative approach addresses key LLM limitations, including context\nwindow constraints and poor structured text handling capabilities, enabling\nmore effective summarization, pattern extraction, and anomaly detection tasks.\nLLMLogAnalyzer is evaluated across four distinct domain logs and various tasks.\nResults demonstrate significant performance improvements over state-of-the-art\nLLM-based chatbots, including ChatGPT, ChatPDF, and NotebookLM, with consistent\ngains ranging from 39% to 68% across different tasks. The system also exhibits\nstrong robustness, achieving a 93% reduction in interquartile range (IQR) when\nusing ROUGE-1 scores, indicating significantly lower result variability. The\nframework's effectiveness stems from its modular architecture comprising a\nrouter, log recognizer, log parser, and search tools. This design enhances LLM\ncapabilities for structured text analysis while improving accuracy and\nrobustness, making it a valuable resource for both cybersecurity experts and\nnon-technical users.", "AI": {"tldr": "A modular, clustering-based log-analysis chatbot (LMMLogAnalyzer) boosts log analysis by combining LLMs with ML to overcome context and structured-text limitations, achieving large gains over baselines and strong robustness across multi-domain logs.", "motivation": "Analyzing diverse, voluminous security logs is costly and requires specialized expertise. LLMs struggle with context windows and structured text; there is a need for a reliable, user-friendly tool to streamline summarization, pattern extraction, and anomaly detection in logs.", "method": "A modular architecture with components: router, log recognizer, log parser, and search tools. Uses clustering-based log analysis in conjunction with LLMs/ML to improve structured-text understanding and robustness. Evaluated on four domain logs across multiple tasks, comparing against state-of-the-art LLM chatbots (ChatGPT, ChatPDF, NotebookLM).", "result": "Reported 39\u201368% performance gains over baselines across tasks; 93% reduction in IQR for ROUGE-1 scores, indicating lower variability. Demonstrates improved summarization, pattern extraction, and anomaly detection.", "conclusion": "The framework enhances LLM capabilities for structured log analysis, improving accuracy and robustness, and is valuable for cybersecurity professionals and non-technical users alike."}}
{"id": "2510.23650", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23650", "abs": "https://arxiv.org/abs/2510.23650", "authors": ["Wei Xia"], "title": "Beyond Hidden-Layer Manipulation: Semantically-Aware Logit Interventions for Debiasing LLMs", "comment": null, "summary": "We proposed Static and Dynamic -- two zero-shot logits-layer debiasing\nmethods. Dynamic reduces bias by up to 70% with minimal fluency loss. Logits\nintervention outperforms hidden-layer approaches. We show semantic-aware logits\nintervention is stable and effective for debiasing aligned LLMs.", "AI": {"tldr": "Proposes static and dynamic zero-shot logits-layer debiasing; dynamic reduces bias up to 70% with minimal fluency loss; logits intervention outperforms hidden-layer approaches; semantic-aware logits intervention is stable and effective for debiasing aligned LLMs.", "motivation": "Tackle bias in language models without retraining by intervening at the logits layer; compare zero-shot logits-based methods to hidden-layer debiasing.", "method": "Introduce two zero-shot logits-layer debiasing strategies (static and dynamic) and a semantic-aware logits intervention; assess performance against hidden-layer approaches on aligned LLMs.", "result": "Dynamic method achieves up to ~70% bias reduction with minimal fluency loss; logits intervention outperforms hidden-layer debiasing; semantic-aware logits intervention is stable and effective for debiasing aligned LLMs.", "conclusion": "Logits-intervention-based debiasing is a robust and effective approach for aligned LLMs, with static/dynamic variants offering strong bias mitigation and favorable fluency trade-offs; semantic-aware logits intervention shows particular promise."}}
{"id": "2510.24078", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24078", "abs": "https://arxiv.org/abs/2510.24078", "authors": ["William Yang", "Xindi Wu", "Zhiwei Deng", "Esin Tureci", "Olga Russakovsky"], "title": "Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained Classification", "comment": null, "summary": "Text-to-image (T2I) models are increasingly used for synthetic dataset\ngeneration, but generating effective synthetic training data for classification\nremains challenging. Fine-tuning a T2I model with a few real examples can help\nimprove the quality of synthetic training data; however, it may also cause\noverfitting and reduce diversity in the generated samples. We propose a\nfine-tuning strategy BOB (BeyondOBjects) to mitigate these concerns for\nfine-grained classification. Given a small set of real examples, we first\nextract class-agnostic attributes such as scene background and object pose. We\nthen explicitly condition on these attributes during fine-tuning of the T2I\nmodel and marginalize them out during generation. This design mitigates\noverfitting, preserves the T2I model's generative prior, reduces estimation\nerrors, and further minimizes unintended inter-class associations. Extensive\nexperiments across multiple T2I models, backbones, and datasets show that our\nmethod achieves state-of-the-art performance in low-shot fine-grained\nclassification when augmented with synthetic data. Concretely, BOB outperforms\nDataDream by 7.4% on the Aircraft dataset (from 50.0% to 57.4% when fine-tuning\na CLIP classifier with five real images augmented with 100 synthetic images).\nIn three of the four benchmarks, fine-tuning downstream models with 5 real\nimages augmented with BOB achieves better performance than fine-tuning with 10\nreal images. Collectively, BOB outperforms prior art in 18 of 24 experimental\nsettings, with 2+% accuracy improvements in 14 of these settings.", "AI": {"tldr": "A fine-tuning strategy (BOB) for text-to-image models that uses class-agnostic attribute conditioning during fine-tuning and marginalization during generation to improve low-shot fine-grained classification by producing more diverse, less overfit synthetic data.", "motivation": "The challenge of creating effective synthetic training data for fine-grained classification when only a few real examples are available, where naive fine-tuning can cause overfitting and loss of diversity.", "method": "From a small real set, extract class-agnostic attributes (e.g., scene background, object pose). Condition the T2I model on these attributes during fine-tuning, then marginalize them out during image generation to preserve the model's generative priors and reduce spurious inter-class associations. Evaluate across multiple T2I models/backbones/datasets, comparing to prior methods.", "result": "BOB achieves state-of-the-art performance in low-shot fine-grained classification with synthetic data. Notably, on Aircraft, it beats DataDream by 7.4% (57.4% vs 50.0%) using 5 real images plus 100 synthetic images. In 3 of 4 benchmarks, 5 real images with BOB outperform 10 real images without BOB. Across 24 settings, BOB outperforms prior work in 18 settings with many >2% accuracy gains.", "conclusion": "Conditioning on extracted attributes during fine-tuning and marginalizing them during generation improves data efficiency for low-shot FG classification, reduces overfitting and unintended inter-class associations, and yields robust improvements across models, backbones, and datasets."}}
{"id": "2510.24315", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24315", "abs": "https://arxiv.org/abs/2510.24315", "authors": ["Baozhe Zhang", "Xinwei Chen", "Qingcheng Chen", "Chao Xu", "Fei Gao", "Yanjun Cao"], "title": "Global-State-Free Obstacle Avoidance for Quadrotor Control in Air-Ground Cooperation", "comment": null, "summary": "CoNi-MPC provides an efficient framework for UAV control in air-ground\ncooperative tasks by relying exclusively on relative states, eliminating the\nneed for global state estimation. However, its lack of environmental\ninformation poses significant challenges for obstacle avoidance. To address\nthis issue, we propose a novel obstacle avoidance algorithm, Cooperative\nNon-inertial frame-based Obstacle Avoidance (CoNi-OA), designed explicitly for\nUAV-UGV cooperative scenarios without reliance on global state estimation or\nobstacle prediction. CoNi-OA uniquely utilizes a single frame of raw LiDAR data\nfrom the UAV to generate a modulation matrix, which directly adjusts the\nquadrotor's velocity to achieve obstacle avoidance. This modulation-based\nmethod enables real-time generation of collision-free trajectories within the\nUGV's non-inertial frame, significantly reducing computational demands (less\nthan 5 ms per iteration) while maintaining safety in dynamic and unpredictable\nenvironments. The key contributions of this work include: (1) a\nmodulation-based obstacle avoidance algorithm specifically tailored for UAV-UGV\ncooperation in non-inertial frames without global states; (2) rapid, real-time\ntrajectory generation based solely on single-frame LiDAR data, removing the\nneed for obstacle modeling or prediction; and (3) adaptability to both static\nand dynamic environments, thus extending applicability to featureless or\nunknown scenarios.", "AI": {"tldr": "Introduces CoNi-OA, a LiDAR-based, modulation-driven obstacle avoidance method for UAV-UGV cooperation in non-inertial frames that operates without global state estimation or obstacle prediction, enabling real-time, collision-free trajectories.", "motivation": "CoNi-MPC relies on relative states but lacks environmental information, making obstacle avoidance difficult in unknown or featureless settings; a fast, local solution is needed for UAV-UGV teams.", "method": "From a single UAV LiDAR frame, compute a modulation matrix that directly modulates the quadrotor\u2019s velocity in the UGV\u2019s non-inertial frame to avoid obstacles, without building obstacle models or predicting motion; achieves real-time trajectory generation (<5 ms per iteration).", "result": "A modulation-based obstacle avoidance algorithm tailored for UAV-UGV cooperation in non-inertial frames, enabling rapid, real-time trajectory updates using only single-frame LiDAR data and maintaining safety in static/dynamic environments.", "conclusion": "This approach removes dependence on global state estimation and obstacle prediction, enhancing safety and responsiveness for cooperative UAV-UGV tasks, and broadening applicability to unknown or featureless environments."}}
{"id": "2510.24085", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24085", "abs": "https://arxiv.org/abs/2510.24085", "authors": ["Md. Shihab Uddin", "Md Nazmus Shakib", "Rahul Bhadani"], "title": "Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach", "comment": null, "summary": "The increasing adoption of electric vehicles (EVs) necessitates an\nunderstanding of their driving behavior to enhance traffic safety and develop\nsmart driving systems. This study compares classical and machine learning\nmodels for EV car following behavior. Classical models include the Intelligent\nDriver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative\nVelocity (OVRV), and a simplified CACC model, while the machine learning\napproach employs a Random Forest Regressor. Using a real world dataset of an EV\nfollowing an internal combustion engine (ICE) vehicle under varied driving\nconditions, we calibrated classical model parameters by minimizing the RMSE\nbetween predictions and real data. The Random Forest model predicts\nacceleration using spacing, speed, and gap type as inputs. Results demonstrate\nthe Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),\n0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,\nCACC performed best, with an RMSE of 2.67 for long gaps. These findings\nhighlight the machine learning model's performance across all scenarios. Such\nmodels are valuable for simulating EV behavior and analyzing mixed autonomy\ntraffic dynamics in EV integrated environments.", "AI": {"tldr": "A study compares classical car-following models (IDM, OVM, OVRV, simplified CACC) with a Random Forest regressor for EV driving behavior using a real-world EV-ICE following dataset. The ML model achieves markedly lower RMSEs than physics-based models, with RFRMSEs of 0.0046 (medium gap), 0.0016 (long gap), and 0.0025 (extra long gap); among physics models, CACC is the best for long gaps (RMSE 2.67).", "motivation": "To understand EV driving behavior for safety and smart driving system development, and to compare traditional physics-based models with machine learning on EV car-following tasks in mixed-autonomy traffic.", "method": "Calibrate classical model parameters by RMSE minimization against real data. Train a Random Forest Regressor to predict acceleration from spacing, speed, and gap type using a real-world EV-ICE following dataset under varied conditions. Evaluate models by RMSE across gap types (medium, long, extra long).", "result": "Machine learning (Random Forest) achieves higher accuracy than physics-based models across all gap types. RF RMSEs are very low (<0.01) for all gaps, while the best physics model (CACC) yields RMSE 2.67 for long gaps.", "conclusion": "ML-based approaches offer superior predictive accuracy for EV car-following and are valuable for simulating EV behavior and analyzing mixed-autonomy traffic in EV-integrated environments; physics-based models can still provide reasonable baselines, with CACC performing best among them for long gaps."}}
{"id": "2510.23652", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23652", "abs": "https://arxiv.org/abs/2510.23652", "authors": ["Yao Lu", "Yuqi Li", "Wenbin Xie", "Shanqing Yu", "Qi Xuan", "Zhaowei Zhu", "Shiping Wen"], "title": "The Structural Scalpel: Automated Contiguous Layer Pruning for Large Language Models", "comment": null, "summary": "Although large language models (LLMs) have achieved revolutionary\nbreakthroughs in many fields, their large model size and high computational\ncost pose significant challenges for practical deployment on\nresource-constrained edge devices. To this end, layer pruning has been proposed\nto reduce the computational overhead by directly removing redundant layers.\nHowever, existing layer pruning methods typically rely on hand-crafted metrics\nto evaluate and remove individual layers, while ignoring the dependencies\nbetween layers. This can disrupt the model's information flow and severely\ndegrade performance. To address these issues, we propose CLP, a novel\ncontinuous layer pruning framework that introduces two key innovations: a\ndifferentiable concave gate algorithm that automatically identifies the best\ncontinuous layer segments for pruning via gradient-based optimization; and a\ncutoff endpoint tuning strategy that effectively restores model performance by\nfine-tuning only the layers adjacent to the pruned segments. Extensive\nexperiments across multiple model architectures (including LLaMA2, LLaMA3 and\nQwen) and sizes (from $7$B to $70$B parameters) show that CLP significantly\noutperforms existing state-of-the-art baselines. For example, at a pruning rate\nof $20\\%$, CLP achieves an average performance retention of $95.34\\%$ on\nLLaMA3-70B, outperforming baselines by $4.29\\%$-$30.52\\%$. Furthermore, CLP can\nbe seamlessly combined with quantization to further compress the model with\nonly a slight performance loss.", "AI": {"tldr": "CLP introduces a differentiable concave gate and endpoint tuning to prune continuous layer segments in LLMs, preserving performance while reducing compute; achieves high retention (e.g., 95.34% at 20% pruning on LLaMA3-70B) across multiple models (LLaMA2/3, Qwen) and sizes (7B\u201370B); can be combined with quantization.", "motivation": "LLMs demand substantial computational resources; existing layer pruning relies on hand-crafted, per-layer metrics and ignores inter-layer dependencies, risking disrupted information flow and degraded performance. A differentiable, dependency-aware pruning framework is needed to reduce compute while preserving accuracy on edge devices.", "method": "(CLIP) CLP proposes two innovations: (1) a differentiable concave gate that automatically identifies the best continuous layer segments to prune via gradient-based optimization; (2) a cutoff endpoint tuning strategy that fine-tunes only the layers adjacent to pruned segments to restore performance. The framework is evaluated across multiple architectures (LLaMA2, LLaMA3, Qwen) and sizes (7B\u201370B) and can be combined with quantization.", "result": "CLP significantly outperforms state-of-the-art baselines in layer pruning. At 20% pruning, it achieves ~95.34% performance retention on LLaMA3-70B, outperforming baselines by 4.29%\u201330.52%. The method generalizes across architectures and sizes and can be combined with quantization for further compression with minimal additional loss.", "conclusion": "A novel, effective continuous layer pruning framework that respects layer dependencies and maintains high performance while reducing compute. Its differentiable gate and endpoint tuning enable better pruning decisions and quick recovery, with demonstrated gains across diverse models and the option to couple with quantization."}}
{"id": "2510.24093", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24093", "abs": "https://arxiv.org/abs/2510.24093", "authors": ["Agus Gunawan", "Samuel Teodoro", "Yun Chen", "Soo Ye Kim", "Jihyong Oh", "Munchurl Kim"], "title": "OmniText: A Training-Free Generalist for Controllable Text-Image Manipulation", "comment": "The first two authors contributed equally to this work. The last two\n  authors are co-corresponding authors", "summary": "Recent advancements in diffusion-based text synthesis have demonstrated\nsignificant performance in inserting and editing text within images via\ninpainting. However, despite the potential of text inpainting methods, three\nkey limitations hinder their applicability to broader Text Image Manipulation\n(TIM) tasks: (i) the inability to remove text, (ii) the lack of control over\nthe style of rendered text, and (iii) a tendency to generate duplicated\nletters. To address these challenges, we propose OmniText, a training-free\ngeneralist capable of performing a wide range of TIM tasks. Specifically, we\ninvestigate two key properties of cross- and self-attention mechanisms to\nenable text removal and to provide control over both text styles and content.\nOur findings reveal that text removal can be achieved by applying\nself-attention inversion, which mitigates the model's tendency to focus on\nsurrounding text, thus reducing text hallucinations. Additionally, we\nredistribute cross-attention, as increasing the probability of certain text\ntokens reduces text hallucination. For controllable inpainting, we introduce\nnovel loss functions in a latent optimization framework: a cross-attention\ncontent loss to improve text rendering accuracy and a self-attention style loss\nto facilitate style customization. Furthermore, we present OmniText-Bench, a\nbenchmark dataset for evaluating diverse TIM tasks. It includes input images,\ntarget text with masks, and style references, covering diverse applications\nsuch as text removal, rescaling, repositioning, and insertion and editing with\nvarious styles. Our OmniText framework is the first generalist method capable\nof performing diverse TIM tasks. It achieves state-of-the-art performance\nacross multiple tasks and metrics compared to other text inpainting methods and\nis comparable with specialist methods.", "AI": {"tldr": "OmniText is a training-free generalist for diverse Text Image Manipulation (TIM) tasks, solving text removal and style/content control by leveraging self-attention inversion and cross-attention redistribution, with novel latent-losses; introduces OmniText-Bench and achieves state-of-the-art results across TIM tasks.", "motivation": "To overcome persistent limitations of text inpainting for TIM: (i) inability to remove text, (ii) lack of control over rendered text style, and (iii) text hallucination/letter duplication, enabling a single generalist framework for varied TIM tasks.", "method": "Investigate cross- and self-attention mechanics in diffusion-based text inpainting. Use self-attention inversion to suppress surrounding-text focus for text removal. Redistribute cross-attention to bias tokens and reduce hallucinations. Introduce latent optimization with two losses: cross-attention content loss (improves text rendering accuracy) and self-attention style loss (enables style control). Propose OmniText-Bench as a benchmark for diverse TIM tasks.", "result": "OmniText achieves state-of-the-art performance across multiple TIM tasks and metrics compared to existing text-inpainting methods and is competitive with specialist methods.", "conclusion": "A training-free generalist framework capable of broad TIM tasks, delivering controllable text content and style while mitigating text hallucinations, and supported by a dedicated benchmark for evaluation."}}
{"id": "2510.24335", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24335", "abs": "https://arxiv.org/abs/2510.24335", "authors": ["Mingyu Jeong", "Eunsung Kim", "Sehun Park", "Andrew Jaeyong Choi"], "title": "NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation", "comment": "9 pages, 10 figures", "summary": "We present NVSim, a framework that automatically constructs large-scale,\nnavigable indoor simulators from only common image sequences, overcoming the\ncost and scalability limitations of traditional 3D scanning. Our approach\nadapts 3D Gaussian Splatting to address visual artifacts on sparsely observed\nfloors a common issue in robotic traversal data. We introduce Floor-Aware\nGaussian Splatting to ensure a clean, navigable ground plane, and a novel\nmesh-free traversability checking algorithm that constructs a topological graph\nby directly analyzing rendered views. We demonstrate our system's ability to\ngenerate valid, large-scale navigation graphs from real-world data. A video\ndemonstration is avilable at https://youtu.be/tTiIQt6nXC8", "AI": {"tldr": "NVSim automatically builds large-scale navigable indoor simulators from ordinary image sequences using Floor-Aware Gaussian Splatting and a mesh-free traversability check to derive navigation graphs from rendered views.", "motivation": "Traditional 3D scanning is costly and scales poorly; indoor robotics needs scalable, navigable representations from readily available data, addressing artifacts on sparsely observed floors.", "method": "Extend 3D Gaussian Splatting to create clean ground planes (Floor-Aware Gaussian Splatting) and perform mesh-free traversability checking by analyzing rendered views to construct a topological graph.", "result": "Demonstrates generation of valid, large-scale navigation graphs from real-world data; video demonstration available.", "conclusion": "NVSim provides a scalable pipeline to create navigable indoor simulators from image sequences, reducing scanning costs and enabling large-scale VR/robotics applications."}}
{"id": "2510.24115", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24115", "abs": "https://arxiv.org/abs/2510.24115", "authors": ["Sandeep Vissapragada", "Vikrant Sahu", "Gagan Raj Gupta", "Vandita Singh"], "title": "HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology", "comment": null, "summary": "For doctors to truly trust artificial intelligence, it can't be a black box.\nThey need to understand its reasoning, almost as if they were consulting a\ncolleague. We created HistoLens1 to be that transparent, collaborative partner.\nIt allows a pathologist to simply ask a question in plain English about a\ntissue slide--just as they would ask a trainee. Our system intelligently\ntranslates this question into a precise query for its AI engine, which then\nprovides a clear, structured report. But it doesn't stop there. If a doctor\never asks, \"Why?\", HistoLens can instantly provide a 'visual proof' for any\nfinding--a heatmap that points to the exact cells and regions the AI used for\nits analysis. We've also ensured the AI focuses only on the patient's tissue,\njust like a trained pathologist would, by teaching it to ignore distracting\nbackground noise. The result is a workflow where the pathologist remains the\nexpert in charge, using a trustworthy AI assistant to verify their insights and\nmake faster, more confident diagnoses.", "AI": {"tldr": "HistoLens provides a transparent, question-driven AI assistant for histopathology that answers plain-English queries, generates structured reports, and offers visual 'proof' heatmaps to show the AI's reasoning while focusing on the patient's tissue.", "motivation": "Doctors often distrust opaque AI systems; they want to understand the AI's reasoning and have verifiable explanations to consult alongside their expertise, similar to consulting a colleague.", "method": "The system translates plain-English questions into precise AI queries, returns structured reports, and supplies visual proofs (heatmaps) showing the exact cells/regions used. It emphasizes focusing on patient tissue by ignoring background noise, enabling the pathologist to supervise while the AI assists.", "result": "A transparent, collaborative AI workflow in pathology where the pathologist remains in control, can verify insights with heatmap proofs, and achieve faster, more confident diagnoses.", "conclusion": "Transparent, explainable AI in pathology can build trust and efficiency by enabling interactive questioning and visual proof, positioning AI as a trustworthy partner rather than a black box."}}
{"id": "2510.23656", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23656", "abs": "https://arxiv.org/abs/2510.23656", "authors": ["Fuqiang Liu", "Weiping Ding", "Luis Miranda-Moreno", "Lijun Sun"], "title": "Error Adjustment Based on Spatiotemporal Correlation Fusion for Traffic Forecasting", "comment": "12 pages, 7 figures, 3 tables", "summary": "Deep neural networks (DNNs) play a significant role in an increasing body of\nresearch on traffic forecasting due to their effectively capturing\nspatiotemporal patterns embedded in traffic data. A general assumption of\ntraining the said forecasting models via mean squared error estimation is that\nthe errors across time steps and spatial positions are uncorrelated. However,\nthis assumption does not really hold because of the autocorrelation caused by\nboth the temporality and spatiality of traffic data. This gap limits the\nperformance of DNN-based forecasting models and is overlooked by current\nstudies. To fill up this gap, this paper proposes Spatiotemporally\nAutocorrelated Error Adjustment (SAEA), a novel and general framework designed\nto systematically adjust autocorrelated prediction errors in traffic\nforecasting. Unlike existing approaches that assume prediction errors follow a\nrandom Gaussian noise distribution, SAEA models these errors as a\nspatiotemporal vector autoregressive (VAR) process to capture their intrinsic\ndependencies. First, it explicitly captures both spatial and temporal error\ncorrelations by a coefficient matrix, which is then embedded into a newly\nformulated cost function. Second, a structurally sparse regularization is\nintroduced to incorporate prior spatial information, ensuring that the learned\ncoefficient matrix aligns with the inherent road network structure. Finally, an\ninference process with test-time error adjustment is designed to dynamically\nrefine predictions, mitigating the impact of autocorrelated errors in real-time\nforecasting. The effectiveness of the proposed approach is verified on\ndifferent traffic datasets. Results across a wide range of traffic forecasting\nmodels show that our method enhances performance in almost all cases.", "AI": {"tldr": "Proposes Spatiotemporally Autocorrelated Error Adjustment (SAEA), a general framework that treats forecasting errors as a spatiotemporal VAR, uses sparse regularization aligned with road networks, and applies test-time error adjustments to improve traffic forecasting across models and datasets.", "motivation": "Common MSE-based training assumes uncorrelated errors across time steps and spatial locations, but traffic data exhibit strong temporal and spatial autocorrelations. This mismatch limits forecast accuracy and real-time performance; a framework to model and mitigate autocorrelated errors is needed.", "method": "Model prediction errors as a spatiotemporal vector autoregressive (VAR) process with a coefficient matrix capturing spatiotemporal error dependencies. Introduce a new cost function incorporating this matrix, apply structurally sparse regularization to align the learned matrix with road network structure, and implement a test-time inference step to dynamically adjust predictions based on estimated autocorrelated errors.", "result": "Empirical evaluation on multiple traffic datasets shows that SAEA improves forecasting accuracy across a wide range of models in most cases.", "conclusion": "SAEA offers a general, effective approach to account for autocorrelated prediction errors in traffic forecasting, integrates with existing models, and enables real-time error refinement by explicitly modeling spatiotemporal error dependencies."}}
{"id": "2510.24105", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24105", "abs": "https://arxiv.org/abs/2510.24105", "authors": ["Shufan Shen", "Zhaobo Qi", "Junshu Sun", "Qingming Huang", "Qi Tian", "Shuhui Wang"], "title": "Enhancing Pre-trained Representation Classifiability can Boost its Interpretability", "comment": "ICLR 2025 (Spotlight)", "summary": "The visual representation of a pre-trained model prioritizes the\nclassifiability on downstream tasks, while the widespread applications for\npre-trained visual models have posed new requirements for representation\ninterpretability. However, it remains unclear whether the pre-trained\nrepresentations can achieve high interpretability and classifiability\nsimultaneously. To answer this question, we quantify the representation\ninterpretability by leveraging its correlation with the ratio of interpretable\nsemantics within the representations. Given the pre-trained representations,\nonly the interpretable semantics can be captured by interpretations, whereas\nthe uninterpretable part leads to information loss. Based on this fact, we\npropose the Inherent Interpretability Score (IIS) that evaluates the\ninformation loss, measures the ratio of interpretable semantics, and quantifies\nthe representation interpretability. In the evaluation of the representation\ninterpretability with different classifiability, we surprisingly discover that\nthe interpretability and classifiability are positively correlated, i.e.,\nrepresentations with higher classifiability provide more interpretable\nsemantics that can be captured in the interpretations. This observation further\nsupports two benefits to the pre-trained representations. First, the\nclassifiability of representations can be further improved by fine-tuning with\ninterpretability maximization. Second, with the classifiability improvement for\nthe representations, we obtain predictions based on their interpretations with\nless accuracy degradation. The discovered positive correlation and\ncorresponding applications show that practitioners can unify the improvements\nin interpretability and classifiability for pre-trained vision models. Codes\nare available at https://github.com/ssfgunner/IIS.", "AI": {"tldr": "Proposes Inherent Interpretability Score (IIS) to quantify how interpretable pre-trained visual representations are, and finds a positive link between interpretability and classifiability, enabling jointly improving both via interpretabiliy-aware fine-tuning.", "motivation": "To answer whether pre-trained representations can be simultaneously highly interpretable and discriminative, and to quantify interpretability in a way that aligns with downstream success.", "method": "Define IIS based on information loss and ratio of interpretable semantics in representations; evaluate interpretability across representations with varying classifiability; analyze correlation; provide code.", "result": "IIS captures information loss and interpretable semantics; reveal a positive correlation between interpretability and classifiability; higher classifiability corresponds to more interpretable semantics; interpretability-driven fine-tuning improves classifiability with less accuracy loss; code available.", "conclusion": "Practitioners can pursue joint improvements in interpretability and classifiability for pre-trained vision models; the method enables interpretable predictions with maintained performance."}}
{"id": "2510.24457", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.24457", "abs": "https://arxiv.org/abs/2510.24457", "authors": ["Jorge Vicente-Martinez", "Edgar Ramirez-Laboreo"], "title": "Flatness-based trajectory planning for 3D overhead cranes with friction compensation and collision avoidance", "comment": "8 pages, 11 figures", "summary": "This paper presents an optimal trajectory generation method for 3D overhead\ncranes by leveraging differential flatness. This framework enables the direct\ninclusion of complex physical and dynamic constraints, such as nonlinear\nfriction and collision avoidance for both payload and rope. Our approach allows\nfor aggressive movements by constraining payload swing only at the final point.\nA comparative simulation study validates our approach, demonstrating that\nneglecting dry friction leads to actuator saturation and collisions. The\nresults show that friction modeling is a fundamental requirement for fast and\nsafe crane trajectories.", "AI": {"tldr": "Proposes an optimal trajectory generation framework for 3D overhead cranes using differential flatness, incorporating nonlinear friction and collision constraints; shows friction modeling is essential for fast, safe trajectories.", "motivation": "To enable fast, aggressive crane motions while ensuring safety, by incorporating realistic physical constraints (dry friction, collision avoidance) into trajectory planning.", "method": "Apply differential flatness to crane dynamics to directly encode nonlinear friction, rope-payload collision avoidance, and swing constraints at the final point; validated via comparative simulations.", "result": "Simulations reveal that ignoring dry friction causes actuator saturation and collisions; incorporating friction yields safer, faster trajectories.", "conclusion": "Friction modeling is fundamental for achieving fast and safe crane trajectories using this differential-flatness-based framework."}}
{"id": "2510.24145", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24145", "abs": "https://arxiv.org/abs/2510.24145", "authors": ["Yu Luo", "Jiamin Jiang", "Jingfei Feng", "Lei Tao", "Qingliang Zhang", "Xidao Wen", "Yongqian Sun", "Shenglin Zhang", "Jielong Huang", "Nan Qi", "Dan Pei"], "title": "From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems", "comment": null, "summary": "Incident management (IM) is central to the reliability of large-scale cloud\nsystems. Yet manual IM, where on-call engineers examine metrics, logs, and\ntraces is labor-intensive and error-prone in the face of massive and\nheterogeneous observability data. Existing automated IM approaches often\nstruggle to generalize across systems, provide limited interpretability, and\nincur high deployment costs, which hinders adoption in practice. In this paper,\nwe present OpsAgent, a lightweight, self-evolving multi-agent system for IM\nthat employs a training-free data processor to convert heterogeneous\nobservability data into structured textual descriptions, along with a\nmulti-agent collaboration framework that makes diagnostic inference transparent\nand auditable. To support continual capability growth, OpsAgent also introduces\na dual self-evolution mechanism that integrates internal model updates with\nexternal experience accumulation, thereby closing the deployment loop.\nComprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art\nperformance and show that OpsAgent is generalizable, interpretable,\ncost-efficient, and self-evolving, making it a practically deployable and\nsustainable solution for long-term operation in real-world cloud systems.", "AI": {"tldr": "OpsAgent is a training-free, self-evolving multi-agent system for incident management that converts heterogeneous observability data into structured text, offers transparent collaborative inference, and achieves state-of-the-art results on OPENRCA with generalizability, interpretability, cost-efficiency, and continual self-evolution.", "motivation": "Manual incident management is labor-intensive and error-prone in the face of massive heterogeneous observability data; existing automated IM lacks generalization, interpretability, and deployability, hindering real-world adoption.", "method": "A lightweight, training-free data processor to convert observability data to structured textual descriptions; a multi-agent collaboration framework for transparent, auditable inference; a dual self-evolution mechanism that integrates internal model updates with external experience accumulation to close the deployment loop.", "result": "State-of-the-art performance on OPENRCA; OpsAgent is generalizable, interpretable, cost-efficient, and self-evolving; demonstrates practical deployability for long-term operation in real-world cloud systems.", "conclusion": "OpsAgent provides a practical, scalable solution for long-term incident management in large-scale cloud systems, combining transparency, adaptability, and cost-efficiency to support continual capability growth and deployment."}}
{"id": "2510.23657", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23657", "abs": "https://arxiv.org/abs/2510.23657", "authors": ["Saklain Niam", "Tashfiqur Rahman", "Md. Amjad Patwary", "Mukarram Hossain"], "title": "A machine learning framework integrating seed traits and plasma parameters for predicting germination uplift in crops", "comment": null, "summary": "Cold plasma (CP) is an eco-friendly method to enhance seed germination, yet\noutcomes remain difficult to predict due to complex seed--plasma--environment\ninteractions. This study introduces the first machine learning framework to\nforecast germination uplift in soybean, barley, sunflower, radish, and tomato\nunder dielectric barrier discharge (DBD) plasma. Among the models tested (GB,\nXGB, ET, and hybrids), Extra Trees (ET) performed best (R\\textsuperscript{2} =\n0.919; RMSE = 3.21; MAE = 2.62), improving to R\\textsuperscript{2} = 0.925\nafter feature reduction. Engineering analysis revealed a hormetic response:\nnegligible effects at $<$7 kV or $<$200 s, maximum germination at 7--15 kV for\n200--500 s, and reduced germination beyond 20 kV or prolonged exposures.\nDischarge power was also a dominant factor, with germination rate maximizing at\n$\\geq$100 W with low exposure time. Species and cultivar-level predictions\nshowed radish (MAE = 1.46) and soybean (MAE = 2.05) were modeled with high\nconsistency, while sunflower remained slightly higher variable (MAE = 3.80).\nAmong cultivars, Williams (MAE = 1.23) and Sari (1.33) were well predicted,\nwhile Arian (2.86) and Ny\\'{\\i}rs\\'{e}gi fekete (3.74) were comparatively\npoorly captured. This framework was also embedded into MLflow, providing a\ndecision-support tool for optimizing CP seed germination in precision\nagriculture.", "AI": {"tldr": "A first ML framework using Extra Trees predicts germination uplift under dielectric barrier discharge plasma across multiple crops, revealing hormesis and power-time effects, and is deployed in MLflow as a precision-agriculture decision tool.", "motivation": "Cold plasma is eco-friendly for enhancing seed germination, but outcomes are hard to predict due to complex interactions among seeds, plasma, and environment; predictive models are needed to optimize treatment for reliable gains.", "method": "Compared multiple models (GB, XGB, ET, and hybrids) on germination data from soybean, barley, sunflower, radish, and tomato under DBD plasma; ET yielded the best fit (R^2 ~0.92, RMSE/MAE ~3); feature reduction improved R^2 to ~0.93. Analyzed dose-time hormesis (kV, exposure seconds) and discharge power (W); provided species- and cultivar-level predictions; embedded the model in MLflow for practical use in precision agriculture.", "result": "ET achieved R^2 = 0.919, RMSE = 3.21, MAE = 2.62; after feature reduction R^2 = 0.925. Hormetic response with negligible effects <7 kV or <200 s; peak germination at 7\u201315 kV for 200\u2013500 s; reduced germination beyond 20 kV or prolonged exposure. Germination rate maximizes at \u2265100 W with low exposure. Radish MAE 1.46; Soybean MAE 2.05; Sunflower MAE 3.80; cultivars Williams MAE 1.23; Sari 1.33; Arian 2.86; Ny\u00edrs\u00e9gi fekete 3.74.", "conclusion": "The study delivers a practical ML-based decision-support tool (via MLflow) to optimize CP seed germination in precision agriculture, enabling informed scheduling of voltage, time, and power for different crops and cultivars."}}
{"id": "2510.24116", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24116", "abs": "https://arxiv.org/abs/2510.24116", "authors": ["Fengming Yu", "Haiwei Pan", "Kejia Zhang", "Jian Guan", "Haiying Jiang"], "title": "UHKD: A Unified Framework for Heterogeneous Knowledge Distillation via Frequency-Domain Representations", "comment": "14 pages, 4 figures", "summary": "Knowledge distillation (KD) is an effective model compression technique that\ntransfers knowledge from a high-performance teacher to a lightweight student,\nreducing cost while maintaining accuracy. In visual applications, where\nlarge-scale image models are widely used, KD enables efficient deployment.\nHowever, architectural diversity introduces semantic discrepancies that hinder\nthe use of intermediate representations. Most existing KD methods are designed\nfor homogeneous models and degrade in heterogeneous scenarios, especially when\nintermediate features are involved. Prior studies mainly focus on the logits\nspace, making limited use of the semantic information in intermediate layers.\nTo address this limitation, Unified Heterogeneous Knowledge Distillation (UHKD)\nis proposed as a framework that leverages intermediate features in the\nfrequency domain for cross-architecture transfer. Fourier transform is applied\nto capture global feature information, alleviating representational\ndiscrepancies between heterogeneous teacher-student pairs. A Feature\nTransformation Module (FTM) produces compact frequency-domain representations\nof teacher features, while a learnable Feature Alignment Module (FAM) projects\nstudent features and aligns them via multi-level matching. Training is guided\nby a joint objective combining mean squared error on intermediate features with\nKullback-Leibler divergence on logits. Experiments on CIFAR-100 and ImageNet-1K\ndemonstrate gains of 5.59% and 0.83% over the latest method, highlighting UHKD\nas an effective approach for unifying heterogeneous representations and\nenabling efficient utilization of visual knowledge", "AI": {"tldr": "A cross-architecture knowledge distillation framework (UHKD) uses frequency-domain intermediate features with a Feature Transformation Module and a Feature Alignment Module to enable KD between heterogeneous models, achieving notable gains on CIFAR-100 and ImageNet-1K.", "motivation": "Architectural diversity causes semantic discrepancies in intermediate representations, making existing KD methods (which mostly target logits or homogeneous models) less effective for heterogeneous teacher\u2013student pairs. There is a need to leverage intermediate features across architectures to improve transfer.", "method": "Apply Fourier transform to teacher and student features to capture global information and reduce representational mismatch. A Feature Transformation Module (FTM) converts teacher features into compact frequency-domain representations. A learnable Feature Alignment Module (FAM) projects and aligns student features via multi-level matching. Training uses a joint objective combining mean squared error on intermediate features and KL divergence on logits.", "result": "Experiments on CIFAR-100 and ImageNet-1K show improvements over the latest method: 5.59 percentage points on CIFAR-100 and 0.83 percentage points on ImageNet-1K.", "conclusion": "UHKD demonstrates that unifying heterogeneous representations via frequency-domain intermediate features enables effective cross-architecture KD, enabling efficient use of visual knowledge."}}
{"id": "2510.24508", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24508", "abs": "https://arxiv.org/abs/2510.24508", "authors": ["Haoying Li", "Yifan Peng", "Junfeng Wu"], "title": "Supervisory Measurement-Guided Noise Covariance Estimation", "comment": null, "summary": "Reliable state estimation hinges on accurate specification of sensor noise\ncovariances, which weigh heterogeneous measurements. In practice, these\ncovariances are difficult to identify due to environmental variability,\nfront-end preprocessing, and other reasons. We address this by formulating\nnoise covariance estimation as a bilevel optimization that, from a Bayesian\nperspective, factorizes the joint likelihood of so-called odometry and\nsupervisory measurements, thereby balancing information utilization with\ncomputational efficiency. The factorization converts the nested Bayesian\ndependency into a chain structure, enabling efficient parallel computation: at\nthe lower level, an invariant extended Kalman filter with state augmentation\nestimates trajectories, while a derivative filter computes analytical gradients\nin parallel for upper-level gradient updates. The upper level refines the\ncovariance to guide the lower-level estimation. Experiments on synthetic and\nreal-world datasets show that our method achieves higher efficiency over\nexisting baselines.", "AI": {"tldr": "A bilevel optimization framework estimates sensor noise covariances by factorizing the joint likelihood of odometry and supervisory measurements, enabling efficient parallel estimation with lower-level invariant EKF trajectory estimation and upper-level gradient updates.", "motivation": "Sensor noise covariances are hard to identify due to environmental variability and preprocessing, yet accurate covariances are crucial for proper sensor fusion; existing methods may be inefficient.", "method": "Formulate noise covariance estimation as a Bayesian bilevel optimization that factorizes the joint likelihood into a chain structure. At the lower level, an invariant extended Kalman filter with state augmentation estimates trajectories. A derivative filter computes analytical gradients in parallel for upper-level gradient updates. The upper level refines the covariance to guide the lower-level estimation.", "result": "Experiments on synthetic and real-world datasets show higher efficiency than existing baselines.", "conclusion": "The proposed bilevel, factorized approach yields efficient, scalable covariance estimation that improves state estimation under varying noise conditions and environmental variability."}}
{"id": "2510.24151", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24151", "abs": "https://arxiv.org/abs/2510.24151", "authors": ["Bingsen Qiu", "Zijian Liu", "Xiao Liu", "Haoshen Yang", "Zeren Gao", "Bingjie Wang", "Feier Zhang", "Yixuan Qin", "Chunyan Li"], "title": "BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data", "comment": null, "summary": "Building training-ready multi-hop question answering (QA) datasets that truly\nstress a model's retrieval and reasoning abilities remains highly challenging\nrecently. While there have been a few recent evaluation datasets that capture\nthe characteristics of hard-to-search but easy-to-verify problems -- requiring\nthe integration of ambiguous, indirect, and cross-domain cues -- these data\nresources remain scarce and are mostly designed for evaluation, making them\nunsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL).\nMeanwhile, manually curating non-trivially retrievable questions -- where\nanswers cannot be found through a single direct query but instead require\nmulti-hop reasoning over oblique and loosely connected evidence -- incurs\nprohibitive human costs and fails to scale, creating a critical data bottleneck\nfor training high-capability retrieval-and-reasoning agents.\n  To address this, we present an automated framework for generating\nhigh-difficulty, training-ready multi-hop questions from semi-structured\nknowledge sources. The system (i) grows diverse, logically labeled evidence\nclusters through Natural Language Inference (NLI)-based relation typing and\ndiversity-aware expansion; (ii) applies reverse question construction to\ncompose oblique cues so that isolated signals are underinformative but their\ncombination uniquely identifies the target entity; and (iii) enforces quality\nwith a two-step evaluation pipeline that combines multi-model consensus\nfiltering with structured constraint decomposition and evidence-based matching.\nThe result is a scalable process that yields complex, retrieval-resistant yet\nverifiable questions suitable for SFT/RL training as well as challenging\nevaluation, substantially reducing human curation effort while preserving the\ndifficulty profile of strong evaluation benchmarks.", "AI": {"tldr": "An automated framework to generate high-difficulty training-ready multi-hop QA data from semi-structured sources, enabling scalable SFT/RL training and evaluation.", "motivation": "Current hard multi-hop QA resources are scarce and often designed only for evaluation; manual curation for training data is costly and not scalable; there is a need for scalable, retrievable, verifiable data to train retrieval-and-reasoning models.", "method": "1) Build diverse, logically labeled evidence clusters via NLI-based relation typing and diversity-aware expansion. 2) Apply reverse question construction to create oblique cues so that isolated signals are underinformative but their combination uniquely identifies the target. 3) Two-step quality filter: multi-model consensus filtering plus structured constraint decomposition and evidence-based matching.", "result": "Produces scalable, complex, retrieval-resistant yet verifiable questions suitable for SFT/RL training and challenging evaluation, substantially reducing human curation effort while preserving the difficulty profile of strong benchmarks.", "conclusion": "An automated generation framework can supply training-ready, high-difficulty multi-hop QA data, narrowing the gap between evaluation benchmarks and training resources and enabling scalable training of retrieval-and-reasoning models."}}
{"id": "2510.23658", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23658", "abs": "https://arxiv.org/abs/2510.23658", "authors": ["Vaibhav Jindal", "Hejian Sang", "Chun-Mao Lai", "Yanning Chen", "Zhipeng Wang"], "title": "Aligning Diffusion Language Models via Unpaired Preference Optimization", "comment": null, "summary": "Diffusion language models (dLLMs) are an emerging alternative to\nautoregressive (AR) generators, but aligning them to human preferences is\nchallenging because sequence log-likelihoods are intractable and pairwise\npreference data are costly to collect. We introduce ELBO-KTO, which combines an\nELBO surrogate for diffusion log-likelihoods with a prospect-theoretic,\nunpaired preference objective (Kahneman Tversky Optimization, KTO). We analyze\nthe bias and variance induced by the ELBO substitution and employ\nvariance-reduction practices that stabilize gradients during training. Applied\nto LLaDA-8B-Instruct, ELBO-KTO yields \\textbf{65.9\\%} and \\textbf{62.3\\%}\nadjusted win rates on kto-mix-14k and UltraFeedback-Binary, respectively,\nversus the base model under an automatic LLM judge. Across downstream tasks,\nincluding GSM8K, MMLU, and additional reasoning/knowledge benchmarks, ELBO-KTO\ntrained on UltraFeedback-Binary performs on par with or better than the base\nmodel under identical decoding. This establishes unpaired preference\noptimization as a viable alternative to pairwise alignment in diffusion LLMs.", "AI": {"tldr": "ELBO-KTO combines an ELBO surrogate for diffusion log-likelihoods with an unpaired Kahneman-Tversky Optimization (KTO) objective to align diffusion LLMs using unpaired preferences; it yields strong win-rate gains and competitive reasoning/knowledge task performance, suggesting unpaired preferences as a viable alternative to pairwise alignment.", "motivation": "Align diffusion language models to human preferences while avoiding intractable diffusion log-likelihoods and costly pairwise preference data; provide a practical, scalable objective by coupling an ELBO surrogate with unpaired preferences.", "method": "Derive and analyze an ELBO surrogate for diffusion log-likelihoods; adopt Kahneman-Tversky Optimization (KTO) as an unpaired preference objective; apply variance-reduction techniques to stabilize gradients; train LLaDA-8B-Instruct with UltraFeedback-Binary data; evaluate on kto-mix-14k, UltraFeedback-Binary and downstream benchmarks (GSM8K, MMLU, etc.).", "result": "ELBO-KTO achieves 65.9% and 62.3% adjusted win rates on kto-mix-14k and UltraFeedback-Binary, respectively, versus the base model under an automatic LLM judge; on downstream tasks (GSM8K, MMLU, etc.), ELBO-KTO trained on UltraFeedback-Binary matches or exceeds base-model performance under identical decoding; demonstrates unpaired preference optimization as a viable alternative to pairwise alignment for diffusion LLMs.", "conclusion": "Unpaired preference optimization with ELBO-KTO is a viable alternative to pairwise alignment for diffusion LLMs, yielding practical gains and stabilized training through bias/variance-aware ELBO substitution and variance-reduction techniques."}}
{"id": "2510.24117", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24117", "abs": "https://arxiv.org/abs/2510.24117", "authors": ["Zan Wang", "Siyu Chen", "Luya Mo", "Xinfeng Gao", "Yuxin Shen", "Lebin Ding", "Wei Liang"], "title": "DogMo: A Large-Scale Multi-View RGB-D Dataset for 4D Canine Motion Recovery", "comment": "19 pages", "summary": "We present DogMo, a large-scale multi-view RGB-D video dataset capturing\ndiverse canine movements for the task of motion recovery from images. DogMo\ncomprises 1.2k motion sequences collected from 10 unique dogs, offering rich\nvariation in both motion and breed. It addresses key limitations of existing\ndog motion datasets, including the lack of multi-view and real 3D data, as well\nas limited scale and diversity. Leveraging DogMo, we establish four motion\nrecovery benchmark settings that support systematic evaluation across monocular\nand multi-view, RGB and RGB-D inputs. To facilitate accurate motion recovery,\nwe further introduce a three-stage, instance-specific optimization pipeline\nthat fits the SMAL model to the motion sequences. Our method progressively\nrefines body shape and pose through coarse alignment, dense correspondence\nsupervision, and temporal regularization. Our dataset and method provide a\nprincipled foundation for advancing research in dog motion recovery and open up\nnew directions at the intersection of computer vision, computer graphics, and\nanimal behavior modeling.", "AI": {"tldr": "DogMo: a large-scale multi-view RGB-D dog motion dataset (1.2k sequences from 10 dogs) for motion recovery, with four benchmark settings and a three-stage SMAL fitting pipeline, enabling principled cross-modal evaluation.", "motivation": "To overcome limitations of existing dog motion datasets\u2014namely the lack of multi-view and real 3D data, limited scale and diversity\u2014and to enable systematic, cross-modal evaluation of dog motion recovery across monocular/multi-view and RGB/RGB-D inputs.", "method": "Collect 1.2k motion sequences from 10 dogs with multi-view RGB-D data, define four motion-recovery benchmark settings (monocular vs. multi-view, RGB vs. RGB-D), and propose a three-stage instance-specific optimization pipeline to fit the SMAL model: coarse alignment, dense correspondence supervision, and temporal regularization.", "result": "Provides a principled dataset and method for dog motion recovery, enabling systematic evaluation across input modalities and view configurations, and a practical SMAL-fitting pipeline to recover motion sequences.", "conclusion": "DogMo advances dog motion modeling by supplying a diverse, multi-view RGB-D dataset and a targeted optimization pipeline, fostering research at the intersection of computer vision, graphics, and animal behavior modeling."}}
{"id": "2510.24515", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24515", "abs": "https://arxiv.org/abs/2510.24515", "authors": ["Malintha Fernando", "Petter \u00d6gren", "Silun Zhang"], "title": "Stochastic Prize-Collecting Games: Strategic Planning in Multi-Robot Systems", "comment": "Submitted to IEEE Robotics and Automation Letters", "summary": "The Team Orienteering Problem (TOP) generalizes many real-world multi-robot\nscheduling and routing tasks that occur in autonomous mobility, aerial\nlogistics, and surveillance applications. While many flavors of the TOP exist\nfor planning in multi-robot systems, they assume that all the robots cooperate\ntoward a single objective; thus, they do not extend to settings where the\nrobots compete in reward-scarce environments. We propose Stochastic\nPrize-Collecting Games (SPCG) as an extension of the TOP to plan in the\npresence of self-interested robots operating on a graph, under energy\nconstraints and stochastic transitions. A theoretical study on complete and\nstar graphs establishes that there is a unique pure Nash equilibrium in SPCGs\nthat coincides with the optimal routing solution of an equivalent TOP given a\nrank-based conflict resolution rule. This work proposes two algorithms: Ordinal\nRank Search (ORS) to obtain the ''ordinal rank'' --one's effective rank in\ntemporarily-formed local neighborhoods during the games' stages, and Fictitious\nOrdinal Response Learning (FORL) to obtain best-response policies against one's\nsenior-rank opponents. Empirical evaluations conducted on road networks and\nsynthetic graphs under both dynamic and stationary prize distributions show\nthat 1) the state-aliasing induced by OR-conditioning enables learning policies\nthat scale more efficiently to large team sizes than those trained with the\nglobal index, and 2) Policies trained with FORL generalize better to imbalanced\nprize distributions than those with other multi-agent training methods.\nFinally, the learned policies in the SPCG achieved between 87% and 95%\noptimality compared to an equivalent TOP solution obtained by mixed-integer\nlinear programming.", "AI": {"tldr": "SPCG extends the Team Orienteering Problem to self-interested agents under energy constraints and stochastic transitions. It proves a unique pure Nash equilibrium that matches the TOP solution under a rank-based conflict rule, introduces Ordinal Rank Search (ORS) and Fictitious Ordinal Response Learning (FORL) for scalable learning, and achieves 87\u201395% of TOP optimality with good generalization and scalability.", "motivation": "To model competitive, reward-scarce multi-robot environments where agents act selfishly and must operate under uncertainty; existing TOP assumes cooperative agents, which is inadequate for competitive settings.", "method": "Theoretically analyze SPCGs on complete and star graphs to prove a unique pure Nash equilibrium that coincides with a TOP solution under a rank-based conflict resolution rule. Develop ORS to infer local ordinal ranks and FORL to learn best-response policies against higher-ranked opponents. Empirically evaluate on road networks and synthetic graphs across dynamic and stationary prize distributions, comparing against global-index training and other multi-agent methods.", "result": "Existence of a unique pure Nash equilibrium in SPCGs that aligns with an equivalent TOP solution under rank-based conflict resolution. ORS reduces state aliasing and scales better with team size. FORL yields policies that generalize better to prize imbalances. Learned policies achieve 87\u201395% of the TOP optimum (via MILP).", "conclusion": "SPCG with ORS and FORL provides scalable, robust planning for competitive multi-robot teams under uncertainty, achieving near-optimal performance relative to centralized TOP solutions and demonstrating good generalization to changing prize distributions."}}
{"id": "2510.24161", "categories": ["cs.AI", "cs.MM", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24161", "abs": "https://arxiv.org/abs/2510.24161", "authors": ["Wentao Tan", "Bowen Wang", "Heng Zhi", "Chenyu Liu", "Zhe Li", "Jian Liu", "Zengrong Lin", "Yukun Dai", "Yipeng Chen", "Wenjie Yang", "Enci Xie", "Hao Xue", "Baixu Ji", "Chen Xu", "Zhibin Wang", "Tianshi Wang", "Lei Zhu", "Heng Tao Shen"], "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning", "comment": null, "summary": "Multimodal large language models (MLLMs) have advanced vision-language\nreasoning and are increasingly deployed in embodied agents. However,\nsignificant limitations remain: MLLMs generalize poorly across digital-physical\nspaces and embodiments; vision-language-action models (VLAs) produce low-level\nactions yet lack robust high-level embodied reasoning; and most embodied large\nlanguage models (ELLMs) are constrained to digital-space with poor\ngeneralization to the physical world. Thus, unified models that operate\nseamlessly across digital and physical spaces while generalizing across\nembodiments and tasks remain absent. We introduce the \\textbf{Boundless Large\nModel (BLM$_1$)}, a multimodal spatial foundation model that preserves\ninstruction following and reasoning, incorporates embodied knowledge, and\nsupports robust cross-embodiment control. BLM$_1$ integrates three key\ncapabilities -- \\textit{cross-space transfer, cross-task learning, and\ncross-embodiment generalization} -- via a two-stage training paradigm. Stage I\ninjects embodied knowledge into the MLLM through curated digital corpora while\nmaintaining language competence. Stage II trains a policy module through an\nintent-bridging interface that extracts high-level semantics from the MLLM to\nguide control, without fine-tuning the MLLM backbone. This process is supported\nby a self-collected cross-embodiment demonstration suite spanning four robot\nembodiments and six progressively challenging tasks. Evaluations across digital\nand physical benchmarks show that a single BLM$_1$ instance outperforms four\nmodel families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving\n$\\sim\\!\\textbf{6%}$ gains in digital tasks and $\\sim\\!\\textbf{3%}$ in physical\ntasks.", "AI": {"tldr": "BLM1 is a multimodal spatial foundation model that bridges digital and physical spaces, cross-embodiment generalization, and high-level embodied reasoning via a two-stage training paradigm; it outperforms MLLMs, ELLMs, VLAs, and GMLMs with ~6% digital and ~3% physical gains.", "motivation": "Current MLLMs and embodied models struggle to generalize across digital-to-physical spaces and different embodiments. A unified model with robust cross-space transfer, cross-task learning, and cross-embodiment generalization is needed to enable reliable reasoning and control in both digital and real-world environments.", "method": "Two-stage training. Stage I injects embodied knowledge into the MLLM via curated digital corpora while preserving language competence. Stage II trains a policy module through an intent-bridging interface that extracts high-level semantics from the MLLM to guide control without fine-tuning the MLLM backbone. A self-collected cross-embodiment demonstration suite spans four robot embodiments and six tasks.", "result": "On digital and physical benchmarks, a single BLM1 instance outperforms four model families (MLLMs, ELLMs, VLAs, GMLMs), achieving approximately 6% gains in digital tasks and 3% gains in physical tasks.", "conclusion": "BLM1 demonstrates cross-space transfer, cross-task learning, and cross-embodiment generalization, enabling robust cross-embodiment control while preserving instruction following and reasoning. It offers a unified approach to operate across digital and physical spaces with improved generalization across embodiments."}}
{"id": "2510.23659", "categories": ["cs.LG", "cs.CV", "cs.ET"], "pdf": "https://arxiv.org/pdf/2510.23659", "abs": "https://arxiv.org/abs/2510.23659", "authors": ["Md. Farhan Shahriyar", "Gazi Tanbhir", "Abdullah Md Raihan Chy"], "title": "Quantum Machine Learning for Image Classification: A Hybrid Model of Residual Network with Quantum Support Vector Machine", "comment": null, "summary": "Recently, there has been growing attention on combining quantum machine\nlearning (QML) with classical deep learning approaches, as computational\ntechniques are key to improving the performance of image classification tasks.\nThis study presents a hybrid approach that uses ResNet-50 (Residual Network)\nfor feature extraction and Quantum Support Vector Machines (QSVM) for\nclassification in the context of potato disease detection. Classical machine\nlearning as well as deep learning models often struggle with high-dimensional\nand complex datasets, necessitating advanced techniques like quantum computing\nto improve classification efficiency. In our research, we use ResNet-50 to\nextract deep feature representations from RGB images of potato diseases. These\nfeatures are then subjected to dimensionality reduction using Principal\nComponent Analysis (PCA). The resulting features are processed through QSVM\nmodels which apply various quantum feature maps such as ZZ, Z, and Pauli-X to\ntransform classical data into quantum states. To assess the model performance,\nwe compared it with classical machine learning algorithms such as Support\nVector Machine (SVM) and Random Forest (RF) using five-fold stratified\ncross-validation for comprehensive evaluation. The experimental results\ndemonstrate that the Z-feature map-based QSVM outperforms classical models,\nachieving an accuracy of 99.23 percent, surpassing both SVM and RF models. This\nresearch highlights the advantages of integrating quantum computing into image\nclassification and provides a potential disease detection solution through\nhybrid quantum-classical modeling.", "AI": {"tldr": "Hybrid quantum-classical image classifier for potato diseases using ResNet-50 features reduced by PCA and QSVM with quantum feature maps; Z-map achieved 99.23% accuracy, outperforming SVM and RF.", "motivation": "Address high-dimensional image data and aim to improve classification by integrating quantum computing with classical deep learning, demonstrated on potato disease detection.", "method": "Use ResNet-50 to extract deep features from RGB potato disease images; apply PCA for dimensionality reduction; feed into QSVM with quantum feature maps (ZZ, Z, Pauli-X); compare against SVM and RF using five-fold stratified CV.", "result": "QSVM with Z-feature map achieved 99.23% accuracy, outperforming classical models (SVM, RF).", "conclusion": "Hybrid quantum-classical modeling can enhance image classification tasks; quantum feature maps show promise for improving performance and potential in disease detection applications."}}
{"id": "2510.24129", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24129", "abs": "https://arxiv.org/abs/2510.24129", "authors": ["Jiajian Xie", "Hubery Yin", "Chen Li", "Zhou Zhao", "Shengyu Zhang"], "title": "ETC: training-free diffusion models acceleration with Error-aware Trend Consistency", "comment": "17 pages, 10 figures", "summary": "Diffusion models have achieved remarkable generative quality but remain\nbottlenecked by costly iterative sampling. Recent training-free methods\naccelerate diffusion process by reusing model outputs. However, these methods\nignore denoising trends and lack error control for model-specific tolerance,\nleading to trajectory deviations under multi-step reuse and exacerbating\ninconsistencies in the generated results. To address these issues, we introduce\nError-aware Trend Consistency (ETC), a framework that (1) introduces a\nconsistent trend predictor that leverages the smooth continuity of diffusion\ntrajectories, projecting historical denoising patterns into stable future\ndirections and progressively distributing them across multiple approximation\nsteps to achieve acceleration without deviating; (2) proposes a model-specific\nerror tolerance search mechanism that derives corrective thresholds by\nidentifying transition points from volatile semantic planning to stable quality\nrefinement. Experiments show that ETC achieves a 2.65x acceleration over FLUX\nwith negligible (-0.074 SSIM score) degradation of consistency.", "AI": {"tldr": "A training-free diffusion-speedup method called ETC that uses an error-aware trend predictor and a model-specific tolerance search to accelerate sampling while preserving trajectory consistency.", "motivation": "Diffusion models are powerful but slow due to iterative sampling. Training-free speedups reuse model outputs but neglect denoising trends and lack per-model error control, causing trajectory deviations and inconsistencies across multi-step reuse.", "method": "ETC introduces a consistent trend predictor that leverages the smooth continuity of diffusion trajectories to project historical denoising patterns into stable future directions and progressively distribute them across multiple approximation steps. It also implements a model-specific error tolerance search to identify corrective thresholds by locating transition points from volatile semantic planning to stable quality refinement.", "result": "The method achieves about 2.65x acceleration over FLUX with a negligible SSIM degradation of about 0.074 points, indicating preserved consistency.", "conclusion": "ETC provides a principled, training-free framework for accelerating diffusion sampling that maintains trajectory consistency through trend-based prediction and error-aware thresholding, outperforming prior reuse-based approaches like FLUX."}}
{"id": "2510.24533", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24533", "abs": "https://arxiv.org/abs/2510.24533", "authors": ["Yuan Shen", "Yuze Hong", "Guangyang Zeng", "Tengfei Zhang", "Pui Yi Chui", "Ziyang Hong", "Junfeng Wu"], "title": "GeVI-SLAM: Gravity-Enhanced Stereo Visua Inertial SLAM for Underwater Robots", "comment": null, "summary": "Accurate visual inertial simultaneous localization and mapping (VI SLAM) for\nunderwater robots remains a significant challenge due to frequent visual\ndegeneracy and insufficient inertial measurement unit (IMU) motion excitation.\nIn this paper, we present GeVI-SLAM, a gravity-enhanced stereo VI SLAM system\ndesigned to address these issues. By leveraging the stereo camera's direct\ndepth estimation ability, we eliminate the need to estimate scale during IMU\ninitialization, enabling stable operation even under low acceleration dynamics.\nWith precise gravity initialization, we decouple the pitch and roll from the\npose estimation and solve a 4 degrees of freedom (DOF) Perspective-n-Point\n(PnP) problem for pose tracking. This allows the use of a minimal 3-point\nsolver, which significantly reduces computational time to reject outliers\nwithin a Random Sample Consensus framework. We further propose a\nbias-eliminated 4-DOF PnP estimator with provable consistency, ensuring the\nrelative pose converges to the true value as the feature number increases. To\nhandle dynamic motion, we refine the full 6-DOF pose while jointly estimating\nthe IMU covariance, enabling adaptive weighting of the gravity prior. Extensive\nexperiments on simulated and real-world data demonstrate that GeVI-SLAM\nachieves higher accuracy and greater stability compared to state-of-the-art\nmethods.", "AI": {"tldr": "GeVI-SLAM advances gravity-aware stereo VI SLAM for underwater robots, enabling stable 6-DOF tracking with a 4-DOF PnP and a bias-eliminated, consistent estimator, plus adaptive IMU weighting\u2014achieving higher accuracy and stability with reduced computation.", "motivation": "Underwater VI SLAM faces severe visual degeneracy and insufficient IMU excitation, causing scale, pitch/roll coupling, and pose estimation challenges. A gravity-informed, efficient approach is needed to maintain reliable localization and mapping in low-dynamic and feature-poor underwater environments.", "method": "Leverage stereo camera direct depth to avoid scale estimation during IMU initialization. Use precise gravity initialization to decouple pitch and roll and solve a 4-DOF PnP for pose tracking with a minimal 3-point solver within RANSAC. Introduce a bias-eliminated 4-DOF PnP estimator with provable consistency so relative pose converges to the true value as features increase. For dynamic motion, refine the full 6-DOF pose while jointly estimating IMU covariance to adaptively weight the gravity prior.", "result": "Extensive experiments on simulated and real-world datasets show GeVI-SLAM achieves higher accuracy and greater stability than state-of-the-art methods, with faster outlier rejection and robust performance under low acceleration dynamics.", "conclusion": "Gravity-enhanced, stereo VI SLAM provides a robust solution for underwater localization and mapping by decoupling gravity-anchored components, enabling a consistent, efficient 4-DOF PnP-based tracking and adaptive IMU weighting, while maintaining full 6-DOF refinement for dynamic motion."}}
{"id": "2510.24166", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24166", "abs": "https://arxiv.org/abs/2510.24166", "authors": ["Xin Yang", "Yuhang Zhang", "Wei Li", "Xin Lin", "Wenbin Zou", "Chen Xu"], "title": "UniPlanner: A Unified Motion Planning Framework for Autonomous Vehicle Decision-Making Systems via Multi-Dataset Integration", "comment": null, "summary": "Motion planning is a critical component of autonomous vehicle decision-making\nsystems, directly determining trajectory safety and driving efficiency. While\ndeep learning approaches have advanced planning capabilities, existing methods\nremain confined to single-dataset training, limiting their robustness in\nplanning.\n  Through systematic analysis, we discover that vehicular trajectory\ndistributions and history-future correlations demonstrate remarkable\nconsistency across different datasets. Based on these findings, we propose\nUniPlanner, the first planning framework designed for multi-dataset integration\nin autonomous vehicle decision-making. UniPlanner achieves unified\ncross-dataset learning through three synergistic innovations.\n  First, the History-Future Trajectory Dictionary Network (HFTDN) aggregates\nhistory-future trajectory pairs from multiple datasets, using historical\ntrajectory similarity to retrieve relevant futures and generate cross-dataset\nplanning guidance.\n  Second, the Gradient-Free Trajectory Mapper (GFTM) learns robust\nhistory-future correlations from multiple datasets, transforming historical\ntrajectories into universal planning priors. Its gradient-free design ensures\nthe introduction of valuable priors while preventing shortcut learning, making\nthe planning knowledge safely transferable. Third, the Sparse-to-Dense (S2D)\nparadigm implements adaptive dropout to selectively suppress planning priors\nduring training for robust learning, while enabling full prior utilization\nduring inference to maximize planning performance.", "AI": {"tldr": "UniPlanner enables cross-dataset autonomous vehicle planning by introducing three innovations\u2014History-Future Trajectory Dictionary Network (HFTDN), Gradient-Free Trajectory Mapper (GFTM), and Sparse-to-Dense (S2D)\u2014to transfer planning priors across multiple datasets and improve robustness.", "motivation": "Current planning methods are generally trained on a single dataset, limiting robustness to distribution shifts. The authors observe consistency in vehicular trajectory distributions and history-future correlations across datasets, motivating unified cross-dataset learning.", "method": "Three synergistic components: (1) History-Future Trajectory Dictionary Network (HFTDN) aggregates history-future trajectory pairs from multiple datasets, using historical similarity to retrieve futures and provide cross-dataset guidance. (2) Gradient-Free Trajectory Mapper (GFTM) learns robust history-future correlations from multiple datasets to transform histories into universal planning priors, using gradient-free optimization to safely transfer knowledge. (3) Sparse-to-Dense (S2D) paradigm applies adaptive dropout during training to suppress priors for robust learning, while allowing full prior usage during inference to maximize performance.", "result": "The abstract presents a conceptual framework with claims of unified cross-dataset learning and improved cross-dataset transfer of planning priors; it does not report empirical results or quantitative benchmarks.", "conclusion": "UniPlanner is positioned as the first planning framework for multi-dataset integration in autonomous vehicle decision-making, enabling transferable planning priors across diverse datasets and potentially improving planning robustness and performance."}}
{"id": "2510.23660", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23660", "abs": "https://arxiv.org/abs/2510.23660", "authors": ["Gazi Tanbhir", "Md. Farhan Shahriyar", "Abdullah Md Raihan Chy"], "title": "Quanvolutional Neural Networks for Pneumonia Detection: An Efficient Quantum-Assisted Feature Extraction Paradigm", "comment": null, "summary": "Pneumonia poses a significant global health challenge, demanding accurate and\ntimely diagnosis. While deep learning, particularly Convolutional Neural\nNetworks (CNNs), has shown promise in medical image analysis for pneumonia\ndetection, CNNs often suffer from high computational costs, limitations in\nfeature representation, and challenges in generalizing from smaller datasets.\nTo address these limitations, we explore the application of Quanvolutional\nNeural Networks (QNNs), leveraging quantum computing for enhanced feature\nextraction. This paper introduces a novel hybrid quantum-classical model for\npneumonia detection using the PneumoniaMNIST dataset. Our approach utilizes a\nquanvolutional layer with a parameterized quantum circuit (PQC) to process 2x2\nimage patches, employing rotational Y-gates for data encoding and entangling\nlayers to generate non-classical feature representations. These\nquantum-extracted features are then fed into a classical neural network for\nclassification. Experimental results demonstrate that the proposed QNN achieves\na higher validation accuracy of 83.33 percent compared to a comparable\nclassical CNN which achieves 73.33 percent. This enhanced convergence and\nsample efficiency highlight the potential of QNNs for medical image analysis,\nparticularly in scenarios with limited labeled data. This research lays the\nfoundation for integrating quantum computing into deep-learning-driven medical\ndiagnostic systems, offering a computationally efficient alternative to\ntraditional approaches.", "AI": {"tldr": "Hybrid quantum-classical model (QNN) for pneumonia detection using PneumoniaMNIST; uses a quanvolutional layer with a parameterized quantum circuit on 2x2 patches; reports higher validation accuracy (83.33%) than a comparable classical CNN (73.33%), suggesting potential for improved feature extraction and data efficiency in medical imaging with limited labeled data.", "motivation": "CNNs in medical imaging face high computational costs, limited feature representation, and poor generalization on small datasets. Quantum feature extraction via parameterized quantum circuits (PQC) may yield richer representations and better sample efficiency, motivating a hybrid quantum-classical approach for pneumonia detection.", "method": "Apply a quanvolutional layer that processes 2x2 image patches encoded by rotational Y-gates into a PQC with entangling layers to generate non-classical features; extract these features and feed into a classical neural network for classification; evaluate on PneumoniaMNIST and compare against a classical CNN.", "result": "Validation accuracy reported as 83.33% for the QNN vs 73.33% for a comparable classical CNN; claims improved convergence and sample efficiency.", "conclusion": "Demonstrates feasibility of integrating quantum computing into deep-learning-based medical diagnostics; suggests quantum feature extraction can enhance performance, especially with limited labeled data; serves as a foundation for future work on more complex datasets and hardware integration."}}
{"id": "2510.24133", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24133", "abs": "https://arxiv.org/abs/2510.24133", "authors": ["Minsuk Ji", "Sanghyeok Lee", "Namhyuk Ahn"], "title": "Compositional Image Synthesis with Inference-Time Scaling", "comment": "projcet page: https://github.com/gcl-inha/ReFocus", "summary": "Despite their impressive realism, modern text-to-image models still struggle\nwith compositionality, often failing to render accurate object counts,\nattributes, and spatial relations. To address this challenge, we present a\ntraining-free framework that combines an object-centric approach with\nself-refinement to improve layout faithfulness while preserving aesthetic\nquality. Specifically, we leverage large language models (LLMs) to synthesize\nexplicit layouts from input prompts, and we inject these layouts into the image\ngeneration process, where a object-centric vision-language model (VLM) judge\nreranks multiple candidates to select the most prompt-aligned outcome\niteratively. By unifying explicit layout-grounding with self-refine-based\ninference-time scaling, our framework achieves stronger scene alignment with\nprompts compared to recent text-to-image models. The code are available at\nhttps://github.com/gcl-inha/ReFocus.", "AI": {"tldr": "Training-free approach that improves layout faithfulness in text-to-image generation by using LLM-generated explicit layouts and an object-centric VLM to iteratively rerank candidates, achieving better prompt alignment without additional training.", "motivation": "Modern text-to-image models struggle with compositionality, including object counts, attributes, and spatial relations; a training-free solution to enforce layout constraints is desirable.", "method": "1) Use large language models to synthesize explicit layouts from input prompts; 2) inject these layouts into image generation; 3) employ an object-centric vision-language model to judge and rerank multiple candidate outputs for prompt alignment; 4) apply iterative self-refinement at inference time to scale results.", "result": "The approach yields stronger scene alignment with prompts and better layout fidelity compared to recent text-to-image models, while preserving aesthetic quality.", "conclusion": "Explicit layout grounding combined with self-refinement at inference improves compositionality without training; the method is training-free and scalable; code is available."}}
{"id": "2510.24554", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24554", "abs": "https://arxiv.org/abs/2510.24554", "authors": ["Vignesh Kottayam Viswanathan", "Yifan Bai", "Scott Fredriksson", "Sumeet Satpute", "Christoforos Kanellakis", "George Nikolakopoulos"], "title": "An Adaptive Inspection Planning Approach Towards Routine Monitoring in Uncertain Environments", "comment": "Submitted for ICRA 2026", "summary": "In this work, we present a hierarchical framework designed to support robotic\ninspection under environment uncertainty. By leveraging a known environment\nmodel, existing methods plan and safely track inspection routes to visit points\nof interest. However, discrepancies between the model and actual site\nconditions, caused by either natural or human activities, can alter the surface\nmorphology or introduce path obstructions. To address this challenge, the\nproposed framework divides the inspection task into: (a) generating the initial\nglobal view-plan for region of interests based on a historical map and (b)\nlocal view replanning to adapt to the current morphology of the inspection\nscene. The proposed hierarchy preserves global coverage objectives while\nenabling reactive adaptation to the local surface morphology. This enables the\nlocal autonomy to remain robust against environment uncertainty and complete\nthe inspection tasks. We validate the approach through deployments in\nreal-world subterranean mines using quadrupedal robot.", "AI": {"tldr": "Hierarchical planning for robotic inspection under uncertainty: global view-plan from historical maps plus local view replanning to adapt to current morphology; validated on a quadrupedal robot in subterranean mines.", "motivation": "Uncertainty between environment models and real site conditions (morphology changes, obstructions) can disrupt inspection routes. A framework is needed to preserve global coverage while adapting locally.", "method": "A two-level hierarchy: (a) generate an initial global view-plan for regions of interest using a historical map; (b) perform local view replanning to adapt to the current inspection scene morphology, preserving global coverage while enabling reactive local adaptation. Implemented on a quadrupedal robot and validated in real-world subterranean mines.", "result": "The approach was validated through real-world subterranean mine deployments with a quadrupedal robot, demonstrating robustness to environment uncertainty and successful completion of inspection tasks.", "conclusion": "A hierarchical planning framework effectively combines global planning with local adaptability to handle environment uncertainty in robotic inspection and can generalize to similar tasks."}}
{"id": "2510.24168", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24168", "abs": "https://arxiv.org/abs/2510.24168", "authors": ["Weihua Cheng", "Ersheng Ni", "Wenlong Wang", "Yifei Sun", "Junming Liu", "Wangyu Shen", "Yirong Chen", "Botian Shi", "Ding Wang"], "title": "MGA: Memory-Driven GUI Agent for Observation-Centric Interaction", "comment": "Submitted to WWW2025", "summary": "The rapid progress of Large Language Models (LLMs) and their multimodal\nextensions (MLLMs) has enabled agentic systems capable of perceiving and acting\nacross diverse environments. A challenging yet impactful frontier is the\ndevelopment of GUI agents, which must navigate complex desktop and web\ninterfaces while maintaining robustness and generalization. Existing paradigms\ntypically model tasks as long-chain executions, concatenating historical\ntrajectories into the context. While approaches such as Mirage and GTA1 refine\nplanning or introduce multi-branch action selection, they remain constrained by\ntwo persistent issues: Dependence on historical trajectories, which amplifies\nerror propagation. And Local exploration bias, where \"decision-first,\nobservation-later\" mechanisms overlook critical interface cues. We introduce\nthe Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the\nprinciple of observe first, then decide. MGA models each step as an\nindependent, context-rich environment state represented by a triad: current\nscreenshot, task-agnostic spatial information, and a dynamically updated\nstructured memory. Experiments on OSworld benchmarks, real desktop applications\n(Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves\nsubstantial gains in robustness, generalization, and efficiency compared to\nstate-of-the-art baselines. The code is publicly available at:\n{https://anonymous.4open.science/r/MGA-3571}.", "AI": {"tldr": "MGA introduces an observe-first, memory-augmented GUI agent that treats each interaction as an independent state (screenshot, spatial cues, memory), yielding better robustness and generalization than history-heavy methods.", "motivation": "To address persistent GUI-agent challenges: (1) error propagation from relying on long historical trajectories, and (2) local exploration bias that under-utilizes interface cues.", "method": "Propose Memory-Driven GUI Agent (MGA) that reformulates GUI interaction as a sequence of independent, context-rich states represented by a triad: current screenshot, task-agnostic spatial information, and a dynamically updated structured memory. The agent follows an observe-first, then-decide paradigm, updating memory at each step and making decisions without depending on full task histories. Evaluation spans OSworld benchmarks, real desktop apps (Chrome, VSCode, VLC), and cross-task transfer.", "result": "MGA achieves substantial gains in robustness, generalization, and efficiency compared with state-of-the-art baselines, demonstrated on OSworld and real applications, with positive cross-task transfer.", "conclusion": "The observe-first, memory-augmented framework effectively addresses key GUI-agent limitations, offering improved robustness and generalization across diverse interfaces and tasks; code is publicly available."}}
{"id": "2510.23663", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23663", "abs": "https://arxiv.org/abs/2510.23663", "authors": ["Padmanabhan Jagannathan Prajesh", "Kaliaperumal Ragunath", "Miriam Gordon", "Bruce Rathgeber", "Suresh Neethirajan"], "title": "AI-Driven Carbon Monitoring: Transformer-Based Reconstruction of Atmospheric CO2 in Canadian Poultry Regions", "comment": null, "summary": "Accurate mapping of column-averaged CO2 (XCO2) over agricultural landscapes\nis essential for guiding emission mitigation strategies. We present a\nSpatiotemporal Vision Transformer with Wavelets (ST-ViWT) framework that\nreconstructs continuous, uncertainty-quantified XCO2 fields from OCO-2 across\nsouthern Canada, emphasizing poultry-intensive regions. The model fuses wavelet\ntime-frequency representations with transformer attention over meteorology,\nvegetation indices, topography, and land cover. On 2024 OCO-2 data, ST-ViWT\nattains R2 = 0.984 and RMSE = 0.468 ppm; 92.3 percent of gap-filled predictions\nlie within +/-1 ppm. Independent validation with TCCON shows robust\ngeneralization (bias = -0.14 ppm; r = 0.928), including faithful reproduction\nof the late-summer drawdown. Spatial analysis across 14 poultry regions reveals\na moderate positive association between facility density and XCO2 (r = 0.43);\nhigh-density areas exhibit larger seasonal amplitudes (9.57 ppm) and enhanced\nsummer variability. Compared with conventional interpolation and standard\nmachine-learning baselines, ST-ViWT yields seamless 0.25 degree CO2 surfaces\nwith explicit uncertainties, enabling year-round coverage despite sparse\nobservations. The approach supports integration of satellite constraints with\nnational inventories and precision livestock platforms to benchmark emissions,\nrefine region-specific factors, and verify interventions. Importantly,\ntransformer-based Earth observation enables scalable, transparent, spatially\nexplicit carbon accounting, hotspot prioritization, and policy-relevant\nmitigation assessment.", "AI": {"tldr": "ST-ViWT uses a spatiotemporal vision transformer with wavelets to reconstruct continuous, uncertainty-quantified XCO2 fields from OCO-2 over southern Canada, achieving high accuracy and robust independent validation, enabling policy-relevant emissions assessment in poultry-dense regions.", "motivation": "Accurate, gap-filled, uncertainty-quantified XCO2 maps are needed in agricultural landscapes with sparse satellite coverage to guide emissions mitigation and verify inventories; existing methods struggle with temporal gaps and regional heterogeneity.", "method": "A Spatiotemporal Vision Transformer with Wavelets (ST-ViWT) fuses wavelet time-frequency representations with transformer attention across features such as meteorology, vegetation indices, topography, and land cover. The model produces 0.25\u00b0 XCO2 surfaces with explicit uncertainties and performs gap-filling on 2024 OCO-2 data, with validation against TCCON and regional poultry sites.", "result": "On 2024 OCO-2 data: R2 = 0.984, RMSE = 0.468 ppm; 92.3% of gap-filled predictions within \u00b11 ppm. Independent TCCON validation: bias = -0.14 ppm; r = 0.928; reproduces late-summer drawdown. Spatial analysis across 14 poultry regions shows r = 0.43 between facility density and XCO2; higher density regions have larger seasonal amplitudes (9.57 ppm) and enhanced summer variability. Outperforms conventional interpolation and standard ML baselines, yielding seamless 0.25\u00b0 CO2 surfaces with explicit uncertainties.", "conclusion": "Transformer-based Earth observation enables scalable, transparent, spatially explicit carbon accounting, hotspot prioritization, and policy-relevant mitigation assessment. The approach supports integrating satellite constraints with inventories and precision livestock platforms to benchmark emissions and verify interventions."}}
{"id": "2510.24134", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24134", "abs": "https://arxiv.org/abs/2510.24134", "authors": ["Yang Du", "Zhuoran Lin", "Kaiqiang Song", "Biao Wang", "Zhicheng Zheng", "Tiezheng Ge", "Bo Zheng", "Qin Jin"], "title": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "comment": "Accepted by EMNLP 2025", "summary": "Recent advances in text-to-video (T2V) generation highlight the critical role\nof high-quality video-text pairs in training models capable of producing\ncoherent and instruction-aligned videos. However, strategies for optimizing\nvideo captions specifically for T2V training remain underexplored. In this\npaper, we introduce VC4VG (Video Captioning for Video Generation), a\ncomprehensive caption optimization framework tailored to the needs of T2V\nmodels.We begin by analyzing caption content from a T2V perspective,\ndecomposing the essential elements required for video reconstruction into\nmultiple dimensions, and proposing a principled caption design methodology. To\nsupport evaluation, we construct VC4VG-Bench, a new benchmark featuring\nfine-grained, multi-dimensional, and necessity-graded metrics aligned with\nT2V-specific requirements.Extensive T2V fine-tuning experiments demonstrate a\nstrong correlation between improved caption quality and video generation\nperformance, validating the effectiveness of our approach. We release all\nbenchmark tools and code at https://github.com/qyr0403/VC4VG to support further\nresearch.", "AI": {"tldr": "Proposes VC4VG, a framework to tailor video captions for text-to-video training, plus VC4VG-Bench benchmark; shows caption quality correlates with improved video generation and releases tools for research.", "motivation": "High-quality video-text pairs are crucial for effective T2V models, yet there is little work on optimizing captions specifically for T2V training.", "method": " analyzes caption content from a T2V perspective, decomposes reconstruction-relevant elements into multiple dimensions, designs a principled caption design methodology, builds VC4VG-Bench with fine-grained, multi-dimensional, necessity-graded metrics, and performs extensive T2V fine-tuning experiments.", "result": " Demonstrates a strong correlation between improved caption quality and video generation performance, validating the framework; provides benchmark tools and code for the community.", "conclusion": "Tailoring captions for T2V training improves video generation; VC4VG offers a practical framework and resources to advance caption-aware video synthesis research."}}
{"id": "2510.24571", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24571", "abs": "https://arxiv.org/abs/2510.24571", "authors": ["Hongxu Zhao", "Guangyang Zeng", "Yunling Shao", "Tengfei Zhang", "Junfeng Wu"], "title": "Spatiotemporal Calibration of Doppler Velocity Logs for Underwater Robots", "comment": null, "summary": "The calibration of extrinsic parameters and clock offsets between sensors for\nhigh-accuracy performance in underwater SLAM systems remains insufficiently\nexplored. Existing methods for Doppler Velocity Log (DVL) calibration are\neither constrained to specific sensor configurations or rely on oversimplified\nassumptions, and none jointly estimate translational extrinsics and time\noffsets. We propose a Unified Iterative Calibration (UIC) framework for general\nDVL sensor setups, formulated as a Maximum A Posteriori (MAP) estimation with a\nGaussian Process (GP) motion prior for high-fidelity motion interpolation. UIC\nalternates between efficient GP-based motion state updates and gradient-based\ncalibration variable updates, supported by a provably statistically consistent\nsequential initialization scheme. The proposed UIC can be applied to IMU,\ncameras and other modalities as co-sensors. We release an open-source\nDVL-camera calibration toolbox. Beyond underwater applications, several aspects\nof UIC-such as the integration of GP priors for MAP-based calibration and the\ndesign of provably reliable initialization procedures-are broadly applicable to\nother multi-sensor calibration problems. Finally, simulations and real-world\ntests validate our approach.", "AI": {"tldr": "A Unified Iterative Calibration (UIC) framework for joint calibration of DVL extrinsics and clock offsets using a Gaussian Process motion prior within a MAP estimation, featuring an efficient alternating update scheme and provable initialization, applicable beyond DVL to IMU/cameras, and validated by simulations and real-world tests.", "motivation": "Calibration of extrinsics and time offsets is crucial for underwater SLAM but remains insufficiently explored. Existing DVL calibration methods are limited to particular sensor configurations or rely on oversimplified assumptions and do not jointly estimate translational extrinsics and time offsets.", "method": "Formulates calibration as a MAP estimation with a Gaussian Process motion prior for high-fidelity motion interpolation. The algorithm alternates between GP-based motion state updates and gradient-based calibration variable updates, supported by a provably statistically consistent initialization scheme. The framework is extendable to IMU, cameras and other modalities, and an open-source DVL-camera calibration toolbox is released.", "result": "Simulations and real-world tests validate the approach, showing high-fidelity motion interpolation and reliable initialization. The method generalizes to multi-sensor setups beyond underwater DVL-camera configurations.", "conclusion": "UIC provides a general, effective calibration framework for multi-sensor setups, enabling joint estimation of translational extrinsics and time offsets with GP priors. Its components\u2014MAP with GP priors and provable initialization\u2014are broadly applicable, and the authors provide open-source toolbox resources."}}
{"id": "2510.24284", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24284", "abs": "https://arxiv.org/abs/2510.24284", "authors": ["Wenhao Wang", "Peizhi Niu", "Zhao Xu", "Zhaoyu Chen", "Jian Du", "Yaxin Du", "Xianghe Pang", "Keduan Huang", "Yanfeng Wang", "Qiang Yan", "Siheng Chen"], "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "comment": null, "summary": "Large Language Models (LLMs) increasingly rely on external tools to perform\ncomplex, realistic tasks, yet their ability to utilize the rapidly expanding\nModel Contextual Protocol (MCP) ecosystem remains limited. Existing MCP\nresearch covers few servers, depends on costly manual curation, and lacks\ntraining support, hindering progress toward real-world deployment. To overcome\nthese limitations, we introduce MCP-Flow, an automated web-agent-driven\npipeline for large-scale server discovery, data synthesis, and model training.\nMCP-Flow collects and filters data from 1166 servers and 11536 tools, producing\n68733 high-quality instruction-function call pairs and 6439 trajectories, far\nexceeding prior work in scale and diversity. Extensive experiments demonstrate\nMCP-Flow's effectiveness in driving superior MCP tool selection, function-call\ngeneration, and enhanced agentic task performance. MCP-Flow thus provides a\nscalable foundation for advancing LLM agents' proficiency in real-world MCP\nenvironments. MCP-Flow is publicly available at\n\\href{https://github.com/wwh0411/MCP-Flow}{https://github.com/wwh0411/MCP-Flow}.", "AI": {"tldr": "MCP-Flow automates a web-agent-driven pipeline to scale MCP data collection and training, enabling large-scale discovery of servers/tools and generation of instruction-function call pairs and trajectories, improving MCP tool selection and function-call generation for real-world LLM agent deployment.", "motivation": "LLMs increasingly rely on external tools, but MCP research is limited in scale, relies on manual curation, and lacks training support. There is a need for automated, scalable data collection and training to enable real-world MCP-enabled agents.", "method": "An automated web-agent-driven pipeline that discovers servers, synthesizes data, and trains models. It collects and filters data from 1166 servers and 11536 tools, producing 68733 instruction-function call pairs and 6439 trajectories to train and evaluate MCP-enabled agents.", "result": "MCP-Flow achieves superior MCP tool selection, better function-call generation, and enhanced agentic task performance, outperforming prior work in scale and diversity; public code available at GitHub.", "conclusion": "MCP-Flow provides a scalable foundation for advancing LLM agents in real-world MCP environments and serves as a robust data/training platform for MCP-enabled agents."}}
{"id": "2510.23665", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23665", "abs": "https://arxiv.org/abs/2510.23665", "authors": ["Juan C. Leon Alcazar", "Mattia Soldan", "Mohammad Saatialsoruji", "Alejandro Pardo", "Hani Itani", "Juan Camilo Perez", "Bernard Ghanem"], "title": "Transformers from Compressed Representations", "comment": null, "summary": "Compressed file formats are the corner stone of efficient data storage and\ntransmission, yet their potential for representation learning remains largely\nunderexplored. We introduce TEMPEST (TransformErs froM comPressed\nrEpreSenTations), a method that exploits the inherent byte-stream structure of\ncompressed files to design an effective tokenization and encoding strategy. By\nleveraging this compact encoding, a standard transformer can directly learn\nsemantic representations from compressed data streams, bypassing the need for\nraw byte-level processing or full media decoding. Our proposal substantially\nreduces the number of tokens required for semantic classification, thereby\nlowering both computational complexity and memory usage. Through extensive\nexperiments across diverse datasets, coding schemes, and modalities, we show\nthat TEMPEST achieves accuracy competitive wit the state-of-the-art while\ndelivering efficiency gains in memory and compute.", "AI": {"tldr": "TEMPEST enables Transformers to learn semantic representations directly from compressed byte streams by a novel tokenization that leverages the intrinsic structure of compressed files, reducing tokens and enabling competitive accuracy with lower memory and compute costs.", "motivation": "Compressed file formats are efficient for storage and transmission, but their potential for representation learning is underexplored. If models can operate on compressed streams without full decoding, we can gain efficiency and broaden applicability across modalities.", "method": "Introduce a tokenization/encoding scheme that exploits the byte-stream structure of compressed data, allowing a standard transformer to process compressed streams directly. This bypasses raw byte-level processing and full media decoding, reducing token count and computational/memory requirements. Extensive experiments across datasets, coding schemes, and modalities validate the approach.", "result": "TEMPEST achieves competitive accuracy with state-of-the-art methods while delivering substantial efficiency gains in memory usage and compute due to a lower token budget and streamlined processing.", "conclusion": "Learning semantic representations directly from compressed streams is viable. TEMPEST offers a practical path to efficient representation learning on compressed data, with potential applicability across multiple modalities and compression schemes."}}
{"id": "2510.24136", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24136", "abs": "https://arxiv.org/abs/2510.24136", "authors": ["Ovi Sarkar", "Md Shafiuzzaman", "Md. Faysal Ahamed", "Golam Mahmud", "Muhammad E. H. Chowdhury"], "title": "MSRANetV2: An Explainable Deep Learning Architecture for Multi-class Classification of Colorectal Histopathological Images", "comment": null, "summary": "Colorectal cancer (CRC) is a leading worldwide cause of cancer-related\nmortality, and the role of prompt precise detection is of paramount interest in\nimproving patient outcomes. Conventional diagnostic methods such as colonoscopy\nand histological examination routinely exhibit subjectivity, are extremely\ntime-consuming, and are susceptible to variation. Through the development of\ndigital pathology, deep learning algorithms have become a powerful approach in\nenhancing diagnostic precision and efficiency. In our work, we proposed a\nconvolutional neural network architecture named MSRANetV2, specially optimized\nfor the classification of colorectal tissue images. The model employs a\nResNet50V2 backbone, extended with residual attention mechanisms and\nsqueeze-and-excitation (SE) blocks, to extract deep semantic and fine-grained\nspatial features. With channel alignment and upsampling operations, MSRANetV2\neffectively fuses multi-scale representations, thereby enhancing the robustness\nof the classification. We evaluated our model on a five-fold stratified\ncross-validation strategy on two publicly available datasets: CRC-VAL-HE-7K and\nNCT-CRC-HE-100K. The proposed model achieved remarkable average Precision,\nrecall, F1-score, AUC, and test accuracy were 0.9884 plus-minus 0.0151, 0.9900\nplus-minus 0.0151, 0.9900 plus-minus 0.0145, 0.9999 plus-minus 0.00006, and\n0.9905 plus-minus 0.0025 on the 7K dataset. On the 100K dataset, they were\n0.9904 plus-minus 0.0091, 0.9900 plus-minus 0.0071, 0.9900 plus-minus 0.0071,\n0.9997 plus-minus 0.00016, and 0.9902 plus-minus 0.0006. Additionally, Grad-CAM\nvisualizations were incorporated to enhance model interpretability by\nhighlighting tissue areas that are medically relevant. These findings validate\nthat MSRANetV2 is a reliable, interpretable, and high-performing architectural\nmodel for classifying CRC tissues.", "AI": {"tldr": "MSRANetV2 is a high-performing, interpretable CNN for colorectal tissue classification, achieving near-perfect AUC and top metrics on two public datasets, with Grad-CAM for visualization.", "motivation": "CRC diagnosis is subjective and time-consuming; digital pathology with deep learning can improve accuracy and efficiency.", "method": "A ResNet50V2-based CNN (MSRANetV2) with residual attention and squeeze-excitation blocks; multi-scale feature fusion via channel alignment/upsampling; five-fold cross-validation on CRC-VAL-HE-7K and NCT-CRC-HE-100K; Grad-CAM for explainability.", "result": "On CRC-VAL-HE-7K: Precision 0.9884\u00b10.0151, Recall 0.9900\u00b10.0151, F1 0.9900\u00b10.0145, AUC 0.9999\u00b10.00006, Accuracy 0.9905\u00b10.0025. On NCT-CRC-HE-100K: Precision 0.9904\u00b10.0091, Recall 0.9900\u00b10.0071, F1 0.9900\u00b10.0071, AUC 0.9997\u00b10.00016, Accuracy 0.9902\u00b10.0006.", "conclusion": "MSRANetV2 is a reliable, interpretable, high-performing architecture for classifying CRC tissues."}}
{"id": "2510.24584", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24584", "abs": "https://arxiv.org/abs/2510.24584", "authors": ["J\u00f8rgen Anker Olsen", "Lars R\u00f8nhaug Pettersen", "Kostas Alexis"], "title": "Towards Quadrupedal Jumping and Walking for Dynamic Locomotion using Reinforcement Learning", "comment": "8 pages", "summary": "This paper presents a curriculum-based reinforcement learning framework for\ntraining precise and high-performance jumping policies for the robot `Olympus'.\nSeparate policies are developed for vertical and horizontal jumps, leveraging a\nsimple yet effective strategy. First, we densify the inherently sparse jumping\nreward using the laws of projectile motion. Next, a reference state\ninitialization scheme is employed to accelerate the exploration of dynamic\njumping behaviors without reliance on reference trajectories. We also present a\nwalking policy that, when combined with the jumping policies, unlocks versatile\nand dynamic locomotion capabilities. Comprehensive testing validates walking on\nvaried terrain surfaces and jumping performance that exceeds previous works,\neffectively crossing the Sim2Real gap. Experimental validation demonstrates\nhorizontal jumps up to 1.25 m with centimeter accuracy and vertical jumps up to\n1.0 m. Additionally, we show that with only minor modifications, the proposed\nmethod can be used to learn omnidirectional jumping.", "AI": {"tldr": "A curriculum-based reinforcement learning framework enabling precise horizontal and vertical jumping for a robot named Olympus, with dense rewards via projectile motion, reference-state initialization for fast exploration, and a walking policy that enables versatile locomotion; achieves centimeter-accurate horizontal jumps up to 1.25 m and vertical jumps up to 1.0 m; can be extended to omnidirectional jumping with minor modifications; shows strong Sim2Real transfer.", "motivation": "Address the challenge of learning precise, high-performance jumping policies for legged robots, addressing sparse rewards and reliance on reference trajectories, and improving Sim2Real transfer by combining curriculum RL, reward shaping, and smart initialization.", "method": "Develop separate vertical and horizontal jumping policies within a curriculum-based RL framework; densify sparse rewards using projectile motion laws; apply a reference state initialization scheme to accelerate exploration without reference trajectories; couple with a walking policy to enable versatile locomotion; demonstrate through experiments including varied terrain and omnidirectional potential.", "result": "Experimental validation demonstrates horizontal jumps up to 1.25 m with centimeter accuracy and vertical jumps up to 1.0 m; walking on varied terrains validated; surpasses prior work and crossing Sim2Real gap.", "conclusion": "The proposed framework enables precise, high-performance, and versatile locomotion combining walking and jumping, with potential for omnidirectional jumping with minor modifications."}}
{"id": "2510.24297", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24297", "abs": "https://arxiv.org/abs/2510.24297", "authors": ["Robin Schm\u00f6cker", "Alexander Dockhorn", "Bodo Rosenhahn"], "title": "Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms", "comment": null, "summary": "One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which\ncan be addressed by building and using state and/or action abstractions in\nparallel to the tree search such that information can be shared among nodes of\nthe same layer. The primary usage of abstractions for MCTS is to enhance the\nUpper Confidence Bound (UCB) value during the tree policy by aggregating visits\nand returns of an abstract node. However, this direct usage of abstractions\ndoes not take the case into account where multiple actions with the same parent\nmight be in the same abstract node, as these would then all have the same UCB\nvalue, thus requiring a tiebreak rule. In state-of-the-art abstraction\nalgorithms such as pruned On the Go Abstractions (pruned OGA), this case has\nnot been noticed, and a random tiebreak rule was implicitly chosen. In this\npaper, we propose and empirically evaluate several alternative\nintra-abstraction policies, several of which outperform the random policy\nacross a majority of environments and parameter settings.", "AI": {"tldr": "This work analyzes intra-abstraction policies for MCTS to fix tiebreak issues when multiple actions share an abstract node, showing several informed policies beat random tiebreaks in most environments and settings.", "motivation": "MCTS abstractions improve sample efficiency by sharing information, but existing tiebreak under MCTS abstractions (like pruned OGA) uses a random tie-break when multiple actions map to the same abstract node, potentially harming performance.", "method": "Propose several alternative intra-abstraction policies and empirically evaluate them against the baseline random tiebreak across multiple environments and parameter settings.", "result": "Some intra-abstraction policies outperform the random tiebreak in the majority of tested environments and parameter settings.", "conclusion": "Careful design of intra-abstraction tiebreak policies can improve MCTS performance and should be preferred over random tiebreaks in abstractions such as pruned OGA."}}
{"id": "2510.23667", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.23667", "abs": "https://arxiv.org/abs/2510.23667", "authors": ["Amin Heyrani Nobari", "Lyle Regenwetter", "Cyril Picard", "Ligong Han", "Faez Ahmed"], "title": "Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free Structural Topology Optimization", "comment": null, "summary": "Structural topology optimization (TO) is central to engineering design but\nremains computationally intensive due to complex physics and hard constraints.\nExisting deep-learning methods are limited to fixed square grids, a few\nhand-coded boundary conditions, and post-hoc optimization, preventing general\ndeployment. We introduce Optimize Any Topology (OAT), a foundation-model\nframework that directly predicts minimum-compliance layouts for arbitrary\naspect ratios, resolutions, volume fractions, loads, and fixtures. OAT combines\na resolution- and shape-agnostic autoencoder with an implicit neural-field\ndecoder and a conditional latent-diffusion model trained on OpenTO, a new\ncorpus of 2.2 million optimized structures covering 2 million unique\nboundary-condition configurations. On four public benchmarks and two\nchallenging unseen tests, OAT lowers mean compliance up to 90% relative to the\nbest prior models and delivers sub-1 second inference on a single GPU across\nresolutions from 64 x 64 to 256 x 256 and aspect ratios as high as 10:1. These\nresults establish OAT as a general, fast, and resolution-free framework for\nphysics-aware topology optimization and provide a large-scale dataset to spur\nfurther research in generative modeling for inverse design. Code & data can be\nfound at https://github.com/ahnobari/OptimizeAnyTopology.", "AI": {"tldr": "OAT is a foundation-model for topology optimization that directly predicts minimum-compliance layouts across arbitrary aspect ratios, resolutions, loads, and fixtures, using a resolution- and shape-agnostic autoencoder, an implicit neural-field decoder, and a conditional latent-diffusion model trained on a 2.2M-strong OpenTO dataset; it achieves up to 90% reduction in mean compliance, sub-1s GPU inference, and works from 64\u00d764 to 256\u00d7256 with aspect ratios up to 10:1.", "motivation": "TO is computationally intensive and traditionally restricted to fixed grids and limited boundary conditions. A general, fast, and flexible framework is needed to enable deployment across diverse designs without hand-tuning or post-hoc optimization.", "method": "The approach combines (1) a resolution- and shape-agnostic autoencoder to encode designs of varying size and aspect ratio, (2) an implicit neural-field decoder to map latent codes to topology fields, and (3) a conditional latent-diffusion model trained on OpenTO, a large corpus (2.2M optimized structures across 2M boundary-condition configurations), enabling generation conditioned on BCs. Outputs are prediction of minimum-compliance layouts across arbitrary specs and fast inference. Dataset and code released.", "result": "On four public benchmarks and two unseen tests, OAT lowers mean compliance up to 90% relative to the best prior models and achieves sub-1 second inference on a single GPU across resolutions 64\u00d764 to 256\u00d7256 and aspect ratios up to 10:1.", "conclusion": "OAT establishes a general, fast, and resolution-free framework for physics-aware topology optimization, and provides a large-scale dataset to spur further research in generative modeling for inverse design; code and data are publicly available."}}
{"id": "2510.24152", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24152", "abs": "https://arxiv.org/abs/2510.24152", "authors": ["Aodi Wu", "Xubo Luo"], "title": "Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning", "comment": "RoboSense Challenge with IROS 2025", "summary": "This technical report presents our solution for the RoboSense Challenge at\nIROS 2025, which evaluates Vision-Language Models (VLMs) on autonomous driving\nscene understanding across perception, prediction, planning, and corruption\ndetection tasks. We propose a systematic framework built on four core\ncomponents. First, a Mixture-of-Prompts router classifies questions and\ndispatches them to task-specific expert prompts, eliminating interference\nacross diverse question types. Second, task-specific prompts embed explicit\ncoordinate systems, spatial reasoning rules, role-playing,\nChain-of-Thought/Tree-of-Thought reasoning, and few-shot examples tailored to\neach task. Third, a visual assembly module composes multi-view images with\nobject crops, magenta markers, and adaptive historical frames based on question\nrequirements. Fourth, we configure model inference parameters (temperature,\ntop-p, message roles) per task to optimize output quality. Implemented on\nQwen2.5-VL-72B, our approach achieves 70.87% average accuracy on Phase-1 (clean\ndata) and 72.85% on Phase-2 (corrupted data), demonstrating that structured\nprompting and spatial grounding substantially enhance VLM performance on\nsafety-critical autonomous driving tasks. Code and prompt are available at\nhttps://github.com/wuaodi/UCAS-CSU-phase2.", "AI": {"tldr": "A four-component, prompt-driven VLM framework for autonomous driving evaluation that uses task-specific prompts, spatial grounding, and a visual assembly module, achieving ~71% average accuracy on both clean and corrupted data in RoboSense IROS 2025 challenges.", "motivation": "To enhance Vision-Language Models for safety-critical autonomous driving tasks by reducing prompt interference across diverse questions, incorporating explicit spatial reasoning, and improving robustness to data corruption.", "method": "1) Mixture-of-Prompts router to classify questions and route to task-specific prompts. 2) Task-specific prompts embedding coordinate systems, spatial rules, role-playing, chain-of-thought/tree-of-thought reasoning, and few-shot examples per task. 3) Visual assembly module composing multi-view images with object crops, magenta markers, and adaptive historical frames per question. 4) Per-task inference configuration (temperature, top-p, message roles). Implemented on Qwen2.5-VL-72B.", "result": "Achieves 70.87% average accuracy on Phase-1 (clean data) and 72.85% on Phase-2 (corrupted data). The results suggest that structured prompting and spatial grounding improve VLM performance in safety-critical autonomous-driving tasks.", "conclusion": "Structured, task-aware prompting plus spatial grounding can enhance VLM performance and robustness in autonomous driving contexts; the approach is reproducible with public code (GitHub link) and emphasizes careful prompt routing, per-task reasoning strategies, and multimodal input assembly."}}
{"id": "2510.24623", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24623", "abs": "https://arxiv.org/abs/2510.24623", "authors": ["Nicolai Steinke", "Daniel Goehring"], "title": "GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization", "comment": null, "summary": "In this letter, we introduce GroundLoc, a LiDAR-only localization pipeline\ndesigned to localize a mobile robot in large-scale outdoor environments using\nprior maps. GroundLoc employs a Bird's-Eye View (BEV) image projection focusing\non the perceived ground area and utilizes the place recognition network R2D2,\nor alternatively, the non-learning approach Scale-Invariant Feature Transform\n(SIFT), to identify and select keypoints for BEV image map registration. Our\nresults demonstrate that GroundLoc outperforms state-of-the-art methods on the\nSemanticKITTI and HeLiPR datasets across various sensors. In the multi-session\nlocalization evaluation, GroundLoc reaches an Average Trajectory Error (ATE)\nwell below 50 cm on all Ouster OS2 128 sequences while meeting online runtime\nrequirements. The system supports various sensor models, as evidenced by\nevaluations conducted with Velodyne HDL-64E, Ouster OS2 128, Aeva Aeries II,\nand Livox Avia sensors. The prior maps are stored as 2D raster image maps,\nwhich can be created from a single drive and require only 4 MB of storage per\nsquare kilometer. The source code is available at\nhttps://github.com/dcmlr/groundloc.", "AI": {"tldr": "GroundLoc is a LiDAR-only outdoor localization pipeline that projects LiDAR data into a BEV ground-focused map and uses R2D2 or SIFT to register 2D raster maps, achieving sub-50 cm ATE across multi-sensor setups and outperforming SOTA on SemanticKITTI/HeLiPR with compact maps.", "motivation": "Robust, scalable LiDAR-based localization in large outdoor environments using pre-built maps, while handling multi-sensor data and keeping map storage minimal. BEV ground projection and keypoint-based registration aim to improve accuracy and efficiency.", "method": "Project LiDAR into Bird's-Eye View ground-area BEV images; perform place recognition using R2D2 or classical SIFT to identify keypoints; register BEV map to prior 2D raster maps stored for each area; supports multiple sensors; maps are small (4 MB per km2) and can be created from a single drive.", "result": "Outperforms state-of-the-art on SemanticKITTI and HeLiPR across sensors; multi-session localization yields average trajectory error well below 50 cm on all Ouster OS2 128 sequences; online runtime satisfied.", "conclusion": "GroundLoc demonstrates accurate, efficient LiDAR-only localization with compact 2D raster priors, cross-sensor compatibility, and practical online performance, enabling scalable large-scale outdoor localization."}}
{"id": "2510.24299", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24299", "abs": "https://arxiv.org/abs/2510.24299", "authors": ["Jiayu Liu", "Wei Dai", "Zhenya Huang", "Ning Miao", "Enhong Chen"], "title": "Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank", "comment": null, "summary": "Despite the strong reasoning ability of large language models~(LLMs), they\nare prone to errors and hallucinations. As a result, how to check their outputs\neffectively and efficiently has become a critical problem in their\napplications. Existing checking methods heavily rely on external resources,\nsuch as trained verifiers (e.g., process/outcome reward models) or elaborate\nprompts, which lead to high computational overhead and are only applicable to\nspecific domains. In this paper, we investigate whether the internal behaviors\nof LLMs have already implied the credibility of their reasoning paths.\nSpecifically, we find that the rank of the correlation matrix between the input\nproblem and the output reasoning path is a robust indicator of reasoning\ncorrectness. Different from other correctness indicators for LLMs, the\ncalculation of the correlation matrix only relies on the LLM itself, which\navoids the hassle of training a separate model or designing complicated\nprompts. Based on it, we design a simple, plug-and-play Self-Indicator method\nto reweight candidate reasoning paths, which achieves significant performance\nimprovements than other voting and verification methods with very few\ncomputational overhead. Our experiments across multiple LLMs of varying scales\nand model families have further shown the effectiveness of Self-Indicator. It\nachieves over 75% accuracy in distinguishing correct reasoning paths from\nincorrect ones, and, in turn, improves the accuracies on three reasoning\nbenchmarks by more than 8%.", "AI": {"tldr": "Self-Indicator uses the rank of the correlation matrix between the input problem and the LLM's reasoning path as an internal credibility signal, reweighting candidate reasoning paths to improve correctness with low overhead.", "motivation": "Current verification methods rely on external verifiers or elaborate prompts, which are computationally expensive and domain-specific. There is a need for a lightweight, internal cue derived from the LLM's own behavior.", "method": "Compute the correlation matrix between the input problem and each candidate reasoning path; take the rank as a robust indicator of reasoning correctness; plug-and-play Self-Indicator reweights candidate paths based on this indicator, avoiding training a separate verifier.", "result": "The approach achieves over 75% accuracy in distinguishing correct versus incorrect reasoning paths and improves the accuracies on three reasoning benchmarks by more than 8%, across multiple LLMs and model families.", "conclusion": "Self-Indicator provides a simple, efficient, and domain-agnostic mechanism to assess and improve LLM reasoning without external verifiers, showing robust performance across models."}}
{"id": "2510.23668", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23668", "abs": "https://arxiv.org/abs/2510.23668", "authors": ["Fujiang Yuan", "Yangrui Fan", "Xiaohuan Bing", "Zhen Tian", "Chunhong Yuan", "Yankang Li"], "title": "Traffic flow forecasting, STL decomposition, Hybrid model, LSTM, ARIMA, XGBoost, Intelligent transportation systems", "comment": null, "summary": "Accurate traffic flow forecasting is essential for intelligent transportation\nsystems and urban traffic management. However, single model approaches often\nfail to capture the complex, nonlinear, and multi scale temporal patterns in\ntraffic flow data. This study proposes a decomposition driven hybrid framework\nthat integrates Seasonal Trend decomposition using Loess (STL) with three\ncomplementary predictive models. STL first decomposes the original time series\ninto trend, seasonal, and residual components. Then, a Long Short Term Memory\n(LSTM) network models long term trends, an Autoregressive Integrated Moving\nAverage (ARIMA) model captures seasonal periodicity, and an Extreme Gradient\nBoosting (XGBoost) algorithm predicts nonlinear residual fluctuations. The\nfinal forecast is obtained through multiplicative integration of the sub model\npredictions. Using 998 traffic flow records from a New York City intersection\nbetween November and December 2015, results show that the LSTM ARIMA XGBoost\nhybrid model significantly outperforms standalone models including LSTM, ARIMA,\nand XGBoost across MAE, RMSE, and R squared metrics. The decomposition strategy\neffectively isolates temporal characteristics, allowing each model to\nspecialize, thereby improving prediction accuracy, interpretability, and\nrobustness.", "AI": {"tldr": "A STL-driven hybrid traffic Forecast framework uses LSTM for trend, ARIMA for seasonality, and XGBoost for residuals, aggregated multiplicatively to improve accuracy.", "motivation": "Accurate traffic forecasting is essential for ITS; single-model approaches struggle with nonlinear, multiscale temporal patterns in traffic data, necessitating decomposition and model specialization.", "method": "Decompose the time series with STL into trend, seasonal, and residual components. Train LSTM on the trend, ARIMA on the seasonal component, and XGBoost on the residuals. Combine predictions multiplicatively to obtain the final forecast. Dataset: 998 traffic-flow records from a NYC intersection (Nov\u2013Dec 2015).", "result": "The hybrid LSTM-ARIMA-XGBoost model significantly outperforms individual models (LSTM, ARIMA, XGBoost) across MAE, RMSE, and R^2 metrics.", "conclusion": "Decomposition isolates temporal characteristics, allowing model specialization, which enhances accuracy, interpretability, and robustness; the approach is promising for multiscale time-series forecasting in traffic and potentially other domains."}}
{"id": "2510.24195", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24195", "abs": "https://arxiv.org/abs/2510.24195", "authors": ["Ziqi Zhou", "Yifan Hu", "Yufei Song", "Zijing Li", "Shengshan Hu", "Leo Yu Zhang", "Dezhong Yao", "Long Zheng", "Hai Jin"], "title": "Vanish into Thin Air: Cross-prompt Universal Adversarial Attacks for SAM2", "comment": "Accepted by NeurIPS 2025", "summary": "Recent studies reveal the vulnerability of the image segmentation foundation\nmodel SAM to adversarial examples. Its successor, SAM2, has attracted\nsignificant attention due to its strong generalization capability in video\nsegmentation. However, its robustness remains unexplored, and it is unclear\nwhether existing attacks on SAM can be directly transferred to SAM2. In this\npaper, we first analyze the performance gap of existing attacks between SAM and\nSAM2 and highlight two key challenges arising from their architectural\ndifferences: directional guidance from the prompt and semantic entanglement\nacross consecutive frames. To address these issues, we propose UAP-SAM2, the\nfirst cross-prompt universal adversarial attack against SAM2 driven by dual\nsemantic deviation. For cross-prompt transferability, we begin by designing a\ntarget-scanning strategy that divides each frame into k regions, each randomly\nassigned a prompt, to reduce prompt dependency during optimization. For\neffectiveness, we design a dual semantic deviation framework that optimizes a\nUAP by distorting the semantics within the current frame and disrupting the\nsemantic consistency across consecutive frames. Extensive experiments on six\ndatasets across two segmentation tasks demonstrate the effectiveness of the\nproposed method for SAM2. The comparative results show that UAP-SAM2\nsignificantly outperforms state-of-the-art (SOTA) attacks by a large margin.", "AI": {"tldr": "Introduces UAP-SAM2, a cross-prompt universal adversarial attack for SAM2 that uses dual semantic deviation to attack both within-frame semantics and cross-frame temporal consistency, achieving superior transferability and effectiveness across six datasets.", "motivation": "SAM2\u2019s robustness and cross-model attack transferability are not well understood. The key architectural differences\u2014prompt-driven directional guidance and semantic entanglement across frames\u2014pose unique challenges not addressed by existing SAM attacks.", "method": "Propose UAP-SAM2 with a cross-prompt target-scanning strategy that splits each frame into k regions with randomly assigned prompts to reduce prompt dependency. Introduce a dual semantic deviation framework to craft a universal perturbation that distorts intra-frame semantics and disrupts inter-frame semantic consistency.", "result": "Extensive experiments on six datasets across two segmentation tasks demonstrate that UAP-SAM2 significantly outperforms state-of-the-art attacks.", "conclusion": "UAP-SAM2 reveals and exploits vulnerabilities in SAM2 by addressing both cross-prompt transferability and temporal semantic entanglement, showing strong effectiveness and raising robustness concerns for SAM2 in video segmentation."}}
{"id": "2510.24671", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24671", "abs": "https://arxiv.org/abs/2510.24671", "authors": ["Li Li", "Tobias Brinkmann", "Till Temmen", "Markus Eisenbarth", "Jakob Andert"], "title": "Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder", "comment": null, "summary": "With the increasing integration of intelligent driving functions into\nserial-produced vehicles, ensuring their functionality and robustness poses\ngreater challenges. Compared to traditional road testing, scenario-based\nvirtual testing offers significant advantages in terms of time and cost\nefficiency, reproducibility, and exploration of edge cases. We propose a\nTransformer-enhanced Conditional Variational Autoencoder (CVAE-T) model for\ngenerating multi-agent traffic scenarios in roundabouts, which are\ncharacterized by high vehicle dynamics and complex layouts, yet remain\nrelatively underexplored in current research. The results show that the\nproposed model can accurately reconstruct original scenarios and generate\nrealistic, diverse synthetic scenarios. Besides, two Key-Performance-Indicators\n(KPIs) are employed to evaluate the interactive behavior in the generated\nscenarios. Analysis of the latent space reveals partial disentanglement, with\nseveral latent dimensions exhibiting distinct and interpretable effects on\nscenario attributes such as vehicle entry timing, exit timing, and velocity\nprofiles. The results demonstrate the model's capability to generate scenarios\nfor the validation of intelligent driving functions involving multi-agent\ninteractions, as well as to augment data for their development and iterative\nimprovement.", "AI": {"tldr": "Transformer-enhanced CVAE (CVAE-T) generates multi-agent roundabout traffic scenarios; achieves accurate reconstruction and realistic, diverse synthetic data with partially disentangled latent factors influencing entry/exit timing and velocity; supports validation of intelligent driving functions and data augmentation.", "motivation": "To enable efficient, reproducible, and comprehensive scenario-based testing for intelligent driving functions, especially in challenging roundabout environments with rich dynamics that are underexplored in current research.", "method": "Develop a Transformer-enhanced Conditional Variational Autoencoder (CVAE-T) to model multi-agent roundabout traffic scenarios. The model learns a latent representation conditioned on context to generate diverse scenarios. It evaluates interactive behavior using two KPIs and analyzes latent space for disentanglement, linking certain latent dimensions to attributes like entry timing, exit timing, and velocity profiles.", "result": "The CVAE-T accurately reconstructs original scenarios and generates realistic, diverse synthetic scenarios. KPIs indicate meaningful interactive behavior in generated data. Latent space shows partial disentanglement, with some dimensions affecting entry timing, exit timing, and velocity, enabling controlled scenario generation.", "conclusion": "CVAE-T is effective for validating intelligent driving functions involving multi-agent interactions in roundabouts and can augment data for development and iterative improvement of automated driving systems."}}
{"id": "2510.24303", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24303", "abs": "https://arxiv.org/abs/2510.24303", "authors": ["Deniz Gorur", "Antoni Rago", "Francesca Toni"], "title": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting", "comment": null, "summary": "Judgmental forecasting is the task of making predictions about future events\nbased on human judgment. This task can be seen as a form of claim verification,\nwhere the claim corresponds to a future event and the task is to assess the\nplausibility of that event. In this paper, we propose a novel multi-agent\nframework for claim verification, whereby different agents may disagree on\nclaim veracity and bring specific evidence for and against the claims,\nrepresented as quantitative bipolar argumentation frameworks (QBAFs). We then\ninstantiate the framework for supporting claim verification, with a variety of\nagents realised with Large Language Models (LLMs): (1) ArgLLM agents, an\nexisting approach for claim verification that generates and evaluates QBAFs;\n(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)\nfrom external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,\nextending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of\narguments from external sources. Finally, we conduct experiments with two\nstandard judgmental forecasting datasets, with instances of our framework with\ntwo or three agents, empowered by six different base LLMs. We observe that\ncombining evidence from agents can improve forecasting accuracy, especially in\nthe case of three agents, while providing an explainable combination of\nevidence for claim verification.", "AI": {"tldr": "A multi-agent, LLM-based claim verification framework uses quantitative bipolar argumentation frameworks (QBAFs) to aggregate diverse evidence from ArgLLM, RbAM, and RAG-ArgLLM agents. Experiments on judgmental forecasting datasets show that combining three agents improves forecast accuracy and provides explainable evidence integration.", "motivation": "Judgmental forecasting can be framed as claim verification; disagreements among agents can be harnessed with structured evidence to improve accuracy and transparency. QBAFs offer a principled way to represent for/against arguments from multiple sources.", "method": "Propose a multi-agent framework where agents generate QBAFs for claims. Instantiate with three agent types: ArgLLM (existing claim verification via QBAFs), RbAM (LLM-powered relation-based argument mining from external sources), and RAG-ArgLLM (ArgLLM enhanced with Retrieval-Augmented Generation). Evaluate on two standard judgmental forecasting datasets using two to three agents and six base LLMs. Assess forecast accuracy and explainability of the evidence fusion.", "result": "Combining evidence across agents improves forecasting accuracy, especially with three agents; the approach yields an explainable combination of evidence for claim verification.", "conclusion": "A multi-agent QBAF-based framework is a promising approach for claim verification in judgmental forecasting, leveraging diverse LLMs and external sources to boost accuracy and provide transparent, explainable evidence fusion."}}
{"id": "2510.23671", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23671", "abs": "https://arxiv.org/abs/2510.23671", "authors": ["Marmik Chaudhari", "Jeremi Nuer", "Rome Thorstenson"], "title": "Sparsity and Superposition in Mixture of Experts", "comment": null, "summary": "Mixture of Experts (MoE) models have become central to scaling large language\nmodels, yet their mechanistic differences from dense networks remain poorly\nunderstood. Previous work has explored how dense models use\n\\textit{superposition} to represent more features than dimensions, and how\nsuperposition is a function of feature sparsity and feature importance. MoE\nmodels cannot be explained mechanistically through the same lens. We find that\nneither feature sparsity nor feature importance cause discontinuous phase\nchanges, and that network sparsity (the ratio of active to total experts)\nbetter characterizes MoEs. We develop new metrics for measuring superposition\nacross experts. Our findings demonstrate that models with greater network\nsparsity exhibit greater \\emph{monosemanticity}. We propose a new definition of\nexpert specialization based on monosemantic feature representation rather than\nload balancing, showing that experts naturally organize around coherent feature\ncombinations when initialized appropriately. These results suggest that network\nsparsity in MoEs may enable more interpretable models without sacrificing\nperformance, challenging the common assumption that interpretability and\ncapability are fundamentally at odds.", "AI": {"tldr": "MoE models differ mechanistically from dense networks; network sparsity\u2014active-to-total-expert ratio\u2014drives their behavior and interpretability more than feature sparsity or importance; higher sparsity yields greater monosemanticity and coherent feature specialization.", "motivation": "Understand how MoE models operate mechanistically and whether sparsity can improve interpretability without sacrificing performance, addressing gaps in how MoEs differ from dense networks.", "method": "Develop new metrics to measure superposition across experts; analyze how feature sparsity, feature importance, and network sparsity relate to phase changes; empirically study MoEs and initialization effects to observe expert organization around feature coalitions.", "result": "Network sparsity better characterizes MoEs than feature sparsity/importance; models with greater sparsity show higher monosemanticity; introduce monosemantic-feature-based expert specialization and observe natural grouping of experts around coherent feature combinations when initialized appropriately.", "conclusion": "Increasing network sparsity in MoEs may yield more interpretable models without sacrificing performance, challenging the common belief that interpretability and capability are inherently at odds."}}
{"id": "2510.24202", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24202", "abs": "https://arxiv.org/abs/2510.24202", "authors": ["Anshul Kaushal", "Kunal Jangid", "Vinod K. Kurmi"], "title": "CLFSeg: A Fuzzy-Logic based Solution for Boundary Clarity and Uncertainty Reduction in Medical Image Segmentation", "comment": "The 36th British Machine Vision Conference (BMVC) 2025", "summary": "Accurate polyp and cardiac segmentation for early detection and treatment is\nessential for the diagnosis and treatment planning of cancer-like diseases.\nTraditional convolutional neural network (CNN) based models have represented\nlimited generalizability, robustness, and inability to handle uncertainty,\nwhich affects the segmentation performance. To solve these problems, this paper\nintroduces CLFSeg, an encoder-decoder based framework that aggregates the\nFuzzy-Convolutional (FC) module leveraging convolutional layers and fuzzy\nlogic. This module enhances the segmentation performance by identifying local\nand global features while minimizing the uncertainty, noise, and ambiguity in\nboundary regions, ensuring computing efficiency. In order to handle class\nimbalance problem while focusing on the areas of interest with tiny and\nboundary regions, binary cross-entropy (BCE) with dice loss is incorporated.\nOur proposed model exhibits exceptional performance on four publicly available\ndatasets, including CVC-ColonDB, CVC-ClinicDB, EtisLaribPolypDB, and ACDC.\nExtensive experiments and visual studies show CLFSeg surpasses the existing\nSOTA performance and focuses on relevant regions of interest in anatomical\nstructures. The proposed CLFSeg improves performance while ensuring computing\nefficiency, which makes it a potential solution for real-world medical\ndiagnostic scenarios. Project page is available at\nhttps://visdomlab.github.io/CLFSeg/", "AI": {"tldr": "CLFSeg is an encoder-decoder segmentation model that fuses a Fuzzy-Convolutional module with standard CNN layers to improve polyp and cardiac segmentation by reducing uncertainty, handling boundary regions, and addressing class imbalance, achieving state-of-the-art results on four public datasets with efficient computation.", "motivation": "Traditional CNN-based medical segmentation models struggle with generalizability, robustness, and uncertainty in boundary regions and noisy data. There is a need for a framework that can capture both local and global features while reducing ambiguity to enable reliable clinical decisions and enable real-world deployment.", "method": "CLFSeg uses an encoder-decoder architecture augmented with a Fuzzy-Convolutional (FC) module that blends convolutional layers with fuzzy logic to better identify local and global features and reduce boundary noise. It addresses class imbalance by using a combined Binary Cross-Entropy (BCE) and Dice loss. The approach emphasizes computational efficiency and focuses on tiny/boundary regions.", "result": "The model demonstrates exceptional performance on four public datasets (CVC-ColonDB, CVC-ClinicDB, EtisLaribPolypDB, ACDC), surpassing state-of-the-art methods and showing robustness and efficiency in identifying regions of interest.", "conclusion": "CLFSeg offers a robust, efficient solution for accurate polyp and cardiac segmentation, with strong potential for real-world clinical deployment and diagnostic support; a project page provides further details."}}
{"id": "2510.24676", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.24676", "abs": "https://arxiv.org/abs/2510.24676", "authors": ["Jiaxuan Zhang", "Yuquan Leng", "Yixuan Guo", "Chenglong Fu"], "title": "Feature Matching-Based Gait Phase Prediction for Obstacle Crossing Control of Powered Transfemoral Prosthesis", "comment": "6 pages, conference", "summary": "For amputees with powered transfemoral prosthetics, navigating obstacles or\ncomplex terrain remains challenging. This study addresses this issue by using\nan inertial sensor on the sound ankle to guide obstacle-crossing movements. A\ngenetic algorithm computes the optimal neural network structure to predict the\nrequired angles of the thigh and knee joints. A gait progression prediction\nalgorithm determines the actuation angle index for the prosthetic knee motor,\nultimately defining the necessary thigh and knee angles and gait progression.\nResults show that when the standard deviation of Gaussian noise added to the\nthigh angle data is less than 1, the method can effectively eliminate noise\ninterference, achieving 100\\% accuracy in gait phase estimation under 150 Hz,\nwith thigh angle prediction error being 8.71\\% and knee angle prediction error\nbeing 6.78\\%. These findings demonstrate the method's ability to accurately\npredict gait progression and joint angles, offering significant practical value\nfor obstacle negotiation in powered transfemoral prosthetics.", "AI": {"tldr": "Inertial-sensor-based obstacle negotiation for transfemoral prosthetics using a GA-optimized neural network and gait progression predictor to estimate thigh/knee angles and knee actuation, demonstrating noise robustness and high gait-phase accuracy.", "motivation": "Assist amputees with powered transfemoral prosthetics in navigating obstacles and complex terrain by accurately predicting joint angles and gait progression.", "method": "An inertial sensor is placed on the sound ankle to guide obstacle-crossing. A genetic algorithm optimizes the neural network structure predicting thigh/knee joint angles. A gait progression prediction algorithm determines the actuation angle index for the prosthetic knee motor, thereby defining thigh and knee angles and gait progression.", "result": "With Gaussian noise on thigh angle data having standard deviation < 1, the method effectively suppresses noise, achieving 100% gait-phase estimation accuracy at up to 150 Hz. Thigh angle prediction error: 8.71%; knee angle prediction error: 6.78%.", "conclusion": "The approach can accurately predict gait progression and joint angles, offering practical value for obstacle negotiation in powered transfemoral prosthetics."}}
{"id": "2510.24337", "categories": ["cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2510.24337", "abs": "https://arxiv.org/abs/2510.24337", "authors": ["Daria Kravets-Meinke", "Hannah Schmid-Petri", "Sonja Niemann", "Ute Schmid"], "title": "Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research", "comment": null, "summary": "Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly\nbeing used in communication research for content analysis. Studies show that\ngLLMs can outperform both crowd workers and trained coders, such as research\nassistants, on various coding tasks relevant to communication science, often at\na fraction of the time and cost. Additionally, gLLMs can decode implicit\nmeanings and contextual information, be instructed using natural language,\ndeployed with only basic programming skills, and require little to no annotated\ndata beyond a validation dataset - constituting a paradigm shift in automated\ncontent analysis. Despite their potential, the integration of gLLMs into the\nmethodological toolkit of communication research remains underdeveloped. In\ngLLM-assisted quantitative content analysis, researchers must address at least\nseven critical challenges that impact result quality: (1) codebook development,\n(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)\niterative refinement, (6) validation of the model's reliability, and\noptionally, (7) performance enhancement. This paper synthesizes emerging\nresearch on gLLM-assisted quantitative content analysis and proposes a\ncomprehensive best-practice guide to navigate these challenges. Our goal is to\nmake gLLM-based content analysis more accessible to a broader range of\ncommunication researchers and ensure adherence to established disciplinary\nquality standards of validity, reliability, reproducibility, and research\nethics.", "AI": {"tldr": "A synthesis and best-practice guide for employing generative LLMs in quantitative content analysis within communication research, addressing seven methodological challenges to improve validity, reliability, reproducibility, and ethics.", "motivation": "Leverage gLLMs' efficiency and ability to infer latent meaning, while addressing gaps in methodological integration and quality assurance.", "method": "Review of recent work on gLLM-assisted content analysis; analysis of seven challenges; proposition of best-practice guidelines and a decision framework.", "result": "A structured guide for researchers; recommended procedures for codebook development, prompting, model and parameter choices, iterative refinement, and validation; emphasis on ethics and replicability.", "conclusion": "gLLMs offer transformative potential for content analysis when integrated with rigorous methods and standards; adoption requires discipline-wide guidelines."}}
{"id": "2510.23672", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23672", "abs": "https://arxiv.org/abs/2510.23672", "authors": ["Xiangfei Qiu", "Xingjian Wu", "Hanyin Cheng", "Xvyuan Liu", "Chenjuan Guo", "Jilin Hu", "Bin Yang"], "title": "DBLoss: Decomposition-based Loss Function for Time Series Forecasting", "comment": "Accepted by NeurIPS 2025", "summary": "Time series forecasting holds significant value in various domains such as\neconomics, traffic, energy, and AIOps, as accurate predictions facilitate\ninformed decision-making. However, the existing Mean Squared Error (MSE) loss\nfunction sometimes fails to accurately capture the seasonality or trend within\nthe forecasting horizon, even when decomposition modules are used in the\nforward propagation to model the trend and seasonality separately. To address\nthese challenges, we propose a simple yet effective Decomposition-Based Loss\nfunction called DBLoss. This method uses exponential moving averages to\ndecompose the time series into seasonal and trend components within the\nforecasting horizon, and then calculates the loss for each of these components\nseparately, followed by weighting them. As a general loss function, DBLoss can\nbe combined with any deep learning forecasting model. Extensive experiments\ndemonstrate that DBLoss significantly improves the performance of\nstate-of-the-art models across diverse real-world datasets and provides a new\nperspective on the design of time series loss functions.", "AI": {"tldr": "Introduces DBLoss, a decomposition-based loss for time-series forecasting that uses exponential moving averages to split the horizon into seasonal and trend parts and computes a weighted sum of component losses, applicable to any forecasting model.", "motivation": "MSE often fails to capture horizon-specific seasonality or trend, even with forward-decomposition modules; a loss that explicitly targets these components can improve training alignment with forecasting objectives.", "method": "Within the forecasting horizon, apply EMA to obtain seasonal-like and trend-like components; compute losses for each component separately (e.g., component-wise MSE) and combine them with weights; DBLoss is model-agnostic and can be plugged into existing forecasting frameworks.", "result": "Empirical evaluation across diverse real-world datasets shows that DBLoss yields significant improvements over state-of-the-art models.", "conclusion": "DBLoss offers a simple, effective, and general approach to time-series loss design, providing a new perspective on decomposing and optimizing forecasting objectives."}}
{"id": "2510.24211", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24211", "abs": "https://arxiv.org/abs/2510.24211", "authors": ["Junhyuk So", "Hyunho Kook", "Chaeyeon Jang", "Eunhyeok Park"], "title": "MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive Visual Generation Acceleration", "comment": null, "summary": "While autoregressive (AR) modeling has recently emerged as a new paradigm in\nvisual generation, its practical adoption is severely constrained by the slow\ninference speed of per-token generation, which often requires thousands of\nsteps to produce a single sample. To address this challenge, we propose MC-SJD,\na training-free, lossless parallel decoding framework designed to accelerate AR\nvisual generation by extending the recently introduced Speculative Jacobi\nDecoding (SJD). Although SJD shows strong potential for accelerating AR\ngeneration, we demonstrate that token instability across iterations\nsignificantly reduces the acceptance rate, a limitation that primarily arises\nfrom the independent sampling process used during draft token generation. To\novercome this, we introduce MC-SJD, an information-theoretic approach based on\ncoupling, which substantially accelerates standard SJD by maximizing the\nprobability of sampling identical draft tokens across consecutive iterations,\nall while preserving its lossless property. Remarkably, this method requires\nonly a single-line modification to the existing algorithm, yet achieves\nsubstantial performance gains, delivering up to a ~4.2x acceleration in image\ngeneration and ~13.3x acceleration in video generation compared to standard AR\ndecoding, without any degradation in output quality.", "AI": {"tldr": "Training-free, lossless parallel decoding for autoregressive visual generation via MC-SJD; couples to increase draft-token consensus and achieves up to 4.2x image and 13.3x video speedups without quality loss.", "motivation": "Autoregressive visual generation suffers from slow per-token decoding; need faster, lossless decoding without retraining.", "method": "MC-SJD extends Speculative Jacobi Decoding using a coupling-based, information-theoretic approach to maximize identical draft tokens across iterations; a minimal one-line modification to SJD; training-free and lossless.", "result": "Delivers up to ~4.2x acceleration for image generation and ~13.3x for video generation over standard AR decoding, with no degradation in output quality.", "conclusion": "MC-SJD provides a simple, effective method to significantly accelerate AR-based visual generation while preserving output quality; potential broad impact on real-time or high-throughput generative systems."}}
{"id": "2510.24680", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24680", "abs": "https://arxiv.org/abs/2510.24680", "authors": ["Zishuo Wang", "Joel Loo", "David Hsu"], "title": "Fare: Failure Resilience in Learned Visual Navigation Control", "comment": null, "summary": "While imitation learning (IL) enables effective visual navigation, IL\npolicies are prone to unpredictable failures in out-of-distribution (OOD)\nscenarios. We advance the notion of failure-resilient policies, which not only\ndetect failures but also recover from them automatically. Failure recognition\nthat identifies the factors causing failure is key to informing recovery: e.g.\npinpointing image regions triggering failure detections can provide cues to\nguide recovery. We present Fare, a framework to construct failure-resilient IL\npolicies, embedding OOD-detection and recognition in them without using\nexplicit failure data, and pairing them with recovery heuristics. Real-world\nexperiments show that Fare enables failure recovery across two different policy\narchitectures, enabling robust long-range navigation in complex environments.", "AI": {"tldr": "Fare enables failure-resilient imitation learning by integrating OOD detection and failure recognition with recovery heuristics, allowing policies to detect and recover from out-of-distribution failures without explicit failure data, improving long-range navigation.", "motivation": "IL policies often fail in out-of-distribution scenarios; there is a need to detect, understand, and automatically recover from such failures to achieve robust navigation.", "method": "Introduce the Fare framework that embeds OOD-detection and failure recognition within imitation learning and pairs them with recovery heuristics. Notably, it does not require explicit failure data. The framework is validated on real-world experiments across two policy architectures to demonstrate cross-architecture failure recovery.", "result": "Fare enables failure recovery across two policy architectures and improves robustness for long-range navigation in complex environments, demonstrating effective handling of OOD failures without explicit failure data.", "conclusion": "Fare provides a practical pathway to building failure-resilient IL policies by coupling OOD detection/recognition with recovery heuristics, enabling robust real-world navigation."}}
{"id": "2510.24339", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24339", "abs": "https://arxiv.org/abs/2510.24339", "authors": ["Yunxuan Jiang", "Silan Hu", "Xiaoning Wang", "Yuanyuan Zhang", "Xiangyu Chang"], "title": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation", "comment": "29 pages, 6 figures. Yunxuan Jiang and Silan Hu contributed equally.\n  Code available at https://github.com/fengzer/VDSAgents", "summary": "Large language models (LLMs) become increasingly integrated into data science\nworkflows for automated system design. However, these LLM-driven data science\nsystems rely solely on the internal reasoning of LLMs, lacking guidance from\nscientific and theoretical principles. This limits their trustworthiness and\nrobustness, especially when dealing with noisy and complex real-world datasets.\nThis paper provides VDSAgents, a multi-agent system grounded in the\nPredictability-Computability-Stability (PCS) principles proposed in the\nVeridical Data Science (VDS) framework. Guided by PCS principles, the system\nimplements a modular workflow for data cleaning, feature engineering, modeling,\nand evaluation. Each phase is handled by an elegant agent, incorporating\nperturbation analysis, unit testing, and model validation to ensure both\nfunctionality and scientific auditability. We evaluate VDSAgents on nine\ndatasets with diverse characteristics, comparing it with state-of-the-art\nend-to-end data science systems, such as AutoKaggle and DataInterpreter, using\nDeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the\nresults of AutoKaggle and DataInterpreter, which validates the feasibility of\nembedding PCS principles into LLM-driven data science automation.", "AI": {"tldr": "VDSAgents is a PCS-guided multi-agent data science system that modularly handles cleaning, feature engineering, modeling, and evaluation, with perturbation analysis, unit testing, and model validation; it outperforms AutoKaggle and DataInterpreter on nine datasets using GPT-4o/DeepSeek-V3.", "motivation": "To inject scientific principles (predictability, computability, stability) into LLM-driven data science to improve trustworthiness and robustness on noisy real-world data.", "method": "A modular, multi-agent workflow guided by PCS; each phase managed by a specialized agent, incorporating perturbation analysis, unit tests, and model validation; evaluation against baselines (AutoKaggle, DataInterpreter) using DeepSeek-V3 and GPT-4o backends.", "result": "VDSAgents consistently outperforms AutoKaggle and DataInterpreter on nine datasets, demonstrating feasibility of PCS-guided LLM-driven data science automation.", "conclusion": "Embedding PCS principles into LLM-driven data science pipelines enhances auditability, reliability, and robustness."}}
{"id": "2510.23681", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23681", "abs": "https://arxiv.org/abs/2510.23681", "authors": ["Carl Hvarfner", "David Eriksson", "Eytan Bakshy", "Max Balandat"], "title": "Informed Initialization for Bayesian Optimization and Active Learning", "comment": "28 pages", "summary": "Bayesian Optimization is a widely used method for optimizing expensive\nblack-box functions, relying on probabilistic surrogate models such as Gaussian\nProcesses. The quality of the surrogate model is crucial for good optimization\nperformance, especially in the few-shot setting where only a small number of\nbatches of points can be evaluated. In this setting, the initialization plays a\ncritical role in shaping the surrogate's predictive quality and guiding\nsubsequent optimization. Despite this, practitioners typically rely on\n(quasi-)random designs to cover the input space. However, such approaches\nneglect two key factors: (a) space-filling designs may not be desirable to\nreduce predictive uncertainty, and (b) efficient hyperparameter learning during\ninitialization is essential for high-quality prediction, which may conflict\nwith space-filling designs. To address these limitations, we propose\nHyperparameter-Informed Predictive Exploration (HIPE), a novel acquisition\nstrategy that balances predictive uncertainty reduction with hyperparameter\nlearning using information-theoretic principles. We derive a closed-form\nexpression for HIPE in the Gaussian Process setting and demonstrate its\neffectiveness through extensive experiments in active learning and few-shot BO.\nOur results show that HIPE outperforms standard initialization strategies in\nterms of predictive accuracy, hyperparameter identification, and subsequent\noptimization performance, particularly in large-batch, few-shot settings\nrelevant to many real-world Bayesian Optimization applications.", "AI": {"tldr": "HIPE is an information-theoretic acquisition for GP-based Bayesian Optimization that jointly prioritizes predictive uncertainty reduction and hyperparameter learning during initialization, with a closed-form expression and strong empirical gains in few-shot, large-batch settings.", "motivation": "In few-shot BO, initialization critically shapes the surrogate model's predictive quality and subsequent optimization, but standard (quasi-)random or space-filling designs may waste effort on uncertain regions or hinder hyperparameter learning.", "method": "Introduce Hyperparameter-Informed Predictive Exploration (HIPE), derive a closed-form GP acquisition balancing uncertainty reduction and hyperparameter learning via information theory, and evaluate in active learning and few-shot BO.", "result": "HIPE outperforms standard initialization strategies in predictive accuracy, hyperparameter identification, and optimization performance, especially for large-batch, few-shot scenarios.", "conclusion": "A principled initialization strategy that accounts for hyperparameter learning improves GP-based BO performance in scarce-data regimes and can enhance real-world BO applications."}}
{"id": "2510.24213", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24213", "abs": "https://arxiv.org/abs/2510.24213", "authors": ["Haoxin Yang", "Yihong Lin", "Jingdan Kang", "Xuemiao Xu", "Yue Li", "Cheng Xu", "Shengfeng He"], "title": "Beyond Inference Intervention: Identity-Decoupled Diffusion for Face Anonymization", "comment": null, "summary": "Face anonymization aims to conceal identity information while preserving\nnon-identity attributes. Mainstream diffusion models rely on inference-time\ninterventions such as negative guidance or energy-based optimization, which are\napplied post-training to suppress identity features. These interventions often\nintroduce distribution shifts and entangle identity with non-identity\nattributes, degrading visual fidelity and data utility. To address this, we\npropose \\textbf{ID\\textsuperscript{2}Face}, a training-centric anonymization\nframework that removes the need for inference-time optimization. The rationale\nof our method is to learn a structured latent space where identity and\nnon-identity information are explicitly disentangled, enabling direct and\ncontrollable anonymization at inference. To this end, we design a conditional\ndiffusion model with an identity-masked learning scheme. An Identity-Decoupled\nLatent Recomposer uses an Identity Variational Autoencoder to model identity\nfeatures, while non-identity attributes are extracted from same-identity pairs\nand aligned through bidirectional latent alignment. An Identity-Guided Latent\nHarmonizer then fuses these representations via soft-gating conditioned on\nnoisy feature prediction. The model is trained with a recomposition-based\nreconstruction loss to enforce disentanglement. At inference, anonymization is\nachieved by sampling a random identity vector from the learned identity space.\nTo further suppress identity leakage, we introduce an Orthogonal Identity\nMapping strategy that enforces orthogonality between sampled and source\nidentity vectors. Experiments demonstrate that ID\\textsuperscript{2}Face\noutperforms existing methods in visual quality, identity suppression, and\nutility preservation.", "AI": {"tldr": "ID^2Face is a training-centric face anonymization framework that learns a disentangled latent space for identity and non-identity features, enabling inference-time anonymization without post-hoc optimization; it uses an Identity-Decoupled Latent Recomposer, Identity-Guided Latent Harmonizer, and Orthogonal Identity Mapping, trained with a recomposition-based reconstruction loss to achieve better visual quality, stronger identity suppression, and preserved utility.", "motivation": "Inference-time interventions in diffusion models (e.g., negative guidance, energy-based methods) introduce distribution shifts, entangle identity with other attributes, and hurt fidelity. A training-centric approach aiming to disentangle identity from non-identity within the latent space can enable cleaner anonymization at inference.", "method": "Propose ID^2Face: a conditional diffusion model with an identity-masked learning scheme. Identity-Decoupled Latent Recomposer uses an Identity Variational Autoencoder to model identity features, while non-identity attributes come from same-identity pairs and are aligned through bidirectional latent alignment. Identity-Guided Latent Harmonizer fuses representations via soft-gating conditioned on noisy feature prediction. Trained with a recomposition-based reconstruction loss to enforce disentanglement. At inference, anonymization is achieved by sampling a random identity vector from the learned identity space. Orthogonal Identity Mapping enforces orthogonality between sampled and source identity vectors to suppress leakage.", "result": "Empirical results show that ID^2Face outperforms existing methods in visual quality, identity suppression, and utility preservation.", "conclusion": "A training-centric framework successfully disentangles identity from non-identity in a structured latent space, enabling direct anonymization at inference without costly post-training optimizations and providing stronger leakage suppression via orthogonal identity mapping."}}
{"id": "2510.24683", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24683", "abs": "https://arxiv.org/abs/2510.24683", "authors": ["Caleb Escobedo", "Nataliya Nechyporenko", "Shreyas Kadekodi", "Alessandro Roncone"], "title": "A Framework for the Systematic Evaluation of Obstacle Avoidance and Object-Aware Controllers", "comment": null, "summary": "Real-time control is an essential aspect of safe robot operation in the real\nworld with dynamic objects. We present a framework for the analysis of\nobject-aware controllers, methods for altering a robot's motion to anticipate\nand avoid possible collisions. This framework is focused on three design\nconsiderations: kinematics, motion profiles, and virtual constraints.\nAdditionally, the analysis in this work relies on verification of robot\nbehaviors using fundamental robot-obstacle experimental scenarios. To showcase\nthe effectiveness of our method we compare three representative object-aware\ncontrollers. The comparison uses metrics originating from the design\nconsiderations. From the analysis, we find that the design of object-aware\ncontrollers often lacks kinematic considerations, continuity of control points,\nand stability in movement profiles. We conclude that this framework can be used\nin the future to design, compare, and benchmark obstacle avoidance methods.", "AI": {"tldr": "A framework to analyze object-aware robot controllers for obstacle avoidance focusing on kinematics, motion profiles, and virtual constraints; evaluates three controllers and highlights gaps; aims to enable design, comparison, and benchmarking of obstacle avoidance methods.", "motivation": "To ensure safe real-time operation of robots in dynamic environments by systematically evaluating how object-aware control strategies handle kinematics, timing, and constraints.", "method": "Proposes a framework built on three design considerations (kinematics, motion profiles, virtual constraints), uses verification via basic robot-obstacle experiments, and compares three representative object-aware controllers using metrics tied to these considerations.", "result": "The analysis shows that many object-aware controllers neglect kinematic considerations, continuity of control points, and stability in movement profiles; the framework successfully enables comparison and benchmarking.", "conclusion": "The framework can be used in future work to design, compare, and benchmark obstacle avoidance methods, guiding improvements in kinematic integration, control point continuity, and stable motion profiles."}}
{"id": "2510.24342", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24342", "abs": "https://arxiv.org/abs/2510.24342", "authors": ["Silin Chen", "Yuzhong Chen", "Zifan Wang", "Junhao Wang", "Zifeng Jia", "Keith M Kendrick", "Tuo Zhang", "Lin Zhao", "Dezhong Yao", "Tianming Liu", "Xi Jiang"], "title": "A Unified Geometric Space Bridging AI Models and the Human Brain", "comment": null, "summary": "For decades, neuroscientists and computer scientists have pursued a shared\nambition: to understand intelligence and build it. Modern artificial neural\nnetworks now rival humans in language, perception, and reasoning, yet it is\nstill largely unknown whether these artificial systems organize information as\nthe brain does. Existing brain-AI alignment studies have shown the striking\ncorrespondence between the two systems, but such comparisons remain bound to\nspecific inputs and tasks, offering no common ground for comparing how AI\nmodels with different kinds of modalities-vision, language, or multimodal-are\nintrinsically organized. Here we introduce a groundbreaking concept of\nBrain-like Space: a unified geometric space in which every AI model can be\nprecisely situated and compared by mapping its intrinsic spatial attention\ntopological organization onto canonical human functional brain networks,\nregardless of input modality, task, or sensory domain. Our extensive analysis\nof 151 Transformer-based models spanning state-of-the-art large vision models,\nlarge language models, and large multimodal models uncovers a continuous\narc-shaped geometry within this space, reflecting a gradual increase of\nbrain-likeness; different models exhibit distinct distribution patterns within\nthis geometry associated with different degrees of brain-likeness, shaped not\nmerely by their modality but by whether the pretraining paradigm emphasizes\nglobal semantic abstraction and whether the positional encoding scheme\nfacilitates deep fusion across different modalities. Moreover, the degree of\nbrain-likeness for a model and its downstream task performance are not\n\"identical twins\". The Brain-like Space provides the first unified framework\nfor situating, quantifying, and comparing intelligence across domains,\nrevealing the deep organizational principles that bridge machines and the\nbrain.", "AI": {"tldr": "", "motivation": "", "method": "", "result": "", "conclusion": ""}}
{"id": "2510.23682", "categories": ["cs.LG", "cs.AI", "cs.LO", "cs.SE", "I.2.11; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2510.23682", "abs": "https://arxiv.org/abs/2510.23682", "authors": ["Gokturk Aytug Akarlar"], "title": "Beyond Prompt Engineering: Neuro-Symbolic-Causal Architecture for Robust Multi-Objective AI Agents", "comment": "35 pages, 15 figures, 2 tables. Keywords: Large Language Models,\n  Autonomous Agents, Neuro-Symbolic AI, Causal Inference, Formal Verification,\n  Multi-Objective Optimization. Open-source code and interactive demo available", "summary": "Large language models show promise as autonomous decision-making agents, yet\ntheir deployment in high-stakes domains remains fraught with risk. Without\narchitectural safeguards, LLM agents exhibit catastrophic brittleness:\nidentical capabilities produce wildly different outcomes depending solely on\nprompt framing. We present Chimera, a neuro-symbolic-causal architecture that\nintegrates three complementary components - an LLM strategist, a formally\nverified symbolic constraint engine, and a causal inference module for\ncounterfactual reasoning. We benchmark Chimera against baseline architectures\n(LLM-only, LLM with symbolic constraints) across 52-week simulations in a\nrealistic e-commerce environment featuring price elasticity, trust dynamics,\nand seasonal demand. Under organizational biases toward either volume or margin\noptimization, LLM-only agents fail catastrophically (total loss of \\$99K in\nvolume scenarios) or destroy brand trust (-48.6% in margin scenarios). Adding\nsymbolic constraints prevents disasters but achieves only 43-87% of Chimera's\nprofit. Chimera consistently delivers the highest returns (\\$1.52M and \\$1.96M\nrespectively, some cases +\\$2.2M) while improving brand trust (+1.8% and\n+10.8%, some cases +20.86%), demonstrating prompt-agnostic robustness. Our TLA+\nformal verification proves zero constraint violations across all scenarios.\nThese results establish that architectural design not prompt engineering\ndetermines the reliability of autonomous agents in production environments. We\nprovide open-source implementations and interactive demonstrations for\nreproducibility.", "AI": {"tldr": "Chimera, a neuro-symbolic-causal architecture combining an LLM strategist, a formally verified symbolic constraint engine, and a causal inference module, yields robust autonomous decision-making in high-stakes e-commerce, outperforming LLM-only and LLM-with-constraints baselines and proven free of constraint violations via formal verification.", "motivation": "LLM agents in high-stakes domains suffer catastrophic brittleness and prompt-framing sensitivity; architectural safeguards are needed to ensure reliability and trust, not just better prompts.", "method": "Propose Chimera by integrating three components: (1) an LLM strategizer, (2) a formally verified symbolic constraint engine, and (3) a causal inference module for counterfactual reasoning. Benchmark against baselines (LLM-only, LLM with symbolic constraints) over 52 weeks in a realistic e-commerce environment with price elasticity, trust dynamics, and seasonal demand. Test under volume vs. margin optimization biases. Validate with TLA+ formal verification for constraint violations and provide open-source implementations and interactive demos.", "result": "LLM-only agents fail catastrophically under some bias (e.g., total loss of $99K in volume scenarios) or erode brand trust (\u221248.6% in margin scenarios). Adding symbolic constraints prevents disasters but yields only 43\u201387% of Chimera\u2019s profits. Chimera delivers the highest returns (approximately $1.52M for volume and $1.96M for margin scenarios, with some cases +$2.2M) and improves brand trust (+1.8%, +10.8%, up to +20.86%). Chimera demonstrates prompt-agnostic robustness across prompts. TLA+ formal verification reports zero constraint violations across all scenarios. Open-source implementations and demonstrations are provided for reproducibility.", "conclusion": "Architectural design choices, not prompt engineering, govern the reliability of autonomous agents in production-like settings. A neuro-symbolic-causal architecture can achieve higher profitability and trust while remaining robust to prompt variations; formal verification confirms safety constraints, and openness enables reproducibility."}}
{"id": "2510.24214", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24214", "abs": "https://arxiv.org/abs/2510.24214", "authors": ["Jinhong Deng", "Wen Li", "Joey Tianyi Zhou", "Yang He"], "title": "SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs", "comment": "NeurIPS 2025", "summary": "Multimodal Large Language Models (MLLMs) typically process a large number of\nvisual tokens, leading to considerable computational overhead, even though many\nof these tokens are redundant. Existing visual token pruning methods primarily\nfocus on selecting the most salient tokens based on attention scores, resulting\nin the semantic incompleteness of the selected tokens. In this paper, we\npropose a novel visual token pruning strategy, called\n\\textbf{S}aliency-\\textbf{C}overage \\textbf{O}riented token \\textbf{P}runing\nfor \\textbf{E}fficient MLLMs (SCOPE), to jointly model both the saliency and\ncoverage of the selected visual tokens to better preserve semantic\ncompleteness. Specifically, we introduce a set-coverage for a given set of\nselected tokens, computed based on the token relationships. We then define a\ntoken-coverage gain for each unselected token, quantifying how much additional\ncoverage would be obtained by including it. By integrating the saliency score\ninto the token-coverage gain, we propose our SCOPE score and iteratively select\nthe token with the highest SCOPE score. We conduct extensive experiments on\nmultiple vision-language understanding benchmarks using the LLaVA-1.5 and\nLLaVA-Next models. Experimental results demonstrate that our method\nconsistently outperforms prior approaches. Our code is available at\n\\href{https://github.com/kinredon/SCOPE}{https://github.com/kinredon/SCOPE}.", "AI": {"tldr": "SCOPE uses saliency-coverage to prune visual tokens in MLLMs, preserving semantic completeness while reducing computation, and outperforms prior pruning methods on LLaVA benchmarks.", "motivation": "To alleviate the high computational cost of processing dense visual tokens in multimodal LLMs while avoiding semantic incompleteness caused by token pruning.", "method": "Define a set-coverage over selected tokens based on token relationships, compute a token-coverage gain for each unselected token, integrate saliency into this gain to form the SCOPE score, and iteratively select the token with the highest score.", "result": "Extensive experiments on vision-language benchmarks with LLaVA-1.5 and LLaVA-Next show that SCOPE consistently outperforms prior token pruning approaches.", "conclusion": "SCOPE effectively balances saliency and coverage to preserve semantic completeness while reducing token count, enabling more efficient MLLMs; code is released."}}
{"id": "2510.24692", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24692", "abs": "https://arxiv.org/abs/2510.24692", "authors": ["Jun Wang", "Ziyang Zhou", "Ardalan Kahak", "Suyi Li"], "title": "Embodying Physical Computing into Soft Robots", "comment": null, "summary": "Softening and onboarding computers and controllers is one of the final\nfrontiers in soft robotics towards their robustness and intelligence for\neveryday use. In this regard, embodying soft and physical computing presents\nexciting potential. Physical computing seeks to encode inputs into a mechanical\ncomputing kernel and leverage the internal interactions among this kernel's\nconstituent elements to compute the output. Moreover, such input-to-output\nevolution can be re-programmable. This perspective paper proposes a framework\nfor embodying physical computing into soft robots and discusses three unique\nstrategies in the literature: analog oscillators, physical reservoir computing,\nand physical algorithmic computing. These embodied computers enable the soft\nrobot to perform complex behaviors that would otherwise require CMOS-based\nelectronics -- including coordinated locomotion with obstacle avoidance,\npayload weight and orientation classification, and programmable operation based\non logical rules. This paper will detail the working principles of these\nembodied physical computing methods, survey the current state-of-the-art, and\npresent a perspective for future development.", "AI": {"tldr": "Embodied physical computing in soft robots enables electronics-free, reprogrammable computation through analog oscillators, physical reservoir computing, and physical algorithmic computing to achieve complex behaviors like obstacle-avoidant locomotion and classification.", "motivation": "Address robustness and intelligence gaps in soft robots by embedding computation directly into their physical substrates, enabling reprogrammable, adaptive behaviors without relying on traditional CMOS electronics.", "method": "Proposes a framework for embedding physical computing in soft robots and surveys three strategies from the literature: analog oscillators, physical reservoir computing, and physical algorithmic computing, detailing how these embedded processors operate and interact with soft actuation/sensing.", "result": "Embodied computers enable soft robots to perform complex tasks\u2014e.g., obstacle-avoiding locomotion, payload/orientation classification, and logic-based programmability\u2014without conventional electronics; the paper surveys current state-of-the-art and outlines a future development trajectory.", "conclusion": "A perspective piece that articulates a framework for embodied physical computing in soft robotics, highlights three enabling strategies, and charts a roadmap for future research and development."}}
{"id": "2510.24359", "categories": ["cs.AI", "cs.SY", "eess.SY", "q-bio.QM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.24359", "abs": "https://arxiv.org/abs/2510.24359", "authors": ["Pedram Fard", "Alaleh Azhir", "Neguine Rezaii", "Jiazi Tian", "Hossein Estiri"], "title": "An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine", "comment": "This study has been supported by grants from the National Institutes\n  of Health: The National Institute on Aging R01AG074372 and The National\n  Institute of Allergy and Infectious Diseases R01AI165535", "summary": "Artificial intelligence in medicine is built to serve the average patient. By\nminimizing error across large datasets, most systems deliver strong aggregate\naccuracy yet falter at the margins: patients with rare variants,\nmultimorbidity, or underrepresented demographics. This average patient fallacy\nerodes both equity and trust. We propose a different design: a multi-agent\necosystem for N-of-1 decision support. In this environment, agents clustered by\norgan systems, patient populations, and analytic modalities draw on a shared\nlibrary of models and evidence synthesis tools. Their results converge in a\ncoordination layer that weighs reliability, uncertainty, and data density\nbefore presenting the clinician with a decision-support packet: risk estimates\nbounded by confidence ranges, outlier flags, and linked evidence. Validation\nshifts from population averages to individual reliability, measured by error in\nlow-density regions, calibration in the small, and risk--coverage trade-offs.\nAnticipated challenges include computational demands, automation bias, and\nregulatory fit, addressed through caching strategies, consensus checks, and\nadaptive trial frameworks. By moving from monolithic models to orchestrated\nintelligence, this approach seeks to align medical AI with the first principle\nof medicine: care that is transparent, equitable, and centered on the\nindividual.", "AI": {"tldr": "A multi-agent N-of-1 decision-support architecture for medical AI emphasizing individual reliability and equity, with organ-system/population/modality-agent clusters, a shared model/library, and a coordination layer delivering transparent, uncertainty-aware decision packets; validation focused on low-density regions; anticipated challenges include compute, automation bias, and regulatory fit.", "motivation": "Current AI in medicine optimizes aggregate accuracy but tends to perform poorly at the margins (rare variants, multimorbidity, underrepresented groups), eroding equity and trust. An individual-centered paradigm is needed.", "method": "Design of a multi-agent ecosystem where agents cluster by organ systems, patient populations, and analytic modalities. They draw on a shared library of models and evidence synthesis tools. A coordination layer weighs reliability, uncertainty, and data density to produce a clinician-facing decision-support packet with calibrated risk estimates, outlier flags, and linked evidence.", "result": "Conceptual framework and proposed validation strategy. Emphasis on evaluating individual reliability, calibration in small data regimes, and risk\u2013coverage trade-offs rather than population averages; no empirical results yet.", "conclusion": "Shifts from monolithic models to orchestrated intelligence to align medical AI with the core medical principle of care\u2014transparent, equitable, and centered on the individual\u2014while anticipating challenges like computation, automation bias, and regulatory alignment."}}
{"id": "2510.23685", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23685", "abs": "https://arxiv.org/abs/2510.23685", "authors": ["Junwen Ma", "Mingyu Ge", "Yisen Wang", "Yong Zhang", "Weicheng Fu"], "title": "Parallel BiLSTM-Transformer networks for forecasting chaotic dynamics", "comment": "9 pages,7 figures", "summary": "The nonlinear nature of chaotic systems results in extreme sensitivity to\ninitial conditions and highly intricate dynamical behaviors, posing fundamental\nchallenges for accurately predicting their evolution. To overcome the\nlimitation that conventional approaches fail to capture both local features and\nglobal dependencies in chaotic time series simultaneously, this study proposes\na parallel predictive framework integrating Transformer and Bidirectional Long\nShort-Term Memory (BiLSTM) networks. The hybrid model employs a dual-branch\narchitecture, where the Transformer branch mainly captures long-range\ndependencies while the BiLSTM branch focuses on extracting local temporal\nfeatures. The complementary representations from the two branches are fused in\na dedicated feature-fusion layer to enhance predictive accuracy. As\nillustrating examples, the model's performance is systematically evaluated on\ntwo representative tasks in the Lorenz system. The first is autonomous\nevolution prediction, in which the model recursively extrapolates system\ntrajectories from the time-delay embeddings of the state vector to evaluate\nlong-term tracking accuracy and stability. The second is inference of\nunmeasured variable, where the model reconstructs the unobserved states from\nthe time-delay embeddings of partial observations to assess its\nstate-completion capability. The results consistently indicate that the\nproposed hybrid framework outperforms both single-branch architectures across\ntasks, demonstrating its robustness and effectiveness in chaotic system\nprediction.", "AI": {"tldr": "A parallel Transformer-BiLSTM framework with a feature-fusion layer improves chaotic time-series prediction, outperforming single-branch models on Lorenz-system tasks.", "motivation": "Conventional approaches struggle to simultaneously capture local temporal features and global dependencies in chaotic time series, due to extreme sensitivity to initial conditions and complex dynamics.", "method": "A dual-branch architecture: one Transformer branch captures long-range dependencies; a BiLSTM branch captures local temporal features. Features from both branches are fused in a dedicated feature-fusion layer. Evaluated on Lorenz system tasks: autonomous evolution prediction (trajectory extrapolation from time-delay embeddings) and inference of unmeasured variables (state reconstruction from partial observations).", "result": "The hybrid Transformer-BiLSTM framework consistently outperforms single-branch architectures on both tasks, demonstrating robustness and effectiveness in chaotic system prediction.", "conclusion": "Integrating complementary representations from Transformer and BiLSTM via a fusion layer yields improved predictive accuracy for chaotic systems and effective state completion, validating the benefit of combining long-range and local features."}}
{"id": "2510.24231", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24231", "abs": "https://arxiv.org/abs/2510.24231", "authors": ["Waseem Shariff", "Timothy Hanley", "Maciej Stec", "Hossein Javidnia", "Peter Corcoran"], "title": "Benchmarking Microsaccade Recognition with Event Cameras: A Novel Dataset and Evaluation", "comment": "Accepted in British Machine Vision Conference (BMVC) 2025, Main\n  Conference", "summary": "Microsaccades are small, involuntary eye movements vital for visual\nperception and neural processing. Traditional microsaccade studies typically\nuse eye trackers or frame-based analysis, which, while precise, are costly and\nlimited in scalability and temporal resolution. Event-based sensing offers a\nhigh-speed, low-latency alternative by capturing fine-grained spatiotemporal\nchanges efficiently. This work introduces a pioneering event-based microsaccade\ndataset to support research on small eye movement dynamics in cognitive\ncomputing. Using Blender, we render high-fidelity eye movement scenarios and\nsimulate microsaccades with angular displacements from 0.5 to 2.0 degrees,\ndivided into seven distinct classes. These are converted to event streams using\nv2e, preserving the natural temporal dynamics of microsaccades, with durations\nranging from 0.25 ms to 2.25 ms. We evaluate the dataset using Spiking-VGG11,\nSpiking-VGG13, and Spiking-VGG16, and propose Spiking-VGG16Flow, an\noptical-flow-enhanced variant implemented in SpikingJelly. The models achieve\naround 90 percent average accuracy, successfully classifying microsaccades by\nangular displacement, independent of event count or duration. These results\ndemonstrate the potential of spiking neural networks for fine motion\nrecognition and establish a benchmark for event-based vision research. The\ndataset, code, and trained models will be publicly available at\nhttps://waseemshariff126.github.io/microsaccades/ .", "AI": {"tldr": "Introduces an event-based microsaccade dataset rendered with Blender, transformed into event streams via v2e, and evaluated with Spiking-VGG variants including an optical-flow-enhanced Spiking-VGG16Flow. Achieves ~90% average accuracy in classifying angular displacement across seven classes, independent of event count or duration, establishing a benchmark for event-based vision with spiking neural networks.", "motivation": "Traditional microsaccade research relies on eye trackers or frame-based methods that are precise but costly, less scalable, and limited in temporal resolution. Event-based sensing offers high-speed, low-latency data capture. There is a need for a public benchmark dataset and SNN-capable models to explore fine eye-movement dynamics in cognitive computing.", "method": "Create a synthetic microsaccade dataset using Blender to render high-fidelity eye movements. Simulate microsaccades with angular displacements from 0.5\u00b0 to 2.0\u00b0 across seven classes. Convert sequences to event streams using the v2e framework, preserving micro-temporal dynamics with durations from 0.25 ms to 2.25 ms. Evaluate on Spiking-VGG11/13/16, and propose Spiking-VGG16Flow (optical-flow-enhanced) implemented in SpikingJelly.", "result": "The models achieve around 90% average accuracy in classifying microsaccades by angular displacement, independent of event count or duration, demonstrating effective fine-motion recognition with spiking networks and establishing a benchmark for event-based vision research.", "conclusion": "This work demonstrates the feasibility and value of event-based datasets and spiking neural networks for precise, high-temporal-resolution motion analysis in microsaccades, and provides publicly available data, code, and trained models to advance research in cognitive computing."}}
{"id": "2510.24095", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24095", "abs": "https://arxiv.org/abs/2510.24095", "authors": ["Vedant Gupta", "Haotian Fu", "Calvin Luo", "Yiding Jiang", "George Konidaris"], "title": "Learning Parameterized Skills from Demonstrations", "comment": "Neurips 2025", "summary": "We present DEPS, an end-to-end algorithm for discovering parameterized skills\nfrom expert demonstrations. Our method learns parameterized skill policies\njointly with a meta-policy that selects the appropriate discrete skill and\ncontinuous parameters at each timestep. Using a combination of temporal\nvariational inference and information-theoretic regularization methods, we\naddress the challenge of degeneracy common in latent variable models, ensuring\nthat the learned skills are temporally extended, semantically meaningful, and\nadaptable. We empirically show that learning parameterized skills from\nmultitask expert demonstrations significantly improves generalization to unseen\ntasks. Our method outperforms multitask as well as skill learning baselines on\nboth LIBERO and MetaWorld benchmarks. We also demonstrate that DEPS discovers\ninterpretable parameterized skills, such as an object grasping skill whose\ncontinuous arguments define the grasp location.", "AI": {"tldr": "DEPS is an end-to-end method for discovering parameterized skills from expert demonstrations, learning skill policies and a meta-policy to select discrete skills and continuous parameters, using temporal variational inference and information-theoretic regularization to avoid latent degeneracy. It achieves strong generalization on LIBERO and MetaWorld and yields interpretable parameterized skills like grasp location parameterization.", "motivation": "There is a need to automatically discover reusable, parameterized skills from demonstrations with strong generalization to unseen tasks, while ensuring latent skills are temporally extended, semantically meaningful, and interpretable. This work also addresses degeneracy in latent-variable models.", "method": "An end-to-end algorithm (DEPS) that jointly learns parameterized skill policies and a meta-policy that selects the discrete skill and continuous parameters at each timestep. It uses temporal variational inference and information-theoretic regularization to mitigate latent degeneracy and produce temporally extended, meaningful, and adaptable skills, trained on multitask expert demonstrations.", "result": "DEPS outperforms multitask and skill learning baselines on LIBERO and MetaWorld benchmarks and discovers interpretable parameterized skills, such as an object grasping skill with continuous arguments defining the grasp location.", "conclusion": "DEPS provides a scalable, interpretable framework for discovering parameterized skills with strong generalization to unseen tasks and interpretable continuous arguments, validated on standard benchmarks."}}
{"id": "2510.24383", "categories": ["cs.AI", "cs.CY", "cs.MA", "I.2.11; I.2.1; I.2.4; K.4.1; K.4.3"], "pdf": "https://arxiv.org/pdf/2510.24383", "abs": "https://arxiv.org/abs/2510.24383", "authors": ["Juraj Mavra\u010di\u0107"], "title": "Policy Cards: Machine-Readable Runtime Governance for Autonomous AI Agents", "comment": "First published on 19/10/2025. Canonical archived record and DOI:\n  10.5281/zenodo.17391796", "summary": "Policy Cards are introduced as a machine-readable, deployment-layer standard\nfor expressing operational, regulatory, and ethical constraints for AI agents.\nThe Policy Card sits with the agent and enables it to follow required\nconstraints at runtime. It tells the agent what it must and must not do. As\nsuch, it becomes an integral part of the deployed agent. Policy Cards extend\nexisting transparency artifacts such as Model, Data, and System Cards by\ndefining a normative layer that encodes allow/deny rules, obligations,\nevidentiary requirements, and crosswalk mappings to assurance frameworks\nincluding NIST AI RMF, ISO/IEC 42001, and the EU AI Act. Each Policy Card can\nbe validated automatically, version-controlled, and linked to runtime\nenforcement or continuous-audit pipelines. The framework enables verifiable\ncompliance for autonomous agents, forming a foundation for distributed\nassurance in multi-agent ecosystems. Policy Cards provide a practical mechanism\nfor integrating high-level governance with hands-on engineering practice and\nenabling accountable autonomy at scale.", "AI": {"tldr": "Policy Cards provide a machine-readable governance layer that encodes constraints, obligations, and assurance mappings, enabling runtime enforcement, validation, and cross-framework compliance for AI agents.", "motivation": "There is a need for verifiable, enforceable governance at runtime to ensure AI agents comply with regulatory, ethical, and operational constraints across deployments and multi-agent ecosystems.", "method": "Introduce Policy Cards as a normative extension to existing transparency artifacts (Model/Data/System Cards). They encode allow/deny rules, obligations, evidentiary requirements, and crosswalk mappings to frameworks like NIST AI RMF, ISO/IEC 42001, and EU AI Act; support automatic validation, version control, and linkage to runtime enforcement and continuous audits; enable distributed assurance in multi-agent ecosystems.", "result": "A practical mechanism that makes governance actionable at deployment, enabling verifiable compliance, enforcement, and continuous auditing of autonomous agents; integrates governance with engineering practice and supports accountable autonomy at scale.", "conclusion": "Policy Cards offer a concrete bridge between high-level governance and hands-on engineering, facilitating trustworthy, scalable autonomous systems through a normative, machine-readable constraint layer."}}
{"id": "2510.23693", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.23693", "abs": "https://arxiv.org/abs/2510.23693", "authors": ["Joachim Baumann"], "title": "On the Societal Impact of Machine Learning", "comment": "PhD thesis", "summary": "This PhD thesis investigates the societal impact of machine learning (ML). ML\nincreasingly informs consequential decisions and recommendations, significantly\naffecting many aspects of our lives. As these data-driven systems are often\ndeveloped without explicit fairness considerations, they carry the risk of\ndiscriminatory effects. The contributions in this thesis enable more\nappropriate measurement of fairness in ML systems, systematic decomposition of\nML systems to anticipate bias dynamics, and effective interventions that reduce\nalgorithmic discrimination while maintaining system utility. I conclude by\ndiscussing ongoing challenges and future research directions as ML systems,\nincluding generative artificial intelligence, become increasingly integrated\ninto society. This work offers a foundation for ensuring that ML's societal\nimpact aligns with broader social values.", "AI": {"tldr": "Thesis on the societal impact of ML, focusing on fair measurement, bias decomposition, and interventions to curb discrimination while preserving utility; with future directions including generative AI.", "motivation": "The abstract identifies the risk that data-driven ML systems can produce discriminatory outcomes due to insufficient explicit fairness considerations, and underscores the need for measurement, decomposition, and interventions to align ML with social values.", "method": "Proposes (1) measurement frameworks for fairness in ML, (2) systematic decomposition of ML systems to understand bias dynamics, and (3) interventions to reduce discrimination without sacrificing utility.", "result": "A set of frameworks and methods enabling more accurate fairness assessment, bias analysis, and effective interventions that maintain system performance.", "conclusion": "Highlights ongoing challenges and outlines future research directions as ML, including generative AI, becomes more embedded in society, stressing the need to ensure ML aligns with broad social values."}}
{"id": "2510.24232", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24232", "abs": "https://arxiv.org/abs/2510.24232", "authors": ["Qing Zhao", "Weijian Deng", "Pengxu Wei", "ZiYi Dong", "Hannan Lu", "Xiangyang Ji", "Liang Lin"], "title": "Delving into Cascaded Instability: A Lipschitz Continuity View on Image Restoration and Object Detection Synergy", "comment": "NeurIPS 2025", "summary": "To improve detection robustness in adverse conditions (e.g., haze and low\nlight), image restoration is commonly applied as a pre-processing step to\nenhance image quality for the detector. However, the functional mismatch\nbetween restoration and detection networks can introduce instability and hinder\neffective integration -- an issue that remains underexplored. We revisit this\nlimitation through the lens of Lipschitz continuity, analyzing the functional\ndifferences between restoration and detection networks in both the input space\nand the parameter space. Our analysis shows that restoration networks perform\nsmooth, continuous transformations, while object detectors operate with\ndiscontinuous decision boundaries, making them highly sensitive to minor\nperturbations. This mismatch introduces instability in traditional cascade\nframeworks, where even imperceptible noise from restoration is amplified during\ndetection, disrupting gradient flow and hindering optimization. To address\nthis, we propose Lipschitz-regularized object detection (LROD), a simple yet\neffective framework that integrates image restoration directly into the\ndetector's feature learning, harmonizing the Lipschitz continuity of both tasks\nduring training. We implement this framework as Lipschitz-regularized YOLO\n(LR-YOLO), extending seamlessly to existing YOLO detectors. Extensive\nexperiments on haze and low-light benchmarks demonstrate that LR-YOLO\nconsistently improves detection stability, optimization smoothness, and overall\naccuracy.", "AI": {"tldr": "LR-YOLO is a Lipschitz-regularized detector that integrates image restoration into detector training to harmonize the Lipschitz properties of restoration and detection, improving robustness under haze and low-light conditions.", "motivation": "There is a functional mismatch between restoration (smooth transformations) and detection (highly discontinuous decision boundaries). This mismatch can cause instability, gradient-flow disruption, and poor optimization in cascade restoration-detection pipelines under adverse conditions.", "method": "Propose Lipschitz-regularized object detection (LROD) implemented as LR-YOLO, embedding restoration into the detector's feature learning and enforcing Lipschitz continuity to align both tasks. The approach is designed to extend to existing YOLO detectors.", "result": "Extensive experiments on haze and low-light benchmarks show that LR-YOLO improves detection stability, optimization smoothness, and overall accuracy compared to traditional cascaded pipelines.", "conclusion": "Aligning Lipschitz continuity between restoration and detection yields more stable and effective detection under adverse conditions; LR-YOLO is simple to implement and generalizes to existing YOLO detectors."}}
{"id": "2510.24390", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24390", "abs": "https://arxiv.org/abs/2510.24390", "authors": ["Xianjun Gao", "Jianchun Liu", "Hongli Xu", "Liusheng Huang"], "title": "Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion", "comment": null, "summary": "The integration of Large Language Models (LLMs) into real-time Web\napplications, such as AI-powered search and conversational agents, presents a\nfundamental Web infrastructure challenge: reconciling the demand for\nhigh-quality, complex reasoning with the stringent low-latency and\nhigh-throughput requirements of interactive services. Current LLM reasoning,\nhindered by computationally inefficient sequential generation and rigid\nreasoning strategies, creates a critical bottleneck for the Web services.\nExisting approaches typically optimize the LLM reasoning for either efficiency\nor quality but struggle to achieve both, and thus fail to meet the dual\nrequirements of modern Web platforms. To overcome these limitations, we propose\nOrion, a novel and efficient reasoning framework that enables dependency-aware\nquery decomposition and logic-parallel content expansion. Concretely, Orion\ndecomposes a single query reasoning process into two synergistic phases: (1)\n\\textit{key point generation}, which distills logically structured key points\nthrough retrieval-augmented few-shot prompting, and (2) \\textit{content\nparallel expansion}, which concurrently elaborates on these points based on a\ndependency graph to ensure logical consistency. Furthermore, Orion introduces a\npipeline scheduling mechanism that exploits the complementary computational\ncharacteristics of the two phases (generation imposes pressure on GPU computing\nand expansion stresses on GPU memory) across multiple queries, enabling\ncross-query parallelism and dramatically improving reasoning performance (\\ie,\nefficiency and quality). Experiments on diverse benchmarks show that Orion not\nonly delivers up to 4.33x higher token generation speed and 3.42x lower answer\nlatency over the baselines but also improves reasoning quality by up to 18.75%\nthrough explicitly modeling inter-point dependencies.", "AI": {"tldr": "Orion is a two-phase reasoning framework for real-time web apps that uses dependency-aware query decomposition and content-parallel expansion to achieve high-quality reasoning with low latency and high throughput.", "motivation": "There is a fundamental tension in real-time Web services between requiring high-quality, complex reasoning and meeting strict latency and throughput. Current LLM reasoning relies on sequential generation and rigid strategies, creating bottlenecks and forcing trade-offs between efficiency and quality.", "method": "Orion decomposes reasoning into two phases: (1) key point generation via retrieval-augmented few-shot prompting to distill structured key points, and (2) content parallel expansion that elaborates on these points in parallel following a dependency graph to preserve logical consistency. A pipeline scheduling mechanism balances GPU generation pressure and GPU memory usage, enabling cross-query parallelism across multiple queries.", "result": "Empirical results show Orion achieves up to 4.33x faster token generation, 3.42x lower answer latency, and up to 18.75% improvement in reasoning quality by explicitly modeling inter-point dependencies.", "conclusion": "Orion offers an efficient and high-quality reasoning framework for real-time Web services by combining dependency-aware query decomposition, parallel content expansion, and cross-query scheduling, addressing both latency and reasoning quality requirements."}}
{"id": "2510.23727", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23727", "abs": "https://arxiv.org/abs/2510.23727", "authors": ["Anisha Saha", "Varsha Suresh", "Timothy Hospedales", "Vera Demberg"], "title": "MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection", "comment": null, "summary": "Sarcasm is a specific type of irony which involves discerning what is said\nfrom what is meant. Detecting sarcasm depends not only on the literal content\nof an utterance but also on non-verbal cues such as speaker's tonality, facial\nexpressions and conversational context. However, current multimodal models\nstruggle with complex tasks like sarcasm detection, which require identifying\nrelevant cues across modalities and pragmatically reasoning over them to infer\nthe speaker's intention. To explore these limitations in VideoLMs, we introduce\nMUStReason, a diagnostic benchmark enriched with annotations of\nmodality-specific relevant cues and underlying reasoning steps to identify\nsarcastic intent. In addition to benchmarking sarcasm classification\nperformance in VideoLMs, using MUStReason we quantitatively and qualitatively\nevaluate the generated reasoning by disentangling the problem into perception\nand reasoning, we propose PragCoT, a framework that steers VideoLMs to focus on\nimplied intentions over literal meaning, a property core to detecting sarcasm.", "AI": {"tldr": "Introduces MUStReason, a diagnostic benchmark for sarcasm in Video-language models, with modality-specific cue annotations and reasoning steps; also proposes PragCoT to steer models toward inferred intent and analyzes perception vs reasoning.", "motivation": "Sarcasm detection relies on cross-modal cues and pragmatic inference; existing multimodal models struggle; need diagnostics to disentangle perception and reasoning; improve VideoLMs' ability to infer speaker intent.", "method": "Construct MUStReason with annotations of cues across modalities (tone, facial expressions, context) and underlying reasoning steps; perform classification benchmarking; quantitatively and qualitatively analyze model-generated reasoning by separating perceptual understanding from higher-level inference; introduce PragCoT prompting to emphasize implied intent.", "result": "MUStReason enables targeted evaluation of cue utilization and reasoning in VideoLMs; developers can dissect whether models focus on correct cues; PragCoT provides a mechanism to steer models toward implied intent; the study demonstrates the value of diagnostic benchmarks for sarcasm and reveals gaps in current models.", "conclusion": "The work provides a diagnostic benchmark and a prompting framework to improve sarcasm detection in VideoLMs, highlighting the importance of separating perception and reasoning, and guiding future research on cross-modal sarcasm and pragmatic inference."}}
{"id": "2510.24260", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24260", "abs": "https://arxiv.org/abs/2510.24260", "authors": ["Zhaotong Yang", "Yi Chen", "Yanying Li", "Shengfeng He", "Yangyang Xu", "Junyu Dong", "Jian Yang", "Yong Du"], "title": "DeshadowMamba: Deshadowing as 1D Sequential Similarity", "comment": null, "summary": "Recent deep models for image shadow removal often rely on attention-based\narchitectures to capture long-range dependencies. However, their fixed\nattention patterns tend to mix illumination cues from irrelevant regions,\nleading to distorted structures and inconsistent colors. In this work, we\nrevisit shadow removal from a sequence modeling perspective and explore the use\nof Mamba, a selective state space model that propagates global context through\ndirectional state transitions. These transitions yield an efficient global\nreceptive field while preserving positional continuity. Despite its potential,\ndirectly applying Mamba to image data is suboptimal, since it lacks awareness\nof shadow-non-shadow semantics and remains susceptible to color interference\nfrom nearby regions. To address these limitations, we propose CrossGate, a\ndirectional modulation mechanism that injects shadow-aware similarity into\nMamba's input gate, allowing selective integration of relevant context along\ntransition axes. To further ensure appearance fidelity, we introduce ColorShift\nregularization, a contrastive learning objective driven by global color\nstatistics. By synthesizing structured informative negatives, it guides the\nmodel to suppress color contamination and achieve robust color restoration.\nTogether, these components adapt sequence modeling to the structural integrity\nand chromatic consistency required for shadow removal. Extensive experiments on\npublic benchmarks demonstrate that DeshadowMamba achieves state-of-the-art\nvisual quality and strong quantitative performance.", "AI": {"tldr": "A shadow-removal framework (DeshadowMamba) combines a selective state-space model (Mamba) with CrossGate directional modulation and ColorShift regularization to achieve state-of-the-art performance by propagating global context while preserving structure and color fidelity.", "motivation": "Current attention-based shadow-removal models rely on fixed attention patterns that can mix illumination cues from irrelevant regions, causing structural distortion and color inconsistency. There is a need to exploit global context with preserved spatial continuity while being shadow-aware.", "method": "Replace standard attention with Mamba to propagate global context through directional state transitions. Introduce CrossGate, a directional modulation mechanism that injects shadow-aware similarity into Mamba's input gate to selectively incorporate relevant context along transition axes. Add ColorShift regularization, a contrastive objective driven by global color statistics, synthesizing structured informative negatives to suppress color contamination and improve color restoration.", "result": "Extensive experiments on public benchmarks show DeshadowMamba achieves state-of-the-art visual quality and strong quantitative performance, validating its effectiveness in maintaining structural integrity and chromatic consistency.", "conclusion": "Adapting sequence-modeling approaches to shadow removal can yield robust, high-fidelity restorations by ensuring effective global context propagation with shadow-aware gating and color-preserving regularization."}}
{"id": "2510.24399", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24399", "abs": "https://arxiv.org/abs/2510.24399", "authors": ["Toan Van Nguyen", "Rasmus G. K. Christiansen", "Dirk Kraft", "Leon Bodenhagen"], "title": "GenTrack: A New Generation of Multi-Object Tracking", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This paper introduces a novel multi-object tracking (MOT) method, dubbed\nGenTrack, whose main contributions include: a hybrid tracking approach\nemploying both stochastic and deterministic manners to robustly handle unknown\nand time-varying numbers of targets, particularly in maintaining target\nidentity (ID) consistency and managing nonlinear dynamics, leveraging particle\nswarm optimization (PSO) with some proposed fitness measures to guide\nstochastic particles toward their target distribution modes, enabling effective\ntracking even with weak and noisy object detectors, integration of social\ninteractions among targets to enhance PSO-guided particles as well as improve\ncontinuous updates of both strong (matched) and weak (unmatched) tracks,\nthereby reducing ID switches and track loss, especially during occlusions, a\nGenTrack-based redefined visual MOT baseline incorporating a comprehensive\nstate and observation model based on space consistency, appearance, detection\nconfidence, track penalties, and social scores for systematic and efficient\ntarget updates, and the first-ever publicly available source-code reference\nimplementation with minimal dependencies, featuring three variants, including\nGenTrack Basic, PSO, and PSO-Social, facilitating flexible reimplementation.\nExperimental results have shown that GenTrack provides superior performance on\nstandard benchmarks and real-world scenarios compared to state-of-the-art\ntrackers, with integrated implementations of baselines for fair comparison.\nPotential directions for future work are also discussed. The source-code\nreference implementations of both the proposed method and compared-trackers are\nprovided on GitHub: https://github.com/SDU-VelKoTek/GenTrack", "AI": {"tldr": "GenTrack presents a hybrid stochastic-deterministic multi-object tracking framework that uses PSO with custom fitness for robust ID maintenance under unknown/variable scene targets, enhanced by social interactions and a redefined MOT baseline; it provides public code with three variants, and shows superior performance over state-of-the-art trackers.", "motivation": "To address tracking with unknown/time-varying target counts, occlusions, weak detectors, and nonlinear dynamics while preserving ID consistency, by integrating stochastic optimization, social cues, and a comprehensive state/observation model.", "method": "A hybrid tracking approach combining stochastic PSO-guided particles and deterministic updates; fitness measures steer particles toward target distribution modes; incorporate social interactions among targets; redefine MOT baseline with space consistency, appearance, detection confidence, track penalties, and social scores; provide three variants (GenTrack Basic, PSO, PSO-Social); release public source code with minimal dependencies.", "result": "Empirical results show GenTrack achieves superior performance on standard benchmarks and real-world scenarios compared to state-of-the-art trackers; provides integrated baselines for fair comparison.", "conclusion": "GenTrack advances MOT by bridging stochastic optimization with social-informed tracking and a comprehensive model, with public code and directions for future work."}}
{"id": "2510.24397", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24397", "abs": "https://arxiv.org/abs/2510.24397", "authors": ["Jiarui Qin", "Yunjia Xi", "Junjie Huang", "Renting Rui", "Di Yin", "Weiwen Liu", "Yong Yu", "Weinan Zhang", "Xing Sun"], "title": "APTBench: Benchmarking Agentic Potential of Base LLMs During Pre-Training", "comment": "46 pages", "summary": "With the rapid development of LLM-based agents, there is a growing trend to\nincorporate agent-specific data into the pre-training stage of LLMs, aiming to\nbetter align LLMs with real-world autonomous task execution. However, current\npre-training benchmarks primarily focus on isolated and static skills, e.g.,\ncommon knowledge or mathematical/code reasoning, and fail to reflect model's\nagentic capabilities. On the other hand, agent benchmarks are typically\ndesigned for post-trained models, requiring multi-turn task execution abilities\nthat base models struggle to support. Thus, there is a compelling need for a\nbenchmark that can evaluate agentic potentials during pre-training and guide\nthe model training more effectively. To address this gap, we propose APTBench,\na framework that converts real-world agent tasks and successful trajectories\ninto multiple-choice or text completion questions tailored for base models. It\nfocuses on core agentic abilities, e.g., planning and action, and covers key\nagent scenarios, software engineering and deep research. Compared to existing\ngeneral-purpose benchmarks, APTBench offers a more predictive signal of a\nmodel's downstream performance as an agent, while remaining significantly more\nlightweight and cost-effective than full-scale, end-to-end agent evaluations\nafter post-training.", "AI": {"tldr": "APTBench is a lightweight pre-training benchmark that turns real-world agent tasks into multiple-choice or text-completion prompts to evaluate agentic potential during pre-training, aiming to better predict downstream agent performance with lower cost than post-training evaluations.", "motivation": "There is a gap between static pre-training benchmarks (focusing on isolated skills) and post-training agent benchmarks (requiring multi-turn skills). A predictive, lightweight tool is needed to guide pre-training toward developing agentic capabilities.", "method": "Convert real-world agent tasks and successful trajectories into multiple-choice or text-completion prompts tailored for base models, emphasizing planning and action across key agent domains such as software engineering and deep research.", "result": "The abstract proposes the framework and argues it provides a predictive signal of downstream agent performance and is more cost-effective than full post-training, but it does not report empirical results.", "conclusion": "APTBench fills a methodological gap by enabling evaluation of agentic potential during pre-training and guiding training to improve downstream agent performance while remaining lightweight compared with end-to-end post-training evaluations."}}
{"id": "2510.23751", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23751", "abs": "https://arxiv.org/abs/2510.23751", "authors": ["Ignavier Ng", "Patrick Bl\u00f6baum", "Siddharth Bhandari", "Kun Zhang", "Shiva Kasiviswanathan"], "title": "Debiasing Reward Models by Representation Learning with Guarantees", "comment": null, "summary": "Recent alignment techniques, such as reinforcement learning from human\nfeedback, have been widely adopted to align large language models with human\npreferences by learning and leveraging reward models. In practice, these models\noften exploit spurious correlations, involving, e.g., response length,\ndiscrimination, sycophancy, and conceptual bias, which is a problem that has\nreceived increasing attention. In this work, we propose a principled framework\nthat mitigates these biases in reward models while preserving the underlying\nfactors that reflect intended preferences. We first provide a formulation of\nthe data-generating process, assuming that the observed data (e.g., text) is\ngenerated from both spurious and non-spurious latent variables. We show that,\ninterestingly, these non-spurious latent variables can be theoretically\nidentified from data, regardless of whether a surrogate for the spurious latent\nvariables is available. This further inspires a practical method that uses\nvariational inference to recover these variables and leverages them to train\nreward models. Experiments on synthetic and real-world datasets demonstrate\nthat our method effectively mitigates spurious correlation issues and yields\nmore robust reward models.", "AI": {"tldr": "A principled variational framework to remove spurious correlations in reward models for RLHF by identifying non-spurious latent variables from data and using them to train more robust reward models.", "motivation": "RLHF reward models often exploit spurious correlations (e.g., response length, discrimination, sycophancy, bias), which can misalign models with true human preferences. The paper aims to disentangle spurious from genuine signals and show non-spurious factors are identifiable from data even without surrogates for spurious factors.", "method": "Formulate a data-generating process with both spurious and non-spurious latent variables; prove identifiability of non-spurious latents from data; propose variational inference to recover these latents and use them to train reward models that focus on genuine preferences.", "result": "Experiments on synthetic and real-world datasets show reduced reliance on spurious cues and improved robustness of reward models.", "conclusion": "The framework offers a principled approach to debias reward modeling in alignment tasks, with identifiability guarantees for non-spurious factors and a practical VI-based training method that preserves intended preferences."}}
{"id": "2510.24262", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24262", "abs": "https://arxiv.org/abs/2510.24262", "authors": ["Jiyu Guo", "Shuo Yang", "Yiming Huang", "Yancheng Long", "Xiaobo Xia", "Xiu Su", "Bo Zhao", "Zeke Xie", "Liqiang Nie"], "title": "UtilGen: Utility-Centric Generative Data Augmentation with Dual-Level Task Adaptation", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "Data augmentation using generative models has emerged as a powerful paradigm\nfor enhancing performance in computer vision tasks. However, most existing\naugmentation approaches primarily focus on optimizing intrinsic data attributes\n-- such as fidelity and diversity -- to generate visually high-quality\nsynthetic data, while often neglecting task-specific requirements. Yet, it is\nessential for data generators to account for the needs of downstream tasks, as\ntraining data requirements can vary significantly across different tasks and\nnetwork architectures. To address these limitations, we propose UtilGen, a\nnovel utility-centric data augmentation framework that adaptively optimizes the\ndata generation process to produce task-specific, high-utility training data\nvia downstream task feedback. Specifically, we first introduce a weight\nallocation network to evaluate the task-specific utility of each synthetic\nsample. Guided by these evaluations, UtilGen iteratively refines the data\ngeneration process using a dual-level optimization strategy to maximize the\nsynthetic data utility: (1) model-level optimization tailors the generative\nmodel to the downstream task, and (2) instance-level optimization adjusts\ngeneration policies -- such as prompt embeddings and initial noise -- at each\ngeneration round. Extensive experiments on eight benchmark datasets of varying\ncomplexity and granularity demonstrate that UtilGen consistently achieves\nsuperior performance, with an average accuracy improvement of 3.87% over\nprevious SOTA. Further analysis of data influence and distribution reveals that\nUtilGen produces more impactful and task-relevant synthetic data, validating\nthe effectiveness of the paradigm shift from visual characteristics-centric to\ntask utility-centric data augmentation.", "AI": {"tldr": "A utility-centric data augmentation framework (UtilGen) optimizes synthetic data for downstream tasks using task feedback, achieving ~3.87% average accuracy gain over SOTA across eight benchmarks.", "motivation": "While most augmentation methods optimize visual fidelity and diversity, they ignore task-specific needs; different tasks and architectures require different data distributions; there is a gap to align augmentation with downstream utility.", "method": "Introduces a weight allocation network to estimate per-sample utility; uses dual-level optimization: model-level to tailor the generator to the task, and instance-level to adjust generation policies (e.g., prompt embeddings, initial noise) each round.", "result": "Empirical results show consistent performance gains; average accuracy improvement of 3.87% over previous SOTA across eight datasets; data influence analyses show synthetic data is more impactful and task-relevant when using UtilGen.", "conclusion": "Shifts augmentation paradigm from visual-centric to task-utility-centric data generation; UtilGen produces high-utility synthetic data that better supports downstream tasks."}}
{"id": "2510.24410", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24410", "abs": "https://arxiv.org/abs/2510.24410", "authors": ["Toan Van Nguyen", "Rasmus G. K. Christiansen", "Dirk Kraft", "Leon Bodenhagen"], "title": "A Hybrid Approach for Visual Multi-Object Tracking", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This paper proposes a visual multi-object tracking method that jointly\nemploys stochastic and deterministic mechanisms to ensure identifier\nconsistency for unknown and time-varying target numbers under nonlinear\ndynamics. A stochastic particle filter addresses nonlinear dynamics and\nnon-Gaussian noise, with support from particle swarm optimization (PSO) to\nguide particles toward state distribution modes and mitigate divergence through\nproposed fitness measures incorporating motion consistency, appearance\nsimilarity, and social-interaction cues with neighboring targets. Deterministic\nassociation further enforces identifier consistency via a proposed cost matrix\nincorporating spatial consistency between particles and current detections,\ndetection confidences, and track penalties. Subsequently, a novel scheme is\nproposed for the smooth updating of target states while preserving their\nidentities, particularly for weak tracks during interactions with other targets\nand prolonged occlusions. Moreover, velocity regression over past states\nprovides trend-seed velocities, enhancing particle sampling and state updates.\nThe proposed tracker is designed to operate flexibly for both pre-recorded\nvideos and camera live streams, where future frames are unavailable.\nExperimental results confirm superior performance compared to state-of-the-art\ntrackers. The source-code reference implementations of both the proposed method\nand compared-trackers are provided on GitHub:\nhttps://github.com/SDU-VelKoTek/GenTrack2", "AI": {"tldr": "A hybrid visual multi-object tracker that combines stochastic (particle filter with PSO-guided sampling) and deterministic data association to maintain consistent identities under unknown/variable target counts and nonlinear dynamics, with occlusion handling and velocity-informed sampling; claims state-of-the-art performance and provides open-source code.", "motivation": "To robustly track multiple targets when the number of targets is time-varying and unknown, dynamics are nonlinear and noisy, and identities must be preserved through occlusions and interactions.", "method": "Stochastic branch: particle filter for nonlinear, non-Gaussian dynamics; PSO guides particles toward distribution modes; novel fitness terms for motion consistency, appearance similarity, and social-interaction cues. Deterministic branch: a cost-based association using spatial consistency between particles and detections, detection confidences, and track penalties. Additional contributions: a smooth state-update scheme to preserve identities during weak or occluded tracks and velocity regression from past states to provide trend-based velocity seeds for better sampling. Applicable to both offline videos and live streams without future frames. Code available on GitHub.", "result": "Experimental results indicate superior performance over state-of-the-art trackers; open-source reference implementations provided.", "conclusion": "The proposed hybrid stochastic-deterministic tracker improves identity preservation and robustness in scenarios with unknown/variable target counts and occlusions, while remaining applicable to both offline and live settings; the accompanying open-source code supports reproducibility."}}
{"id": "2510.24411", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.24411", "abs": "https://arxiv.org/abs/2510.24411", "authors": ["Qiushi Sun", "Mukai Li", "Zhoumianze Liu", "Zhihui Xie", "Fangzhi Xu", "Zhangyue Yin", "Kanzhi Cheng", "Zehao Li", "Zichen Ding", "Qi Liu", "Zhiyong Wu", "Zhuosheng Zhang", "Ben Kao", "Lingpeng Kong"], "title": "OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows", "comment": "work in progress", "summary": "Computer-using agents powered by Vision-Language Models (VLMs) have\ndemonstrated human-like capabilities in operating digital environments like\nmobile platforms. While these agents hold great promise for advancing digital\nautomation, their potential for unsafe operations, such as system compromise\nand privacy leakage, is raising significant concerns. Detecting these safety\nconcerns across the vast and complex operational space of mobile environments\npresents a formidable challenge that remains critically underexplored. To\nestablish a foundation for mobile agent safety research, we introduce\nMobileRisk-Live, a dynamic sandbox environment accompanied by a safety\ndetection benchmark comprising realistic trajectories with fine-grained\nannotations. Built upon this, we propose OS-Sentinel, a novel hybrid safety\ndetection framework that synergistically combines a Formal Verifier for\ndetecting explicit system-level violations with a VLM-based Contextual Judge\nfor assessing contextual risks and agent actions. Experiments show that\nOS-Sentinel achieves 10%-30% improvements over existing approaches across\nmultiple metrics. Further analysis provides critical insights that foster the\ndevelopment of safer and more reliable autonomous mobile agents.", "AI": {"tldr": "Dynamic safety evaluation for Vision-Language Model-powered mobile agents using MobileRisk-Live sandbox and OS-Sentinel detector.", "motivation": "To address underexplored safety risks of mobile agents operating in complex, real-world environments; need a benchmark and effective detection framework.", "method": "Create MobileRisk-Live sandbox with realistic trajectories and fine-grained annotations; develop OS-Sentinel, combining a Formal Verifier for explicit violations with a VLM-based Contextual Judge for contextual risks.", "result": "OS-Sentinel yields 10-30% improvements over existing approaches across multiple metrics; provides insights for safer autonomous mobile agents.", "conclusion": "Establishes a foundation for mobile agent safety research and guides the development of safer, more reliable autonomous mobile agents."}}
{"id": "2510.23756", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23756", "abs": "https://arxiv.org/abs/2510.23756", "authors": ["Nicki Barari", "Edward Kim", "Christopher MacLellan"], "title": "Explaining Robustness to Catastrophic Forgetting Through Incremental Concept Formation", "comment": "18 pages, 5 figures, Advances in Cognitive Systems 2025", "summary": "Catastrophic forgetting remains a central challenge in continual learning,\nwhere models are required to integrate new knowledge over time without losing\nwhat they have previously learned. In prior work, we introduced Cobweb/4V, a\nhierarchical concept formation model that exhibited robustness to catastrophic\nforgetting in visual domains. Motivated by this robustness, we examine three\nhypotheses regarding the factors that contribute to such stability: (1)\nadaptive structural reorganization enhances knowledge retention, (2) sparse and\nselective updates reduce interference, and (3) information-theoretic learning\nbased on sufficiency statistics provides advantages over gradient-based\nbackpropagation. To test these hypotheses, we compare Cobweb/4V with neural\nbaselines, including CobwebNN, a neural implementation of the Cobweb framework\nintroduced in this work. Experiments on datasets of varying complexity (MNIST,\nFashion-MNIST, MedMNIST, and CIFAR-10) show that adaptive restructuring\nenhances learning plasticity, sparse updates help mitigate interference, and\nthe information-theoretic learning process preserves prior knowledge without\nrevisiting past data. Together, these findings provide insight into mechanisms\nthat can mitigate catastrophic forgetting and highlight the potential of\nconcept-based, information-theoretic approaches for building stable and\nadaptive continual learning systems.", "AI": {"tldr": "A hierarchical, concept-based continual learning model, Cobweb/4V, demonstrates robustness to catastrophic forgetting by integrating adaptive structure, sparse updates, and information-theoretic learning via sufficiency statistics, outperforming neural baselines across multiple datasets while preserving prior knowledge without revisiting past data.", "motivation": "Catastrophic forgetting remains a key challenge in continual learning. Building on Cobweb/4V's observed robustness in visual domains, the work investigates whether adaptive restructuring, sparse updates, and information-theoretic learning contribute to stability and knowledge retention, aiming to explain and harness these effects.", "method": "Compare Cobweb/4V with neural baselines (including CobwebNN, a neural implementation of Cobweb) across datasets of increasing complexity (MNIST, Fashion-MNIST, MedMNIST, CIFAR-10). Test three hypotheses: (1) adaptive structural reorganization enhances retention/plasticity, (2) sparse/ selective updates reduce interference, (3) information-theoretic learning based on sufficiency statistics offers advantages over backpropagation. Evaluate plasticity, interference, and prior knowledge preservation without revisiting past data.", "result": "Adaptive restructuring enhances learning plasticity; sparse updates mitigate interference; information-theoretic learning preserves prior knowledge without revisiting past data. Across datasets, Cobweb/4V and CobwebNN outperform purely gradient-based baselines, illustrating the benefits of concept-based, information-theoretic approaches for continual learning.", "conclusion": "The study provides mechanistic insight into reducing catastrophic forgetting by combining structure adaptation, sparse updates, and sufficiency-statistics\u2013driven learning. It highlights the potential of concept-based, information-theoretic methods for building stable, adaptive continual learning systems."}}
{"id": "2510.24278", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24278", "abs": "https://arxiv.org/abs/2510.24278", "authors": ["Pietro Bongini", "Valentina Molinari", "Andrea Costanzo", "Benedetta Tondi", "Mauro Barni"], "title": "Training-free Source Attribution of AI-generated Images via Resynthesis", "comment": "14 pages, 4 figures, 1 table, accepted at \"The 17th IEEE\n  INTERNATIONAL WORKSHOP ON INFORMATION FORENSICS AND SECURITY (WIFS2025)\",\n  Perth, Australia", "summary": "Synthetic image source attribution is a challenging task, especially in data\nscarcity conditions requiring few-shot or zero-shot classification\ncapabilities. We present a new training-free one-shot attribution method based\non image resynthesis. A prompt describing the image under analysis is\ngenerated, then it is used to resynthesize the image with all the candidate\nsources. The image is attributed to the model which produced the resynthesis\nclosest to the original image in a proper feature space. We also introduce a\nnew dataset for synthetic image attribution consisting of face images from\ncommercial and open-source text-to-image generators. The dataset provides a\nchallenging attribution framework, useful for developing new attribution models\nand testing their capabilities on different generative architectures. The\ndataset structure allows to test approaches based on resynthesis and to compare\nthem to few-shot methods. Results from state-of-the-art few-shot approaches and\nother baselines show that the proposed resynthesis method outperforms existing\ntechniques when only a few samples are available for training or fine-tuning.\nThe experiments also demonstrate that the new dataset is a challenging one and\nrepresents a valuable benchmark for developing and evaluating future few-shot\nand zero-shot methods.", "AI": {"tldr": "Proposes a training-free one-shot method for attributing synthetic image sources via resynthesis, and introduces a challenging dataset; the resynthesis approach outperforms existing few-shot baselines in low-data regimes.", "motivation": "Address data scarcity in synthetic image source attribution, enabling reliable few-shot or zero-shot classification across diverse generative models.", "method": "For a given image, generate a descriptive prompt, resynthesize the image using each candidate source, then attribute to the source whose resynthesized image is closest to the original in a chosen feature space.", "result": "On a new dataset of faces from commercial and open-source text-to-image generators, the resynthesis method outperforms state-of-the-art few-shot methods and baselines when little training data is available; the dataset is challenging and suitable as a benchmark.", "conclusion": "Resynthesis-based attribution is effective in few-shot/zero-shot settings and the dataset provides a valuable benchmark to develop and evaluate future attribution methods across synthetic-image sources."}}
{"id": "2510.24461", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24461", "abs": "https://arxiv.org/abs/2510.24461", "authors": ["Korneel Van den Berghe", "Stein Stroobants", "Vijay Janapa Reddi", "G. C. H. E. de Croon"], "title": "Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks", "comment": null, "summary": "Neuromorphic computing systems are set to revolutionize energy-constrained\nrobotics by achieving orders-of-magnitude efficiency gains, while enabling\nnative temporal processing. Spiking Neural Networks (SNNs) represent a\npromising algorithmic approach for these systems, yet their application to\ncomplex control tasks faces two critical challenges: (1) the non-differentiable\nnature of spiking neurons necessitates surrogate gradients with unclear\noptimization properties, and (2) the stateful dynamics of SNNs require training\non sequences, which in reinforcement learning (RL) is hindered by limited\nsequence lengths during early training, preventing the network from bridging\nits warm-up period.\n  We address these challenges by systematically analyzing surrogate gradient\nslope settings, showing that shallower slopes increase gradient magnitude in\ndeeper layers but reduce alignment with true gradients. In supervised learning,\nwe find no clear preference for fixed or scheduled slopes. The effect is much\nmore pronounced in RL settings, where shallower slopes or scheduled slopes lead\nto a 2.1x improvement in both training and final deployed performance. Next, we\npropose a novel training approach that leverages a privileged guiding policy to\nbootstrap the learning process, while still exploiting online environment\ninteractions with the spiking policy. Combining our method with an adaptive\nslope schedule for a real-world drone position control task, we achieve an\naverage return of 400 points, substantially outperforming prior techniques,\nincluding Behavioral Cloning and TD3BC, which achieve at most --200 points\nunder the same conditions. This work advances both the theoretical\nunderstanding of surrogate gradient learning in SNNs and practical training\nmethodologies for neuromorphic controllers demonstrated in real-world robotic\nsystems.", "AI": {"tldr": "Analyzes surrogate gradient slopes in Spiking Neural Networks (SNNs) for neuromorphic control, finds shallower/scheduled slopes improve RL performance; introduces a privileged guiding policy to bootstrap learning with online interactions; demonstrates adaptive slope schedules on a real-world drone task, surpassing Baselines (e.g., Behavioral Cloning, TD3BC) in average return.", "motivation": "Tackling two main challenges in SNNs for control: (i) non-differentiable spikes requiring surrogate gradients with unclear optimization properties, and (ii) stateful, sequence-based learning in RL limited by short early training sequences and warm-up dynamics.", "method": "Systematically analyze surrogate gradient slope settings, comparing fixed vs. scheduled slopes and their effects on gradient magnitude and alignment; examine both supervised learning and RL; propose a training method that uses a privileged guiding policy to bootstrap learning while continuing online interaction with the spiking policy; apply an adaptive slope schedule to a real-world drone position control task.", "result": "In RL, shallower or scheduled slopes yield ~2.1x improvement in both training and deployed performance. On a real-world drone task with an adaptive slope schedule, average return reaches 400 points, substantially outperforming prior techniques such as Behavioral Cloning and TD3BC (\u2264 -200 points under the same conditions).", "conclusion": "Provides a deeper theoretical understanding of surrogate gradient learning in SNNs and demonstrates practical training strategies for neuromorphic controllers in real robotic systems, including a novel privileged-guided bootstrap and adaptive slope scheduling that improves RL performance."}}
{"id": "2510.24435", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24435", "abs": "https://arxiv.org/abs/2510.24435", "authors": ["Benjamin Grando Moreira"], "title": "Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning", "comment": "12 pages", "summary": "Evaluating reasoning ability in Large Language Models (LLMs) is important for\nadvancing artificial intelligence, as it transcends mere linguistic task\nperformance. It involves understanding whether these models truly understand\ninformation, perform inferences, and are able to draw conclusions in a logical\nand valid way. This study compare logical and abstract reasoning skills of\nseveral LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,\nPerplexity, and Sabi\\'a - using a set of eight custom-designed reasoning\nquestions. The LLM results are benchmarked against human performance on the\nsame tasks, revealing significant differences and indicating areas where LLMs\nstruggle with deduction.", "AI": {"tldr": "Eight LLMs (GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral, Perplexity, Sabi\u2019a) are evaluated on eight custom-designed reasoning questions and benchmarked against human performance, revealing notable gaps in deductive reasoning.", "motivation": "To move beyond surface language tasks and assess whether LLMs truly understand information, can perform inferences, and draw logical conclusions.", "method": "Compare logical and abstract reasoning abilities of multiple LLMs on eight specially designed questions, against human performance on the same set, analyzing where deductions succeed or fail.", "result": "There are significant differences between LLMs and human test-takers, with performance varying by model. LLMs struggle with deduction in several items, indicating gaps in current reasoning abilities despite language proficiency.", "conclusion": "Current LLMs exhibit limitations in deductive and abstract reasoning; the study highlights areas for improvement and guides future work in enhancing genuine reasoning capabilities."}}
{"id": "2510.23786", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23786", "abs": "https://arxiv.org/abs/2510.23786", "authors": ["Joohwan Ko", "Aristofanis Rontogiannis", "Yih-En Andrew Ban", "Axel Elaldi", "Nicholas Franklin"], "title": "Relaxed Sequence Sampling for Diverse Protein Design", "comment": null, "summary": "Protein design using structure prediction models such as AlphaFold2 has shown\nremarkable success, but existing approaches like relaxed sequence optimization\n(RSO) rely on single-path gradient descent and ignore sequence-space\nconstraints, limiting diversity and designability. We introduce Relaxed\nSequence Sampling (RSS), a Markov chain Monte Carlo (MCMC) framework that\nintegrates structural and evolutionary information for protein design. RSS\noperates in continuous logit space, combining gradient-guided exploration with\nprotein language model-informed jumps. Its energy function couples\nAlphaFold2-derived structural objectives with ESM2-derived sequence priors,\nbalancing accuracy and biological plausibility. In an in silico protein binder\ndesign task, RSS produces 5$\\times$ more designable structures and 2-3$\\times$\ngreater structural diversity than RSO baselines, at equal computational cost.\nThese results highlight RSS as a principled approach for efficiently exploring\nthe protein design landscape.", "AI": {"tldr": "RSS is an MCMC method that explores protein sequence space in continuous logit space, combining AlphaFold2 structural objectives with ESM2 priors to improve designability and diversity over RSO at equal cost.", "motivation": "RSO and similar single-path gradient methods ignore sequence-space constraints, limiting diversity and designability of protein designs; integrating evolutionary priors and efficient exploration is needed.", "method": "RSS uses a Markov chain Monte Carlo framework operating in continuous logit space, with gradient-guided exploration and language-model-informed jumps. The energy combines AF2-derived structural objectives with ESM2-derived sequence priors to balance structure accuracy and biological plausibility.", "result": "In silico protein binder design shows RSS yields about 5\u00d7 more designable structures and 2\u20133\u00d7 greater structural diversity than RSO baselines at the same computational cost.", "conclusion": "RSS is a principled framework for efficiently exploring protein design landscapes by jointly leveraging structure predictions and evolutionary priors within an MCMC in continuous space."}}
{"id": "2510.24285", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24285", "abs": "https://arxiv.org/abs/2510.24285", "authors": ["Juntian Zhang", "Song Jin", "Chuanqi Cheng", "Yuhan Liu", "Yankai Lin", "Xun Zhang", "Yufei Zhang", "Fei Jiang", "Guojun Yin", "Wei Lin", "Rui Yan"], "title": "ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model", "comment": null, "summary": "The limited capacity for fine-grained visual perception presents a critical\nbottleneck for Vision-Language Models (VLMs) in real-world applications.\nAddressing this is challenging due to the scarcity of high-quality data and the\nlimitations of existing methods: supervised fine-tuning (SFT) often compromises\ngeneral capabilities, while reinforcement fine-tuning (RFT) prioritizes textual\nreasoning over visual perception. To bridge this gap, we propose a novel\ntwo-stage task that structures visual perception learning as a coarse-to-fine\nprogressive process. Based on this task formulation, we develop ViPER, a\nself-bootstrapping framework specifically designed to enable iterative\nevolution through self-critiquing and self-prediction. By synergistically\nintegrating image-level and instance-level reconstruction with a two-stage\nreinforcement learning strategy, ViPER establishes a closed-loop training\nparadigm, where internally synthesized data directly fuel the enhancement of\nperceptual ability. Applied to the Qwen2.5-VL family, ViPER produces the\nQwen-Viper series. With an average gain of 1.7% on seven comprehensive\nbenchmarks spanning various tasks and up to 6.0% on fine-grained perception,\nQwen-Viper consistently demonstrates superior performance across different\nvision-language scenarios while maintaining generalizability. Beyond enabling\nself-improvement in perceptual capabilities, ViPER provides concrete evidence\nfor the reciprocal relationship between generation and understanding, a\nbreakthrough to developing more autonomous and capable VLMs.", "AI": {"tldr": "Proposes ViPER, a two-stage coarse-to-fine learning framework that self-critiques and self-predicts to improve fine-grained visual perception in Vision-Language Models (VLMs). Demonstrates that internal data synthesis and a closed-loop RL paradigm yield consistent gains on Qwen2.5-VL (Qwen-Viper series) and seven benchmarks, highlighting a reciprocal relationship between generation and understanding.", "motivation": "Address the bottleneck of fine-grained visual perception in VLMs, hindered by limited high-quality data and the drawbacks of supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT). The goal is to enhance perceptual ability without sacrificing general capabilities.", "method": "Introduce a two-stage coarse-to-fine task for visual perception; develop ViPER, a self-bootstrapping framework with self-critique and self-prediction. Combine image-level and instance-level reconstruction with a two-stage reinforcement learning strategy to create a closed-loop where synthetic data from the model itself fuels perceptual improvement. Applied to Qwen2.5-VL to produce the Qwen-Viper series.", "result": "Average improvement of 1.7% across seven benchmarks; up to 6.0% gains on fine-grained perception. Qwen-Viper series shows improved performance across varying VLM tasks while maintaining generalizability.", "conclusion": "The work provides evidence for a reciprocal link between generation and understanding in VLMs and demonstrates that self-bootstrapping via ViPER can autonomously enhance perceptual capabilities, pushing toward more capable and autonomous VLMs."}}
{"id": "2510.24482", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.24482", "abs": "https://arxiv.org/abs/2510.24482", "authors": ["Klemens Iten", "Lenart Treven", "Bhavya Sukhija", "Florian D\u00f6rfler", "Andreas Krause"], "title": "Sample-efficient and Scalable Exploration in Continuous-Time RL", "comment": "26 pages, 6 figures, 6 tables", "summary": "Reinforcement learning algorithms are typically designed for discrete-time\ndynamics, even though the underlying real-world control systems are often\ncontinuous in time. In this paper, we study the problem of continuous-time\nreinforcement learning, where the unknown system dynamics are represented using\nnonlinear ordinary differential equations (ODEs). We leverage probabilistic\nmodels, such as Gaussian processes and Bayesian neural networks, to learn an\nuncertainty-aware model of the underlying ODE. Our algorithm, COMBRL, greedily\nmaximizes a weighted sum of the extrinsic reward and model epistemic\nuncertainty. This yields a scalable and sample-efficient approach to\ncontinuous-time model-based RL. We show that COMBRL achieves sublinear regret\nin the reward-driven setting, and in the unsupervised RL setting (i.e., without\nextrinsic rewards), we provide a sample complexity bound. In our experiments,\nwe evaluate COMBRL in both standard and unsupervised RL settings and\ndemonstrate that it scales better, is more sample-efficient than prior methods,\nand outperforms baselines across several deep RL tasks.", "AI": {"tldr": "Continuous-time RL with uncertain ODE dynamics using COMBRL, achieving sublinear regret and good sample efficiency via uncertainty-aware model-based planning.", "motivation": "Real-world control is continuous in time; discrete-time RL struggles with unknown continuous dynamics; need scalable, uncertainty-aware continuous-time model-based RL.", "method": "Use probabilistic models (Gaussian processes, Bayesian neural networks) to learn an uncertainty-aware ODE model; COMBRL greedily optimizes a weighted sum of extrinsic reward and model epistemic uncertainty.", "result": "Sublinear regret in reward-driven setting; sample complexity bound in unsupervised RL; experiments show better scalability, sample efficiency, and superior performance against baselines on multiple deep RL tasks.", "conclusion": "COMBRL provides a scalable, sample-efficient approach to continuous-time model-based RL with theoretical guarantees and strong empirical performance."}}
{"id": "2510.24442", "categories": ["cs.AI", "cs.CL", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.24442", "abs": "https://arxiv.org/abs/2510.24442", "authors": ["Yiding Wang", "Yuxuan Chen", "Fanxu Meng", "Xifan Chen", "Xiaolei Yang", "Muhan Zhang"], "title": "Law in Silico: Simulating Legal Society with LLM-Based Agents", "comment": null, "summary": "Since real-world legal experiments are often costly or infeasible, simulating\nlegal societies with Artificial Intelligence (AI) systems provides an effective\nalternative for verifying and developing legal theory, as well as supporting\nlegal administration. Large Language Models (LLMs), with their world knowledge\nand role-playing capabilities, are strong candidates to serve as the foundation\nfor legal society simulation. However, the application of LLMs to simulate\nlegal systems remains underexplored. In this work, we introduce Law in Silico,\nan LLM-based agent framework for simulating legal scenarios with individual\ndecision-making and institutional mechanisms of legislation, adjudication, and\nenforcement. Our experiments, which compare simulated crime rates with\nreal-world data, demonstrate that LLM-based agents can largely reproduce\nmacro-level crime trends and provide insights that align with real-world\nobservations. At the same time, micro-level simulations reveal that a\nwell-functioning, transparent, and adaptive legal system offers better\nprotection of the rights of vulnerable individuals.", "AI": {"tldr": "LLM-based agents (Law in Silico) can simulate legal systems; macro crime trends align with real-world data; transparency and adaptivity improve protection of vulnerable individuals, suggesting utility for theory and administration.", "motivation": "Real-world legal experiments are costly/infeasible; simulating legal societies with AI can verify legal theory and support legal administration; LLMs' world knowledge and role-playing capabilities make them suitable for simulating legal decision-making and institutions.", "method": "Develop Law in Silico: an LLM-based agent framework with individual decision-making and institutional mechanisms for legislation, adjudication, and enforcement; run simulations; compare macro crime rates to real-world data; analyze micro-level rights protection.", "result": "Simulated macro-level crime trends largely reproduce real-world trends; framework yields insights aligned with observations; micro-level simulations show that a well-functioning, transparent, and adaptive legal system better protects the rights of vulnerable individuals.", "conclusion": "LLM-based simulations of legal societies are feasible and informative for theory verification and policy design; highlights the importance of transparency and adaptability in protecting vulnerable groups, and suggests broader potential for AI-assisted legal research and administration."}}
{"id": "2510.23794", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23794", "abs": "https://arxiv.org/abs/2510.23794", "authors": ["Jun Liu", "Tao Zhou", "Jiarui Li", "Xiaohui Zhong", "Peng Zhang", "Jie Feng", "Lei Chen", "Hao Li"], "title": "Revealing the Potential of Learnable Perturbation Ensemble Forecast Model for Tropical Cyclone Prediction", "comment": "30 pages, 21 figures, 1 table", "summary": "Tropical cyclones (TCs) are highly destructive and inherently uncertain\nweather systems. Ensemble forecasting helps quantify these uncertainties, yet\ntraditional systems are constrained by high computational costs and limited\ncapability to fully represent atmospheric nonlinearity. FuXi-ENS introduces a\nlearnable perturbation scheme for ensemble generation, representing a novel\nAI-based forecasting paradigm. Here, we systematically compare FuXi-ENS with\nECMWF-ENS using all 90 global TCs in 2018, examining their performance in\nTC-related physical variables, track and intensity forecasts, and the\nassociated dynamical and thermodynamical fields. FuXi-ENS demonstrates clear\nadvantages in predicting TC-related physical variables, and achieves more\naccurate track forecasts with reduced ensemble spread, though it still\nunderestimates intensity relative to observations. Further dynamical and\nthermodynamical analyses reveal that FuXi-ENS better captures large-scale\ncirculation, with moisture turbulent energy more tightly concentrated around\nthe TC warm core, whereas ECMWF-ENS exhibits a more dispersed distribution.\nThese findings highlight the potential of learnable perturbations to improve TC\nforecasting skill and provide valuable insights for advancing AI-based ensemble\nprediction of extreme weather events that have significant societal impacts.", "AI": {"tldr": "FuXi-ENS, a learnable perturbation ensemble method, outperforms ECMWF-ENS in tracking tropical cyclones and predicting TC-related variables, with tighter ensemble spread and better large-scale circulation representation, though it underestimates intensity.", "motivation": "Ensemble forecasts for tropical cyclones are computationally expensive and struggle to fully capture atmospheric nonlinearity. A learnable perturbation approach (FuXi-ENS) aims to improve forecast skill and efficiency by better representing uncertainty and nonlinear dynamics.", "method": "The paper introduces FuXi-ENS and systematically compares it with ECMWF-ENS using all 90 global TCs from 2018. Evaluations cover TC-related physical variables, track and intensity forecasts, and associated dynamical/thermodynamical fields.", "result": "FuXi-ENS shows clear advantages in predicting TC-related physical variables and achieves more accurate track forecasts with reduced ensemble spread, though it underestimates intensity. Dynamical/thermodynamical analyses indicate FuXi-ENS better captures large-scale circulation and concentrates moisture turbulent energy near the TC warm core, while ECMWF-ENS exhibits a more dispersed moisture distribution.", "conclusion": "Learnable perturbations offer a promising AI-based path to improve TC ensemble forecasting and broader AI-driven ensemble predictions of extreme weather, though intensity bias remains an area for further improvement."}}
{"id": "2510.24321", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24321", "abs": "https://arxiv.org/abs/2510.24321", "authors": ["Ivica Dimitrovski", "Vlatko Spasev", "Ivan Kitanovski"], "title": "Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning", "comment": null, "summary": "Remote sensing applications increasingly rely on deep learning for scene\nclassification. However, their performance is often constrained by the scarcity\nof labeled data and the high cost of annotation across diverse geographic and\nsensor domains. While recent vision-language models like CLIP have shown\npromise by learning transferable representations at scale by aligning visual\nand textual modalities, their direct application to remote sensing remains\nsuboptimal due to significant domain gaps and the need for task-specific\nsemantic adaptation. To address this critical challenge, we systematically\nexplore prompt learning as a lightweight and efficient adaptation strategy for\nfew-shot remote sensing image scene classification. We evaluate several\nrepresentative methods, including Context Optimization, Conditional Context\nOptimization, Multi-modal Prompt Learning, and Prompting with Self-Regulating\nConstraints. These approaches reflect complementary design philosophies: from\nstatic context optimization to conditional prompts for enhanced generalization,\nmulti-modal prompts for joint vision-language adaptation, and semantically\nregularized prompts for stable learning without forgetting. We benchmark these\nprompt-learning methods against two standard baselines: zero-shot CLIP with\nhand-crafted prompts and a linear probe trained on frozen CLIP features.\nThrough extensive experiments on multiple benchmark remote sensing datasets,\nincluding cross-dataset generalization tests, we demonstrate that prompt\nlearning consistently outperforms both baselines in few-shot scenarios.\nNotably, Prompting with Self-Regulating Constraints achieves the most robust\ncross-domain performance. Our findings underscore prompt learning as a scalable\nand efficient solution for bridging the domain gap in satellite and aerial\nimagery, providing a strong foundation for future research in this field.", "AI": {"tldr": "Prompt learning is an effective, scalable adaptation for few-shot remote sensing scene classification, outperforming zero-shot CLIP and linear probes; self-regulating, semantically guided prompts offer the strongest cross-domain robustness.", "motivation": "Remote sensing suffers from scarce labeled data and domain shifts across geographic and sensor modalities. While CLIP-like vision-language models offer transferable representations, domain gaps to RS tasks necessitate task-specific semantic adaptation.", "method": "Systematic evaluation of four prompt-learning schemes\u2014Context Optimization, Conditional Context Optimization, Multi-modal Prompt Learning, and Prompting with Self-Regulating Constraints\u2014against zero-shot CLIP with handcrafted prompts and a linear probe on frozen CLIP features. Extensive experiments on multiple RS benchmarks, including cross-dataset generalization.", "result": "Prompt-learning methods consistently outperform the baselines in few-shot scenarios; the Self-Regulating Constraints approach yields the most robust cross-domain performance.", "conclusion": "Prompt learning provides a scalable, efficient path to bridge domain gaps in satellite and aerial imagery, establishing a solid foundation for future remote-sensing\u2013focused vision-language adaptation."}}
{"id": "2510.24459", "categories": ["cs.AI", "cs.MA", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.24459", "abs": "https://arxiv.org/abs/2510.24459", "authors": ["Habtom Kahsay Gidey", "Niklas Huber", "Alexander Lenz", "Alois Knoll"], "title": "Affordance Representation and Recognition for Autonomous Agents", "comment": null, "summary": "The autonomy of software agents is fundamentally dependent on their ability\nto construct an actionable internal world model from the structured data that\ndefines their digital environment, such as the Document Object Model (DOM) of\nweb pages and the semantic descriptions of web services. However, constructing\nthis world model from raw structured data presents two critical challenges: the\nverbosity of raw HTML makes it computationally intractable for direct use by\nfoundation models, while the static nature of hardcoded API integrations\nprevents agents from adapting to evolving services.\n  This paper introduces a pattern language for world modeling from structured\ndata, presenting two complementary architectural patterns. The DOM Transduction\nPattern addresses the challenge of web page complexity by distilling} a\nverbose, raw DOM into a compact, task-relevant representation or world model\noptimized for an agent's reasoning core. Concurrently, the Hypermedia\nAffordances Recognition Pattern enables the agent to dynamically enrich its\nworld model by parsing standardized semantic descriptions to discover and\nintegrate the capabilities of unknown web services at runtime. Together, these\npatterns provide a robust framework for engineering agents that can efficiently\nconstruct and maintain an accurate world model, enabling scalable, adaptive,\nand interoperable automation across the web and its extended resources.", "AI": {"tldr": "A two-pattern pattern-language for world modeling from structured data, combining DOM Transduction to compress verbose DOM into a compact, task-relevant world model and Hypermedia Affordances Recognition to dynamically enrich models by interpreting semantic service descriptions at runtime, enabling scalable, adaptive web automation.", "motivation": "To overcome (1) the verbosity of raw HTML/structured data that makes direct use by foundation models inefficient, and (2) the static, hardcoded API integrations that hinder agents from adapting to evolving services.", "method": "Proposes a pattern-language with two complementary architectural patterns: (a) DOM Transduction Pattern that distills verbose DOM into a compact, task-focused world model; (b) Hypermedia Affordances Recognition Pattern that parses standardized semantic descriptions to discover and integrate capabilities of unknown web services at runtime.", "result": "A robust framework for engineering agents to construct and maintain an accurate and scalable world model, enabling adaptive and interoperable automation across the web and its resources.", "conclusion": "The two patterns together offer a scalable, dynamic approach to world modeling from structured data, allowing agents to reason efficiently with a compact internal representation and to discover new service capabilities on the fly, thereby enhancing autonomy and interoperability."}}
{"id": "2510.23802", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23802", "abs": "https://arxiv.org/abs/2510.23802", "authors": ["Nathan Paek", "Yongyi Zang", "Qihui Yang", "Randal Leistikow"], "title": "Learning Interpretable Features in Audio Latent Spaces via Sparse Autoencoders", "comment": "Accepted to NeurIPS 2025 Mechanistic Interpretability Workshop", "summary": "While sparse autoencoders (SAEs) successfully extract interpretable features\nfrom language models, applying them to audio generation faces unique\nchallenges: audio's dense nature requires compression that obscures semantic\nmeaning, and automatic feature characterization remains limited. We propose a\nframework for interpreting audio generative models by mapping their latent\nrepresentations to human-interpretable acoustic concepts. We train SAEs on\naudio autoencoder latents, then learn linear mappings from SAE features to\ndiscretized acoustic properties (pitch, amplitude, and timbre). This enables\nboth controllable manipulation and analysis of the AI music generation process,\nrevealing how acoustic properties emerge during synthesis. We validate our\napproach on continuous (DiffRhythm-VAE) and discrete (EnCodec, WavTokenizer)\naudio latent spaces, and analyze DiffRhythm, a state-of-the-art text-to-music\nmodel, to demonstrate how pitch, timbre, and loudness evolve throughout\ngeneration. While our work is only done on audio modality, our framework can be\nextended to interpretable analysis of visual latent space generation models.", "AI": {"tldr": "SAE-based mapping from audio latent spaces to discretized acoustic concepts enables interpretable, controllable analysis of audio generation.", "motivation": "Address the difficulty of interpreting dense audio latent spaces and the limited ability to characterize features in audio generative models.", "method": "Train sparse autoencoders on audio latents; learn linear mappings from SAE features to discretized pitch, amplitude, and timbre; validate on DiffRhythm-VAE (continuous) and EnCodec/WavTokenizer (discrete) latents; analyze DiffRhythm generation.", "result": "Enables controllable manipulation and analysis of acoustic properties; reveals how pitch, timbre, and loudness emerge during synthesis; demonstrates applicability across latent spaces; suggests extension to other modalities.", "conclusion": "Provides a framework for interpretable analysis of audio generative models; extensible to other modalities like vision."}}
{"id": "2510.24366", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24366", "abs": "https://arxiv.org/abs/2510.24366", "authors": ["Thanh-Huy Nguyen", "Hoang-Thien Nguyen", "Ba-Thinh Lam", "Vi Vu", "Bach X. Nguyen", "Jianhua Xing", "Tianyang Wang", "Xingjian Li", "Min Xu"], "title": "Adaptive Knowledge Transferring with Switching Dual-Student Framework for Semi-Supervised Medical Image Segmentation", "comment": "The paper is under review at Pattern Recognition Journal", "summary": "Teacher-student frameworks have emerged as a leading approach in\nsemi-supervised medical image segmentation, demonstrating strong performance\nacross various tasks. However, the learning effects are still limited by the\nstrong correlation and unreliable knowledge transfer process between teacher\nand student networks. To overcome this limitation, we introduce a novel\nswitching Dual-Student architecture that strategically selects the most\nreliable student at each iteration to enhance dual-student collaboration and\nprevent error reinforcement. We also introduce a strategy of Loss-Aware\nExponential Moving Average to dynamically ensure that the teacher absorbs\nmeaningful information from students, improving the quality of pseudo-labels.\nOur plug-and-play framework is extensively evaluated on 3D medical image\nsegmentation datasets, where it outperforms state-of-the-art semi-supervised\nmethods, demonstrating its effectiveness in improving segmentation accuracy\nunder limited supervision.", "AI": {"tldr": "Switching Dual-Student with Loss-Aware EMA improves semi-supervised 3D medical image segmentation by dynamically selecting the most reliable student and using EMA to transfer rich information to the teacher, reducing error reinforcement and enhancing pseudo-label quality.", "motivation": "Conventional teacher-student methods suffer from strong correlation and error reinforcement between teacher and student, limiting learning from limited labeled data in semi-supervised medical image segmentation.", "method": "Introduce a Switching Dual-Student architecture that, at each iteration, selects the most reliable student to collaborate with the teacher, and apply a Loss-Aware Exponential Moving Average to adaptively absorb informative signals from students into the teacher, yielding higher-quality pseudo-labels. The framework is plug-and-play and evaluated on 3D medical image segmentation datasets.", "result": "The approach outperforms state-of-the-art semi-supervised methods on 3D medical image segmentation under limited supervision, demonstrating improved segmentation accuracy.", "conclusion": "The proposed Switching Dual-Student with Loss-Aware EMA enhances learning dynamics by preventing error reinforcement and delivering meaningful pseudo-labels, leading to superior performance in semi-supervised 3D medical image segmentation."}}
{"id": "2510.23804", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23804", "abs": "https://arxiv.org/abs/2510.23804", "authors": ["Adela DePavia", "Vasileios Charisopoulos", "Rebecca Willett"], "title": "How do simple rotations affect the implicit bias of Adam?", "comment": null, "summary": "Adaptive gradient methods such as Adam and Adagrad are widely used in machine\nlearning, yet their effect on the generalization of learned models -- relative\nto methods like gradient descent -- remains poorly understood. Prior work on\nbinary classification suggests that Adam exhibits a ``richness bias,'' which\ncan help it learn nonlinear decision boundaries closer to the Bayes-optimal\ndecision boundary relative to gradient descent. However, the coordinate-wise\npreconditioning scheme employed by Adam renders the overall method sensitive to\northogonal transformations of feature space. We show that this sensitivity can\nmanifest as a reversal of Adam's competitive advantage: even small rotations of\nthe underlying data distribution can make Adam forfeit its richness bias and\nconverge to a linear decision boundary that is farther from the Bayes-optimal\ndecision boundary than the one learned by gradient descent. To alleviate this\nissue, we show that a recently proposed reparameterization method -- which\napplies an orthogonal transformation to the optimization objective -- endows\nany first-order method with equivariance to data rotations, and we empirically\ndemonstrate its ability to restore Adam's bias towards rich decision\nboundaries.", "AI": {"tldr": "Adam's optimization advantage is not invariant to rotations of the data; small orthogonal transforms can eliminate its richness bias and push the learned boundary toward linearity, but a recently proposed orthogonal reparameterization makes first-order methods rotation-equivariant and can restore the bias toward richer decision boundaries.", "motivation": "Understand how adaptive, coordinate-wise preconditioned optimizers like Adam generalize relative to SGD, and whether data geometry (rotations) can alter their bias; evaluate a method to enforce rotation equivariance.", "method": "Analyze the effect of orthogonal transformations on Adam's learned decision boundary; propose an orthogonal reparameterization of the optimization objective to render first-order methods rotation-equivariant; empirically evaluate the impact on binary classification tasks.", "result": "Without reparameterization, Adam's bias can vanish under small data rotations, leading to linear boundaries farther from Bayes-optimal than gradient descent; with the proposed reparameterization, Adam regains its bias toward rich, non-linear decision boundaries.", "conclusion": "Rotation-equivariant reformulations of the objective can preserve or restore Adam's favorable generalization bias, suggesting geometry-preserving transforms are valuable for the design and analysis of first-order optimization methods."}}
{"id": "2510.24374", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24374", "abs": "https://arxiv.org/abs/2510.24374", "authors": ["Yuda Zou", "Zijian Zhang", "Yongchao Xu"], "title": "Decoupling What to Count and Where to See for Referring Expression Counting", "comment": null, "summary": "Referring Expression Counting (REC) extends class-level object counting to\nthe fine-grained subclass-level, aiming to enumerate objects matching a textual\nexpression that specifies both the class and distinguishing attribute. A\nfundamental challenge, however, has been overlooked: annotation points are\ntypically placed on class-representative locations (e.g., heads), forcing\nmodels to focus on class-level features while neglecting attribute information\nfrom other visual regions (e.g., legs for \"walking\"). To address this, we\npropose W2-Net, a novel framework that explicitly decouples the problem into\n\"what to count\" and \"where to see\" via a dual-query mechanism. Specifically,\nalongside the standard what-to-count (w2c) queries that localize the object, we\nintroduce dedicated where-to-see (w2s) queries. The w2s queries are guided to\nseek and extract features from attribute-specific visual regions, enabling\nprecise subclass discrimination. Furthermore, we introduce Subclass Separable\nMatching (SSM), a novel matching strategy that incorporates a repulsive force\nto enhance inter-subclass separability during label assignment. W2-Net\nsignificantly outperforms the state-of-the-art on the REC-8K dataset, reducing\ncounting error by 22.5% (validation) and 18.0% (test), and improving\nlocalization F1 by 7% and 8%, respectively. Code will be available.", "AI": {"tldr": "W2-Net decouples counting and localization with a dual-query mechanism (what-to-count and where-to-see) and a Subclass Separable Matching strategy, achieving state-of-the-art results on Referring Expression Counting (REC-8K).", "motivation": "Annotation points are typically placed on class-representative locations (e.g., heads), causing models to overemphasize class-level features and neglect attribute information from other regions necessary for fine-grained subclass discrimination.", "method": "Introduce a dual-query framework: what-to-count (w2c) queries localize the object, and where-to-see (w2s) queries extract features from attribute-specific regions to capture distinguishing attributes. Also propose Subclass Separable Matching (SSM) with a repulsive force to improve inter-subclass separability during label assignment.", "result": "Significant gains on REC-8K: counting error reduced by 22.5% on validation and 18.0% on test; localization F1 improved by 7% and 8% respectively. Code will be available.", "conclusion": "Decoupling counting and viewing via the dual-query W2-Net, together with SSM, enhances fine-grained counting and localization by leveraging attribute-specific regions and stronger inter-subclass discrimination, achieving state-of-the-art performance on REC-8K."}}
{"id": "2510.24528", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24528", "abs": "https://arxiv.org/abs/2510.24528", "authors": ["Zihan Chen", "Song Wang", "Xingbo Fu", "Chengshuai Shi", "Zhenyu Lei", "Cong Shen", "Jundong Li"], "title": "From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning", "comment": null, "summary": "The capability of in-context learning (ICL) enables large language models\n(LLMs) to perform novel tasks without parameter updates by conditioning on a\nfew input-output examples. However, collecting high-quality examples for new or\nchallenging tasks can be costly and labor-intensive. In this work, we propose a\ncost-efficient two-stage pipeline that reduces reliance on LLMs for data\nlabeling. Our approach first leverages readily available cross-task examples to\nprompt an LLM and pseudo-label a small set of target task instances. We then\nintroduce a graph-based label propagation method that spreads label information\nto the remaining target examples without additional LLM queries. The resulting\nfully pseudo-labeled dataset is used to construct in-task demonstrations for\nICL. This pipeline combines the flexibility of cross-task supervision with the\nscalability of LLM-free propagation. Experiments across five tasks demonstrate\nthat our method achieves strong performance while lowering labeling costs.", "AI": {"tldr": "A cost-efficient two-stage pipeline for constructing in-task demonstrations for in-context learning by using cross-task LLM prompts to pseudo-label a small set of target instances, followed by graph-based label propagation to label the rest, enabling LLM-free data generation with reduced labeling effort.", "motivation": "Reduce labeling cost and dependence on large language models for creating high-quality in-context learning demonstrations, by combining cross-task supervision with scalable propagation techniques.", "method": "Stage 1: Prompt an LLM with cross-task examples to pseudo-label a small subset of target task instances. Stage 2: Apply a graph-based label propagation algorithm to spread labels to the remaining target examples without further LLM queries. Use the fully pseudo-labeled data to construct in-task demonstrations for ICL.", "result": "Experiments across five tasks show strong performance and reduced labeling costs compared to baselines, demonstrating the effectiveness and efficiency of the proposed pipeline.", "conclusion": "A hybrid strategy that blends cross-task supervision with LLM-free propagation can efficiently generate useful in-task demonstrations for ICL, lowering labeling costs while preserving performance."}}
{"id": "2510.23810", "categories": ["cs.LG", "math.AP", "physics.comp-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23810", "abs": "https://arxiv.org/abs/2510.23810", "authors": ["Sumanta Roy", "Bahador Bahmani", "Ioannis G. Kevrekidis", "Michael D. Shields"], "title": "A Physics-informed Multi-resolution Neural Operator", "comment": "26 pages, 14 figures, 4 tables", "summary": "The predictive accuracy of operator learning frameworks depends on the\nquality and quantity of available training data (input-output function pairs),\noften requiring substantial amounts of high-fidelity data, which can be\nchallenging to obtain in some real-world engineering applications. These\ndatasets may be unevenly discretized from one realization to another, with the\ngrid resolution varying across samples. In this study, we introduce a\nphysics-informed operator learning approach by extending the Resolution\nIndependent Neural Operator (RINO) framework to a fully data-free setup,\naddressing both challenges simultaneously. Here, the arbitrarily (but\nsufficiently finely) discretized input functions are projected onto a latent\nembedding space (i.e., a vector space of finite dimensions), using pre-trained\nbasis functions. The operator associated with the underlying partial\ndifferential equations (PDEs) is then approximated by a simple multi-layer\nperceptron (MLP), which takes as input a latent code along with spatiotemporal\ncoordinates to produce the solution in the physical space. The PDEs are\nenforced via a finite difference solver in the physical space. The validation\nand performance of the proposed method are benchmarked on several numerical\nexamples with multi-resolution data, where input functions are sampled at\nvarying resolutions, including both coarse and fine discretizations.", "AI": {"tldr": "A fully data-free physics-informed operator learning framework extending RINO to handle multi-resolution inputs by projecting onto a latent space with pre-trained bases and learning an operator via an MLP, with PDE enforcement via finite difference; validated on multi-resolution PDE benchmarks.", "motivation": "Data scarcity and heterogeneous discretizations hinder operator learning; a data-efficient, grid-agnostic method that respects underlying physics is desirable.", "method": "Inputs are projected onto a latent embedding using pre-trained basis functions; an MLP learns the operator mapping latent code and spatiotemporal coordinates to the solution; PDEs are enforced via a finite-difference solver in physical space; training is fully data-free (no high-fidelity data). Benchmarks include numerical examples with varying discretizations (coarse and fine).", "result": "Demonstrates capability to handle multi-resolution data and varying grids in a data-free setting, with performance comparable to or exceeding data-dependent baselines on benchmark PDE problems.", "conclusion": "Shows feasibility of data-free physics-informed operator learning for PDEs across multi-resolution discretizations, offering a practical route when high-fidelity data is unavailable or expensive to obtain."}}
{"id": "2510.24378", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24378", "abs": "https://arxiv.org/abs/2510.24378", "authors": ["Yann Kerverdo", "Florent Leray", "Youwan Mah\u00e9", "St\u00e9phanie Leplaideur", "Francesca Galassi"], "title": "Stroke Lesion Segmentation in Clinical Workflows: A Modular, Lightweight, and Deployment-Ready Tool", "comment": null, "summary": "Deep learning frameworks such as nnU-Net achieve state-of-the-art performance\nin brain lesion segmentation but remain difficult to deploy clinically due to\nheavy dependencies and monolithic design. We introduce \\textit{StrokeSeg}, a\nmodular and lightweight framework that translates research-grade stroke lesion\nsegmentation models into deployable applications. Preprocessing, inference, and\npostprocessing are decoupled: preprocessing relies on the Anima toolbox with\nBIDS-compliant outputs, and inference uses ONNX Runtime with \\texttt{Float16}\nquantisation, reducing model size by about 50\\%. \\textit{StrokeSeg} provides\nboth graphical and command-line interfaces and is distributed as Python scripts\nand as a standalone Windows executable. On a held-out set of 300 sub-acute and\nchronic stroke subjects, segmentation performance was equivalent to the\noriginal PyTorch pipeline (Dice difference $<10^{-3}$), demonstrating that\nhigh-performing research pipelines can be transformed into portable, clinically\nusable tools.", "AI": {"tldr": "A modular StrokeSeg framework decouples preprocessing, inference, and postprocessing to create deployable stroke lesion segmentation tools; using ONNX with Float16 halves model size and matches PyTorch performance on 300 subjects, available as Python scripts and a Windows executable.", "motivation": "State-of-the-art brain lesion segmentation models (e.g., nnU-Net) are powerful but hard to deploy clinically due to heavy dependencies and monolithic designs; there is a need for portable, clinician-friendly tools.", "method": "Decouple pipeline: preprocessing via Anima toolbox with BIDS-compliant outputs; inference with ONNX Runtime using Float16 quantisation to reduce size; postprocessing integrated as needed; provide GUI and CLI interfaces; distribution as Python scripts and a standalone Windows executable.", "result": "On a held-out set of 300 sub-acute and chronic stroke subjects, segmentation performance was equivalent to the original PyTorch pipeline (Dice difference < 0.001); model size reduced by ~50% due to quantisation.", "conclusion": "Demonstrates that high-performing research pipelines can be transformed into portable, clinically usable tools, enabling deployment of state-of-the-art stroke lesion segmentation in clinical settings."}}
{"id": "2510.24551", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24551", "abs": "https://arxiv.org/abs/2510.24551", "authors": ["Gang Chen", "Changshuo Liu", "Gene Anne Ooi", "Marcus Tan", "Zhongle Xie", "Jianwei Yin", "James Wei Luen Yip", "Wenqiao Zhang", "Jiaqi Zhu", "Beng Chin Ooi"], "title": "Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives", "comment": null, "summary": "Generative Artificial Intelligence (GenAI) is taking the world by storm. It\npromises transformative opportunities for advancing and disrupting existing\npractices, including healthcare. From large language models (LLMs) for clinical\nnote synthesis and conversational assistance to multimodal systems that\nintegrate medical imaging, electronic health records, and genomic data for\ndecision support, GenAI is transforming the practice of medicine and the\ndelivery of healthcare, such as diagnosis and personalized treatments, with\ngreat potential in reducing the cognitive burden on clinicians, thereby\nimproving overall healthcare delivery. However, GenAI deployment in healthcare\nrequires an in-depth understanding of healthcare tasks and what can and cannot\nbe achieved. In this paper, we propose a data-centric paradigm in the design\nand deployment of GenAI systems for healthcare. Specifically, we reposition the\ndata life cycle by making the medical data ecosystem as the foundational\nsubstrate for generative healthcare systems. This ecosystem is designed to\nsustainably support the integration, representation, and retrieval of diverse\nmedical data and knowledge. With effective and efficient data processing\npipelines, such as semantic vector search and contextual querying, it enables\nGenAI-powered operations for upstream model components and downstream clinical\napplications. Ultimately, it not only supplies foundation models with\nhigh-quality, multimodal data for large-scale pretraining and domain-specific\nfine-tuning, but also serves as a knowledge retrieval backend to support\ntask-specific inference via the agentic layer. The ecosystem enables the\ndeployment of GenAI for high-quality and effective healthcare delivery.", "AI": {"tldr": "A data-centric paradigm for GenAI in healthcare that treats the medical data ecosystem as the foundation for all GenAI activities, enabling high-quality data supply, retrieval, and deployment for clinical tasks.", "motivation": "GenAI has transformative potential in healthcare but requires deep understanding of tasks and data, necessitating an integrated data lifecycle and ecosystem to ensure quality, access, and safety.", "method": "Reframe the data lifecycle as the core substrate; design a medical data ecosystem that supports integration, representation, and retrieval of heterogeneous data; deploy semantic vector search and contextual querying to support upstream models and downstream clinical applications.", "result": "The ecosystem provides high-quality multimodal data for large-scale pretraining and domain-specific fine-tuning, and acts as a knowledge retrieval backend to support task-specific inference via an agentic layer, enabling effective GenAI deployment in healthcare.", "conclusion": "A data-centric healthcare GenAI paradigm can sustainably enable accurate, efficient, and safe AI-assisted clinical care by tightly coupling data infrastructure with model and inference layers."}}
{"id": "2510.23817", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.23817", "abs": "https://arxiv.org/abs/2510.23817", "authors": ["Pedro Cortes dos Santos", "Matheus Becali Rocha", "Renato A Krohling"], "title": "Combining SHAP and Causal Analysis for Interpretable Fault Detection in Industrial Processes", "comment": null, "summary": "Industrial processes generate complex data that challenge fault detection\nsystems, often yielding opaque or underwhelming results despite advanced\nmachine learning techniques. This study tackles such difficulties using the\nTennessee Eastman Process, a well-established benchmark known for its intricate\ndynamics, to develop an innovative fault detection framework. Initial attempts\nwith standard models revealed limitations in both performance and\ninterpretability, prompting a shift toward a more tractable approach. By\nemploying SHAP (SHapley Additive exPlanations), we transform the problem into a\nmore manageable and transparent form, pinpointing the most critical process\nfeatures driving fault predictions. This reduction in complexity unlocks the\nability to apply causal analysis through Directed Acyclic Graphs, generated by\nmultiple algorithms, to uncover the underlying mechanisms of fault propagation.\nThe resulting causal structures align strikingly with SHAP findings,\nconsistently highlighting key process elements-like cooling and separation\nsystems-as pivotal to fault development. Together, these methods not only\nenhance detection accuracy but also provide operators with clear, actionable\ninsights into fault origins, a synergy that, to our knowledge, has not been\npreviously explored in this context. This dual approach bridges predictive\npower with causal understanding, offering a robust tool for monitoring complex\nmanufacturing environments and paving the way for smarter, more interpretable\nfault detection in industrial systems.", "AI": {"tldr": "A fault-detection framework for the Tennessee Eastman Process using SHAP for feature attribution and DAG-based causal analysis to improve interpretability and detection accuracy.", "motivation": "Industrial processes produce complex, opaque data that hamper fault detection; there is a need for interpretable and accurate monitoring in manufacturing environments.", "method": "Start with standard models to establish baseline performance, then apply SHAP explanations to identify and reduce to key features, and finally construct/discover causal structures via multiple DAG-learning algorithms to reveal fault propagation mechanisms and validate SHAP findings against causal insights.", "result": "SHAP-based feature reduction aligns with the discovered causal structures, consistently highlighting critical elements (e.g., cooling and separation systems) as central to fault development, leading to improved detection accuracy and interpretability.", "conclusion": "A hybrid SHAP + DAG framework provides robust, actionable fault detection for complex industrial systems, bridging predictive power with causal understanding and offering a path toward smarter, interpretable monitoring."}}
{"id": "2510.24379", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24379", "abs": "https://arxiv.org/abs/2510.24379", "authors": ["Zhuangfan Huang", "Xiaosong Li", "Gao Wang", "Tao Ye", "Haishu Tan", "Huafeng Li"], "title": "A Luminance-Aware Multi-Scale Network for Polarization Image Fusion with a Multi-Scene Dataset", "comment": null, "summary": "Polarization image fusion combines S0 and DOLP images to reveal surface\nroughness and material properties through complementary texture features, which\nhas important applications in camouflage recognition, tissue pathology\nanalysis, surface defect detection and other fields. To intergrate\ncoL-Splementary information from different polarized images in complex\nluminance environment, we propose a luminance-aware multi-scale network (MLSN).\nIn the encoder stage, we propose a multi-scale spatial weight matrix through a\nbrightness-branch , which dynamically weighted inject the luminance into the\nfeature maps, solving the problem of inherent contrast difference in polarized\nimages. The global-local feature fusion mechanism is designed at the bottleneck\nlayer to perform windowed self-attention computation, to balance the global\ncontext and local details through residual linking in the feature dimension\nrestructuring stage. In the decoder stage, to further improve the adaptability\nto complex lighting, we propose a Brightness-Enhancement module, establishing\nthe mapping relationship between luminance distribution and texture features,\nrealizing the nonlinear luminance correction of the fusion result. We also\npresent MSP, an 1000 pairs of polarized images that covers 17 types of indoor\nand outdoor complex lighting scenes. MSP provides four-direction polarization\nraw maps, solving the scarcity of high-quality datasets in polarization image\nfusion. Extensive experiment on MSP, PIF and GAND datasets verify that the\nproposed MLSN outperms the state-of-the-art methods in subjective and objective\nevaluations, and the MS-SSIM and SD metircs are higher than the average values\nof other methods by 8.57%, 60.64%, 10.26%, 63.53%, 22.21%, and 54.31%,\nrespectively. The source code and dataset is avalable at\nhttps://github.com/1hzf/MLS-UNet.", "AI": {"tldr": "A luminance-aware multi-scale network (MLSN) fuses polarized images (S0 and DOLP) to reveal surface texture and material properties under complex lighting. It introduces a brightness-driven encoder, global-local fusion via windowed self-attention, and a brightness-enhancement decoder, plus MSP, a 1000-image polarization dataset for 17 lighting scenes. It reports state-of-the-art gains on MSP, PIF, and GAND datasets, with notable MS-SSIM and SD improvements, and provides code.", "motivation": "Polarization images carry complementary texture cues but fusion is challenged by varying luminance and contrast across images. There is a scarcity of high-quality polarized fusion datasets; a robust, luminance-aware fusion model is needed to preserve texture and material properties under diverse lighting.", "method": "An encoder-decoder network (MLSN) with: (1) a brightness-branch that produces a multi-scale spatial weight matrix to inject luminance into feature maps; (2) a global-local feature fusion mechanism at the bottleneck using windowed self-attention with residual connections; (3) a Brightness-Enhancement module in the decoder that maps luminance distribution to texture features for nonlinear luminance correction; (4) MSP dataset of 1000 polarized image pairs across 17 indoor/outdoor lighting scenarios providing four-direction polarization raw maps; (5) training/evaluation on MSP, PIF, and GAND datasets with MS-SSIM and SD as metrics.", "result": "The MLSN approach outperforms state-of-the-art polarization image fusion methods on subjective and objective evaluations. Reported improvements include MS-SSIM, SD and other metrics with percentage gains (e.g., 8.57%, 60.64%, 10.26%, 63.53%, 22.21%, 54.31% across metrics). MSP dataset is introduced to address data scarcity and enable robust evaluation.", "conclusion": "MLSN effectively integrates luminance cues and multi-scale context for robust polarization image fusion under complex lighting. The MSP dataset helps advance evaluation in this domain, and the accompanying code is publicly available for reproducibility."}}
{"id": "2510.24645", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24645", "abs": "https://arxiv.org/abs/2510.24645", "authors": ["Zengzhuang Xu", "Bingguang Hao", "Zechuan Wang", "Yuntao Wen", "Maolin Wang", "Yang Liu", "Long Chen", "Dong Wang", "Yicheng Chen", "Cunyin Peng", "Chenyi Zhuang", "Jinjie Gu", "Leilei Gan", "Xiangyu Zhao", "Shi Gu"], "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling", "comment": null, "summary": "Function calling (FC) empowers large language models (LLMs) and autonomous\nagents to interface with external tools, a critical capability for solving\ncomplex, real-world problems. As this ability becomes increasingly central to\nadvanced AI systems, the need for high-quality, multi-turn training data to\ndevelop and refine it cannot be overstated. Existing data synthesis methods,\nsuch as random environment sampling or multi-agent role-playing, are not\npowerful enough to generate high-quality data in real-world environments.\nPractical challenges come in three folds: targeted model training, isolation of\ntool architecture, and multi-turn logical dependency. To address these\nstructural deficiencies, we present FunReason-MT, a novel data synthesis\nframework for real-world multi-turn tool use. FunReason-MT resolves the\ncomplexity barrier in multi-turn FC data by employing 1) Environment-API Graph\nInteractions to gather varied high-quality trajectories, 2) Advanced Tool-Query\nSynthesis to simplify hard query construction, and 3) Guided Iterative Chain\nfor sophisticated CoT generation. Evaluations on Berkeley Function-Calling\nLeaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built\nupon FunReason-MT generated data achieves state-of-the-art performance among\ncomparable-sized models, outperforming most close-source models. Further\nperformance improvements on BFCLv4 confirm that FunReason-MT provides a\nreliable and robust source for agentic learning.", "AI": {"tldr": "Proposes FunReason-MT, a data-synthesis framework for real-world multi-turn function calling, to generate high-quality training data and improve agentic LLM performance; achieves state-of-the-art results on BFCL benchmarks for 4B models.", "motivation": "Addresses the need for high-quality, multi-turn FC training data and the three practical challenges: targeted model training, isolation of tool architecture, and multi-turn dependencies.", "method": "1) Environment-API Graph Interactions for diverse trajectories; 2) Advanced Tool-Query Synthesis to ease hard queries; 3) Guided Iterative Chain for enhanced CoT generation.", "result": "4B model trained on FunReason-MT attains state-of-the-art among comparable-sized models on BFCLv3; surpasses many close-source models; BFCLv4 results confirm robustness.", "conclusion": "FunReason-MT is a reliable, robust data source to advance agentic learning in real-world, multi-turn tool use."}}
{"id": "2510.23818", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23818", "abs": "https://arxiv.org/abs/2510.23818", "authors": ["Yilang Zhang", "Xiaodong Yang", "Yiwei Cai", "Georgios B. Giannakis"], "title": "ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning", "comment": null, "summary": "As large language models (LLMs) continue to scale in size, the computational\noverhead has become a major bottleneck for task-specific fine-tuning. While\nlow-rank adaptation (LoRA) effectively curtails this cost by confining the\nweight updates to a low-dimensional subspace, such a restriction can hinder\neffectiveness and slow convergence. This contribution deals with these\nlimitations by accumulating progressively a high-rank weight update from\nconsecutive low-rank increments. Specifically, the per update optimal low-rank\nmatrix is identified to minimize the loss function and closely approximate full\nfine-tuning. To endow efficient and seamless optimization without restarting,\nthis optimal choice is formed by appropriately scaling the columns of the\noriginal low-rank matrix. Rigorous performance guarantees reveal that the\noptimal scaling can be found analytically. Extensive numerical tests with\npopular LLMs scaling up to 12 billion parameters demonstrate a consistent\nperformance gain and fast convergence relative to state-of-the-art LoRA\nvariants on diverse tasks including natural language understanding, commonsense\nreasoning, and mathematical problem solving.", "AI": {"tldr": "A method to progressively build higher-rank weight updates from consecutive low-rank LoRA increments to improve fine-tuning efficiency and convergence.", "motivation": "LoRA reduces fine-tuning cost by restricting updates to a low-rank subspace, but this can hurt effectiveness and slow convergence for large models; a high-rank, efficiently computable alternative is needed.", "method": "At each update, compute the per-update optimal low-rank matrix to minimize the loss and approximate full fine-tuning. The cumulative high-rank update is formed by scaling the columns of the original low-rank matrix, enabling seamless optimization without restarts. The scaling factors can be found analytically.", "result": "Empirical evaluations on LLMs up to 12B parameters show consistent performance gains and faster convergence compared with state-of-the-art LoRA variants across tasks such as natural language understanding, commonsense reasoning, and mathematical problem solving.", "conclusion": "Progressively accumulating high-rank updates via optimally scaled low-rank increments provides a more effective and faster-fine-tuning paradigm for LLMs than standard LoRA, with analytical scaling enabling efficient optimization."}}
{"id": "2510.24385", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24385", "abs": "https://arxiv.org/abs/2510.24385", "authors": ["Herman Bergstr\u00f6m", "Zhongqi Yue", "Fredrik D. Johansson"], "title": "When are radiology reports useful for training medical image classifiers?", "comment": null, "summary": "Medical images used to train machine learning models are often accompanied by\nradiology reports containing rich expert annotations. However, relying on these\nreports as inputs for clinical prediction requires the timely manual work of a\ntrained radiologist. This raises a natural question: when can radiology reports\nbe leveraged during training to improve image-only classification? Prior works\nare limited to evaluating pre-trained image representations by fine-tuning them\nto predict diagnostic labels, often extracted from reports, ignoring tasks with\nlabels that are weakly associated with the text. To address this gap, we\nconduct a systematic study of how radiology reports can be used during both\npre-training and fine-tuning, across diagnostic and prognostic tasks (e.g.,\n12-month readmission), and under varying training set sizes. Our findings\nreveal that: (1) Leveraging reports during pre-training is beneficial for\ndownstream classification tasks where the label is well-represented in the\ntext; however, pre-training through explicit image-text alignment can be\ndetrimental in settings where it's not; (2) Fine-tuning with reports can lead\nto significant improvements and even have a larger impact than the pre-training\nmethod in certain settings. These results provide actionable insights into when\nand how to leverage privileged text data to train medical image classifiers\nwhile highlighting gaps in current research.", "AI": {"tldr": "A study on using radiology reports to train medical image classifiers, showing that reports help during pre-training only when labels are well represented in text; explicit image-text alignment can hurt otherwise. Fine-tuning with reports often yields substantial gains, sometimes more than pre-training.", "motivation": "Radiology reports contain rich expert annotations that could improve image-based predictions, but leveraging them at scale requires understanding when they are beneficial and how best to use them during pre-training and fine-tuning across diagnostic and prognostic tasks.", "method": "Systematic study comparing pre-training (with and without image-text alignment) and fine-tuning using reports, across diagnostic and prognostic tasks (e.g., 12-month readmission), and under varying training set sizes.", "result": "Pre-training with reports benefits downstream tasks only when labels are well-represented in text; explicit image-text alignment can be detrimental when the text-label relationship is weak. Fine-tuning with reports yields significant improvements and can surpass pre-training in some settings.", "conclusion": "Provides actionable guidance on when and how to leverage privileged radiology text data: use reports to enhance fine-tuning, exercise caution with image-text alignment during pre-training, and identify task-label/text correlations to maximize gains, while noting gaps for future research."}}
{"id": "2510.24650", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24650", "abs": "https://arxiv.org/abs/2510.24650", "authors": ["Nitin Rai", "Daeun", "Choi", "Nathan S. Boyd", "Arnold W. Schumann"], "title": "Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning", "comment": "26 pages, 8 figures, and 2 tables", "summary": "Site-specific disease management (SSDM) in crops has advanced rapidly through\nmachine and deep learning (ML and DL) for real-time computer vision. Research\nevolved from handcrafted feature extraction to large-scale automated feature\nlearning. With foundation models (FMs), crop disease datasets are now processed\nin fundamentally new ways. Unlike traditional neural networks, FMs integrate\nvisual and textual data, interpret symptoms in text, reason about\nsymptom-management relationships, and support interactive QA for growers and\neducators. Adaptive and imitation learning in robotics further enables\nfield-based disease management. This review screened approx. 40 articles on FM\napplications for SSDM, focusing on large-language models (LLMs) and\nvision-language models (VLMs), and discussing their role in adaptive learning\n(AL), reinforcement learning (RL), and digital twin frameworks for targeted\nspraying. Key findings: (a) FMs are gaining traction with surging literature in\n2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL\nand AL are still nascent for smart spraying; (d) digital twins with RL can\nsimulate targeted spraying virtually; (e) addressing the sim-to-real gap is\ncritical for real-world deployment; (f) human-robot collaboration remains\nlimited, especially in human-in-the-loop approaches where robots detect early\nsymptoms and humans validate uncertain cases; (g) multi-modal FMs with\nreal-time feedback will drive next-gen SSDM. For updates, resources, and\ncontributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to\nsubmit papers, code, or datasets.", "AI": {"tldr": "Foundation models (FMs) enable new, integrated approaches for site-specific disease management (SSDM) in crops, merging vision and language to interpret symptoms, reason about management, and support interactive QA. VLMs lead in publications (vs LLMs), with RL/AL still nascent for field spraying. Digital twins with RL offer virtual spray simulation; sim-to-real gap and limited human-in-the-loop collaboration remain key challenges. The field is rapidly growing (2023\u201324), with multi-modal FMs and real-time feedback poised to drive next-gen SSDM. A community resource at the AgriPathogenDatabase is highlighted for sharing papers, code, and data.", "motivation": "The abstract addresses the demand for accurate, adaptive disease management in crops and the limitations of traditional ML pipelines. Foundation models promise to fuse visual and textual cues, interpret symptoms, and reason about management decisions, enabling more scalable and interactive SSDM for growers, educators, and researchers.", "method": "A literature review of ~40 articles on FM applications to SSDM, with a focus on large-language models (LLMs) and vision-language models (VLMs). The review discusses adaptive learning (AL), reinforcement learning (RL), and digital twin frameworks for targeted spraying, and provides a synthesis of trends, gaps, and future directions.", "result": "Key findings include: (a) rapid growth of FM literature in 2023\u201324; (b) VLMs outpace LLMs by a factor of 5\u201310x in publications; (c) RL and AL are still nascent for smart spraying; (d) digital twins with RL can virtually simulate targeted spraying; (e) sim-to-real gap is critical for deployment; (f) human\u2013robot collaboration remains limited, especially in human-in-the-loop settings; (g) multi-modal FMs with real-time feedback are shaping next-gen SSDM.", "conclusion": "The field is rapidly evolving toward integrated, multi-modal, interactive SSDM. To transition to real-world use, efforts must address sim-to-real transfer, robust field validation, and increased human-in-the-loop collaboration. The review highlights community resources (e.g., AgriPathogenDatabase) and anticipates that multi-modal FMs with real-time feedback will drive future SSDM developments."}}
{"id": "2510.23866", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23866", "abs": "https://arxiv.org/abs/2510.23866", "authors": ["Paul Rosu", "Muchang Bahng", "Erick Jiang", "Rico Zhu", "Vahid Tarokh"], "title": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling", "comment": null, "summary": "This work presents a physics-conditioned latent diffusion model tailored for\ndynamical downscaling of atmospheric data, with a focus on reconstructing\nhigh-resolution 2-m temperature fields. Building upon a pre-existing diffusion\narchitecture and employing a residual formulation against a reference UNet, we\nintegrate a partial differential equation (PDE) loss term into the model's\ntraining objective. The PDE loss is computed in the full resolution (pixel)\nspace by decoding the latent representation and is designed to enforce physical\nconsistency through a finite-difference approximation of an effective\nadvection-diffusion balance. Empirical observations indicate that conventional\ndiffusion training already yields low PDE residuals, and we investigate how\nfine-tuning with this additional loss further regularizes the model and\nenhances the physical plausibility of the generated fields. The entirety of our\ncodebase is available on Github, for future reference and development.", "AI": {"tldr": "A physics-informed diffusion model for downscaling atmospheric data, using a PDE-based loss to enforce advection-diffusion consistency during training; improves physical plausibility of high-resolution 2m temperature fields beyond standard diffusion, with code available on GitHub.", "motivation": "To reconstruct high-resolution surface temperature fields from coarse atmospheric data while ensuring physical consistency, leveraging a latent diffusion framework and incorporating a PDE-based regularization term.", "method": "Extend a pre-existing diffusion backbone with a residual connection to a UNet. Introduce a full-resolution PDE loss computed by decoding the latent representation and applying a finite-difference advection-diffusion balance. Train with and without the PDE loss to assess regularization effects; codebase released on GitHub.", "result": "Conventional diffusion training already yields low PDE residuals; fine-tuning with the PDE loss provides additional regularization and improves the physical plausibility of generated fields.", "conclusion": "A PDE-based loss can modestly enhance the physical consistency of diffusion-based dynamical downscaling for atmospheric temperatures, offering a feasible augmentation to standard diffusion training; the authors provide their code for replication."}}
{"id": "2510.24398", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24398", "abs": "https://arxiv.org/abs/2510.24398", "authors": ["Youwan Mah\u00e9", "Elise Bannier", "St\u00e9phanie Leplaideur", "Elisa Fromont", "Francesca Galassi"], "title": "Unsupervised Detection of Post-Stroke Brain Abnormalities", "comment": null, "summary": "Post-stroke MRI not only delineates focal lesions but also reveals secondary\nstructural changes, such as atrophy and ventricular enlargement. These\nabnormalities, increasingly recognised as imaging biomarkers of recovery and\noutcome, remain poorly captured by supervised segmentation methods. We evaluate\nREFLECT, a flow-based generative model, for unsupervised detection of both\nfocal and non-lesional abnormalities in post-stroke patients. Using dual-expert\ncentral-slice annotations on ATLAS data, performance was assessed at the object\nlevel with Free-Response ROC analysis for anomaly maps. Two models were trained\non lesion-free slices from stroke patients (ATLAS) and on healthy controls\n(IXI) to test the effect of training data. On ATLAS test subjects, the\nIXI-trained model achieved higher lesion segmentation (Dice = 0.37 vs 0.27) and\nimproved sensitivity to non-lesional abnormalities (FROC = 0.62 vs 0.43).\nTraining on fully healthy anatomy improves the modelling of normal variability,\nenabling broader and more reliable detection of structural abnormalities.", "AI": {"tldr": "Unsupervised flow-based anomaly detection (REFLECT) trained on healthy brains (IXI) outperforms stroke-lesion-free training (ATLAS) for detecting post-stroke focal and non-lesional abnormalities.", "motivation": "Post-stroke MRI reveals focal lesions and secondary structural changes; such abnormalities are important biomarkers but poorly captured by supervised segmentation. The study assesses whether a flow-based unsupervised detector can uncover both focal and non-lesional abnormalities and how training data (healthy vs stroke- lesion-free brains) affects performance.", "method": "REFLECT, a flow-based generative model, used for unsupervised anomaly detection. Dual-expert central-slice annotations on ATLAS; object-level evaluation with Free-Response ROC for anomaly maps. Two models trained on lesion-free slices from stroke patients (ATLAS) and on healthy controls (IXI); tested on ATLAS subjects.", "result": "On ATLAS test subjects, the IXI-trained model achieved higher lesion segmentation Dice (0.37) than the ATLAS-trained model (0.27) and improved sensitivity to non-lesional abnormalities (FROC 0.62 vs 0.43).", "conclusion": "Training on fully healthy anatomy improves modelling of normal variability, enabling broader and more reliable detection of structural abnormalities after stroke."}}
{"id": "2510.24663", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24663", "abs": "https://arxiv.org/abs/2510.24663", "authors": ["Yifu Lu", "Shengjie Liu", "Li Dong"], "title": "OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs", "comment": "9 pages, 4 figures", "summary": "Agentic tool use has gained traction with the rise of agentic tool calling,\nyet most existing work overlooks the complexity of multi-turn tool\ninteractions. We introduce OrchDAG, a synthetic data generation pipeline that\nmodels tool execution as directed acyclic graphs (DAGs) with controllable\ncomplexity. Using this dataset, we benchmark model performance and propose a\ngraph-based reward to enhance RLVR training. Experiments show that the dataset\npresents a challenging but solvable benchmark, and the proposed reward is\neffective when combined with GRPO-style algorithms, highlighting the importance\nof leveraging topological structure and data complexity in multi-turn tool use.", "AI": {"tldr": "Synthetic DAG-based dataset OrchDAG for multi-turn agentic tool use; benchmarks models; introduces a graph-aware reward to improve RLVR with GRPO-style training.", "motivation": "To address the complexity of multi-turn tool interactions by encoding tool executions as directed acyclic graphs (DAGs) with controllable complexity, providing a challenging benchmark and a graph-informed reward.", "method": "Develop OrchDAG, a data-generation pipeline that creates DAG-structured tool-use sequences with tunable complexity; evaluate model performance on this dataset; propose a graph-based reward function; test with GRPO-style RL training.", "result": "The dataset is challenging yet solvable; the graph-based reward improves RLVR performance when combined with GRPO-style algorithms; highlights the value of leveraging topological structure and data complexity in multi-turn tool use.", "conclusion": "Topology-aware data generation and DAG-based representations are beneficial for training models in multi-turn tool use; synthetic DAG datasets can drive improvements in RLVR when paired with graph-informed rewards and GRPO-like training. "}}
{"id": "2510.23868", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.23868", "abs": "https://arxiv.org/abs/2510.23868", "authors": ["Zhichao Wang"], "title": "GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA", "comment": null, "summary": "I propose \\textbf{G}roup-relative \\textbf{I}mplicit \\textbf{F}ine\n\\textbf{T}uning (GIFT), a novel reinforcement learning framework for aligning\nLLMs. Instead of directly maximizing cumulative rewards like PPO or GRPO, GIFT\nminimizes the discrepancy between implicit and explicit reward models. It\ncombines three key ideas: (1) the online multi-response generation and\nnormalization of GRPO, (2) the implicit reward formulation of DPO, and (3) the\nimplicit-explicit reward alignment principle of UNA. By jointly normalizing the\nimplicit and explicit rewards, GIFT eliminates an otherwise intractable term\nthat prevents effective use of implicit rewards. This normalization transforms\nthe complex reward maximization objective into a simple mean squared error\n(MSE) loss between the normalized reward functions, converting a non-convex\noptimization problem into a convex, stable, and analytically differentiable\nformulation. Unlike offline methods such as DPO and UNA, GIFT remains on-policy\nand thus retains exploration capability. Compared to GRPO, it requires fewer\nhyperparameters, converges faster, and generalizes better with significantly\nreduced training overfitting. Empirically, GIFT achieves superior reasoning and\nalignment performance on mathematical benchmarks while remaining\ncomputationally efficient.", "AI": {"tldr": "GIFT is an on-policy RL framework for LLM alignment that minimizes the gap between implicit and explicit reward models via normalization, turning the objective into a convex, differentiable MSE loss; it blends GRPO, DPO, and UNA ideas to improve efficiency and generalization.", "motivation": "To improve alignment of LLMs by leveraging implicit rewards while avoiding intractable optimization, enabling on-policy learning with stable, simple optimization and better generalization.", "method": "Combine online multi-response generation and normalization (GRPO), implicit reward of DPO, and UNA's alignment principle; normalize both rewards, derive MSE loss between normalized reward functions, enabling convex optimization; on-policy.", "result": "Empirically shows superior reasoning and alignment on mathematical benchmarks; faster convergence, fewer hyperparameters, less overfitting, computational efficiency.", "conclusion": "GIFT offers a stable, convex, on-policy RL framework for LLM alignment, outperforming existing methods and simplifying training."}}
{"id": "2510.24690", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24690", "abs": "https://arxiv.org/abs/2510.24690", "authors": ["Shengjie Liu", "Li Dong", "Zhenyu Zhang"], "title": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning", "comment": "4 pages, 2 figures, short paper, NeurIPS 2025 workshop on Bridging\n  Language, Agent, and World Models for Reasoning and Planning", "summary": "We present a framework for uncovering and exploiting dependencies among tools\nand documents to enhance exemplar artifact generation. Our method begins by\nconstructing a tool knowledge graph from tool schemas,including descriptions,\narguments, and output payloads, using a DeepResearch-inspired analysis. In\nparallel, we derive a complementary knowledge graph from internal documents and\nSOPs, which is then fused with the tool graph. To generate exemplar plans, we\nadopt a deep-sparse integration strategy that aligns structural tool\ndependencies with procedural knowledge. Experiments demonstrate that this\nunified framework effectively models tool interactions and improves plan\ngeneration, underscoring the benefits of linking tool graphs with domain\nknowledge graphs for tool-augmented reasoning and planning.", "AI": {"tldr": "A framework to model dependencies between tools and documents via knowledge graphs to improve exemplar artifact generation, using a fused tool graph and domain knowledge graph and deep-sparse integration for planning.", "motivation": "To enhance exemplar artifact generation and planning by capturing dependencies among tools and documents, enabling tool-augmented reasoning and addressing the limitations of isolated tool schemas.", "method": "Build a tool knowledge graph from tool schemas (descriptions, arguments, and outputs) using a DeepResearch-inspired analysis; concurrently derive a knowledge graph from internal documents and SOPs; fuse the tool graph with the domain knowledge graph; use a deep-sparse integration strategy to align tool dependencies with procedural knowledge for exemplar plan generation.", "result": "Experiments show the unified framework effectively models tool interactions and improves plan generation, highlighting the benefits of linking tool graphs with domain knowledge graphs for tool-augmented reasoning and planning.", "conclusion": "Linking tool graphs with domain knowledge graphs enhances tool-augmented reasoning and planning; the framework provides a unified approach to model dependencies and improve exemplar artifact generation."}}
{"id": "2510.23879", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23879", "abs": "https://arxiv.org/abs/2510.23879", "authors": ["Ayse Irmak Ercevik", "Ahmet Murat Ozbayoglu"], "title": "Artificial Intelligence Based Predictive Maintenance for Electric Buses", "comment": null, "summary": "Predictive maintenance (PdM) is crucial for optimizing efficiency and\nminimizing downtime of electric buses. While these vehicles provide\nenvironmental benefits, they pose challenges for PdM due to complex electric\ntransmission and battery systems. Traditional maintenance, often based on\nscheduled inspections, struggles to capture anomalies in multi-dimensional\nreal-time CAN Bus data. This study employs a graph-based feature selection\nmethod to analyze relationships among CAN Bus parameters of electric buses and\ninvestigates the prediction performance of targeted alarms using artificial\nintelligence techniques. The raw data collected over two years underwent\nextensive preprocessing to ensure data quality and consistency. A hybrid\ngraph-based feature selection tool was developed by combining statistical\nfiltering (Pearson correlation, Cramer's V, ANOVA F-test) with\noptimization-based community detection algorithms (InfoMap, Leiden, Louvain,\nFast Greedy). Machine learning models, including SVM, Random Forest, and\nXGBoost, were optimized through grid and random search with data balancing via\nSMOTEEN and binary search-based down-sampling. Model interpretability was\nachieved using LIME to identify the features influencing predictions. The\nresults demonstrate that the developed system effectively predicts vehicle\nalarms, enhances feature interpretability, and supports proactive maintenance\nstrategies aligned with Industry 4.0 principles.", "AI": {"tldr": "Graph-based feature selection with ML to predict alarms in electric buses from CAN data; enhances interpretability and supports proactive maintenance.", "motivation": "Improve predictive maintenance for electric buses given complex CAN/battery systems to reduce downtime and capture anomalies beyond traditional scheduled maintenance.", "method": "Two-year CAN data collected; extensive preprocessing; hybrid feature selection combining statistical filters (Pearson, Cramer's V, ANOVA F-test) with optimization-based community detection (InfoMap, Leiden, Louvain, Fast Greedy); ML models (SVM, Random Forest, XGBoost) tuned via grid/random search; data balancing via SMOTEEN and down-sampling; model interpretability via LIME.", "result": "The approach effectively predicts vehicle alarms and enhances feature interpretability, enabling proactive maintenance aligned with Industry 4.0.", "conclusion": "Demonstrates feasibility and benefits of graph-based feature selection and AI-driven PdM for electric buses, supporting proactive maintenance to reduce downtime."}}
{"id": "2505.22820", "categories": ["cs.LG", "cs.AI", "econ.TH", "stat.ML"], "pdf": "https://arxiv.org/pdf/2505.22820", "abs": "https://arxiv.org/abs/2505.22820", "authors": ["Ayush Sawarni", "Sahasrajit Sarmasarkar", "Vasilis Syrgkanis"], "title": "Preference Learning with Response Time: Robust Losses and Guarantees", "comment": "Accepted at NeurIPS 2025", "summary": "This paper investigates the integration of response time data into human\npreference learning frameworks for more effective reward model elicitation.\nWhile binary preference data has become fundamental in fine-tuning foundation\nmodels, generative AI systems, and other large-scale models, the valuable\ntemporal information inherent in user decision-making remains largely\nunexploited. We propose novel methodologies to incorporate response time\ninformation alongside binary choice data, leveraging the Evidence Accumulation\nDrift Diffusion (EZ) model, under which response time is informative of the\npreference strength. We develop Neyman-orthogonal loss functions that achieve\noracle convergence rates for reward model learning, matching the theoretical\noptimal rates that would be attained if the expected response times for each\nquery were known a priori. Our theoretical analysis demonstrates that for\nlinear reward functions, conventional preference learning suffers from error\nrates that scale exponentially with reward magnitude. In contrast, our response\ntime-augmented approach reduces this to polynomial scaling, representing a\nsignificant improvement in sample efficiency. We extend these guarantees to\nnon-parametric reward function spaces, establishing convergence properties for\nmore complex, realistic reward models. Our extensive experiments validate our\ntheoretical findings in the context of preference learning over images.", "AI": {"tldr": "Adds response-time data to binary preferences using the EZ diffusion model to improve reward-model learning; achieves oracle convergence with Neyman-orthogonal losses; for linear rewards, it changes error growth from exponential to polynomial; extends to nonparametric spaces; validated on image preference tasks.", "motivation": "Binary preference data is common in reward-model elicitation for foundation models, but it discards valuable temporal information from decision processes. Incorporating response times can reveal decision strength and improve sample efficiency in learning reward functions.", "method": "Model response time via the Evidence Accumulation Drift Diffusion (EZ) framework to link RTs to latent preference strength; develop Neyman-orthogonal loss functions to attain oracle convergence rates; prove results for linear and non-parametric reward function spaces; perform experiments on image-based preference data.", "result": "Theoretical analysis shows RT-augmented methods achieve polynomial scaling with reward magnitude, contrasting with exponential scaling in standard setups; empirical experiments on image preference tasks validate the theory and demonstrate improved data efficiency.", "conclusion": "Incorporating response-time information into reward-model learning yields meaningful gains in sample efficiency and robustness, with guarantees extending to complex reward models and practical validation on image datasets; the framework is promising for enhancing human-in-the-loop alignment in large-scale AI systems."}}
{"id": "2510.23901", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23901", "abs": "https://arxiv.org/abs/2510.23901", "authors": ["Cristobal Heredia", "Pedro Chumpitaz-Flores", "Kaixun Hua"], "title": "RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees", "comment": "20 pages, 1 figure, uses ICLR 2026 LaTeX style. Submitted to arXiv as\n  a preprint version", "summary": "Mixed-integer programming (MIP) has emerged as a powerful framework for\nlearning optimal decision trees. Yet, existing MIP approaches for regression\ntasks are either limited to purely binary features or become computationally\nintractable when continuous, large-scale data are involved. Naively binarizing\ncontinuous features sacrifices global optimality and often yields needlessly\ndeep trees. We recast the optimal regression-tree training as a two-stage\noptimization problem and propose Reduced-Space Optimal Regression Trees\n(RS-ORT) - a specialized branch-and-bound (BB) algorithm that branches\nexclusively on tree-structural variables. This design guarantees the\nalgorithm's convergence and its independence from the number of training\nsamples. Leveraging the model's structure, we introduce several bound\ntightening techniques - closed-form leaf prediction, empirical threshold\ndiscretization, and exact depth-1 subtree parsing - that combine with\ndecomposable upper and lower bounding strategies to accelerate the training.\nThe BB node-wise decomposition enables trivial parallel execution, further\nalleviating the computational intractability even for million-size datasets.\nBased on the empirical studies on several regression benchmarks containing both\nbinary and continuous features, RS-ORT also delivers superior training and\ntesting performance than state-of-the-art methods. Notably, on datasets with up\nto 2,000,000 samples with continuous features, RS-ORT can obtain guaranteed\ntraining performance with a simpler tree structure and a better generalization\nability in four hours.", "AI": {"tldr": "RS-ORT is an exact, scalable two-stage MIP framework for optimal regression trees (no binarization of continuous features). It uses a reduced-space branch-and-bound that only branches on tree-structure variables, with bound-tightening and parallelizable node-wise decomposition, achieving strong performance on large-scale datasets.", "motivation": "Motivated by the limitations of existing MIP-based regression trees that are restricted to binary features or become intractable on large, continuous data, leading to suboptimal, deep trees.", "method": "A two-stage optimization recasting of optimal regression-tree training into Reduced-Space Optimal Regression Trees (RS-ORT). It employs a branch-and-bound algorithm that branches exclusively on tree-structural variables, along with bound-tightening techniques (closed-form leaf prediction, empirical threshold discretization, exact depth-1 subtree parsing) and decomposable upper/lower bounds. Node-wise BB enables trivial parallelism.", "result": "Empirical evaluation on regression benchmarks with binary and continuous features shows RS-ORT achieves superior training and testing performance compared to state-of-the-art methods. It scales to datasets with up to 2,000,000 samples with continuous features, delivering guaranteed training performance with a simpler tree and better generalization within about four hours.", "conclusion": "RS-ORT delivers scalable, exact training for regression trees on large-scale datasets, avoiding crude binarization, and enabling efficient, parallelizable optimization that yields competitive or superior generalization with simpler trees."}}
{"id": "2510.24413", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24413", "abs": "https://arxiv.org/abs/2510.24413", "authors": ["Ali Ahmad Faour", "Nabil Amacha", "Ali J. Ghandour"], "title": "50 Years of Water Body Monitoring: The Case of Qaraaoun Reservoir, Lebanon", "comment": null, "summary": "The sustainable management of the Qaraaoun Reservoir, the largest surface\nwater body in Lebanon located in the Bekaa Plain, depends on reliable\nmonitoring of its storage volume despite frequent sensor malfunctions and\nlimited maintenance capacity. This study introduces a sensor-free approach that\nintegrates open-source satellite imagery, advanced water-extent segmentation,\nand machine learning to estimate the reservoir surface area and volume in near\nreal time. Sentinel-2 and Landsat images are processed, where surface water is\ndelineated using a newly proposed water segmentation index. A machine learning\nmodel based on Support Vector Regression (SVR) is trained on a curated dataset\nthat includes water surface area, water level, and water volume calculations\nusing a reservoir bathymetry survey. The model is then able to estimate\nreservoir volume relying solely on surface area extracted from satellite\nimagery, without the need for ground measurements. Water segmentation using the\nproposed index aligns with ground truth for more than 95 percent of the\nshoreline. Hyperparameter tuning with GridSearchCV yields an optimized SVR\nperformance with error under 1.5 percent of full reservoir capacity and\ncoefficients of determination exceeding 0.98. These results demonstrate the\nrobustness and cost-effectiveness of the method, offering a practical solution\nfor continuous, sensor-independent monitoring of reservoir storage. The\nproposed methodology can be replicated for other water bodies, and the\nresulting 50 years of time-series data is valuable for research on climate\nchange and environmental patterns.", "AI": {"tldr": "Sensor-free, satellite-based framework estimating reservoir volume from surface area using water-segmentation and SVR, achieving high accuracy and enabling near real-time, sensor-independent monitoring.", "motivation": "Addresses unreliable ground sensors, limited maintenance, and need for long-term storage-volume data for water management, climate research, and disaster resilience. A cost-effective, scalable solution for continuous reservoir monitoring.", "method": "Process Sentinel-2 and Landsat imagery; delineate surface water with a new water segmentation index; train an SVR model on a bathymetry-informed dataset (water surface area, water level, volume) to predict volume from surface area alone; use GridSearchCV for hyperparameter tuning; aim for near real-time, sensor-free estimates.", "result": "Water segmentation aligns with ground truth for >95% of shoreline. Optimized SVR yields error <1.5% of full reservoir capacity and R^2 > 0.98. Demonstrates robustness, cost-effectiveness, and replicability; supports 50 years of time-series data for climate/environmental studies.", "conclusion": "The approach provides a sensor-independent, scalable method for continuous reservoir storage monitoring that can be replicated for other water bodies and supports long-term analyses of climate change impacts and hydrological patterns."}}
{"id": "2510.23906", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23906", "abs": "https://arxiv.org/abs/2510.23906", "authors": ["Wasim Ahmad", "Maha Shadaydeh", "Joachim Denzler"], "title": "Group Interventions on Deep Networks for Causal Discovery in Subsystems", "comment": "Submitted to IEEE Access. We are working on the revised version", "summary": "Causal discovery uncovers complex relationships between variables, enhancing\npredictions, decision-making, and insights into real-world systems, especially\nin nonlinear multivariate time series. However, most existing methods primarily\nfocus on pairwise cause-effect relationships, overlooking interactions among\ngroups of variables, i.e., subsystems and their collective causal influence. In\nthis study, we introduce gCDMI, a novel multi-group causal discovery method\nthat leverages group-level interventions on trained deep neural networks and\nemploys model invariance testing to infer causal relationships. Our approach\ninvolves three key steps. First, we use deep learning to jointly model the\nstructural relationships among groups of all time series. Second, we apply\ngroup-wise interventions to the trained model. Finally, we conduct model\ninvariance testing to determine the presence of causal links among variable\ngroups. We evaluate our method on simulated datasets, demonstrating its\nsuperior performance in identifying group-level causal relationships compared\nto existing methods. Additionally, we validate our approach on real-world\ndatasets, including brain networks and climate ecosystems. Our results\nhighlight that applying group-level interventions to deep learning models,\ncombined with invariance testing, can effectively reveal complex causal\nstructures, offering valuable insights for domains such as neuroscience and\nclimate science.", "AI": {"tldr": "Proposes gCDMI, a multi-group causal discovery method using group-level interventions on trained deep networks and model invariance testing to infer group causal links in nonlinear multivariate time series; shows improved performance on simulated data and real-world brain/climate datasets.", "motivation": "Current causal discovery largely targets pairwise relationships, missing group-level interactions and subsystems in multivariate time series; there is a need to uncover causal structures among groups of variables using interventions.", "method": "1) Train a deep neural network to jointly model relationships among groups of time series. 2) Apply group-level interventions to the trained model. 3) Use model invariance testing to infer causal links between variable groups.", "result": "In simulations, gCDMI outperforms existing methods at identifying group-level causal relationships. On real-world data (brain networks, climate ecosystems), it reveals complex causal structures and validates the approach.", "conclusion": "Group-level interventions on deep models combined with invariance testing can effectively uncover complex causal structures among groups, with valuable applications in neuroscience and climate science."}}
{"id": "2510.24414", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24414", "abs": "https://arxiv.org/abs/2510.24414", "authors": ["Reem Hammoud", "Abdul karim Gizzini", "Ali J. Ghandour"], "title": "XAI Evaluation Framework for Semantic Segmentation", "comment": null, "summary": "Ensuring transparency and trust in artificial intelligence (AI) models is\nessential, particularly as they are increasingly applied in safety-critical and\nhigh-stakes domains. Explainable AI (XAI) has emerged as a promising approach\nto address this challenge, yet the rigorous evaluation of XAI methods remains\ncrucial for optimizing the trade-offs between model complexity, predictive\nperformance, and interpretability. While extensive progress has been achieved\nin evaluating XAI techniques for classification tasks, evaluation strategies\ntailored to semantic segmentation remain relatively underexplored. This work\nintroduces a comprehensive and systematic evaluation framework specifically\ndesigned for assessing XAI in semantic segmentation, explicitly accounting for\nboth spatial and contextual task complexities. The framework employs\npixel-level evaluation strategies and carefully designed metrics to provide\nfine-grained interpretability insights. Simulation results using recently\nadapted class activation mapping (CAM)-based XAI schemes demonstrate the\nefficiency, robustness, and reliability of the proposed methodology. These\nfindings contribute to advancing transparent, trustworthy, and accountable\nsemantic segmentation models.", "AI": {"tldr": "A framework for evaluating XAI in semantic segmentation using pixel-level metrics and CAM-based schemes; demonstrates robustness and reliability.", "motivation": "Semantic segmentation requires spatial and contextual interpretability; existing XAI evaluation centers on classification, lacking rigorous, fine\u2011grained tools for segmentation in safety-critical contexts.", "method": "Proposes a systematic evaluation framework with pixel-level evaluation strategies and tailored metrics for segmentation; adapts CAM-based XAI methods for segmentation; validates via simulations.", "result": "Delivers fine-grained interpretability insights and shows the framework's efficiency, robustness, and reliability in assessing XAI for semantic segmentation.", "conclusion": "Advances transparent, trustworthy semantic segmentation by providing a rigorous, fine-grained evaluation framework for XAI methods, enabling better trade-offs and accountability."}}
{"id": "2510.23912", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23912", "abs": "https://arxiv.org/abs/2510.23912", "authors": ["Marko Karbevski", "Antonij Mijoski"], "title": "Key and Value Weights Are Probably All You Need: On the Necessity of the Query, Key, Value weight Triplet in Decoder-Only Transformers", "comment": null, "summary": "The Query, Key, Value weight triplet is a building block of current attention\nmechanisms in state-of-the-art LLMs. We theoretically investigate whether this\ntriplet can be reduced, proving under simplifying assumptions that the Query\nweights are redundant, thereby reducing the number of non-embedding/lm-head\nparameters by over 8%. We validate the theory on full-complexity GPT-3 small\narchitectures (with layer normalization, skip connections, and weight decay)\ntrained from scratch, demonstrating that the reduced model achieves comparable\nvalidation loss to standard baselines. These findings motivate the\ninvestigation of the Query weight redundancy at scale.", "AI": {"tldr": "Query weights in the QKV attention triplet appear redundant, enabling >8% fewer non-embedding/lm-head parameters while preserving validation loss in GPT-3 small-scale experiments; findings motivate scale testing.", "motivation": "Improve transformer efficiency by eliminating redundant Query weights in attention, potentially reducing parameter count without sacrificing performance.", "method": "Theoretically analyze the QKV triplet under simplifying assumptions to show Query weight redundancy, then implement a reduced-parameter model by removing/tying Query weights; validate on full-complexity GPT-3 small architectures (layer norm, skip connections, weight decay) trained from scratch, comparing to standard baselines.", "result": "The reduced model achieves comparable validation loss to standard baselines while using over 8% fewer non-embedding/lm-head parameters.", "conclusion": "Supports the idea that Query weight redundancy can be exploited; encourages scaling studies to determine practical benefits and limits in larger models, with attention to the assumptions behind the theoretical reductions."}}
{"id": "2510.24437", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24437", "abs": "https://arxiv.org/abs/2510.24437", "authors": ["Zhineng Zhao", "Zhihai He", "Zikun Zhou", "Siwei Ma", "Yaowei Wang"], "title": "Deeply-Conditioned Image Compression via Self-Generated Priors", "comment": null, "summary": "Learned image compression (LIC) has shown great promise for achieving high\nrate-distortion performance. However, current LIC methods are often limited in\ntheir capability to model the complex correlation structures inherent in\nnatural images, particularly the entanglement of invariant global structures\nwith transient local textures within a single monolithic representation. This\nlimitation precipitates severe geometric deformation at low bitrates. To\naddress this, we introduce a framework predicated on functional decomposition,\nwhich we term Deeply-Conditioned Image Compression via self-generated priors\n(DCIC-sgp). Our central idea is to first encode a potent, self-generated prior\nto encapsulate the image's structural backbone. This prior is subsequently\nutilized not as mere side-information, but to holistically modulate the entire\ncompression pipeline. This deep conditioning, most critically of the analysis\ntransform, liberates it to dedicate its representational capacity to the\nresidual, high-entropy details. This hierarchical, dependency-driven approach\nachieves an effective disentanglement of information streams. Our extensive\nexperiments validate this assertion; visual analysis demonstrates that our\nmethod substantially mitigates the geometric deformation artifacts that plague\nconventional codecs at low bitrates. Quantitatively, our framework establishes\nhighly competitive performance, achieving significant BD-rate reductions of\n14.4%, 15.7%, and 15.1% against the VVC test model VTM-12.1 on the Kodak, CLIC,\nand Tecnick datasets.", "AI": {"tldr": "Introduces DCIC-sgp, a learned image compression method using a self-generated prior to deeply condition the entire pipeline, especially the analysis transform, enabling disentangled representation of global structure and local textures to reduce geometric deformation at low bitrates, achieving BD-rate reductions of ~14\u201315% against VTM-12.1 on Kodak, CLIC, and Tecnick.", "motivation": "Conventional learned image compression (LIC) struggles to model complex correlations in natural images, particularly the entanglement of invariant global structures with transient local textures within a single monolithic representation, causing geometric deformation at low bitrates.", "method": "Encode a strong self-generated prior that captures the image's structural backbone and use it to condition the entire compression pipeline (deep conditioning), especially the analysis transform, so it allocates capacity to residual high-entropy details, enabling hierarchical, dependency-driven information streams.", "result": "Empirical results show visual improvements with reduced geometric deformation artifacts at low bitrates and quantitative BD-rate reductions of 14.4% (Kodak), 15.7% (CLIC), and 15.1% (Tecnick) against VVC test model VTM-12.1.", "conclusion": "Deep conditioning with self-generated priors enables effective disentanglement of structure and texture in LIC, yielding competitive rate-distortion performance and alleviating geometric deformation issues at low bitrates."}}
{"id": "2510.23914", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23914", "abs": "https://arxiv.org/abs/2510.23914", "authors": ["Arsenii Mustafin", "Xinyi Sheng", "Dominik Baumann"], "title": "Geometry-Inspired Unified Framework for Discounted and Average Reward MDPs", "comment": "12 pages, 1 figure", "summary": "The theoretical analysis of Markov Decision Processes (MDPs) is commonly\nsplit into two cases - the average-reward case and the discounted-reward case -\nwhich, while sharing similarities, are typically analyzed separately. In this\nwork, we extend a recently introduced geometric interpretation of MDPs for the\ndiscounted-reward case to the average-reward case, thereby unifying both. This\nallows us to extend a major result known for the discounted-reward case to the\naverage-reward case: under a unique and ergodic optimal policy, the Value\nIteration algorithm achieves a geometric convergence rate.", "AI": {"tldr": "Unifies discounted and average-reward MDP analyses via a geometric interpretation; shows Value Iteration converges geometrically under a unique, ergodic optimal policy in average-reward MDPs.", "motivation": "Average-reward and discounted-reward MDPs are usually analyzed separately despite similarities; a unified geometric view can extend powerful results to the average-reward case.", "method": "Extend a recently introduced geometric interpretation from discounted MDPs to the average-reward setting and prove geometric convergence of Value Iteration under a unique, ergodic optimal policy.", "result": "The geometric convergence rate of Value Iteration, previously known for discounted MDPs under a unique-ergodic optimal policy, is now established for the average-reward MDP setting as well.", "conclusion": "Provides a unified framework for MDP analysis across reward criteria and extends key algorithmic guarantees (geometric VI convergence) to the average-reward case."}}
{"id": "2510.24448", "categories": ["cs.CV", "cs.AI", "68T07, 68T45, 68T20", "I.2.10; I.4.8; I.5.1; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.24448", "abs": "https://arxiv.org/abs/2510.24448", "authors": ["Pablo Acuaviva", "Aram Davtyan", "Mariam Hassan", "Sebastian Stapf", "Ahmad Rahimi", "Alexandre Alahi", "Paolo Favaro"], "title": "Rethinking Visual Intelligence: Insights from Video Pretraining", "comment": "Updated version from preprint arXiv:2506.07280 (Gen2Gen) focused on\n  visual intelligence. This work can be considered as v2", "summary": "Large language models (LLMs) have demonstrated that large-scale pretraining\nenables systems to adapt rapidly to new problems with little supervision in the\nlanguage domain. This success, however, has not translated as effectively to\nthe visual domain, where models, including LLMs, continue to struggle with\ncompositional understanding, sample efficiency, and general-purpose\nproblem-solving. We investigate Video Diffusion Models (VDMs) as a promising\ndirection for bridging this gap. Pretraining on spatiotemporal data endows\nthese models with strong inductive biases for structure and dynamics, which we\nhypothesize can support broad task adaptability. To test this, we design a\ncontrolled evaluation in which both a pretrained LLM and a pretrained VDM are\nequipped with lightweight adapters and presented with tasks in their natural\nmodalities. Across benchmarks including ARC-AGI, ConceptARC, visual games,\nroute planning, and cellular automata, VDMs demonstrate higher data efficiency\nthan their language counterparts. Taken together, our results indicate that\nvideo pretraining offers inductive biases that support progress toward visual\nfoundation models.", "AI": {"tldr": "Video diffusion models pretrained on spatiotemporal data show strong inductive biases for structure and dynamics, enabling higher data efficiency and broader task adaptability in vision tasks compared to language-model-based approaches.", "motivation": "The paper aims to bridge the gap between the success of large language models in the language domain and their limited transfer to the visual domain by exploring how video pretraining can provide architectural priors and inductive biases that improve visual problem solving and sample efficiency.", "method": "The authors design a controlled evaluation by pairing pretrained LLMs and pretrained VDMs with lightweight adapters and testing them on tasks in their natural modalities across benchmarks such as ARC-AGI, ConceptARC, visual games, route planning, and cellular automata to compare data efficiency and adaptability.", "result": "VDMs demonstrate higher data efficiency than language models in the evaluated tasks, supporting the hypothesis that video pretraining supplies inductive biases conducive to broader visual task adaptability.", "conclusion": "Video pretraining offers inductive biases for structure and dynamics that can advance visual foundation models, suggesting a productive direction for cross-domain generality and sample-efficient visual reasoning."}}
{"id": "2510.23926", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23926", "abs": "https://arxiv.org/abs/2510.23926", "authors": ["Ningfeng Yang", "Tor M. Aamodt"], "title": "Improving the Straight-Through Estimator with Zeroth-Order Information", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "We study the problem of training neural networks with quantized parameters.\nLearning low-precision quantized parameters by enabling computation of\ngradients via the Straight-Through Estimator (STE) can be challenging. While\nthe STE enables back-propagation, which is a first-order method, recent works\nhave explored the use of zeroth-order (ZO) gradient descent for fine-tuning. We\nnote that the STE provides high-quality biased gradients, and ZO gradients are\nunbiased but can be expensive. We thus propose First-Order-Guided Zeroth-Order\nGradient Descent (FOGZO) that reduces STE bias while reducing computations\nrelative to ZO methods. Empirically, we show FOGZO improves the tradeoff\nbetween quality and training time in Quantization-Aware Pre-Training.\nSpecifically, versus STE at the same number of iterations, we show a 1-8\\%\naccuracy improvement for DeiT Tiny/Small, 1-2\\% accuracy improvement on ResNet\n18/50, and 1-22 perplexity point improvement for LLaMA models with up to 0.3\nbillion parameters. For the same loss, FOGZO yields a 796$\\times$ reduction in\ncomputation versus n-SPSA for a 2-layer MLP on MNIST. Code is available at\nhttps://github.com/1733116199/fogzo.", "AI": {"tldr": "FOGZO (First-Order-Guided Zeroth-Order Gradient Descent) blends guided first-order information with zeroth-order updates to train quantized networks, improving accuracy over standard STE and reducing computational cost relative to pure ZO methods.", "motivation": "Training neural networks with quantized parameters is hindered by biased gradients from straight-through estimators (STE) and the high cost of unbiased zeroth-order (ZO) gradient estimates. The work aims to balance gradient quality with computational efficiency during quantization-aware training.", "method": "Introduce FOGZO, a gradient-descent method that uses first-order guidance to steer zeroth-order gradient estimates, thereby reducing STE bias while lowering the computational load compared to conventional ZO methods (e.g., n-SPSA). Applied to quantization-aware pre-training across vision models, CNNs, and LLMs.", "result": "Empirically, FOGZO yields improvements over STE at the same iteration count (e.g., 1\u20138% accuracy on DeiT Tiny/Small; 1\u20132% on ResNet-18/50) and up to 1\u201322 perplexity points on LLaMA models up to 0.3B params). It also achieves a 796\u00d7 reduction in computation versus n-SPSA for a 2-layer MLP on MNIST at the same loss. Code is provided at the linked GitHub repository.", "conclusion": "FOGZO offers a favorable tradeoff between gradient quality and training time for quantization-aware pre-training, enabling better performance with reduced computational cost."}}
{"id": "2510.24456", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24456", "abs": "https://arxiv.org/abs/2510.24456", "authors": ["Vivek Chetia", "Abdul Taher Khan", "Rahish Gogoi", "David Kapsian Khual", "Purnendu Bikash", "Sajal Saha"], "title": "A Critical Study towards the Detection of Parkinsons Disease using ML Technologies", "comment": null, "summary": "The proposed solution is Deep Learning Technique that will be able classify\nthree types of tea leaves diseases from which two diseases are caused by the\npests and one due to pathogens (infectious organisms) and environmental\nconditions and also show the area damaged by a disease in leaves. Namely Red\nRust, Helopeltis and Red spider mite respectively. In this paper we have\nevaluated two models namely SSD MobileNet V2 and Faster R-CNN ResNet50 V1 for\nthe object detection. The SSD MobileNet V2 gave precision of 0.209 for IOU\nrange of 0.50:0.95 with recall of 0.02 on IOU 0.50:0.95 and final mAP of 20.9%.\nWhile Faster R-CNN ResNet50 V1 has precision of 0.252 on IOU range of 0.50:0.95\nand recall of 0.044 on IOU of 0.50:0.95 with a mAP of 25%, which is better than\nSSD. Also used Mask R-CNN for Object Instance Segmentation where we have\nimplemented our custom method to calculate the damaged diseased portion of\nleaves. Keywords: Tea Leaf Disease, Deep Learning, Red Rust, Helopeltis and Red\nSpider Mite, SSD MobileNet V2, Faster R-CNN ResNet50 V1 and Mask RCNN.", "AI": {"tldr": "A DL-based tea leaf disease detector compares SSD MobileNet V2 and Faster R-CNN ResNet50 V1 for pest- and pathogen-caused diseases, and uses Mask R-CNN to estimate damaged leaf area; Faster R-CNN outperforms SSD in mAP, while both provide precision/recall stats at IOU 0.50:0.95.", "motivation": "Automate detection and quantification of tea leaf diseases to aid crop management and reduce losses.", "method": "Evaluate two object detectors (SSD MobileNet V2 and Faster R-CNN ResNet50 V1) on three diseases (Red Rust, Helopeltis, Red Spider Mite); report precision, recall, and mAP for IOU 0.50:0.95; use Mask R-CNN with a custom method to compute the damaged area of leaves.", "result": "SSD MobileNet V2 achieved precision 0.209, recall 0.02, and mAP 20.9% for IOU 0.50:0.95; Faster R-CNN ResNet50 V1 achieved precision 0.252, recall 0.044, and mAP 25% for the same IOU range; Faster R-CNN outperformed SSD; Mask R-CNN was used for instance segmentation to quantify damaged leaf area (details not provided).", "conclusion": "Faster R-CNN ResNet50 V1 provides better detection/localization for tea-leaf diseases than SSD MobileNet V2, and Mask R-CNN enables area estimation of disease damage in leaves."}}
{"id": "2510.23931", "categories": ["cs.LG", "cs.CR", "cs.DC", "68T07 (Primary) 68M14, 68P27, 68Q32, 94A16, 62H35 (Secondary)", "I.2.11; I.2.6; C.2.4; D.4.6; K.4.1"], "pdf": "https://arxiv.org/pdf/2510.23931", "abs": "https://arxiv.org/abs/2510.23931", "authors": ["Miguel Fernandez-de-Retana", "Unai Zulaika", "Rub\u00e9n S\u00e1nchez-Corcuera", "Aitor Almeida"], "title": "Differential Privacy: Gradient Leakage Attacks in Federated Learning Environments", "comment": "17 pages, 12 figures", "summary": "Federated Learning (FL) allows for the training of Machine Learning models in\na collaborative manner without the need to share sensitive data. However, it\nremains vulnerable to Gradient Leakage Attacks (GLAs), which can reveal private\ninformation from the shared model updates. In this work, we investigate the\neffectiveness of Differential Privacy (DP) mechanisms - specifically, DP-SGD\nand a variant based on explicit regularization (PDP-SGD) - as defenses against\nGLAs. To this end, we evaluate the performance of several computer vision\nmodels trained under varying privacy levels on a simple classification task,\nand then analyze the quality of private data reconstructions obtained from the\nintercepted gradients in a simulated FL environment. Our results demonstrate\nthat DP-SGD significantly mitigates the risk of gradient leakage attacks,\nalbeit with a moderate trade-off in model utility. In contrast, PDP-SGD\nmaintains strong classification performance but proves ineffective as a\npractical defense against reconstruction attacks. These findings highlight the\nimportance of empirically evaluating privacy mechanisms beyond their\ntheoretical guarantees, particularly in distributed learning scenarios where\ninformation leakage may represent an unassumable critical threat to data\nsecurity and privacy.", "AI": {"tldr": "DP-SGD reduces gradient leakage risk in federated learning with a moderate drop in model utility; PDP-SGD preserves accuracy but is ineffective against gradient reconstruction attacks.", "motivation": "To empirically evaluate privacy mechanisms against gradient leakage in FL, comparing DP-SGD and a regularization-based PDP-SGD under practical conditions.", "method": "Train computer vision models on a simple classification task with varying privacy levels in a simulated FL setup; perform gradient leakage attacks to reconstruct private data from intercepted gradients; compare DP-SGD and PDP-SGD in terms of leakage and utility.", "result": "DP-SGD significantly mitigates gradient leakage with a moderate utility loss; PDP-SGD maintains classification performance but is ineffective as a practical defense against reconstruction attacks.", "conclusion": "Empirical evaluation of privacy mechanisms is essential; DP-SGD offers leakage protection with a trade-off in accuracy, while PDP-SGD does not provide effective defense against data reconstruction, highlighting gaps between theoretical guarantees and real-world security in distributed learning."}}
{"id": "2510.24464", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24464", "abs": "https://arxiv.org/abs/2510.24464", "authors": ["Charles Javerliat", "Pierre Raimbaud", "Guillaume Lavou\u00e9"], "title": "Kineo: Calibration-Free Metric Motion Capture From Sparse RGB Cameras", "comment": null, "summary": "Markerless multiview motion capture is often constrained by the need for\nprecise camera calibration, limiting accessibility for non-experts and\nin-the-wild captures. Existing calibration-free approaches mitigate this\nrequirement but suffer from high computational cost and reduced reconstruction\naccuracy.\n  We present Kineo, a fully automatic, calibration-free pipeline for markerless\nmotion capture from videos captured by unsynchronized, uncalibrated,\nconsumer-grade RGB cameras. Kineo leverages 2D keypoints from off-the-shelf\ndetectors to simultaneously calibrate cameras, including Brown-Conrady\ndistortion coefficients, and reconstruct 3D keypoints and dense scene point\nmaps at metric scale. A confidence-driven spatio-temporal keypoint sampling\nstrategy, combined with graph-based global optimization, ensures robust\ncalibration at a fixed computational cost independent of sequence length. We\nfurther introduce a pairwise reprojection consensus score to quantify 3D\nreconstruction reliability for downstream tasks.\n  Evaluations on EgoHumans and Human3.6M demonstrate substantial improvements\nover prior calibration-free methods. Compared to previous state-of-the-art\napproaches, Kineo reduces camera translation error by approximately 83-85%,\ncamera angular error by 86-92%, and world mean-per-joint error (W-MPJPE) by\n83-91%.\n  Kineo is also efficient in real-world scenarios, processing multi-view\nsequences faster than their duration in specific configuration (e.g., 36min to\nprocess 1h20min of footage). The full pipeline and evaluation code are openly\nreleased to promote reproducibility and practical adoption at\nhttps://liris-xr.github.io/kineo/.", "AI": {"tldr": "Kineo is a fully automatic, calibration-free multi-view markerless mocap pipeline for unsynchronized, uncalibrated consumer RGB cameras that achieves metric-scale 3D reconstruction using 2D keypoints, with a robust confidence-based sampling and graph optimization, plus a pairwise reprojection score; it shows large accuracy gains and real-world efficiency, with code released.", "motivation": "Calibration-free markerless motion capture is appealing for accessibility and in-the-wild captures, but existing calibration-free methods suffer from high computational cost and reduced reconstruction accuracy; Kineo aims to remove calibration requirements while delivering metric-scale accuracy at fixed computational cost.", "method": "Kineo uses 2D keypoints from off-the-shelf detectors to jointly calibrate cameras (including Brown-Conrady distortion coefficients) and reconstruct 3D keypoints and dense scene maps at metric scale. It employs a confidence-driven spatio-temporal keypoint sampling strategy and graph-based global optimization, ensuring robust calibration with a computational cost independent of sequence length, and introduces a pairwise reprojection consensus score to assess 3D reconstruction reliability.", "result": "On EgoHumans and Human3.6M, Kineo yields substantial improvements over prior calibration-free methods, reducing camera translation error by ~83\u201385%, camera angular error by ~86\u201392%, and world MPJPE by ~83\u201391%. It is also efficient in real-world usage, processing multi-view sequences faster than their duration (e.g., 36 minutes to process 1 hour 20 minutes). The full pipeline and evaluation code are publicly released.", "conclusion": "Kineo enables practical, robust calibration-free markerless mocap at metric scale with strong accuracy and efficiency gains, supporting reproducibility and broad adoption."}}
{"id": "2510.23936", "categories": ["cs.LG", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.23936", "abs": "https://arxiv.org/abs/2510.23936", "authors": ["Junho Choi", "Teng-Yuan Chang", "Namjung Kim", "Youngjoon Hong"], "title": "A data free neural operator enabling fast inference of 2D and 3D Navier Stokes equations", "comment": null, "summary": "Ensemble simulations of high-dimensional flow models (e.g., Navier Stokes\ntype PDEs) are computationally prohibitive for real time applications. Neural\noperators enable fast inference but are limited by costly data requirements and\npoor generalization to 3D flows. We present a data-free operator network for\nthe Navier Stokes equations that eliminates the need for paired solution data\nand enables robust, real time inference for large ensemble forecasting. The\nphysics-grounded architecture takes initial and boundary conditions as well as\nforcing functions, yielding solutions robust to high variability and\nperturbations. Across 2D benchmarks and 3D test cases, the method surpasses\nprior neural operators in accuracy and, for ensembles, achieves greater\nefficiency than conventional numerical solvers. Notably, it delivers accurate\nsolutions of the three dimensional Navier Stokes equations, a regime not\npreviously demonstrated for data free neural operators. By uniting a\nnumerically grounded architecture with the scalability of machine learning,\nthis approach establishes a practical pathway toward data free, high fidelity\nPDE surrogates for end to end scientific simulation and prediction.", "AI": {"tldr": "Data-free neural operator for 3D Navier\u2013Stokes enabling real-time ensemble forecasting with higher accuracy than prior neural operators and greater efficiency than traditional solvers; requires no paired solution data.", "motivation": "High-dimensional Navier\u2013Stokes ensembles are computationally prohibitive for real-time use. Data-driven operators usually need large paired datasets and struggle with 3D generalization. A data-free, physics-grounded operator could provide fast, robust surrogates for complex flows.", "method": "A physics-grounded neural operator that ingests initial and boundary conditions and forcing terms. The architecture is numerically grounded and data-free, designed to handle high variability and perturbations, enabling end-to-end simulation for ensembles.", "result": "In 2D benchmarks and 3D tests, the method surpasses prior neural operators in accuracy. For ensembles, it is more efficient than conventional solvers and accurately solves 3D Navier\u2013Stokes, a regime not previously demonstrated for data-free operators.", "conclusion": "Merges numerical grounding with machine-learning scalability to deliver data-free, high-fidelity PDE surrogates for real-time simulation and prediction, enabling practical end-to-end scientific forecasting for high-dimensional flows."}}
{"id": "2510.24474", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24474", "abs": "https://arxiv.org/abs/2510.24474", "authors": ["Kyungmin Lee", "Sihyun Yu", "Jinwoo Shin"], "title": "Decoupled MeanFlow: Turning Flow Models into Flow Maps for Accelerated Sampling", "comment": null, "summary": "Denoising generative models, such as diffusion and flow-based models, produce\nhigh-quality samples but require many denoising steps due to discretization\nerror. Flow maps, which estimate the average velocity between timesteps,\nmitigate this error and enable faster sampling. However, their training\ntypically demands architectural changes that limit compatibility with\npretrained flow models. We introduce Decoupled MeanFlow, a simple decoding\nstrategy that converts flow models into flow map models without architectural\nmodifications. Our method conditions the final blocks of diffusion transformers\non the subsequent timestep, allowing pretrained flow models to be directly\nrepurposed as flow maps. Combined with enhanced training techniques, this\ndesign enables high-quality generation in as few as 1 to 4 steps. Notably, we\nfind that training flow models and subsequently converting them is more\nefficient and effective than training flow maps from scratch. On ImageNet\n256x256 and 512x512, our models attain 1-step FID of 2.16 and 2.12,\nrespectively, surpassing prior art by a large margin. Furthermore, we achieve\nFID of 1.51 and 1.68 when increasing the steps to 4, which nearly matches the\nperformance of flow models while delivering over 100x faster inference.", "AI": {"tldr": "Decoupled MeanFlow converts pretrained flow models into flow-map decoders without changing architecture, enabling 1-4 step fast sampling with state-of-the-art 1-step FID on ImageNet and dramatic 100x inference speed-up; training flow models then converting is more efficient than training flow maps from scratch.", "motivation": "Reduce sampling cost in denoising generative models while preserving compatibility with pretrained flow models by decoupling training from architecture.", "method": "Introduce Decoupled MeanFlow decoding strategy: modify final blocks of diffusion transformers to condition on the next timestep, allowing pretrained flow models to be repurposed as flow maps; pair with enhanced training techniques.", "result": "Achieves 1-step FID of 2.16 (256x256) and 2.12 (512x512); 4-step FID of 1.51 and 1.68, nearly matching flow models with over 100x faster inference; training flow models then converting is more efficient than training flow maps from scratch.", "conclusion": "Decoupled MeanFlow enables efficient, high-quality fast sampling without architectural changes, leveraging pretrained flow models to match flow-map performance with minimal steps and major speedups."}}
{"id": "2510.23940", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23940", "abs": "https://arxiv.org/abs/2510.23940", "authors": ["Anastasia-Maria Leventi-Peetz", "J\u00f6rg-Volker Peetz", "Kai Weber", "Nikolaos Zacharis"], "title": "Modeling Biological Multifunctionality with Echo State Networks", "comment": "26 pages, 17 figures, 6 tables, 23 references", "summary": "In this work, a three-dimensional multicomponent reaction-diffusion model has\nbeen developed, combining excitable-system dynamics with diffusion processes\nand sharing conceptual features with the FitzHugh-Nagumo model. Designed to\ncapture the spatiotemporal behavior of biological systems, particularly\nelectrophysiological processes, the model was solved numerically to generate\ntime-series data. These data were subsequently used to train and evaluate an\nEcho State Network (ESN), which successfully reproduced the system's dynamic\nbehavior. The results demonstrate that simulating biological dynamics using\ndata-driven, multifunctional ESN models is both feasible and effective.", "AI": {"tldr": "A 3D multicomponent reaction-diffusion model with excitable dynamics (resembling FitzHugh\u2013Nagumo) generates time-series data used to train an Echo State Network (ESN); the ESN reproduces the system\u2019s spatiotemporal dynamics, demonstrating the feasibility of data-driven ESN models for simulating biological dynamics.", "motivation": "To capture and understand spatiotemporal electrophysiological dynamics in biological systems and to assess whether a data-driven ESN can learn and reproduce such dynamics from numerical simulations.", "method": "Develop a three-dimensional multicomponent reaction-diffusion model with excitable-system dynamics, solve it numerically to produce time-series data, then train and evaluate an Echo State Network on these data.", "result": "The ESN successfully reproduced the system\u2019s dynamic behavior, indicating that data-driven, multifunctional ESN models can feasibly and effectively simulate biological dynamics.", "conclusion": "Data-driven ESN approaches are viable for modeling complex biological spatiotemporal dynamics, illustrating a productive combination of RD electrophysiological models with ESN-based learning."}}
{"id": "2510.24486", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.24486", "abs": "https://arxiv.org/abs/2510.24486", "authors": ["Tinsae G. Dulecha", "Leonardo Righetto", "Ruggero Pintus", "Enrico Gobbetti", "Andrea Giachetti"], "title": "Fast and accurate neural reflectance transformation imaging through knowledge distillation", "comment": "18 pages", "summary": "Reflectance Transformation Imaging (RTI) is very popular for its ability to\nvisually analyze surfaces by enhancing surface details through interactive\nrelighting, starting from only a few tens of photographs taken with a fixed\ncamera and variable illumination. Traditional methods like Polynomial Texture\nMaps (PTM) and Hemispherical Harmonics (HSH) are compact and fast, but struggle\nto accurately capture complex reflectance fields using few per-pixel\ncoefficients and fixed bases, leading to artifacts, especially in highly\nreflective or shadowed areas. The NeuralRTI approach, which exploits a neural\nautoencoder to learn a compact function that better approximates the local\nreflectance as a function of light directions, has been shown to produce\nsuperior quality at comparable storage cost. However, as it performs\ninteractive relighting with custom decoder networks with many parameters, the\nrendering step is computationally expensive and not feasible at full resolution\nfor large images on limited hardware. Earlier attempts to reduce costs by\ndirectly training smaller networks have failed to produce valid results. For\nthis reason, we propose to reduce its computational cost through a novel\nsolution based on Knowledge Distillation (DisK-NeuralRTI). ...", "AI": {"tldr": "A knowledge-distillation-based approach (DisK-NeuralRTI) to reduce rendering cost of NeuralRTI while preserving quality for interactive full-resolution RTI relighting.", "motivation": "RTI methods like PTM/HSH are fast but lack full reflectance fidelity; NeuralRTI improves quality but with high per-frame cost due to a large decoder. Smaller networks previously failed to provide valid results, creating a cost bottleneck for interactive, high-resolution relighting on limited hardware.", "method": "Introduce a knowledge distillation framework: train a compact student network to imitate a high-capacity teacher NeuralRTI decoder, yielding DisK-NeuralRTI with lower inference cost but similar visual fidelity.", "result": "The proposed approach aims to substantially reduce computational cost and enable interactive relighting at full resolution on modest hardware, addressing the primary bottleneck of NeuralRTI.", "conclusion": "Distilling a powerful neural RTI decoder into a compact model is a viable path to practical, real-time RTI systems (DisK-NeuralRTI)."}}
{"id": "2510.23948", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23948", "abs": "https://arxiv.org/abs/2510.23948", "authors": ["Qianfeng Wen", "Zhenwei Tang", "Ashton Anderson"], "title": "ChessQA: Evaluating Large Language Models for Chess Understanding", "comment": "33 pages,8 figures", "summary": "Chess provides an ideal testbed for evaluating the reasoning, modeling, and\nabstraction capabilities of large language models (LLMs), as it has\nwell-defined structure and objective ground truth while admitting a wide\nspectrum of skill levels. However, existing evaluations of LLM ability in chess\nare ad hoc and narrow in scope, making it difficult to accurately measure LLM\nchess understanding and how it varies with scale, post-training methodologies,\nor architecture choices. We present ChessQA, a comprehensive benchmark that\nassesses LLM chess understanding across five task categories (Structural,\nMotifs, Short Tactics, Position Judgment, and Semantic), which approximately\ncorrespond to the ascending abstractions that players master as they accumulate\nchess knowledge, from understanding basic rules and learning tactical motifs to\ncorrectly calculating tactics, evaluating positions, and semantically\ndescribing high-level concepts. In this way, ChessQA captures a more\ncomprehensive picture of chess ability and understanding, going significantly\nbeyond the simple move quality evaluations done previously, and offers a\ncontrolled, consistent setting for diagnosis and comparison. Furthermore,\nChessQA is inherently dynamic, with prompts, answer keys, and construction\nscripts that can evolve as models improve. Evaluating a range of contemporary\nLLMs, we find persistent weaknesses across all five categories and provide\nresults and error analyses by category. We will release the code, periodically\nrefreshed datasets, and a public leaderboard to support further research.", "AI": {"tldr": "ChessQA introduces a dynamic, multi-category benchmark to diagnose LLM chess understanding across five abstraction levels, revealing persistent weaknesses and enabling ongoing evaluation with open resources.", "motivation": "Current chess evaluations with LLMs are ad hoc and narrow; chess provides a structured ground truth and a wide skill spectrum; need scalable, comparable diagnostics across model scale, training methodologies, and architectures.", "method": "Develop ChessQA with five task categories\u2014Structural, Motifs, Short Tactics, Position Judgment, Semantic\u2014mapping to increasing chess knowledge abstractions. Use prompts, answer keys, construction scripts that evolve with model advances. Evaluate contemporary LLMs and provide error analyses by category. Plan to release code, datasets, and a public leaderboard.", "result": "Across contemporary LLMs, persistent weaknesses are observed in all five categories; error analyses by category highlight where capabilities fail. The benchmark is dynamic and repeatable, enabling ongoing tracking of progress.", "conclusion": "ChessQA offers a more comprehensive picture of chess understanding than move-quality metrics, enabling diagnosis, comparison, and tracking of progress across models. It emphasizes abstraction and semantic understanding and will be supported by open resources for community use."}}
{"id": "2510.24514", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24514", "abs": "https://arxiv.org/abs/2510.24514", "authors": ["Huanyu Zhang", "Wenshan Wu", "Chengzu Li", "Ning Shang", "Yan Xia", "Yangyu Huang", "Yifan Zhang", "Li Dong", "Zhang Zhang", "Liang Wang", "Tieniu Tan", "Furu Wei"], "title": "Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs", "comment": null, "summary": "While Multimodal Large Language Models (MLLMs) excel at visual understanding,\nthey often struggle in complex scenarios that require visual planning and\nimagination. Inspired by how humans use sketching as a form of visual thinking\nto develop and communicate ideas, we introduce Latent Sketchpad, a framework\nthat equips MLLMs with an internal visual scratchpad. The internal visual\nrepresentations of MLLMs have traditionally been confined to perceptual\nunderstanding. We repurpose them to support generative visual thought without\ncompromising reasoning ability. Building on frontier MLLMs, our approach\nintegrates visual generation directly into their native autoregressive\nreasoning process. It allows the model to interleave textual reasoning with the\ngeneration of visual latents. These latents guide the internal thought process\nand can be translated into sketch images for interpretability. To realize this,\nwe introduce two components: a Context-Aware Vision Head autoregressively\nproduces visual representations, and a pretrained Sketch Decoder renders these\ninto human-interpretable images. We evaluate the framework on our new dataset\nMazePlanning. Experiments across various MLLMs show that Latent Sketchpad\ndelivers comparable or even superior reasoning performance to their backbone.\nIt further generalizes across distinct frontier MLLMs, including Gemma3 and\nQwen2.5-VL. By extending model's textual reasoning to visual thinking, our\nframework opens new opportunities for richer human-computer interaction and\nbroader applications. More details and resources are available on our project\npage: https://latent-sketchpad.github.io/.", "AI": {"tldr": "Latent Sketchpad adds an internal visual scratchpad to Multimodal LLMs by generating visual latent representations during autoregressive reasoning and rendering them into sketches, enabling visual thinking and interpretability while maintaining or improving reasoning performance. Evaluated on MazePlanning, it generalizes across frontier models (Gemma3, Qwen2.5-VL).", "motivation": "Humans use sketches as a form of visual thinking to develop and communicate ideas. MLLMs excel at perception but struggle with complex planning that benefits from mental visualization. The work aims to fuse visual generation with reasoning to enhance planning capabilities and interpretability.", "method": "Integrates two components into frontier MLLMs: (1) a Context-Aware Vision Head that autoregressively produces visual representations (latent sketches) aligned with the ongoing textual reasoning, and (2) a pretrained Sketch Decoder that renders these latents into human-interpretable sketch images. The visual latents are interleaved with, and influence, the model's autoregressive reasoning. Evaluation is conducted on a new MazePlanning dataset across multiple MLLMs (e.g., Gemma3, Qwen2.5-VL).", "result": "The Latent Sketchpad framework achieves comparable or superior reasoning performance to the backbone models and generalizes to different frontier LLMs (Gemma3, Qwen2.5-VL). The latent visuals can be translated into sketch images, providing interpretable insight into the model\u2019s thought process without compromising reasoning ability.", "conclusion": "Extending textual reasoning with an internal visual thinking process broadens the scope of human\u2013computer interaction and potential applications. The approach is model-agnostic across frontier MLLMs and offers a pathway to richer, more interpretable AI that combines planning with visualization."}}
{"id": "2510.23966", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.23966", "abs": "https://arxiv.org/abs/2510.23966", "authors": ["Scott Emmons", "Roland S. Zimmermann", "David K. Elson", "Rohin Shah"], "title": "A Pragmatic Way to Measure Chain-of-Thought Monitorability", "comment": "The first two authors contributed equally", "summary": "While Chain-of-Thought (CoT) monitoring offers a unique opportunity for AI\nsafety, this opportunity could be lost through shifts in training practices or\nmodel architecture. To help preserve monitorability, we propose a pragmatic way\nto measure two components of it: legibility (whether the reasoning can be\nfollowed by a human) and coverage (whether the CoT contains all the reasoning\nneeded for a human to also produce the final output). We implement these\nmetrics with an autorater prompt that enables any capable LLM to compute the\nlegibility and coverage of existing CoTs. After sanity-checking our prompted\nautorater with synthetic CoT degradations, we apply it to several frontier\nmodels on challenging benchmarks, finding that they exhibit high\nmonitorability. We present these metrics, including our complete autorater\nprompt, as a tool for developers to track how design decisions impact\nmonitorability. While the exact prompt we share is still a preliminary version\nunder ongoing development, we are sharing it now in the hopes that others in\nthe community will find it useful. Our method helps measure the default\nmonitorability of CoT - it should be seen as a complement, not a replacement,\nfor the adversarial stress-testing needed to test robustness against\ndeliberately evasive models.", "AI": {"tldr": "Proposes measuring chain-of-thought monitorability via legibility and coverage using an autorater prompt; early results show frontier models have high monitorability; provides the prompt as a tool for developers; emphasizes complementarity with adversarial testing.", "motivation": "Preserve the ability to monitor and interpret AI chain-of-thought (CoT) reasoning as training practices and architectures evolve, by ensuring humans can follow (legibility) and derive the final output from the reasoning (coverage).", "method": "Define two metrics (legibility and coverage) and implement them with an autorater prompt that enables capable LLMs to evaluate existing CoTs. Validate with synthetic degradations, then apply to frontier models on challenging benchmarks. Share the complete autorater prompt and encourage community use as a monitoring tool.", "result": "Frontier models show high monitorability according to the proposed metrics. The metrics and autorater prompt provide a practical tool for developers to track design decisions on monitorability, though the exact prompt is preliminary and should complement, not replace, adversarial stress-testing.", "conclusion": "The proposed legibility and coverage metrics, implemented via an autorater prompt, offer a pragmatic way to maintain CoT monitorability; they should be used alongside adversarial testing to assess robustness against evasive models."}}
{"id": "2510.24563", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24563", "abs": "https://arxiv.org/abs/2510.24563", "authors": ["Hongrui Jia", "Jitong Liao", "Xi Zhang", "Haiyang Xu", "Tianbao Xie", "Chaoya Jiang", "Ming Yan", "Si Liu", "Wei Ye", "Fei Huang"], "title": "OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents", "comment": null, "summary": "With advances in decision-making and reasoning capabilities, multimodal\nagents show strong potential in computer application scenarios. Past\nevaluations have mainly assessed GUI interaction skills, while tool invocation\nabilities, such as those enabled by the Model Context Protocol (MCP), have been\nlargely overlooked. Comparing agents with integrated tool invocation to those\nevaluated only on GUI interaction is inherently unfair. We present OSWorld-MCP,\nthe first comprehensive and fair benchmark for assessing computer-use agents'\ntool invocation, GUI operation, and decision-making abilities in a real-world\nenvironment. We design a novel automated code-generation pipeline to create\ntools and combine them with a curated selection from existing tools. Rigorous\nmanual validation yields 158 high-quality tools (covering 7 common\napplications), each verified for correct functionality, practical\napplicability, and versatility. Extensive evaluations of state-of-the-art\nmultimodal agents on OSWorld-MCP show that MCP tools generally improve task\nsuccess rates (e.g., from 8.3% to 20.4% for OpenAI o3 at 15 steps, from 40.1%\nto 43.3% for Claude 4 Sonnet at 50 steps), underscoring the importance of\nassessing tool invocation capabilities. However, even the strongest models have\nrelatively low tool invocation rates, Only 36.3%, indicating room for\nimprovement and highlighting the benchmark's challenge. By explicitly measuring\nMCP tool usage skills, OSWorld-MCP deepens understanding of multimodal agents\nand sets a new standard for evaluating performance in complex, tool-assisted\nenvironments. Our code, environment, and data are publicly available at\nhttps://osworld-mcp.github.io.", "AI": {"tldr": "OSWorld-MCP introduces a comprehensive, fair benchmark for evaluating multimodal agents on tool invocation, GUI interaction, and decision-making in real-world settings, using a large catalog of validated MCP-enabled tools; results show MCP tools boost task success but tool usage remains relatively low, highlighting room for progress and the benchmark's challenge.", "motivation": "To address the lack of fair, integrated evaluation of tool invocation capabilities in multimodal agents, which commonly focus only on GUI interactions, thereby misrepresenting overall agent competence in real-world tool usage.", "method": "Developed OSWorld-MCP with an automated pipeline that generates tools and curates 158 high-quality MCP-enabled tools across 7 applications. Conducted manual validation and extensive evaluations of state-of-the-art multimodal agents, measuring task success and tool invocation rates at various step counts.", "result": "Tool-enabled interactions improved performance (e.g., OpenAI o3: 8.3%\u219220.4% at 15 steps; Claude 4 Sonnet: 40.1%\u219243.3% at 50 steps). Overall tool invocation rate among strongest models was 36.3%, indicating substantial room for improvement; the benchmark reveals the importance and difficulty of evaluating tool usage in real-world tasks.", "conclusion": "OSWorld-MCP sets a new standard for evaluating complex, tool-assisted decision-making in multimodal agents, highlighting the need to measure tool invocation explicitly and encouraging further advancement in model capabilities and benchmark design; the authors provide code, environment, and data publicly."}}
{"id": "2510.23972", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23972", "abs": "https://arxiv.org/abs/2510.23972", "authors": ["Andra\u017e Jelin\u010di\u010d", "Owen Lockwood", "Akhil Garlapati", "Guillaume Verdon", "Trevor McCourt"], "title": "An efficient probabilistic hardware architecture for diffusion-like models", "comment": "9 pages, 6 figures", "summary": "The proliferation of probabilistic AI has promoted proposals for specialized\nstochastic computers. Despite promising efficiency gains, these proposals have\nfailed to gain traction because they rely on fundamentally limited modeling\ntechniques and exotic, unscalable hardware. In this work, we address these\nshortcomings by proposing an all-transistor probabilistic computer that\nimplements powerful denoising models at the hardware level. A system-level\nanalysis indicates that devices based on our architecture could achieve\nperformance parity with GPUs on a simple image benchmark using approximately\n10,000 times less energy.", "AI": {"tldr": "An all-transistor probabilistic computer implementing denoising models at hardware level; system-level analysis suggests parity with GPUs on image tasks with ~10,000\u00d7 energy savings.", "motivation": "Current probabilistic AI hardware proposals rely on limited modeling techniques and exotic hardware; there is a need for scalable, energy-efficient hardware to realize probabilistic models.", "method": "Design of an all-transistor probabilistic computer that implements denoising models at hardware level; perform a system-level analysis comparing its energy-performance to GPUs on a simple image benchmark; estimate potential energy efficiency.", "result": "Architecture could match GPU performance on a simple image benchmark while consuming ~10,000\u00d7 less energy.", "conclusion": "Hardware-level denoising via a transistor-based probabilistic computer shows promise for energy-efficient probabilistic AI; validation on real devices and broader benchmarks is needed to confirm practicality."}}
{"id": "2510.24579", "categories": ["cs.CV", "I.4.5; I.5"], "pdf": "https://arxiv.org/pdf/2510.24579", "abs": "https://arxiv.org/abs/2510.24579", "authors": ["Xu Jiang", "Huiying Pan", "Ligen Shi", "Jianing Sun", "Wenfeng Xu", "Xing Zhao"], "title": "Physics-Inspired Gaussian Kolmogorov-Arnold Networks for X-ray Scatter Correction in Cone-Beam CT", "comment": "8 pages, 6 figures", "summary": "Cone-beam CT (CBCT) employs a flat-panel detector to achieve\nthree-dimensional imaging with high spatial resolution. However, CBCT is\nsusceptible to scatter during data acquisition, which introduces CT value bias\nand reduced tissue contrast in the reconstructed images, ultimately degrading\ndiagnostic accuracy. To address this issue, we propose a deep learning-based\nscatter artifact correction method inspired by physical prior knowledge.\nLeveraging the fact that the observed point scatter probability density\ndistribution exhibits rotational symmetry in the projection domain. The method\nuses Gaussian Radial Basis Functions (RBF) to model the point scatter function\nand embeds it into the Kolmogorov-Arnold Networks (KAN) layer, which provides\nefficient nonlinear mapping capabilities for learning high-dimensional scatter\nfeatures. By incorporating the physical characteristics of the scattered photon\ndistribution together with the complex function mapping capacity of KAN, the\nmodel improves its ability to accurately represent scatter. The effectiveness\nof the method is validated through both synthetic and real-scan experiments.\nExperimental results show that the model can effectively correct the scatter\nartifacts in the reconstructed images and is superior to the current methods in\nterms of quantitative metrics.", "AI": {"tldr": "A deep learning\u2013based scatter artifact correction for CBCT that models the point scatter function with Gaussian radial basis functions and a Kolmogorov\u2013Arnold Network layer, leveraging rotational symmetry; validated on synthetic and real data with superior quantitative performance over existing methods.", "motivation": "CBCT scatter causes CT value bias and reduced tissue contrast, harming diagnostic accuracy; a physics-informed DL approach can better represent scatter and restore image quality.", "method": "Model point scatter with Gaussian RBFs; integrate into a Kolmogorov\u2013Arnold Network to enable nonlinear mapping; exploit rotational symmetry in projection domain; validate on synthetic and real-scan datasets.", "result": "Demonstrates effective scatter correction in reconstructed images and outperforms current methods on quantitative metrics.", "conclusion": "The proposed physics-informed DL framework improves CBCT scatter correction, combining physical priors with powerful nonlinear learning, and generalizes to both synthetic and real data."}}
{"id": "2510.23974", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23974", "abs": "https://arxiv.org/abs/2510.23974", "authors": ["Byeonghu Na", "Minsang Park", "Gyuwon Sim", "Donghyeok Shin", "HeeSun Bae", "Mina Kang", "Se Jung Kwon", "Wanmo Kang", "Il-Chul Moon"], "title": "Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models", "comment": "Accepted at NeurIPS 2025", "summary": "Text-to-image diffusion models rely on text embeddings from a pre-trained\ntext encoder, but these embeddings remain fixed across all diffusion timesteps,\nlimiting their adaptability to the generative process. We propose Diffusion\nAdaptive Text Embedding (DATE), which dynamically updates text embeddings at\neach diffusion timestep based on intermediate perturbed data. We formulate an\noptimization problem and derive an update rule that refines the text embeddings\nat each sampling step to improve alignment and preference between the mean\npredicted image and the text. This allows DATE to dynamically adapts the text\nconditions to the reverse-diffused images throughout diffusion sampling without\nrequiring additional model training. Through theoretical analysis and empirical\nresults, we show that DATE maintains the generative capability of the model\nwhile providing superior text-image alignment over fixed text embeddings across\nvarious tasks, including multi-concept generation and text-guided image\nediting. Our code is available at https://github.com/aailab-kaist/DATE.", "AI": {"tldr": "DATE dynamically updates text embeddings at every diffusion timestep to improve text-image alignment without retraining.", "motivation": "Fixed text embeddings in diffusion models limit adaptability to intermediate data and the generative process; better alignment between prompt and evolving image is desirable.", "method": "Formulate an optimization at each sampling step to update the text embeddings based on intermediate perturbed data; derive an update rule that refines embeddings to better align the mean predicted image with the text; requires no additional training.", "result": "Theoretical analysis supports maintained generative capability; empirical results show superior text-image alignment over fixed embeddings across tasks like multi-concept generation and text-guided editing.", "conclusion": "Dynamic conditioning via DATE improves alignment while preserving diffusion model capability, applicable to various prompts and editing tasks; code provided."}}
{"id": "2510.24640", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24640", "abs": "https://arxiv.org/abs/2510.24640", "authors": ["Xin Zhang", "Yuqi Song", "Fei Zuo"], "title": "A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries", "comment": null, "summary": "The rapid advancement of generative AI has enabled the creation of highly\nrealistic forged facial images, posing significant threats to AI security,\ndigital media integrity, and public trust. Face forgery techniques, ranging\nfrom face swapping and attribute editing to powerful diffusion-based image\nsynthesis, are increasingly being used for malicious purposes such as\nmisinformation, identity fraud, and defamation. This growing challenge\nunderscores the urgent need for robust and generalizable face forgery detection\nmethods as a critical component of AI security infrastructure. In this work, we\npropose a novel dual-branch convolutional neural network for face forgery\ndetection that leverages complementary cues from both spatial and frequency\ndomains. The RGB branch captures semantic information, while the frequency\nbranch focuses on high-frequency artifacts that are difficult for generative\nmodels to suppress. A channel attention module is introduced to adaptively fuse\nthese heterogeneous features, highlighting the most informative channels for\nforgery discrimination. To guide the network's learning process, we design a\nunified loss function, FSC Loss, that combines focal loss, supervised\ncontrastive loss, and a frequency center margin loss to enhance class\nseparability and robustness. We evaluate our model on the DiFF benchmark, which\nincludes forged images generated from four representative methods:\ntext-to-image, image-to-image, face swap, and face edit. Our method achieves\nstrong performance across all categories and outperforms average human\naccuracy. These results demonstrate the model's effectiveness and its potential\ncontribution to safeguarding AI ecosystems against visual forgery attacks.", "AI": {"tldr": "A dual-branch RGB+frequency CNN with channel attention and FSC Loss for robust face forgery detection, achieving state-of-the-art performance on the DiFF benchmark and surpassing average human accuracy.", "motivation": "Rapid advances in generative AI enable highly realistic forged faces, threatening AI security, digital media integrity, and public trust. There is an urgent need for robust, generalizable face forgery detectors as a key component of AI security infrastructure.", "method": "A dual-branch convolutional neural network. The RGB branch captures semantic information; the frequency branch targets high-frequency artifacts that are hard for generative models to suppress. A channel attention module adaptively fuses these heterogeneous features. A unified FSC Loss combines focal loss, supervised contrastive loss, and a frequency center margin loss to improve class separability and robustness.", "result": "The model achieves strong performance across all DiFF categories (text-to-image, image-to-image, face swap, face edit) and outperforms average human accuracy on the benchmark.", "conclusion": "The proposed approach is effective and generalizable for face forgery detection, contributing to AI security infrastructure by enabling robust detection of diverse forgery techniques."}}
{"id": "2510.23977", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.23977", "abs": "https://arxiv.org/abs/2510.23977", "authors": ["Yohan Abeysinghe", "Muhammad Akhtar Munir", "Sanoojan Baliah", "Ron Sarafian", "Fahad Shahbaz Khan", "Yinon Rudich", "Salman Khan"], "title": "Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling", "comment": null, "summary": "Air pollution remains a leading global health and environmental risk,\nparticularly in regions vulnerable to episodic air pollution spikes due to\nwildfires, urban haze and dust storms. Accurate forecasting of particulate\nmatter (PM) concentrations is essential to enable timely public health warnings\nand interventions, yet existing models often underestimate rare but hazardous\npollution events. Here, we present SynCast, a high-resolution neural\nforecasting model that integrates meteorological and air composition data to\nimprove predictions of both average and extreme pollution levels. Built on a\nregionally adapted transformer backbone and enhanced with a diffusion-based\nstochastic refinement module, SynCast captures the nonlinear dynamics driving\nPM spikes more accurately than existing approaches. Leveraging on harmonized\nERA5 and CAMS datasets, our model shows substantial gains in forecasting\nfidelity across multiple PM variables (PM$_1$, PM$_{2.5}$, PM$_{10}$),\nespecially under extreme conditions. We demonstrate that conventional loss\nfunctions underrepresent distributional tails (rare pollution events) and show\nthat SynCast, guided by domain-aware objectives and extreme value theory,\nsignificantly enhances performance in highly impacted regions without\ncompromising global accuracy. This approach provides a scalable foundation for\nnext-generation air quality early warning systems and supports climate-health\nrisk mitigation in vulnerable regions.", "AI": {"tldr": "SynCast is a high-resolution transformer-based PM forecasting model with diffusion-based stochastic refinement that integrates ERA5 and CAMS data to improve predictions of average and extreme PM levels (PM1, PM2.5, PM10), addressing tail events with domain-aware objectives and extreme value theory for better performance in highly impacted regions without sacrificing global accuracy.", "motivation": "Air pollution causes significant health and environmental risks, and accurate forecasts are crucial for timely warnings. Rare but hazardous pollution spikes from wildfires, haze, and dust storms are often underestimated by existing models, necessitating tail-aware forecasting approaches.", "method": "A regionally adapted transformer backbone augmented with a diffusion-based stochastic refinement module. The model fuses meteorological data and air composition data using harmonized ERA5 and CAMS datasets and optimizes with domain-aware objectives and extreme value theory to improve tail predictions for PM1, PM2.5, and PM10.", "result": "SynCast achieves substantial gains in forecasting fidelity for multiple PM variables, with improved performance under extreme conditions and without compromising global (mean) accuracy, outperforming existing approaches.", "conclusion": "This framework provides a scalable foundation for next-generation air quality early warning systems and climate-health risk mitigation in vulnerable regions, with potential applicability to other pollutants and extreme-event forecasting."}}
{"id": "2510.24653", "categories": ["cs.CV", "cs.HC", "J.3"], "pdf": "https://arxiv.org/pdf/2510.24653", "abs": "https://arxiv.org/abs/2510.24653", "authors": ["Veronica Thai", "Rui Li", "Meng Ling", "Shuning Jiang", "Jeremy Wolfe", "Raghu Machiraju", "Yan Hu", "Zaibo Li", "Anil Parwani", "Jian Chen"], "title": "Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology", "comment": "16 pages, 9 figures, submitted to Nature Scientific Data", "summary": "Interpretation of giga-pixel whole-slide images (WSIs) is an important but\ndifficult task for pathologists. Their diagnostic accuracy is estimated to\naverage around 70%. Adding a second pathologist does not substantially improve\ndecision consistency. The field lacks adequate behavioral data to explain\ndiagnostic errors and inconsistencies. To fill in this gap, we present\nPathoGaze1.0, a comprehensive behavioral dataset capturing the dynamic visual\nsearch and decision-making processes of the full diagnostic workflow during\ncancer diagnosis. The dataset comprises 18.69 hours of eye-tracking, mouse\ninteraction, stimulus tracking, viewport navigation, and diagnostic decision\ndata (EMSVD) collected from 19 pathologists interpreting 397 WSIs. The data\ncollection process emphasizes ecological validity through an\napplication-grounded testbed, called PTAH. In total, we recorded 171,909\nfixations, 263,320 saccades, and 1,867,362 mouse interaction events. In\naddition, such data could also be used to improve the training of both\npathologists and AI systems that might support human experts. All experiments\nwere preregistered at https://osf.io/hj9a7, and the complete dataset along with\nanalysis code is available at https://go.osu.edu/pathogaze.", "AI": {"tldr": "PathoGaze1.0 is a large multimodal behavioral dataset of pathologists diagnosing cancer on giga-pixel WSIs, enabling study of gaze and decision processes and potential AI\u2013human collaboration.", "motivation": "Addresses the lack of behavioral data to explain diagnostic errors and inconsistencies in WSI interpretation; aims to improve training for pathologists and to support AI systems that assist human experts, with ecological validity through an application-grounded testbed.", "method": "Data were collected from 19 pathologists interpreting 397 whole-slide images (WSIs) using the PTAH testbed, recording 18.69 hours of multimodal data (eye-tracking, mouse interactions, stimulus tracking, viewport navigation, and diagnostic decisions). The study was preregistered, and the complete dataset and analysis code are public.", "result": "The dataset comprises 171,909 fixations, 263,320 saccades, and 1,867,362 mouse interaction events, across 19 participants and 397 WSIs, providing a rich resource for analyzing diagnostic behavior and training AI or human-in-the-loop systems.", "conclusion": "PathoGaze1.0 offers a comprehensive, ecologically valid resource to understand diagnostic variability and to support education and AI-assisted pathology, with public availability of data and code for reproducible research."}}
{"id": "2510.23980", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.23980", "abs": "https://arxiv.org/abs/2510.23980", "authors": ["Guojing Cong", "Tom Potok", "Hamed Poursiami", "Maryam Parsa"], "title": "HyperGraphX: Graph Transductive Learning with Hyperdimensional Computing and Message Passing", "comment": null, "summary": "We present a novel algorithm, \\hdgc, that marries graph convolution with\nbinding and bundling operations in hyperdimensional computing for transductive\ngraph learning. For prediction accuracy \\hdgc outperforms major and popular\ngraph neural network implementations as well as state-of-the-art\nhyperdimensional computing implementations for a collection of homophilic\ngraphs and heterophilic graphs. Compared with the most accurate learning\nmethodologies we have tested, on the same target GPU platform, \\hdgc is on\naverage 9561.0 and 144.5 times faster than \\gcnii, a graph neural network\nimplementation and HDGL, a hyperdimensional computing implementation,\nrespectively. As the majority of the learning operates on binary vectors, we\nexpect outstanding energy performance of \\hdgc on neuromorphic and emerging\nprocess-in-memory devices.", "AI": {"tldr": "HDGC is a novel algorithm that combines graph convolution with binding and bundling in hyperdimensional computing for transductive graph learning, delivering higher accuracy and orders-of-magnitude speedups over state-of-the-art GNNs and HD methods, with energy-efficiency potential on binary-vector hardware.", "motivation": "To improve predictive accuracy on both homophilic and heterophilic graphs while reducing computational cost by integrating graph learning with hyperdimensional computing's binding/bundling operations.", "method": "Proposes HDGC architecture that marries graph convolution with HD computing operations (binding and bundling) for transductive graph learning on binary vectors; evaluated on a GPU platform against GNN and HD methods across homophilic and heterophilic graphs.", "result": "HDGC outperforms major GNNs and state-of-the-art HD methods in accuracy across tested graphs; achieves up to about 9,561x faster than GCNII and 144.5x faster than HDGL on same GPU platform; learning predominantly on binary vectors suggests energy efficiency on neuromorphic or in-memory devices.", "conclusion": "HDGC demonstrates a compelling combination of accuracy and speed, with strong implications for energy-efficient graph learning on specialized hardware; promising for future hardware-friendly HD-based graph models."}}
{"id": "2510.24657", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24657", "abs": "https://arxiv.org/abs/2510.24657", "authors": ["Xuanpu Zhang", "Xuesong Niu", "Ruidong Chen", "Dan Song", "Jianhao Zeng", "Penghui Du", "Haoxiang Cao", "Kai Wu", "An-an Liu"], "title": "Group Relative Attention Guidance for Image Editing", "comment": null, "summary": "Recently, image editing based on Diffusion-in-Transformer models has\nundergone rapid development. However, existing editing methods often lack\neffective control over the degree of editing, limiting their ability to achieve\nmore customized results. To address this limitation, we investigate the\nMM-Attention mechanism within the DiT model and observe that the Query and Key\ntokens share a bias vector that is only layer-dependent. We interpret this bias\nas representing the model's inherent editing behavior, while the delta between\neach token and its corresponding bias encodes the content-specific editing\nsignals. Based on this insight, we propose Group Relative Attention Guidance, a\nsimple yet effective method that reweights the delta values of different tokens\nto modulate the focus of the model on the input image relative to the editing\ninstruction, enabling continuous and fine-grained control over editing\nintensity without any tuning. Extensive experiments conducted on existing image\nediting frameworks demonstrate that GRAG can be integrated with as few as four\nlines of code, consistently enhancing editing quality. Moreover, compared to\nthe commonly used Classifier-Free Guidance, GRAG achieves smoother and more\nprecise control over the degree of editing. Our code will be released at\nhttps://github.com/little-misfit/GRAG-Image-Editing.", "AI": {"tldr": "GRAG introduces Group Relative Attention Guidance to continuously control editing intensity in diffusion-based image editing by reweighting token deltas in DiT's MM-Attention, achieving smoother, more precise edits with minimal code.", "motivation": "Current diffusion-in-transformer editing methods lack fine-grained control over editing strength, limiting customization of results.", "method": "Investigate MM-Attention bias: Query/Key share a layer-dependent bias; interpret as inherent editing behavior; delta between token and bias encodes content-specific edit signals. Propose GRAG to reweight token deltas, modulating focus relative to editing instruction without tuning.", "result": "GRAG can be plugged in with as few as four lines of code, improves editing quality, and provides smoother/more precise control compared with classifier-free guidance.", "conclusion": "GRAG is a simple, effective mechanism for continuous editing control in diffusion-based image editing and can be broadly integrated; code will be released."}}
{"id": "2510.23986", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.23986", "abs": "https://arxiv.org/abs/2510.23986", "authors": ["Hong Wang", "Jiang Yixuan", "Jie Wang", "Xinyi Li", "Jian Luo", "Huanshuo Dong"], "title": "STNet: Spectral Transformation Network for Solving Operator Eigenvalue Problem", "comment": null, "summary": "Operator eigenvalue problems play a critical role in various scientific\nfields and engineering applications, yet numerical methods are hindered by the\ncurse of dimensionality. Recent deep learning methods provide an efficient\napproach to address this challenge by iteratively updating neural networks.\nThese methods' performance relies heavily on the spectral distribution of the\ngiven operator: larger gaps between the operator's eigenvalues will improve\nprecision, thus tailored spectral transformations that leverage the spectral\ndistribution can enhance their performance. Based on this observation, we\npropose the Spectral Transformation Network (STNet). During each iteration,\nSTNet uses approximate eigenvalues and eigenfunctions to perform spectral\ntransformations on the original operator, turning it into an equivalent but\neasier problem. Specifically, we employ deflation projection to exclude the\nsubspace corresponding to already solved eigenfunctions, thereby reducing the\nsearch space and avoiding converging to existing eigenfunctions. Additionally,\nour filter transform magnifies eigenvalues in the desired region and suppresses\nthose outside, further improving performance. Extensive experiments demonstrate\nthat STNet consistently outperforms existing learning-based methods, achieving\nstate-of-the-art performance in accuracy.", "AI": {"tldr": "Spectral Transformation Network (STNet) improves neural-network-based eigenvalue computations by applying spectral transformations to the operator during training, using deflation to remove solved subspaces and a filter transform to emphasize a target spectral region; achieves state-of-the-art accuracy on benchmark tests.", "motivation": "Eigenvalue problems in high dimensions suffer from the curse of dimensionality. The performance of learning-based eigen-solvers depends on the operator's spectral distribution; larger eigenvalue gaps typically yield better accuracy and convergence. Tailored spectral transformations can exploit this distribution to improve learning-based solvers.", "method": "STNet iteratively applies spectral transformations to the operator using approximate eigenvalues/eigenfunctions. Deflation projection excludes subspaces corresponding to already solved eigenfunctions to reduce the search space and avoid convergence to known eigenpairs. A filter transform magnifies eigenvalues in a target region while suppressing others, guiding the network to compute desired eigenpairs.", "result": "Empirical evaluations show STNet consistently outperforms existing learning-based methods, achieving state-of-the-art accuracy in eigenvalue problems.", "conclusion": "Incorporating spectral transformations\u2014via deflation and filtering\u2014into a learning-based framework yields significant improvements for operator eigenvalue problems, particularly when leveraging the operator's spectral distribution."}}
{"id": "2510.24667", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24667", "abs": "https://arxiv.org/abs/2510.24667", "authors": ["Mia Kan", "Yilin Liu", "Niloy Mitra"], "title": "SAGE: Structure-Aware Generative Video Transitions between Diverse Clips", "comment": "Website: https://kan32501.github.io/sage.github.io/", "summary": "Video transitions aim to synthesize intermediate frames between two clips,\nbut naive approaches such as linear blending introduce artifacts that limit\nprofessional use or break temporal coherence. Traditional techniques\n(cross-fades, morphing, frame interpolation) and recent generative inbetweening\nmethods can produce high-quality plausible intermediates, but they struggle\nwith bridging diverse clips involving large temporal gaps or significant\nsemantic differences, leaving a gap for content-aware and visually coherent\ntransitions. We address this challenge by drawing on artistic workflows,\ndistilling strategies such as aligning silhouettes and interpolating salient\nfeatures to preserve structure and perceptual continuity. Building on this, we\npropose SAGE (Structure-Aware Generative vidEo transitions) as a zeroshot\napproach that combines structural guidance, provided via line maps and motion\nflow, with generative synthesis, enabling smooth, semantically consistent\ntransitions without fine-tuning. Extensive experiments and comparison with\ncurrent alternatives, namely [FILM, TVG, DiffMorpher, VACE, GI], demonstrate\nthat SAGE outperforms both classical and generative baselines on quantitative\nmetrics and user studies for producing transitions between diverse clips. Code\nto be released on acceptance.", "AI": {"tldr": "A zero-shot structure-aware video transition framework (SAGE) that uses line-map and motion-flow guidance with generative synthesis to produce coherent, semantically consistent intermediate frames between diverse clips, without fine-tuning, outperforming classical and generative baselines in both quantitative metrics and user studies.", "motivation": "Video transitions often suffer from artifacts when using simple blending or when bridging clips with large temporal gaps or semantic differences. Existing methods (cross-fades, morphing, frame interpolation, and some generative inbetweening) struggle to maintain structure and perceptual continuity across diverse content, creating a gap for content-aware, visually coherent transitions.", "method": "Introduce SAGE (Structure-Aware Generative vidEo transitions), a zero-shot approach that combines structural guidance (line maps and motion flow) with generative synthesis to produce transitions. It leverages alignment of silhouettes and interpolation of salient features to preserve structure without requiring fine-tuning on new clips.", "result": "Extensive experiments and comparisons against FILM, TVG, DiffMorpher, VACE, and GI show that SAGE achieves superior performance on quantitative metrics and user studies for transitions between diverse clips.", "conclusion": "SAGE demonstrates that explicit structural guidance paired with generative synthesis enables smooth, semantically consistent video transitions across diverse content without fine-tuning, indicating strong potential for professional workflows; code will be released on acceptance."}}
{"id": "2510.23992", "categories": ["cs.LG", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.23992", "abs": "https://arxiv.org/abs/2510.23992", "authors": ["Yuxiao Wen", "Yanjun Han", "Zhengyuan Zhou"], "title": "Optimal Arm Elimination Algorithms for Combinatorial Bandits", "comment": null, "summary": "Combinatorial bandits extend the classical bandit framework to settings where\nthe learner selects multiple arms in each round, motivated by applications such\nas online recommendation and assortment optimization. While extensions of upper\nconfidence bound (UCB) algorithms arise naturally in this context, adapting arm\nelimination methods has proved more challenging. We introduce a novel\nelimination scheme that partitions arms into three categories (confirmed,\nactive, and eliminated), and incorporates explicit exploration to update these\nsets. We demonstrate the efficacy of our algorithm in two settings: the\ncombinatorial multi-armed bandit with general graph feedback, and the\ncombinatorial linear contextual bandit. In both cases, our approach achieves\nnear-optimal regret, whereas UCB-based methods can provably fail due to\ninsufficient explicit exploration. Matching lower bounds are also provided.", "AI": {"tldr": "Introduces a novel three-set elimination scheme for combinatorial bandits with explicit exploration, achieving near-optimal regret and matching lower bounds in both combinatorial MAB with graph feedback and combinatorial linear contextual bandits; highlights limitations of UCB-based methods due to insufficient exploration.", "motivation": "Extend bandit algorithms to combinatorial actions, addressing the elimination challenge in high-dimensional action spaces while ensuring exploration guarantees; motivated by online recommendations and assortment optimization.", "method": "Proposes an elimination scheme that partitions arms into confirmed, active, and eliminated categories and injects explicit exploration steps to update these sets; applies to two settings: combinatorial MAB with graph feedback and combinatorial linear contextual bandits.", "result": "Achieves near-optimal regret in both settings; provides matching lower bounds; demonstrates that UCB-based methods can fail without explicit exploration.", "conclusion": "The three-set elimination with explicit exploration offers robust performance and better regret guarantees than standard UCB approaches in these combinatorial settings."}}
{"id": "2510.24688", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24688", "abs": "https://arxiv.org/abs/2510.24688", "authors": ["Yun Zhang", "Zhaoliang Zheng", "Johnson Liu", "Zhiyu Huang", "Zewei Zhou", "Zonglin Meng", "Tianhui Cai", "Jiaqi Ma"], "title": "MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection", "comment": null, "summary": "Infrastructure-based perception plays a crucial role in intelligent\ntransportation systems, offering global situational awareness and enabling\ncooperative autonomy. However, existing camera-based detection models often\nunderperform in such scenarios due to challenges such as multi-view\ninfrastructure setup, diverse camera configurations, degraded visual inputs,\nand various road layouts. We introduce MIC-BEV, a Transformer-based\nbird's-eye-view (BEV) perception framework for infrastructure-based\nmulti-camera 3D object detection. MIC-BEV flexibly supports a variable number\nof cameras with heterogeneous intrinsic and extrinsic parameters and\ndemonstrates strong robustness under sensor degradation. The proposed\ngraph-enhanced fusion module in MIC-BEV integrates multi-view image features\ninto the BEV space by exploiting geometric relationships between cameras and\nBEV cells alongside latent visual cues. To support training and evaluation, we\nintroduce M2I, a synthetic dataset for infrastructure-based object detection,\nfeaturing diverse camera configurations, road layouts, and environmental\nconditions. Extensive experiments on both M2I and the real-world dataset\nRoScenes demonstrate that MIC-BEV achieves state-of-the-art performance in 3D\nobject detection. It also remains robust under challenging conditions,\nincluding extreme weather and sensor degradation. These results highlight the\npotential of MIC-BEV for real-world deployment. The dataset and source code are\navailable at: https://github.com/HandsomeYun/MIC-BEV.", "AI": {"tldr": "MIC-BEV is a Transformer-based BEV perception framework for infrastructure-based multi-camera 3D object detection that handles flexible camera counts and heterogeneous camera parameters, with a graph-enhanced fusion module. It introduces the synthetic M2I dataset and achieves state-of-the-art results on M2I and RoScenes, including robustness under extreme weather and sensor degradation; code and data are released.", "motivation": "Infrastructure-based intelligent transportation systems require global situational awareness and cooperative perception, but camera-based detectors struggle with multi-view infrastructure setups, varied camera configurations, degraded visual inputs, and diverse road layouts. A robust, flexible fusion approach across heterogeneous cameras is needed, along with datasets that cover realistic variations.", "method": "MIC-BEV uses a Transformer-based BEV perception backbone. It features a graph-enhanced fusion module that fuses multi-view image features into BEV space by exploiting geometric relationships between cameras and BEV cells and leveraging latent visual cues. The system supports a variable number of cameras with heterogeneous intrinsic and extrinsic parameters. It additionally introduces M2I, a synthetic dataset with diverse camera configurations, road layouts, and environmental conditions for infrastructure-based object detection.", "result": "MIC-BEV achieves state-of-the-art 3D object detection performance on both the synthetic M2I dataset and the real-world RoScenes dataset. It maintains robustness under challenging conditions, including extreme weather and sensor degradation.", "conclusion": "MIC-BEV demonstrates that flexible, Transformer-based BEV perception with graph-enhanced fusion is viable for real-world infrastructure-based deployment. The synthetic M2I dataset complements real data to cover diverse configurations. The work provides a promising path toward robust, scalable infrastructure-based perception, with code and data available for reproducibility."}}
{"id": "2510.23994", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.23994", "abs": "https://arxiv.org/abs/2510.23994", "authors": ["Geoffery Agorku", "Sarah Hernandez", "Hayley Hames", "Cade Wagner"], "title": "Predicting Barge Tow Size on Inland Waterways Using Vessel Trajectory Derived Features: Proof of Concept", "comment": null, "summary": "Accurate, real-time estimation of barge quantity on inland waterways remains\na critical challenge due to the non-self-propelled nature of barges and the\nlimitations of existing monitoring systems. This study introduces a novel\nmethod to use Automatic Identification System (AIS) vessel tracking data to\npredict the number of barges in tow using Machine Learning (ML). To train and\ntest the model, barge instances were manually annotated from satellite scenes\nacross the Lower Mississippi River. Labeled images were matched to AIS vessel\ntracks using a spatiotemporal matching procedure. A comprehensive set of 30\nAIS-derived features capturing vessel geometry, dynamic movement, and\ntrajectory patterns were created and evaluated using Recursive Feature\nElimination (RFE) to identify the most predictive variables. Six regression\nmodels, including ensemble, kernel-based, and generalized linear approaches,\nwere trained and evaluated. The Poisson Regressor model yielded the best\nperformance, achieving a Mean Absolute Error (MAE) of 1.92 barges using 12 of\nthe 30 features. The feature importance analysis revealed that metrics\ncapturing vessel maneuverability such as course entropy, speed variability and\ntrip length were most predictive of barge count. The proposed approach provides\na scalable, readily implementable method for enhancing Maritime Domain\nAwareness (MDA), with strong potential applications in lock scheduling, port\nmanagement, and freight planning. Future work will expand the proof of concept\npresented here to explore model transferability to other inland rivers with\ndiffering operational and environmental conditions.", "AI": {"tldr": "Poisson regression with AIS-derived features predicts barge count from satellite-annotated data, achieving MAE 1.92 using 12 features; key predictors are course entropy, speed variability and trip length; scalable approach for Maritime Domain Awareness with transferability to other rivers.", "motivation": "Accurate, real-time estimation of tow size on inland waterways is challenging due to non-self-propelled barges and limited monitoring. The work aims to enhance Maritime Domain Awareness (MDA) by leveraging AIS tracking and ML to estimate barge counts, improving operations like lock scheduling and freight planning.", "method": "Collect AIS data and manually annotated barge instances from satellite scenes along the Lower Mississippi River. Spatiotemporal matching linked AIS tracks to labeled barges. Derived 30 AIS-based features covering geometry, dynamics, and trajectories. Used Recursive Feature Elimination to select predictive features. Trained six regression models across ensemble, kernel-based, and GLM families. Poisson Regressor performed best with MAE=1.92 using 12 features.", "result": "Poisson Regressor emerged as the best model, achieving MAE of 1.92 barges using 12 of the 30 features. Feature importance highlighted maneuverability measures such as course entropy, speed variability, and trip length as the most predictive. The study demonstrates a scalable approach to estimate barge counts for MDA and river logistics, with potential applications in lock scheduling, port management, and freight planning.", "conclusion": "The approach provides a scalable, implementable method for enhancing Maritime Domain Awareness. It shows strong potential for improving operational decision-making on inland rivers and can be adapted to other waterways. Future work should test model transferability to different rivers with varying conditions and environmental factors."}}
{"id": "2510.24709", "categories": ["cs.CV", "cs.AI", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.24709", "abs": "https://arxiv.org/abs/2510.24709", "authors": ["Yihao Li", "Saeed Salehi", "Lyle Ungar", "Konrad P. Kording"], "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?", "comment": "Accepted as a Spotlight at NeurIPS 2025", "summary": "Object binding, the brain's ability to bind the many features that\ncollectively represent an object into a coherent whole, is central to human\ncognition. It groups low-level perceptual features into high-level object\nrepresentations, stores those objects efficiently and compositionally in\nmemory, and supports human reasoning about individual object instances. While\nprior work often imposes object-centric attention (e.g., Slot Attention)\nexplicitly to probe these benefits, it remains unclear whether this ability\nnaturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they\ncould: recognizing which patches belong to the same object should be useful for\ndownstream prediction and thus guide attention. Motivated by the quadratic\nnature of self-attention, we hypothesize that ViTs represent whether two\npatches belong to the same object, a property we term IsSameObject. We decode\nIsSameObject from patch embeddings across ViT layers using a similarity probe,\nwhich reaches over 90% accuracy. Crucially, this object-binding capability\nemerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker\nin ImageNet-supervised models, suggesting that binding is not a trivial\narchitectural artifact, but an ability acquired through specific pretraining\nobjectives. We further discover that IsSameObject is encoded in a\nlow-dimensional subspace on top of object features, and that this signal\nactively guides attention. Ablating IsSameObject from model activations\ndegrades downstream performance and works against the learning objective,\nimplying that emergent object binding naturally serves the pretraining\nobjective. Our findings challenge the view that ViTs lack object binding and\nhighlight how symbolic knowledge of \"which parts belong together\" emerges\nnaturally in a connectionist system.", "AI": {"tldr": "Self-supervised Vision Transformers show emergent object binding (IsSameObject): patches belonging to the same object can be decoded from layer-wise patch embeddings with over 90% accuracy; this binding guides attention and is weak in ImageNet-supervised models, indicating it arises from pretraining objectives, not architecture.", "motivation": "To determine whether object binding naturally emerges in pre-trained ViTs and whether it depends on pretraining objectives (self-supervised vs supervised) rather than architecture alone.", "method": "Decode a patch-level IsSameObject signal from ViT embeddings across layers using a similarity probe. Compare self-supervised (DINO, MAE, CLIP) versus ImageNet-supervised models. Analyze the dimensionality of the IsSameObject subspace, visualize its influence on attention, and perform ablations removing IsSameObject to assess impact on downstream performance and training objective alignment.", "result": "IsSameObject decoded with >90% accuracy; emergent in self-supervised ViTs but weaker in supervised ones; encoded in a low-dimensional subspace atop object features and actively guides attention; ablating it degrades downstream performance and misaligns with the pretraining objective.", "conclusion": "ViTs naturally develop object binding, challenging the claim that binding requires explicit object-centric architectures; the emergent binding appears as a beneficial byproduct of self-supervised pretraining and is instrumental for attention and downstream tasks."}}
{"id": "2510.24012", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24012", "abs": "https://arxiv.org/abs/2510.24012", "authors": ["Byeonghu Na", "Mina Kang", "Jiseok Kwak", "Minsang Park", "Jiwoo Shin", "SeJoon Jun", "Gayoung Lee", "Jin-Hwa Kim", "Il-Chul Moon"], "title": "Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion Models", "comment": "Accepted at NeurIPS 2025", "summary": "Text-to-image models have recently made significant advances in generating\nrealistic and semantically coherent images, driven by advanced diffusion models\nand large-scale web-crawled datasets. However, these datasets often contain\ninappropriate or biased content, raising concerns about the generation of\nharmful outputs when provided with malicious text prompts. We propose Safe Text\nembedding Guidance (STG), a training-free approach to improve the safety of\ndiffusion models by guiding the text embeddings during sampling. STG adjusts\nthe text embeddings based on a safety function evaluated on the expected final\ndenoised image, allowing the model to generate safer outputs without additional\ntraining. Theoretically, we show that STG aligns the underlying model\ndistribution with safety constraints, thereby achieving safer outputs while\nminimally affecting generation quality. Experiments on various safety\nscenarios, including nudity, violence, and artist-style removal, show that STG\nconsistently outperforms both training-based and training-free baselines in\nremoving unsafe content while preserving the core semantic intent of input\nprompts. Our code is available at https://github.com/aailab-kaist/STG.", "AI": {"tldr": "A training-free method STG (Safe Text embedding Guidance) improves the safety of diffusion models by adjusting text embeddings during sampling using a safety function applied to the expected final denoised image; it aligns the model distribution with safety constraints and outperforms baselines while preserving core semantics.", "motivation": "Text-to-image models trained on large web-crawled datasets can generate harmful or biased content; there is a need for safer outputs without retraining or heavy computational costs.", "method": "STG modulates the input text embeddings during the sampling process using a safety function evaluated on the expected final denoised image. This training-free approach steers generation toward safer outputs while minimally impacting quality, effectively aligning the model distribution with safety constraints.", "result": "Empirical results across safety scenarios (nudity, violence, artist-style removal) show STG outperforms both training-based and training-free baselines in removing unsafe content while preserving the semantic intent of prompts.", "conclusion": "STG provides a training-free mechanism to enhance diffusion-model safety by steering embeddings to satisfy safety constraints, achieving safer outputs with minimal degradation in generation quality; code is released."}}
{"id": "2510.24711", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24711", "abs": "https://arxiv.org/abs/2510.24711", "authors": ["Yujie Wei", "Shiwei Zhang", "Hangjie Yuan", "Yujin Han", "Zhekai Chen", "Jiayu Wang", "Difan Zou", "Xihui Liu", "Yingya Zhang", "Yu Liu", "Hongming Shan"], "title": "Routing Matters in MoE: Scaling Diffusion Transformers with Explicit Routing Guidance", "comment": null, "summary": "Mixture-of-Experts (MoE) has emerged as a powerful paradigm for scaling model\ncapacity while preserving computational efficiency. Despite its notable success\nin large language models (LLMs), existing attempts to apply MoE to Diffusion\nTransformers (DiTs) have yielded limited gains. We attribute this gap to\nfundamental differences between language and visual tokens. Language tokens are\nsemantically dense with pronounced inter-token variation, while visual tokens\nexhibit spatial redundancy and functional heterogeneity, hindering expert\nspecialization in vision MoE. To this end, we present ProMoE, an MoE framework\nfeaturing a two-step router with explicit routing guidance that promotes expert\nspecialization. Specifically, this guidance encourages the router to partition\nimage tokens into conditional and unconditional sets via conditional routing\naccording to their functional roles, and refine the assignments of conditional\nimage tokens through prototypical routing with learnable prototypes based on\nsemantic content. Moreover, the similarity-based expert allocation in latent\nspace enabled by prototypical routing offers a natural mechanism for\nincorporating explicit semantic guidance, and we validate that such guidance is\ncrucial for vision MoE. Building on this, we propose a routing contrastive loss\nthat explicitly enhances the prototypical routing process, promoting\nintra-expert coherence and inter-expert diversity. Extensive experiments on\nImageNet benchmark demonstrate that ProMoE surpasses state-of-the-art methods\nunder both Rectified Flow and DDPM training objectives. Code and models will be\nmade publicly available.", "AI": {"tldr": "ProMoE introduces a two-step vision MoE with conditional and prototypical routing, plus a routing-contrastive loss, achieving state-of-the-art results on ImageNet with diffusion-based training (Rectified Flow and DDPM).", "motivation": "MoE scaling has boosted language models, but vision MoEs underperform due to fundamental token differences: visual tokens exhibit spatial redundancy and functional heterogeneity, hindering expert specialization. Explicit routing guidance is needed to promote specialization in vision models.", "method": "A two-step router: (1) conditional routing partitions image tokens into conditional vs unconditional sets by functional role; (2) prototypical routing refines conditional token assignments using learnable prototypes based on semantic content. A similarity-based expert allocation via prototypes and a routing contrastive loss further enhances intra-expert coherence and inter-expert diversity.", "result": "Extensive ImageNet experiments show ProMoE surpasses state-of-the-art methods under both Rectified Flow and DDPM training objectives.", "conclusion": "Explicit semantic guidance is crucial for effective vision MoE. ProMoE demonstrates that structured routing and prototypical routing can unlock gains in vision MoE; code and models will be released."}}
{"id": "2510.24025", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24025", "abs": "https://arxiv.org/abs/2510.24025", "authors": ["Guo Tianqi Guo", "Chen Liping", "Peng Ciyuan", "Guo Jingjing", "Ren Jing"], "title": "NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional Connectivity Analysis", "comment": null, "summary": "Understanding the evolution of brain functional networks over time is of\ngreat significance for the analysis of cognitive mechanisms and the diagnosis\nof neurological diseases. Existing methods often have difficulty in capturing\nthe temporal evolution characteristics of connections between specific\nfunctional communities. To this end, this paper proposes a new path-level\ntrajectory modeling framework (NeuroPathNet) to characterize the dynamic\nbehavior of connection pathways between brain functional partitions. Based on\nmedically supported static partitioning schemes (such as Yeo and Smith ICA), we\nextract the time series of connection strengths between each pair of functional\npartitions and model them using a temporal neural network. We validate the\nmodel performance on three public functional Magnetic Resonance Imaging (fMRI)\ndatasets, and the results show that it outperforms existing mainstream methods\nin multiple indicators. This study can promote the development of dynamic graph\nlearning methods for brain network analysis, and provide possible clinical\napplications for the diagnosis of neurological diseases.", "AI": {"tldr": "A path-level trajectory model (NeuroPathNet) captures time-varying connectivity between brain functional partitions using a temporal neural network, outperforming baselines on three fMRI datasets with potential clinical implications.", "motivation": "To understand how brain functional networks evolve over time and to address the difficulty of modeling temporal evolution of connections between functional communities with static or conventional methods; aims to advance dynamic graph learning for brain networks and support neurological disease diagnosis.", "method": "Using medically supported static partition schemes (e.g., Yeo, Smith ICA), compute time series of connection strengths between each pair of partitions. These trajectories are modeled with a temporal neural network to capture dynamic pathway-level behavior.", "result": "Empirical validation on three public fMRI datasets showing NeuroPathNet outperforms existing mainstream methods across multiple metrics.", "conclusion": "The framework advances dynamic graph learning for brain network analysis and offers potential clinical applications in neurological disease diagnosis."}}
{"id": "2510.24717", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24717", "abs": "https://arxiv.org/abs/2510.24717", "authors": ["Haoge Deng", "Ting Pan", "Fan Zhang", "Yang Liu", "Zhuoyan Luo", "Yufeng Cui", "Wenxuan Wang", "Chunhua Shen", "Shiguang Shan", "Zhaoxiang Zhang", "Xinlong Wang"], "title": "Uniform Discrete Diffusion with Metric Path for Video Generation", "comment": "19 pages, 10 figures", "summary": "Continuous-space video generation has advanced rapidly, while discrete\napproaches lag behind due to error accumulation and long-context inconsistency.\nIn this work, we revisit discrete generative modeling and present Uniform\ndiscRete diffuSion with metric pAth (URSA), a simple yet powerful framework\nthat bridges the gap with continuous approaches for the scalable video\ngeneration. At its core, URSA formulates the video generation task as an\niterative global refinement of discrete spatiotemporal tokens. It integrates\ntwo key designs: a Linearized Metric Path and a Resolution-dependent Timestep\nShifting mechanism. These designs enable URSA to scale efficiently to\nhigh-resolution image synthesis and long-duration video generation, while\nrequiring significantly fewer inference steps. Additionally, we introduce an\nasynchronous temporal fine-tuning strategy that unifies versatile tasks within\na single model, including interpolation and image-to-video generation.\nExtensive experiments on challenging video and image generation benchmarks\ndemonstrate that URSA consistently outperforms existing discrete methods and\nachieves performance comparable to state-of-the-art continuous diffusion\nmethods. Code and models are available at https://github.com/baaivision/URSA", "AI": {"tldr": "URSA reframes video generation as iterative refinement over discrete spatiotemporal tokens, using Linearized Metric Path and Resolution-dependent Timestep Shifting to scale discrete diffusion to high-resolution, long-duration video with fewer steps; adds asynchronous temporal fine-tuning to support interpolation and image-to-video tasks; outperforms existing discrete methods and rivals continuous diffusion, with code available.", "motivation": "Discrete diffusion models suffer from error accumulation and long-context inconsistency and lag behind continuous approaches in video generation. A scalable, high-quality discrete framework is needed to close this gap and enable long-horizon, high-resolution video synthesis.", "method": "The method treats video generation as iterative global refinement of discrete tokens. It introduces a Linearized Metric Path and a Resolution-dependent Timestep Shifting mechanism to enable efficient scaling to high-resolution images and long-duration videos, with fewer inference steps. An asynchronous temporal fine-tuning strategy unifies tasks like interpolation and image-to-video within a single model.", "result": "URSA outperforms existing discrete methods on challenging video and image generation benchmarks and achieves performance comparable to state-of-the-art continuous diffusion methods, while requiring significantly fewer inference steps.", "conclusion": "URSA bridges the gap between discrete and continuous video diffusion, offering a scalable, flexible framework for high-quality, long-duration video generation and multi-task capabilities, with public code and models."}}
{"id": "2510.24026", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24026", "abs": "https://arxiv.org/abs/2510.24026", "authors": ["Jiaqi Luo", "Shixin Xu", "Zhouwang Yang"], "title": "Efficient Global-Local Fusion Sampling for Physics-Informed Neural Networks", "comment": null, "summary": "The accuracy of Physics-Informed Neural Networks (PINNs) critically depends\non the placement of collocation points, as the PDE loss is approximated through\nsampling over the solution domain. Global sampling ensures stability by\ncovering the entire domain but requires many samples and is computationally\nexpensive, whereas local sampling improves efficiency by focusing on\nhigh-residual regions but may neglect well-learned areas, reducing robustness.\nWe propose a Global-Local Fusion (GLF) Sampling Strategy that combines the\nstrengths of both approaches. Specifically, new collocation points are\ngenerated by perturbing training points with Gaussian noise scaled inversely to\nthe residual, thereby concentrating samples in difficult regions while\npreserving exploration. To further reduce computational overhead, a lightweight\nlinear surrogate is introduced to approximate the global residual-based\ndistribution, achieving similar effectiveness at a fraction of the cost.\nTogether, these components, residual-adaptive sampling and residual-based\napproximation, preserve the stability of global methods while retaining the\nefficiency of local refinement. Extensive experiments on benchmark PDEs\ndemonstrate that GLF consistently improves both accuracy and efficiency\ncompared with global and local sampling strategies. This study provides a\npractical and scalable framework for enhancing the reliability and efficiency\nof PINNs in solving complex and high-dimensional PDEs.", "AI": {"tldr": "Global-local fusion (GLF) for PINN sampling improves accuracy and efficiency by adaptively concentrating collocation points in difficult regions while using a lightweight surrogate to approximate global residual distribution.", "motivation": "PINN performance hinges on collocation-point placement: global sampling is robust but costly; local sampling is efficient but can miss hard regions. A hybrid strategy aims to combine stability with efficiency.", "method": "Residual-adaptive sampling: generate new collocation points by perturbing training points with Gaussian noise scaled inversely to the PDE residual. A lightweight linear surrogate approximates the global residual distribution to reduce computational cost.", "result": "GLF consistently improves both accuracy and efficiency over global and local sampling strategies on benchmark PDEs.", "conclusion": "GLF provides a practical, scalable framework that preserves stability of global methods while retaining the efficiency of local refinement for solving complex, high-dimensional PDEs."}}
{"id": "2510.24718", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24718", "abs": "https://arxiv.org/abs/2510.24718", "authors": ["Chonghyuk Song", "Michal Stary", "Boyuan Chen", "George Kopanas", "Vincent Sitzmann"], "title": "Generative View Stitching", "comment": "Project website: https://andrewsonga.github.io/gvs", "summary": "Autoregressive video diffusion models are capable of long rollouts that are\nstable and consistent with history, but they are unable to guide the current\ngeneration with conditioning from the future. In camera-guided video generation\nwith a predefined camera trajectory, this limitation leads to collisions with\nthe generated scene, after which autoregression quickly collapses. To address\nthis, we propose Generative View Stitching (GVS), which samples the entire\nsequence in parallel such that the generated scene is faithful to every part of\nthe predefined camera trajectory. Our main contribution is a sampling algorithm\nthat extends prior work on diffusion stitching for robot planning to video\ngeneration. While such stitching methods usually require a specially trained\nmodel, GVS is compatible with any off-the-shelf video model trained with\nDiffusion Forcing, a prevalent sequence diffusion framework that we show\nalready provides the affordances necessary for stitching. We then introduce\nOmni Guidance, a technique that enhances the temporal consistency in stitching\nby conditioning on both the past and future, and that enables our proposed\nloop-closing mechanism for delivering long-range coherence. Overall, GVS\nachieves camera-guided video generation that is stable, collision-free,\nframe-to-frame consistent, and closes loops for a variety of predefined camera\npaths, including Oscar Reutersv\\\"ard's Impossible Staircase. Results are best\nviewed as videos at https://andrewsonga.github.io/gvs.", "AI": {"tldr": "GVS enables parallel sampling of an entire video sequence to enforce adherence to a predefined camera trajectory, achieving stable, collision-free, and temporally coherent camera-guided video generation via diffusion stitching and Omni Guidance.", "motivation": "Autoregressive video diffusion struggles to incorporate future conditioning, causing collisions and collapsed generations when following fixed camera paths; there is need for long-range coherence and loop-closure.", "method": "Propose Generative View Stitching (GVS) that samples the sequence in parallel using a diffusion stitching approach adapted from robot planning; compatible with any Diffusion Forcing video model; introduce Omni Guidance to condition on past and future for better temporal consistency; implement loop-closing mechanism to maintain long-range coherence.", "result": "Produces camera-guided video generation that is stable, collision-free, frame-to-frame consistent, and capable of closing loops for various predefined camera paths (e.g., Oscar Reutersv\u00e4rd's Impossible Staircase). Results are showcased on a project site.", "conclusion": "GVS offers a practical, model-agnostic approach to long-range, camera-conditioned video generation, improving stability and coherence without retraining; expands possibilities for scripted cinematic sequences; potential trade-offs include computational cost and stitching-induced artifacts."}}
{"id": "2510.24027", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24027", "abs": "https://arxiv.org/abs/2510.24027", "authors": ["Zibo Liu", "Zhe Jiang", "Zelin Xu", "Tingsong Xiao", "Yupu Zhang", "Zhengkun Xiao", "Haibo Wang", "Shigang Chen"], "title": "Spatio-temporal Multivariate Time Series Forecast with Chosen Variables", "comment": "In submission", "summary": "Spatio-Temporal Multivariate time series Forecast (STMF) uses the time series\nof $n$ spatially distributed variables in a period of recent past to forecast\ntheir values in a period of near future. It has important applications in\nspatio-temporal sensing forecast such as road traffic prediction and air\npollution prediction. Recent papers have addressed a practical problem of\nmissing variables in the model input, which arises in the sensing applications\nwhere the number $m$ of sensors is far less than the number $n$ of locations to\nbe monitored, due to budget constraints. We observe that the state of the art\nassumes that the $m$ variables (i.e., locations with sensors) in the model\ninput are pre-determined and the important problem of how to choose the $m$\nvariables in the input has never been studied. This paper fills the gap by\nstudying a new problem of STMF with chosen variables, which optimally selects\n$m$-out-of-$n$ variables for the model input in order to maximize the forecast\naccuracy. We propose a unified framework that jointly performs variable\nselection and model optimization for both forecast accuracy and model\nefficiency. It consists of three novel technical components: (1) masked\nvariable-parameter pruning, which progressively prunes less informative\nvariables and attention parameters through quantile-based masking; (2)\nprioritized variable-parameter replay, which replays low-loss past samples to\npreserve learned knowledge for model stability; (3) dynamic extrapolation\nmechanism, which propagates information from variables selected for the input\nto all other variables via learnable spatial embeddings and adjacency\ninformation. Experiments on five real-world datasets show that our work\nsignificantly outperforms the state-of-the-art baselines in both accuracy and\nefficiency, demonstrating the effectiveness of joint variable selection and\nmodel optimization.", "AI": {"tldr": "A unified framework for spatio-temporal multivariate forecasting with chosen inputs (m out of n variables). It jointly performs variable selection and model optimization using three novel components, achieving higher accuracy and efficiency than baselines on real-world data.", "motivation": "In sensing applications, the number of available sensors (m) is much smaller than the number of locations (n), creating a missing-input problem. Prior work treats input variables as fixed; there is a need to intelligently select which variables to include to maximize forecast accuracy under budget constraints.", "method": "A unified framework that jointly optimizes variable selection and forecasting, featuring (1) masked variable-parameter pruning (quantile-based masking to prune less informative variables and parameters), (2) prioritized variable-parameter replay (replays low-loss past samples to preserve learned knowledge), and (3) dynamic extrapolation (propagates information from selected variables to all others via learnable spatial embeddings and adjacency information).", "result": "On five real-world datasets, the proposed method significantly outperforms state-of-the-art baselines in both forecast accuracy and model efficiency, demonstrating the benefit of jointly selecting variables and optimizing the model.", "conclusion": "Joint variable selection and model optimization for STMF with chosen variables is effective, enabling accurate and efficient forecasting under sensor-budget constraints."}}
{"id": "2510.24035", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.24035", "abs": "https://arxiv.org/abs/2510.24035", "authors": ["Xinqi Li", "Yiqun Liu", "Shan Jiang", "Enrong Zheng", "Huaijin Zheng", "Wenhao Dai", "Haodong Deng", "Dianhai Yu", "Yanjun Ma"], "title": "GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler Research", "comment": null, "summary": "We introduce GraphNet, a dataset of 2.7K real-world deep learning\ncomputational graphs with rich metadata, spanning six major task categories\nacross multiple deep learning frameworks. To evaluate tensor compiler\nperformance on these samples, we propose the benchmark metric Speedup Score\nS(t), which jointly considers runtime speedup and execution correctness under\ntunable tolerance levels, offering a reliable measure of general optimization\ncapability. Furthermore, we extend S(t) to the Error-aware Speedup Score ES(t),\nwhich incorporates error information and helps compiler developers identify key\nperformance bottlenecks. In this report, we benchmark the default tensor\ncompilers, CINN for PaddlePaddle and TorchInductor for PyTorch, on computer\nvision (CV) and natural language processing (NLP) samples to demonstrate the\npracticality of GraphNet. The full construction pipeline with graph extraction\nand compiler evaluation tools is available at\nhttps://github.com/PaddlePaddle/GraphNet .", "AI": {"tldr": "GraphNet introduces a real-world DL graph dataset and two benchmark metrics (Speedup Score S(t) and ES(t)) to evaluate tensor compiler performance, with validation on CV/NLP samples using CINN (PaddlePaddle) and TorchInductor (PyTorch).", "motivation": "There is a need for a reliable, generalizable metric and dataset to assess tensor compiler optimizations on realistic DL workloads, balancing runtime speed with correctness and exposing bottlenecks across frameworks.", "method": "Construct GraphNet with 2.7K real-world DL computational graphs across six task categories and multiple frameworks; define Speedup Score S(t) combining runtime speedup and correctness within tolerance; extend to ES(t) by incorporating error information; benchmark default compilers CINN for PaddlePaddle and TorchInductor for PyTorch on CV and NLP samples; provide an end-to-end construction pipeline and tools on GitHub.", "result": "Demonstrates practical utility and reproducibility of GraphNet and its metrics in diagnosing compiler performance on CV and NLP workloads; establishes a framework to compare and identify bottlenecks across frameworks and tasks.", "conclusion": "GraphNet enables a standardized, open benchmarking framework for tensor compilers, with metrics that jointly capture speed and correctness and an error-aware variant to highlight bottlenecks, supported by a public pipeline."}}
{"id": "2510.24039", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24039", "abs": "https://arxiv.org/abs/2510.24039", "authors": ["Nikolaos Karalias", "Akbar Rafiey", "Yifei Xu", "Zhishang Luo", "Behrooz Tahmasebi", "Connie Jiang", "Stefanie Jegelka"], "title": "Geometric Algorithms for Neural Combinatorial Optimization with Constraints", "comment": null, "summary": "Self-Supervised Learning (SSL) for Combinatorial Optimization (CO) is an\nemerging paradigm for solving combinatorial problems using neural networks. In\nthis paper, we address a central challenge of SSL for CO: solving problems with\ndiscrete constraints. We design an end-to-end differentiable framework that\nenables us to solve discrete constrained optimization problems with neural\nnetworks. Concretely, we leverage algorithmic techniques from the literature on\nconvex geometry and Carath\\'eodory's theorem to decompose neural network\noutputs into convex combinations of polytope corners that correspond to\nfeasible sets. This decomposition-based approach enables self-supervised\ntraining but also ensures efficient quality-preserving rounding of the neural\nnet output into feasible solutions. Extensive experiments in\ncardinality-constrained optimization show that our approach can consistently\noutperform neural baselines. We further provide worked-out examples of how our\nmethod can be applied beyond cardinality-constrained problems to a diverse set\nof combinatorial optimization tasks, including finding independent sets in\ngraphs, and solving matroid-constrained problems.", "AI": {"tldr": "A differentiable SSL framework for discrete constrained combinatorial optimization that uses Carath\u00e9odory-based decomposition of network outputs into convex combinations of feasible polytope corners, enabling self-supervised training and efficient feasible rounding, with strong results on cardinality constraints and extensions to independent sets and matroid constraints.", "motivation": "Discrete constrained optimization is hard for neural nets, particularly under self-supervised learning. There is a need for an end-to-end differentiable approach that preserves feasibility and yields high-quality solutions without heavy supervision.", "method": "An end-to-end differentiable framework that applies convex geometry and Carath\u00e9odory's theorem to decompose neural network outputs into convex combinations of polytope corners representing feasible sets. This enables self-supervised training and efficient rounding of outputs to feasible discrete solutions.", "result": "Empirically, the method consistently outperforms neural baselines on cardinality-constrained problems. The paper also demonstrates worked-out examples extending the approach to independent sets in graphs and matroid-constrained problems.", "conclusion": "The proposed decomposition-based SSL framework offers a general, differentiable mechanism for solving discrete constrained optimization, with strong empirical performance and broad applicability to various combinatorial tasks."}}
{"id": "2510.24043", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24043", "abs": "https://arxiv.org/abs/2510.24043", "authors": ["Akira Tamamori"], "title": "Localized Kernel Projection Outlyingness: A Two-Stage Approach for Multi-Modal Outlier Detection", "comment": "10 pages, 4 figures; submitted to The IEICE Transactions on\n  Information and Systems", "summary": "This paper presents Two-Stage LKPLO, a novel multi-stage outlier detection\nframework that overcomes the coexisting limitations of conventional\nprojection-based methods: their reliance on a fixed statistical metric and\ntheir assumption of a single data structure. Our framework uniquely synthesizes\nthree key concepts: (1) a generalized loss-based outlyingness measure (PLO)\nthat replaces the fixed metric with flexible, adaptive loss functions like our\nproposed SVM-like loss; (2) a global kernel PCA stage to linearize non-linear\ndata structures; and (3) a subsequent local clustering stage to handle\nmulti-modal distributions. Comprehensive 5-fold cross-validation experiments on\n10 benchmark datasets, with automated hyperparameter optimization, demonstrate\nthat Two-Stage LKPLO achieves state-of-the-art performance. It significantly\noutperforms strong baselines on datasets with challenging structures where\nexisting methods fail, most notably on multi-cluster data (Optdigits) and\ncomplex, high-dimensional data (Arrhythmia). Furthermore, an ablation study\nempirically confirms that the synergistic combination of both the kernelization\nand localization stages is indispensable for its superior performance. This\nwork contributes a powerful new tool for a significant class of outlier\ndetection problems and underscores the importance of hybrid, multi-stage\narchitectures.", "AI": {"tldr": "A novel Three-stage outlier detector (Two-Stage LKPLO) that uses a flexible loss-based outlyingness measure, global kernel PCA, and local clustering to handle non-linear, multi-modal data, achieving state-of-the-art results.", "motivation": "Conventional projection-based outlier methods rely on fixed metrics and assume a single data structure, limiting performance on complex, multi-modal data; a flexible, multi-stage approach is needed.", "method": "Introduce PLO loss-based outlyingness (including SVM-like loss), apply a global kernel PCA stage to linearize non-linear structures, followed by a local clustering stage to capture multi-modality; evaluate with 5-fold CV and automated hyperparameter optimization.", "result": "Achieves state-of-the-art performance across 10 benchmarks; notably superior on Optdigits (multi-cluster) and Arrhythmia (high-dimensional); ablation confirms the necessity of both kernelization and localization.", "conclusion": "Hybrid, multi-stage architecture is effective for a broad class of outlier problems and highlights the value of combining kernelization with localization for robust outlier detection."}}
{"id": "2510.24044", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24044", "abs": "https://arxiv.org/abs/2510.24044", "authors": ["Hui Sun", "Zheng Xie", "Hao-Yuan He", "Ming Li"], "title": "Mitigating Negative Transfer via Reducing Environmental Disagreement", "comment": "13 pages, 5 figures", "summary": "Unsupervised Domain Adaptation~(UDA) focuses on transferring knowledge from a\nlabeled source domain to an unlabeled target domain, addressing the challenge\nof \\emph{domain shift}. Significant domain shifts hinder effective knowledge\ntransfer, leading to \\emph{negative transfer} and deteriorating model\nperformance. Therefore, mitigating negative transfer is essential. This study\nrevisits negative transfer through the lens of causally disentangled learning,\nemphasizing cross-domain discriminative disagreement on non-causal\nenvironmental features as a critical factor. Our theoretical analysis reveals\nthat overreliance on non-causal environmental features as the environment\nevolves can cause discriminative disagreements~(termed \\emph{environmental\ndisagreement}), thereby resulting in negative transfer. To address this, we\npropose Reducing Environmental Disagreement~(RED), which disentangles each\nsample into domain-invariant causal features and domain-specific non-causal\nenvironmental features via adversarially training domain-specific environmental\nfeature extractors in the opposite domains. Subsequently, RED estimates and\nreduces environmental disagreement based on domain-specific non-causal\nenvironmental features. Experimental results confirm that RED effectively\nmitigates negative transfer and achieves state-of-the-art performance.", "AI": {"tldr": "A method to mitigate negative transfer in unsupervised domain adaptation (UDA) by causally disentangled learning that separates domain-invariant causal features from domain-specific non-causal environmental features, then reduces environmental disagreement via adversarially trained domain-specific extractors, achieving state-of-the-art results.", "motivation": "Negative transfer arises when models over-rely on non-causal environmental features that shift across domains. A causal-disentangled perspective can isolate invariant causal features, improving cross-domain generalization.", "method": "Propose RED (Reducing Environmental Disagreement): (1) disentangle each sample into domain-invariant causal features and domain-specific non-causal environmental features using adversarial training with domain-specific environmental feature extractors in the opposite domains; (2) estimate and reduce environmental disagreement using the domain-specific non-causal features, thereby aligning predictions on causal information across domains.", "result": "Experimental results show that RED effectively mitigates negative transfer and achieves state-of-the-art performance on standard UDA benchmarks.", "conclusion": "Disentangling causal and environmental features and actively reducing environmental disagreement yields robust cross-domain transfer in UDA, addressing negative transfer without sacrificing domain alignment."}}
{"id": "2510.24046", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24046", "abs": "https://arxiv.org/abs/2510.24046", "authors": ["Tu Anh Hoang Nguyen", "Dang Nguyen", "Tri-Nhan Vo", "Thuc Duy Le", "Sunil Gupta"], "title": "Causal-Aware Generative Adversarial Networks with Reinforcement Learning", "comment": null, "summary": "The utility of tabular data for tasks ranging from model training to\nlarge-scale data analysis is often constrained by privacy concerns or\nregulatory hurdles. While existing data generation methods, particularly those\nbased on Generative Adversarial Networks (GANs), have shown promise, they\nfrequently struggle with capturing complex causal relationship, maintaining\ndata utility, and providing provable privacy guarantees suitable for enterprise\ndeployment. We introduce CA-GAN, a novel generative framework specifically\nengineered to address these challenges for real-world tabular datasets. CA-GAN\nutilizes a two-step approach: causal graph extraction to learn a robust,\ncomprehensive causal relationship in the data's manifold, followed by a custom\nConditional WGAN-GP (Wasserstein GAN with Gradient Penalty) that operates\nexclusively as per the structure of nodes in the causal graph. More\nimportantly, the generator is trained with a new Reinforcement Learning-based\nobjective that aligns the causal graphs constructed from real and fake data,\nensuring the causal awareness in both training and sampling phases. We\ndemonstrate CA-GAN superiority over six SOTA methods across 14 tabular\ndatasets. Our evaluations, focused on core data engineering metrics: causal\npreservation, utility preservation, and privacy preservation. Our method offers\na practical, high-performance solution for data engineers seeking to create\nhigh-quality, privacy-compliant synthetic datasets to benchmark database\nsystems, accelerate software development, and facilitate secure data-driven\nresearch.", "AI": {"tldr": "CA-GAN is a causal-structure aware GAN for tabular data that uses causal graph extraction and a conditional WGAN-GP with an RL-based objective to preserve causal structure, utility, and privacy, outperforming six SOTA methods across 14 datasets.", "motivation": "Privacy concerns and regulatory constraints limit tabular data sharing; existing GAN-based data generators struggle to capture complex causal relationships, maintain data utility, and offer provable privacy guarantees suitable for enterprise deployment.", "method": "A two-step approach: (1) extract a causal graph from the data to learn robust causal relationships; (2) train a conditional WGAN-GP that operates according to the causal graph structure, with a reinforcement learning\u2013based objective enforcing alignment of causal graphs between real and fake data.", "result": "CA-GAN outperforms six state-of-the-art methods on 14 tabular datasets, evaluated on causal preservation, utility preservation, and privacy preservation metrics.", "conclusion": "CA-GAN provides a practical, high-performance solution for generating privacy-compliant synthetic tabular data to benchmark database systems, accelerate software development, and enable secure data-driven research."}}
{"id": "2510.24049", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24049", "abs": "https://arxiv.org/abs/2510.24049", "authors": ["Hao Jia", "Penghao Zhao", "Hao Wu", "Yuan Gao", "Yangyu Tao", "Bin Cui"], "title": "Learning from History: A Retrieval-Augmented Framework for Spatiotemporal Prediction", "comment": null, "summary": "Accurate and long-term spatiotemporal prediction for complex physical systems\nremains a fundamental challenge in scientific computing. While deep learning\nmodels, as powerful parametric approximators, have shown remarkable success,\nthey suffer from a critical limitation: the accumulation of errors during\nlong-term autoregressive rollouts often leads to physically implausible\nartifacts. This deficiency arises from their purely parametric nature, which\nstruggles to capture the full constraints of a system's intrinsic dynamics. To\naddress this, we introduce a novel \\textbf{Retrieval-Augmented Prediction\n(RAP)} framework, a hybrid paradigm that synergizes the predictive power of\ndeep networks with the grounded truth of historical data. The core philosophy\nof RAP is to leverage historical evolutionary exemplars as a non-parametric\nestimate of the system's local dynamics. For any given state, RAP efficiently\nretrieves the most similar historical analog from a large-scale database. The\ntrue future evolution of this analog then serves as a \\textbf{reference\ntarget}. Critically, this target is not a hard constraint in the loss function\nbut rather a powerful conditional input to a specialized dual-stream\narchitecture. It provides strong \\textbf{dynamic guidance}, steering the\nmodel's predictions towards physically viable trajectories. In extensive\nbenchmarks across meteorology, turbulence, and fire simulation, RAP not only\nsurpasses state-of-the-art methods but also significantly outperforms a strong\n\\textbf{analog-only forecasting baseline}. More importantly, RAP generates\npredictions that are more physically realistic by effectively suppressing error\ndivergence in long-term rollouts.", "AI": {"tldr": "A Retrieval-Augmented Prediction framework (RAP) that uses historical exemplars as non-parametric references to steer long-term spatiotemporal forecasts, improving physical realism and reducing error accumulation; outperforms state-of-the-art and analog-only baselines in meteorology, turbulence, and fire simulation.", "motivation": "Long-term predictions of complex physical systems suffer from error accumulation in purely parametric deep models and struggle to satisfy physical constraints. There is a need to integrate data-driven power with grounding in historical dynamics to improve fidelity and plausibility.", "method": "RAP retrieves the most similar historical evolution for a given state from a large database. The true future of that analog serves as a reference target and is fed as a conditional input to a dual-stream network. The target provides dynamic guidance but is not a hard constraint in the loss, enabling the model to align predictions with physically plausible trajectories.", "result": "Extensive benchmarks across meteorology, turbulence, and fire simulation show RAP outperforms state-of-the-art methods and a strong analog-only baseline, significantly reducing error divergence in long-term rollouts and producing more physically realistic trajectories.", "conclusion": "The RAP framework demonstrates that combining parametric deep learning with non-parametric historical data can effectively constrain dynamics, yielding higher-fidelity, physically plausible long-term predictions and broad applicability in scientific computing."}}
{"id": "2510.24053", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.24053", "abs": "https://arxiv.org/abs/2510.24053", "authors": ["Jacob B. Roberts", "Catherine R. Ji", "Isaac Donnell", "Thomas D. Young", "Allison N. Pearson", "Graham A. Hudson", "Leah S. Keiser", "Mia Wesselkamper", "Peter H. Winegar", "Janik Ludwig", "Sarah H. Klass", "Isha V. Sheth", "Ezechinyere C. Ukabiala", "Maria C. T. Astolfi", "Benjamin Eysenbach", "Jay D. Keasling"], "title": "Low-N Protein Activity Optimization with FolDE", "comment": "18 pages, 4 figures. Preprint. Open-source software available at\n  https://github.com/JBEI/foldy", "summary": "Proteins are traditionally optimized through the costly construction and\nmeasurement of many mutants. Active Learning-assisted Directed Evolution (ALDE)\nalleviates that cost by predicting the best improvements and iteratively\ntesting mutants to inform predictions. However, existing ALDE methods face a\ncritical limitation: selecting the highest-predicted mutants in each round\nyields homogeneous training data insufficient for accurate prediction models in\nsubsequent rounds. Here we present FolDE, an ALDE method designed to maximize\nend-of-campaign success. In simulations across 20 protein targets, FolDE\ndiscovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005)\nand is 55% more likely to find top 1% mutants. FolDE achieves this primarily\nthrough naturalness-based warm-starting, which augments limited activity\nmeasurements with protein language model outputs to improve activity\nprediction. We also introduce a constant-liar batch selector, which improves\nbatch diversity; this is important in multi-mutation campaigns but had limited\neffect in our benchmarks. The complete workflow is freely available as\nopen-source software, making efficient protein optimization accessible to any\nlaboratory.", "AI": {"tldr": "FolDE uses naturalness-based warm-starting and a constant-liar batch selector to improve end-of-campaign success in active-learning-assisted directed evolution, outperforming baselines in simulations across 20 targets; open-source workflow.", "motivation": "ALDE reduces experimental cost but suffers from homogeneous training data when selecting top-predicted mutants each round, which degrades predictive accuracy in later rounds. There is a need to diversify data and improve early predictions to maximize end-of-campaign success in protein optimization.", "method": "FolDE introduces two core innovations: (1) naturalness-based warm-starting that augments limited activity measurements with protein-language-model outputs to improve activity prediction; (2) a constant-liar batch selector to increase batch diversity in multi-mutation campaigns.", "result": "In simulations across 20 protein targets, FolDE discovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005) and is 55% more likely to find top 1% mutants.", "conclusion": "FolDE advances ALDE by maximizing end-of-campaign success and provides an open-source workflow that makes efficient protein optimization accessible to laboratories."}}
{"id": "2510.24061", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24061", "abs": "https://arxiv.org/abs/2510.24061", "authors": ["Kanghyun Choi", "Hyeyoon Lee", "SunJong Park", "Dain Kwon", "Jinho Lee"], "title": "FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point Arithmetic", "comment": "NeurIPS 2025", "summary": "Low-bit floating-point (FP) formats, such as FP8, provide significant\nacceleration and memory savings in model training thanks to native hardware\nsupport on modern GPUs and NPUs. However, we analyze that FP8 quantization\noffers speedup primarily for large-dimensional matrix multiplications, while\ninherent quantization overheads diminish speedup when applied to low-rank\nadaptation (LoRA), which uses small-dimensional matrices for efficient\nfine-tuning of large language models (LLMs). To address this limitation, we\npropose FALQON, a novel framework that eliminates the quantization overhead\nfrom separate LoRA computational paths by directly merging LoRA adapters into\nan FP8-quantized backbone during fine-tuning. Furthermore, we reformulate the\nforward and backward computations for merged adapters to significantly reduce\nquantization overhead, and introduce a row-wise proxy update mechanism that\nefficiently integrates substantial updates into the quantized backbone.\nExperimental evaluations demonstrate that FALQON achieves approximately a\n3$\\times$ training speedup over existing quantized LoRA methods with a similar\nlevel of accuracy, providing a practical solution for efficient large-scale\nmodel fine-tuning. Moreover, FALQON's end-to-end FP8 workflow removes the need\nfor post-training quantization, facilitating efficient deployment. Code is\navailable at https://github.com/iamkanghyunchoi/falqon.", "AI": {"tldr": "FALQON merges LoRA adapters into an FP8 backbone to eliminate quantization overhead in low-bit fine-tuning, delivering ~3x speedup with similar accuracy and enabling end-to-end FP8 training.", "motivation": "FP8 formats offer speedups for large matrix multiplications, but LoRA-based fine-tuning incurs quantization overhead that negates benefits; a method that removes separate quantized paths could unlock FP8's full potential for LLM fine-tuning.", "method": "Directly merge LoRA adapters into the FP8-quantized backbone during fine-tuning; reformulate forward and backward passes for the merged adapters to reduce quantization overhead; introduce a row-wise proxy update to efficiently integrate large updates into the quantized backbone; enable an end-to-end FP8 training workflow without post-training quantization.", "result": "Approximately 3\u00d7 training speedup over existing quantized LoRA methods with comparable accuracy; end-to-end FP8 workflow eliminates the need for post-training quantization, facilitating efficient deployment.", "conclusion": "FALQON provides a practical solution for efficient large-scale fine-tuning by removing quantization bottlenecks in LoRA paths and delivering deploy-friendly end-to-end FP8 training."}}
{"id": "2510.24088", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24088", "abs": "https://arxiv.org/abs/2510.24088", "authors": ["Moongyu Jeon", "Sangwoo Shin", "Dongjae Jeon", "Albert No"], "title": "Information-Theoretic Discrete Diffusion", "comment": "Accepted at NeurIPS 2025", "summary": "We present an information-theoretic framework for discrete diffusion models\nthat yields principled estimators of log-likelihood using score-matching\nlosses. Inspired by the I-MMSE identity for the Gaussian setup, we derive\nanalogous results for the discrete setting. Specifically, we introduce the\nInformation-Minimum Denoising Score Entropy (I-MDSE) relation, which links\nmutual information between data and its diffused version to the minimum\ndenoising score entropy (DSE) loss. We extend this theory to masked diffusion\nand establish the Information-Minimum Denoising Cross-Entropy (I-MDCE)\nrelation, connecting cross-entropy losses to mutual information in discrete\nmasked processes. These results provide a time-integral decomposition of the\nlog-likelihood of the data in terms of optimal score-based losses, showing that\ncommonly used losses such as DSE and DCE are not merely variational bounds but\ntight and principled estimators of log-likelihood. The I-MDCE decomposition\nfurther enables practical extensions, including time-free formula, conditional\nlikelihood estimation in prompt-response tasks, and coupled Monte Carlo\nestimation of likelihood ratios. Experiments on synthetic and real-world data\nconfirm the accuracy, variance stability, and utility of our estimators. The\ncode is publicly available at https://github.com/Dongjae0324/infodis.", "AI": {"tldr": "A principled information-theoretic framework for discrete diffusion that connects mutual information to score-based losses to yield tight log-likelihood estimators, with extensions to masked diffusion and practical estimators; code released.", "motivation": "To obtain principled, potentially tight estimators of data log-likelihood in discrete diffusion models, moving beyond variational bounds, and to enable practical tasks like conditional likelihood and likelihood ratios.", "method": "Introduce I-MDSE relation linking MI between data and diffused version to minimum denoising score entropy; extend to I-MDCE in masked diffusion; derive a time-integral decomposition of log-likelihood in terms of optimal score-based losses; provide time-free formula and Monte Carlo estimators; validate theoretically and empirically.", "result": "Proves that DSE/DCE-based losses can be tight estimators of log-likelihood; yields decompositions and practical formulas; experiments on synthetic/real data show accuracy and stable variance; code released.", "conclusion": "The framework provides principled, tight estimators of log-likelihood for discrete diffusion models and enables practical extensions; paves the way for better evaluation and use of score-based methods in discrete settings; future work may explore broader tasks and further empirical evaluation."}}
{"id": "2510.24331", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.24331", "abs": "https://arxiv.org/abs/2510.24331", "authors": ["Gabriel O. dos Santos", "Esther Colombini", "Sandra Avila"], "title": "What do vision-language models see in the context? Investigating multimodal in-context learning", "comment": null, "summary": "In-context learning (ICL) enables Large Language Models (LLMs) to learn tasks\nfrom demonstration examples without parameter updates. Although it has been\nextensively studied in LLMs, its effectiveness in Vision-Language Models (VLMs)\nremains underexplored. In this work, we present a systematic study of ICL in\nVLMs, evaluating seven models spanning four architectures on three image\ncaptioning benchmarks. We analyze how prompt design, architectural choices, and\ntraining strategies influence multimodal ICL. To our knowledge, we are the\nfirst to analyze how attention patterns in VLMs vary with an increasing number\nof in-context demonstrations. Our results reveal that training on imag-text\ninterleaved data enhances ICL performance but does not imply effective\nintegration of visual and textual information from demonstration examples. In\ncontrast, instruction tuning improves instruction-following but can reduce\nreliance on in-context demonstrations, suggesting a trade-off between\ninstruction alignment and in-context adaptation. Attention analyses further\nshow that current VLMs primarily focus on textual cues and fail to leverage\nvisual information, suggesting a limited capacity for multimodal integration.\nThese findings highlight key limitations in the ICL abilities of current VLMs\nand provide insights for enhancing their ability to learn from multimodal\nin-context examples.", "AI": {"tldr": "In-context learning in vision-language models is limited; interleaved image-text training helps ICL but does not yield true multimodal integration from demonstrations; instruction tuning improves following instructions but reduces reliance on demonstrations, revealing a trade-off; attention analyses show models rely on textual cues rather than visuals, indicating limited multimodal integration.", "motivation": "The abstract motivates a systematic study of ICL in VLMs because while ICL has been explored in LLMs, its behavior and effectiveness in multimodal models remain underexplored. The goal is to understand how prompt design, architectural choices, and training strategies shape multimodal ICL and attention patterns, and to uncover limitations in current VLMs\u2019 ability to learn from multimodal in-context examples.", "method": "1) Evaluate seven models spanning four architectures on three image captioning benchmarks. 2) Systematically study prompt design, architectural choices, and training strategies. 3) Analyze attention patterns as the number of in-context demonstrations increases. 4) Compare training data regimes (imag-text interleaved vs others) and post-hoc effects of instruction tuning.", "result": "Findings include: (a) Training on imag-text interleaved data improves ICL performance but does not reflect effective integration of visual and textual information from demonstrations; (b) Instruction tuning enhances instruction-following but can reduce reliance on in-context demonstrations, indicating a trade-off between instruction alignment and in-context adaptation; (c) Attention analyses show that models primarily attend to textual cues and fail to leverage visual information, revealing limited multimodal integration in current VLMs.", "conclusion": "The study reveals key limitations in VLMs\u2019 ICL ability and offers directions for improving multimodal in-context learning, such as balancing instruction alignment with in-context adaptation and developing attentional mechanisms that better integrate visual cues from demonstrations."}}
{"id": "2510.24120", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24120", "abs": "https://arxiv.org/abs/2510.24120", "authors": ["Ziyu Liu", "Yijing Liu", "Jianfei Yuan", "Minzhi Yan", "Le Yue", "Honghui Xiong", "Yi Yang"], "title": "Graph-Guided Concept Selection for Efficient Retrieval-Augmented Generation", "comment": null, "summary": "Graph-based RAG constructs a knowledge graph (KG) from text chunks to enhance\nretrieval in Large Language Model (LLM)-based question answering. It is\nespecially beneficial in domains such as biomedicine, law, and political\nscience, where effective retrieval often involves multi-hop reasoning over\nproprietary documents. However, these methods demand numerous LLM calls to\nextract entities and relations from text chunks, incurring prohibitive costs at\nscale. Through a carefully designed ablation study, we observe that certain\nwords (termed concepts) and their associated documents are more important.\nBased on this insight, we propose Graph-Guided Concept Selection (G2ConS). Its\ncore comprises a chunk selection method and an LLM-independent concept graph.\nThe former selects salient document chunks to reduce KG construction costs; the\nlatter closes knowledge gaps introduced by chunk selection at zero cost.\nEvaluations on multiple real-world datasets show that G2ConS outperforms all\nbaselines in construction cost, retrieval effectiveness, and answering quality.", "AI": {"tldr": "G2ConS reduces the cost of graph-based retrieval for LLM QA by selecting salient chunks and using a zero-cost, LLM-independent concept graph, achieving better construction cost, retrieval effectiveness, and QA quality across real datasets.", "motivation": "Retrieval-driven QA with LLMs in domains with proprietary documents requires many LLM calls to extract entities/relations, making it costly at scale; a cheaper, effective retrieval graph is highly desirable.", "method": "An ablation study identifies important words (concepts) and their documents. Proposes Graph-Guided Concept Selection (G2ConS) with (1) a chunk selection method to pick salient document chunks, and (2) a zero-cost, LLM-independent concept graph to bridge gaps caused by chunk reduction.", "result": "G2ConS outperforms baselines on construction cost, retrieval effectiveness, and answering quality across multiple real-world datasets.", "conclusion": "G2ConS offers a cost-efficient, end-to-end KG-based retrieval approach for LLM QA, reducing dependence on expensive LLM-derived extractions while maintaining or improving QA performance; well-suited for domains with proprietary documents and multi-hop retrieval."}}
{"id": "2510.24125", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24125", "abs": "https://arxiv.org/abs/2510.24125", "authors": ["Kiran Bacsa", "Wei Liu", "Xudong Jian", "Huangbin Liang", "Eleni Chatzi"], "title": "Causal Convolutional Neural Networks as Finite Impulse Response Filters", "comment": "14 pages, 19 figures, Under review", "summary": "This study investigates the behavior of Causal Convolutional Neural Networks\n(CNNs) with quasi-linear activation functions when applied to time-series data\ncharacterized by multimodal frequency content. We demonstrate that, once\ntrained, such networks exhibit properties analogous to Finite Impulse Response\n(FIR) filters, particularly when the convolutional kernels are of extended\nlength exceeding those typically employed in standard CNN architectures. Causal\nCNNs are shown to capture spectral features both implicitly and explicitly,\noffering enhanced interpretability for tasks involving dynamic systems.\nLeveraging the associative property of convolution, we further show that the\nentire network can be reduced to an equivalent single-layer filter resembling\nan FIR filter optimized via least-squares criteria. This equivalence yields new\ninsights into the spectral learning behavior of CNNs trained on signals with\nsparse frequency content. The approach is validated on both simulated beam\ndynamics and real-world bridge vibration datasets, underlining its relevance\nfor modeling and identifying physical systems governed by dynamic responses.", "AI": {"tldr": "Causal CNNs with long kernels and quasi-linear activations on multimodal time-series behave like FIR filters and can be reduced to a single-layer FIR via least-squares, enabling interpretable spectral learning; validated on beam dynamics and bridge vibration data.", "motivation": "Understand how deep causal CNNs learn spectral content in time-series and link their behavior to classical linear signal processing to improve interpretability for dynamic physical systems.", "method": "Theoretical and empirical analysis of causal CNNs with extended kernels and quasi-linear activations. Demonstrate FIR-like behavior and use associativity of convolution to reduce the network to an equivalent single-layer FIR filter optimized by least-squares. Validate on simulated beam dynamics and real bridge vibration datasets.", "result": "CNNs capture spectral features implicitly and explicitly, offering enhanced interpretability. The network is equivalent to an optimized FIR filter under least-squares criteria, yielding insights into spectral learning for signals with sparse frequency content; validation on beam dynamics simulations and bridge data supports relevance for modeling dynamic systems.", "conclusion": "Establishes a bridge between CNN-based spectral learning and FIR filtering, providing a practical reduction technique and interpretability framework for modeling physical dynamic systems with time-series data."}}
{"id": "2510.24503", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.24503", "abs": "https://arxiv.org/abs/2510.24503", "authors": ["Mortesa Hussaini", "Jan Thei\u00df", "Anthony Stein"], "title": "Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments", "comment": null, "summary": "In the context of Federated Learning with heterogeneous data environments,\nlocal models tend to converge to their own local model optima during local\ntraining steps, deviating from the overall data distributions. Aggregation of\nthese local updates, e.g., with FedAvg, often does not align with the global\nmodel optimum (client drift), resulting in an update that is suboptimal for\nmost clients. Personalized Federated Learning approaches address this challenge\nby exclusively focusing on the average local performances of clients' models on\ntheir own data distribution. Generalization to out-of-distribution samples,\nwhich is a substantial benefit of FedAvg and represents a significant component\nof robustness, appears to be inadequately incorporated into the assessment and\nevaluation processes. This study involves a thorough evaluation of Federated\nLearning approaches, encompassing both their local performance and their\ngeneralization capabilities. Therefore, we examine different stages within a\nsingle communication round to enable a more nuanced understanding of the\nconsidered metrics. Furthermore, we propose and incorporate a modified approach\nof FedAvg, designated as Federated Learning with Individualized Updates (FLIU),\nextending the algorithm by a straightforward individualization step with an\nadaptive personalization factor. We evaluate and compare the approaches\nempirically using MNIST and CIFAR-10 under various distributional conditions,\nincluding benchmark IID and pathological non-IID, as well as additional novel\ntest environments with Dirichlet distribution specifically developed to stress\nthe algorithms on complex data heterogeneity.", "AI": {"tldr": "Proposes Federated Learning with Individualized Updates (FLIU) to address client drift in heterogeneous data by extending FedAvg with an adaptive personalization step, and emphasizes evaluating both local performance and generalization across staged metrics and diverse data splits.", "motivation": "In FL with heterogeneous data, local models drift toward local optima, and FedAvg updates may be suboptimal for the global objective. Current personalized FL often focuses on local performance, neglecting robustness and generalization to out-of-distribution data. A comprehensive evaluation framework and a method combining personalization with aggregation are needed.", "method": "Extend FedAvg with an adaptive individualized update step (FLIU) to personalize updates per client. Evaluate empirically on MNIST and CIFAR-10 under IID, non-IID Dirichlet distributions, and novel stress-test environments to assess both local performance and generalization across different stages within a communication round.", "result": "Abstract does not report concrete empirical results; it indicates that the method will be evaluated empirically under various data heterogeneity conditions.", "conclusion": "The work proposes a straightforward augmentation to FedAvg (individualized updates with adaptive personalization) and a richer evaluation framework to capture both local performance and generalization, signaling potential robustness benefits but requiring empirical validation."}}
{"id": "2510.24135", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24135", "abs": "https://arxiv.org/abs/2510.24135", "authors": ["Hojin Cheon", "Hyeongseok Seo", "Jihun Jeon", "Wooju Lee", "Dohyun Jeong", "Hongseok Kim"], "title": "Fixed Point Neural Acceleration and Inverse Surrogate Model for Battery Parameter Identification", "comment": "31 pages, 11 figures, submitted to Applied Energy", "summary": "The rapid expansion of electric vehicles has intensified the need for\naccurate and efficient diagnosis of lithium-ion batteries. Parameter\nidentification of electrochemical battery models is widely recognized as a\npowerful method for battery health assessment. However, conventional\nmetaheuristic approaches suffer from high computational cost and slow\nconvergence, and recent machine learning methods are limited by their reliance\non constant current data, which may not be available in practice. To overcome\nthese challenges, we propose deep learning-based framework for parameter\nidentification of electrochemical battery models. The proposed framework\ncombines a neural surrogate model of the single particle model with electrolyte\n(NeuralSPMe) and a deep learning-based fixed-point iteration method. NeuralSPMe\nis trained on realistic EV load profiles to accurately predict lithium\nconcentration dynamics under dynamic operating conditions while a parameter\nupdate network (PUNet) performs fixed-point iterative updates to significantly\nreduce both the evaluation time per sample and the overall number of iterations\nrequired for convergence. Experimental evaluations demonstrate that the\nproposed framework accelerates the parameter identification by more than 2000\ntimes, achieves superior sample efficiency and more than 10 times higher\naccuracy compared to conventional metaheuristic algorithms, particularly under\ndynamic load scenarios encountered in practical applications.", "AI": {"tldr": "A deep learning-based framework combining NeuralSPMe surrogate and PUNet for fast, accurate parameter identification of electrochemical battery models, achieving huge speedups under dynamic EV loads.", "motivation": "Need for accurate, efficient battery health assessment. Metaheuristics are computationally expensive; existing ML methods depend on constant-current data; real-world EVs exhibit dynamic loads requiring robust identification.", "method": "Employ NeuralSPMe as a neural surrogate of the single particle model with electrolyte, trained on realistic EV load profiles to capture lithium concentration dynamics; use a parameter update network (PUNet) to perform fixed-point iterations and accelerate convergence, reducing evaluation time and total iterations.", "result": "Accelerates parameter identification by >2000\u00d7, achieves superior sample efficiency, and >10\u00d7 higher accuracy compared with conventional metaheuristic algorithms, particularly under dynamic load scenarios.", "conclusion": "The proposed framework offers a scalable, efficient, and accurate solution for parameter identification of electrochemical battery models in realistic, dynamic operating conditions, addressing the limitations of traditional optimization and ML approaches."}}
{"id": "2510.24160", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24160", "abs": "https://arxiv.org/abs/2510.24160", "authors": ["Aiqing Zhu", "Beatrice W. Soh", "Grigorios A. Pavliotis", "Qianxiao Li"], "title": "Identifiable learning of dissipative dynamics", "comment": null, "summary": "Complex dissipative systems appear across science and engineering, from\npolymers and active matter to learning algorithms. These systems operate far\nfrom equilibrium, where energy dissipation and time irreversibility are key to\ntheir behavior, but are difficult to quantify from data. Learning accurate and\ninterpretable models of such dynamics remains a major challenge: the models\nmust be expressive enough to describe diverse processes, yet constrained enough\nto remain physically meaningful and mathematically identifiable. Here, we\nintroduce I-OnsagerNet, a neural framework that learns dissipative stochastic\ndynamics directly from trajectories while ensuring both interpretability and\nuniqueness. I-OnsagerNet extends the Onsager principle to guarantee that the\nlearned potential is obtained from the stationary density and that the drift\ndecomposes cleanly into time-reversible and time-irreversible components, as\ndictated by the Helmholtz decomposition. Our approach enables us to calculate\nthe entropy production and to quantify irreversibility, offering a principled\nway to detect and quantify deviations from equilibrium. Applications to polymer\nstretching in elongational flow and to stochastic gradient Langevin dynamics\nreveal new insights, including super-linear scaling of barrier heights and\nsub-linear scaling of entropy production rates with the strain rate, and the\nsuppression of irreversibility with increasing batch size. I-OnsagerNet thus\nestablishes a general, data-driven framework for discovering and interpreting\nnon-equilibrium dynamics.", "AI": {"tldr": "Introduces I-OnsagerNet, a data-driven framework for learning dissipative stochastic dynamics with interpretable, unique decompositions to quantify irreversibility and entropy production.", "motivation": "Quantify energy dissipation and time irreversibility in far-from-equilibrium systems from trajectory data, with models that are expressive yet physically meaningful and identifiable.", "method": "Extends Onsager's principle by learning a potential from the stationary density and decomposing drift via Helmholtz decomposition into reversible and irreversible parts; enables computation of entropy production and irreversibility; ensures uniqueness and interpretability.", "result": "Allows calculation of entropy production and quantification of irreversibility; uncovering scaling laws (e.g., super-linear barrier heights with strain rate; sub-linear entropy production with strain rate) and batch-size effects; validated on polymer stretching in elongational flow and stochastic gradient Langevin dynamics.", "conclusion": "I-OnsagerNet provides a general, data-driven framework for discovering and interpreting non-equilibrium dynamics, offering a principled means to detect and quantify deviations from equilibrium."}}
{"id": "2510.24173", "categories": ["cs.LG", "cs.NA", "math.DS", "math.NA", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.24173", "abs": "https://arxiv.org/abs/2510.24173", "authors": ["Yiheng Du", "Aditi S. Krishnapriyan"], "title": "EddyFormer: Accelerated Neural Simulations of Three-Dimensional Turbulence at Scale", "comment": "NeurIPS 2025", "summary": "Computationally resolving turbulence remains a central challenge in fluid\ndynamics due to its multi-scale interactions. Fully resolving large-scale\nturbulence through direct numerical simulation (DNS) is computationally\nprohibitive, motivating data-driven machine learning alternatives. In this\nwork, we propose EddyFormer, a Transformer-based spectral-element (SEM)\narchitecture for large-scale turbulence simulation that combines the accuracy\nof spectral methods with the scalability of the attention mechanism. We\nintroduce an SEM tokenization that decomposes the flow into grid-scale and\nsubgrid-scale components, enabling capture of both local and global features.\nWe create a new three-dimensional isotropic turbulence dataset and train\nEddyFormer to achieves DNS-level accuracy at 256^3 resolution, providing a 30x\nspeedup over DNS. When applied to unseen domains up to 4x larger than in\ntraining, EddyFormer preserves accuracy on physics-invariant metrics-energy\nspectra, correlation functions, and structure functions-showing domain\ngeneralization. On The Well benchmark suite of diverse turbulent flows,\nEddyFormer resolves cases where prior ML models fail to converge, accurately\nreproducing complex dynamics across a wide range of physical conditions.", "AI": {"tldr": "EddyFormer combines a Transformer-based spectral-element approach with a novel SEM tokenization to simulate large-scale turbulence. It achieves DNS-level accuracy at 256^3 with ~30x speedup, generalizes to unseen domains up to 4x larger, and performs well on diverse flows where prior ML models struggle.", "motivation": "DNS of turbulence is computationally prohibitive due to multi-scale interactions. A data-driven, scalable model that preserves physics-inspired metrics and generalizes across domain sizes is needed.", "method": "A Transformer-based spectral-element (SEM) architecture named EddyFormer. Introduces SEM tokenization that splits flow into grid-scale and subgrid-scale components to capture local and global features. Trains on a newly created 3D isotropic turbulence dataset to reproduce DNS accuracy at 256^3. Evaluates on larger unseen domains and on the Well benchmark suite to assess generalization and robustness.", "result": "EddyFormer achieves DNS-level accuracy at 256^3 and delivers ~30x speedup over DNS. It generalizes to unseen domains up to 4x larger than training while preserving physics-invariant metrics: energy spectra, correlation functions, and structure functions. On The Well benchmark, it resolves cases where prior ML models fail to converge and accurately reproduces complex dynamics across diverse physical conditions.", "conclusion": "The combination of SEM with Transformer-based attention and the SEM tokenization enables accurate, scalable turbulence simulation with strong domain generalization. EddyFormer demonstrates competitive performance across a range of flows and conditions, suggesting potential to complement or replace DNS in large-scale turbulence studies."}}
{"id": "2510.24180", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24180", "abs": "https://arxiv.org/abs/2510.24180", "authors": ["Arpita Kundu", "Joyita Chakraborty", "Anindita Desarkar", "Aritra Sen", "Srushti Anil Patil", "Vishwanathan Raman"], "title": "V-SAT: Video Subtitle Annotation Tool", "comment": null, "summary": "The surge of audiovisual content on streaming platforms and social media has\nheightened the demand for accurate and accessible subtitles. However, existing\nsubtitle generation methods primarily speech-based transcription or OCR-based\nextraction suffer from several shortcomings, including poor synchronization,\nincorrect or harmful text, inconsistent formatting, inappropriate reading\nspeeds, and the inability to adapt to dynamic audio-visual contexts. Current\napproaches often address isolated issues, leaving post-editing as a\nlabor-intensive and time-consuming process. In this paper, we introduce V-SAT\n(Video Subtitle Annotation Tool), a unified framework that automatically\ndetects and corrects a wide range of subtitle quality issues. By combining\nLarge Language Models(LLMs), Vision-Language Models (VLMs), Image Processing,\nand Automatic Speech Recognition (ASR), V-SAT leverages contextual cues from\nboth audio and video. Subtitle quality improved, with the SUBER score reduced\nfrom 9.6 to 3.54 after resolving all language mode issues and F1-scores of\n~0.80 for image mode issues. Human-in-the-loop validation ensures high-quality\nresults, providing the first comprehensive solution for robust subtitle\nannotation.", "AI": {"tldr": "A unified subtitle annotation framework (V-SAT) that uses LLMs, VLMs, image processing, and ASR to automatically detect and correct a wide range of subtitle quality issues using audio-visual context, reducing post-editing effort.", "motivation": "Subtitles on streaming platforms are essential but current methods (speech transcription or OCR) struggle with synchronization, harmful/inaccurate text, formatting inconsistencies, reading-speed issues, and adapting to dynamic audiovisual context. Post-editing is labor-intensive, motivating a unified, automated solution.", "method": "V-SAT integrates Large Language Models, Vision-Language Models, image processing, and automatic speech recognition to jointly analyze audio and video cues for a broad range of subtitle quality issues. It addresses both language-mode and image-mode problems, employing human-in-the-loop validation to ensure high-quality results, and reporting quantitative improvements (e.g., SUBER and F1 metrics).", "result": "Subtitle quality improves significantly: SUBER score drops from 9.6 to 3.54 after correcting language-mode issues; image-mode issues achieve ~0.80 F1-score. Human-in-the-loop validation confirms robust outputs; claimed as the first comprehensive solution for robust subtitle annotation.", "conclusion": "The paper presents a unified, multimodal framework that tackles diverse subtitle quality issues end-to-end, reducing manual post-editing and enabling robust, accurate subtitles across content."}}
{"id": "2510.24200", "categories": ["cs.LG", "cs.CR", "cs.DC", "I.2.11"], "pdf": "https://arxiv.org/pdf/2510.24200", "abs": "https://arxiv.org/abs/2510.24200", "authors": ["Alexander Bakarsky", "Dimitar I. Dimitrov", "Maximilian Baader", "Martin Vechev"], "title": "SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary Learning", "comment": "Published at the Workshop on Regulatable ML at the 39th Conference on\n  Neural Information Processing Systems (NeurIPS 2025)", "summary": "Federated Learning has seen an increased deployment in real-world scenarios\nrecently, as it enables the distributed training of machine learning models\nwithout explicit data sharing between individual clients. Yet, the introduction\nof the so-called gradient inversion attacks has fundamentally challenged its\nprivacy-preserving properties. Unfortunately, as these attacks mostly rely on\ndirect data optimization without any formal guarantees, the vulnerability of\nreal-world systems remains in dispute and requires tedious testing for each new\nfederated deployment. To overcome these issues, recently the SPEAR attack was\nintroduced, which is based on a theoretical analysis of the gradients of linear\nlayers with ReLU activations. While SPEAR is an important theoretical\nbreakthrough, the attack's practicality was severely limited by its exponential\nruntime in the batch size b. In this work, we fill this gap by applying\nState-of-the-Art techniques from Sparsely-Used Dictionary Learning to make the\nproblem of gradient inversion on linear layers with ReLU activations tractable.\nOur experiments demonstrate that our new attack, SPEAR++, retains all desirable\nproperties of SPEAR, such as robustness to DP noise and FedAvg aggregation,\nwhile being applicable to 10x bigger batch sizes.", "AI": {"tldr": "SPEAR++ makes gradient inversion attacks on linear layers with ReLU practical for larger batch sizes using sparse dictionary learning, preserving robustness to DP noise and FedAvg.", "motivation": "Assess privacy risks in federated learning and address SPEAR's prohibitive runtime by enabling a tractable attack that scales to bigger batches.", "method": "Apply Sparsely-Used Dictionary Learning techniques to reformulate gradient inversion for linear-ReLU networks, enabling efficient recovery.", "result": "Attack becomes scalable; can handle 10x larger batch sizes and retains robustness to DP noise and FedAvg aggregation.", "conclusion": "SPEAR++ demonstrates a more practical gradient inversion threat under standard privacy defenses, highlighting ongoing privacy risks in FL."}}
{"id": "2510.24216", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24216", "abs": "https://arxiv.org/abs/2510.24216", "authors": ["Fan Xu", "Hao Wu", "Kun Wang", "Nan Wang", "Qingsong Wen", "Xian Wu", "Wei Gong", "Xibin Zhao"], "title": "Unlocking Out-of-Distribution Generalization in Dynamics through Physics-Guided Augmentation", "comment": null, "summary": "In dynamical system modeling, traditional numerical methods are limited by\nhigh computational costs, while modern data-driven approaches struggle with\ndata scarcity and distribution shifts. To address these fundamental\nlimitations, we first propose SPARK, a physics-guided quantitative augmentation\nplugin. Specifically, SPARK utilizes a reconstruction autoencoder to integrate\nphysical parameters into a physics-rich discrete state dictionary. This state\ndictionary then acts as a structured dictionary of physical states, enabling\nthe creation of new, physically-plausible training samples via principled\ninterpolation in the latent space. Further, for downstream prediction, these\naugmented representations are seamlessly integrated with a Fourier-enhanced\nGraph ODE, a combination designed to robustly model the enriched data\ndistribution while capturing long-term temporal dependencies. Extensive\nexperiments on diverse benchmarks demonstrate that SPARK significantly\noutperforms state-of-the-art baselines, particularly in challenging\nout-of-distribution scenarios and data-scarce regimes, proving the efficacy of\nour physics-guided augmentation paradigm.", "AI": {"tldr": "SPARK proposes physics-guided data augmentation for dynamical systems: a reconstruction autoencoder builds a physics-rich discrete state dictionary, enabling principled latent-space interpolation; augmented representations feed a Fourier-enhanced Graph ODE for robust, long-horizon prediction, yielding strong gains in data-scarce and out-of-distribution scenarios.", "motivation": "Traditional numerical methods are computationally costly, and modern data-driven models struggle with limited data and distribution shifts. Incorporating physics via data augmentation aims to enrich training samples and stabilize long-term predictions.", "method": "Train a reconstruction autoencoder to embed physical parameters into a discrete physics-rich state dictionary. Use this dictionary to interpolate new, physically plausible samples in the latent space. For prediction, integrate the augmented representations with a Fourier-enhanced Graph ODE to capture long-range temporal dependencies while leveraging the enriched data distribution.", "result": "Extensive experiments show SPARK outperforms state-of-the-art baselines, particularly in out-of-distribution and data-scarce regimes, demonstrating the efficacy of physics-guided augmentation.", "conclusion": "Physics-guided augmentation via SPARK is an effective paradigm for robust, data-efficient dynamical modeling, enabling improved generalization and long-horizon predictions."}}
{"id": "2510.24217", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24217", "abs": "https://arxiv.org/abs/2510.24217", "authors": ["Alisher Turubayev", "Anna Shopova", "Fabian Lange", "Mahmut Kamalak", "Paul Mattes", "Victoria Ayvasky", "Bert Arnrich", "Bjarne Pfitzner", "Robin P. van de Water"], "title": "Closing Gaps: An Imputation Analysis of ICU Vital Signs", "comment": "Preprint", "summary": "As more Intensive Care Unit (ICU) data becomes available, the interest in\ndeveloping clinical prediction models to improve healthcare protocols\nincreases. However, the lack of data quality still hinders clinical prediction\nusing Machine Learning (ML). Many vital sign measurements, such as heart rate,\ncontain sizeable missing segments, leaving gaps in the data that could\nnegatively impact prediction performance. Previous works have introduced\nnumerous time-series imputation techniques. Nevertheless, more comprehensive\nwork is needed to compare a representative set of methods for imputing ICU\nvital signs and determine the best practice. In reality, ad-hoc imputation\ntechniques that could decrease prediction accuracy, like zero imputation, are\nstill used. In this work, we compare established imputation techniques to guide\nresearchers in improving the performance of clinical prediction models by\nselecting the most accurate imputation technique. We introduce an extensible\nand reusable benchmark with currently 15 imputation and 4 amputation methods,\ncreated for benchmarking on major ICU datasets. We hope to provide a\ncomparative basis and facilitate further ML development to bring more models\ninto clinical practice.", "AI": {"tldr": "Proposes an extensible benchmark to compare ICU vital-sign imputation methods and guide ML predictions in healthcare.", "motivation": "Data quality and missingness in ICU vital signs hinder machine learning-based predictions; ad-hoc imputation (e.g., zero fill) can degrade performance, necessitating systematic evaluation of imputation strategies.", "method": "Introduces a reusable benchmark framework encompassing 15 imputation methods and 4 amputation methods, designed for benchmarking on major ICU datasets to enable fair comparisons.", "result": "The abstract presents the benchmark and its intended use but does not report empirical results; it outlines how it will allow researchers to compare methods.", "conclusion": "A standardized benchmark should help identify the most accurate imputation techniques and accelerate the adoption of ML models in clinical practice."}}
{"id": "2510.24233", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24233", "abs": "https://arxiv.org/abs/2510.24233", "authors": ["Antoine Szatkownik", "Aur\u00e9lien Decelle", "Beatriz Seoane", "Nicolas Bereux", "L\u00e9o Planche", "Guillaume Charpiat", "Burak Yelmen", "Flora Jay", "Cyril Furtlehner"], "title": "PRIVET: Privacy Metric Based on Extreme Value Theory", "comment": null, "summary": "Deep generative models are often trained on sensitive data, such as genetic\nsequences, health data, or more broadly, any copyrighted, licensed or protected\ncontent. This raises critical concerns around privacy-preserving synthetic\ndata, and more specifically around privacy leakage, an issue closely tied to\noverfitting. Existing methods almost exclusively rely on global criteria to\nestimate the risk of privacy failure associated to a model, offering only\nquantitative non interpretable insights. The absence of rigorous evaluation\nmethods for data privacy at the sample-level may hinder the practical\ndeployment of synthetic data in real-world applications. Using extreme value\nstatistics on nearest-neighbor distances, we propose PRIVET, a generic\nsample-based, modality-agnostic algorithm that assigns an individual privacy\nleak score to each synthetic sample. We empirically demonstrate that PRIVET\nreliably detects instances of memorization and privacy leakage across diverse\ndata modalities, including settings with very high dimensionality, limited\nsample sizes such as genetic data and even under underfitting regimes. We\ncompare our method to existing approaches under controlled settings and show\nits advantage in providing both dataset level and sample level assessments\nthrough qualitative and quantitative outputs. Additionally, our analysis\nreveals limitations in existing computer vision embeddings to yield\nperceptually meaningful distances when identifying near-duplicate samples.", "AI": {"tldr": "PRIVET provides per-sample privacy leakage scores using extreme value statistics on nearest-neighbor distances, enabling interpretable, sample-level detection of memorization across data modalities; it outperforms global-risk criteria and uncovers current CV embedding limitations.", "motivation": "Existing privacy evaluation for synthetic data relies on global metrics that lack interpretability and sample-level insight, hindering deployment. There is a need for a rigorous, modality-agnostic method to assess privacy risk at the sample level.", "method": "Apply extreme value statistics to NN distances to assign an individual privacy leak score to each synthetic sample. Modality-agnostic approach, enabling dataset-level and sample-level outputs. Evaluated across high-dimensional data, small sample sizes (e.g., genetic data), and underfitting regimes; comparisons with existing approaches under controlled settings.", "result": "PRIVET reliably detects memorization and privacy leakage across diverse modalities; provides both dataset-level and sample-level assessments with qualitative and quantitative outputs; reveals that many computer-vision embeddings produce distances that are not perceptually meaningful for near-duplicate detection.", "conclusion": "Sample-level privacy evaluation is feasible and useful for real-world deployment of synthetic data; PRIVET offers a generic, interpretable, and robust tool, while also highlighting limitations of current CV embeddings for privacy assessment."}}
{"id": "2510.24234", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24234", "abs": "https://arxiv.org/abs/2510.24234", "authors": ["Ludovic Schwartz", "Hamish Flynn", "Gergely Neu"], "title": "Sparse Optimistic Information Directed Sampling", "comment": null, "summary": "Many high-dimensional online decision-making problems can be modeled as\nstochastic sparse linear bandits. Most existing algorithms are designed to\nachieve optimal worst-case regret in either the data-rich regime, where\npolynomial dependence on the ambient dimension is unavoidable, or the data-poor\nregime, where dimension-independence is possible at the cost of worse\ndependence on the number of rounds. In contrast, the sparse Information\nDirected Sampling (IDS) algorithm satisfies a Bayesian regret bound that has\nthe optimal rate in both regimes simultaneously. In this work, we explore the\nuse of Sparse Optimistic Information Directed Sampling (SOIDS) to achieve the\nsame adaptivity in the worst-case setting, without Bayesian assumptions.\nThrough a novel analysis that enables the use of a time-dependent learning\nrate, we show that SOIDS can optimally balance information and regret. Our\nresults extend the theoretical guarantees of IDS, providing the first algorithm\nthat simultaneously achieves optimal worst-case regret in both the data-rich\nand data-poor regimes. We empirically demonstrate the good performance of\nSOIDS.", "AI": {"tldr": "SOIDS achieves optimal worst-case regret in both data-rich and data-poor regimes for sparse linear bandits, without Bayesian assumptions, by using a time-dependent learning rate; theory and experiments support its performance.", "motivation": "There is a need for algorithms that adaptively achieve optimal worst-case regret across both data-rich and data-poor regimes in high-dimensional online decision problems, without relying on Bayesian priors.", "method": "Introduce Sparse Optimistic Information Directed Sampling (SOIDS) with a time-dependent learning rate and novel analysis; extends IDS to worst-case, sparse setting to balance information and regret.", "result": "SOIDS provably attains optimal worst-case regret in both regimes; provides the first such guarantee in the non-Bayesian setting; empirical experiments show good performance.", "conclusion": "SOIDS unifies optimal worst-case guarantees across data-rich and data-poor regimes without Bayesian assumptions, extending IDS and proving practical effectiveness."}}
{"id": "2510.24235", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24235", "abs": "https://arxiv.org/abs/2510.24235", "authors": ["Ai Jian", "Jingqing Ruan", "Xing Ma", "Dailin Li", "QianLin Zhou", "Ke Zeng", "Xunliang Cai"], "title": "PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling", "comment": null, "summary": "Reward models (RMs) are central to reinforcement learning from human feedback\n(RLHF), providing the critical supervision signals that align large language\nmodels (LLMs) with human preferences. While generative reward models (GRMs)\noffer greater interpretability than traditional scalar RMs, current training\nparadigms remain limited. Pair-wise methods rely on binary good-versus-bad\nlabels, which cause mismatches for point-wise inference and necessitate complex\npairing strategies for effective application in RLHF. On the other hand,\npoint-wise methods require more elaborate absolute labeling with rubric-driven\ncriteria, resulting in poor adaptability and high annotation costs. In this\nwork, we propose the Preference-Aware Task-Adaptive Reward Model (PaTaRM), a\nunified framework that integrates a preference-aware reward (PAR) mechanism\nwith dynamic rubric adaptation. PaTaRM leverages relative preference\ninformation from pairwise data to construct robust point-wise training signals,\neliminating the need for explicit point-wise labels. Simultaneously, it employs\na task-adaptive rubric system that flexibly generates evaluation criteria for\nboth global task consistency and instance-specific fine-grained reasoning. This\ndesign enables efficient, generalizable, and interpretable reward modeling for\nRLHF. Extensive experiments show that PaTaRM achieves an average relative\nimprovement of 4.7% on RewardBench and RMBench across Qwen3-8B and Qwen3-14B\nmodels. Furthermore, PaTaRM boosts downstream RLHF performance, with an average\nimprovement of 13.6% across IFEval and InFoBench benchmarks, confirming its\neffectiveness and robustness. Our code is available at\nhttps://github.com/JaneEyre0530/PaTaRM.", "AI": {"tldr": "PaTaRM unifies preference-aware reward modeling with dynamic rubric adaptation to turn pairwise preferences into robust point-wise training signals and generate task-adaptive evaluation criteria, enabling efficient, generalizable, and interpretable RLHF reward models; shows improvements on benchmarks and code released.", "motivation": "Current reward models for RLHF face a mismatch between pairwise labels and point-wise inferences, plus high annotation costs and limited adaptability. There is a need for an interpretable, flexible reward signal that leverages relative preferences to produce robust training signals and adaptable evaluation criteria.", "method": "Introduce PaTaRM which combines a Preference-Aware Reward (PAR) mechanism with a dynamic rubric adaptation system. It uses relative preferences from pairwise data to create robust point-wise training signals without explicit point-wise labels, and a task-adaptive rubric system to generate criteria for global task consistency and instance-specific reasoning.", "result": "Empirical results show an average relative improvement of 4.7% on RewardBench and RMBench across Qwen3-8B and Qwen3-14B models. Downstream RLHF performance improves by an average of 13.6% on IFEval and InFoBench. Code is released at https://github.com/JaneEyre0530/PaTaRM.", "conclusion": "PaTaRM delivers efficient, generalizable, and interpretable reward modeling for RLHF, demonstrating robustness and improved downstream RLHF performance, with a flexible framework that reduces labeling burdens and supports task-adaptive evaluation."}}
{"id": "2510.24240", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24240", "abs": "https://arxiv.org/abs/2510.24240", "authors": ["Edward Markai", "Sina Molavipour"], "title": "Temporal Knowledge Graph Hyperedge Forecasting: Exploring Entity-to-Category Link Prediction", "comment": null, "summary": "Temporal Knowledge Graphs have emerged as a powerful way of not only modeling\nstatic relationships between entities but also the dynamics of how relations\nevolve over time. As these informational structures can be used to store\ninformation from a real-world setting, such as a news flow, predicting future\ngraph components to a certain extent equates predicting real-world events. Most\nof the research in this field focuses on embedding-based methods, often\nleveraging convolutional neural net architectures. These solutions act as black\nboxes, limiting insight. In this paper, we explore an extension to an\nestablished rule-based framework, TLogic, that yields a high accuracy in\ncombination with explainable predictions. This offers transparency and allows\nthe end-user to critically evaluate the rules applied at the end of the\nprediction stage. The new rule format incorporates entity category as a key\ncomponent with the purpose of limiting rule application only to relevant\nentities. When categories are unknown for building the graph, we propose a\ndata-driven method to generate them with an LLM-based approach. Additionally,\nwe investigate the choice of aggregation method for scores of retrieved\nentities when performing category prediction.", "AI": {"tldr": "Extends TLogic with category-aware rules for Temporal Knowledge Graphs, enabling explainable predictions; uses LLM-based category generation when categories are unknown; studies aggregation methods for ranking retrieved entities.", "motivation": "To overcome the black-box nature of embedding-based temporal KG methods by providing explainable, rule-based predictions; incorporate entity categories to constrain rule applicability; handle missing category information with data-driven categorization; assess how score aggregation affects category prediction.", "method": "Introduce a new rule format that embeds entity category; adopt a data-driven method (LLM-based) to generate categories when graph lacks them; evaluate different aggregation methods for combining scores of retrieved entities during category prediction.", "result": "Achieves high accuracy together with explainable predictions, demonstrating the viability of the category-aware rule extension; provides transparency for end-users to evaluate rules.", "conclusion": "Category-aware rules and LLM-generated categories are viable for temporal KG reasoning, improving interpretability without sacrificing accuracy; the chosen aggregation method for scores influences category prediction and is an important design choice."}}
{"id": "2510.24273", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24273", "abs": "https://arxiv.org/abs/2510.24273", "authors": ["Junlin Mu", "Hantao Huang", "Jihang Zhang", "Minghui Yu", "Tao Wang", "Yidong Li"], "title": "SALS: Sparse Attention in Latent Space for KV cache Compression", "comment": null, "summary": "Large Language Models capable of handling extended contexts are in high\ndemand, yet their inference remains challenging due to substantial Key-Value\ncache size and high memory bandwidth requirements. Previous research has\ndemonstrated that KV cache exhibits low-rank characteristics within the hidden\ndimension, suggesting the potential for effective compression. However, due to\nthe widely adopted Rotary Position Embedding mechanism in modern LLMs, naive\nlow-rank compression suffers severe accuracy degradation or creates a new speed\nbottleneck, as the low-rank cache must first be reconstructed in order to apply\nRoPE. In this paper, we introduce two key insights: first, the application of\nRoPE to the key vectors increases their variance, which in turn results in a\nhigher rank; second, after the key vectors are transformed into the latent\nspace, they largely maintain their representation across most layers. Based on\nthese insights, we propose the Sparse Attention in Latent Space framework. SALS\nprojects the KV cache into a compact latent space via low-rank projection, and\nperforms sparse token selection using RoPE-free query-key interactions in this\nspace. By reconstructing only a small subset of important tokens, it avoids the\noverhead of full KV cache reconstruction. We comprehensively evaluate SALS on\nvarious tasks using two large-scale models: LLaMA2-7b-chat and Mistral-7b, and\nadditionally verify its scalability on the RULER-128k benchmark with\nLLaMA3.1-8B-Instruct. Experimental results demonstrate that SALS achieves SOTA\nperformance by maintaining competitive accuracy. Under different settings, SALS\nachieves 6.4-fold KV cache compression and 5.7-fold speed-up in the attention\noperator compared to FlashAttention2 on the 4K sequence. For the end-to-end\nthroughput performance, we achieves 1.4-fold and 4.5-fold improvement compared\nto GPT-fast on 4k and 32K sequences, respectively.", "AI": {"tldr": "SALS reduces KV cache size and speeds up attention for long-context LLMs by projecting KV caches into a latent space and performing RoPE-free sparse QK interactions, avoiding full KV reconstruction while maintaining accuracy; achieves substantial compression and speedups across models and benchmarks.", "motivation": "Handling extended-context inference is bottlenecked by large KV caches and high memory bandwidth. Low-rank KV cache hints exist, but RoPE-based models complicate compression; naive low-rank methods degrade accuracy. The goal is efficient KV compression without reconstructing the full cache.", "method": "SALS projects the KV cache into a compact latent space via low-rank projection and performs sparse token selection using RoPE-free query-key interactions in this space. Only a subset of tokens needed for accurate attention are reconstructed, enabling sparse attention in latent space instead of full KV-cache expansion.", "result": "Achieves 6.4\u00d7 KV-cache compression and 5.7\u00d7 speed-up in the attention operator vs FlashAttention2 on 4K sequences. End-to-end throughput improves 1.4\u00d7 and 4.5\u00d7 compared to GPT-fast on 4K and 32K sequences, respectively. Validated on LLaMA2-7b-chat and Mistral-7b; scalable to RULER-128k with LLaMA3.1-8B-Instruct. Maintains competitive accuracy, achieving SOTA performance.", "conclusion": "SALS enables efficient long-context inference by compressing KV caches in latent space with RoPE-free sparse QK, delivering substantial memory bandwidth reductions and speedups while preserving accuracy, and demonstrating strong scalability across models and long sequences."}}
{"id": "2510.24310", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24310", "abs": "https://arxiv.org/abs/2510.24310", "authors": ["Guus Toussaint", "Arno Knobbe"], "title": "EDC: Equation Discovery for Classification", "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  published in Lecture Notes in Computer Science, and is available online at\n  https://doi.org/10.1007/978-3-032-05461-6_9", "summary": "Equation Discovery techniques have shown considerable success in regression\ntasks, where they are used to discover concise and interpretable models\n(\\textit{Symbolic Regression}). In this paper, we propose a new ED-based binary\nclassification framework. Our proposed method EDC finds analytical functions of\nmanageable size that specify the location and shape of the decision boundary.\nIn extensive experiments on artificial and real-life data, we demonstrate how\nEDC is able to discover both the structure of the target equation as well as\nthe value of its parameters, outperforming the current state-of-the-art\nED-based classification methods in binary classification and achieving\nperformance comparable to the state of the art in binary classification. We\nsuggest a grammar of modest complexity that appears to work well on the tested\ndatasets but argue that the exact grammar -- and thus the complexity of the\nmodels -- is configurable, and especially domain-specific expressions can be\nincluded in the pattern language, where that is required. The presented grammar\nconsists of a series of summands (additive terms) that include linear,\nquadratic and exponential terms, as well as products of two features (producing\nhyperbolic curves ideal for capturing XOR-like dependencies). The experiments\ndemonstrate that this grammar allows fairly flexible decision boundaries while\nnot so rich to cause overfitting.", "AI": {"tldr": "A new ED-based binary classifier (EDC) learns analytic decision-boundary functions using a modest, configurable grammar; it shows strong performance among ED-based methods and competitive overall accuracy; supports domain-specific expressions.", "motivation": "Extend equation-discovery (ED) methods to binary classification to produce concise, interpretable decision boundaries, and to simultaneously recover structure and parameters.", "method": "Introduce EDC framework that searches for analytical functions forming the decision boundary via a grammar of additive terms (linear, quadratic, exponential) and products of features to capture nonlinearities (including XOR-like patterns); learn both the structure and numerical parameters; conduct extensive experiments on artificial and real datasets; grammar complexity is configurable and adaptable to domain knowledge.", "result": "EDC outperforms current state-of-the-art ED-based classification methods for binary tasks and achieves performance comparable to the overall state of the art in binary classification; demonstrates recovery of both the target equation structure and its parameters; enables flexible decision boundaries without promoting overfitting due to a moderately expressive grammar.", "conclusion": "EDC provides a viable, interpretable ED-based classifier with a tunable grammar, balancing expressiveness and generalization; domain-specific expressions can be integrated into the pattern language to suit particular problems; shows promise for discovering interpretable boundary equations in classification."}}
{"id": "2510.24318", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24318", "abs": "https://arxiv.org/abs/2510.24318", "authors": ["Prajit Bhaskaran", "Tom Viering"], "title": "Transformers can do Bayesian Clustering", "comment": null, "summary": "Bayesian clustering accounts for uncertainty but is computationally demanding\nat scale. Furthermore, real-world datasets often contain missing values, and\nsimple imputation ignores the associated uncertainty, resulting in suboptimal\nresults. We present Cluster-PFN, a Transformer-based model that extends\nPrior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering. Trained\nentirely on synthetic datasets generated from a finite Gaussian Mixture Model\n(GMM) prior, Cluster-PFN learns to estimate the posterior distribution over\nboth the number of clusters and the cluster assignments. Our method estimates\nthe number of clusters more accurately than handcrafted model selection\nprocedures such as AIC, BIC and Variational Inference (VI), and achieves\nclustering quality competitive with VI while being orders of magnitude faster.\nCluster-PFN can be trained on complex priors that include missing data,\noutperforming imputation-based baselines on real-world genomic datasets, at\nhigh missingness. These results show that the Cluster-PFN can provide scalable\nand flexible Bayesian clustering.", "AI": {"tldr": "Cluster-PFN uses a Transformer-based Prior-Data Fitted Network to perform unsupervised Bayesian clustering, estimating both the number of clusters and assignments. Trained on synthetic data from a finite Gaussian Mixture Model prior, it handles missing data, outperforms traditional model selection (AIC/BIC) and is competitive with Variational Inference while being much faster. It remains robust to high missingness and scales to complex priors.", "motivation": "Bayesian clustering accounts for uncertainty but is computationally heavy, especially at scale; real-world data often contain missing values and simple imputation ignores associated uncertainty, yielding suboptimal results.", "method": "Extend Prior-Data Fitted Networks (PFNs) with a Transformer-based architecture to unsupervised Bayesian clustering (Cluster-PFN). Train entirely on synthetic data generated from a finite Gaussian Mixture Model prior, teaching the model to infer the posterior over the number of clusters and cluster assignments. The framework accommodates missing data within the prior, enabling learning under incomplete observations.", "result": "Cluster-PFN estimates the posterior over the number of clusters more accurately than handcrafted model-selection criteria (AIC, BIC) and achieves clustering quality competitive with Variational Inference, while being orders of magnitude faster. It can be trained on complex priors that include missing data and outperforms imputation-based baselines on real-world genomic datasets with high missingness.", "conclusion": "Cluster-PFN provides scalable and flexible Bayesian clustering, capable of handling missing data via learned priors and delivering fast, accurate inference for both the number of clusters and cluster assignments in real-world, high-m missingness settings."}}
{"id": "2510.24356", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.24356", "abs": "https://arxiv.org/abs/2510.24356", "authors": ["Suman Sanyal"], "title": "Perception Learning: A Formal Separation of Sensory Representation Learning from Decision Learning", "comment": null, "summary": "We introduce Perception Learning (PeL), a paradigm that optimizes an agent's\nsensory interface $f_\\phi:\\mathcal{X}\\to\\mathcal{Z}$ using task-agnostic\nsignals, decoupled from downstream decision learning\n$g_\\theta:\\mathcal{Z}\\to\\mathcal{Y}$. PeL directly targets label-free\nperceptual properties, such as stability to nuisances, informativeness without\ncollapse, and controlled geometry, assessed via objective\nrepresentation-invariant metrics. We formalize the separation of perception and\ndecision, define perceptual properties independent of objectives or\nreparameterizations, and prove that PeL updates preserving sufficient\ninvariants are orthogonal to Bayes task-risk gradients. Additionally, we\nprovide a suite of task-agnostic evaluation metrics to certify perceptual\nquality.", "AI": {"tldr": "PeL decouples perception from decision, learning task-agnostic perceptual representations with invariants, and provides metrics to certify perceptual quality.", "motivation": "To enable robust, task-agnostic perception: learn perceptual interfaces that resist nuisances, preserve informative content, and maintain controlled geometry, independently of downstream tasks.", "method": "Formally separate perception and decision; define perceptual properties independent of objectives or reparameterizations; prove that invariant-preserving PeL updates are orthogonal to Bayes task-risk gradients; introduce a suite of task-agnostic metrics to certify perceptual quality.", "result": "Theoretical guarantees: formal separation of perception and decision, invariant properties, and an orthogonality result; practical toolkit: a suite of task-agnostic metrics to certify perceptual quality.", "conclusion": "PeL provides a principled separation of perception and decision along with a metric-based toolkit to certify perceptual quality, enabling stable, informative, and geometrically controlled perceptual representations that are decoupled from downstream tasks."}}
{"id": "2510.24368", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24368", "abs": "https://arxiv.org/abs/2510.24368", "authors": ["Maria Gabriela Valeriano", "David Kohan Marzag\u00e3o", "Alfredo Montelongo", "Carlos Roberto Veiga Kiffer", "Natan Katz", "Ana Carolina Lorena"], "title": "Filtering instances and rejecting predictions to obtain reliable models in healthcare", "comment": "This paper is under review at Machine Learning (Springer)", "summary": "Machine Learning (ML) models are widely used in high-stakes domains such as\nhealthcare, where the reliability of predictions is critical. However, these\nmodels often fail to account for uncertainty, providing predictions even with\nlow confidence. This work proposes a novel two-step data-centric approach to\nenhance the performance of ML models by improving data quality and filtering\nlow-confidence predictions. The first step involves leveraging Instance\nHardness (IH) to filter problematic instances during training, thereby refining\nthe dataset. The second step introduces a confidence-based rejection mechanism\nduring inference, ensuring that only reliable predictions are retained. We\nevaluate our approach using three real-world healthcare datasets, demonstrating\nits effectiveness at improving model reliability while balancing predictive\nperformance and rejection rate. Additionally, we use alternative criteria -\ninfluence values for filtering and uncertainty for rejection - as baselines to\nevaluate the efficiency of the proposed method. The results demonstrate that\nintegrating IH filtering with confidence-based rejection effectively enhances\nmodel performance while preserving a large proportion of instances. This\napproach provides a practical method for deploying ML systems in\nsafety-critical applications.", "AI": {"tldr": "A two-step data-centric approach improves ML reliability in healthcare by first filtering problematic training instances using Instance Hardness (IH) and then rejecting low-confidence predictions at inference, balancing accuracy and coverage across three real-world datasets and baselines.", "motivation": "ML models in high-stakes domains (e.g., healthcare) must account for uncertainty and avoid making unreliable predictions; data quality and selective prediction are key to deploying trustworthy systems.", "method": "Step 1: filter problematic instances during training using Instance Hardness to refine the dataset. Step 2: apply a confidence-based rejection mechanism during inference to retain only reliable predictions. Baselines include using influence values for filtering and uncertainty for rejection; evaluated on three real healthcare datasets.", "result": "IH-based filtering plus confidence-based rejection improves model reliability and predictive performance while maintaining a high proportion of accepted instances and a manageable rejection rate, outperforming the chosen baselines.", "conclusion": "A practical data-centric strategy for safety-critical ML: combining training-time IH filtering with inference-time confidence-based rejection yields robust, deployable models without excessively sacrificing coverage."}}
{"id": "2510.24375", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24375", "abs": "https://arxiv.org/abs/2510.24375", "authors": ["Yuanyuan Wu", "Zhenlin Qin", "Zhenliang Ma"], "title": "A Comprehensive Evaluation Framework for Synthetic Trip Data Generation in Public Transport", "comment": null, "summary": "Synthetic data offers a promising solution to the privacy and accessibility\nchallenges of using smart card data in public transport research. Despite rapid\nprogress in generative modeling, there is limited attention to comprehensive\nevaluation, leaving unclear how reliable, safe, and useful synthetic data truly\nare. Existing evaluations remain fragmented, typically limited to\npopulation-level representativeness or record-level privacy, without\nconsidering group-level variations or task-specific utility. To address this\ngap, we propose a Representativeness-Privacy-Utility (RPU) framework that\nsystematically evaluates synthetic trip data across three complementary\ndimensions and three hierarchical levels (record, group, population). The\nframework integrates a consistent set of metrics to quantify similarity,\ndisclosure risk, and practical usefulness, enabling transparent and balanced\nassessment of synthetic data quality. We apply the framework to benchmark\ntwelve representative generation methods, spanning conventional statistical\nmodels, deep generative networks, and privacy-enhanced variants. Results show\nthat synthetic data do not inherently guarantee privacy and there is no\n\"one-size-fits-all\" model, the trade-off between privacy and\nrepresentativeness/utility is obvious. Conditional Tabular generative\nadversarial network (CTGAN) provide the most balanced trade-off and is\nsuggested for practical applications. The RPU framework provides a systematic\nand reproducible basis for researchers and practitioners to compare synthetic\ndata generation techniques and select appropriate methods in public transport\napplications.", "AI": {"tldr": "A framework (RPU) evaluates synthetic trip data on Representativeness, Privacy, and Utility across record, group, and population levels; evaluated on 12 generation methods; CTGAN offers the best balanced trade-off.", "motivation": "There is fragmentation in how synthetic data quality is assessed for smart card/public transport data. A unified framework is needed to assess representativeness, privacy risks, and practical utility across hierarchical levels.", "method": "Introduce the RPU framework comprising metrics for similarity (representativeness), disclosure risk (privacy), and utility (practical usefulness) across three hierarchical levels (record, group, population). Apply the framework to 12 generation methods (statistical, deep generative networks, privacy-enhanced variants) and benchmark their performance.", "result": "Synthetic data do not inherently guarantee privacy; no single method dominates across tasks or levels. Trade-offs between privacy and representativeness/utility are evident. CTGAN provides the most balanced trade-off and is recommended for practical use.", "conclusion": "The RPU framework offers a systematic, reproducible basis for comparing synthetic data generation techniques and guiding method selection for public transport applications."}}
{"id": "2510.24380", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24380", "abs": "https://arxiv.org/abs/2510.24380", "authors": ["Aryan Pedawi", "Jordi Silvestre-Ryan", "Bradley Worley", "Darren J Hsu", "Kushal S Shah", "Elias Stehle", "Jingrong Zhang", "Izhar Wallach"], "title": "APEX: Approximate-but-exhaustive search for ultra-large combinatorial synthesis libraries", "comment": null, "summary": "Make-on-demand combinatorial synthesis libraries (CSLs) like Enamine REAL\nhave significantly enabled drug discovery efforts. However, their large size\npresents a challenge for virtual screening, where the goal is to identify the\ntop compounds in a library according to a computational objective (e.g.,\noptimizing docking score) subject to computational constraints under a limited\ncomputational budget. For current library sizes -- numbering in the tens of\nbillions of compounds -- and scoring functions of interest, a routine virtual\nscreening campaign may be limited to scoring fewer than 0.1% of the available\ncompounds, leaving potentially many high scoring compounds undiscovered.\nFurthermore, as constraints (and sometimes objectives) change during the course\nof a virtual screening campaign, existing virtual screening algorithms\ntypically offer little room for amortization. We propose the\napproximate-but-exhaustive search protocol for CSLs, or APEX. APEX utilizes a\nneural network surrogate that exploits the structure of CSLs in the prediction\nof objectives and constraints to make full enumeration on a consumer GPU\npossible in under a minute, allowing for exact retrieval of approximate top-$k$\nsets. To demonstrate APEX's capabilities, we develop a benchmark CSL comprised\nof more than 10 million compounds, all of which have been annotated with their\ndocking scores on five medically relevant targets along with physicohemical\nproperties measured with RDKit such that, for any objective and set of\nconstraints, the ground truth top-$k$ compounds can be identified and compared\nagainst the retrievals from any virtual screening algorithm. We show APEX's\nconsistently strong performance both in retrieval accuracy and runtime compared\nto alternative methods.", "AI": {"tldr": "APEX is an approximate-but-exhaustive search protocol for make-on-demand combinatorial libraries (CSLs) that enables fast, near-top-k retrieval under a constrained computational budget by using a neural-network surrogate tailored to CSL structure. It allows full enumeration on a consumer GPU in under a minute and retrieves approximate top-k sets exactly, demonstrated on a benchmark CSL of >10M compounds with docking scores and RDKit properties, showing strong retrieval accuracy and runtime versus alternatives.", "motivation": "Large make-on-demand CSLs (e.g., Enamine REAL) have tens of billions of compounds, making full screening infeasible. Virtual screening must identify top candidates under fixed computational budgets and often needs to adapt as constraints/objectives change, with little opportunity for amortization. There is a need for fast, accurate top-k retrieval that exploits CSL structure.", "method": "Train a neural network surrogate that leverages the structure of CSLs to predict objectives and constraints. Use this surrogate to perform near-exhaustive search that can enumerate the CSL on a consumer GPU in under a minute, enabling exact retrieval of approximate top-k compounds under given constraints. Build a benchmark CSL containing over 10 million compounds annotated with docking scores for five targets and RDKit physico-chemical properties to quantify ground-truth top-k and compare retrievals.", "result": "APEX achieves consistently strong retrieval accuracy and fast runtime, outperforming alternative methods in identifying near-top-k compounds under various constraints on the benchmark CSL.", "conclusion": "APEX provides an effective, fast, approximate-exhaustive search strategy for enormous CSLs, enabling rapid, accurate retrieval of high-scoring compounds under changing objectives and constraints; the accompanying benchmark enables robust evaluation of virtual screening algorithms for CSLs."}}
{"id": "2510.24432", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24432", "abs": "https://arxiv.org/abs/2510.24432", "authors": ["Seyed Mahdi Basiri Azad", "Joschka Boedecker"], "title": "Fill in the Blanks: Accelerating Q-Learning with a Handful of Demonstrations in Sparse Reward Settings", "comment": null, "summary": "Reinforcement learning (RL) in sparse-reward environments remains a\nsignificant challenge due to the lack of informative feedback. We propose a\nsimple yet effective method that uses a small number of successful\ndemonstrations to initialize the value function of an RL agent. By precomputing\nvalue estimates from offline demonstrations and using them as targets for early\nlearning, our approach provides the agent with a useful prior over promising\nactions. The agent then refines these estimates through standard online\ninteraction. This hybrid offline-to-online paradigm significantly reduces the\nexploration burden and improves sample efficiency in sparse-reward settings.\nExperiments on benchmark tasks demonstrate that our method accelerates\nconvergence and outperforms standard baselines, even with minimal or suboptimal\ndemonstration data.", "AI": {"tldr": "A simple offline-to-online RL method that initializes the value function with a few successful demonstrations and then refines it through online learning, boosting sample efficiency in sparse rewards.", "motivation": "Sparse-reward environments yield slow learning; leveraging a small number of demonstrations can provide a valuable prior to guide exploration and bootstrap value estimates.", "method": "Compute initial value estimates from offline demonstrations and use them as targets to initialize the value function. After this offline bootstrap, continue with standard online RL to refine these estimates through interaction, forming a hybrid offline-to-online learning paradigm.", "result": "Experiments on benchmark tasks show faster convergence and improved sample efficiency, outperforming standard baselines even when demonstrations are minimal or suboptimal.", "conclusion": "A simple offline-to-online strategy can effectively mitigate exploration challenges in sparse-reward RL by providing a strong initial prior from demonstrations and refining it online, with robust performance under limited demonstration data."}}
{"id": "2510.24473", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24473", "abs": "https://arxiv.org/abs/2510.24473", "authors": ["Lucas Buk Cardoso", "Simone Aldrey Angelo", "Yasmin Pacheco Gil Bonilha", "Fernando Maia", "Adeylson Guimar\u00e3es Ribeiro", "Maria Paula Curado", "Gisele Aparecida Fernandes", "Vanderlei Cunha Parro", "Fl\u00e1vio Almeida de Magalh\u00e3es Cipparrone", "Alexandre Dias Porto Chiavegatto Filho", "Tatiana Natasha Toporcov"], "title": "Methodology for Comparing Machine Learning Algorithms for Survival Analysis", "comment": null, "summary": "This study presents a comparative methodological analysis of six machine\nlearning models for survival analysis (MLSA). Using data from nearly 45,000\ncolorectal cancer patients in the Hospital-Based Cancer Registries of S\\~ao\nPaulo, we evaluated Random Survival Forest (RSF), Gradient Boosting for\nSurvival Analysis (GBSA), Survival SVM (SSVM), XGBoost-Cox (XGB-Cox),\nXGBoost-AFT (XGB-AFT), and LightGBM (LGBM), capable of predicting survival\nconsidering censored data. Hyperparameter optimization was performed with\ndifferent samplers, and model performance was assessed using the Concordance\nIndex (C-Index), C-Index IPCW, time-dependent AUC, and Integrated Brier Score\n(IBS). Survival curves produced by the models were compared with predictions\nfrom classification algorithms, and predictor interpretation was conducted\nusing SHAP and permutation importance. XGB-AFT achieved the best performance\n(C-Index = 0.7618; IPCW = 0.7532), followed by GBSA and RSF. The results\nhighlight the potential and applicability of MLSA to improve survival\nprediction and support decision making.", "AI": {"tldr": "Six MLSA models were compared on ~45k colorectal cancer patients; XGB-AFT best with C-index ~0.762; MLSA shows promise for survival prediction.", "motivation": "To systematically compare multiple machine learning survival analysis models using a large censored cancer dataset and assess predictive performance, interpretability, and clinical relevance.", "method": "Dataset of ~45,000 colorectal cancer patients from Hospital-Based Cancer Registries of S\u00e3o Paulo. Compared six models: Random Survival Forest (RSF), Gradient Boosting for Survival Analysis (GBSA), Survival SVM (SSVM), XGBoost-Cox (XGB-Cox), XGBoost-AFT (XGB-AFT), and LightGBM (LGBM). Hyperparameter optimization with different samplers. Evaluated performance using Concordance Index (C-Index), C-Index IPCW, time-dependent AUC, and Integrated Brier Score (IBS). Survival curves from MLSA were compared with those from classification algorithms. Predictor interpretation via SHAP and permutation importance.", "result": "XGB-AFT achieved the best performance (C-Index 0.7618; IPCW 0.7532); GBSA and RSF also performed well. Overall, six MLSA models demonstrated predictive capability on censored survival data, with improvements over some traditional approaches and valuable interpretability analyses.", "conclusion": "MLSAs show potential to improve survival prediction and support decision making in colorectal cancer, highlighting their applicability and interpretability in clinical contexts."}}
{"id": "2510.24500", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24500", "abs": "https://arxiv.org/abs/2510.24500", "authors": ["Yong Huang", "Zhongqi Yang", "Amir Rahmani"], "title": "MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU", "comment": null, "summary": "Sepsis is a leading cause of mortality in intensive care units (ICUs), yet\nexisting research often relies on outdated datasets, non-reproducible\npreprocessing pipelines, and limited coverage of clinical interventions. We\nintroduce MIMIC-Sepsis, a curated cohort and benchmark framework derived from\nthe MIMIC-IV database, designed to support reproducible modeling of sepsis\ntrajectories. Our cohort includes 35,239 ICU patients with time-aligned\nclinical variables and standardized treatment data, including vasopressors,\nfluids, mechanical ventilation and antibiotics. We describe a transparent\npreprocessing pipeline-based on Sepsis-3 criteria, structured imputation\nstrategies, and treatment inclusion-and release it alongside benchmark tasks\nfocused on early mortality prediction, length-of-stay estimation, and shock\nonset classification. Empirical results demonstrate that incorporating\ntreatment variables substantially improves model performance, particularly for\nTransformer-based architectures. MIMIC-Sepsis serves as a robust platform for\nevaluating predictive and sequential models in critical care research.", "AI": {"tldr": "A curated, reproducible sepsis benchmark from MIMIC-IV (MIMIC-Sepsis) with 35k ICU patients, time-aligned clinical and treatment data, a transparent preprocessing pipeline based on Sepsis-3, and benchmark tasks (early mortality, length of stay, shock onset). Including treatments improves predictive performance, especially for Transformer models; aims to standardize evaluation of sepsis trajectory modeling.", "motivation": "Sepsis remains a major ICU mortality driver and current studies rely on outdated data, opaque preprocessing, and limited treatment coverage. A reproducible, treatment-inclusive benchmark is needed to fairly evaluate predictive models of sepsis trajectories.", "method": "Construct a large, standardized sepsis cohort from MIMIC-IV aligned in time with clinical variables and treatments (vasopressors, fluids, ventilation, antibiotics). Apply Sepsis-3 criteria for cohort definition, implement structured imputation and a transparent preprocessing pipeline, and release benchmark tasks for early mortality, length of stay, and shock onset classification.", "result": "Inclusion of treatment variables substantially improves model performance, with Transformer-based architectures gaining notable benefits.", "conclusion": "MIMIC-Sepsis provides a robust, reproducible platform for evaluating predictive and sequential models in critical care, enabling standardized benchmarking and fair comparison across methods."}}
{"id": "2510.24561", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24561", "abs": "https://arxiv.org/abs/2510.24561", "authors": ["Qingyue Zhang", "Chang Chu", "Tianren Peng", "Qi Li", "Xiangyang Luo", "Zhihao Jiang", "Shao-Lun Huang"], "title": "LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via Asymptotic Analysis", "comment": null, "summary": "With the widespread adoption of LLMs, LoRA has become a dominant method for\nPEFT, and its initialization methods have attracted increasing attention.\nHowever, existing methods have notable limitations: many methods do not\nincorporate target-domain data, while gradient-based methods exploit data only\nat a shallow level by relying on one-step gradient decomposition, which remains\nunsatisfactory due to the weak empirical performance of the one-step\nfine-tuning model that serves as their basis, as well as the fact that these\nmethods either lack a rigorous theoretical foundation or depend heavily on\nrestrictive isotropic assumptions. In this paper, we establish a theoretical\nframework for data-aware LoRA initialization based on asymptotic analysis.\nStarting from a general optimization objective that minimizes the expectation\nof the parameter discrepancy between the fine-tuned and target models, we\nderive an optimization problem with two components: a bias term, which is\nrelated to the parameter distance between the fine-tuned and target models, and\nis approximated using a Fisher-gradient formulation to preserve anisotropy; and\na variance term, which accounts for the uncertainty introduced by sampling\nstochasticity through the Fisher information. By solving this problem, we\nobtain an optimal initialization strategy for LoRA. Building on this\ntheoretical framework, we develop an efficient algorithm, LoRA-DA, which\nestimates the terms in the optimization problem from a small set of target\ndomain samples and obtains the optimal LoRA initialization. Empirical results\nacross multiple benchmarks demonstrate that LoRA-DA consistently improves final\naccuracy over existing initialization methods. Additional studies show faster,\nmore stable convergence, robustness across ranks, and only a small\ninitialization overhead for LoRA-DA. The source code will be released upon\npublication.", "AI": {"tldr": "A theoretically grounded, data-aware initialization for LoRA (LoRA-DA) that uses a Fisher-based bias-variance decomposition to optimize LoRA initialization from a small target-domain sample set, improving accuracy and convergence over existing methods.", "motivation": "Existing LoRA initializations either ignore target-domain data, rely on shallow one-step gradient updates, or lack a solid theoretical foundation (often assuming isotropy). A data-aware, rigorously grounded initialization is needed to improve performance and stability across domains and ranks.", "method": "Develop an asymptotic optimization framework for initializing LoRA by minimizing the expected parameter discrepancy between the fine-tuned model and the target model, decomposed into a bias term (parameter distance approximated with a Fisher-gradient to preserve anisotropy) and a variance term (uncertainty from sampling via Fisher information). Solve for the optimal initialization and implement LoRA-DA, which estimates the two terms from a small set of target-domain samples to compute the initialization.", "result": "Empirical evaluation across multiple benchmarks shows that LoRA-DA consistently improves final accuracy over existing initialization methods, with faster and more stable convergence and robustness to rank variations, while adding only a modest initialization overhead. Source code will be released.", "conclusion": "LoRA-DA provides a principled, data-aware initialization for LoRA that yields consistent accuracy gains and improved training efficiency, with a solid theoretical basis and practical robustness."}}
{"id": "2510.24574", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24574", "abs": "https://arxiv.org/abs/2510.24574", "authors": ["Hao Wang", "Licheng Pan", "Yuan Lu", "Zhixuan Chu", "Xiaoxi Li", "Shuting He", "Zhichao Chen", "Haoxuan Li", "Qingsong Wen", "Zhouchen Lin"], "title": "DistDF: Time-Series Forecasting Needs Joint-Distribution Wasserstein Alignment", "comment": null, "summary": "Training time-series forecast models requires aligning the conditional\ndistribution of model forecasts with that of the label sequence. The standard\ndirect forecast (DF) approach resorts to minimize the conditional negative\nlog-likelihood of the label sequence, typically estimated using the mean\nsquared error. However, this estimation proves to be biased in the presence of\nlabel autocorrelation. In this paper, we propose DistDF, which achieves\nalignment by alternatively minimizing a discrepancy between the conditional\nforecast and label distributions. Because conditional discrepancies are\ndifficult to estimate from finite time-series observations, we introduce a\nnewly proposed joint-distribution Wasserstein discrepancy for time-series\nforecasting, which provably upper bounds the conditional discrepancy of\ninterest. This discrepancy admits tractable, differentiable estimation from\nempirical samples and integrates seamlessly with gradient-based training.\nExtensive experiments show that DistDF improves the performance diverse\nforecast models and achieves the state-of-the-art forecasting performance. Code\nis available at https://anonymous.4open.science/r/DistDF-F66B.", "AI": {"tldr": "DistDF introduces a joint-distribution Wasserstein discrepancy to align the conditional forecast and label distributions in time-series forecasting, addressing bias from label autocorrelation; it offers tractable, differentiable estimation and yields state-of-the-art results across models.", "motivation": "Direct forecast using conditional likelihood (often via MSE) is biased when label sequences are autocorrelated; a reliable measure to align conditional forecast distributions with label distributions is needed.", "method": "Propose DistDF that minimizes a discrepancy between conditional forecast and label distributions. Introduce a joint-distribution Wasserstein discrepancy for time-series forecasting that upper bounds the conditioned discrepancy, is tractable to estimate from empirical samples, differentiable, and integrates with gradient-based training.", "result": "Empirical studies show DistDF improves performance across diverse forecast models and achieves state-of-the-art forecasting performance.", "conclusion": "DistDF provides an effective and scalable way to align conditional distributions in time-series forecasting, mitigating bias from autocorrelation and delivering strong empirical performance; code is released."}}
{"id": "2510.24577", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24577", "abs": "https://arxiv.org/abs/2510.24577", "authors": ["He Yang", "Fei Ren", "Hai-Sui Yu", "Xiaohui Chen", "Pei-Zhi Zhuang"], "title": "Physics-Informed Extreme Learning Machine (PIELM): Opportunities and Challenges", "comment": null, "summary": "We are very delighted to see the fast development of physics-informed extreme\nlearning machine (PIELM) in recent years for higher computation efficiency and\naccuracy in physics-informed machine learning. As a summary or review on PIELM\nis currently not available, we would like to take this opportunity to show our\nperspective and experience for this promising research direction. We can see\nmany efforts are made to solve PDEs with sharp gradients, nonlinearities,\nhigh-frequency behavior, hard constraints, uncertainty, multiphysics coupling.\nDespite the success, many urgent challenges remain to be tackled, which also\nprovides us opportunities to develop more robust, interpretable, and\ngeneralizable PIELM frameworks with applications in science and engineering.", "AI": {"tldr": "PIELM is a rapidly developing area that combines physics-informed models with extreme learning machines. This piece offers a perspective/review highlighting recent developments, applications to PDEs with sharp gradients, nonlinearities, and high-frequency behavior, and discusses key challenges and opportunities for robustness, interpretability, and generalization.", "motivation": "There is a need for fast, accurate, and trustworthy physics-informed machine learning tools that can handle complex PDE features (sharp gradients, nonlinearities, high-frequency dynamics) and support robust, interpretable, and generalizable frameworks for science and engineering.", "method": "A perspective/review synthesizing recent work on physics-informed extreme learning machines (PIELM). It discusses methods and experiences in solving PDEs with challenging attributes and provides insights into challenges and future directions.", "result": "Identifies urgent challenges and opportunities in PIELM, offering a structured outlook and recommendations to improve robustness, interpretability, and generalization across applications in science and engineering.", "conclusion": "PIELM shows promise for efficient physics-informed computation, but substantial work remains to address robustness, interpretability, and generalization; future research should target these aspects across multiphysics and uncertainty settings."}}
{"id": "2510.24598", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.24598", "abs": "https://arxiv.org/abs/2510.24598", "authors": ["Sathwik Narkedimilli", "N V Saran Kumar", "Aswath Babu H", "Manjunath K Vanahalli", "Manish M", "Vinija Jain", "Aman Chadha"], "title": "A Novel XAI-Enhanced Quantum Adversarial Networks for Velocity Dispersion Modeling in MaNGA Galaxies", "comment": null, "summary": "Current quantum machine learning approaches often face challenges balancing\npredictive accuracy, robustness, and interpretability. To address this, we\npropose a novel quantum adversarial framework that integrates a hybrid quantum\nneural network (QNN) with classical deep learning layers, guided by an\nevaluator model with LIME-based interpretability, and extended through quantum\nGAN and self-supervised variants. In the proposed model, an adversarial\nevaluator concurrently guides the QNN by computing feedback loss, thereby\noptimizing both prediction accuracy and model explainability. Empirical\nevaluations show that the Vanilla model achieves RMSE = 0.27, MSE = 0.071, MAE\n= 0.21, and R^2 = 0.59, delivering the most consistent performance across\nregression metrics compared to adversarial counterparts. These results\ndemonstrate the potential of combining quantum-inspired methods with classical\narchitectures to develop lightweight, high-performance, and interpretable\npredictive models, advancing the applicability of QML beyond current\nlimitations.", "AI": {"tldr": "A hybrid quantum-classical adversarial framework for regression integrating a quantum neural network with classical layers, an LIME-based evaluator for interpretability, and extensions via quantum GAN and self-supervised variants; shows competitive regression metrics with a Vanilla model.", "motivation": "Address the trade-offs among predictive accuracy, robustness, and interpretability in quantum machine learning; advance QML toward lighter, more interpretable models.", "method": "Hybrid quantum neural network (QNN) with classical layers; adversarial evaluator providing feedback loss to optimize both accuracy and explainability; LIME-based interpretability; extended with quantum GAN and self-supervised variants; evaluated on regression tasks.", "result": "Vanilla model achieves RMSE 0.27, MSE 0.071, MAE 0.21, R^2 0.59; demonstrates the most consistent performance across regression metrics compared to adversarial counterparts.", "conclusion": "Combining quantum-inspired methods with classical architectures can yield lightweight, high-performance, and interpretable predictive models, expanding the applicability of quantum-inspired machine learning."}}
{"id": "2510.24614", "categories": ["cs.LG", "cs.CE", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24614", "abs": "https://arxiv.org/abs/2510.24614", "authors": ["James Josep Perry", "Pablo Garcia-Conde Ortiz", "George Konstantinou", "Cornelie Vergouwen", "Edlyn Santha Kumaran", "Morteza Moradi"], "title": "Semi-supervised and unsupervised learning for health indicator extraction from guided waves in aerospace composite structures", "comment": null, "summary": "Health indicators (HIs) are central to diagnosing and prognosing the\ncondition of aerospace composite structures, enabling efficient maintenance and\noperational safety. However, extracting reliable HIs remains challenging due to\nvariability in material properties, stochastic damage evolution, and diverse\ndamage modes. Manufacturing defects (e.g., disbonds) and in-service incidents\n(e.g., bird strikes) further complicate this process. This study presents a\ncomprehensive data-driven framework that learns HIs via two learning approaches\nintegrated with multi-domain signal processing. Because ground-truth HIs are\nunavailable, a semi-supervised and an unsupervised approach are proposed: (i) a\ndiversity deep semi-supervised anomaly detection (Diversity-DeepSAD) approach\naugmented with continuous auxiliary labels used as hypothetical damage proxies,\nwhich overcomes the limitation of prior binary labels that only distinguish\nhealthy and failed states while neglecting intermediate degradation, and (ii) a\ndegradation-trend-constrained variational autoencoder (DTC-VAE), in which the\nmonotonicity criterion is embedded via an explicit trend constraint. Guided\nwaves with multiple excitation frequencies are used to monitor single-stiffener\ncomposite structures under fatigue loading. Time, frequency, and time-frequency\nrepresentations are explored, and per-frequency HIs are fused via unsupervised\nensemble learning to mitigate frequency dependence and reduce variance. Using\nfast Fourier transform features, the augmented Diversity-DeepSAD model achieved\n81.6% performance, while DTC-VAE delivered the most consistent HIs with 92.3%\nperformance, outperforming existing baselines.", "AI": {"tldr": "Dual learning framework for health indicators in aerospace composites using semi-supervised Diversity-DeepSAD with continuous auxiliary labels and a degradation-trend-constrained VAE (DTC-VAE), integrated with multi-domain guided-wave data. Per-frequency HIs fused via unsupervised ensemble; achieves 81.6% (Diversity-DeepSAD) and 92.3% (DTC-VAE), outperforming baselines.", "motivation": "Ground-truth health indicators are unavailable; high variability in material properties, stochastic damage evolution, and multiple damage modes challenge reliable HI extraction. Manufacturing defects and in-service incidents further complicate monitoring. A data-driven, weakly supervised framework leveraging multi-frequency signals can robustly infer degradation trajectories.", "method": "Two learning approaches: (i) Diversity-DeepSAD with continuous auxiliary labels as hypothetical damage proxies to capture intermediate degradation beyond binary healthy/faulty labeling; (ii) DTC-VAE with explicit monotonic degradation trend constraint. Guided waves at multiple excitation frequencies monitor single-stiffener composites under fatigue. Explores time, frequency, and time-frequency representations; per-frequency HIs fused via unsupervised ensemble learning. Features derived from fast Fourier transforms.", "result": "Empirical performance: Diversity-DeepSAD achieves 81.6%; DTC-VAE achieves 92.3% and provides more consistent HIs. Both approaches outperform existing baselines.", "conclusion": "The integrated framework yields more stable and interpretable health indicators under fatigue for aerospace composites, addressing intermediate degradation and frequency dependence. The combination of semi-supervised and unsupervised methods with multi-domain signal processing enhances robustness and reduces HI variance."}}
{"id": "2510.24633", "categories": ["cs.LG", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.24633", "abs": "https://arxiv.org/abs/2510.24633", "authors": ["Mingyue Liu", "Andrew Cropper"], "title": "Symbolic Snapshot Ensembles", "comment": null, "summary": "Inductive logic programming (ILP) is a form of logical machine learning. Most\nILP algorithms learn a single hypothesis from a single training run. Ensemble\nmethods train an ILP algorithm multiple times to learn multiple hypotheses. In\nthis paper, we train an ILP algorithm only once and save intermediate\nhypotheses. We then combine the hypotheses using a minimum description length\nweighting scheme. Our experiments on multiple benchmarks, including game\nplaying and visual reasoning, show that our approach improves predictive\naccuracy by 4% with less than 1% computational overhead.", "AI": {"tldr": "One-shot ILP with saved intermediate hypotheses and MDL-weighted ensemble improves accuracy by ~4% at <1% overhead.", "motivation": "Reduce the computational cost of ensemble ILP methods that train multiple times by reusing hypotheses from a single run and weighting them using MDL.", "method": "Train an ILP algorithm once, save intermediate hypotheses encountered during the search, and form an ensemble from these hypotheses. Use a minimum description length (MDL) based weighting to combine their predictions.", "result": "On benchmarks including game playing and visual reasoning, predictive accuracy improved by about 4% with less than 1% additional computational overhead.", "conclusion": "A single-run ILP with an MDL-weighted ensemble can achieve competitive accuracy with very low overhead, offering a practical efficiency improvement for ILP."}}
{"id": "2510.24639", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24639", "abs": "https://arxiv.org/abs/2510.24639", "authors": ["Pedro P. Sanchez", "Damian Machlanski", "Steven McDonagh", "Sotirios A. Tsaftaris"], "title": "Causal Ordering for Structure Learning From Time Series", "comment": "32 pages", "summary": "Predicting causal structure from time series data is crucial for\nunderstanding complex phenomena in physiology, brain connectivity, climate\ndynamics, and socio-economic behaviour. Causal discovery in time series is\nhindered by the combinatorial complexity of identifying true causal\nrelationships, especially as the number of variables and time points grow. A\ncommon approach to simplify the task is the so-called ordering-based methods.\nTraditional ordering methods inherently limit the representational capacity of\nthe resulting model. In this work, we fix this issue by leveraging multiple\nvalid causal orderings, instead of a single one as standard practice. We\npropose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based\ncausal discovery for temporal data. By integrating multiple orderings, DOTS\neffectively recovers the transitive closure of the underlying directed acyclic\ngraph, mitigating spurious artifacts inherent in single-ordering approaches. We\nformalise the problem under standard assumptions such as stationarity and the\nadditive noise model, and leverage score matching with diffusion processes to\nenable efficient Hessian estimation. Extensive experiments validate the\napproach. Empirical evaluations on synthetic and real-world datasets\ndemonstrate that DOTS outperforms state-of-the-art baselines, offering a\nscalable and robust approach to temporal causal discovery. On synthetic\nbenchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS\nimproves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the\nCausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the\nbest on individual datasets, DOTS attains the highest average summary-graph\n$F1$ while halving runtime relative to graph-optimisation methods. These\nresults establish DOTS as a scalable and accurate solution for temporal causal\ndiscovery.", "AI": {"tldr": "DOTS uses diffusion-based causal discovery across multiple valid temporal orderings to recover the transitive closure of the causal graph in time-series data, improving accuracy and scalability over single-ordering methods.", "motivation": "Causal discovery in time series is combinatorially hard and single-ordering methods limit the model's representational capacity, often introducing spurious artifacts. Using multiple valid orderings aims to more faithfully capture causal structure and improve robustness.", "method": "DOTS (Diffusion Ordered Temporal Structure) integrates diffusion-based causal discovery with multiple temporal orderings. It leverages score matching with diffusion processes to enable efficient Hessian estimation under standard assumptions (stationarity and additive noise). The approach recovers the transitive closure of the underlying DAG by aggregating information from multiple orderings, rather than relying on a single ordering.", "result": "Empirical evaluation shows strong gains: on synthetic benchmarks (d=3\u20136, T=200\u20135,000), mean window-graph F1 improves from 0.63 (best baseline) to 0.81. On the real-world CausalTime benchmark (d=20\u201336), DOTS attains the highest average summary-graph F1, while halving runtime compared with graph-optimization baselines.", "conclusion": "DOTS provides a scalable and accurate solution for temporal causal discovery by leveraging multiple orderings to recover the transitive closure, outperforming state-of-the-art baselines on both synthetic and real-world datasets."}}
{"id": "2510.24643", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24643", "abs": "https://arxiv.org/abs/2510.24643", "authors": ["Yujun Kim", "Chaewon Moon", "Chulhee Yun"], "title": "The Cost of Robustness: Tighter Bounds on Parameter Complexity for Robust Memorization in ReLU Nets", "comment": "Accepted to NeurIPS 2025, 72 pages, 8 figures", "summary": "We study the parameter complexity of robust memorization for $\\mathrm{ReLU}$\nnetworks: the number of parameters required to interpolate any given dataset\nwith $\\epsilon$-separation between differently labeled points, while ensuring\npredictions remain consistent within a $\\mu$-ball around each training sample.\nWe establish upper and lower bounds on the parameter count as a function of the\nrobustness ratio $\\rho = \\mu / \\epsilon$. Unlike prior work, we provide a\nfine-grained analysis across the entire range $\\rho \\in (0,1)$ and obtain\ntighter upper and lower bounds that improve upon existing results. Our findings\nreveal that the parameter complexity of robust memorization matches that of\nnon-robust memorization when $\\rho$ is small, but grows with increasing $\\rho$.", "AI": {"tldr": "Tight parameter-count bounds for robust memorization in ReLU nets across rho in (0,1); robustness increases parameter complexity; matches non-robust at small rho.", "motivation": "Understand how many parameters are necessary to interpolate data under mu-robustness with epsilon separation; fill gap with fine-grained rho analysis.", "method": "Derives upper and lower bounds on parameter count as a function of rho; analyzes the entire range (0,1); provides tighter bounds than prior work.", "result": "Shows parameter complexity for robust memorization matches non-robust when rho is small, and grows with rho; tighter bounds compared to previous results.", "conclusion": "Robustness incurs parameter cost; trade-off between robustness and model size; results illuminate the parameter-efficiency landscape across the rho spectrum."}}
{"id": "2510.24670", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.24670", "abs": "https://arxiv.org/abs/2510.24670", "authors": ["Genesis Research Team", "Alejandro Dobles", "Nina Jovic", "Kenneth Leidal", "Pranav Murugan", "David C. Williams", "Drausin Wulsin", "Nate Gruver", "Christina X. Ji", "Korrawat Pruegsanusak", "Gianluca Scarpellini", "Ansh Sharma", "Wojciech Swiderski", "Andrea Bootsma", "Richard Strong Bowen", "Charlotte Chen", "Jamin Chen", "Marc Andr\u00e9 D\u00e4mgen", "Roy Tal Dew", "Benjamin DiFrancesco", "J. D. Fishman", "Alla Ivanova", "Zach Kagin", "David Li-Bland", "Zuli Liu", "Igor Morozov", "Jeffrey Ouyang-Zhang", "Frank C. Pickard IV", "Kushal S. Shah", "Ben Shor", "Gabriel Monteiro da Silva", "Maxx Tessmer", "Carl Tilbury", "Cyr Vetcher", "Daniel Zeng", "Maruan Al-Shedivat", "Aleksandra Faust", "Evan N. Feinberg", "Michael V. LeVine", "Matteus Pan"], "title": "Pearl: A Foundation Model for Placing Every Atom in the Right Location", "comment": null, "summary": "Accurately predicting the three-dimensional structures of protein-ligand\ncomplexes remains a fundamental challenge in computational drug discovery that\nlimits the pace and success of therapeutic design. Deep learning methods have\nrecently shown strong potential as structural prediction tools, achieving\npromising accuracy across diverse biomolecular systems. However, their\nperformance and utility are constrained by scarce experimental data,\ninefficient architectures, physically invalid poses, and the limited ability to\nexploit auxiliary information available at inference. To address these issues,\nwe introduce Pearl (Placing Every Atom in the Right Location), a foundation\nmodel for protein-ligand cofolding at scale. Pearl addresses these challenges\nwith three key innovations: (1) training recipes that include large-scale\nsynthetic data to overcome data scarcity; (2) architectures that incorporate an\nSO(3)-equivariant diffusion module to inherently respect 3D rotational\nsymmetries, improving generalization and sample efficiency, and (3)\ncontrollable inference, including a generalized multi-chain templating system\nsupporting both protein and non-polymeric components as well as dual\nunconditional/conditional modes. Pearl establishes a new state-of-the-art\nperformance in protein-ligand cofolding. On the key metric of generating\naccurate (RMSD < 2 \\r{A}) and physically valid poses, Pearl surpasses AlphaFold\n3 and other open source baselines on the public Runs N' Poses and PoseBusters\nbenchmarks, delivering 14.5% and 14.2% improvements, respectively, over the\nnext best model. In the pocket-conditional cofolding regime, Pearl delivers\n$3.6\\times$ improvement on a proprietary set of challenging, real-world drug\ntargets at the more rigorous RMSD < 1 \\r{A} threshold. Finally, we demonstrate\nthat model performance correlates directly with synthetic dataset size used in\ntraining.", "AI": {"tldr": "Pearl is a foundation model for protein\u2013ligand cofolding that combines large-scale synthetic data, an SO(3)-equivariant diffusion architecture, and controllable inference with multi-chain templating. It achieves state-of-the-art pose accuracy and validity, outperforming AlphaFold 3 and baselines on key benchmarks, with performance scaling with training data size.", "motivation": "To overcome data scarcity, enforce physical plausibility and symmetry in 3D structure prediction, and enable flexible inference with multiple input types and conditional modes for protein and non-polymeric components.", "method": "Three innovations: (1) large-scale synthetic data to mitigate data scarcity; (2) an SO(3)-equivariant diffusion module that respects 3D rotational symmetry for better generalization and sample efficiency; (3) a controllable inference framework with a generalized multi-chain templating system supporting both protein and non-polymeric components and dual unconditional/conditional modes.", "result": "Pearl achieves state-of-the-art performance in protein\u2013ligand cofolding. On RMSD<2 \u00c5 and physically valid poses, it surpasses AlphaFold 3 and other baselines on Runs N' Poses and PoseBusters benchmarks by about 14.5% and 14.2%, respectively. In pocket-conditional cofolding on a real-world proprietary set, it yields 3.6\u00d7 improvement at RMSD<1 \u00c5. Performance scales with synthetic data size used for training.", "conclusion": "Three-tier approach\u2014data scale, symmetry-aware diffusion architectures, and controllable inference\u2014drives superior performance in protein\u2013ligand cofolding and demonstrates that model capability correlates with synthetic data volume; promise for broader applications in structure-based drug discovery, with caveats regarding reliance on synthetic data and computational cost."}}
{"id": "2510.24672", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.24672", "abs": "https://arxiv.org/abs/2510.24672", "authors": ["Burak Var\u0131c\u0131", "Che-Ping Tsai", "Ritabrata Ray", "Nicholas M. Boffi", "Pradeep Ravikumar"], "title": "Eigenfunction Extraction for Ordered Representation Learning", "comment": null, "summary": "Recent advances in representation learning reveal that widely used\nobjectives, such as contrastive and non-contrastive, implicitly perform\nspectral decomposition of a contextual kernel, induced by the relationship\nbetween inputs and their contexts. Yet, these methods recover only the linear\nspan of top eigenfunctions of the kernel, whereas exact spectral decomposition\nis essential for understanding feature ordering and importance. In this work,\nwe propose a general framework to extract ordered and identifiable\neigenfunctions, based on modular building blocks designed to satisfy key\ndesiderata, including compatibility with the contextual kernel and scalability\nto modern settings. We then show how two main methodological paradigms,\nlow-rank approximation and Rayleigh quotient optimization, align with this\nframework for eigenfunction extraction. Finally, we validate our approach on\nsynthetic kernels and demonstrate on real-world image datasets that the\nrecovered eigenvalues act as effective importance scores for feature selection,\nenabling principled efficiency-accuracy tradeoffs via adaptive-dimensional\nrepresentations.", "AI": {"tldr": "Proposes a modular framework to extract ordered, identifiable eigenfunctions of contextual kernels in representation learning, addressing limitations of recovering only top linear eigenfunctions; uses low-rank and Rayleigh quotient approaches; eigenvalues provide feature-importance scores for adaptive dimensions in image tasks.", "motivation": "There is a need for exact spectral decomposition to understand feature ordering and importance in representation learning. Current contrastive/non-contrastive methods only recover the linear span of top eigenfunctions of a contextual kernel, which limits interpretability and control over feature dimensionality. A scalable, kernel-compatible method for ordered, identifiable eigenfunctions would improve feature selection and efficiency.", "method": "Introduce modular building blocks that ensure compatibility with the contextual kernel and scalability. Show alignment with two main paradigms for eigenfunction extraction: (i) low-rank approximation and (ii) Rayleigh quotient optimization, within the proposed framework.", "result": "Validation on synthetic kernels and real-world image datasets demonstrates that the recovered eigenvalues act as meaningful feature importance scores, enabling principled efficiency-accuracy tradeoffs via adaptive-dimensional representations.", "conclusion": "The framework provides a principled, scalable approach to extract ordered, identifiable eigenfunctions from contextual kernels, enabling better feature selection and interpretation in representation learning."}}
{"id": "2510.24674", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.24674", "abs": "https://arxiv.org/abs/2510.24674", "authors": ["Bram De Cooman", "Johan Suykens"], "title": "Learning to Drive Safely with Hybrid Options", "comment": null, "summary": "Out of the many deep reinforcement learning approaches for autonomous\ndriving, only few make use of the options (or skills) framework. That is\nsurprising, as this framework is naturally suited for hierarchical control\napplications in general, and autonomous driving tasks in specific. Therefore,\nin this work the options framework is applied and tailored to autonomous\ndriving tasks on highways. More specifically, we define dedicated options for\nlongitudinal and lateral manoeuvres with embedded safety and comfort\nconstraints. This way, prior domain knowledge can be incorporated into the\nlearning process and the learned driving behaviour can be constrained more\neasily. We propose several setups for hierarchical control with options and\nderive practical algorithms following state-of-the-art reinforcement learning\ntechniques. By separately selecting actions for longitudinal and lateral\ncontrol, the introduced policies over combined and hybrid options obtain the\nsame expressiveness and flexibility that human drivers have, while being easier\nto interpret than classical policies over continuous actions. Of all the\ninvestigated approaches, these flexible policies over hybrid options perform\nthe best under varying traffic conditions, outperforming the baseline policies\nover actions.", "AI": {"tldr": "Hierarchical RL for highway driving using the options framework with dedicated longitudinal/lateral maneuvers and safety/comfort constraints; hybrid options outperform action-based baselines and offer interpretability.", "motivation": "Options (skills) offer hierarchical control benefits that are underutilized in autonomous driving. Incorporating domain knowledge and safety/comfort constraints can guide learning, improve safety, and enhance interpretability of policies amid varying traffic.", "method": "Define dedicated options for longitudinal and lateral maneuvers with embedded safety/comfort constraints; explore several hierarchical control setups using the options framework; derive practical RL algorithms with state-of-the-art techniques; learn policies over separate longitudinal and lateral controls, yielding combined/hybrid options.", "result": "Policies over hybrid/combined options outperform baseline policies that operate over primitive actions, especially under varying traffic conditions; hybrid options provide the best performance and interpretability relative to action-based baselines.", "conclusion": "Applying the options framework to autonomous highway driving is effective, enabling incorporation of domain knowledge and constraints, improving performance and interpretability over traditional action-space policies."}}
{"id": "2510.24700", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.24700", "abs": "https://arxiv.org/abs/2510.24700", "authors": ["Di Wu", "Chengshuai Shi", "Jing Yang", "Cong Shen"], "title": "Greedy Sampling Is Provably Efficient for RLHF", "comment": "NeurIPS 2025", "summary": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a key\ntechnique for post-training large language models. Despite its empirical\nsuccess, the theoretical understanding of RLHF is still limited, as learning\nthe KL-regularized target with only preference feedback poses additional\nchallenges compared with canonical RL. Existing works mostly study the\nreward-based Bradley-Terry (BT) preference model, and extend classical designs\nutilizing optimism or pessimism. This work, instead, considers the general\npreference model (whose practical relevance has been observed recently) and\nobtains performance guarantees with major, order-wise improvements over\nexisting ones. Surprisingly, these results are derived from algorithms that\ndirectly use the empirical estimates (i.e., greedy sampling), as opposed to\nconstructing optimistic or pessimistic estimates in previous works. This\ninsight has a deep root in the unique structural property of the optimal policy\nclass under the KL-regularized target, and we further specialize it to the BT\nmodel, highlighting the surprising sufficiency of greedy sampling in RLHF.", "AI": {"tldr": "Greedy sampling (empirical estimates) suffices for KL-regularized RLHF with general preference models, yielding strong, order-wise guarantees and improving over BT-based reward designs.", "motivation": "RLHF is central to post-training LLMs, but theory lags, especially for KL-regularized targets with only preference feedback; existing work focuses on reward-based BT models and optimistic/pessimistic analyses.", "method": "The authors analyze a general preference model under KL-regularized RLHF, prove performance guarantees using greedy empirical estimates rather than optimistic/pessimistic constructions, and identify a unique structural property of the optimal policy class; they then specialize results to the Bradley\u2013Terrey (BT) model.", "result": "They obtain major, order-wise improvements over existing guarantees; show that greedy sampling is sufficient in RLHF for the general model, and provide BT-specific instantiations.", "conclusion": "Greedy sampling suffices for RLHF under KL regularization due to intrinsic structure of the optimal policy class; this advances theoretical understanding and suggests simpler algorithmic approaches for RLHF."}}
