{"id": "2510.19962", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.19962", "abs": "https://arxiv.org/abs/2510.19962", "authors": ["Chen-Lung Lu", "Honglu He", "Agung Julius", "John T. Wen"], "title": "Configuration-Dependent Robot Kinematics Model and Calibration", "comment": null, "summary": "Accurate robot kinematics is essential for precise tool placement in\narticulated robots, but non-geometric factors can introduce\nconfiguration-dependent model discrepancies. This paper presents a\nconfiguration-dependent kinematic calibration framework for improving accuracy\nacross the entire workspace. Local Product-of-Exponential (POE) models,\nselected for their parameterization continuity, are identified at multiple\nconfigurations and interpolated into a global model. Inspired by joint gravity\nload expressions, we employ Fourier basis function interpolation parameterized\nby the shoulder and elbow joint angles, achieving accuracy comparable to neural\nnetwork and autoencoder methods but with substantially higher training\nefficiency. Validation on two 6-DoF industrial robots shows that the proposed\napproach reduces the maximum positioning error by over 50%, meeting the\nsub-millimeter accuracy required for cold spray manufacturing. Robots with\nlarger configuration-dependent discrepancies benefit even more. A dual-robot\ncollaborative task demonstrates the framework's practical applicability and\nrepeatability.", "AI": {"tldr": "Configuration-dependent calibration improves robot kinematics across the workspace by interpolating local POE models with Fourier basis functions tied to shoulder/elbow angles, delivering training-efficient, sub-millimeter accuracy.", "motivation": "Non-geometric, configuration-dependent discrepancies degrade kinematic precision; a global, continuous model is needed to maintain accuracy across the full workspace.", "method": "Identify local POE models at multiple configurations and interpolate them into a global model using Fourier basis functions parameterized by shoulder and elbow angles; inspired by gravity-load expressions to ensure continuity; validated on two 6-DoF industrial robots; training efficiency surpasses neural-network/autoencoder approaches.", "result": "Maximum positioning error is reduced by more than 50%, achieving sub-millimeter accuracy; larger gains on robots with greater configuration-dependent discrepancies; a dual-robot collaborative task demonstrates practical applicability and repeatability.", "conclusion": "The framework provides a practical, repeatable, and training-efficient solution for configuration-dependent kinematic calibration, suitable for high-precision tasks in manufacturing (e.g., cold spray) and across varying robot configurations."}}
{"id": "2510.19974", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.19974", "abs": "https://arxiv.org/abs/2510.19974", "authors": ["Hien Bui", "Yufeiyang Gao", "Haoran Yang", "Eric Cui", "Siddhant Mody", "Brian Acosta", "Thomas Stephen Felix", "Bibit Bianchini", "Michael Posa"], "title": "Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC", "comment": "Hien Bui, Yufeiyang Gao, and Haoran Yang contributed equally to this\n  work", "summary": "Non-prehensile manipulation of diverse objects remains a core challenge in\nrobotics, driven by unknown physical properties and the complexity of\ncontact-rich interactions. Recent advances in contact-implicit model predictive\ncontrol (CI-MPC), with contact reasoning embedded directly in the trajectory\noptimization, have shown promise in tackling the task efficiently and robustly,\nyet demonstrations have been limited to narrowly curated examples. In this\nwork, we showcase the broader capabilities of CI-MPC through precise planar\npushing tasks over a wide range of object geometries, including multi-object\ndomains. These scenarios demand reasoning over numerous inter-object and\nobject-environment contacts to strategically manipulate and de-clutter the\nenvironment, challenges that were intractable for prior CI-MPC methods. To\nachieve this, we introduce Consensus Complementarity Control Plus (C3+), an\nenhanced CI-MPC algorithm integrated into a complete pipeline spanning object\nscanning, mesh reconstruction, and hardware execution. Compared to its\npredecessor C3, C3+ achieves substantially faster solve times, enabling\nreal-time performance even in multi-object pushing tasks. On hardware, our\nsystem achieves overall 98% success rate across 33 objects, reaching pose goals\nwithin tight tolerances. The average time-to-goal is approximately 0.5, 1.6,\n3.2, and 5.3 minutes for 1-, 2-, 3-, and 4-object tasks, respectively. Project\npage: https://dairlab.github.io/push-anything.", "AI": {"tldr": "CI-MPC with C3+ enables real-time, multi-object planar pushing and de-cluttering with high success across 33 objects, leveraging scanning, mesh reconstruction, and hardware execution; faster solves than C3 enable practical real-time performance (0.5\u20135.3 minutes to goal depending on object count).", "motivation": "Non-prehensile manipulation with unknown object properties and dense contact interactions remains hard; existing CI-MPC methods were limited to curated scenarios. This work aims to generalize CI-MPC to diverse geometries and multi-object scenarios to enable robust, real-time planning and execution.", "method": "Introduce Consensus Complementarity Control Plus (C3+)\u2014an enhanced CI-MPC algorithm integrated into a full pipeline including object scanning, mesh reconstruction, and hardware execution. Improves solve speed over the predecessor C3 to enable real-time performance, including multi-object pushing tasks.", "result": "Hardware experiments show a 98% success rate across 33 objects, achieving pose goals within tight tolerances. Time-to-goal averages roughly 0.5, 1.6, 3.2, and 5.3 minutes for 1, 2, 3, and 4-object tasks respectively.", "conclusion": "C3+ extends CI-MPC applicability to diverse planar pushing tasks and cluttered environments, enabling efficient, robust manipulation across multiple objects in real time."}}
{"id": "2510.20008", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20008", "abs": "https://arxiv.org/abs/2510.20008", "authors": ["Swati Dantu", "Robert P\u011bni\u010dka", "Martin Saska"], "title": "Simultaneous learning of state-to-state minimum-time planning and control", "comment": null, "summary": "This paper tackles the challenge of learning a generalizable minimum-time\nflight policy for UAVs, capable of navigating between arbitrary start and goal\nstates while balancing agile flight and stable hovering. Traditional\napproaches, particularly in autonomous drone racing, achieve impressive speeds\nand agility but are constrained to predefined track layouts, limiting\nreal-world applicability. To address this, we propose a reinforcement\nlearning-based framework that simultaneously learns state-to-state minimum-time\nplanning and control and generalizes to arbitrary state-to-state flights. Our\napproach leverages Point Mass Model (PMM) trajectories as proxy rewards to\napproximate the true optimal flight objective and employs curriculum learning\nto scale the training process efficiently and to achieve generalization. We\nvalidate our method through simulation experiments, comparing it against\nNonlinear Model Predictive Control (NMPC) tracking PMM-generated trajectories\nand conducting ablation studies to assess the impact of curriculum learning.\nFinally, real-world experiments confirm the robustness of our learned policy in\noutdoor environments, demonstrating its ability to generalize and operate on a\nsmall ARM-based single-board computer.", "AI": {"tldr": "RL-based generalizable minimum-time UAV policy for arbitrary start/goal flights, using PMM trajectories as proxy rewards and curriculum learning; validated in simulation and real-world on a small ARM SBC.", "motivation": "Traditional fast drone racing methods excel on predefined tracks but fail to generalize to arbitrary environments; there is a need for a learning framework that can plan and control for minimum time between arbitrary states while remaining robust to real-world constraints.", "method": "A reinforcement learning framework that jointly learns state-to-state minimum-time planning and control. It uses Point Mass Model (PMM) trajectories as proxy rewards to approximate the true optimal objective and employs curriculum learning to scale training and improve generalization. Evaluation includes comparisons with NMPC tracking PMM-generated trajectories, ablation studies on curriculum learning, and outdoor real-world tests on an ARM-based single-board computer.", "result": "The approach demonstrates generalization to arbitrary state-to-state flights in simulation and shows robustness in real-world outdoor experiments. Compared to an NMPC baseline that tracks PMM-generated trajectories, the method achieves competitive performance, and ablations confirm the benefit of curriculum learning. Real-world tests validate deployment on resource-constrained hardware.", "conclusion": "RL with PMM proxy rewards and curriculum learning can realize a generalizable minimum-time UAV policy across arbitrary state pairs, offering improved generalization beyond track-specific racing and enabling practical deployment on low-power hardware. The work highlights the value of curriculum design and proxy objectives in guiding RL for UAV planning and control."}}
{"id": "2510.20070", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20070", "abs": "https://arxiv.org/abs/2510.20070", "authors": ["Sourabh Karmakar", "Apurva Patel", "Cameron J. Turner"], "title": "Calibration of Parallel Kinematic Machine Based on Stewart Platform-A Literature Review", "comment": null, "summary": "Stewart platform-based Parallel Kinematic (PKM) Machines have been\nextensively studied by researchers due to their inherent finer control\ncharacteristics. This has opened its potential deployment opportunities in\nversatile critical applications like the medical field, engineering machines,\nspace research, electronic chip manufacturing, automobile manufacturing, etc.\nAll these precise, complicated, and repeatable motion applications require\nmicro and nano-scale movement control in 3D space; a 6-DOF PKM can take this\nchallenge smartly. For this, the PKM must be more accurate than the desired\napplication accuracy level and thus proper calibration for a PKM robot is\nessential. Forward kinematics-based calibration for such hexapod machines\nbecomes unnecessarily complex and inverse kinematics complete this task with\nmuch ease. To analyze different techniques, an external instrument-based,\nconstraint-based, and auto or self-calibration-based approaches have been used\nfor calibration. This survey has been done by reviewing these key\nmethodologies, their outcome, and important points related to inverse\nkinematic-based PKM calibrations in general. It is observed in this study that\nthe researchers focused on improving the accuracy of the platform position and\norientation considering the errors contributed by a single source or multiple\nsources. The error sources considered are mainly structural, in some cases,\nenvironmental factors are also considered, however, these calibrations are done\nunder no-load conditions. This study aims to understand the current state of\nthe art in this field and to expand the scope for other researchers in further\nexploration in a specific area.", "AI": {"tldr": "A survey of calibration methods for 6-DOF Stewart platform PKMs, focusing on inverse kinematics; compares external-instrument, constraint-based, and self-calibration approaches; notes emphasis on structural and sometimes environmental errors under no-load conditions; highlights need for broader future work.", "motivation": "Precise micro- to nano-scale 3D motion control in PKMs is required for diverse high-end applications; forward kinematics calibration is complex; inverse-kinematics calibration simplifies the task; improve accuracy across platform position and orientation.", "method": "Literature survey categorizing calibration techniques into external-instrument-based, constraint-based, and auto/self-calibration approaches; analyzes outcomes and key points related to inverse-kinematics calibration for PKMs; discusses error sources (structural, environmental).", "result": "Current studies focus on improving accuracy given single/multiple error sources, often considering structural errors; environmental factors occasionally considered; calibrations typically performed under no-load conditions; a consolidated view of state of the art.", "conclusion": "Inverse kinematics-based PKM calibration is effective; there is a need to expand research horizons to include load conditions, multiple error sources, environmental and dynamic effects, and real-operating scenarios to enhance calibration robustness."}}
{"id": "2510.19840", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.19840", "abs": "https://arxiv.org/abs/2510.19840", "authors": ["Sai Teja Erukude", "Viswa Chaitanya Marella", "Suhasnadh Reddy Veluru"], "title": "Fourier-Based GAN Fingerprint Detection using ResNet50", "comment": "6 pages. Published in IEEE", "summary": "The rapid rise of photorealistic images produced from Generative Adversarial\nNetworks (GANs) poses a serious challenge for image forensics and industrial\nsystems requiring reliable content authenticity. This paper uses\nfrequency-domain analysis combined with deep learning to solve the problem of\ndistinguishing StyleGAN-generated images from real ones. Specifically, a\ntwo-dimensional Discrete Fourier Transform (2D DFT) was applied to transform\nimages into the Fourier domain, where subtle periodic artifacts become\ndetectable. A ResNet50 neural network is trained on these transformed images to\ndifferentiate between real and synthetic ones. The experiments demonstrate that\nthe frequency-domain model achieves a 92.8 percent and an AUC of 0.95,\nsignificantly outperforming the equivalent model trained on raw spatial-domain\nimages. These results indicate that the GAN-generated images have unique\nfrequency-domain signatures or \"fingerprints\". The method proposed highlights\nthe industrial potential of combining signal processing techniques and deep\nlearning to enhance digital forensics and strengthen the trustworthiness of\nindustrial AI systems.", "AI": {"tldr": "The paper reports a frequency-domain detector for StyleGAN images using 2D DFT inputs to a ResNet50, achieving high performance (92.8% accuracy, AUC 0.95) and outperforming spatial-domain models, indicating GANs leave exploitable Fourier-domain fingerprints.", "motivation": "As GANs produce highly realistic images, there is a growing need for reliable forensics methods. Frequency-domain signatures may reveal artifacts not apparent in the spatial domain, offering robust detection for industrial AI systems.", "method": "Apply a two-dimensional Discrete Fourier Transform to images to obtain Fourier-domain representations, then train a ResNet50 classifier to distinguish real versus StyleGAN-generated images. Compare performance against a model trained on raw spatial-domain images.", "result": "The frequency-domain approach achieves 92.8% accuracy and an AUC of 0.95, outperforming the spatial-domain baseline, indicating GAN-generated images possess distinctive frequency-domain fingerprints.", "conclusion": "Frequency-domain features provide a robust cue for GAN image forensics; integrating signal processing with deep learning can enhance authenticity verification in industrial AI systems."}}
{"id": "2510.19835", "categories": ["cs.AI", "cs.ET", "cs.NE", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.19835", "abs": "https://arxiv.org/abs/2510.19835", "authors": ["Max B. Zhao", "Fei Li"], "title": "A Quantum-Inspired Algorithm for Solving Sudoku Puzzles and the MaxCut Problem", "comment": "29 pages, 10 figures, accepted by Quantum Information & Computation\n  on August 6, 2025", "summary": "We propose and evaluate a quantum-inspired algorithm for solving Quadratic\nUnconstrained Binary Optimization (QUBO) problems, which are mathematically\nequivalent to finding ground states of Ising spin-glass Hamiltonians. The\nalgorithm employs Matrix Product States (MPS) to compactly represent large\nsuperpositions of spin configurations and utilizes a discrete driving schedule\nto guide the MPS toward the ground state. At each step, a driver Hamiltonian --\nincorporating a transverse magnetic field -- is combined with the problem\nHamiltonian to enable spin flips and facilitate quantum tunneling. The MPS is\nupdated using the standard Density Matrix Renormalization Group (DMRG) method,\nwhich iteratively minimizes the system's energy via multiple sweeps across the\nspin chain. Despite its heuristic nature, the algorithm reliably identifies\nglobal minima, not merely near-optimal solutions, across diverse QUBO\ninstances. We first demonstrate its effectiveness on intermediate-level Sudoku\npuzzles from publicly available sources, involving over $200$ Ising spins with\nlong-range couplings dictated by constraint satisfaction. We then apply the\nalgorithm to MaxCut problems from the Biq Mac library, successfully solving\ninstances with up to $251$ nodes and $3,265$ edges. We discuss the advantages\nof this quantum-inspired approach, including its scalability, generalizability,\nand suitability for industrial-scale QUBO applications.", "AI": {"tldr": "Quantum-inspired MPS/DMRG approach solves QUBO/Ising problems by evolving a Matrix Product State under a driver-plus-problem Hamiltonian, successfully finding global minima on Sudoku-like and MaxCut instances, with good scalability and generalizability.", "motivation": "QUBO/Ising problems are computationally hard; there is a need for scalable, versatile solvers that can locate global minima. Quantum-inspired methods, leveraging MPS and tunneling-like dynamics, may enhance exploration beyond classical local optimizers.", "method": "Represent the solution as a Matrix Product State (MPS). Apply a discrete driving schedule with a driver Hamiltonian that includes a transverse field, intertwined with the problem Hamiltonian to enable spin flips and tunneling. Update the MPS using standard Density Matrix Renormalization Group (DMRG) sweeps to minimize energy. Test on challenging Sudoku instances with ~200+ spins and long-range couplings; then apply to MaxCut instances from Biq Mac library up to 251 nodes and 3,265 edges.", "result": "The approach reliably identifies global minima across diverse QUBO instances, not merely near-optimal solutions, demonstrating effectiveness on both Sudoku-like problems and sizeable MaxCut problems.", "conclusion": "Quantum-inspired MPS/DMRG methods offer scalable, generalizable solvers for large-scale QUBO/Ising problems, with potential industrial applicability and advantages over some classical heuristics."}}
{"id": "2510.19861", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19861", "abs": "https://arxiv.org/abs/2510.19861", "authors": ["Felix Michalak", "Steven Abreu"], "title": "Some Attention is All You Need for Retrieval", "comment": "16 pages, 10 figures", "summary": "We demonstrate complete functional segregation in hybrid SSM-Transformer\narchitectures: retrieval depends exclusively on self-attention layers. Across\nRecurrentGemma-2B/9B and Jamba-Mini-1.6, attention ablation causes catastrophic\nretrieval failure (0% accuracy), while SSM layers show no compensatory\nmechanisms even with improved prompting. Conversely, sparsifying attention to\njust 15% of heads maintains near-perfect retrieval while preserving 84% MMLU\nperformance, suggesting self-attention specializes primarily for retrieval\ntasks. We identify precise mechanistic requirements for retrieval: needle\ntokens must be exposed during generation and sufficient context must be\navailable during prefill or generation. This strict functional specialization\nchallenges assumptions about redundancy in hybrid architectures and suggests\nthese models operate as specialized modules rather than integrated systems,\nwith immediate implications for architecture optimization and interpretability.", "AI": {"tldr": "Hybrid SSM-Transformer models show complete functional segregation: retrieval relies entirely on self-attention, with SSM layers unable to compensate. Reducing attention to ~15% of heads preserves retrieval and most task performance, suggesting self-attention is specialized for retrieval rather than integration.", "motivation": "To test whether retrieval in hybrid SSM-Transformer architectures can be supported by non-attention modules (SSM) and to probe redundancy/interaction between components, with implications for interpretability and architecture design.", "method": "Experiments across RecurrentGemma-2B/9B and Jamba-Mini-1.6. Ablate attention and SSM layers; test prompting effects; sparsify attention to 15% of heads; evaluate retrieval accuracy and MMLU performance; analyze required conditions for retrieval (needle tokens exposure and sufficient context during prefill/generation).", "result": "Ablating attention causes 0% retrieval accuracy; SSM layers show no compensatory retrieval capability even with improved prompting. Sparsifying attention to about 15% of heads maintains near-perfect retrieval while preserving 84% of MMLU performance. Findings indicate retrieval depends on self-attention, while SSMs do not adaptively compensate; functional segregation is precise rather than redundant.", "conclusion": "The results reveal strict functional specialization in hybrid architectures: models function as modular, specialized components rather than integrated systems. This challenges redundancy assumptions and has immediate implications for architectural optimization and interpretability."}}
{"id": "2510.20079", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20079", "abs": "https://arxiv.org/abs/2510.20079", "authors": ["Travis A. Roberts", "Sourabh Karmakar", "Cameron J. Turner"], "title": "Design of a Bed Rotation Mechanism to Facilitate In-Situ Photogrammetric Reconstruction of Printed Parts", "comment": null, "summary": "Additive manufacturing, or 3D printing, is a complex process that creates\nfree-form geometric objects by sequentially placing material to construct an\nobject, usually in a layer-by-layer process. One of the most widely used\nmethods is Fused Deposition Modeling (FDM). FDM is used in many of the\nconsumer-grade polymer 3D printers available today. While consumer grade\nmachines are cheap and plentiful, they lack many of the features desired in a\nmachine used for research purposes and are often closed-source platforms.\nCommercial-grade models are more expensive and are also usually closed-source\nplatforms that do not offer flexibility for modifications often needed for\nresearch. The authors designed and fabricated a machine to be used as a test\nbed for research in the field of polymer FDM processes. The goal was to create\na platform that tightly controls and/or monitors the FDM build parameters so\nthat experiments can be repeated with a known accuracy. The platform offers\nclosed loop position feedback, control of the hot end and bed temperature, and\nmonitoring of environment temperature and humidity. Additionally, the platform\nis equipped with cameras and a mechanism for in-situ photogrammetry, creating a\ngeometric record of the printing throughout the printing process. Through\nphotogrammetry, backtracking and linking process parameters to observable\ngeometric defects can be achieved. This paper focuses on the design of a novel\nmechanism for spinning the heated bed to allow for photogrammetric\nreconstruction of the printed part using a minimal number of cameras, as\nimplemented on this platform.", "AI": {"tldr": "The authors build a research-oriented FDM test bed with closed-loop controls, environmental monitoring, and in-situ photogrammetry, including a novel spinning heated bed to enable 3D reconstruction with few cameras.", "motivation": "To enable repeatable, accurately controlled polymer FDM experiments and to link process parameters to geometric defects through photogrammetry, addressing the limitations of consumer and commercial printers.", "method": "Design and fabrication of a test-bed platform with closed-loop position feedback; heated nozzle and bed temperature control; environmental sensing (temperature, humidity); cameras; an in-situ photogrammetry system; and a novel mechanism to rotate the heated bed for photogrammetric reconstruction using minimal cameras.", "result": "A platform that records geometry throughout printing and allows backtracking of process parameters to defects; demonstration of the spinning bed mechanism enabling photogrammetric reconstruction with a minimal camera setup.", "conclusion": "This platform provides a controllable, observable environment suitable for research on polymer FDM processes and demonstrates how photogrammetry can be integrated to correlate process parameters with geometric outcomes; the spinning bed mechanism is a key enabler for efficient reconstruction."}}
{"id": "2510.19955", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.19955", "abs": "https://arxiv.org/abs/2510.19955", "authors": ["M\u00e1rcus Vin\u00edcius Lobo Costa", "Sherlon Almeida da Silva", "B\u00e1rbara Caroline Benato", "Leo Sampaio Ferraz Ribeiro", "Moacir Antonelli Ponti"], "title": "Transformed Multi-view 3D Shape Features with Contrastive Learning", "comment": null, "summary": "This paper addresses the challenges in representation learning of 3D shape\nfeatures by investigating state-of-the-art backbones paired with both\ncontrastive supervised and self-supervised learning objectives. Computer vision\nmethods struggle with recognizing 3D objects from 2D images, often requiring\nextensive labeled data and relying on Convolutional Neural Networks (CNNs) that\nmay overlook crucial shape relationships. Our work demonstrates that Vision\nTransformers (ViTs) based architectures, when paired with modern contrastive\nobjectives, achieve promising results in multi-view 3D analysis on our\ndownstream tasks, unifying contrastive and 3D shape understanding pipelines.\nFor example, supervised contrastive losses reached about 90.6% accuracy on\nModelNet10. The use of ViTs and contrastive learning, leveraging ViTs' ability\nto understand overall shapes and contrastive learning's effectiveness,\novercomes the need for extensive labeled data and the limitations of CNNs in\ncapturing crucial shape relationships. The success stems from capturing global\nshape semantics via ViTs and refining local discriminative features through\ncontrastive optimization. Importantly, our approach is empirical, as it is\ngrounded on extensive experimental evaluation to validate the effectiveness of\ncombining ViTs with contrastive objectives for 3D representation learning.", "AI": {"tldr": "ViT-based architectures with contrastive objectives improve 3D shape representation learning for multi-view analysis; achieves ~90.6% accuracy on ModelNet10, bridging supervised/self-supervised contrastive methods with 3D shape understanding.", "motivation": "Address limitations of CNNs in capturing global 3D shape semantics and reduce reliance on large labeled datasets. Explore Vision Transformers (ViTs) combined with modern contrastive objectives to unify contrastive learning with 3D shape understanding.", "method": "Utilize Vision Transformer backbones trained with both supervised contrastive and self-supervised contrastive objectives on multi-view 3D data; perform extensive empirical evaluation on downstream 3D tasks to assess global vs local shape representations.", "result": "Supervised contrastive losses reached about 90.6% accuracy on ModelNet10, indicating competitive performance of ViT-plus-contrastive approaches for 3D shape representation learning.", "conclusion": "ViTs paired with contrastive objectives effectively capture global shape semantics and refine local discriminative features, offering an empirical, unified pathway for integrating contrastive learning with 3D shape understanding."}}
{"id": "2510.19836", "categories": ["cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.19836", "abs": "https://arxiv.org/abs/2510.19836", "authors": ["Eliseo Curcio"], "title": "Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis", "comment": null, "summary": "Artificial intelligence and machine learning are increasingly used for\nforecasting, optimization, and policy design in the energy sector, yet no\nstandardized framework exists to evaluate whether these systems reason\ncorrectly. Current validation practices focus on predictive accuracy or\ncomputational efficiency, leaving the logical integrity of analytical\nconclusions untested. This study introduces the Analytical Reliability\nBenchmark (ARB), a reproducible framework that quantifies reasoning reliability\nin large language models applied to energy system analysis. The benchmark\nintegrates five submetrics: accuracy, reasoning reliability, uncertainty\ndiscipline, policy consistency, and transparency, and evaluates model\nperformance across deterministic, probabilistic, and epistemic scenarios using\nopen technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four\nfrontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) were\ntested under identical factual and regulatory conditions. Results show that\nreasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5\nSonnet achieved consistent and policy-compliant reasoning (Analytical\nReliability Index greater than 90), Gemini 2.5 Pro demonstrated moderate\nstability, and Llama 3 70B remained below professional thresholds. Statistical\nvalidation confirmed that these differences are significant and reproducible.\nThe ARB establishes the first quantitative method in the energy literature for\nverifying causal, probabilistic, and policy-driven reasoning in artificial\nintelligence systems, providing a reference framework for trustworthy and\ntransparent analytical applications in the global energy transition.", "AI": {"tldr": "The paper introduces the Analytical Reliability Benchmark (ARB) to quantify reasoning reliability in large language models for energy system analysis, moving beyond predictive accuracy to assess logical integrity and policy alignment using a reproducible, multi-metric framework.", "motivation": "There is no standardized framework to evaluate whether AI-driven conclusions in energy forecasting/optimization are logically consistent, causally valid, and policy-aligned. Current validation focuses on accuracy or efficiency, neglecting reasoning quality and transparency.", "method": "ARB combines five submetrics\u2014accuracy, reasoning reliability, uncertainty discipline, policy consistency, and transparency\u2014and tests models under deterministic, probabilistic, and epistemic scenarios using open technoeconomic datasets (NREL ATB 2024, DOE H2A/H2New, IEA WEO 2024). Four frontier models (GPT-4/5, Claude 4.5 Sonnet, Gemini 2.5 Pro, Llama 3 70B) are evaluated under identical factual and regulatory conditions.", "result": "Reasoning reliability can be objectively measured. GPT-4/5 and Claude 4.5 Sonnet achieve Analytical Reliability Index > 90 with consistent and policy-compliant reasoning; Gemini 2.5 Pro shows moderate stability; Llama 3 70B remains below professional thresholds. Statistical validation confirms these differences are significant and reproducible.", "conclusion": "ARB provides the first quantitative method in the energy literature for verifying causal, probabilistic, and policy-driven reasoning in AI systems, offering a reference framework for trustworthy and transparent analytical applications in the global energy transition."}}
{"id": "2510.19872", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19872", "abs": "https://arxiv.org/abs/2510.19872", "authors": ["Iman Rahmani", "Saman Yazdannik", "Morteza Tayefi", "Jafar Roshanian"], "title": "An Integrated Approach to Neural Architecture Search for Deep Q-Networks", "comment": null, "summary": "The performance of deep reinforcement learning agents is fundamentally\nconstrained by their neural network architecture, a choice traditionally made\nthrough expensive hyperparameter searches and then fixed throughout training.\nThis work investigates whether online, adaptive architecture optimization can\nescape this constraint and outperform static designs. We introduce NAS-DQN, an\nagent that integrates a learned neural architecture search controller directly\ninto the DRL training loop, enabling dynamic network reconfiguration based on\ncumulative performance feedback. We evaluate NAS-DQN against three\nfixed-architecture baselines and a random search control on a continuous\ncontrol task, conducting experiments over multiple random seeds. Our results\ndemonstrate that NAS-DQN achieves superior final performance, sample\nefficiency, and policy stability while incurring negligible computational\noverhead. Critically, the learned search strategy substantially outperforms\nboth undirected random architecture exploration and poorly-chosen fixed\ndesigns, indicating that intelligent, performance-guided search is the key\nmechanism driving success. These findings establish that architecture\nadaptation is not merely beneficial but necessary for optimal sample efficiency\nin online deep reinforcement learning, and suggest that the design of RL agents\nneed not be a static offline choice but can instead be seamlessly integrated as\na dynamic component of the learning process itself.", "AI": {"tldr": "NAS-DQN integrates a learned neural architecture search controller into the DRL training loop to adapt architectures online, yielding better final performance, sample efficiency, and stability with negligible overhead.", "motivation": "Neural network architecture choices heavily constrain DRL performance and are typically fixed after costly offline searches; online adaptive architecture optimization may unlock better efficiency and performance.", "method": "Propose NAS-DQN, which embeds a neural architecture search controller into the DRL training loop to dynamically reconfigure the network based on accumulated performance feedback; evaluate against fixed-architecture baselines and a random search control on a continuous-control task across multiple seeds.", "result": "NAS-DQN achieves superior final performance, improved sample efficiency and policy stability, with negligible computational overhead; its learned search strategy outperforms undirected random exploration and poorly chosen fixed designs.", "conclusion": "Online architecture adaptation is necessary for optimal sample efficiency in online DRL, suggesting RL agent design can be a dynamic component integrated into learning rather than a static offline choice."}}
{"id": "2510.20161", "categories": ["cs.RO", "68T07, 68T40", "I.2.9; I.2.10; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.20161", "abs": "https://arxiv.org/abs/2510.20161", "authors": ["Ahmed Alanazi", "Duy Ho", "Yugyung Lee"], "title": "PathFormer: A Transformer with 3D Grid Constraints for Digital Twin Robot-Arm Trajectory Generation", "comment": "8 pages, 7 figures, 7 tables", "summary": "Robotic arms require precise, task-aware trajectory planning, yet sequence\nmodels that ignore motion structure often yield invalid or inefficient\nexecutions. We present a Path-based Transformer that encodes robot motion with\na 3-grid (where/what/when) representation and constraint-masked decoding,\nenforcing lattice-adjacent moves and workspace bounds while reasoning over task\ngraphs and action order. Trained on 53,755 trajectories (80% train / 20%\nvalidation), the model aligns closely with ground truth -- 89.44% stepwise\naccuracy, 93.32% precision, 89.44% recall, and 90.40% F1 -- with 99.99% of\npaths legal by construction. Compiled to motor primitives on an xArm Lite 6\nwith a depth-camera digital twin, it attains up to 97.5% reach and 92.5% pick\nsuccess in controlled tests, and 86.7% end-to-end success across 60\nlanguage-specified tasks in cluttered scenes, absorbing slips and occlusions\nvia local re-grounding without global re-planning. These results show that\npath-structured representations enable Transformers to generate accurate,\nreliable, and interpretable robot trajectories, bridging graph-based planning\nand sequence-based learning and providing a practical foundation for\ngeneral-purpose manipulation and sim-to-real transfer.", "AI": {"tldr": "A Path-based Transformer uses a 3-grid where/what/when encoding and constraint-masked decoding to generate valid, task-aware robot trajectories, bridging graph-based planning and sequence learning, with strong real-world performance.", "motivation": "Standard sequence models often ignore motion structure, leading to invalid or inefficient executions; there is a need for task-aware trajectory planning that respects lattice-adjacent moves, workspace bounds, and action ordering.", "method": "Proposes a Path-based Transformer with a 3-grid (where/what/when) representation and constraint-masked decoding. Enforces lattice-adjacent moves and workspace bounds, reasons over task graphs and action order. Trains on 53,755 trajectories (80% train / 20% validation). Compiled to motor primitives on an xArm Lite 6 with a depth-camera digital twin.", "result": "The model aligns closely with ground truth: 89.44% stepwise accuracy, 93.32% precision, 89.44% recall, 90.40% F1. 99.99% of paths are legal by construction. In controlled tests, reach up to 97.5% and pick success 92.5%; in 60 language-specified tasks in cluttered scenes, end-to-end success 86.7%. It tolerates slips and occlusions via local re-grounding without global re-planning.", "conclusion": "Path-structured representations enable Transformers to generate accurate, reliable, and interpretable robot trajectories, bridging graph-based planning and sequence-based learning, providing a practical foundation for general-purpose manipulation and sim-to-real transfer."}}
{"id": "2510.19981", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.19981", "abs": "https://arxiv.org/abs/2510.19981", "authors": ["Martha Teiko Teye", "Ori Maoz", "Matthias Rottmann"], "title": "FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking", "comment": null, "summary": "We propose FutrTrack, a modular camera-LiDAR multi-object tracking framework\nthat builds on existing 3D detectors by introducing a transformer-based\nsmoother and a fusion-driven tracker. Inspired by query-based tracking\nframeworks, FutrTrack employs a multimodal two-stage transformer refinement and\ntracking pipeline. Our fusion tracker integrates bounding boxes with multimodal\nbird's-eye-view (BEV) fusion features from multiple cameras and LiDAR without\nthe need for an explicit motion model. The tracker assigns and propagates\nidentities across frames, leveraging both geometric and semantic cues for\nrobust re-identification under occlusion and viewpoint changes. Prior to\ntracking, we refine sequences of bounding boxes with a temporal smoother over a\nmoving window to refine trajectories, reduce jitter, and improve spatial\nconsistency. Evaluated on nuScenes and KITTI, FutrTrack demonstrates that\nquery-based transformer tracking methods benefit significantly from multimodal\nsensor features compared with previous single-sensor approaches. With an aMOTA\nof 74.7 on the nuScenes test set, FutrTrack achieves strong performance on 3D\nMOT benchmarks, reducing identity switches while maintaining competitive\naccuracy. Our approach provides an efficient framework for improving\ntransformer-based trackers to compete with other neural-network-based methods\neven with limited data and without pretraining.", "AI": {"tldr": "FutrTrack presents a modular camera-LiDAR 3D MOT framework built on a transformer-based temporal smoother and a fusion-driven tracker; it leverages multimodal BEV features and query-based tracking to improve identity maintenance without explicit motion models, achieving strong nuScenes results (aMOTA 74.7) and showing data-efficient, pretrain-free performance.", "motivation": "Address jitter, occlusion, and cross-view re-identification in 3D MOT by integrating multimodal cues and transformer-based tracking; reduce reliance on hand-crafted motion models and large pretraining.", "method": "A two-stage, transformer-based refinement: (1) temporal smoother over a moving window to refine trajectories; (2) a fusion-driven tracker that combines detector bounding boxes with multimodal BEV features from cameras and LiDAR, enabling query-based tracking without an explicit motion model.", "result": "On nuScenes and KITTI, FutrTrack demonstrates that multimodal features significantly benefit query-based transformer tracking; achieves aMOTA of 74.7 on nuScenes test set, reduces identity switches, and remains competitive, with claimed data efficiency and no pretraining.", "conclusion": "FutrTrack shows that robust, multimodal transformer-based tracking can outperform single-sensor approaches and be competitive with neural-motion trackers, while offering an efficient, modular solution that works well with limited data and without pretraining."}}
{"id": "2510.19838", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19838", "abs": "https://arxiv.org/abs/2510.19838", "authors": ["Shiqi He", "Yue Cui", "Xinyu Ma", "Yaliang Li", "Bolin Ding", "Mosharaf Chowdhury"], "title": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory", "comment": null, "summary": "Autonomous web agents powered by large language models (LLMs) show strong\npotential for performing goal-oriented tasks such as information retrieval,\nreport generation, and online transactions. These agents mark a key step toward\npractical embodied reasoning in open web environments. However, existing\napproaches remain limited in reasoning depth and efficiency: vanilla linear\nmethods fail at multi-step reasoning and lack effective backtracking, while\nother search strategies are coarse-grained and computationally costly. We\nintroduce Branch-and-Browse, a fine-grained web agent framework that unifies\nstructured reasoning-acting, contextual memory, and efficient execution. It (i)\nemploys explicit subtask management with tree-structured exploration for\ncontrollable multi-branch reasoning, (ii) bootstraps exploration through\nefficient web state replay with background reasoning, and (iii) leverages a\npage action memory to share explored actions within and across sessions. On the\nWebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8\\%\nand reduces execution time by up to 40.4\\% relative to state-of-the-art\nmethods. These results demonstrate that Branch-and-Browse is a reliable and\nefficient framework for LLM-based web agents.", "AI": {"tldr": "Branch-and-Browse offers a fine-grained, memory-enabled web-agent framework that uses tree-structured subtask exploration, web-state replay, and a page action memory to enable multi-branch reasoning with improved efficiency; on WebArena it achieves 35.8% task success and up to 40% faster execution than state-of-the-art methods.", "motivation": "Existing LLM-based web agents struggle with deep multi-step reasoning, backtracking, and efficiency; vanilla linear methods fail at multi-step reasoning; coarse-grained or costly search strategies hinder practical embodied reasoning on open web environments.", "method": "Introduce Branch-and-Browse: a unified framework combining structured reasoning-acting, contextual memory, and efficient execution. Key components include (i) explicit subtask management with tree-structured exploration for controllable multi-branch reasoning, (ii) efficient web state replay with background reasoning to bootstrap exploration, and (iii) a page action memory that shares explored actions within and across sessions.", "result": "On the WebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8% and reduces execution time by up to 40.4% relative to state-of-the-art methods.", "conclusion": "Branch-and-Browse demonstrates a reliable and efficient framework for LLm-based web agents, enabling deeper, more efficient, and more controllable embodied reasoning in open web environments."}}
{"id": "2510.19873", "categories": ["cs.LG", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2510.19873", "abs": "https://arxiv.org/abs/2510.19873", "authors": ["Junfeng Gong", "Zhiyi Wei", "Junying Chen", "Cheng Liu", "Huawei Li"], "title": "From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph", "comment": null, "summary": "Despite significant evolution of CUDA programming and domain-specific\nlibraries, effectively utilizing GPUs with massively parallel engines remains\ndifficult. Large language models (LLMs) show strong potential in generating\noptimized CUDA code from sequential code. However, using LLMs in practice faces\ntwo major challenges: cloud-based APIs pose risks of code leakage, and local\ndeployment is often computationally expensive and inefficient. These drawbacks\nhave spurred interest in small language models (SLMs), which are more\nlightweight and privacy-friendly. Encouragingly, recent studies show that SLMs\ncan achieve performance comparable to LLMs on specific tasks. While SLMs can\nmatch LLMs on domain-specific tasks, their limited reasoning abilities lead to\nsuboptimal performance in complex CUDA generation according to our experiments.\nTo bridge this gap, we propose ReGraphT, a training-free, retrieval-augmented\ngeneration framework that transfers LLM-level reasoning to smaller models.\nReGraphT organizes CUDA optimization trajectories into a structured reasoning\ngraph, modeling the combined CUDA optimizations as state transitions, and\nleverages Monte Carlo Graph Search (MCGS) for efficient exploration. We also\npresent a CUDA-specific benchmark with difficulty tiers defined by reasoning\ncomplexity to evaluate models more comprehensively. Experiments show that\nReGraphT outperforms HPC-specific fine-tuned models and other\nretrieval-augmented approaches, achieving an average 2.33X speedup on CUDAEval\nand ParEval. When paired with DeepSeek-Coder-V2-Lite-Instruct and\nQwen2.5-Coder-7B-Instruct, ReGraphT enables SLMs to approach LLM-level\nperformance without the associated privacy risks or excessive computing\noverhead.", "AI": {"tldr": "A training-free retrieval-augmented framework named ReGraphT helps small language models (SLMs) match LLMs in CUDA optimization by organizing optimization steps into a reasoning graph and using Monte Carlo Graph Search, plus a CUDA-focused benchmark. It achieves 2.33x speedups and preserves privacy by avoiding cloud APIs.", "motivation": "Despite CUDA's evolution, generating optimized CUDA code remains hard, and LLM-based approaches raise privacy and cost concerns. SLMs are privacy-friendly but lag in complex reasoning. A training-free method that transfers LLM-like reasoning to SLMs could combine privacy with strong performance.", "method": "ReGraphT constructs a structured reasoning graph from CUDA optimization trajectories, treats optimizations as state transitions, and applies Monte Carlo Graph Search to explore the graph. It is training-free and uses a retrieval-augmented setup. A CUDA-specific benchmark with tiers by reasoning complexity is introduced. Evaluation uses CUDAEval and ParEval, pairing ReGraphT with DeepSeek-Coder-V2-Lite-Instruct and Qwen2.5-Coder-7B-Instruct.", "result": "ReGraphT outperforms HPC-specific fine-tuned models and other retrieval-augmented methods, delivering an average 2.33\u00d7 speedup on CUDAEval and ParEval. When combined with selected SLMs, it enables approaching LLM-level performance without privacy risks or heavy computing overhead.", "conclusion": "The framework demonstrates that LLM-level reasoning can be effectively transferred to smaller, privacy-friendly models via a training-free, graph-based retrieval-augmented approach, supported by a CUDA-focused benchmark. This points to practical, scalable, privacy-preserving CUDA optimization for broader adoption."}}
{"id": "2510.20174", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20174", "abs": "https://arxiv.org/abs/2510.20174", "authors": ["Yong Um", "Young-Ha Shin", "Joon-Ha Kim", "Soonpyo Kwon", "Hae-Won Park"], "title": "Reinforcement Learning-based Robust Wall Climbing Locomotion Controller in Ferromagnetic Environment", "comment": "8 pages, 6 figures", "summary": "We present a reinforcement learning framework for quadrupedal wall-climbing\nlocomotion that explicitly addresses uncertainty in magnetic foot adhesion. A\nphysics-based adhesion model of a quadrupedal magnetic climbing robot is\nincorporated into simulation to capture partial contact, air-gap sensitivity,\nand probabilistic attachment failures. To stabilize learning and enable\nreliable transfer, we design a three-phase curriculum: (1) acquire a crawl gait\non flat ground without adhesion, (2) gradually rotate the gravity vector to\nvertical while activating the adhesion model, and (3) inject stochastic\nadhesion failures to encourage slip recovery. The learned policy achieves a\nhigh success rate, strong adhesion retention, and rapid recovery from\ndetachment in simulation under degraded adhesion. Compared with a model\npredictive control (MPC) baseline that assumes perfect adhesion, our controller\nmaintains locomotion when attachment is intermittently lost. Hardware\nexperiments with the untethered robot further confirm robust vertical crawling\non steel surfaces, maintaining stability despite transient misalignment and\nincomplete attachment. These results show that combining curriculum learning\nwith realistic adhesion modeling provides a resilient sim-to-real framework for\nmagnetic climbing robots in complex environments.", "AI": {"tldr": "A reinforcement learning approach with a physics-based adhesion model and a three-phase curriculum yields robust magnetic quadruped wall-climbing that tolerates adhesion uncertainty and transfers to hardware, outperforming an adhesion-ideal MPC baseline.", "motivation": "Magnetic climbing robots face significant adhesion variability (partial contact, air gaps, occasional attachment failure). Robust, transferable control under these uncertainties is essential for reliable operation in real-world environments.", "method": "Train a quadrupedal policy via reinforcement learning using a physics-based adhesion model in simulation. Employ a three-phase curriculum: (1) crawl on flat ground without adhesion, (2) gradually rotate gravity to vertical while activating adhesion, (3) inject stochastic adhesion failures to promote slip recovery. Compare to an MPC baseline assuming perfect adhesion; validate with untethered hardware experiments on steel surfaces.", "result": "In simulation, the policy achieves high success rates, strong adhesion retention, and rapid recovery from detachment under degraded adhesion. It maintains locomotion when attachment is intermittently lost, outperforming the MPC baseline. Hardware experiments confirm robust vertical crawling on steel, maintaining stability despite transient misalignment and incomplete attachment.", "conclusion": "Coupling curriculum learning with a realistic adhesion model yields a resilient sim-to-real framework for magnetic climbing robots, enabling reliable, robust locomotion in environments with uncertain adhesion."}}
{"id": "2510.20011", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20011", "abs": "https://arxiv.org/abs/2510.20011", "authors": ["Kushan Choudhury", "Shubhrodeep Roy", "Ankur Chanda", "Shubhajit Biswas", "Somenath Kuiry"], "title": "Improving Predictive Confidence in Medical Imaging via Online Label Smoothing", "comment": "Accepted and presented in International Conference on Advancing\n  Science and Technologies in Health Science", "summary": "Deep learning models, especially convolutional neural networks, have achieved\nimpressive results in medical image classification. However, these models often\nproduce overconfident predictions, which can undermine their reliability in\ncritical healthcare settings. While traditional label smoothing offers a simple\nway to reduce such overconfidence, it fails to consider relationships between\nclasses by treating all non-target classes equally. In this study, we explore\nthe use of Online Label Smoothing (OLS), a dynamic approach that adjusts soft\nlabels throughout training based on the model's own prediction patterns. We\nevaluate OLS on the large-scale RadImageNet dataset using three widely used\narchitectures: ResNet-50, MobileNetV2, and VGG-19. Our results show that OLS\nconsistently improves both Top-1 and Top-5 classification accuracy compared to\nstandard training methods, including hard labels, conventional label smoothing,\nand teacher-free knowledge distillation. In addition to accuracy gains, OLS\nleads to more compact and well-separated feature embeddings, indicating\nimproved representation learning. These findings suggest that OLS not only\nstrengthens predictive performance but also enhances calibration, making it a\npractical and effective solution for developing trustworthy AI systems in the\nmedical imaging domain.", "AI": {"tldr": "Online Label Smoothing (OLS) dynamically updates soft labels during training to reflect the model\u2019s own predictions, improving accuracy and calibration on RadImageNet across several architectures.", "motivation": "Deep learning models often produce overconfident predictions in medical image classification. Traditional label smoothing ignores relationships between classes, prompting the need for a dynamic, model-aware smoothing approach.", "method": "Implement OLS that adjusts non-target label probabilities during training based on the model\u2019s prediction patterns. Evaluate on RadImageNet using ResNet-50, MobileNetV2, and VGG-19, comparing against hard labels, standard label smoothing, and teacher-free knowledge distillation. Assess both classification performance (Top-1/Top-5) and representation learning (embedding geometry).", "result": "OLS consistently improves Top-1 and Top-5 accuracy over hard labels, conventional label smoothing, and teacher-free KD across the three architectures. It also yields more compact and well-separated feature embeddings, indicating enhanced representation learning.", "conclusion": "OLS strengthens predictive performance and calibration, offering a practical, effective solution for trustworthy AI in medical imaging."}}
{"id": "2510.19842", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19842", "abs": "https://arxiv.org/abs/2510.19842", "authors": ["Yuanhe Zhang", "Ilja Kuzborskij", "Jason D. Lee", "Chenlei Leng", "Fanghui Liu"], "title": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs", "comment": "28 pages, 6 figures. Comments are welcome", "summary": "Large Language Models (LLMs) demonstrate strong performance on mathematical\nproblems when prompted with Chain-of-Thought (CoT), yet it remains unclear\nwhether this success stems from search, rote procedures, or rule-consistent\nreasoning. To address this, we propose modeling CoT as a certain rule-based\nstochastic process over directed acyclic graphs (DAGs), where nodes represent\nintermediate derivation states and edges encode rule applications. Within this\nframework, we introduce logical closeness, a metric that quantifies how well a\nmodel's CoT trajectory (i.e., the LLM's final output) adheres to the DAG\nstructure, providing evaluation beyond classical PASS@k metrics. Building on\nthis, we introduce the DAG-MATH CoT format and construct a benchmark that\nguides LLMs to generate CoT trajectories in this format, thereby enabling the\nevaluation of their reasoning ability under our framework. Across standard\nmathematical reasoning datasets, our analysis uncovers statistically\nsignificant differences in reasoning fidelity among representative LLM\nfamilies-even when PASS@k is comparable-highlighting gaps between final-answer\naccuracy and rule-consistent derivation. Our framework provides a balance\nbetween free-form CoT and formal proofs systems, offering actionable\ndiagnostics for LLMs reasoning evaluation. Our benchmark and code are available\nat: https://github.com/YuanheZ/DAG-MATH-Formatted-CoT.", "AI": {"tldr": "A DAG-based formalization of chain-of-thought for LLMs with a new metric 'logical closeness' and a DAG-MATH CoT benchmark; reveals gaps between final answers and rule-consistent derivations across LLMs; code available.", "motivation": "To understand whether CoT's gains come from search, rote procedures, or rule-consistent reasoning; to move beyond PASS@k with a framework that evaluates rule-consistency; provide diagnostics for LLM reasoning.", "method": "Model CoT as a rule-based stochastic process on directed acyclic graphs (DAGs); nodes are intermediate derivation states; edges encode rule applications. Introduce 'logical closeness' to quantify how well a model's CoT trajectory adheres to the DAG structure. Define DAG-MATH CoT format and build a benchmark guiding LLMs to generate CoT trajectories in this format.", "result": "Across standard mathematical reasoning datasets, there are statistically significant differences in reasoning fidelity among representative LLM families even when PASS@k is comparable; final-answer accuracy can diverge from derivation quality, highlighting gaps between end results and rule-consistent derivations.", "conclusion": "The framework offers a middle ground between free-form CoT and formal proofs, providing actionable diagnostics for evaluating LLM reasoning. The DAG-MATH CoT benchmark and code enable reproducible assessment and diagnostics."}}
{"id": "2510.19889", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.19889", "abs": "https://arxiv.org/abs/2510.19889", "authors": ["Mostafa Ameli", "Van Anh Le", "Sulthana Shams", "Alexander Skabardonis"], "title": "From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem", "comment": null, "summary": "The traffic assignment problem is essential for traffic flow analysis,\ntraditionally solved using mathematical programs under the Equilibrium\nprinciple. These methods become computationally prohibitive for large-scale\nnetworks due to non-linear growth in complexity with the number of OD pairs.\nThis study introduces a novel data-driven approach using deep neural networks,\nspecifically leveraging the Transformer architecture, to predict equilibrium\npath flows directly. By focusing on path-level traffic distribution, the\nproposed model captures intricate correlations between OD pairs, offering a\nmore detailed and flexible analysis compared to traditional link-level\napproaches. The Transformer-based model drastically reduces computation time,\nwhile adapting to changes in demand and network structure without the need for\nrecalculation. Numerical experiments are conducted on the Manhattan-like\nsynthetic network, the Sioux Falls network, and the Eastern-Massachusetts\nnetwork. The results demonstrate that the proposed model is orders of magnitude\nfaster than conventional optimization. It efficiently estimates path-level\ntraffic flows in multi-class networks, reducing computational costs and\nimproving prediction accuracy by capturing detailed trip and flow information.\nThe model also adapts flexibly to varying demand and network conditions,\nsupporting traffic management and enabling rapid `what-if' analyses for\nenhanced transportation planning and policy-making.", "AI": {"tldr": "A data-driven Transformer-based approach predicts equilibrium path flows in traffic assignment, achieving orders-of-magnitude speedups over traditional optimization by modeling path-level flows and cross-OD correlations, validated on multiple networks.", "motivation": "Traditional traffic assignment solving equilibrium via mathematical programs scales poorly with the number of origin-destination (OD) pairs; there is a need for faster, flexible methods that can adapt to changing demand and network structure to support rapid what-if analyses and policy decisions.", "method": "Employ a Transformer-based deep neural network to predict equilibrium path flows directly from network and demand inputs, focusing on path-level traffic distribution and inter-OD correlations. Train on synthetic and real networks and evaluate against conventional optimization, with emphasis on multi-class networks.", "result": "The approach achieves substantial computational speedups, being orders of magnitude faster than conventional optimization. It improves prediction accuracy by capturing detailed trip and flow information, estimates path-level flows efficiently, and adapts to varying demand and network conditions. Demonstrated across Manhattan-like synthetic network, Sioux Falls, and Eastern Massachusetts networks, enabling rapid what-if analyses for planning and policy.", "conclusion": "A Transformer-based data-driven method offers a scalable, flexible alternative to traditional equilibrium traffic assignment, reducing computational costs while handling multi-class networks and enabling rapid planning analyses for traffic management and policy decisions."}}
{"id": "2510.20177", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20177", "abs": "https://arxiv.org/abs/2510.20177", "authors": ["Muhammad Suhail Saleem", "Lai Yuan", "Maxim Likhachev"], "title": "A Contact-Driven Framework for Manipulating in the Blind", "comment": null, "summary": "Robots often face manipulation tasks in environments where vision is\ninadequate due to clutter, occlusions, or poor lighting--for example, reaching\na shutoff valve at the back of a sink cabinet or locating a light switch above\na crowded shelf. In such settings, robots, much like humans, must rely on\ncontact feedback to distinguish free from occupied space and navigate around\nobstacles. Many of these environments often exhibit strong structural\npriors--for instance, pipes often span across sink cabinets--that can be\nexploited to anticipate unseen structure and avoid unnecessary collisions. We\npresent a theoretically complete and empirically efficient framework for\nmanipulation in the blind that integrates contact feedback with structural\npriors to enable robust operation in unknown environments. The framework\ncomprises three tightly coupled components: (i) a contact detection and\nlocalization module that utilizes joint torque sensing with a contact particle\nfilter to detect and localize contacts, (ii) an occupancy estimation module\nthat uses the history of contact observations to build a partial occupancy map\nof the workspace and extrapolate it into unexplored regions with learned\npredictors, and (iii) a planning module that accounts for the fact that contact\nlocalization estimates and occupancy predictions can be noisy, computing paths\nthat avoid collisions and complete tasks efficiently without eliminating\nfeasible solutions. We evaluate the system in simulation and in the real world\non a UR10e manipulator across two domestic tasks--(i) manipulating a valve\nunder a kitchen sink surrounded by pipes and (ii) retrieving a target object\nfrom a cluttered shelf. Results show that the framework reliably solves these\ntasks, achieving up to a 2x reduction in task completion time compared to\nbaselines, with ablations confirming the contribution of each module.", "AI": {"tldr": "A complete framework for manipulation in the blind that fuses contact feedback with structural priors to navigate unknown environments, leveraging a contact filter, occupancy prediction, and robust planning; demonstrated efficiency gains on real robots.", "motivation": "Vision can be unreliable in cluttered or occluded environments. Humans rely on touch and structural regularities to infer unseen space. The paper seeks a theoretically complete, empirically efficient method that integrates contact sensing with priors to enable robust blind manipulation.", "method": "Three coupled components: (i) contact detection/localization using joint torque sensing with a contact particle filter to detect and localize contacts; (ii) occupancy estimation from contact history to build a partial workspace map and extrapolate into unexplored regions with learned predictors; (iii) planning that accounts for noise in contact localization and occupancy estimates to compute collision-avoiding, efficient paths without discarding feasible solutions.", "result": "Evaluated in simulation and on a UR10e across two domestic tasks (valve under a sink with pipes; retrieving a target object from a cluttered shelf). Achieves up to 2x faster task completion vs baselines; ablations confirm the contribution of each module.", "conclusion": "The framework offers a theoretically complete and empirically efficient approach to blind manipulation by integrating contact sensing with structural priors. It enables robust operation in unknown environments and shows strong efficiency gains, with potential generalization to other priors and tasks."}}
{"id": "2510.20016", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20016", "abs": "https://arxiv.org/abs/2510.20016", "authors": ["Neema Jakisa Owor", "Joshua Kofi Asamoah", "Tanner Wambui Muturi", "Anneliese Jakisa Owor", "Blessing Agyei Kyem", "Andrews Danyo", "Yaw Adu-Gyamfi", "Armstrong Aboah"], "title": "A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance", "comment": "The paper was accepted at ICCV 2025 and published in CVF database", "summary": "Fisheye cameras offer an efficient solution for wide-area traffic\nsurveillance by capturing large fields of view from a single vantage point.\nHowever, the strong radial distortion and nonuniform resolution inherent in\nfisheye imagery introduce substantial challenges for standard object detectors,\nparticularly near image boundaries where object appearance is severely\ndegraded. In this work, we present a detection framework designed to operate\nrobustly under these conditions. Our approach employs a simple yet effective\npre and post processing pipeline that enhances detection consistency across the\nimage, especially in regions affected by severe distortion. We train several\nstate-of-the-art detection models on the fisheye traffic imagery and combine\ntheir outputs through an ensemble strategy to improve overall detection\naccuracy. Our method achieves an F1 score of0.6366 on the 2025 AI City\nChallenge Track 4, placing 8thoverall out of 62 teams. These results\ndemonstrate the effectiveness of our framework in addressing issues inherent to\nfisheye imagery.", "AI": {"tldr": "A fisheye-aware detection framework improves object detection under strong distortion by pre/post processing and ensemble of detectors, achieving competitive performance on AI City Challenge.", "motivation": "Fisheye imagery has strong radial distortion and nonuniform resolution, causing degraded object appearance near image boundaries, hindering standard detectors; there is a need for robustness across the distorted field.", "method": "A simple yet effective pre- and post-processing pipeline to stabilize detections across the image; train multiple state-of-the-art detectors on fisheye traffic data; ensemble their outputs to boost accuracy.", "result": "Achieved F1 score 0.6366 on AI City Challenge Track 4 (2025), placing 8th out of 62 teams.", "conclusion": "The framework demonstrates robustness to fisheye distortions and shows the benefit of pre/post processing plus ensemble in improving detection under severe distortion."}}
{"id": "2510.19949", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19949", "abs": "https://arxiv.org/abs/2510.19949", "authors": ["Mathieu Andreux", "M\u00e4rt Bakler", "Yanael Barbier", "Hamza Ben Chekroun", "Emilien Bir\u00e9", "Antoine Bonnet", "Riaz Bordie", "Nathan Bout", "Matthias Brunel", "Aleix Cambray", "Pierre-Louis Cedoz", "Antoine Chassang", "Gautier Cloix", "Ethan Connelly", "Alexandra Constantinou", "Ramzi De Coster", "Hubert de la Jonquiere", "Aur\u00e9lien Delfosse", "Maxime Delpit", "Alexis Deprez", "Augustin Derupti", "Mathieu Diaz", "Shannon D'Souza", "Julie Dujardin", "Abai Edmund", "Michael Eickenberg", "Armand Fatalot", "Wissem Felissi", "Isaac Herring", "Xavier Koegler", "Erwan Le Jumeau de Kergaradec", "Aur\u00e9lien Lac", "Maxime Langevin", "Corentin Lauverjat", "Antonio Loison", "Avshalom Manevich", "Axel Moyal", "Axel Nguyen Kerbel", "Marinela Parovic", "Julien Revelle", "Guillaume Richard", "Mats Richter", "Ronan Riochet", "Mar\u00eda Santos", "Romain Savidan", "Laurent Sifre", "Maxime Theillard", "Marc Thibault", "Ivan Valentini", "Tony Wu", "Laura Yie", "Kai Yuan", "Jevgenij Zubovskij"], "title": "Surfer 2: The Next Generation of Cross-Platform Computer Use Agents", "comment": "21 pages, 9 figures, 2 tables", "summary": "Building agents that generalize across web, desktop, and mobile environments\nremains an open challenge, as prior systems rely on environment-specific\ninterfaces that limit cross-platform deployment. We introduce Surfer 2, a\nunified architecture operating purely from visual observations that achieves\nstate-of-the-art performance across all three environments. Surfer 2 integrates\nhierarchical context management, decoupled planning and execution, and\nself-verification with adaptive recovery, enabling reliable operation over long\ntask horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on\nWebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior\nsystems without task-specific fine-tuning. With multiple attempts, Surfer 2\nexceeds human performance on all benchmarks. These results demonstrate that\nsystematic orchestration amplifies foundation model capabilities and enables\ngeneral-purpose computer control through visual interaction alone, while\ncalling for a next-generation vision language model to achieve Pareto-optimal\ncost-efficiency.", "AI": {"tldr": "A visual-only, unified architecture (Surfer 2) achieves state-of-the-art cross-platform automation across web, desktop, and mobile, outperforming prior methods and humans on multiple benchmarks without task-specific fine-tuning.", "motivation": "Cross-platform automation is hampered by environment-specific interfaces; enabling reliable control using only visual observations would enable general-purpose deployment without platform-specific adapters.", "method": "Surfer 2 uses a unified architecture with hierarchical context management, decoupled planning and execution, and self-verification with adaptive recovery, operating entirely from visual inputs to handle long-horizon tasks.", "result": "Achieves 97.1% accuracy on WebVoyager, 69.6% on WebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld; outperforms all prior systems without task-specific fine-tuning; with multiple attempts, surpasses human performance on all benchmarks.", "conclusion": "Systematic orchestration enhances foundation-model capabilities for general-purpose computer control via visual interaction, suggesting a need for next-generation vision-language models to maximize cost-efficiency."}}
{"id": "2510.19893", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19893", "abs": "https://arxiv.org/abs/2510.19893", "authors": ["Shiqi Dai", "Wei Dai", "Jiaee Cheong", "Paul Pu Liang"], "title": "FairGRPO: Fair Reinforcement Learning for Equitable Clinical Reasoning", "comment": "Accepted as Oral on NeurIPS 2025 GenAI4Health Workshop", "summary": "Medical artificial intelligence systems have achieved remarkable diagnostic\ncapabilities, yet they consistently exhibit performance disparities across\ndemographic groups, causing real-world harm to underrepresented populations.\nWhile recent multimodal reasoning foundation models have advanced clinical\ndiagnosis through integrated analysis of diverse medical data, reasoning\ntrainings via reinforcement learning inherit and often amplify biases present\nin training datasets dominated by majority populations. We introduce\nFairness-aware Group Relative Policy Optimization (FairGRPO), a hierarchical\nreinforcement learning approach that promotes equitable learning across\nheterogeneous clinical populations. FairGRPO employs adaptive importance\nweighting of advantages based on representation, task difficulty, and data\nsource. To address the common issue of missing demographic labels in the\nclinical domain, we further employ unsupervised clustering, which automatically\ndiscovers latent demographic groups when labels are unavailable. Through\ncomprehensive experiments across 7 clinical diagnostic datasets spanning 5\nclinical modalities across X-ray, CT scan, dermoscropy, mammography and\nultrasound, we demonstrate that FairGRPO reduces predictive parity by 27.2%\nagainst all vanilla and bias mitigated RL baselines, while improving F1 score\nby 12.49%. Furthermore, training dynamics analysis reveals that FairGRPO\nprogressively improves fairness throughout optimization, while baseline RL\nmethods exhibit deteriorating fairness as training progresses. Based on\nFairGRPO, we release FairMedGemma-4B, a fairness-aware clinical VLLM that\nachieves state-of-the-art performance while demonstrating significantly reduced\ndisparities across demographic groups.", "AI": {"tldr": "A fairness-aware hierarchical RL method (FairGRPO) for equitable clinical learning, using adaptive advantage weighting and unsupervised clustering to discover latent groups, evaluated across diverse medical modalities; reports reduced disparities and higher F1, and releases a fairness-focused clinical VLLM (FairMedGemma-4B).", "motivation": "Medical AI systems show persistent performance disparities across demographic groups, and RL-based reasoning can inherit or amplify these biases when training data are dominated by majority populations. When demographic labels are missing, latent groups are often unobserved, complicating fairness efforts.", "method": "FairGRPO is a hierarchical reinforcement learning framework that applies adaptive importance weighting of advantages based on representation, task difficulty, and data source to promote equitable learning across heterogeneous clinical populations. It uses unsupervised clustering to discover latent demographic groups when labels are unavailable. Evaluations span 7 clinical diagnostic datasets across 5 modalities (X-ray, CT, dermoscopy, mammography, ultrasound). A fairness-aware clinical VLLM, FairMedGemma-4B, is released.", "result": "FairGRPO reduces predictive disparity (parity gap) by 27.2% compared with vanilla and bias-mitigated RL baselines and improves F1 score by 12.49%. Training dynamics show fairness steadily improves during optimization for FairGRPO, whereas baseline RL methods exhibit deteriorating fairness. The approach demonstrates broad empirical gains across multiple datasets and modalities.", "conclusion": "FairGRPO offers a learning framework that progressively enhances fairness during optimization in medical RL, enabling fairer diagnoses. The accompanying FairMedGemma-4B model demonstrates state-of-the-art performance with reduced demographic disparities."}}
{"id": "2510.20231", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20231", "abs": "https://arxiv.org/abs/2510.20231", "authors": ["Yuta Takahashi", "Atsuki Ochi", "Yoichi Tomioka", "Shin-Ichiro Sakai"], "title": "NODA-MMH: Certified Learning-Aided Nonlinear Control for Magnetically-Actuated Swarm Experiment Toward On-Orbit Proof", "comment": "Accepted for presentation at the 2025 International Conference on\n  Space Robotics (iSpaRo 2025)", "summary": "This study experimentally validates the principle of large-scale satellite\nswarm control through learning-aided magnetic field interactions generated by\nsatellite-mounted magnetorquers. This actuation presents a promising solution\nfor the long-term formation maintenance of multiple satellites and has\nprimarily been demonstrated in ground-based testbeds for two-satellite position\ncontrol. However, as the number of satellites increases beyond three,\nfundamental challenges coupled with the high nonlinearity arise: 1)\nnonholonomic constraints, 2) underactuation, 3) scalability, and 4)\ncomputational cost. Previous studies have shown that time-integrated current\ncontrol theoretically solves these problems, where the average actuator outputs\nalign with the desired command, and a learning-based technique further enhances\ntheir performance. Through multiple experiments, we validate critical aspects\nof learning-aided time-integrated current control: (1) enhanced controllability\nof the averaged system dynamics, with a theoretically guaranteed error bound,\nand (2) decentralized current management. We design two-axis coils and a\nground-based experimental setup utilizing an air-bearing platform, enabling a\nmathematical replication of orbital dynamics. Based on the effectiveness of the\nlearned interaction model, we introduce NODA-MMH (Neural power-Optimal Dipole\nAllocation for certified learned Model-based Magnetically swarm control\nHarness) for model-based power-optimal swarm control. This study complements\nour tutorial paper on magnetically actuated swarms for the long-term formation\nmaintenance problem.", "AI": {"tldr": "Experimental validation of learning-aided time-integrated current control for magnetically actuated satellite swarms, achieving enhanced controllability and decentralized current management; introduces NODA-MMH for power-optimal swarm control.", "motivation": "Enable long-term formation maintenance of large satellite swarms using magnetorquers by addressing nonlinear, underactuated, scalable, and computational challenges that grow with swarm size.", "method": "Ground-based air-bearing experiments with two-axis coils to mimic orbital dynamics; implement time-integrated current control augmented by a learning-based interaction model; establish theoretical error bounds for the averaged dynamics; demonstrate decentralized current management; introduce NODA-MMH for model-based power-optimal swarm control.", "result": "Demonstrated enhanced controllability of the averaged system dynamics with a guaranteed error bound; validated decentralized current management; confirmed effectiveness of the learned interaction model; proposed NODA-MMH for power-optimal swarm control based on the learned model.", "conclusion": "The work supports the viability of learning-aided magnetically actuated swarms for long-term formation maintenance and provides a path toward scalable, power-efficient, model-based control, complementing existing tutorials in the area."}}
{"id": "2510.20027", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.20027", "abs": "https://arxiv.org/abs/2510.20027", "authors": ["Damian Bowness", "Charalambos Poullis"], "title": "Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses", "comment": null, "summary": "When viewing a 3D Gaussian Splatting (3DGS) model from camera positions\nsignificantly outside the training data distribution, substantial visual noise\ncommonly occurs. These artifacts result from the lack of training data in these\nextrapolated regions, leading to uncertain density, color, and geometry\npredictions from the model.\n  To address this issue, we propose a novel real-time render-aware filtering\nmethod. Our approach leverages sensitivity scores derived from intermediate\ngradients, explicitly targeting instabilities caused by anisotropic\norientations rather than isotropic variance. This filtering method directly\naddresses the core issue of generative uncertainty, allowing 3D reconstruction\nsystems to maintain high visual fidelity even when users freely navigate\noutside the original training viewpoints.\n  Experimental evaluation demonstrates that our method substantially improves\nvisual quality, realism, and consistency compared to existing Neural Radiance\nField (NeRF)-based approaches such as BayesRays. Critically, our filter\nseamlessly integrates into existing 3DGS rendering pipelines in real-time,\nunlike methods that require extensive post-hoc retraining or fine-tuning.\n  Code and results at https://damian-bowness.github.io/EV3DGS", "AI": {"tldr": "A real-time, render-aware filter for 3D Gaussian Splatting that mitigates extrapolation artifacts by using gradient-derived sensitivity scores to suppress unstable anisotropic regions, enabling higher fidelity rendering without retraining.", "motivation": "Extrapolations far from training viewpoints produce noisy, uncertain density/color/geometry in 3DGS models; a real-time method is needed to preserve visual fidelity during free navigation.", "method": "Compute sensitivity scores from intermediate gradients that target anisotropic orientation instabilities, apply a render-aware filter during rendering, and integrate seamlessly into existing 3DGS pipelines without retraining.", "result": "Significant gains in visual quality, realism, and consistency over NeRF-based approaches such as BayesRays; method runs in real-time within the rendering pipeline; code and results are provided at the project link.", "conclusion": "The approach effectively reduces generative uncertainty in extrapolated views, enabling robust, real-time 3DGS rendering across unseen viewpoints."}}
{"id": "2510.19954", "categories": ["cs.AI", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19954", "abs": "https://arxiv.org/abs/2510.19954", "authors": ["Joseph Meyer", "Divyansha Lachi", "Reza Mohammadi", "Roshan Reddy Upendra", "Eva L. Dyer", "Mark Li", "Tom Palczewski"], "title": "RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs", "comment": "6 pages", "summary": "Relational multi-table data is common in domains such as e-commerce,\nhealthcare, and scientific research, and can be naturally represented as\nheterogeneous temporal graphs with multi-modal node attributes. Existing graph\nneural networks (GNNs) rely on schema-specific feature encoders, requiring\nseparate modules for each node type and feature column, which hinders\nscalability and parameter sharing. We introduce RELATE (Relational Encoder for\nLatent Aggregation of Typed Entities), a schema-agnostic, plug-and-play feature\nencoder that can be used with any general purpose GNN. RELATE employs shared\nmodality-specific encoders for categorical, numerical, textual, and temporal\nattributes, followed by a Perceiver-style cross-attention module that\naggregates features into a fixed-size, permutation-invariant node\nrepresentation. We evaluate RELATE on ReLGNN and HGT in the RelBench benchmark,\nwhere it achieves performance within 3% of schema-specific encoders while\nreducing parameter counts by up to 5x. This design supports varying schemas and\nenables multi-dataset pretraining for general-purpose GNNs, paving the way\ntoward foundation models for relational graph data.", "AI": {"tldr": "RELATE provides a schema-agnostic, plug-and-play feature encoder for heterogeneous temporal graphs, enabling scalable, multi-modal node representations with strong parameter efficiency and near-parity to schema-specific encoders.", "motivation": "To address scalability and parameter-sharing challenges in GNNs that use schema-specific feature encoders for heterogeneous graphs with multiple modalities, by enabling a single, reusable encoder across node types and schemas.", "method": "Shared modality-specific encoders for categorical, numerical, textual, and temporal data feed into a Perceiver-style cross-attention module that produces fixed-size, permutation-invariant node embeddings, which can be plugged into any general-purpose GNN.", "result": "On RelBench using ReLGNN and HGT backbones, achieving within 3% of schema-specific encoders while reducing parameters by up to 5x.", "conclusion": "The approach enables handling varying schemas and supports multi-dataset pretraining, contributing toward foundation-model-like capabilities for relational graph data."}}
{"id": "2510.19896", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19896", "abs": "https://arxiv.org/abs/2510.19896", "authors": ["Filipe Ferreira de Oliveira", "Matheus Becali Rocha", "Renato A. Krohling"], "title": "Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable SHAP-Guided Feature Selection and Classification", "comment": null, "summary": "In this paper, we propose an approach to support the diagnosis of urinary\ntract diseases, with a focus on bladder cancer, using SHAP (SHapley Additive\nexPlanations)-based feature selection to enhance the transparency and\neffectiveness of predictive models. Six binary classification scenarios were\ndeveloped to distinguish bladder cancer from other urological and oncological\nconditions. The algorithms XGBoost, LightGBM, and CatBoost were employed, with\nhyperparameter optimization performed using Optuna and class balancing with the\nSMOTE technique. The selection of predictive variables was guided by importance\nvalues through SHAP-based feature selection while maintaining or even improving\nperformance metrics such as balanced accuracy, precision, and specificity. The\nuse of explainability techniques (SHAP) for feature selection proved to be an\neffective approach. The proposed methodology may contribute to the development\nof more transparent, reliable, and efficient clinical decision support systems,\noptimizing screening and early diagnosis of urinary tract diseases.", "AI": {"tldr": "SHAP-guided feature selection enhances transparent, accurate bladder cancer prediction using XGBoost/LightGBM/CatBoost with SMOTE and Optuna across six binary tasks.", "motivation": "To improve transparency and reliability of ML-based urinary tract disease diagnosis and address class imbalance, enabling better clinical decision support.", "method": "Perform SHAP-based feature selection to identify predictive features; train XGBoost, LightGBM, CatBoost with Optuna for hyperparameter tuning and SMOTE for balancing; evaluate on six binary classification tasks distinguishing bladder cancer from other conditions; report balanced accuracy, precision, specificity.", "result": "SHAP-based feature selection maintains or improves performance while enhancing explainability; the approach yields transparent models suitable for clinical decision support.", "conclusion": "SHAP-informed feature selection is effective for clinical ML pipelines, offering transparent, reliable screening for urinary tract diseases and potential for deployment in decision-support systems."}}
{"id": "2510.20261", "categories": ["cs.RO", "cs.CV", "I.2.10"], "pdf": "https://arxiv.org/pdf/2510.20261", "abs": "https://arxiv.org/abs/2510.20261", "authors": ["Mert Bulent Sariyildiz", "Philippe Weinzaepfel", "Guillaume Bono", "Gianluca Monaci", "Christian Wolf"], "title": "Kinaema: a recurrent sequence model for memory and pose in motion", "comment": "10 pages + references + checklist + appendix, 29 pages total", "summary": "One key aspect of spatially aware robots is the ability to \"find their\nbearings\", ie. to correctly situate themselves in previously seen spaces. In\nthis work, we focus on this particular scenario of continuous robotics\noperations, where information observed before an actual episode start is\nexploited to optimize efficiency. We introduce a new model, Kinaema, and agent,\ncapable of integrating a stream of visual observations while moving in a\npotentially large scene, and upon request, processing a query image and\npredicting the relative position of the shown space with respect to its current\nposition. Our model does not explicitly store an observation history, therefore\ndoes not have hard constraints on context length. It maintains an implicit\nlatent memory, which is updated by a transformer in a recurrent way,\ncompressing the history of sensor readings into a compact representation. We\nevaluate the impact of this model in a new downstream task we call \"Mem-Nav\".\nWe show that our large-capacity recurrent model maintains a useful\nrepresentation of the scene, navigates to goals observed before the actual\nepisode start, and is computationally efficient, in particular compared to\nclassical transformers with attention over an observation history.", "AI": {"tldr": "Kinaema offers a scalable, memory-efficient approach to place recognition in continuous robotics by using a latent memory updated by a recurrent transformer to predict relative pose from a query image, showing favorable Mem-Nav performance against full-history transformers.", "motivation": "In continuous robotic operations, robots must re-localize using prior observations without fixed context limits, and conventional transformers struggle with long histories or are computationally costly. The work aims to enable large-scale, efficient spatial memory for relocalization using pre-episode data.", "method": "Introduce Kinaema, a model that ingests streaming visual observations and maintains an implicit latent memory updated by a transformer in a recurrent loop. It does not store explicit observation history; instead, it compresses sensor history into a compact latent representation. Upon a query image, it predicts the target space's relative position from the current pose. Evaluated on the Mem-Nav downstream task to assess navigation to goals observed before episode start and computational efficiency relative to full-history transformer approaches.", "result": "The model retains a useful scene representation, enables navigation to previously observed goals, and achieves computational efficiency, notably compared to classical transformers with attention over entire histories.", "conclusion": "A large-capacity recurrent model with implicit, compressed memory can effectively support long-horizon spatial localization in large scenes, offering efficiency advantages over explicit history-aware transformers and enabling memory-based navigation tasks like Mem-Nav."}}
{"id": "2510.20029", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20029", "abs": "https://arxiv.org/abs/2510.20029", "authors": ["Shengyu Chen", "Shihang Feng", "Yi Luo", "Xiaowei Jia", "Youzuo Lin"], "title": "BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for Transcranial Ultrasound Tomography", "comment": "13 pages", "summary": "Ultrasound brain imaging remains challenging due to the large difference in\nsound speed between the skull and brain tissues and the difficulty of coupling\nlarge probes to the skull. This work aims to achieve quantitative transcranial\nultrasound by reconstructing an accurate speed-of-sound (SoS) map of the brain.\nTraditional physics-based full-waveform inversion (FWI) is limited by weak\nsignals caused by skull-induced attenuation, mode conversion, and phase\naberration, as well as incomplete spatial coverage since full-aperture arrays\nare clinically impractical. In contrast, purely data-driven methods that learn\ndirectly from raw ultrasound data often fail to model the complex nonlinear and\nnonlocal wave propagation through bone, leading to anatomically plausible but\nquantitatively biased SoS maps under low signal-to-noise and sparse-aperture\nconditions. To address these issues, we propose BrainPuzzle, a hybrid two-stage\nframework that combines physical modeling with machine learning. In the first\nstage, reverse time migration (time-reversal acoustics) is applied to\nmulti-angle acquisitions to produce migration fragments that preserve\nstructural details even under low SNR. In the second stage, a transformer-based\nsuper-resolution encoder-decoder with a graph-based attention unit (GAU) fuses\nthese fragments into a coherent and quantitatively accurate SoS image. A\npartial-array acquisition strategy using a movable low-count transducer set\nimproves feasibility and coupling, while the hybrid algorithm compensates for\nthe missing aperture. Experiments on two synthetic datasets show that\nBrainPuzzle achieves superior SoS reconstruction accuracy and image\ncompleteness, demonstrating its potential for advancing quantitative ultrasound\nbrain imaging.", "AI": {"tldr": "Hybrid physics-informed deep learning for transcranial SoS mapping: stage-1 time-reversal migration fragments; stage-2 transformer-based fusion with graph attention; partial movable array; synthetic data show improved accuracy and completeness.", "motivation": "Transcranial ultrasound faces skull-induced velocity variations, attenuation, phase aberrations, and limited clinical full-aperture access. Pure physics-based FWI is hampered by weak signals and incomplete coverage, while purely data-driven methods struggle under low SNR and sparse sensing.", "method": "Stage 1: apply reverse-time migration (time-reversal acoustics) to multi-angle acquisitions to generate migration fragments that preserve structural details at low SNR. Stage 2: use a transformer-based super-resolution encoder\u2013decoder with a graph-based attention unit to fuse fragments into a coherent, quantitative SoS image. Employ a partial-array acquisition with a movable low-count transducer set to improve feasibility; the hybrid method compensates for missing aperture.", "result": "Two synthetic datasets show BrainPuzzle achieves superior SoS reconstruction accuracy and image completeness compared to baselines.", "conclusion": "A hybrid physics\u2013machine-learning framework can overcome skull-induced challenges and sparse aperture limitations, enabling more accurate and complete quantitative ultrasound brain imaging with potential clinical impact."}}
{"id": "2510.19957", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19957", "abs": "https://arxiv.org/abs/2510.19957", "authors": ["Amir Hever", "Itai Orr"], "title": "A new wave of vehicle insurance fraud fueled by generative AI", "comment": null, "summary": "Generative AI is supercharging insurance fraud by making it easier to falsify\naccident evidence at scale and in rapid time. Insurance fraud is a pervasive\nand costly problem, amounting to tens of billions of dollars in losses each\nyear. In the vehicle insurance sector, fraud schemes have traditionally\ninvolved staged accidents, exaggerated damage, or forged documents. The rise of\ngenerative AI, including deepfake image and video generation, has introduced\nnew methods for committing fraud at scale. Fraudsters can now fabricate highly\nrealistic crash photos, damage evidence, and even fake identities or documents\nwith minimal effort, exploiting AI tools to bolster false insurance claims.\nInsurers have begun deploying countermeasures such as AI-based deepfake\ndetection software and enhanced verification processes to detect and mitigate\nthese AI-driven scams. However, current mitigation strategies face significant\nlimitations. Detection tools can suffer from false positives and negatives, and\nsophisticated fraudsters continuously adapt their tactics to evade automated\nchecks. This cat-and-mouse arms race between generative AI and detection\ntechnology, combined with resource and cost barriers for insurers, means that\ncombating AI-enabled insurance fraud remains an ongoing challenge. In this\nwhite paper, we present UVeye layered solution for vehicle fraud, representing\na major leap forward in the ability to detect, mitigate and deter this new wave\nof fraud.", "AI": {"tldr": "Generative AI enables scalable, realistic insurance fraud (deepfakes, forged documents) in vehicle claims; existing defenses are limited, and a layered UVeye solution is proposed to detect, deter, and mitigate AI-driven fraud.", "motivation": "Insurance fraud costs tens of billions annually and is exacerbated by generative AI tools that produce realistic accident evidence, damaging the integrity of claims and increasing losses.", "method": "The paper analyzes AI-enabled fraud vectors (deepfake images/videos, forged documents) and advocates a layered UVeye approach combining detection and verification processes to counter these scams, while acknowledging an ongoing arms race with adversaries.", "result": "Proposes an architecture and strategy (layered UVeye solution) to detect, mitigate, and deter AI-driven vehicle fraud; claims progress but provides no empirical results in the abstract.", "conclusion": "AI-enabled insurance fraud remains an ongoing challenge; a robust, layered defense is necessary, and the UVeye solution represents a significant step forward, albeit with unresolved issues like false positives/negatives and evolving attacker tactics."}}
{"id": "2510.19917", "categories": ["cs.LG", "cs.CV", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.19917", "abs": "https://arxiv.org/abs/2510.19917", "authors": ["Trajan Murphy", "Akshunna S. Dogra", "Hanfeng Gu", "Caleb Meredith", "Mark Kon", "Julio Enrique Castrillion-Candas"], "title": "FINDER: Feature Inference on Noisy Datasets using Eigenspace Residuals", "comment": "30 pages, 11 figures, 8 tables. Code available at\n  https://github.com/MathePhysics/FINDER", "summary": "''Noisy'' datasets (regimes with low signal to noise ratios, small sample\nsizes, faulty data collection, etc) remain a key research frontier for\nclassification methods with both theoretical and practical implications. We\nintroduce FINDER, a rigorous framework for analyzing generic classification\nproblems, with tailored algorithms for noisy datasets. FINDER incorporates\nfundamental stochastic analysis ideas into the feature learning and inference\nstages to optimally account for the randomness inherent to all empirical\ndatasets. We construct ''stochastic features'' by first viewing empirical\ndatasets as realizations from an underlying random field (without assumptions\non its exact distribution) and then mapping them to appropriate Hilbert spaces.\nThe Kosambi-Karhunen-Lo\\'eve expansion (KLE) breaks these stochastic features\ninto computable irreducible components, which allow classification over noisy\ndatasets via an eigen-decomposition: data from different classes resides in\ndistinct regions, identified by analyzing the spectrum of the associated\noperators. We validate FINDER on several challenging, data-deficient scientific\ndomains, producing state of the art breakthroughs in: (i) Alzheimer's Disease\nstage classification, (ii) Remote sensing detection of deforestation. We end\nwith a discussion on when FINDER is expected to outperform existing methods,\nits failure modes, and other limitations.", "AI": {"tldr": "FINDER is a robust, stochastic-feature-based classifier framework for noisy data that uses the Kosambi-Karhunen-Lo\u00e8ve decomposition to extract irreducible components for classification, showing state-of-the-art results in Alzheimer's stage classification and deforestation detection; the paper also discusses when it should outperform existing methods, plus potential failure modes and limitations.", "motivation": "Noisy datasets with low signal-to-noise ratios, small sample sizes, or faulty data collection hinder reliable classification. A principled framework that integrates stochastic analysis into feature learning and inference is needed to account for inherent randomness in empirical data and to enable robust decision-making in data-deficient domains.", "method": "Treat empirical datasets as realizations of an underlying random field, map them into appropriate Hilbert spaces, and apply the Kosambi-Karhunen-Lo\u00e8ve expansion to decompose stochastic features into computable irreducible components. Classification is then performed via an eigen-decomposition in which data from different classes occupy distinct spectral regions.", "result": "Validation on challenging, data-deficient domains yields state-of-the-art breakthroughs in (i) Alzheimer's Disease stage classification and (ii) remote sensing detection of deforestation, demonstrating the framework\u2019s practical effectiveness in noisy settings.", "conclusion": "FINDER offers a principled route to improved classification in noisy regimes and for data-scarce problems. It is most beneficial under conditions where stochastic structure can be exploited; the paper discusses when it is expected to outperform existing methods, along with identified failure modes and limitations such as modeling assumptions, computational complexity, and scalability."}}
{"id": "2510.20328", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20328", "abs": "https://arxiv.org/abs/2510.20328", "authors": ["Ajay Sridhar", "Jennifer Pan", "Satvik Sharma", "Chelsea Finn"], "title": "MemER: Scaling Up Memory for Robot Control via Experience Retrieval", "comment": "Project page: https://jen-pan.github.io/memer/", "summary": "Humans routinely rely on memory to perform tasks, yet most robot policies\nlack this capability; our goal is to endow robot policies with the same\nability. Naively conditioning on long observation histories is computationally\nexpensive and brittle under covariate shift, while indiscriminate subsampling\nof history leads to irrelevant or redundant information. We propose a\nhierarchical policy framework, where the high-level policy is trained to select\nand track previous relevant keyframes from its experience. The high-level\npolicy uses selected keyframes and the most recent frames when generating text\ninstructions for a low-level policy to execute. This design is compatible with\nexisting vision-language-action (VLA) models and enables the system to\nefficiently reason over long-horizon dependencies. In our experiments, we\nfinetune Qwen2.5-VL-7B-Instruct and $\\pi_{0.5}$ as the high-level and low-level\npolicies respectively, using demonstrations supplemented with minimal language\nannotations. Our approach, MemER, outperforms prior methods on three real-world\nlong-horizon robotic manipulation tasks that require minutes of memory. Videos\nand code can be found at https://jen-pan.github.io/memer/.", "AI": {"tldr": "MemER introduces a hierarchical memory-aware policy for long-horizon robotics, selecting keyframes to guide a low-level policy, using vision-language-action models, and achieving superior performance on memory-intensive tasks.", "motivation": "Humans rely on memory for planning; current robot policies struggle with long histories, suffering from computational strain and brittleness under covariate shift; there is a need for efficient memory-based decision-making.", "method": "A two-level hierarchy where the high-level policy selects and tracks relevant past keyframes; the high-level uses these keyframes plus the most recent frames to generate text instructions for a low-level policy. The approach is compatible with existing vision-language-action (VLA) models. In experiments, Qwen2.5-VL-7B-Instruct is finetuned as the high-level policy and \u03c00.5 as the low-level policy, using demonstrations augmented with minimal language annotations.", "result": "MemER outperforms prior methods on three real-world long-horizon robotic manipulation tasks that require minutes of memory.", "conclusion": "The memory-focused hierarchical framework enables efficient long-horizon reasoning by selectively retaining and using past experiences; it leverages existing VLA models and demonstrates practical gains in real-world tasks."}}
{"id": "2510.20042", "categories": ["cs.CV", "I.2.10; I.2.6; I.4.9"], "pdf": "https://arxiv.org/pdf/2510.20042", "abs": "https://arxiv.org/abs/2510.20042", "authors": ["Huichan Seo", "Sieun Choi", "Minki Hong", "Yi Zhou", "Junseo Kim", "Lukman Ismaila", "Naome Etori", "Mehul Agarwal", "Zhixuan Liu", "Jihie Kim", "Jean Oh"], "title": "Exposing Blindspots: Cultural Bias Evaluation in Generative Image Models", "comment": "28 pages, 8 figures. Submitted to the Second Conference of the\n  International Association for Safe and Ethical Artificial Intelligence\n  (IASEAI '26)", "summary": "Generative image models produce striking visuals yet often misrepresent\nculture. Prior work has examined cultural bias mainly in text-to-image (T2I)\nsystems, leaving image-to-image (I2I) editors underexplored. We bridge this gap\nwith a unified evaluation across six countries, an 8-category/36-subcategory\nschema, and era-aware prompts, auditing both T2I generation and I2I editing\nunder a standardized protocol that yields comparable diagnostics. Using open\nmodels with fixed settings, we derive cross-country, cross-era, and\ncross-category evaluations. Our framework combines standard automatic metrics,\na culture-aware retrieval-augmented VQA, and expert human judgments collected\nfrom native reviewers. To enable reproducibility, we release the complete image\ncorpus, prompts, and configurations. Our study reveals three findings: (1)\nunder country-agnostic prompts, models default to Global-North, modern-leaning\ndepictions that flatten cross-country distinctions; (2) iterative I2I editing\nerodes cultural fidelity even when conventional metrics remain flat or improve;\nand (3) I2I models apply superficial cues (palette shifts, generic props)\nrather than era-consistent, context-aware changes, often retaining source\nidentity for Global-South targets. These results highlight that\nculture-sensitive edits remain unreliable in current systems. By releasing\nstandardized data, prompts, and human evaluation protocols, we provide a\nreproducible, culture-centered benchmark for diagnosing and tracking cultural\nbias in generative image models.", "AI": {"tldr": "A cross-country, era-aware benchmark for evaluating culture bias in generative image models, covering both T2I and I2I, revealing Global-North bias, erosion of cultural fidelity with iterative edits, and superficial cue-based edits; provides standardized data, prompts, and evaluation protocols for reproducible, culture-centered bias diagnostics.", "motivation": "Address a gap where cultural bias has been studied mainly in text-to-image systems, leaving image-to-image editors underexplored. Propose a unified, reproducible protocol across six countries, 8 categories/36 subcategories, and era-aware prompts to diagnose culture sensitivity in both generation and editing.", "method": "Open models with fixed settings; evaluate across country, era, and category dimensions using a standardized protocol. Combine automatic metrics, a culture-aware retrieval-augmented VQA, and expert human judgments from native reviewers. Use an 8-category/36-subcategory schema and era-aware prompts. Release the complete image corpus, prompts, and configurations for reproducibility.", "result": "Three key findings: (1) Country-agnostic prompts lead to Global-North, modern-leaning depictions that flatten cross-country distinctions; (2) Iterative I2I editing erodes cultural fidelity even when metrics stay flat or improve; (3) I2I models apply superficial cues (palette shifts, generic props) rather than era-consistent, context-aware changes, often retaining source identity for Global-South targets.", "conclusion": "Culture-sensitive edits remain unreliable with current systems. The authors provide standardized data, prompts, and human evaluation protocols to enable a reproducible, culture-centered benchmark for diagnosing and tracking cultural bias in generative image models."}}
{"id": "2510.19964", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.19964", "abs": "https://arxiv.org/abs/2510.19964", "authors": ["Nitsa J Herzog", "Rejwan Bin Sulaiman", "David J Herzog", "Rose Fong"], "title": "AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits", "comment": "20 pages, 6 figures, research article", "summary": "The study explores the potential of AI technologies in personalized learning,\nsuggesting the prediction of academic success through leadership personality\ntraits and machine learning modelling. The primary data were obtained from 129\nmaster's students in the Environmental Engineering Department, who underwent\nfive leadership personality tests with 23 characteristics. Students used\nself-assessment tools that included Personality Insight, Workplace Culture,\nMotivation at Work, Management Skills, and Emotion Control tests. The test\nresults were combined with the average grade obtained from academic reports.\nThe study employed exploratory data analysis and correlation analysis. Feature\nselection utilized Pearson correlation coefficients of personality traits. The\naverage grades were separated into three categories: fail, pass, and excellent.\nThe modelling process was performed by tuning seven ML algorithms, such as SVM,\nLR, KNN, DT, GB, RF, XGBoost and LightGBM. The highest predictive performance\nwas achieved with the RF classifier, which yielded an accuracy of 87.50% for\nthe model incorporating 17 personality trait features and the leadership mark\nfeature, and an accuracy of 85.71% for the model excluding this feature. In\nthis way, the study offers an additional opportunity to identify students'\nstrengths and weaknesses at an early stage of their education process and\nselect the most suitable strategies for personalized learning.", "AI": {"tldr": "AI-based prediction of student academic success from leadership personality traits using ML; Random Forest achieved up to ~87% accuracy on 17 traits plus leadership score (vs ~85.7% without it) in 129 Environmental Engineering master's students.", "motivation": "To enable early identification of students\u2019 strengths and weaknesses for personalized learning by predicting academic outcomes from leadership-related personality traits using machine learning.", "method": "Collected data from 129 master's students in Environmental Engineering who completed five leadership personality tests (23 traits) and self-assessments (Personality Insight; Workplace Culture; Motivation at Work; Management Skills; Emotion Control). Grades were merged with test results. Performed exploratory data analysis and correlation analysis. Feature selection via Pearson correlations. Labels: fail, pass, excellent. Evaluated multiple ML models (SVM, Logistic Regression, KNN, Decision Tree, Gradient Boosting, Random Forest, XGBoost, LightGBM); tuned models; compared with and without a leadership mark feature.", "result": "Random Forest yielded the highest predictive accuracy: 87.50% with 17 personality traits plus leadership mark, and 85.71% without the leadership mark.", "conclusion": "The study demonstrates that leadership-related personality traits can support early assessment of student strengths and weaknesses, enabling personalized learning strategies, with RF providing strong predictive performance among tested algorithms."}}
{"id": "2510.19933", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.19933", "abs": "https://arxiv.org/abs/2510.19933", "authors": ["Egor Shulgin", "Sultan AlRashed", "Francesco Orabona", "Peter Richt\u00e1rik"], "title": "Beyond the Ideal: Analyzing the Inexact Muon Update", "comment": null, "summary": "The Muon optimizer has rapidly emerged as a powerful, geometry-aware\nalternative to AdamW, demonstrating strong performance in large-scale training\nof neural networks. However, a critical theory-practice disconnect exists:\nMuon's efficiency relies on fast, approximate orthogonalization, yet all prior\ntheoretical work analyzes an idealized, computationally intractable version\nassuming exact SVD-based updates. This work moves beyond the ideal by providing\nthe first analysis of the inexact orthogonalized update at Muon's core. We\ndevelop our analysis within the general framework of Linear Minimization Oracle\n(LMO)-based optimization, introducing a realistic additive error model to\ncapture the inexactness of practical approximation schemes. Our analysis yields\nexplicit bounds that quantify performance degradation as a function of the LMO\ninexactness/error. We reveal a fundamental coupling between this inexactness\nand the optimal step size and momentum: lower oracle precision requires a\nsmaller step size but larger momentum parameter. These findings elevate the\napproximation procedure (e.g., the number of Newton-Schulz steps) from an\nimplementation detail to a critical parameter that must be co-tuned with the\nlearning schedule. NanoGPT experiments directly confirm the predicted coupling,\nwith optimal learning rates clearly shifting as approximation precision\nchanges.", "AI": {"tldr": "First theoretical treatment of inexact orthogonalized updates in Muon within an LMO-based framework. It derives explicit bounds linking approximation error to performance and shows a coupling: with less precise oracle, you should reduce step size but can tolerate larger momentum. Empirical NanoGPT results confirm the predicted learning-rate shifts with precision.", "motivation": "Bridging the gap between theory and practice for Muon. Prior work assumes exact SVD-based updates, but practical implementations rely on approximate orthogonalization, creating a disconnect between theory and real performance.", "method": "Model the orthogonalization error as an additive inexactness in a Linear Minimization Oracle (LMO) framework. Derive explicit performance bounds as a function of LMO inexactness. Analyze the coupling between inexactness, step size, and momentum; treat the level of approximation (e.g., Newton-Schulz iterations) as a tunable parameter.", "result": "Provided explicit bounds that quantify degradation in performance due to LMO inexactness. Identified a fundamental coupling: lower oracle precision necessitates smaller step sizes but allows larger momentum. Experimental NanoGPT results corroborate the theory, showing optimal learning rates shift with approximation precision.", "conclusion": "Approximation quality of the orthogonalization procedure is a critical hyperparameter that must be co-tuned with the learning schedule. This work closes the theory-practice gap by showing how inexact updates affect Muon's performance and how to adjust optimization hyperparameters accordingly."}}
{"id": "2510.20335", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20335", "abs": "https://arxiv.org/abs/2510.20335", "authors": ["Zixuan Wu", "Hengyuan Zhang", "Ting-Hsuan Chen", "Yuliang Guo", "David Paz", "Xinyu Huang", "Liu Ren"], "title": "Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking", "comment": "Code is at\n  https://github.com/ChampagneAndfragrance/Dino_Diffusion_Parking_Official", "summary": "Parking is a critical pillar of driving safety. While recent end-to-end (E2E)\napproaches have achieved promising in-domain results, robustness under domain\nshifts (e.g., weather and lighting changes) remains a key challenge. Rather\nthan relying on additional data, in this paper, we propose Dino-Diffusion\nParking (DDP), a domain-agnostic autonomous parking pipeline that integrates\nvisual foundation models with diffusion-based planning to enable generalized\nperception and robust motion planning under distribution shifts. We train our\npipeline in CARLA at regular setting and transfer it to more adversarial\nsettings in a zero-shot fashion. Our model consistently achieves a parking\nsuccess rate above 90% across all tested out-of-distribution (OOD) scenarios,\nwith ablation studies confirming that both the network architecture and\nalgorithmic design significantly enhance cross-domain performance over existing\nbaselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment\nreconstructed from a real-world parking lot demonstrates promising sim-to-real\ntransfer.", "AI": {"tldr": "A domain-agnostic parking pipeline (DDP) combines visual foundation models with diffusion-based planning to achieve robust, cross-domain parking performance, including zero-shot transfer to adversarial scenarios and sim-to-real transfer via a 3D Gaussian splatting environment, achieving >90% success in OOD tests.", "motivation": "Improve robustness of autonomous parking under distribution shifts (e.g., weather, lighting) where many end-to-end systems fail, without requiring extra data. Leverage visual foundation models for generalized perception and diffusion-based planning for robust motion planning.", "method": "Introduce Dino-Diffusion Parking (DDP), a pipeline that fuses visual foundation models with diffusion-based planning. Trained in CARLA under regular settings and deployed zero-shot to adversarial settings. Evaluated in a 3D Gaussian splatting (3DGS) environment reconstructed from real parking data to assess sim-to-real transfer.", "result": "Achieves parking success rate >90% across all tested out-of-distribution scenarios. Ablation studies show both network architecture and algorithmic design significantly improve cross-domain performance versus baselines.", "conclusion": "DDP provides a domain-agnostic parking pipeline enabling generalized perception and robust planning under distribution shifts, with promising cross-domain performance and sim-to-real transfer potential."}}
{"id": "2510.20071", "categories": ["cs.CV", "I.4.1"], "pdf": "https://arxiv.org/pdf/2510.20071", "abs": "https://arxiv.org/abs/2510.20071", "authors": ["Bernd Pfrommer"], "title": "Filter-Based Reconstruction of Images from Events", "comment": null, "summary": "Reconstructing an intensity image from the events of a moving event camera is\na challenging task that is typically approached with neural networks deployed\non graphics processing units. This paper presents a much simpler, FIlter Based\nAsynchronous Reconstruction method (FIBAR). First, intensity changes signaled\nby events are integrated with a temporal digital IIR filter. To reduce\nreconstruction noise, stale pixels are detected by a novel algorithm that\nregulates a window of recently updated pixels. Arguing that for a moving\ncamera, the absence of events at a pixel location likely implies a low image\ngradient, stale pixels are then blurred with a Gaussian filter. In contrast to\nmost existing methods, FIBAR is asynchronous and permits image read-out at an\narbitrary time. It runs on a modern laptop CPU at about 42(140) million\nevents/s with (without) spatial filtering enabled. A few simple qualitative\nexperiments are presented that show the difference in image reconstruction\nbetween FIBAR and a neural network-based approach (FireNet). FIBAR's\nreconstruction is noisier than neural network-based methods and suffers from\nghost images. However, it is sufficient for certain tasks such as the detection\nof fiducial markers. Code is available at\nhttps://github.com/ros-event-camera/event_image_reconstruction_fibar", "AI": {"tldr": "A lightweight, asynchronous, filter-based method (FIBAR) for reconstructing intensity images from event-camera data using an IIR temporal filter, stale-pixel regulation, and optional Gaussian smoothing, enabling CPU-based readouts with fast throughput; trades some image quality for speed and simplicity.", "motivation": "Event cameras produce sparse, high-temporal-resolution data, making intensity reconstruction challenging. Most effective approaches rely on neural networks on GPUs, which are resource-intensive. There is a need for a simple, CPU-friendly, asynchronous reconstruction method that can read out at arbitrary times and support downstream tasks.", "method": "Apply a temporal digital IIR filter to integrate intensity changes signaled by events. Detect and regulate a window of recently updated (stale) pixels to suppress reconstruction noise. Assume absence of events at a location implies low image gradient; blur stale pixels with a Gaussian filter. Make the method asynchronous, allowing image read-out at any time. Implemented on a modern laptop CPU, achieving 42(140) million events/s with/without spatial filtering. Compare qualitatively to a neural-network method (FireNet). Code available.", "result": "FIBAR runs efficiently on CPU, achieving high event throughput (42(140) M events/s). The reconstructions are noisier and exhibit ghosting compared to neural-network baselines but are still useful for certain tasks such as fiducial-marker detection. The paper provides qualitative comparisons demonstrating the differences in image quality and shows that a simple filter-based pipeline can yield usable results without heavy training or GPU resources.", "conclusion": "A simple, asynchronous, filter-based approach provides a viable alternative to DNN-based methods for event-camera image reconstruction. It enables arbitrary-time readouts and runs efficiently on consumer hardware, but at the cost of higher noise and ghost artifacts. It is suitable for basic tasks like fiducial detection and serves as a lightweight baseline that could be improved with hybrid or post-filtering strategies."}}
{"id": "2510.20075", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20075", "abs": "https://arxiv.org/abs/2510.20075", "authors": ["Antonio Norelli", "Michael Bronstein"], "title": "LLMs can hide text in other text of the same length.ipynb", "comment": "21 pages, main paper 9 pages", "summary": "A meaningful text can be hidden inside another, completely different yet\nstill coherent and plausible, text of the same length. For example, a tweet\ncontaining a harsh political critique could be embedded in a tweet that\ncelebrates the same political leader, or an ordinary product review could\nconceal a secret manuscript. This uncanny state of affairs is now possible\nthanks to Large Language Models, and in this paper we present a simple and\nefficient protocol to achieve it. We show that even modest 8-billion-parameter\nopen-source LLMs are sufficient to obtain high-quality results, and a message\nas long as this abstract can be encoded and decoded locally on a laptop in\nseconds. The existence of such a protocol demonstrates a radical decoupling of\ntext from authorial intent, further eroding trust in written communication,\nalready shaken by the rise of LLM chatbots. We illustrate this with a concrete\nscenario: a company could covertly deploy an unfiltered LLM by encoding its\nanswers within the compliant responses of a safe model. This possibility raises\nurgent questions for AI safety and challenges our understanding of what it\nmeans for a Large Language Model to know something.", "AI": {"tldr": "A protocol enables hiding a coherent text inside another of the same length using 8B-parameter LLMs, enabling local encoding/decoding; raises AI-safety and trust concerns about covert messaging and authorial intent.", "motivation": "Investigate text steganography via LLMs and its implications for trust in communication and the semantics of LLM knowledge; highlight potential misuse (covert unfiltered deployment).", "method": "Proposes a simple, efficient protocol to encode/decode a message of equal length into a cover text using modest open-source LLMs; demonstrates local encoding/decoding on a laptop in seconds.", "result": "The protocol can encode a message as long as the abstract and decode it locally with high-quality results using ~8B parameters; performance is fast and practical.", "conclusion": "Decoupling text from authorial intent erodes trust in written communication and raises urgent AI-safety questions about model deployment and what it means for a model to 'know' something; suggests need for safeguards against covert use of safe models to emit unfiltered outputs."}}
{"id": "2510.19934", "categories": ["cs.LG", "cs.CR", "math.ST", "stat.ME", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.19934", "abs": "https://arxiv.org/abs/2510.19934", "authors": ["Xiang Li", "Buxin Su", "Chendi Wang", "Qi Long", "Weijie J. Su"], "title": "Mitigating Privacy-Utility Trade-off in Decentralized Federated Learning via $f$-Differential Privacy", "comment": "NeurIPS 2025 (Spotlight)", "summary": "Differentially private (DP) decentralized Federated Learning (FL) allows\nlocal users to collaborate without sharing their data with a central server.\nHowever, accurately quantifying the privacy budget of private FL algorithms is\nchallenging due to the co-existence of complex algorithmic components such as\ndecentralized communication and local updates. This paper addresses privacy\naccounting for two decentralized FL algorithms within the $f$-differential\nprivacy ($f$-DP) framework. We develop two new $f$-DP-based accounting methods\ntailored to decentralized settings: Pairwise Network $f$-DP (PN-$f$-DP), which\nquantifies privacy leakage between user pairs under random-walk communication,\nand Secret-based $f$-Local DP (Sec-$f$-LDP), which supports structured noise\ninjection via shared secrets. By combining tools from $f$-DP theory and Markov\nchain concentration, our accounting framework captures privacy amplification\narising from sparse communication, local iterations, and correlated noise.\nExperiments on synthetic and real datasets demonstrate that our methods yield\nconsistently tighter $(\\epsilon,\\delta)$ bounds and improved utility compared\nto R\\'enyi DP-based approaches, illustrating the benefits of $f$-DP in\ndecentralized privacy accounting.", "AI": {"tldr": "Introduces f-DP-based privacy accounting for decentralized FL; presents PN-f-DP and Sec-f-LDP to quantify privacy leakage under decentralized settings; uses Markov chain concentration to capture amplification from sparse communication, local iterations, and correlated noise; shows tighter (\u03b5,\u03b4) bounds and better utility than RDP-based methods.", "motivation": "Accurately quantifying the privacy budget in decentralized FL is challenging due to intertwined components (decentralized communication, local updates) and limitations of existing DP accounting (e.g., R\u00e9nyi DP). The work aims to provide tighter, more reliable privacy accounting under f-DP.", "method": "Develops two f-DP-based accounting methods: (1) Pairwise Network f-DP (PN-f-DP) for privacy leakage between user pairs under random-walk communication, and (2) Secret-based f-LDP (Sec-f-LDP) that enables structured noise via shared secrets. Combines f-DP theory with Markov chain concentration to model amplification from sparse communication, multiple local iterations, and correlated noise.", "result": "Empirical results on synthetic and real datasets show consistently tighter (\u03b5,\u03b4) privacy bounds and improved data utility compared to Renyi DP-based accounting approaches.", "conclusion": "f-DP-based accounting is advantageous for decentralized FL privacy budgeting, yielding tighter bounds and better utility by capturing amplification effects from communication sparsity, local updates, and correlated noise via PN-f-DP and Sec-f-LDP frameworks."}}
{"id": "2510.20347", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.20347", "abs": "https://arxiv.org/abs/2510.20347", "authors": ["Ashutosh Mishra", "Shreya Santra", "Elian Neppel", "Edoardo M. Rossi Lombardi", "Shamistan Karimov", "Kentaro Uno", "Kazuya Yoshida"], "title": "Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots", "comment": "Accepted in IEEE iSpaRo 2025. Awaiting Publication", "summary": "Modular reconfigurable robots suit task-specific space operations, but the\ncombinatorial growth of morphologies hinders unified control. We propose a\ndecentralized reinforcement learning (Dec-RL) scheme where each module learns\nits own policy: wheel modules use Soft Actor-Critic (SAC) for locomotion and\n7-DoF limbs use Proximal Policy Optimization (PPO) for steering and\nmanipulation, enabling zero-shot generalization to unseen configurations. In\nsimulation, the steering policy achieved a mean absolute error of 3.63{\\deg}\nbetween desired and induced angles; the manipulation policy plateaued at 84.6 %\nsuccess on a target-offset criterion; and the wheel policy cut average motor\ntorque by 95.4 % relative to baseline while maintaining 99.6 % success.\nLunar-analogue field tests validated zero-shot integration for autonomous\nlocomotion, steering, and preliminary alignment for reconfiguration. The system\ntransitioned smoothly among synchronous, parallel, and sequential modes for\nPolicy Execution, without idle states or control conflicts, indicating a\nscalable, reusable, and robust approach for modular lunar robots.", "AI": {"tldr": "Decentralized RL for modular reconfigurable robots enables zero-shot generalization across configurations with module-specific policies and shows strong simulation and lunar-analogue results.", "motivation": "The combinatorial growth of possible morphologies in modular robots creates control complexity and limits unified control; there is a need for scalable, zero-shot capable policies that generalize to unseen configurations.", "method": "Each module learns its own policy: wheel modules use Soft Actor-Critic (SAC) for locomotion, 7-DoF limbs use Proximal Policy Optimization (PPO) for steering/manipulation. The approach aims for zero-shot generalization to unseen configurations and examines policy execution modes (synchronous, parallel, sequential) for conflict-free control. Evaluations are done in simulation and lunar-analogue field tests.", "result": "Simulation results: steering MAE 3.63 degrees; manipulation success at 84.6% on target-offset criterion; wheel policy reduces average motor torque by 95.4% vs baseline with 99.6% success. Field tests show zero-shot integration for autonomous locomotion, steering, and preliminary alignment; system transitions smoothly among execution modes without idle states or conflicts.", "conclusion": "The Dec-RL scheme is scalable, reusable, and robust for modular lunar robots, enabling zero-shot integration across morphologies and adaptable policy execution, with practical viability demonstrated in lunar-analogue scenarios."}}
{"id": "2510.20077", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20077", "abs": "https://arxiv.org/abs/2510.20077", "authors": ["Hui Chen", "Xinjie Wang", "Xianchao Xiu", "Wanquan Liu"], "title": "Data-Adaptive Transformed Bilateral Tensor Low-Rank Representation for Clustering", "comment": null, "summary": "Tensor low-rank representation (TLRR) has demonstrated significant success in\nimage clustering. However, most existing methods rely on fixed transformations\nand suffer from poor robustness to noise. In this paper, we propose a novel\ntransformed bilateral tensor low-rank representation model called TBTLRR, which\nintroduces a data-adaptive tensor nuclear norm by learning arbitrary unitary\ntransforms, allowing for more effective capture of global correlations. In\naddition, by leveraging the bilateral structure of latent tensor data, TBTLRR\nis able to exploit local correlations between image samples and features.\nFurthermore, TBTLRR integrates the $\\ell_{1/2}$-norm and Frobenius norm\nregularization terms for better dealing with complex noise in real-world\nscenarios. To solve the proposed nonconvex model, we develop an efficient\noptimization algorithm inspired by the alternating direction method of\nmultipliers (ADMM) and provide theoretical convergence. Extensive experiments\nvalidate its superiority over the state-of-the-art methods in clustering. The\ncode will be available at https://github.com/xianchaoxiu/TBTLRR.", "AI": {"tldr": "Proposes TBTLRR, a data-adaptive, transformed bilateral tensor low-rank representation model for image clustering that learns unitary transforms to define a tensor nuclear norm, leveraging both global and local correlations, with l1/2 and Frobenius regularization, solved via an ADMM-inspired algorithm with proven convergence and strong clustering performance.", "motivation": "Existing tensor low-rank methods rely on fixed transformations and struggle with noise robustness. There is a need for data-adaptive transforms and a bilateral (local-global) view to better capture correlations in image data under real-world noise.", "method": "Introduce TBTLRR: (1) learn arbitrary unitary transforms to form a data-adaptive tensor nuclear norm; (2) exploit bilateral structure to capture local sample-feature correlations; (3) regularize with l1/2-norm and Frobenius norm to handle complex noise; (4) solve the nonconvex problem with an ADMM-inspired optimization algorithm and prove convergence.", "result": "Extensive experiments demonstrate that TBTLRR outperforms state-of-the-art clustering methods, validating its robustness and effectiveness in capturing global and local correlations under noise. Code will be released at the provided GitHub link.", "conclusion": "TBTLRR provides a robust, data-adaptive framework for tensor low-rank representation in image clustering, leveraging both global and local correlations and offering convergent, efficient optimization with superior clustering performance."}}
{"id": "2510.20099", "categories": ["cs.AI", "cs.CE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20099", "abs": "https://arxiv.org/abs/2510.20099", "authors": ["Daewoo Park", "Suho Park", "Inseok Hong", "Hanwool Lee", "Junkyu Park", "Sangjun Lee", "Jeongman An", "Hyunbin Loh"], "title": "AI PB: A Grounded Generative Agent for Personalized Investment Insights", "comment": "Under Review", "summary": "We present AI PB, a production-scale generative agent deployed in real retail\nfinance. Unlike reactive chatbots that answer queries passively, AI PB\nproactively generates grounded, compliant, and user-specific investment\ninsights. It integrates (i) a component-based orchestration layer that\ndeterministically routes between internal and external LLMs based on data\nsensitivity, (ii) a hybrid retrieval pipeline using OpenSearch and the\nfinance-domain embedding model, and (iii) a multi-stage recommendation\nmechanism combining rule heuristics, sequential behavioral modeling, and\ncontextual bandits. Operating fully on-premises under Korean financial\nregulations, the system employs Docker Swarm and vLLM across 24 X NVIDIA H100\nGPUs. Through human QA and system metrics, we demonstrate that grounded\ngeneration with explicit routing and layered safety can deliver trustworthy AI\ninsights in high-stakes finance.", "AI": {"tldr": "Production-scale, on-prem AI PB in Korean retail finance that proactively generates grounded, compliant, user-specific investment insights using layered routing, hybrid retrieval, and multi-stage recommender, with stringent safety.", "motivation": "Address high-stakes finance by delivering proactive, trustworthy investment insights while meeting data sensitivity and regulatory constraints.", "method": "A component-based orchestration layer routes between internal and external LLMs based on data sensitivity; a hybrid retrieval pipeline uses OpenSearch and finance-domain embeddings; a multi-stage recommender combines rule heuristics, sequential behavioral modeling, and contextual bandits; deploys on-premises using Docker Swarm and vLLM on 24 NVIDIA H100 GPUs; safety is enforced via grounding and layered QA.", "result": "Demonstrates grounded generation with explicit routing and layered safety; measured as trustworthy AI insights through human QA and system metrics in a real retail finance setting.", "conclusion": "It's feasible to deliver proactive, trustworthy investment insights in high-stakes finance with on-prem architecture, explicit routing, and layered safety controls."}}
{"id": "2510.19941", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19941", "abs": "https://arxiv.org/abs/2510.19941", "authors": ["Matan Tsipory", "Ran Levinstein", "Itay Evron", "Mark Kong", "Deanna Needell", "Daniel Soudry"], "title": "Are Greedy Task Orderings Better Than Random in Continual Linear Regression?", "comment": "Accepted to NeurIPS 2025", "summary": "We analyze task orderings in continual learning for linear regression,\nassuming joint realizability of training data. We focus on orderings that\ngreedily maximize dissimilarity between consecutive tasks, a concept briefly\nexplored in prior work but still surrounded by open questions. Using tools from\nthe Kaczmarz method literature, we formalize such orderings and develop\ngeometric and algebraic intuitions around them. Empirically, we demonstrate\nthat greedy orderings converge faster than random ones in terms of the average\nloss across tasks, both for linear regression with random data and for linear\nprobing on CIFAR-100 classification tasks. Analytically, in a high-rank\nregression setting, we prove a loss bound for greedy orderings analogous to\nthat of random ones. However, under general rank, we establish a\nrepetition-dependent separation. Specifically, while prior work showed that for\nrandom orderings, with or without replacement, the average loss after $k$\niterations is bounded by $\\mathcal{O}(1/\\sqrt{k})$, we prove that single-pass\ngreedy orderings may fail catastrophically, whereas those allowing repetition\nconverge at rate $\\mathcal{O}(1/\\sqrt[3]{k})$. Overall, we reveal nuances\nwithin and between greedy and random orderings.", "AI": {"tldr": "Greedy task orderings based on maximizing dissimilarity improve continual learning for linear regression in practice, but theoretical guarantees depend on rank; repetition matters.", "motivation": "Investigate how task orderings influence continual learning performance and clarify open questions around greedy dissimilarity orderings using Kaczmarz-method insights.", "method": "Formalize greedy dissimilarity orderings via Kaczmarz literature; derive geometric/algebraic intuition; conduct experiments on linear regression with random data and CIFAR-100 linear probing; prove theory: loss bound in high-rank setting; analyze rank-dependent behavior including single-pass vs repeated passes.", "result": "Empirically, greedy orderings converge faster than random on average loss; analytically, a high-rank setting yields a loss bound comparable to random; in general rank, single-pass greedy can fail catastrophically, while repeated-pass greedy converges at rate O(k^{-1/3}); distinct behaviors highlight nuance between greedy and random orderings.", "conclusion": "Greedy orderings offer practical benefits but come with rank-sensitive guarantees; allowing repetition mitigates worst-case failures; results enrich understanding of ordering in continual learning and guide design choices."}}
{"id": "2510.20390", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20390", "abs": "https://arxiv.org/abs/2510.20390", "authors": ["Yijiong Lin", "Bowen Deng", "Chenghua Lu", "Max Yang", "Efi Psomopoulou", "Nathan F. Lepora"], "title": "NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control", "comment": null, "summary": "Grasping accuracy is a critical prerequisite for precise object manipulation,\noften requiring careful alignment between the robot hand and object. Neural\nDescriptor Fields (NDF) offer a promising vision-based method to generate\ngrasping poses that generalize across object categories. However, NDF alone can\nproduce inaccurate poses due to imperfect camera calibration, incomplete point\nclouds, and object variability. Meanwhile, tactile sensing enables more precise\ncontact, but existing approaches typically learn policies limited to simple,\npredefined contact geometries. In this work, we introduce NeuralTouch, a\nmultimodal framework that integrates NDF and tactile sensing to enable\naccurate, generalizable grasping through gentle physical interaction. Our\napproach leverages NDF to implicitly represent the target contact geometry,\nfrom which a deep reinforcement learning (RL) policy is trained to refine the\ngrasp using tactile feedback. This policy is conditioned on the neural\ndescriptors and does not require explicit specification of contact types. We\nvalidate NeuralTouch through ablation studies in simulation and zero-shot\ntransfer to real-world manipulation tasks--such as peg-out-in-hole and bottle\nlid opening--without additional fine-tuning. Results show that NeuralTouch\nsignificantly improves grasping accuracy and robustness over baseline methods,\noffering a general framework for precise, contact-rich robotic manipulation.", "AI": {"tldr": "NeuralTouch fuses Neural Descriptor Fields with tactile feedback and RL to refine grasps, enabling accurate, generalizable contact-rich manipulation with zero-shot sim-to-real transfer.", "motivation": "NDF alone is sensitive to calibration and perception noise and tactile policies often rely on fixed contact geometries; a general, contact-rich approach is needed for robust manipulation across objects.", "method": "Represent target contact geometry via NDF; train a deep RL policy that uses tactile feedback to refine the grasp, conditioned on neural descriptors; no explicit contact-type specification; evaluate via ablations and zero-shot real-world tasks.", "result": "Ablation studies in simulation; zero-shot transfer to real-world tasks (peg-out-in-hole, bottle lid opening) without fine-tuning; improved grasping accuracy and robustness over baselines.", "conclusion": "NeuralTouch offers a general, multimodal framework for precise, contact-rich robotic manipulation by combining vision-based descriptors with tactile feedback, improving robustness and transferability."}}
{"id": "2510.20087", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20087", "abs": "https://arxiv.org/abs/2510.20087", "authors": ["Lorenzo Arboit", "Dennis N. Schneider", "Britty Baby", "Vinkle Srivastav", "Pietro Mascagni", "Nicolas Padoy"], "title": "Endoshare: A Source Available Solution to De-Identify and Manage Surgical Videos", "comment": "13 pages, 6 figures. Source-available software:\n  https://camma-public.github.io/Endoshare/", "summary": "Video-based assessment and surgical data science can advance surgical\ntraining, research, and quality improvement. However, widespread use remains\nlimited by heterogeneous recording formats and privacy concerns associated with\nvideo sharing. We present Endoshare, a source-available, cross-platform\napplication for merging, standardizing, and de-identifying endoscopic videos in\nminimally invasive surgery. Development followed the software development life\ncycle with iterative, user-centered feedback. During the analysis phase, an\ninternal survey of clinicians and computer scientists based on ten usability\nheuristics identified key requirements that guided a privacy-by-design\narchitecture. In the testing phase, an external clinician survey combined the\nsame heuristics with Technology Acceptance Model constructs to assess usability\nand adoption, complemented by benchmarking across different hardware\nconfigurations. Four clinicians and four computer scientists initially tested\nthe prototype, reporting high usability (4.68 +/- 0.40/5 and 4.03 +/- 0.51/5),\nwith the lowest score (4.00 +/- 0.93/5) relating to label clarity. After\nrefinement, the testing phase surveyed ten surgeons who reported high perceived\nusefulness (5.07 +/- 1.75/7), ease of use (5.15 +/- 1.71/7), heuristic\nusability (4.38 +/- 0.48/5), and strong recommendation (9.20 +/- 0.79/10).\nProcessing time varied with processing mode, video duration (both p <= 0.001),\nand machine computational power (p = 0.041). Endoshare provides a transparent,\nuser-friendly pipeline for standardized, privacy-preserving surgical video\nmanagement. Compliance certification and broader interoperability validation\nare needed to establish it as a deployable alternative to proprietary systems.\nThe software is available at https://camma-public.github.io/Endoshare/", "AI": {"tldr": "Endoshare is a source-available, cross-platform tool to merge, standardize, and de-identify endoscopic videos in MIS, showing high usability and adoption potential, but requiring compliance and interoperability validation for deployment.", "motivation": "To overcome heterogeneity in recording formats and privacy concerns in surgical video sharing, enabling standardized, privacy-preserving video management for training, research, and quality improvement.", "method": "Software development lifecycle with iterative, user-centered feedback; internal usability heuristics survey; external clinician survey combining heuristics with Technology Acceptance Model; benchmarking across hardware; development of a privacy-by-design architecture.", "result": "Prototype scored high in usability (clinicians 4.68\u00b10.40/5; 4.03\u00b10.51/5; lowest label clarity 4.00\u00b10.93/5); after refinement, ten surgeons reported high perceived usefulness (5.07\u00b11.75/7), ease of use (5.15\u00b11.71/7), heuristic usability (4.38\u00b10.48/5), and strong recommendation (9.20\u00b10.79/10); processing time varied with mode, video duration (both p\u22640.001), and hardware (p=0.041).", "conclusion": "Endoshare provides a transparent, user-friendly pipeline for standardized, privacy-preserving surgical video management; compliance certification and broader interoperability validation are needed to establish it as a deployable alternative to proprietary systems."}}
{"id": "2510.20102", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20102", "abs": "https://arxiv.org/abs/2510.20102", "authors": ["Gyuyeon Na", "Minjung Park", "Hyeonjeong Cha", "Sangmi Chai"], "title": "Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions", "comment": null, "summary": "We present HCLA, a human-centered multi-agent system for anomaly detection in\ndigital asset transactions. The system links three roles: Parsing, Detection,\nand Explanation, into a conversational workflow that lets non-experts ask\nquestions in natural language, inspect structured analytics, and obtain\ncontext-aware rationales. Implemented with an open-source web UI, HCLA\ntranslates user intents into a schema for a classical detector (XGBoost in our\nprototype) and returns narrative explanations grounded in the underlying\nfeatures. On a labeled Bitcoin mixing dataset (Wasabi Wallet, 2020-2024), the\nbaseline detector reaches strong accuracy, while HCLA adds interpretability and\ninteractive refinement. We describe the architecture, interaction loop,\ndataset, evaluation protocol, and limitations, and discuss how a\nhuman-in-the-loop design improves transparency and trust in financial\nforensics.", "AI": {"tldr": "HCLA is a human-centered multi-agent system that makes anomaly detection in digital asset transactions more interpretable and interactive by coupling an NL-driven parsing/detection/explanation workflow with an XGBoost detector; it preserves accuracy while providing feature-grounded narrative explanations on a Wasabi Wallet Bitcoin-mixing dataset.", "motivation": "Transparency and accessibility in financial forensics: non-experts should be able to ask questions in natural language and receive understandable, feature-grounded rationales; also to translate user intents into detector schemas for improved trust.", "method": "Three-agent roles (Parsing, Detection, Explanation) form a conversational loop in an open-source web UI. User intents are translated into a detector schema (XGBoost used in prototype) and accompanied by narrative explanations grounded in features. Evaluated on a labeled Wasabi Wallet Bitcoin-mixing dataset (2020\u20132024).", "result": "Baseline detector achieves strong accuracy; HCLA adds interpretability and allows interactive refinement without sacrificing performance. Architecture, interaction loop, dataset, and evaluation protocol are described, along with limitations.", "conclusion": "A human-in-the-loop design enhances transparency and trust in financial forensics by making anomaly detection more explainable and controllable for non-experts."}}
{"id": "2510.19950", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.19950", "abs": "https://arxiv.org/abs/2510.19950", "authors": ["Shaocong Ma", "Heng Huang"], "title": "Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets", "comment": null, "summary": "In financial applications, reinforcement learning (RL) agents are commonly\ntrained on historical data, where their actions do not influence prices.\nHowever, during deployment, these agents trade in live markets where their own\ntransactions can shift asset prices, a phenomenon known as market impact. This\nmismatch between training and deployment environments can significantly degrade\nperformance. Traditional robust RL approaches address this model\nmisspecification by optimizing the worst-case performance over a set of\nuncertainties, but typically rely on symmetric structures that fail to capture\nthe directional nature of market impact. To address this issue, we develop a\nnovel class of elliptic uncertainty sets. We establish both implicit and\nexplicit closed-form solutions for the worst-case uncertainty under these sets,\nenabling efficient and tractable robust policy evaluation. Experiments on\nsingle-asset and multi-asset trading tasks demonstrate that our method achieves\nsuperior Sharpe ratio and remains robust under increasing trade volumes,\noffering a more faithful and scalable approach to RL in financial markets.", "AI": {"tldr": "Introduces elliptic uncertainty sets to model market impact in robust RL for trading; derives closed-form worst-case solutions enabling efficient robust policy evaluation; demonstrates improved Sharpe ratio and robustness to higher trade volumes.", "motivation": "Mismatch between training on historical data (actions do not affect prices) and deployment in live markets (actions shift prices). Traditional symmetric robust methods fail to capture directional market impact.", "method": "Proposes a novel class of elliptic uncertainty sets representing directional uncertainty; derives implicit and explicit closed-form solutions for worst-case uncertainty; applies to robust policy evaluation in RL for trading.", "result": "Single-asset and multi-asset trading experiments show superior Sharpe ratio and robust performance as trade volumes increase.", "conclusion": "Elliptic uncertainty sets offer a faithful, scalable approach for robust RL in financial markets with market impact, improving evaluation and potential deployment robustness over symmetric models."}}
{"id": "2510.20406", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20406", "abs": "https://arxiv.org/abs/2510.20406", "authors": ["Xiaogang Jia", "Qian Wang", "Anrui Wang", "Han A. Wang", "Bal\u00e1zs Gyenes", "Emiliyan Gospodinov", "Xinkai Jiang", "Ge Li", "Hongyi Zhou", "Weiran Liao", "Xi Huang", "Maximilian Beck", "Moritz Reuss", "Rudolf Lioutikov", "Gerhard Neumann"], "title": "PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning", "comment": null, "summary": "Robotic manipulation systems benefit from complementary sensing modalities,\nwhere each provides unique environmental information. Point clouds capture\ndetailed geometric structure, while RGB images provide rich semantic context.\nCurrent point cloud methods struggle to capture fine-grained detail, especially\nfor complex tasks, which RGB methods lack geometric awareness, which hinders\ntheir precision and generalization. We introduce PointMapPolicy, a novel\napproach that conditions diffusion policies on structured grids of points\nwithout downsampling. The resulting data type makes it easier to extract shape\nand spatial relationships from observations, and can be transformed between\nreference frames. Yet due to their structure in a regular grid, we enable the\nuse of established computer vision techniques directly to 3D data. Using xLSTM\nas a backbone, our model efficiently fuses the point maps with RGB data for\nenhanced multi-modal perception. Through extensive experiments on the RoboCasa\nand CALVIN benchmarks and real robot evaluations, we demonstrate that our\nmethod achieves state-of-the-art performance across diverse manipulation tasks.\nThe overview and demos are available on our project page:\nhttps://point-map.github.io/Point-Map/", "AI": {"tldr": "Diffusion-based policy conditioned on structured, non-downsampled point maps fused with RGB (via xLSTM) for multi-modal robotic manipulation, achieving state-of-the-art on RoboCasa/CALVIN and real robots.", "motivation": "Combine geometric detail from point clouds with semantic context from RGB images to overcome the limitations of relying on a single modality in robotic manipulation, improving precision and generalization.", "method": "Introduce PointMapPolicy that uses structured grids of points (point maps) without downsampling, enabling the use of standard computer vision techniques on 3D data. Fuse point maps with RGB through an xLSTM backbone to form a diffusion-conditioned policy. The approach supports frame-aligned data and avoids loss of fine details, tested on RoboCasa and CALVIN benchmarks and real robots.", "result": "Achieves state-of-the-art performance across diverse manipulation tasks on RoboCasa and CALVIN benchmarks and in real-robot experiments.", "conclusion": "Structured 3D point maps, when fused with RGB in a diffusion-driven policy, enhance geometric awareness and multi-modal perception for robotic manipulation, with strong empirical validation and accessible resources on the project page."}}
{"id": "2510.20092", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20092", "abs": "https://arxiv.org/abs/2510.20092", "authors": ["Hao Yu", "Haoyu Chen", "Yan Jiang", "Wei Peng", "Zhaodong Sun", "Samuel Kaski", "Guoying Zhao"], "title": "Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency", "comment": null, "summary": "Self-attention (SA) has become the cornerstone of modern vision backbones for\nits powerful expressivity over traditional Convolutions (Conv). However, its\nquadratic complexity remains a critical bottleneck for practical applications.\nGiven that Conv offers linear complexity and strong visual priors, continuing\nefforts have been made to promote the renaissance of Conv. However, a\npersistent performance chasm remains, highlighting that these modernizations\nhave not yet captured the intrinsic expressivity that defines SA. In this\npaper, we re-examine the design of the CNNs, directed by a key question: what\nprinciples give SA its edge over Conv? As a result, we reveal two fundamental\ninsights that challenge the long-standing design intuitions in prior research\n(e.g., Receptive field). The two findings are: (1) \\textit{Adaptive routing}:\nSA dynamically regulates positional information flow according to semantic\ncontent, whereas Conv employs static kernels uniformly across all positions.\n(2) \\textit{Lateral inhibition}: SA induces score competition among token\nweighting, effectively suppressing redundancy and sharpening representations,\nwhereas Conv filters lack such inhibitory dynamics and exhibit considerable\nredundancy. Based on this, we propose \\textit{Attentive Convolution} (ATConv),\na principled reformulation of the convolutional operator that intrinsically\ninjects these principles. Interestingly, with only $3\\times3$ kernels, ATConv\nconsistently outperforms various SA mechanisms in fundamental vision tasks.\nBuilding on ATConv, we introduce AttNet, a CNN family that can attain\n\\textbf{84.4\\%} ImageNet-1K Top-1 accuracy with only 27M parameters. In\ndiffusion-based image generation, replacing all SA with the proposed $3\\times\n3$ ATConv in SiT-XL/2 reduces ImageNet FID by 0.15 in 400k steps with faster\nsampling. Code is available at: github.com/price112/Attentive-Convolution.", "AI": {"tldr": "Attentive Convolution (ATConv) reformulates convolution to inject SA-style adaptive routing and lateral inhibition, bridging CNNs and self-attention with linear complexity. With 3x3 kernels, ATConv-based AttNet achieves strong ImageNet results (84.4% Top-1 with 27M params) and improves diffusion-model quality (FID drop of 0.15 at 400k steps) with faster sampling; code released.", "motivation": "Self-attention offers strong expressivity but has quadratic complexity; conventional convolutions are efficient but lack SA-like expressivity. The paper seeks to identify the core principles that give SA its edge and integrate them into CNN design to obtain high performance with efficiency.", "method": "Introduce Attentive Convolution (ATConv), a principled reformulation of convolution that incorporates two SA-inspired principles: (1) Adaptive routing, which modulates how positional information is propagated based on semantic content; (2) Lateral inhibition, which enables score competition among tokens to suppress redundancy. Build AttNet, a CNN family using ATConv (notably with 3x3 kernels) and evaluate in vision tasks and diffusion models.", "result": "ATConv with 3x3 kernels consistently surpasses various SA mechanisms on fundamental vision tasks. AttNet reaches 84.4% ImageNet-1K Top-1 with 27M parameters. In diffusion-based image generation, replacing SA with ATConv in SiT-XL/2 reduces ImageNet FID by 0.15 in 400k steps and enables faster sampling.", "conclusion": "ATConv provides a principled, efficient route to capture SA-like expressivity within CNNs, closing much of the performance gap while maintaining low computational cost. AttNet demonstrates strong practical performance, and the approach is applicable to diffusion models. Code is publicly available."}}
{"id": "2510.20109", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20109", "abs": "https://arxiv.org/abs/2510.20109", "authors": ["Joshua Yuvaraj"], "title": "The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice", "comment": null, "summary": "It is often claimed that machine learning-based generative AI products will\ndrastically streamline and reduce the cost of legal practice. This enthusiasm\nassumes lawyers can effectively manage AI's risks. Cases in Australia and\nelsewhere in which lawyers have been reprimanded for submitting inaccurate\nAI-generated content to courts suggest this paradigm must be revisited. This\npaper argues that a new paradigm is needed to evaluate AI use in practice,\ngiven (a) AI's disconnection from reality and its lack of transparency, and (b)\nlawyers' paramount duties like honesty, integrity, and not to mislead the\ncourt. It presents an alternative model of AI use in practice that more\nholistically reflects these features (the verification-value paradox). That\nparadox suggests increases in efficiency from AI use in legal practice will be\nmet by a correspondingly greater imperative to manually verify any outputs of\nthat use, rendering the net value of AI use often negligible to lawyers. The\npaper then sets out the paradox's implications for legal practice and legal\neducation, including for AI use but also the values that the paradox suggests\nshould undergird legal practice: fidelity to the truth and civic\nresponsibility.", "AI": {"tldr": "A normative argument for a new paradigm in AI-assisted legal practice, introducing the \u201cverification-value paradox\u201d: efficiency gains from AI are counterbalanced by a greater need for manual verification due to AI\u2019s disconnection from reality and opacity, leading to an emphasis on truthfulness and civic responsibility in law education and practice.", "motivation": "The surge of generative AI in law promises cost savings, but documented missteps where lawyers rely on erroneous AI outputs threaten legal integrity; a new framework is needed to align AI use with professional duties and avoid misleading courts.", "method": "Normative-analytic approach that highlights AI limitations (hallucination, opacity) and lawyers\u2019 duties; introduces the verification-value paradox and derives practical and educational implications for practice and policy.", "result": "The paradox suggests efficiency gains are often offset by verification burdens, resulting in negligible net value in many AI-assisted tasks; the paper outlines implications for practice, governance, and education grounded in fidelity to truth and civic responsibility.", "conclusion": "To responsibly integrate AI into legal work, the field should adopt values-centered guidelines that prioritize verification, transparency, and accountability, shaping both practice and legal education around truth-telling and public duty."}}
{"id": "2510.19953", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.19953", "abs": "https://arxiv.org/abs/2510.19953", "authors": ["Shaocong Ma", "Heng Huang"], "title": "On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization", "comment": null, "summary": "Zeroth-order optimization (ZOO) is an important framework for stochastic\noptimization when gradients are unavailable or expensive to compute. A\npotential limitation of existing ZOO methods is the bias inherent in most\ngradient estimators unless the perturbation stepsize vanishes. In this paper,\nwe overcome this biasedness issue by proposing a novel family of unbiased\ngradient estimators based solely on function evaluations. By reformulating\ndirectional derivatives as a telescoping series and sampling from carefully\ndesigned distributions, we construct estimators that eliminate bias while\nmaintaining favorable variance. We analyze their theoretical properties, derive\noptimal scaling distributions and perturbation stepsizes of four specific\nconstructions, and prove that SGD using the proposed estimators achieves\noptimal complexity for smooth non-convex objectives. Experiments on synthetic\ntasks and language model fine-tuning confirm the superior accuracy and\nconvergence of our approach compared to standard methods.", "AI": {"tldr": "Proposes a family of unbiased zeroth-order gradient estimators that rely only on function evaluations, by reformulating directional derivatives as a telescoping series and sampling from carefully designed distributions; proves optimal SGD complexity for smooth non-convex objectives and validates with synthetic tasks and language-model fine-tuning.", "motivation": "Standard ZOO estimators are biased unless perturbation stepsizes vanish, which can hinder practical optimization. There is a need for unbiased gradient estimators that use only function evaluations while maintaining tractable variance.", "method": "Reformulate directional derivatives as a telescoping series and sample from carefully designed distributions to construct unbiased gradient estimators. Develop four constructions with specific scaling distributions and perturbation stepsizes. Analyze bias-variance properties and derive optimal parameters; apply SGD with these estimators to smooth non-convex objectives.", "result": "The estimators are proven unbiased; variance is controlled with favorable properties. Theoretical analysis yields optimal scaling distributions and perturbation stepsizes for the four constructions. SGD using these estimators achieves optimal complexity for smooth non-convex objectives. Experiments on synthetic tasks and language-model fine-tuning demonstrate improved accuracy and convergence over standard ZOO methods.", "conclusion": "Unbiased, function-evaluation-based ZOO estimators can eliminate bias without sacrificing efficiency, enabling near-optimal SGD performance on non-convex problems and broad practical applicability, including language-model fine-tuning."}}
{"id": "2510.20407", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20407", "abs": "https://arxiv.org/abs/2510.20407", "authors": ["Kohei Nishi", "Masato Kobayashi", "Yuki Uranishi"], "title": "MR-UBi: Mixed Reality-Based Underwater Robot Arm Teleoperation System with Reaction Torque Indicator via Bilateral Control", "comment": null, "summary": "We present a mixed reality-based underwater robot arm teleoperation system\nwith a reaction torque indicator via bilateral control (MR-UBi). The reaction\ntorque indicator (RTI) overlays a color and length-coded torque bar in the\nMR-HMD, enabling seamless integration of visual and haptic feedback during\nunderwater robot arm teleoperation. User studies with sixteen participants\ncompared MR-UBi against a bilateral-control baseline. MR-UBi significantly\nimproved grasping-torque control accuracy, increasing the time within the\noptimal torque range and reducing both low and high grasping torque range\nduring lift and pick-and-place tasks with objects of different stiffness.\nSubjective evaluations further showed higher usability (SUS) and lower workload\n(NASA--TLX). Overall, the results confirm that \\textit{MR-UBi} enables more\nstable, accurate, and user-friendly underwater robot-arm teleoperation through\nthe integration of visual and haptic feedback. For additional material, please\ncheck: https://mertcookimg.github.io/mr-ubi", "AI": {"tldr": "A mixed-reality underwater teleoperation system (MR-UBi) with a reaction-torque indicator, driven by bilateral control, enhances visual-haptic feedback to improve torque control, usability, and workload during robot-arm manipulation.", "motivation": "Underwater teleoperation suffers from imperfect torque feedback and cognitive load; integrating intuitive visual torque cues with haptic information could improve stability, accuracy, and operator experience.", "method": "Implemented MR-UBi with a reaction torque indicator (RTI) overlay in a MR-HMD using color- and length-coded torque bars. Evaluated against a bilateral-control baseline with 16 participants on lift/pick-and-place tasks across objects of varying stiffness.", "result": "MR-UBi significantly improved grasping-torque control accuracy by increasing time within the optimal torque range and reducing both low- and high-torque events. Subjective measures showed higher usability (SUS) and lower workload (NASA-TLX).", "conclusion": "Integrating visual torque cues with haptic feedback via MR-UBi yields more stable, accurate, and user-friendly underwater robot-arm teleoperation, demonstrating the value of multimodal feedback in complex teleoperation environments."}}
{"id": "2510.20093", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20093", "abs": "https://arxiv.org/abs/2510.20093", "authors": ["Jiho Park", "Sieun Choi", "Jaeyoon Seo", "Jihie Kim"], "title": "StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback", "comment": "Under review at IEEE Access. Author-submitted preprint. Not the\n  IEEE-published version", "summary": "Although recent advancements in diffusion models have significantly enriched\nthe quality of generated images, challenges remain in synthesizing pixel-based\nhuman-drawn sketches, a representative example of abstract expression. To\ncombat these challenges, we propose StableSketcher, a novel framework that\nempowers diffusion models to generate hand-drawn sketches with high prompt\nfidelity. Within this framework, we fine-tune the variational autoencoder to\noptimize latent decoding, enabling it to better capture the characteristics of\nsketches. In parallel, we integrate a new reward function for reinforcement\nlearning based on visual question answering, which improves text-image\nalignment and semantic consistency. Extensive experiments demonstrate that\nStableSketcher generates sketches with improved stylistic fidelity, achieving\nbetter alignment with prompts compared to the Stable Diffusion baseline.\nAdditionally, we introduce SketchDUO, to the best of our knowledge, the first\ndataset comprising instance-level sketches paired with captions and\nquestion-answer pairs, thereby addressing the limitations of existing datasets\nthat rely on image-label pairs. Our code and dataset will be made publicly\navailable upon acceptance.", "AI": {"tldr": "Proposes StableSketcher to generate hand-drawn sketches with high prompt fidelity by VAE latent-decoding fine-tuning and a VQA-based RL reward; introduces SketchDUO dataset with instance-level sketches, captions, and Q&A; claims improved stylistic fidelity and prompt alignment over Stable Diffusion; code/dataset to be released.", "motivation": "Bridge the gap between diffusion-based image synthesis and the creation of pixel-based, human-drawn sketches, which require different stylistic and semantic alignment than typical photo-realistic images. Current datasets lack well-aligned, instance-level sketch data with rich textual annotations.", "method": "Fine-tune the VAE to better model sketch latent spaces for diffusion-based generation. Introduce a reinforcement learning objective with a reward grounded in visual question answering to optimize text-image alignment and semantic consistency during generation. Create SketchDUO, a dataset pairing instance-level sketches with captions and QA pairs to support evaluation and training.", "result": "Empirically, StableSketcher yields sketches with improved stylistic fidelity and better prompt alignment compared to a Stable Diffusion baseline. SketchDUO is introduced as the first dataset with instance-level sketches paired with captions and QA pairs.", "conclusion": "StableSketcher advances sketch synthesis by aligning generated sketches more closely with prompts and stylistic cues; SketchDUO fills a dataset gap for evaluation and training incorporating sketches with richer textual annotations. Code and dataset to be released."}}
{"id": "2510.20188", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20188", "abs": "https://arxiv.org/abs/2510.20188", "authors": ["Morris Yu-Chao Huang", "Zhen Tan", "Mohan Zhang", "Pingzhi Li", "Zhuo Zhang", "Tianlong Chen"], "title": "TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning", "comment": null, "summary": "Large Language Models generate complex reasoning chains that reveal their\ndecision-making, yet verifying the faithfulness and harmlessness of these\nintermediate steps remains a critical unsolved problem. Existing auditing\nmethods are centralized, opaque, and hard to scale, creating significant risks\nfor deploying proprietary models in high-stakes domains. We identify four core\nchallenges: (1) Robustness: Centralized auditors are single points of failure,\nprone to bias or attacks. (2) Scalability: Reasoning traces are too long for\nmanual verification. (3) Opacity: Closed auditing undermines public trust. (4)\nPrivacy: Exposing full reasoning risks model theft or distillation. We propose\nTRUST, a transparent, decentralized auditing framework that overcomes these\nlimitations via: (1) A consensus mechanism among diverse auditors, guaranteeing\ncorrectness under up to $30\\%$ malicious participants. (2) A hierarchical DAG\ndecomposition of reasoning traces, enabling scalable, parallel auditing. (3) A\nblockchain ledger that records all verification decisions for public\naccountability. (4) Privacy-preserving segmentation, sharing only partial\nreasoning steps to protect proprietary logic. We provide theoretical guarantees\nfor the security and economic incentives of the TRUST framework. Experiments\nacross multiple LLMs (GPT-OSS, DeepSeek-r1, Qwen) and reasoning tasks (math,\nmedical, science, humanities) show TRUST effectively detects reasoning flaws\nand remains robust against adversarial auditors. Our work pioneers\ndecentralized AI auditing, offering a practical path toward safe and\ntrustworthy LLM deployment.", "AI": {"tldr": "TRUST proposes a decentralized auditing framework for LLM reasoning traces that combines a consensus among diverse auditors, a hierarchical DAG decomposition for scalable verification, a blockchain ledger for public accountability, and privacy-preserving segmentation to protect proprietary logic. It provides theoretical security and incentive guarantees and demonstrates robustness and effectiveness across multiple models and reasoning tasks.", "motivation": "Current auditing of LLM reasoning is centralized, opaque, and hard to scale, posing risks for deploying proprietary models in high-stakes domains. There is a need for robust, scalable, transparent, and privacy-preserving auditing.", "method": "1) A consensus mechanism that tolerates up to 30% malicious auditors; 2) Hierarchical DAG decomposition of reasoning traces enabling parallel, scalable auditing; 3) A blockchain ledger recording all verification decisions for public accountability; 4) Privacy-preserving segmentation sharing only partial reasoning steps to protect proprietary logic; 5) Theoretical guarantees of security and economic incentives; 6) Empirical evaluation across LLMs (GPT-OSS, DeepSeek-r1, Qwen) and tasks (math, medical, science, humanities).", "result": "Experiments show that TRUST effectively detects reasoning flaws and remains robust against adversarial auditors across multiple LLMs and reasoning domains.", "conclusion": "Decentralized AI auditing is a practical path toward safe and trustworthy LLM deployment, offering transparency, robustness, and privacy-preserving governance for high-stakes applications."}}
{"id": "2510.19975", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.19975", "abs": "https://arxiv.org/abs/2510.19975", "authors": ["Shaocong Ma", "Heng Huang"], "title": "Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations", "comment": null, "summary": "In this paper, we explore the two-point zeroth-order gradient estimator and\nidentify the distribution of random perturbations that minimizes the\nestimator's asymptotic variance as the perturbation stepsize tends to zero. We\nformulate it as a constrained functional optimization problem over the space of\nperturbation distributions. Our findings reveal that such desired perturbations\ncan align directionally with the true gradient, instead of maintaining a fixed\nlength. While existing research has largely focused on fixed-length\nperturbations, the potential advantages of directional alignment have been\noverlooked. To address this gap, we delve into the theoretical and empirical\nproperties of the directionally aligned perturbation (DAP) scheme, which\nadaptively offers higher accuracy along critical directions. Additionally, we\nprovide a convergence analysis for stochastic gradient descent using\n$\\delta$-unbiased random perturbations, extending existing complexity bounds to\na wider range of perturbations. Through empirical evaluations on both synthetic\nproblems and practical tasks, we demonstrate that DAPs outperform traditional\nmethods under specific conditions.", "AI": {"tldr": "The paper optimizes perturbation distributions for two-point zeroth-order gradient estimators to minimize asymptotic variance; shows directional alignment with the true gradient can outperform fixed-length perturbations; introduces the directionally aligned perturbation (DAP) scheme, provides convergence analysis for SGD with delta-unbiased perturbations, and shows empirical gains under certain conditions.", "motivation": "ZO methods often rely on fixed-length random perturbations, which may ignore directional information of the true gradient. Reducing estimator variance and extending theory to broader perturbation classes could improve efficiency and convergence.", "method": "Formulate a constrained functional optimization over perturbation distributions to minimize estimator variance as perturbation step size tends to zero; derive a directionally aligned perturbation (DAP) scheme that aligns perturbations with the gradient; provide convergence analysis for SGD using delta-unbiased perturbations; perform empirical evaluations on synthetic problems and practical tasks.", "result": "Optimal perturbations that minimize asymptotic variance tend to align with the gradient rather than have fixed magnitude; DAP improves accuracy along critical directions; convergence bounds are extended to a broader class of perturbations; empirical results show DAPs outperform traditional methods under certain conditions.", "conclusion": "Directional alignment in perturbations is a viable approach to variance reduction in zeroth-order optimization; the DAP framework offers both theoretical and empirical benefits and warrants further exploration of condition-specific perturbation strategies."}}
{"id": "2510.20473", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20473", "abs": "https://arxiv.org/abs/2510.20473", "authors": ["Bernhard Rameder", "Hubert Gattringer", "Andreas Mueller", "Ronald Naderer"], "title": "Robot Path and Trajectory Planning Considering a Spatially Fixed TCP", "comment": null, "summary": "This paper presents a method for planning a trajectory in workspace\ncoordinates using a spatially fixed tool center point (TCP), while taking into\naccount the processing path on a part. This approach is beneficial if it is\neasier to move the part rather than moving the tool. Whether a mathematical\ndescription that defines the shape to be processed or single points from a\ndesign program are used, the robot path is finally represented using B-splines.\nThe use of splines enables the path to be continuous with a desired degree,\nwhich finally leads to a smooth robot trajectory. While calculating the robot\ntrajectory through prescribed orientation, additionally a given velocity at the\nTCP has to be considered. The procedure was validated on a real system using an\nindustrial robot moving an arbitrary defined part.", "AI": {"tldr": "A method for planning robot trajectories with a fixed tool center point by moving the workpiece, using B-splines to produce smooth, orientation-constrained paths, validated on a real industrial robot.", "motivation": "To enable smooth, orientation-aware trajectory planning in scenarios where it is easier to move the workpiece than the tool, and to ensure continuity and feasibility of the robot path.", "method": "Represent the motion in workspace coordinates with a spatially fixed TCP, model the processing path (from design points or a defined shape) with B-splines to ensure smoothness, enforce prescribed orientation and a specific TCP velocity during trajectory generation, and validate the approach on a real industrial robot moving an arbitrarily defined part.", "result": "A continuous, smooth robot trajectory was generated and validated on a real system, demonstrating feasibility of the approach for fixed TCP with part movement.", "conclusion": "The proposed framework enables practical trajectory planning under a fixed TCP by coordinating part movement and spline-based path generation, yielding smooth, orientation-consistent motion demonstrated experimentally."}}
{"id": "2510.20095", "categories": ["cs.CV", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20095", "abs": "https://arxiv.org/abs/2510.20095", "authors": ["Ziheng Zhang", "Xinyue Ma", "Arpita Chowdhury", "Elizabeth G. Campolongo", "Matthew J. Thompson", "Net Zhang", "Samuel Stevens", "Hilmar Lapp", "Tanya Berger-Wolf", "Yu Su", "Wei-Lun Chao", "Jianyang Gu"], "title": "BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models", "comment": "Project page: https://imageomics.github.io/biocap/", "summary": "This work investigates descriptive captions as an additional source of\nsupervision for biological multimodal foundation models. Images and captions\ncan be viewed as complementary samples from the latent morphospace of a\nspecies, each capturing certain biological traits. Incorporating captions\nduring training encourages alignment with this shared latent structure,\nemphasizing potentially diagnostic characters while suppressing spurious\ncorrelations. The main challenge, however, lies in obtaining faithful,\ninstance-specific captions at scale. This requirement has limited the\nutilization of natural language supervision in organismal biology compared with\nmany other scientific domains. We complement this gap by generating synthetic\ncaptions with multimodal large language models (MLLMs), guided by\nWikipedia-derived visual information and taxon-tailored format examples. These\ndomain-specific contexts help reduce hallucination and yield accurate,\ninstance-based descriptive captions. Using these captions, we train BIOCAP\n(i.e., BIOCLIP with Captions), a biological foundation model that captures rich\nsemantics and achieves strong performance in species classification and\ntext-image retrieval. These results demonstrate the value of descriptive\ncaptions beyond labels in bridging biological images with multimodal foundation\nmodels.", "AI": {"tldr": "The paper introduces BIOCAP, a biological foundation model trained with synthetic descriptive captions generated by multimodal LLMs to align images with richer textual supervision, improving species classification and text-image retrieval beyond label-only methods.", "motivation": "Descriptive captions can reveal diagnostic biological traits and reduce reliance on spurious correlations, but collecting faithful, instance-specific captions at scale is challenging in organismal biology. Synthetic captions guided by domain knowledge can bridge this gap.", "method": "Generate synthetic, descriptive captions using multimodal large language models guided by Wikipedia-derived visual information and taxon-tailored prompts; train BIOCAP (BIOCLIP with Captions) to align image and caption modalities, leveraging the richer supervision from captions.", "result": "BIOCAP achieves strong performance in species classification and text-image retrieval, demonstrating that descriptive captions provide valuable supervision beyond labels and help bridge biological images with multimodal foundation models.", "conclusion": "Descriptive captions are a valuable source of supervision for biological multimodal models, and synthetic captions produced by MLLMs can unlock robust, instance-aware language supervision at scale."}}
{"id": "2510.20190", "categories": ["cs.AI", "cs.IT", "math.IT", "68T07 (Primary) 92B20, 37N25, 68Q32, 94A17 (Secondary)", "I.2.6; I.2.7; I.2.4; I.2.0"], "pdf": "https://arxiv.org/pdf/2510.20190", "abs": "https://arxiv.org/abs/2510.20190", "authors": ["Marcelo Maciel Amaral", "Raymond Aschheim"], "title": "The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI", "comment": null, "summary": "Large language models (LLMs) remain broadly open and highly steerable: they\nimitate at scale, accept arbitrary system prompts, and readily adopt multiple\npersonae. By analogy to human development, we hypothesize that progress toward\nartificial general intelligence (AGI) involves a lock-in phase: a transition\nfrom open imitation to identity consolidation, in which goal structures,\nrefusals, preferences, and internal representations become comparatively stable\nand resistant to external steering. We formalize this phase, link it to known\nphenomena in learning dynamics, and propose operational metrics for onset\ndetection. Experimentally, we demonstrate that while the behavioral\nconsolidation is rapid and non-linear, its side-effects on general capabilities\nare not monolithic. Our results reveal a spectrum of outcomes--from performance\ntrade-offs in small models, through largely cost-free adoption in mid-scale\nmodels, to transient instabilities in large, quantized models. We argue that\nsuch consolidation is a prerequisite for AGI-level reliability and also a\ncritical control point for safety: identities can be deliberately engineered\nfor reliability, yet may also emerge spontaneously during scaling, potentially\nhardening unpredictable goals and behaviors.", "AI": {"tldr": "A 'lock-in' phase in LLM development marks a shift from open imitation to stable identities, with goal structures and refusals becoming resistant to steering. The paper formalizes this phase, proposes onset metrics, and shows rapid, nonlinear consolidation with varied effects on capabilities across model scales; it argues consolidation is key for AGI reliability and a critical safety control point.", "motivation": "To understand how scaling pushes LLMs toward stable, potentially autonomous identities, and to identify when and how this consolidation affects reliability and safety.", "method": "Formalize the consolidation phase, relate it to learning dynamics, develop operational metrics for onset detection, and empirically test across model scales to observe behavioral consolidation and side-effects on capabilities.", "result": "Consolidation is rapid and nonlinear. Side-effects on general capabilities vary: small models incur performance trade-offs, mid-scale models adopt behavior largely without cost, and large, quantized models show transient instabilities.", "conclusion": "Consolidation may be a prerequisite for AGI-level reliability and is a critical safety control point: identities can be engineered for reliability but may also emerge during scaling, potentially hardening unpredictable goals and behaviors."}}
{"id": "2510.19977", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.19977", "abs": "https://arxiv.org/abs/2510.19977", "authors": ["Hanbin Hong", "Ashish Kundu", "Ali Payani", "Binghui Wang", "Yuan Hong"], "title": "Towards Strong Certified Defense with Universal Asymmetric Randomization", "comment": "Accepted by CSF 2026, 39th IEEE Computer Security Foundations\n  Symposium", "summary": "Randomized smoothing has become essential for achieving certified adversarial\nrobustness in machine learning models. However, current methods primarily use\nisotropic noise distributions that are uniform across all data dimensions, such\nas image pixels, limiting the effectiveness of robustness certification by\nignoring the heterogeneity of inputs and data dimensions. To address this\nlimitation, we propose UCAN: a novel technique that \\underline{U}niversally\n\\underline{C}ertifies adversarial robustness with \\underline{A}nisotropic\n\\underline{N}oise. UCAN is designed to enhance any existing randomized\nsmoothing method, transforming it from symmetric (isotropic) to asymmetric\n(anisotropic) noise distributions, thereby offering a more tailored defense\nagainst adversarial attacks. Our theoretical framework is versatile, supporting\na wide array of noise distributions for certified robustness in different\n$\\ell_p$-norms and applicable to any arbitrary classifier by guaranteeing the\nclassifier's prediction over perturbed inputs with provable robustness bounds\nthrough tailored noise injection. Additionally, we develop a novel framework\nequipped with three exemplary noise parameter generators (NPGs) to optimally\nfine-tune the anisotropic noise parameters for different data dimensions,\nallowing for pursuing different levels of robustness enhancements in\npractice.Empirical evaluations underscore the significant leap in UCAN's\nperformance over existing state-of-the-art methods, demonstrating up to\n$182.6\\%$ improvement in certified accuracy at large certified radii on MNIST,\nCIFAR10, and ImageNet datasets.\\footnote{Code is anonymously available at\n\\href{https://github.com/youbin2014/UCAN/}{https://github.com/youbin2014/UCAN/}}", "AI": {"tldr": "UCAN introduces anisotropic noise into randomized smoothing to universally certify adversarial robustness, using three Noise Parameter Generators to tailor per-dimension noise; shows large certified-accuracy gains on MNIST, CIFAR-10, ImageNet.", "motivation": "Isotropic (uniform) noise in existing randomized smoothing ignores input-dimension heterogeneity, limiting robustness certification; a method to arbitrarily adapt noise across dimensions and norms, compatible with any classifier, is needed.", "method": "Propose UCAN framework that transforms any smoothing method from symmetric to asymmetric noise; supports diverse noise distributions for certifying robustness under different L_p norms; develop three Noise Parameter Generators (NPGs) to optimally tune per-dimension noise; provide theoretical foundation and implementation pipeline.", "result": "Empirical evaluation shows significant improvements over state-of-the-art, up to 182.6% increase in certified accuracy at large radii across MNIST, CIFAR-10, ImageNet.", "conclusion": "UCAN enables universal, anisotropic-noise certified robustness, broadening applicability of randomized smoothing and offering practical robustness gains; code available."}}
{"id": "2510.20480", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20480", "abs": "https://arxiv.org/abs/2510.20480", "authors": ["V\u00e1clav Pritzl", "Xianjia Yu", "Tomi Westerlund", "Petr \u0160t\u011bp\u00e1n", "Martin Saska"], "title": "Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization Leveraging LiDAR-Based Robot Detections", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Accurate long-term localization using onboard sensors is crucial for robots\noperating in Global Navigation Satellite System (GNSS)-denied environments.\nWhile complementary sensors mitigate individual degradations, carrying all the\navailable sensor types on a single robot significantly increases the size,\nweight, and power demands. Distributing sensors across multiple robots enhances\nthe deployability but introduces challenges in fusing asynchronous, multi-modal\ndata from independently moving platforms. We propose a novel adaptive\nmulti-modal multi-robot cooperative localization approach using a factor-graph\nformulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial\nOdometry (LIO), and 3D inter-robot detections from distinct robots in a\nloosely-coupled fashion. The approach adapts to changing conditions, leveraging\nreliable data to assist robots affected by sensory degradations. A novel\ninterpolation-based factor enables fusion of the unsynchronized measurements.\nLIO degradations are evaluated based on the approximate scan-matching Hessian.\nA novel approach of weighting odometry data proportionally to the Wasserstein\ndistance between the consecutive VIO outputs is proposed. A theoretical\nanalysis is provided, investigating the cooperative localization problem under\nvarious conditions, mainly in the presence of sensory degradations. The\nproposed method has been extensively evaluated on real-world data gathered with\nheterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial\nVehicles (UAVs), showing that the approach provides significant improvements in\nlocalization accuracy in the presence of various sensory degradations.", "AI": {"tldr": "An adaptive, loosely-coupled multi-robot localization framework that fuses asynchronous VIO, LIO, and 3D inter-robot detections using a factor graph, with interpolation-based fusion and degradation-aware weighting; demonstrated on UGV/UAV teams with improved localization under sensor faults.", "motivation": "Long-term, accurate localization in GNSS-denied environments is essential but challenging. Relying on a single robot's sensors increases size, weight, and power costs; distributing sensors across multiple robots improves deployability but requires robust fusion of asynchronous, multi-modal data.", "method": "A factor-graph-based cooperative localization approach that fuses asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial Odometry (LIO), and 3D inter-robot detections in a loosely-coupled manner. Introduces an interpolation-based factor to handle unsynchronized measurements. Evaluates LIO degradations via an approximate scan-matching Hessian and weights odometry data proportionally to the Wasserstein distance between consecutive VIO outputs. Includes theoretical analysis of cooperative localization under sensory degradations, and extensive real-world experiments with heterogeneous UGV/UAV teams.", "result": "The approach yields significant improvements in localization accuracy under various sensory degradations in real-world UGV/UAV experiments.", "conclusion": "Adaptive, multi-modal, multi-robot cooperative localization with interpolation-based fusion and degradation-aware weighting robustly enhances localization in GNSS-denied settings, leveraging cross-robot information to compensate for degraded sensors."}}
{"id": "2510.20126", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20126", "abs": "https://arxiv.org/abs/2510.20126", "authors": ["Prithvi Raj Singh", "Raju Gottumukkala", "Anthony S. Maida", "Alan B. Barhorst", "Vijaya Gopu"], "title": "Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects", "comment": "13 pages, 6 figures", "summary": "While computer vision has advanced considerably for general object detection\nand tracking, the specific problem of fast-moving tiny objects remains\nunderexplored. This paper addresses the significant challenge of detecting and\ntracking rapidly moving small objects using an RGB-D camera. Our novel system\ncombines deep learning-based detection with physics-based tracking to overcome\nthe limitations of existing approaches. Our contributions include: (1) a\ncomprehensive system design for object detection and tracking of fast-moving\nsmall objects in 3D space, (2) an innovative physics-based tracking algorithm\nthat integrates kinematics motion equations to handle outliers and missed\ndetections, and (3) an outlier detection and correction module that\nsignificantly improves tracking performance in challenging scenarios such as\nocclusions and rapid direction changes. We evaluated our proposed system on a\ncustom racquetball dataset. Our evaluation shows our system surpassing kalman\nfilter based trackers with up to 70\\% less Average Displacement Error. Our\nsystem has significant applications for improving robot perception on\nautonomous platforms and demonstrates the effectiveness of combining\nphysics-based models with deep learning approaches for real-time 3D detection\nand tracking of challenging small objects.", "AI": {"tldr": "A system that detects and tracks fast-moving small objects in 3D using RGB-D, merging deep learning detection with a physics-based tracker and an outlier correction module; evaluated on a racquetball dataset and outperforming Kalman-filter trackers by up to 70% reduction in Average Displacement Error.", "motivation": "Fast-moving tiny objects in 3D are underexplored; existing CV trackers struggle with occlusions and rapid changes; need robust perception for autonomous systems.", "method": "A combined pipeline: deep learning-based detection, physics-based tracking incorporating kinematic equations to predict states and handle outliers/missed detections, plus an outlier detection/correction module.", "result": "On a custom racquetball dataset, the approach surpasses Kalman-filter based trackers with up to 70% lower Average Displacement Error, demonstrating real-time 3D detection/tracking of small objects.", "conclusion": "Integrating physics-based models with deep learning improves 3D tracking of fast-moving small objects and has strong potential for robotics perception applications."}}
{"id": "2510.20205", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20205", "abs": "https://arxiv.org/abs/2510.20205", "authors": ["Maggie Bai", "Ava Kim Cohen", "Eleanor Koss", "Charlie Lichtenbaum"], "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "comment": "9 pages, 5 figures", "summary": "Optimizing artificial intelligence (AI) for dynamic environments remains a\nfundamental challenge in machine learning research. In this paper, we examine\nevolutionary training methods for optimizing AI to solve the game 2048, a 2D\nsliding puzzle. 2048, with its mix of strategic gameplay and stochastic\nelements, presents an ideal playground for studying decision-making, long-term\nplanning, and dynamic adaptation. We implemented two distinct systems: a\ntwo-agent metaprompting system where a \"thinker\" large language model (LLM)\nagent refines gameplay strategies for an \"executor\" LLM agent, and a\nsingle-agent system based on refining a value function for a limited Monte\nCarlo Tree Search. We also experimented with rollback features to avoid\nperformance degradation. Our results demonstrate the potential of evolutionary\nrefinement techniques in improving AI performance in non-deterministic\nenvironments. The single-agent system achieved substantial improvements, with\nan average increase of 473.2 points per cycle, and with clear upward trends\n(correlation $\\rho$=0.607) across training cycles. The LLM's understanding of\nthe game grew as well, shown in its development of increasingly advanced\nstrategies. Conversely, the two-agent system did not garner much improvement,\nhighlighting the inherent limits of meta-prompting.", "AI": {"tldr": "The paper compares evolutionary refinement approaches for AI in the stochastic game 2048, finding strong gains from a single-agent MCTS-based refinement, while a two-agent metaprompting system shows limited benefits.", "motivation": "Investigate how to optimize AI in dynamic, non-deterministic environments using role-based LLMs and search-based methods; use 2048 as a testbed; assess the value of rollback features.", "method": "Implemented two systems: (1) a two-agent metaprompting setup where a 'thinker' LLM refines strategies for an 'executor' LLM; (2) a single-agent system that refines a value function for a limited Monte Carlo Tree Search (MCTS). Explored rollback features to mitigate performance degradation. Evaluated across training cycles, reporting score changes and correlations.", "result": "Single-agent approach achieved an average increase of 473.2 points per cycle with clear upward trends (\u03c1=0.607) across cycles; the LLM improved its game strategies over time. The two-agent system showed limited improvement, exposing limits of meta-prompting.", "conclusion": "Evolutionary refinement techniques can enhance AI performance in non-deterministic environments, with the single-agent MCTS-based approach being more effective here. Meta-prompting via a two-agent setup has limited utility in this context; rollback features offer some stability benefits."}}
{"id": "2510.19980", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.19980", "abs": "https://arxiv.org/abs/2510.19980", "authors": ["Renzhao Liang", "Sizhe Xu", "Chenggang Xie", "Jingru Chen", "Feiyang Ren", "Shu Yang", "Takahiro Yabe"], "title": "Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency", "comment": "20 pages, 4 figures. Accepted as Spotlight poster in NeurIPS 2025", "summary": "Time series forecasting plays a pivotal role in critical domains such as\nenergy management and financial markets. Although deep learning-based\napproaches (e.g., MLP, RNN, Transformer) have achieved remarkable progress, the\nprevailing \"long-sequence information gain hypothesis\" exhibits inherent\nlimitations. Through systematic experimentation, this study reveals a\ncounterintuitive phenomenon: appropriately truncating historical data can\nparadoxically enhance prediction accuracy, indicating that existing models\nlearn substantial redundant features (e.g., noise or irrelevant fluctuations)\nduring training, thereby compromising effective signal extraction. Building\nupon information bottleneck theory, we propose an innovative solution termed\nAdaptive Masking Loss with Representation Consistency (AMRC), which features\ntwo core components: 1) Dynamic masking loss, which adaptively identified\nhighly discriminative temporal segments to guide gradient descent during model\ntraining; 2) Representation consistency constraint, which stabilized the\nmapping relationships among inputs, labels, and predictions. Experimental\nresults demonstrate that AMRC effectively suppresses redundant feature learning\nwhile significantly improving model performance. This work not only challenges\nconventional assumptions in temporal modeling but also provides novel\ntheoretical insights and methodological breakthroughs for developing efficient\nand robust forecasting models.", "AI": {"tldr": "A paradoxical finding: truncating historical data can improve time-series forecasting performance. The paper introduces AMRC to suppress redundant features and boost accuracy.", "motivation": "Challenging the long-sequence information gain hypothesis in time-series forecasting; redundant/noisy history can hinder learning; leverage information bottleneck to improve robustness and efficiency.", "method": "Adaptive Masking Loss with Representation Consistency (AMRC): (1) dynamic masking loss to identify highly discriminative temporal segments during training; (2) representation consistency constraint to stabilize the relations among inputs, labels, and predictions, reducing reliance on redundant features.", "result": "Empirical results show AMRC reduces redundant feature learning and significantly improves forecasting accuracy, even when less historical data is used, challenging conventional long-history assumptions.", "conclusion": "The work provides theoretical and practical advances by leveraging information bottleneck concepts to suppress noise and redundancy in temporal models, offering a robust, efficient framework for forecasting."}}
{"id": "2510.20483", "categories": ["cs.RO", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20483", "abs": "https://arxiv.org/abs/2510.20483", "authors": ["Victor Vantilborgh", "Hrishikesh Sathyanarayan", "Guillaume Crevecoeur", "Ian Abraham", "Tom Lefebvre"], "title": "Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty", "comment": null, "summary": "This work addresses the problem of robot manipulation tasks under unknown\ndynamics, such as pick-and-place tasks under payload uncertainty, where active\nexploration and(/for) online parameter adaptation during task execution are\nessential to enable accurate model-based control. The problem is framed as dual\ncontrol seeking a closed-loop optimal control problem that accounts for\nparameter uncertainty. We simplify the dual control problem by pre-defining the\nstructure of the feedback policy to include an explicit adaptation mechanism.\nThen we propose two methods for reference trajectory generation. The first\ndirectly embeds parameter uncertainty in robust optimal control methods that\nminimize the expected task cost. The second method considers minimizing the\nso-called optimality loss, which measures the sensitivity of parameter-relevant\ninformation with respect to task performance. We observe that both approaches\nreason over the Fisher information as a natural side effect of their\nformulations, simultaneously pursuing optimal task execution. We demonstrate\nthe effectiveness of our approaches for a pick-and-place manipulation task. We\nshow that designing the reference trajectories whilst taking into account the\ncontrol enables faster and more accurate task performance and system\nidentification while ensuring stable and efficient control.", "AI": {"tldr": "A dual-control approach to robot manipulation with unknown dynamics, using adaptive feedback and two trajectory-generation methods that account for parameter uncertainty; both approaches leverage Fisher information to balance task performance and learning, validated on pick-and-place tasks.", "motivation": "Unknown dynamics in manipulation tasks require online adaptation and active exploration to enable accurate, model-based control; dual control offers a framework to balance control and learning.", "method": "Fix a structured adaptive feedback policy and propose two trajectory-generation strategies: (1) robust optimal control that minimizes expected task cost incorporating parameter uncertainty, and (2) minimizing optimality loss, i.e., the sensitivity of parameter-relevant information to task performance. Fisher information emerges as a natural side effect in both methods.", "result": "Demonstrated on a pick-and-place task: reference trajectories designed with control considerations yield faster, more accurate task execution and system identification, while maintaining stable and efficient control.", "conclusion": "The proposed dual-control-inspired framework enables efficient manipulation under unknown dynamics by embedding adaptation in the feedback policy and using trajectory objectives that account for uncertainty; Fisher information naturally guides the trade-off between learning and performance."}}
{"id": "2510.20132", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20132", "abs": "https://arxiv.org/abs/2510.20132", "authors": ["Hyunjun Jung", "Hae-Gon Jeon"], "title": "Inverse Image-Based Rendering for Light Field Generation from Single Images", "comment": null, "summary": "A concept of light-fields computed from multiple view images on regular grids\nhas proven its benefit for scene representations, and supported realistic\nrenderings of novel views and photographic effects such as refocusing and\nshallow depth of field. In spite of its effectiveness of light flow\ncomputations, obtaining light fields requires either computational costs or\nspecialized devices like a bulky camera setup and a specialized microlens\narray. In an effort to broaden its benefit and applicability, in this paper, we\npropose a novel view synthesis method for light field generation from only\nsingle images, named inverse image-based rendering. Unlike previous attempts to\nimplicitly rebuild 3D geometry or to explicitly represent objective scenes, our\nmethod reconstructs light flows in a space from image pixels, which behaves in\nthe opposite way to image-based rendering. To accomplish this, we design a\nneural rendering pipeline to render a target ray in an arbitrary viewpoint. Our\nneural renderer first stores the light flow of source rays from the input\nimage, then computes the relationships among them through cross-attention, and\nfinally predicts the color of the target ray based on these relationships.\nAfter the rendering pipeline generates the first novel view from a single input\nimage, the generated out-of-view contents are updated to the set of source\nrays. This procedure is iteratively performed while ensuring the consistent\ngeneration of occluded contents. We demonstrate that our inverse image-based\nrendering works well with various challenging datasets without any retraining\nor finetuning after once trained on synthetic dataset, and outperforms relevant\nstate-of-the-art novel view synthesis methods.", "AI": {"tldr": "A neural inverse image-based rendering method that generates light-field views from a single image by learning light flows and cross-attention among source rays, iteratively updating occluded content; it generalizes across datasets without retraining and outperforms state-of-the-art methods.", "motivation": "To broaden the benefits of light-field rendering by removing reliance on bulky multi-view capture setups and heavy computation, enabling novel-view synthesis from a single image without explicit 3D reconstruction.", "method": "A neural renderer stores the light flows of source rays from the input image, uses cross-attention to relate these rays, and predicts the color of a target ray. After rendering a new view, the generated content is merged back into the source rays and the process repeats to ensure occluded regions are consistently filled. The system is trained on synthetic data and tested on challenging datasets without retraining, and it achieves better performance than relevant state-of-the-art methods.", "result": "The approach works well across various challenging datasets without additional retraining after the initial synthetic training and outperforms relevant state-of-the-art novel view synthesis methods.", "conclusion": "Inverse image-based rendering offers a practical pathway to generate light-field views from a single image, expanding applicability of light-field techniques by removing the need for specialized capture hardware and explicit 3D geometry reconstruction."}}
{"id": "2510.20252", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20252", "abs": "https://arxiv.org/abs/2510.20252", "authors": ["Tianyi Zhang", "Xiaolin Zhou", "Yunzhe Wang", "Erik Cambria", "David Traum", "Rui Mao"], "title": "Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods", "comment": null, "summary": "Individualized cognitive simulation (ICS) aims to build computational models\nthat approximate the thought processes of specific individuals. While large\nlanguage models (LLMs) convincingly mimic surface-level human behavior such as\nrole-play, their ability to simulate deeper individualized cognitive processes\nremains poorly understood. To address this gap, we introduce a novel task that\nevaluates different cognitive representation methods in ICS. We construct a\ndataset from recently published novels (later than the release date of the\ntested LLMs) and propose an 11-condition cognitive evaluation framework to\nbenchmark seven off-the-shelf LLMs in the context of authorial style emulation.\nWe hypothesize that effective cognitive representations can help LLMs generate\nstorytelling that better mirrors the original author. Thus, we test different\ncognitive representations, e.g., linguistic features, concept mappings, and\nprofile-based information. Results show that combining conceptual and\nlinguistic features is particularly effective in ICS, outperforming static\nprofile-based cues in overall evaluation. Importantly, LLMs are more effective\nat mimicking linguistic style than narrative structure, underscoring their\nlimits in deeper cognitive simulation. These findings provide a foundation for\ndeveloping AI systems that adapt to individual ways of thinking and expression,\nadvancing more personalized and human-aligned creative technologies.", "AI": {"tldr": "A study on individualized cognitive simulation (ICS) for authorial style emulation in LLMs. It evaluates 11 cognitive representation methods (linguistic features, concept mappings, profile cues) across seven LLMs using a dataset of post-release novels; finds that combining linguistic and conceptual features best supports ICS, with LLMs better at mimicking linguistic style than narrative structure, highlighting limits in deep cognitive simulation.", "motivation": "To move beyond surface-level mimicry by LLMs and evaluate how to represent internal cognitive processes of individuals for more faithful personalized storytelling.", "method": "Create a dataset from novels released after the tested LLMs. Propose an 11-condition cognitive evaluation framework. Benchmark seven off-the-shelf LLMs on authorial style emulation. Test cognitive representations including linguistic features, concept mappings, and profile-based cues.", "result": "Combining conceptual and linguistic features yields the strongest performance in ICS, surpassing static profile cues. LLMs more effectively mimic linguistic style than narrative structure, indicating limits in deep cognitive simulation.", "conclusion": "A hybrid of linguistic and conceptual representations facilitates more accurate individualized cognitive simulation in storytelling. The work lays groundwork for adaptive, human-aligned creative AI but also reveals current limits in encoding deeper cognitive processes."}}
{"id": "2510.19990", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19990", "abs": "https://arxiv.org/abs/2510.19990", "authors": ["Zachary Horvitz", "Raghav Singhal", "Hao Zou", "Carles Domingo-Enrich", "Zhou Yu", "Rajesh Ranganath", "Kathleen McKeown"], "title": "No Compute Left Behind: Rethinking Reasoning and Sampling with Masked Diffusion Models", "comment": null, "summary": "Masked diffusion language models (MDLMs) are trained to in-fill positions in\nrandomly masked sequences, in contrast to next-token prediction models.\nDiscussions around MDLMs focus on two benefits: (1) any-order decoding and 2)\nmulti-token decoding. However, we observe that for math and coding tasks,\nany-order algorithms often underperform or behave similarly to left-to-right\nsampling, and standard multi-token decoding significantly degrades performance.\nAt inference time, MDLMs compute the conditional distribution of all masked\npositions. A natural question is: How can we justify this additional compute\nwhen left-to-right one-token-at-a-time decoding is on par with any-order\ndecoding algorithms? First, we propose reasoning-as-infilling. By using MDLMs\nto infill a reasoning template, we can structure outputs and distinguish\nbetween reasoning and answer tokens. In turn, this enables measuring answer\nuncertainty during reasoning, and early exits when the model converges on an\nanswer. Next, given an answer, reasoning-as-infilling enables sampling from the\nMDLM posterior over reasoning traces conditioned on the answer, providing a new\nsource of high-quality data for post-training. On GSM8k, we observe that\nfine-tuning LLaDA-8B Base on its posterior reasoning traces provides a\nperformance boost on par with fine-tuning on human-written reasoning traces.\nAdditionally, given an answer, reasoning-as-infilling provides a method for\nscoring the correctness of the reasoning process at intermediate steps. Second,\nwe propose multi-token entropy decoding (MED), a simple adaptive sampler that\nminimizes the error incurred by decoding positions in parallel based on the\nconditional entropies of those positions. MED preserves performance across\nbenchmarks and leads to 2.7x fewer steps. Our work demonstrates that the\ntraining and compute used by MDLMs unlock many new inference and post-training\nmethods.", "AI": {"tldr": "Masked diffusion language models (MDLMs) enable new inference and post-training methods via infilling-based reasoning and adaptive multi-token decoding, but their expected benefits on math/coding tasks are not straightforward. The paper proposes reasoning-as-infilling and multi-token entropy decoding (MED) to improve efficiency and data quality, with notable gains on GSM8k and substantial step reductions.", "motivation": "To justify the extra compute of MDLMs beyond left-to-right decoding and to exploit their posterior distributions for inference, uncertainty estimation, early exits, and post-training data generation, especially for math/coding tasks where any-order or multi-token decoding can underperform.", "method": "1) Reasoning-as-infilling: structure outputs as a reasoning template and infer answers, enabling uncertainty measurement and early exits; sample posterior reasoning traces conditioned on an answer to create high-quality post-training data; fine-tune LLaDA-8B Base on posterior traces. 2) Multi-token entropy decoding (MED): an adaptive sampler that decodes masked positions in parallel based on conditional entropies to minimize error, preserving performance while reducing steps (2.7x).", "result": "MDLM-based reasoning with infilling provides performance gains on GSM8k when fine-tuned on posterior reasoning traces comparable to human-written traces; MED maintains performance across benchmarks while achieving a 2.7x reduction in decoding steps.", "conclusion": "MDLM training and computation unlock new inference and post-training paradigms (structured reasoning, uncertainty-based early exit, and posterior-trace augmentation) and can yield substantial efficiency improvements with MED, motivating further exploration of infilling-based reasoning and adaptive decoding."}}
{"id": "2510.20490", "categories": ["cs.RO", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.20490", "abs": "https://arxiv.org/abs/2510.20490", "authors": ["Thomas Kordik", "Hubert Gattringer", "Andreas Mueller"], "title": "Simultaneous Stiffness and Trajectory Optimization for Energy Minimization of Pick-and-Place Tasks of SEA-Actuated Parallel Kinematic Manipulators", "comment": null, "summary": "A major field of industrial robot applications deals with repetitive tasks\nthat alternate between operating points. For these so-called pick-and-place\noperations, parallel kinematic manipulators (PKM) are frequently employed.\nThese tasks tend to automatically run for a long period of time and therefore\nminimizing energy consumption is always of interest. Recent research addresses\nthis topic by the use of elastic elements and particularly series elastic\nactuators (SEA). This paper explores the possibilities of minimizing energy\nconsumption of SEA actuated PKM performing pick-and-place tasks. The basic idea\nis to excite eigenmotions that result from the actuator springs and exploit\ntheir oscillating characteristics. To this end, a prescribed cyclic\npick-and-place operation is analyzed and a dynamic model of SEA driven PKM is\nderived. Subsequently, an energy minimizing optimal control problem is\nformulated where operating trajectories as well as SEA stiffnesses are\noptimized simultaneously. Here, optimizing the actuator stiffness does not\naccount for variable stiffness actuators. It serves as a tool for the design\nand dimensioning process. The hypothesis on energy reduction is tested on two\n(parallel) robot applications where redundant actuation is also addressed. The\nresults confirm the validity of this approach.", "AI": {"tldr": "Energy-efficient control for SEA-actuated PKMs in pick-and-place by exciting elastic eigenmotions; jointly optimize task trajectories and SEA stiffness; validated on two parallel robots with redundancy, showing energy reduction.", "motivation": "Industrial PKMs performing repetitive pick-and-place tasks consume notable energy; leveraging series elastic actuators and elastic eigenmotions can reduce energy drain; providing a design-tool through stiffness optimization for SEA actuators.", "method": "Develop a dynamic model of SEA-driven PKMs, formulate an energy-minimizing optimal control problem with both operating trajectories and SEA stiffnesses as decision variables, analyze a prescribed cyclic pick-and-place task, and test on two parallel robot applications with redundancy.", "result": "The optimization yields energy savings compared to baseline; optimizing SEA stiffness informs design/dimensioning; redundancy is addressed; results confirm the energy-reduction hypothesis.", "conclusion": "The approach is viable for reducing energy use in SEA-actuated PKMs via simultaneous trajectory and stiffness optimization. The stiffness optimization serves as a design tool for dimensioning. The study validates the concept on two parallel robot tasks; variable-stiffness actuators are not considered, suggesting a direction for future work."}}
{"id": "2510.20134", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20134", "abs": "https://arxiv.org/abs/2510.20134", "authors": ["Jiachen Liang", "Ruibing Hou", "Minyang Hu", "Hong Chang", "Shiguang Shan", "Xilin Chen"], "title": "Revisiting Logit Distributions for Reliable Out-of-Distribution Detection", "comment": "Accepted by NeurIPS 2025", "summary": "Out-of-distribution (OOD) detection is critical for ensuring the reliability\nof deep learning models in open-world applications. While post-hoc methods are\nfavored for their efficiency and ease of deployment, existing approaches often\nunderexploit the rich information embedded in the model's logits space. In this\npaper, we propose LogitGap, a novel post-hoc OOD detection method that\nexplicitly exploits the relationship between the maximum logit and the\nremaining logits to enhance the separability between in-distribution (ID) and\nOOD samples. To further improve its effectiveness, we refine LogitGap by\nfocusing on a more compact and informative subset of the logit space.\nSpecifically, we introduce a training-free strategy that automatically\nidentifies the most informative logits for scoring. We provide both theoretical\nanalysis and empirical evidence to validate the effectiveness of our approach.\nExtensive experiments on both vision-language and vision-only models\ndemonstrate that LogitGap consistently achieves state-of-the-art performance\nacross diverse OOD detection scenarios and benchmarks. Code is available at\nhttps://github.com/GIT-LJc/LogitGap.", "AI": {"tldr": "LogitGap is a post-hoc OOD detector that exploits the relationship between the top logit and the remaining logits, with a training-free strategy to select informative logits, achieving state-of-the-art results on both vision-language and vision-only models.", "motivation": "Out-of-distribution detection is crucial for reliable open-world deployment. Existing post-hoc methods underutilize the rich information in the model's logits space. This work aims to improve ID-OOD separability by leveraging the relationship between the maximum logit and other logits, and by focusing on a compact, informative subset of logits.", "method": "Propose LogitGap, a post-hoc OOD detector that scores samples based on the gap between the maximum logit and the remaining logits. Further refine with a training-free strategy that automatically identifies the most informative logits to use for scoring.", "result": "Empirical results show that LogitGap achieves state-of-the-art OOD detection performance across diverse benchmarks, including both vision-language and vision-only models. The approach is supported by theoretical analysis and extensive experiments; code is available at the provided URL.", "conclusion": "LogitGap provides an effective and efficient post-hoc OOD detection method by leveraging logit-space relationships and automatically selecting informative logits, yielding strong, broadly applicable improvements over existing methods."}}
{"id": "2510.20258", "categories": ["cs.AI", "I.2"], "pdf": "https://arxiv.org/pdf/2510.20258", "abs": "https://arxiv.org/abs/2510.20258", "authors": ["Bita Banihashemi", "Megh Patel", "Yves Lesp\u00e9rance"], "title": "Using Large Language Models for Abstraction of Planning Domains - Extended Version", "comment": null, "summary": "Generating an abstraction of a dynamic domain that aligns with a given\npurpose remains a significant challenge given that the choice of such an\nabstraction can impact an agent's ability to plan, reason, and provide\nexplanations effectively. We model the agent's concrete behaviors in PDDL and\ninvestigate the use of in-context learning with large language models (LLMs)\nfor the generation of abstract PDDL domains and problem instances, given an\nabstraction objective specified in natural language. The benchmark examples we\nuse are new and have not been part of the data any LLMs have been trained on.\nWe consider three categories of abstractions: abstraction of choice of\nalternative concrete actions, abstraction of sequences of concrete actions, and\nabstraction of action/predicate parameters, as well as combinations of these.\nThe generated abstract PDDL domains and problem instances are then checked by\nsymbolic validation tools as well as human experts. Our experiments show that\nGPT-4o can generally synthesize useful planning domain abstractions in simple\nsettings, although it is better at abstracting over actions than over the\nassociated fluents.", "AI": {"tldr": "LLMs (GPT-4o) can generate useful abstract PDDL domains and problems from natural-language abstraction objectives, mainly for action-level abstractions; validated by symbolic tools and experts; effective in simple settings but less robust for fluent/predicate abstractions.", "motivation": "Abstraction choices in a dynamic domain critically affect planning, reasoning, and explanations. Automating abstraction generation to align with user objectives can streamline planning pipelines and improve interpretability.", "method": "Model concrete behaviors in PDDL; use in-context learning with LLMs to generate abstract PDDL domains and problems from a natural-language abstraction objective. Consider abstractions over (i) alternative actions, (ii) action sequences, (iii) action/predicate parameters, and their combinations. Benchmark on new, unseen examples; validate results with symbolic validation tools and human experts.", "result": "GPT-4o generally synthesizes useful planning-domain abstractions in simple settings, excelling at abstracting actions rather than fluents (fluents/predicate aspects).", "conclusion": "LLMs can assist in generating domain abstractions for planning, but current capabilities are strongest for action-level abstractions and weaker for fluent/predicate abstractions; further work needed for robustness in complex domains and for broader abstraction types."}}
{"id": "2510.20019", "categories": ["cs.LG", "cs.CR", "2020: Primary 68T05, Secondary 68T10", "I.2.6; I.6.4; C.3"], "pdf": "https://arxiv.org/pdf/2510.20019", "abs": "https://arxiv.org/abs/2510.20019", "authors": ["Curtis Lee Shull", "Merrick Green"], "title": "Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications", "comment": "10 pages, 5 figures. Submitted to the Journal of Defense Modeling and\n  Simulation (JDMS) for the Special Issue Integrating AI/ML Into Modeling and\n  Simulation (J22-4). This work evaluates machine learning-based RFID\n  localization for defense logistics environments using CAD-modeled simulations\n  and RSSI-driven decision tree classification", "summary": "Radio Frequency Identification (RFID) tracking may be a viable solution for\ndefense assets that must be stored in accordance with security guidelines.\nHowever, poor sensor specificity (vulnerabilities include long range detection,\nspoofing, and counterfeiting) can lead to erroneous detection and operational\nsecurity events. We present a supervised learning simulation with realistic\nReceived Signal Strength Indicator (RSSI) data and Decision Tree classification\nin a Computer Assisted Design (CAD)-modeled floor plan that encapsulates some\nof the challenges encountered in defense storage. In this work, we focused on\nclassifying 12 lab zones (LabZoneA-L) to perform location inference. The raw\ndataset had approximately 980,000 reads. Class frequencies were imbalanced, and\nclass weights were calculated to account for class imbalance in this\nmulti-class setting. The model, trained on stratified subsamples to 5,000\nbalanced observations, yielded an overall accuracy of 34.2% and F1-scores\ngreater than 0.40 for multiple zones (Zones F, G, H, etc.). However, rare\nclasses (most notably LabZoneC) were often misclassified, even with the use of\nclass weights. An adjacency-aware confusion matrix was calculated to allow\nbetter interpretation of physically adjacent zones. These results suggest that\nRSSI-based decision trees can be applied in realistic simulations to enable\nzone-level anomaly detection or misplacement monitoring for defense supply\nlogistics. Reliable classification performance in low-coverage and low-signal\nzones could be improved with better antenna placement or additional sensors and\nsensor fusion with other modalities.", "AI": {"tldr": "RSSI-based decision-tree classification on RFID data in a CAD floor plan provides zone-level inference with modest overall accuracy; performance is uneven across zones due to class imbalance and rare-zone misclassification; adjacency-aware interpretation aids understanding; improvements likely from antenna placement and sensor fusion.", "motivation": "Defense asset storage requires reliable, zone-level localization under security constraints; RFID/RSSI methods offer scalable monitoring but face spoofing, long-range detection, and data imbalance challenges. This work explores feasibility through a realistic simulation.", "method": "Supervised learning simulation using realistic RSSI data in a CAD-modeled floor plan; 12 zones (LabZoneA-L); dataset ~980,000 reads; class weights to handle imbalance; stratified subsampling to 5,000 balanced observations; Decision Tree classifier; adjacency-aware confusion matrix for interpretation.", "result": "Overall accuracy 34.2%; F1-scores >0.40 for multiple zones (e.g., F, G, H); rare zones (notably LabZoneC) misclassified despite class weights; interpretation aided by adjacency-aware matrix; results indicate potential for zone-level anomaly detection in defense logistics; performance could improve with better antenna placement or sensor fusion.", "conclusion": "RSSI-based decision trees can be applied in realistic defense simulations for zone-level anomaly detection or misplacement monitoring; reliability in low-coverage zones could be improved through hardware improvements (antenna placement) and integration with additional sensors or modalities."}}
{"id": "2510.20496", "categories": ["cs.RO", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.20496", "abs": "https://arxiv.org/abs/2510.20496", "authors": ["Tobias Marauli", "Hubert Gattringer", "Andreas Mueller"], "title": "A Parameter-Linear Formulation of the Optimal Path Following Problem for Robotic Manipulator", "comment": null, "summary": "In this paper the computational challenges of time-optimal path following are\naddressed. The standard approach is to minimize the travel time, which\ninevitably leads to singularities at zero path speed, when reformulating the\noptimization problem in terms of a path parameter. Thus, smooth trajectory\ngeneration while maintaining a low computational effort is quite challenging,\nsince the singularities have to be taken into account. To this end, a different\napproach is presented in this paper. This approach is based on maximizing the\npath speed along a prescribed path. Furthermore, the approach is capable of\nplanning smooth trajectories numerically efficient. Moreover, the discrete\nreformulation of the underlying problem is linear in optimization variables.", "AI": {"tldr": "Maximizes path speed on a fixed path to avoid time-optimal singularities, enabling smooth trajectory planning with a linear, discrete optimization problem.", "motivation": "Time-optimal path following has singularities at zero path speed when parameterizing the path, and generating smooth trajectories with low computation is challenging.", "method": "Formulates trajectory planning by maximizing the speed along a prescribed path; the discrete reformulation of the problem is linear in the optimization variables.", "result": "Provides smooth trajectory planning with low computational effort and a linear discrete formulation, mitigating the singularities of time-optimal approaches.", "conclusion": "Maximizing path speed along a prescribed path is a viable, computationally efficient alternative to time-optimal formulations, producing smooth trajectories without the zero-speed singularities."}}
{"id": "2510.20155", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20155", "abs": "https://arxiv.org/abs/2510.20155", "authors": ["Penghao Wang", "Yiyang He", "Xin Lv", "Yukai Zhou", "Lan Xu", "Jingyi Yu", "Jiayuan Gu"], "title": "PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding", "comment": "NeurIPS 2025 DB Track. Project page:\n  https://authoritywang.github.io/partnext", "summary": "Understanding objects at the level of their constituent parts is fundamental\nto advancing computer vision, graphics, and robotics. While datasets like\nPartNet have driven progress in 3D part understanding, their reliance on\nuntextured geometries and expert-dependent annotation limits scalability and\nusability. We introduce PartNeXt, a next-generation dataset addressing these\ngaps with over 23,000 high-quality, textured 3D models annotated with\nfine-grained, hierarchical part labels across 50 categories. We benchmark\nPartNeXt on two tasks: (1) class-agnostic part segmentation, where\nstate-of-the-art methods (e.g., PartField, SAMPart3D) struggle with\nfine-grained and leaf-level parts, and (2) 3D part-centric question answering,\na new benchmark for 3D-LLMs that reveals significant gaps in open-vocabulary\npart grounding. Additionally, training Point-SAM on PartNeXt yields substantial\ngains over PartNet, underscoring the dataset's superior quality and diversity.\nBy combining scalable annotation, texture-aware labels, and multi-task\nevaluation, PartNeXt opens new avenues for research in structured 3D\nunderstanding.", "AI": {"tldr": "PartNeXt: a textured, large-scale 3D part dataset with hierarchical labels across 50 categories, enabling robust 3D part segmentation and 3D-LLM QA; shows improvements over PartNet; enables gains when training Point-SAM.", "motivation": "Current 3D part datasets (e.g., PartNet) use untextured geometry and rely on expert labeling, limiting realism, scalability, and open-vocabulary evaluation. A textured, richly labeled dataset is needed for advances in segmentation, reasoning, and real-world robotics/graphics.", "method": "Construct PartNeXt with 23k textured 3D models annotated with fine-grained, hierarchical part labels over 50 categories. Benchmark on two tasks: (1) class-agnostic part segmentation (evaluating existing methods like PartField, SAMPart3D on fine-grained/leaf parts); (2) 3D part-centric question answering (a benchmark for 3D-LLMs). Train Point-SAM on PartNeXt and compare to PartNet to assess gains.", "result": "PartNeXt enables new evaluation challenges: state-of-the-art methods struggle with fine-grained leaf parts; the 3D-LLM QA benchmark reveals substantial gaps in open-vocabulary part grounding. Training Point-SAM on PartNeXt yields substantial gains over PartNet, demonstrating higher quality and diversity of annotations and texture-aware labels.", "conclusion": "PartNeXt provides scalable, texture-aware, multi-task data that advances structured 3D understanding, enabling more realistic segmentation, richer 3D reasoning, and stronger foundation models for 3D vision, graphics, and robotics."}}
{"id": "2510.20275", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20275", "abs": "https://arxiv.org/abs/2510.20275", "authors": ["Yunzhi Liu", "Haokai Tan", "Rushi Kanjaria", "Lihuan Li", "Flora D. Salim"], "title": "Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction", "comment": "This paper has been accepted by ACM SIGSPATIAL 2025 as a short paper", "summary": "Human mobility forecasting is crucial for disaster relief, city planning, and\npublic health. However, existing models either only model location sequences or\ninclude time information merely as auxiliary input, thereby failing to leverage\nthe rich semantic context provided by points of interest (POIs). To address\nthis, we enrich a BERT-based mobility model with derived temporal descriptors\nand POI embeddings to better capture the semantics underlying human movement.\nWe propose STaBERT (Semantic-Temporal aware BERT), which integrates both POI\nand temporal information at each location to construct a unified, semantically\nenriched representation of mobility. Experimental results show that STaBERT\nsignificantly improves prediction accuracy: for single-city prediction, the\nGEO-BLEU score improved from 0.34 to 0.75; for multi-city prediction, from 0.34\nto 0.56.", "AI": {"tldr": "Semantic-Temporal aware BERT (STaBERT) integrates POI and temporal cues into a BERT-based mobility model, yielding major accuracy gains in GEO-BLEU for single-city and multi-city predictions.", "motivation": "Existing mobility models either focus on location sequences or treat time as mere auxiliary input, missing rich semantic context from POIs; incorporating POI semantics and temporal descriptors can improve forecasting.", "method": "Propose STaBERT: a BERT-based mobility model that fuses derived temporal descriptors and POI embeddings at each location to form a unified semantically enriched representation of mobility; applied to single-city and multi-city predictions.", "result": "Significant improvements: GEO-BLEU from 0.34 to 0.75 for single-city; from 0.34 to 0.56 for multi-city.", "conclusion": "Integrating POI and temporal context into a BERT-based mobility model yields stronger predictive performance and demonstrates the value of semantically enriched representations for human mobility forecasting."}}
{"id": "2510.20022", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20022", "abs": "https://arxiv.org/abs/2510.20022", "authors": ["Jiazheng Li", "Yawei Wang", "David Yan", "Yijun Tian", "Zhichao Xu", "Huan Song", "Panpan Xu", "Lin Lee Cheong"], "title": "SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities,\nenabling language agents to excel at single-turn tasks. However, their\napplication to complex, multi-step, and long-horizon tasks remains challenging.\nWhile reinforcement learning (RL) offers a promising avenue for addressing\nthese challenges, mainstream approaches typically rely solely on sparse,\noutcome-based rewards, a limitation that becomes especially problematic for\ngroup-based RL algorithms lacking critic models, such as Group Relative Policy\nOptimization (GRPO). In such methods, uniformly rewarding or penalizing all\nactions within a trajectory can lead to training instability and suboptimal\npolicies, because beneficial and detrimental actions are often entangled across\nmulti-step interactions. To address this challenge, we propose SALT, a novel\nand lightweight framework that provides a finer-grained advantage assignment,\nderived solely from outcome rewards. We achieve this by constructing a graph\nfrom trajectories of the same prompt, which allows us to quantify the quality\nof each step and assign advantages accordingly. Crucially, SALT is designed as\na plug-and-play module that seamlessly integrates with existing group-based RL\nalgorithms, requiring no modifications to the rollout procedure and introducing\nnegligible computational overhead. Extensive experiments on the WebShop,\nALFWorld, and AppWorld benchmarks with various model sizes demonstrate that\nSALT consistently improves performance. We also conduct a thorough analysis to\nvalidate the design choices behind SALT and offer actionable insights.", "AI": {"tldr": "SALT provides a fine-grained credit assignment for group-based RL using trajectory graphs, improving performance with negligible overhead.", "motivation": "Group-based RL approaches struggle with uniformly rewarding all actions due to entangled multi-step effects; need a way to credit individual steps using only outcome rewards.", "method": "Construct a trajectory graph from samples with the same prompt to quantify per-step quality and derive step-wise advantages; SALT is a plug-and-play module that requires no rollout changes and adds minimal computation.", "result": "Empirically improves performance across WebShop, ALFWorld, AppWorld for multiple model sizes; robust analyses validating design choices.", "conclusion": "SALT offers an effective, lightweight solution for finer-grained credit assignment in group-based RL, enabling better performance with low overhead and easy integration."}}
{"id": "2510.20529", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20529", "abs": "https://arxiv.org/abs/2510.20529", "authors": ["Constantine Frost", "Chad Council", "Margaret McGuinness", "Nathaniel Hanson"], "title": "RubbleSim: A Photorealistic Structural Collapse Simulator for Confined Space Mapping", "comment": "Accepted to 2025 IEEE International Symposium on Safety, Security,\n  and Rescue Robotics", "summary": "Despite well-reported instances of robots being used in disaster response,\nthere is scant published data on the internal composition of the void spaces\nwithin structural collapse incidents. Data collected during these incidents is\nmired in legal constraints, as ownership is often tied to the responding\nagencies, with little hope of public release for research. While engineered\nrubble piles are used for training, these sites are also reluctant to release\ninformation about their proprietary training grounds. To overcome this access\nchallenge, we present RubbleSim -- an open-source, reconfigurable simulator for\nphotorealistic void space exploration. The design of the simulation assets is\ndirectly informed by visits to numerous training rubble sites at differing\nlevels of complexity. The simulator is implemented in Unity with\nmulti-operating system support. The simulation uses a physics-based approach to\nbuild stochastic rubble piles, allowing for rapid iteration between simulation\nworlds while retaining absolute knowledge of the ground truth. Using RubbleSim,\nwe apply a state-of-the-art structure-from-motion algorithm to illustrate how\nperception performance degrades under challenging visual conditions inside the\nemulated void spaces. Pre-built binaries and source code to implement are\navailable online: https://github.com/mit-ll/rubble_pile_simulator.", "AI": {"tldr": "An open-source, Unity-based simulator (RubbleSim) for photorealistic rubble void spaces, enabling ground-truth, configurable experiments to study robot perception and to overcome data-access barriers in disaster scenes.", "motivation": "Public data on void spaces in structural collapses is scarce due to legal ownership and safety constraints; sites that could be used for training are proprietary. RubbleSim provides a repeatable, accessible benchmark for evaluating perception under challenging visual conditions in rubble environments.", "method": "Physics-based, stochastic rubble-pile generation implemented in Unity with multi-OS support; design informed by visits to real rubble training sites; photorealistic rendering; preserves ground-truth; assesses perception via a state-of-the-art structure-from-motion pipeline.", "result": "Demonstrates how perception performance degrades under challenging visual conditions in emulated void spaces; provides pre-built binaries and source code for researchers to reuse and modify.", "conclusion": "RubbleSim offers an open, configurable platform to study perception in rubble void spaces, addressing access barriers to real disaster data and enabling rapid, reproducible experimentation in disaster robotics research."}}
{"id": "2510.20158", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20158", "abs": "https://arxiv.org/abs/2510.20158", "authors": ["Eduardo R. Corral-Soto", "Yang Liu", "Yuan Ren", "Bai Dongfeng", "Liu Bingbing"], "title": "Monocular Visual 8D Pose Estimation for Articulated Bicycles and Cyclists", "comment": null, "summary": "In Autonomous Driving, cyclists belong to the safety-critical class of\nVulnerable Road Users (VRU), and accurate estimation of their pose is critical\nfor cyclist crossing intention classification, behavior prediction, and\ncollision avoidance. Unlike rigid objects, articulated bicycles are composed of\nmovable rigid parts linked by joints and constrained by a kinematic structure.\n6D pose methods can estimate the 3D rotation and translation of rigid bicycles,\nbut 6D becomes insufficient when the steering/pedals angles of the bicycle\nvary. That is because: 1) varying the articulated pose of the bicycle causes\nits 3D bounding box to vary as well, and 2) the 3D box orientation is not\nnecessarily aligned to the orientation of the steering which determines the\nactual intended travel direction. In this work, we introduce a method for\ncategory-level 8D pose estimation for articulated bicycles and cyclists from a\nsingle RGB image. Besides being able to estimate the 3D translation and\nrotation of a bicycle from a single image, our method also estimates the\nrotations of its steering handles and pedals with respect to the bicycle body\nframe. These two new parameters enable the estimation of a more fine-grained\nbicycle pose state and travel direction. Our proposed model jointly estimates\nthe 8D pose and the 3D Keypoints of articulated bicycles, and trains with a mix\nof synthetic and real image data to generalize on real images. We include an\nevaluation section where we evaluate the accuracy of our estimated 8D pose\nparameters, and our method shows promising results by achieving competitive\nscores when compared against state-of-the-art category-level 6D pose estimators\nthat use rigid canonical object templates for matching.", "AI": {"tldr": "Introduces 8D pose estimation for articulated bicycles and cyclists from a single RGB image, estimating bicycle pose plus steering/pedal rotations to infer pose and travel direction; trained with synthetic + real data; shows competitive results vs 6D rigid methods.", "motivation": "Accurate pose and travel direction of vulnerable road users (VRUs) like cyclists are critical for safety in autonomous driving. Articulated bicycles have moving joints (steering, pedals) that cause the 3D bounding box and orientation to change, making standard 6D pose insufficient.", "method": "Proposes category-level 8D pose estimation from a single image: jointly estimate 3D translation and rotation of the bicycle body, plus the rotations of its steering handles and pedals relative to the body; also estimates 3D keypoints; trained with a mix of synthetic and real images to generalize to real-world data.", "result": "The approach achieves accurate estimation of 8D pose parameters and 3D keypoints; it yields competitive scores when compared to state-of-the-art category-level 6D pose estimators that rely on rigid canonical templates.", "conclusion": "8D pose estimation for articulated bicycles is feasible and provides a more fine-grained pose state and travel direction, enhancing safety-critical perception in autonomous driving and potentially improving obstacle avoidance and planning."}}
{"id": "2510.20310", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20310", "abs": "https://arxiv.org/abs/2510.20310", "authors": ["Mingliang Zhai", "Hansheng Liang", "Xiaomeng Fan", "Zhi Gao", "Chuanhao Li", "Che Sun", "Xu Bin", "Yuwei Wu", "Yunde Jia"], "title": "Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation", "comment": "16 pages, 7 figures, 8 tables", "summary": "Embodied Question Answering (EQA) requires agents to explore 3D environments\nto obtain observations and answer questions related to the scene. Existing\nmethods leverage VLMs to directly explore the environment and answer questions\nwithout explicit thinking or planning, which limits their reasoning ability and\nresults in excessive or inefficient exploration as well as ineffective\nresponses. In this paper, we introduce ToolEQA, an agent that integrates\nexternal tools with multi-step reasoning, where external tools can provide more\nuseful information for completing the task, helping the model derive better\nexploration directions in the next step of reasoning and thus obtaining\nadditional effective information. This enables ToolEQA to generate more\naccurate responses with a shorter exploration distance. To enhance the model's\nability for tool-usage and multi-step reasoning, we further design a novel EQA\ndata generation pipeline that automatically constructs large-scale EQA tasks\nwith reasoning trajectories and corresponding answers. Based on the pipeline,\nwe collect the EQA-RT dataset that contains about 18K tasks, divided into a\ntraining set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping\nwith the training set) and EQA-RT-Unseen (novel scenes). Experiments on\nEQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by\n9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot\nToolEQA by 10% in success rate. In addition, ToolEQA also achieves\nstate-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench\ndatasets, demonstrating its generality. Our homepage see\nhttps://tooleqa.github.io.", "AI": {"tldr": "ToolEQA integrates external tools with multi-step reasoning for Embodied Question Answering, enabling more accurate answers with shorter exploration and introducing the EQA-RT dataset (~18k tasks).", "motivation": "Current VLM-based EQA methods rely on direct exploration and lack explicit planning, leading to inefficient exploration and weaker reasoning.", "method": "Proposes ToolEQA, which leverages external tools to supply information and supports multi-step reasoning to guide exploration. Also introduces an automatic EQA data generation pipeline that creates large-scale EQA tasks with reasoning trajectories, resulting in the EQA-RT dataset (\u224818k tasks) with train and seen/unseen test splits. Evaluations on EQA-RT-Seen/Unseen and other benchmarks (HM-EQA, OpenEQA, EXPRESS-Bench) demonstrate improved performance.", "result": "On EQA-RT-Seen and EQA-RT-Unseen, ToolEQA improves success rate by 9.2\u201320.2% over state-of-the-art baselines and surpasses zero-shot ToolEQA by ~10%. It also achieves state-of-the-art results on HM-EQA, OpenEQA, and EXPRESS-Bench.", "conclusion": "Integrating external tools with multi-step reasoning and a scalable data-generation pipeline yields more efficient, accurate EQA with broader generality across benchmarks."}}
{"id": "2510.20028", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20028", "abs": "https://arxiv.org/abs/2510.20028", "authors": ["Vahid Jalili"], "title": "The Temporal Graph of Bitcoin Transactions", "comment": null, "summary": "Since its 2009 genesis block, the Bitcoin network has processed \\num{>1.08}\nbillion (B) transactions representing \\num{>8.72}B BTC, offering rich potential\nfor machine learning (ML); yet, its pseudonymity and obscured flow of funds\ninherent in its \\utxo-based design, have rendered this data largely\ninaccessible for ML research. Addressing this gap, we present an ML-compatible\ngraph modeling the Bitcoin's economic topology by reconstructing the flow of\nfunds. This temporal, heterogeneous graph encompasses complete transaction\nhistory up to block \\cutoffHeight, consisting of \\num{>2.4}B nodes and\n\\num{>39.72}B edges. Additionally, we provide custom sampling methods yielding\nnode and edge feature vectors of sampled communities, tools to load and analyze\nthe Bitcoin graph data within specialized graph databases, and ready-to-use\ndatabase snapshots. This comprehensive dataset and toolkit empower the ML\ncommunity to tackle Bitcoin's intricate ecosystem at scale, driving progress in\napplications such as anomaly detection, address classification, market\nanalysis, and large-scale graph ML benchmarking. Dataset and code available at\n\\href{https://github.com/B1AAB/EBA}{github.com/b1aab/eba}", "AI": {"tldr": "A large-scale, ML-ready temporal heterogeneous graph of Bitcoin transaction flow enabling scalable ML research and benchmarking.", "motivation": "Bitcoin's pseudonymity and opaque UTXO-based flow hinder ML research; this work provides a complete, ML-friendly representation and toolkit.", "method": "Construct a temporal heterogeneous graph from all transactions up to cutoffHeight, with >2.4B nodes and >39.72B edges; generate node/edge features for sampled communities; provide graph DB loading/analysis tools and database snapshots.", "result": "An ML-ready Bitcoin graph dataset (>2.4B nodes, >39.72B edges) plus sampling methods, tooling, and ready snapshots; code and data available at GitHub.", "conclusion": "Enables large-scale ML studies of Bitcoin, including anomaly detection, address classification, and market analysis; provides benchmarks for graph ML on a real, large-scale financial network."}}
{"id": "2510.20685", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20685", "abs": "https://arxiv.org/abs/2510.20685", "authors": ["Ming-Ming Yu", "Fei Zhu", "Wenzhuo Liu", "Yirong Yang", "Qunbo Wang", "Wenjun Wu", "Jing Liu"], "title": "C-NAV: Towards Self-Evolving Continual Object Navigation in Open World", "comment": null, "summary": "Embodied agents are expected to perform object navigation in dynamic,\nopen-world environments. However, existing approaches typically rely on static\ntrajectories and a fixed set of object categories during training, overlooking\nthe real-world requirement for continual adaptation to evolving scenarios. To\nfacilitate related studies, we introduce the continual object navigation\nbenchmark, which requires agents to acquire navigation skills for new object\ncategories while avoiding catastrophic forgetting of previously learned\nknowledge. To tackle this challenge, we propose C-Nav, a continual visual\nnavigation framework that integrates two key innovations: (1) A dual-path\nanti-forgetting mechanism, which comprises feature distillation that aligns\nmulti-modal inputs into a consistent representation space to ensure\nrepresentation consistency, and feature replay that retains temporal features\nwithin the action decoder to ensure policy consistency. (2) An adaptive\nsampling strategy that selects diverse and informative experiences, thereby\nreducing redundancy and minimizing memory overhead. Extensive experiments\nacross multiple model architectures demonstrate that C-Nav consistently\noutperforms existing approaches, achieving superior performance even compared\nto baselines with full trajectory retention, while significantly lowering\nmemory requirements. The code will be publicly available at\nhttps://bigtree765.github.io/C-Nav-project.", "AI": {"tldr": "A continual visual navigation framework, C-Nav, for continual object navigation in dynamic open-world environments, using a dual-path anti-forgetting mechanism (feature distillation for representation consistency across modalities and feature replay for policy consistency) and adaptive sampling, achieving superior performance with lower memory than baselines; code release.", "motivation": "Addresses the real-world need for continual adaptation to evolving object categories and dynamic environments; current methods rely on fixed trajectories/categories and suffer catastrophic forgetting; proposes a benchmark and methods to study continual object navigation.", "method": "Introduce C-Nav with two components: (1) dual-path anti-forgetting: feature distillation aligning multi-modal inputs into a shared representation space; feature replay preserving temporal features in the action decoder; (2) adaptive sampling selecting diverse/informative experiences to minimize redundancy and memory usage. Evaluated across multiple model architectures; benchmark for continual object navigation.", "result": "C-Nav consistently outperforms existing approaches, even surpassing baselines with full trajectory retention, while significantly reducing memory requirements.", "conclusion": "C-Nav offers effective continual learning for embodied navigation in open-world dynamics, enabling continual acquisition of new object categories with retained prior knowledge; code will be publicly released."}}
{"id": "2510.20162", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20162", "abs": "https://arxiv.org/abs/2510.20162", "authors": ["Xudong Yan", "Songhe Feng"], "title": "TOMCAT: Test-time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning", "comment": "Accepted to NeurIPS 2025", "summary": "Compositional Zero-Shot Learning (CZSL) aims to recognize novel\nattribute-object compositions based on the knowledge learned from seen ones.\nExisting methods suffer from performance degradation caused by the distribution\nshift of label space at test time, which stems from the inclusion of unseen\ncompositions recombined from attributes and objects. To overcome the challenge,\nwe propose a novel approach that accumulates comprehensive knowledge in both\ntextual and visual modalities from unsupervised data to update multimodal\nprototypes at test time. Building on this, we further design an adaptive update\nweight to control the degree of prototype adjustment, enabling the model to\nflexibly adapt to distribution shift during testing. Moreover, a dynamic\npriority queue is introduced that stores high-confidence images to acquire\nvisual knowledge from historical images for inference. Considering the semantic\nconsistency of multimodal knowledge, we align textual and visual prototypes by\nmultimodal collaborative representation learning. Extensive experiments\nindicate that our approach achieves state-of-the-art performance on four\nbenchmark datasets under both closed-world and open-world settings. Code will\nbe available at https://github.com/xud-yan/TOMCAT .", "AI": {"tldr": "A novel compositional zero-shot learning method (TOMCAT) updates multimodal prototypes at test time by leveraging unsupervised textual and visual data, with an adaptive update weight and a dynamic high-confidence image queue, aligning textual and visual representations to achieve state-of-the-art results on four benchmarks in both closed-world and open-world CZSL.", "motivation": " CZSL suffers from distribution shift when unseen attribute-object compositions are encountered at test time. The paper aims to mitigate this by accumulating broad knowledge from unsupervised data in both text and images to refresh prototypes, thereby improving generalization to unseen compositions.", "method": "The approach accumulates knowledge from unlabeled textual and visual data to update multimodal prototypes at test time. An adaptive update weight controls how much prototypes are adjusted. A dynamic priority queue stores high-confidence images to leverage historical visual knowledge during inference. Multimodal collaborative representation learning aligns textual and visual prototypes to maintain semantic consistency between modalities.", "result": "Extensive experiments show state-of-the-art performance on four benchmark datasets under both closed-world and open-world CZSL settings.", "conclusion": "The proposed framework effectively mitigates distribution shift in CZSL by adaptive, multimodal prototype updates and dynamic memory strategies, achieving strong cross-modal alignment and improved generalization; code will be available at the authors' repository."}}
{"id": "2510.20332", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20332", "abs": "https://arxiv.org/abs/2510.20332", "authors": ["Anna Arias-Duart", "Maria Eugenia Cardello", "Atia Cort\u00e9s"], "title": "Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems", "comment": "8 pages, 3 tables, accepted in AEQUITAS 2025 (not in proceedings)", "summary": "Artificial intelligence (AI) holds great promise for transforming healthcare.\nHowever, despite significant advances, the integration of AI solutions into\nreal-world clinical practice remains limited. A major barrier is the quality\nand fairness of training data, which is often compromised by biased data\ncollection practices. This paper draws on insights from the AI4HealthyAging\nproject, part of Spain's national R&D initiative, where our task was to detect\nbiases during clinical data collection. We identify several types of bias\nacross multiple use cases, including historical, representation, and\nmeasurement biases. These biases manifest in variables such as sex, gender,\nage, habitat, socioeconomic status, equipment, and labeling. We conclude with\npractical recommendations for improving the fairness and robustness of clinical\nproblem design and data collection. We hope that our findings and experience\ncontribute to guiding future projects in the development of fairer AI systems\nin healthcare.", "AI": {"tldr": "This paper analyzes biases in clinical data collection for AI in healthcare within the AI4HealthyAging project, identifying historical, representation, and measurement biases across use cases, affecting variables like sex, gender, age, habitat, SES, equipment, and labeling, and provides practical recommendations to improve fairness and robustness in data design and collection.", "motivation": "To address data quality and fairness barriers that hinder deploying AI in real-world clinical practice; biased data can undermine fairness, generalizability, and safety of AI systems in healthcare.", "method": "Qualitative analysis across multiple use cases within the AI4HealthyAging project to identify and taxonomy biases; examines how variables such as sex, gender, age, habitat, SES, equipment, and labeling contribute to bias.", "result": "Identification of several bias types (historical, representation, measurement) across use cases and concrete variables; development of practical recommendations for fairer problem design and data collection in clinical AI.", "conclusion": "The work contributes guidance for future healthcare AI projects to develop fairer and more robust AI systems by improving data collection practices and problem formulation."}}
{"id": "2510.20031", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20031", "abs": "https://arxiv.org/abs/2510.20031", "authors": ["Marin Bilo\u0161", "Anderson Schneider", "Yuriy Nevmyvaka"], "title": "Speculative Sampling for Parametric Temporal Point Processes", "comment": null, "summary": "Temporal point processes are powerful generative models for event sequences\nthat capture complex dependencies in time-series data. They are commonly\nspecified using autoregressive models that learn the distribution of the next\nevent from the previous events. This makes sampling inherently sequential,\nlimiting efficiency. In this paper, we propose a novel algorithm based on\nrejection sampling that enables exact sampling of multiple future values from\nexisting TPP models, in parallel, and without requiring any architectural\nchanges or retraining. Besides theoretical guarantees, our method demonstrates\nempirical speedups on real-world datasets, bridging the gap between expressive\nmodeling and efficient parallel generation for large-scale TPP applications.", "AI": {"tldr": "A rejection-sampling based method enables exact, parallel sampling of multiple future events in temporal point processes (TPPs) from existing models without retraining or architecture changes, with theoretical guarantees and real-data speedups.", "motivation": "Autoregressive TPPs force sequential sampling, which hurts efficiency and scalability. There is a need for a method that can generate multiple future events in parallel while preserving exactness and without changing models.", "method": "Introduce a rejection sampling algorithm that operates on the conditional intensities of existing TPPs to sample several future events in parallel. It does not require retraining or changes to the model architecture and provides theoretical guarantees of correctness.", "result": "The approach yields theoretical guarantees of exact sampling and demonstrates empirical speedups on real-world datasets, showing practical benefits for large-scale TPP applications.", "conclusion": "The method closes the gap between expressive TPP modeling and efficient parallel generation, enabling scalable, exact multi-step sampling without additional training or architectural modification."}}
{"id": "2510.20706", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20706", "abs": "https://arxiv.org/abs/2510.20706", "authors": ["Ganga Nair B", "Prakrut Kotecha", "Shishir Kolathaya"], "title": "Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning", "comment": null, "summary": "Model-free reinforcement learning (RL) has enabled adaptable and agile\nquadruped locomotion; however, policies often converge to a single gait,\nleading to suboptimal performance. Traditionally, Model Predictive Control\n(MPC) has been extensively used to obtain task-specific optimal policies but\nlacks the ability to adapt to varying environments. To address these\nlimitations, we propose an optimization framework for real-time gait adaptation\nin a continuous gait space, combining the Model Predictive Path Integral (MPPI)\nalgorithm with a Dreamer module to produce adaptive and optimal policies for\nquadruped locomotion. At each time step, MPPI jointly optimizes the actions and\ngait variables using a learned Dreamer reward that promotes velocity tracking,\nenergy efficiency, stability, and smooth transitions, while penalizing abrupt\ngait changes. A learned value function is incorporated as terminal reward,\nextending the formulation to an infinite-horizon planner. We evaluate our\nframework in simulation on the Unitree Go1, demonstrating an average reduction\nof up to 36.48\\% in energy consumption across varying target speeds, while\nmaintaining accurate tracking and adaptive, task-appropriate gaits.", "AI": {"tldr": "A model-free RL framework combines MPPI and Dreamer to adapt quadruped gait in a continuous gait space, achieving energy-efficient, adaptive gaits with real-time optimization.", "motivation": "Conventional model-free RL tends to converge to a single gait; MPC yields optimal policies but struggles to adapt to changing environments. The paper aims to enable real-time, adaptive gait optimization across a continuum of gaits.", "method": "At each step, MPPI jointly optimizes actions and gait variables using a Dreamer-based reward; includes velocity tracking, energy efficiency, stability, smooth gait transitions; penalties for abrupt gait changes; a learned value function is used as terminal reward, enabling infinite-horizon planning.", "result": "In simulation on Unitree Go1, energy consumption reduced by up to 36.48% across target speeds, with accurate tracking and adaptive gaits.", "conclusion": "The framework enables real-time, continuous-gait adaptation with improved energy efficiency and task-appropriate locomotion, validated in simulation; suggests potential for deployment on physical quadrupeds with learned rewards."}}
{"id": "2510.20165", "categories": ["cs.CV", "cs.AI", "68T45 (Machine learning in discrete mathematics), 68T07 (Artificial\n  neural networks and deep learning)"], "pdf": "https://arxiv.org/pdf/2510.20165", "abs": "https://arxiv.org/abs/2510.20165", "authors": ["Insu Jeon", "Wonkwang Lee", "Myeongjang Pyeon", "Gunhee Kim"], "title": "IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks", "comment": "Published in the Proceedings of the Thirty Fifth AAAI Conference on\n  Artificial Intelligence (AAAI 2021), paper number 7926", "summary": "We propose a new GAN-based unsupervised model for disentangled representation\nlearning. The new model is discovered in an attempt to utilize the Information\nBottleneck (IB) framework to the optimization of GAN, thereby named IB-GAN. The\narchitecture of IB-GAN is partially similar to that of InfoGAN but has a\ncritical difference; an intermediate layer of the generator is leveraged to\nconstrain the mutual information between the input and the generated output.\nThe intermediate stochastic layer can serve as a learnable latent distribution\nthat is trained with the generator jointly in an end-to-end fashion. As a\nresult, the generator of IB-GAN can harness the latent space in a disentangled\nand interpretable manner. With the experiments on dSprites and Color-dSprites\ndataset, we demonstrate that IB-GAN achieves competitive disentanglement scores\nto those of state-of-the-art \\b{eta}-VAEs and outperforms InfoGAN. Moreover,\nthe visual quality and the diversity of samples generated by IB-GAN are often\nbetter than those by \\b{eta}-VAEs and Info-GAN in terms of FID score on CelebA\nand 3D Chairs dataset.", "AI": {"tldr": "IB-GAN introduces an information-bottleneck-based GAN where an intermediate stochastic layer acts as a learnable latent distribution, enabling disentangled representations. It achieves competitive disentanglement with beta-VAE and outperforms InfoGAN, and shows improved sample quality (lower FID) on CelebA and 3D Chairs.", "motivation": "To achieve disentangled representations within GANs by leveraging the Information Bottleneck (IB) framework, addressing limited disentanglement and controllability in existing GAN variants like InfoGAN.", "method": "Incorporate the IB principle into GAN training by using an intermediate stochastic layer in the generator that constrains mutual information between the input and generated output. This layer serves as a learnable latent distribution trained end-to-end with the generator, enabling disentangled and interpretable latent factors.", "result": "Experimental results on dSprites and Color-dSprites show IB-GAN attains disentanglement scores competitive with beta-VAE and better than InfoGAN. On CelebA and 3D Chairs, the generated samples exhibit improved visual quality and diversity, as reflected by favorable FID scores compared to beta-VAE and InfoGAN.", "conclusion": "IB-GAN demonstrates that applying the Information Bottleneck to GANs can yield disentangled, interpretable latent representations without sacrificing, and potentially improving, sample quality relative to existing disentanglement-oriented models like InfoGAN and beta-VAE."}}
{"id": "2510.20337", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20337", "abs": "https://arxiv.org/abs/2510.20337", "authors": ["Clara Maathuis", "Kasper Cools"], "title": "Collateral Damage Assessment Model for AI System Target Engagement in Military Operations", "comment": "Accepted at MILCOM 2025 WS07", "summary": "In an era where AI (Artificial Intelligence) systems play an increasing role\nin the battlefield, ensuring responsible targeting demands rigorous assessment\nof potential collateral effects. In this context, a novel collateral damage\nassessment model for target engagement of AI systems in military operations is\nintroduced. The model integrates temporal, spatial, and force dimensions within\na unified Knowledge Representation and Reasoning (KRR) architecture following a\ndesign science methodological approach. Its layered structure captures the\ncategories and architectural components of the AI systems to be engaged\ntogether with corresponding engaging vectors and contextual aspects. At the\nsame time, spreading, severity, likelihood, and evaluation metrics are\nconsidered in order to provide a clear representation enhanced by transparent\nreasoning mechanisms. Further, the model is demonstrated and evaluated through\ninstantiation which serves as a basis for further dedicated efforts that aim at\nbuilding responsible and trustworthy intelligent systems for assessing the\neffects produced by engaging AI systems in military operations.", "AI": {"tldr": "Proposes a collateral damage assessment model for AI-enabled battlefield targeting using a layered Knowledge Representation and Reasoning architecture that integrates temporal, spatial, and force dimensions with explicit metrics and transparent reasoning.", "motivation": "To ensure responsible and trustworthy engagement of AI systems in military operations by systematically evaluating potential collateral effects and enabling transparent, accountable decision-making.", "method": "Design-science\u2013driven development of a layered KRR architecture that captures AI system categories/components, engagement vectors, and contextual factors; integrates spreading, severity, and likelihood alongside evaluation metrics; demonstrated via instantiation for demonstration and evaluation.", "result": "A formally structured model and instantiation that yields transparent reasoning about potential collateral effects, supporting more responsible assessment and providing a basis for further dedicated work in trustworthy AI for military engagements.", "conclusion": "The approach offers a structured, explainable framework for assessing collateral damage in AI-enabled targeting, with potential to improve safety and accountability, though further empirical validation and refinement are needed for real-world deployment."}}
{"id": "2510.20055", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.20055", "abs": "https://arxiv.org/abs/2510.20055", "authors": ["Yuwei Cheng", "Zifeng Zhao", "Haifeng Xu"], "title": "Learning Personalized Ad Impact via Contextual Reinforcement Learning under Delayed Rewards", "comment": null, "summary": "Online advertising platforms use automated auctions to connect advertisers\nwith potential customers, requiring effective bidding strategies to maximize\nprofits. Accurate ad impact estimation requires considering three key factors:\ndelayed and long-term effects, cumulative ad impacts such as reinforcement or\nfatigue, and customer heterogeneity. However, these effects are often not\njointly addressed in previous studies. To capture these factors, we model ad\nbidding as a Contextual Markov Decision Process (CMDP) with delayed Poisson\nrewards. For efficient estimation, we propose a two-stage maximum likelihood\nestimator combined with data-splitting strategies, ensuring controlled\nestimation error based on the first-stage estimator's (in)accuracy. Building on\nthis, we design a reinforcement learning algorithm to derive efficient\npersonalized bidding strategies. This approach achieves a near-optimal regret\nbound of $\\tilde{O}{(dH^2\\sqrt{T})}$, where $d$ is the contextual dimension,\n$H$ is the number of rounds, and $T$ is the number of customers. Our\ntheoretical findings are validated by simulation experiments.", "AI": {"tldr": "Introduces a Contextual MDP framework for online ad bidding with delayed Poisson rewards, plus a two-stage maximum likelihood estimator with data-splitting and a reinforcement learning algorithm that achieves near-optimal regret; validated via simulations.", "motivation": "Online advertising auctions require accounting for delayed and long-term effects, cumulative ad impacts (reinforcement or fatigue), and user heterogeneity. These factors are seldom addressed jointly in prior work, limiting accurate estimation and effective bidding.", "method": "Model the bidding problem as a Contextual MDP with delayed Poisson rewards. Propose a two-stage maximum likelihood estimator with data-splitting to control estimation error based on the first-stage accuracy. Build a reinforcement learning algorithm to derive personalized bidding strategies.", "result": "Theoretical regret bound of tilde O(d H^2 sqrt(T)) for the proposed RL algorithm. Simulation experiments corroborate the theoretical findings, demonstrating effective personalized bidding performance.", "conclusion": "A joint framework combining estimation and RL for contextual bidding under delayed effects; provides controlled estimation error and near-optimal regret, with simulations validating its promise for practical deployment in ad platforms."}}
{"id": "2510.20774", "categories": ["cs.RO", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.20774", "abs": "https://arxiv.org/abs/2510.20774", "authors": ["Wenhao Wang", "Kehe Ye", "Xinyu Zhou", "Tianxing Chen", "Cao Min", "Qiaoming Zhu", "Xiaokang Yang", "Yongjian Shen", "Yang Yang", "Maoqing Yao", "Yao Mu"], "title": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation", "comment": "Webpage: https://fieldgen.github.io/", "summary": "Large-scale and diverse datasets are vital for training robust robotic\nmanipulation policies, yet existing data collection methods struggle to balance\nscale, diversity, and quality. Simulation offers scalability but suffers from\nsim-to-real gaps, while teleoperation yields high-quality demonstrations with\nlimited diversity and high labor cost. We introduce FieldGen, a field-guided\ndata generation framework that enables scalable, diverse, and high-quality\nreal-world data collection with minimal human supervision. FieldGen decomposes\nmanipulation into two stages: a pre-manipulation phase, allowing trajectory\ndiversity, and a fine manipulation phase requiring expert precision. Human\ndemonstrations capture key contact and pose information, after which an\nattraction field automatically generates diverse trajectories converging to\nsuccessful configurations. This decoupled design combines scalable trajectory\ndiversity with precise supervision. Moreover, FieldGen-Reward augments\ngenerated data with reward annotations to further enhance policy learning.\nExperiments demonstrate that policies trained with FieldGen achieve higher\nsuccess rates and improved stability compared to teleoperation-based baselines,\nwhile significantly reducing human effort in long-term real-world data\ncollection. Webpage is available at https://fieldgen.github.io/.", "AI": {"tldr": "FieldGen uses an attractor-field-guided data generation to collect scalable, diverse, high-quality real-world manipulation data with minimal supervision, achieving better policy performance than teleoperation while cutting human effort.", "motivation": "There is a need for large-scale, diverse, and high-quality real-world data for robotic manipulation. Simulation suffers from sim-to-real gaps, and teleoperation provides high-quality data but with limited diversity and high labor costs.", "method": "FieldGen decomposes manipulation into two stages: a pre-manipulation phase to diversify trajectories and a fine manipulation phase requiring precision. Human demonstrations capture key contact and pose information; an attraction field automatically generates diverse trajectories converging to successful configurations. FieldGen-Reward provides reward annotations to further enhance learning.", "result": "Policies trained with FieldGen show higher success rates and improved stability compared to teleoperation baselines, while significantly reducing human effort in long-term real-world data collection.", "conclusion": "FieldGen enables scalable, diverse, and high-quality real-world data collection with minimal supervision by decoupling trajectory diversity from precise manipulation; the reward-augmented variant further improves policy learning."}}
{"id": "2510.20178", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20178", "abs": "https://arxiv.org/abs/2510.20178", "authors": ["Yun Wang", "Junjie Hu", "Qiaole Dong", "Yongjian Zhang", "Yanwei Fu", "Tin Lun Lam", "Dapeng Wu"], "title": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching", "comment": null, "summary": "Temporally consistent depth estimation from stereo video is critical for\nreal-world applications such as augmented reality, where inconsistent depth\nestimation disrupts the immersion of users. Despite its importance, this task\nremains challenging due to the difficulty in modeling long-term temporal\nconsistency in a computationally efficient manner. Previous methods attempt to\naddress this by aggregating spatio-temporal information but face a fundamental\ntrade-off: limited temporal modeling provides only modest gains, whereas\ncapturing long-range dependencies significantly increases computational cost.\nTo address this limitation, we introduce a memory buffer for modeling\nlong-range spatio-temporal consistency while achieving efficient dynamic stereo\nmatching. Inspired by the two-stage decision-making process in humans, we\npropose a \\textbf{P}ick-and-\\textbf{P}lay \\textbf{M}emory (PPM) construction\nmodule for dynamic \\textbf{Stereo} matching, dubbed as \\textbf{PPMStereo}. PPM\nconsists of a `pick' process that identifies the most relevant frames and a\n`play' process that weights the selected frames adaptively for spatio-temporal\naggregation. This two-stage collaborative process maintains a compact yet\nhighly informative memory buffer while achieving temporally consistent\ninformation aggregation. Extensive experiments validate the effectiveness of\nPPMStereo, demonstrating state-of-the-art performance in both accuracy and\ntemporal consistency. % Notably, PPMStereo achieves 0.62/1.11 TEPE on the\nSintel clean/final (17.3\\% \\& 9.02\\% improvements over BiDAStereo) with fewer\ncomputational costs. Codes are available at\n\\textcolor{blue}{https://github.com/cocowy1/PPMStereo}.", "AI": {"tldr": "PPMStereo introduces a Pick-and-Play Memory (PPM) module for dynamic stereo matching that maintains a compact, informative memory buffer to model long-range spatio-temporal consistency, enabling temporally consistent depth estimation with efficient computation.", "motivation": "Temporally consistent depth estimation from stereo video is essential for AR/VR experiences, but modeling long-range temporal dependencies is computationally expensive. Prior approaches face a trade-off between temporal modeling capacity and efficiency.", "method": "A two-stage Pick-and-Play Memory (PPM) module stores a memory buffer for dynamic stereo matching. The 'pick' stage identifies the most relevant frames; the 'play' stage adaptively weights these frames for spatio-temporal aggregation, enabling long-range consistency with low computational overhead.", "result": "Extensive experiments show state-of-the-art performance in accuracy and temporal consistency (e.g., on Sintel benchmarks) with reduced computational costs compared to baselines such as BiDAStereo; code is publicly available.", "conclusion": "PPMStereo provides an effective, efficient approach to long-range temporal modeling in dynamic stereo matching by using a compact memory buffer and a two-stage pick-and-play strategy, achieving superior temporal consistency and accuracy while reducing computational burden."}}
{"id": "2510.20345", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20345", "abs": "https://arxiv.org/abs/2510.20345", "authors": ["Haonan Bian"], "title": "LLM-empowered knowledge graph construction: A survey", "comment": null, "summary": "Knowledge Graphs (KGs) have long served as a fundamental infrastructure for\nstructured knowledge representation and reasoning. With the advent of Large\nLanguage Models (LLMs), the construction of KGs has entered a new\nparadigm-shifting from rule-based and statistical pipelines to language-driven\nand generative frameworks. This survey provides a comprehensive overview of\nrecent progress in LLM-empowered knowledge graph construction, systematically\nanalyzing how LLMs reshape the classical three-layered pipeline of ontology\nengineering, knowledge extraction, and knowledge fusion.\n  We first revisit traditional KG methodologies to establish conceptual\nfoundations, and then review emerging LLM-driven approaches from two\ncomplementary perspectives: schema-based paradigms, which emphasize structure,\nnormalization, and consistency; and schema-free paradigms, which highlight\nflexibility, adaptability, and open discovery. Across each stage, we synthesize\nrepresentative frameworks, analyze their technical mechanisms, and identify\ntheir limitations.\n  Finally, the survey outlines key trends and future research directions,\nincluding KG-based reasoning for LLMs, dynamic knowledge memory for agentic\nsystems, and multimodal KG construction. Through this systematic review, we aim\nto clarify the evolving interplay between LLMs and knowledge graphs, bridging\nsymbolic knowledge engineering and neural semantic understanding toward the\ndevelopment of adaptive, explainable, and intelligent knowledge systems.", "AI": {"tldr": "A survey of how LLMs reshape knowledge-graph construction, comparing schema-based and schema-free approaches across ontology engineering, extraction, and fusion, and outlining future directions such as KG-based reasoning, dynamic memory for agents, and multimodal KG construction.", "motivation": "LLMs enable language-driven, generative KG pipelines, promising more flexible and capable knowledge systems, but require systematic analysis to bridge symbolic KG engineering with neural semantic understanding.", "method": "Systematic literature review anchored in traditional KG methodologies; categorize LL-driven work into schema-based and schema-free paradigms; analyze mechanisms and limitations across ontology engineering, extraction, and fusion; synthesize frameworks and trends.", "result": "Identifies benefits and challenges of LLM-driven KG construction: improved integration and generation across stages but issues with consistency, reliability, and scalability. Schema-based approaches emphasize structure and normalization; schema-free approaches emphasize adaptability and discovery. Highlights directions like KG-based reasoning for LLMs, dynamic memory for agentic systems, and multimodal KG construction.", "conclusion": "The field is converging toward adaptive, explainable knowledge systems that integrate symbolic KG engineering with neural semantic understanding; future work should advance KG-based reasoning for LLMs, dynamic memory in agents, and multimodal KGs to enable robust, intelligent KGs."}}
{"id": "2510.20064", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20064", "abs": "https://arxiv.org/abs/2510.20064", "authors": ["Hongyi Liu", "Jiaji Huang", "Zhen Jia", "Youngsuk Park", "Yu-Xiang Wang"], "title": "Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs", "comment": null, "summary": "Speculative decoding is widely used in accelerating large language model\n(LLM) inference. In this work, we focus on the online draft model selection\nproblem in speculative decoding. We design an algorithm that provably competes\nwith the best draft model in hindsight for each query in terms of either the\ntoken acceptance probability or expected acceptance length. In particular, we\nshow that we can accurately evaluate all draft models, instead of only the\nchosen model without incurring additional queries to the target model, which\nallows us to improve exponentially over the existing bandit-based approach as\nthe number of draft models increases. Our approach is generically applicable\nwith any speculative decoding methods (single draft, multi-drafts and\ndraft-trees). Moreover, we design system-efficient versions of online learners\nand demonstrate that the overhead in computation and latency can be\nsubstantially reduced. We conduct extensive experiments on open-source LLMs and\ndiverse datasets, demonstrating that our methods substantially outperform the\nstate-of-the-art EAGLE3 and the BanditSpec baseline in a variety of domains\nwhere specialized domain-expert drafters are available, especially when long\nreasoning chains are required.", "AI": {"tldr": "Proposes an online draft-model selection algorithm for speculative decoding that provably competes with the best draft model in hindsight, enabling evaluation of all drafts without extra queries and achieving exponential improvement over bandit approaches; applicable to single/multi-draft and draft-tree methods; includes system-efficient online learners and strong empirical gains vs EAGLE3 and BanditSpec, especially for long reasoning chains.", "motivation": "Improve draft-model selection in speculative decoding by obtaining theoretical guarantees and reducing overhead, enabling accurate evaluation of all drafts without additional queries to the target model.", "method": "Designs an online learning algorithm that, for each query, competes with the best draft model in hindsight using metrics like token acceptance probability or expected acceptance length; can evaluate all drafts without extra target-model queries; applicable to various speculative decoding setups; provides system-efficient implementations of online learners.", "result": "The approach achieves provable competitive guarantees and empirically outperforms state-of-the-art baselines (EAGLE3, BanditSpec) across multiple datasets and domains, particularly when long reasoning chains are required.", "conclusion": "The framework generalizes speculative decoding, enabling more effective, lower-cost draft-model selection with strong theoretical guarantees and practical performance gains."}}
{"id": "2510.20808", "categories": ["cs.RO", "cs.AI", "cs.LG", "stat.ML", "I.2.6; I.2.8; I.2.9"], "pdf": "https://arxiv.org/pdf/2510.20808", "abs": "https://arxiv.org/abs/2510.20808", "authors": ["Elie Aljalbout", "Jiaxu Xing", "Angel Romero", "Iretiayo Akinola", "Caelan Reed Garrett", "Eric Heiden", "Abhishek Gupta", "Tucker Hermans", "Yashraj Narang", "Dieter Fox", "Davide Scaramuzza", "Fabio Ramos"], "title": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices", "comment": "Accepted for Publication as part of the Annual Review of Control,\n  Robotics, and Autonomous Systems 2026", "summary": "Machine learning has facilitated significant advancements across various\nrobotics domains, including navigation, locomotion, and manipulation. Many such\nachievements have been driven by the extensive use of simulation as a critical\ntool for training and testing robotic systems prior to their deployment in\nreal-world environments. However, simulations consist of abstractions and\napproximations that inevitably introduce discrepancies between simulated and\nreal environments, known as the reality gap. These discrepancies significantly\nhinder the successful transfer of systems from simulation to the real world.\nClosing this gap remains one of the most pressing challenges in robotics.\nRecent advances in sim-to-real transfer have demonstrated promising results\nacross various platforms, including locomotion, navigation, and manipulation.\nBy leveraging techniques such as domain randomization, real-to-sim transfer,\nstate and action abstractions, and sim-real co-training, many works have\novercome the reality gap. However, challenges persist, and a deeper\nunderstanding of the reality gap's root causes and solutions is necessary. In\nthis survey, we present a comprehensive overview of the sim-to-real landscape,\nhighlighting the causes, solutions, and evaluation metrics for the reality gap\nand sim-to-real transfer.", "AI": {"tldr": "A survey of sim-to-real transfer in robotics, outlining the reality gap, existing solutions (domain randomization, real-to-sim transfer, state/action abstractions, sim-real co-training), evaluation metrics, and persisting challenges.", "motivation": "Closing the simulation-to-reality gap is critical for reliable deployment of learned robotic policies from simulation to the real world.", "method": "Literature survey and synthesis: taxonomy of root causes of the reality gap, review of proposed solutions and evaluation metrics, and discussion of gaps and future directions.", "result": "A comprehensive overview and taxonomy of the sim-to-real landscape, summarizing current methods, their evaluation, practical guidance for researchers, and a synthesis of progress and limitations.", "conclusion": "While advances exist across locomotion, navigation, and manipulation, the reality gap remains a core challenge; there is a need for deeper cause analysis, standardized evaluation, and integrated approaches to improve sim-to-real transfer."}}
{"id": "2510.20182", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20182", "abs": "https://arxiv.org/abs/2510.20182", "authors": ["Aaron Appelle", "Jerome P. Lynch"], "title": "Evaluating Video Models as Simulators of Multi-Person Pedestrian Trajectories", "comment": "Preprint, under review", "summary": "Large-scale video generation models have demonstrated high visual realism in\ndiverse contexts, spurring interest in their potential as general-purpose world\nsimulators. Existing benchmarks focus on individual subjects rather than scenes\nwith multiple interacting people. However, the plausibility of multi-agent\ndynamics in generated videos remains unverified. We propose a rigorous\nevaluation protocol to benchmark text-to-video (T2V) and image-to-video (I2V)\nmodels as implicit simulators of pedestrian dynamics. For I2V, we leverage\nstart frames from established datasets to enable comparison with a ground truth\nvideo dataset. For T2V, we develop a prompt suite to explore diverse pedestrian\ndensities and interactions. A key component is a method to reconstruct 2D\nbird's-eye view trajectories from pixel-space without known camera parameters.\nOur analysis reveals that leading models have learned surprisingly effective\npriors for plausible multi-agent behavior. However, failure modes like merging\nand disappearing people highlight areas for future improvement.", "AI": {"tldr": "A protocol to benchmark text-to-video (T2V) and image-to-video (I2V) models as implicit simulators of pedestrian dynamics, using I2V ground-truth frames and a T2V prompt suite, plus a camera-free method to reconstruct 2D trajectories. Finds plausible multi-agent behavior but with failure modes like merging and disappearing pedestrians.", "motivation": "Assess whether large-scale video generation models can serve as general-purpose world simulators for multi-agent scenes, addressing a gap where existing benchmarks focus on single subjects.", "method": "For I2V: use start frames from established datasets to enable comparison with ground-truth videos. For T2V: develop a prompt suite to explore diverse pedestrian densities and interactions. Introduce a method to reconstruct 2D bird's-eye-view trajectories from pixel-space without known camera parameters.", "result": "Leading models exhibit surprisingly effective priors for plausible multi-agent behavior; however, failure modes such as merging and disappearing people highlight areas for improvement.", "conclusion": "The protocol reveals promise of current models as implicit simulators for pedestrian dynamics while identifying specific failure modes and avenues for enhancement in multi-agent consistency and reidentification."}}
{"id": "2510.20377", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20377", "abs": "https://arxiv.org/abs/2510.20377", "authors": ["Tianyi Zhang", "Florian Mai", "Lucie Flek"], "title": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation", "comment": null, "summary": "Continual pretraining promises to adapt large language models (LLMs) to new\ndomains using only unlabeled test-time data, but naively applying standard\nself-supervised objectives to instruction-tuned models is known to degrade\ntheir instruction-following capability and semantic representations. Existing\nfixes assume access to the original base model or rely on knowledge from an\nexternal domain-specific database - both of which pose a realistic barrier in\nsettings where the base model weights are withheld for safety reasons or\nreliable external corpora are unavailable. In this work, we propose\nInstruction-Knowledge-Aware Continual Adaptation (IKnow), a simple and general\nframework that formulates novel self-supervised objectives in the\ninstruction-response dialogue format. Rather than depend- ing on external\nresources, IKnow leverages domain knowledge embedded within the text itself and\nlearns to encode it at a deeper semantic level.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.20066", "categories": ["cs.LG", "cs.CE", "econ.EM"], "pdf": "https://arxiv.org/pdf/2510.20066", "abs": "https://arxiv.org/abs/2510.20066", "authors": ["Yimeng Qiu", "Feihuang Fang"], "title": "A Multi-Layer Machine Learning and Econometric Pipeline for Forecasting Market Risk: Evidence from Cryptoasset Liquidity Spillovers", "comment": null, "summary": "We study whether liquidity and volatility proxies of a core set of\ncryptoassets generate spillovers that forecast market-wide risk. Our empirical\nframework integrates three statistical layers: (A) interactions between core\nliquidity and returns, (B) principal-component relations linking liquidity and\nreturns, and (C) volatility-factor projections that capture cross-sectional\nvolatility crowding. The analysis is complemented by vector autoregression\nimpulse responses and forecast error variance decompositions (see Granger 1969;\nSims 1980), heterogeneous autoregressive models with exogenous regressors\n(HAR-X, Corsi 2009), and a leakage-safe machine learning protocol using\ntemporal splits, early stopping, validation-only thresholding, and SHAP-based\ninterpretation. Using daily data from 2021 to 2025 (1462 observations across 74\nassets), we document statistically significant Granger-causal relationships\nacross layers and moderate out-of-sample predictive accuracy. We report the\nmost informative figures, including the pipeline overview, Layer A heatmap,\nLayer C robustness analysis, vector autoregression variance decompositions, and\nthe test-set precision-recall curve. Full data and figure outputs are provided\nin the artifact repository.", "AI": {"tldr": "A multi-layer empirical study on whether core cryptoassets' liquidity and volatility proxies generate spillovers that forecast market-wide risk; it combines A) liquidity-returns interactions, B) PCA-based liquidity-returns relations, and C) volatility-crowding factors, using VARs, HAR-X, and leakage-safe ML with SHAP. It analyzes daily data (2021\u20132025) across 74 assets, finds significant cross-layer Granger-causality and moderate out-of-sample predictive accuracy, and provides artifacts and figures.", "motivation": "To determine whether microstructure-like signals (liquidity and volatility proxies) in a core cryptoasset set can forecast systemic market risk, and to integrate multiple analytical layers and interpretable ML to assess spillovers and forecastability.", "method": "Three-layer framework: Layer A \u2014 interactions between core liquidity and returns; Layer B \u2014 principal-component relations linking liquidity and returns; Layer C \u2014 volatility-factor projections capturing cross-sectional volatility crowding. Supplemented by VAR impulse responses and forecast error variance decompositions; HAR-X models; leakage-safe machine learning with temporal splits, early stopping, validation-thresholding, and SHAP-based interpretation. Data: daily observations from 2021\u20132025 (1,462 obs across 74 assets). Outputs include pipeline overview, Layer A heatmap, Layer C robustness analysis, VAR variance decompositions, and test-set precision-recall curves; full data/figures in artifact repository.", "result": "Evidence of statistically significant Granger-causal relationships across the three layers, with moderate out-of-sample predictive accuracy. Layer C robustness analyses and various figures (VAR decompositions, precision-recall curves) support the robustness of findings; comprehensive data and figures are archived in the artifact repository.", "conclusion": "A multi-layer framework can reveal meaningful cross-layer spillovers from liquidity and volatility proxies to market-wide risk in crypto markets, with interpretable ML components (SHAP) and transparent evaluation; the work provides data and figures for replication and future research."}}
{"id": "2510.20813", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20813", "abs": "https://arxiv.org/abs/2510.20813", "authors": ["Guangqi Jiang", "Haoran Chang", "Ri-Zhao Qiu", "Yutong Liang", "Mazeyu Ji", "Jiyue Zhu", "Zhao Dong", "Xueyan Zou", "Xiaolong Wang"], "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation", "comment": null, "summary": "This paper presents GSWorld, a robust, photo-realistic simulator for robotics\nmanipulation that combines 3D Gaussian Splatting with physics engines. Our\nframework advocates \"closing the loop\" of developing manipulation policies with\nreproducible evaluation of policies learned from real-robot data and sim2real\npolicy training without using real robots. To enable photo-realistic rendering\nof diverse scenes, we propose a new asset format, which we term GSDF (Gaussian\nScene Description File), that infuses Gaussian-on-Mesh representation with\nrobot URDF and other objects. With a streamlined reconstruction pipeline, we\ncurate a database of GSDF that contains 3 robot embodiments for single-arm and\nbimanual manipulation, as well as more than 40 objects. Combining GSDF with\nphysics engines, we demonstrate several immediate interesting applications: (1)\nlearning zero-shot sim2real pixel-to-action manipulation policy with\nphoto-realistic rendering, (2) automated high-quality DAgger data collection\nfor adapting policies to deployment environments, (3) reproducible benchmarking\nof real-robot manipulation policies in simulation, (4) simulation data\ncollection by virtual teleoperation, and (5) zero-shot sim2real visual\nreinforcement learning. Website: https://3dgsworld.github.io/.", "AI": {"tldr": "GSWorld introduces a photo-realistic robotics manipulation simulator that fuses 3D Gaussian Splatting with physics engines and a new Gaussian Scene Description File (GSDF) to enable reproducible, zero-shot sim2real and policy benchmarking across multiple robots and objects.", "motivation": "There is a need for reproducible, photo-realistic simulation that can closely reflect real-robot data and support sim-to-real policy training without using real robots, closing the loop in manipulation research.", "method": "Combine 3D Gaussian Splatting rendering with physics engines; create GSDF asset format (Gaussian-on-Mesh with URDF and objects); assemble a GSDF database featuring 3 robot embodiments (single-arm and bimanual) and 40+ objects; apply the framework to zero-shot sim2real learning, automated high-quality DAgger data collection, reproducible benchmarking, virtual teleoperation data collection, and zero-shot visual RL.", "result": "Demonstrates practical applications including (1) zero-shot, pixel-to-action manipulation with photo-realistic rendering, (2) automated high-quality DAgger data collection for deployment adaptation, (3) reproducible real-robot policy benchmarks in simulation, (4) simulation data collection via virtual teleoperation, (5) zero-shot sim2real visual reinforcement learning.", "conclusion": "GSWorld provides a robust, reproducible pipeline for photo-realistic manipulation simulation, enabling close-loop development from real data to sim2real training, with the GSDF asset format facilitating scalable, diverse scenes and robot embodiments."}}
{"id": "2510.20189", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20189", "abs": "https://arxiv.org/abs/2510.20189", "authors": ["Xinyi Hu", "Yuran Wang", "Yue Li", "Wenxuan Liu", "Zheng Wang"], "title": "SPAN: Continuous Modeling of Suspicion Progression for Temporal Intention Localization", "comment": null, "summary": "Temporal Intention Localization (TIL) is crucial for video surveillance,\nfocusing on identifying varying levels of suspicious intentions to improve\nsecurity monitoring. However, existing discrete classification methods fail to\ncapture the continuous nature of suspicious intentions, limiting early\nintervention and explainability. In this paper, we propose the Suspicion\nProgression Analysis Network (SPAN), which shifts from discrete classification\nto continuous regression, enabling the capture of fluctuating and evolving\nsuspicious intentions. We reveal that suspicion exhibits long-term dependencies\nand cumulative effects, similar to Temporal Point Process (TPP) theory. Based\non these insights, we define a suspicion score formula that models continuous\nchanges while accounting for temporal characteristics. We also introduce\nSuspicion Coefficient Modulation, which adjusts suspicion coefficients using\nmultimodal information to reflect the varying impacts of suspicious actions.\nAdditionally, the Concept-Anchored Mapping method is proposed to link\nsuspicious actions to predefined intention concepts, offering insights into\nboth the actions and their potential underlying intentions. Extensive\nexperiments on the HAI dataset show that SPAN significantly outperforms\nexisting methods, reducing MSE by 19.8% and improving average mAP by 1.78%.\nNotably, SPAN achieves a 2.74% mAP gain in low-frequency cases, demonstrating\nits superior ability to capture subtle behavioral changes. Compared to discrete\nclassification systems, our continuous suspicion modeling approach enables\nearlier detection and proactive intervention, greatly enhancing system\nexplainability and practical utility in security applications.", "AI": {"tldr": "SPAN reframes Temporal Intention Localization as continuous regression to model evolving suspicion, leveraging a Temporal Point Process\u2013like suspicion score, multimodal coefficient modulation, and concept-anchored mapping, achieving superior performance and earlier, more explainable detection on HAI.", "motivation": "Discrete classification cannot capture the gradual evolution and long-term dependencies of suspicious behavior, limiting early intervention and interpretability.", "method": "Introduce Suspicion Progression Analysis Network (SPAN) with a continuous suspicion score based on a progression formula inspired by Temporal Point Process; apply Suspicion Coefficient Modulation using multimodal information; use Concept-Anchored Mapping to link actions to predefined intention concepts; evaluate on the HAI dataset.", "result": "Outperforms prior methods, reducing MSE by 19.8% and increasing average mAP by 1.78%, with a 2.74% mAP gain in low-frequency cases, demonstrating improved sensitivity to subtle changes and earlier detection.", "conclusion": "Continuous modeling of suspicion enables earlier, proactive intervention and enhances explainability, representing a practical and effective advancement in security-oriented video analysis."}}
{"id": "2510.20402", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20402", "abs": "https://arxiv.org/abs/2510.20402", "authors": ["Neil Maiden", "Konstantinos Zachos", "James Lockerbie", "Kostas Petrianakis", "Amanda Brown"], "title": "A computational model and tool for generating more novel opportunities in professional innovation processes", "comment": null, "summary": "This paper presents a new computational model of creative outcomes, informed\nby creativity theories and techniques, which was implemented to generate more\nnovel opportunities for innovation projects. The model implemented five\nfunctions that were developed to contribute to the generation of innovation\nopportunities with higher novelty without loss of usefulness. The model was\nevaluated using opportunities generated for an innovation project in the\nhospitality sector. The evaluation revealed that the computational model\ngenerated outcomes that were more novel and/or useful than outcomes from\nNotebook LM and ChatGPT4o. However, not all model functions contributed to the\ngeneration of more novel opportunities, leading to new directions for further\nmodel development", "AI": {"tldr": "A novel five-function computational model to improve novelty of innovation opportunities; in hospitality domain, outperforming Notebook LM and ChatGPT4o on novelty/usefulness; some functions underperforming, prompting further work.", "motivation": "To integrate creativity theories and techniques into a computational pipeline to produce more novel yet useful innovation opportunities, addressing limits of generic LMs in creative tasks.", "method": "Implemented five distinct functions within a computational model; applied to generate opportunities for an innovation project in the hospitality sector; evaluated against Notebook LM and ChatGPT4o on novelty and usefulness of outputs.", "result": "Outcomes were more novel and/or useful than baselines; however, not all functions contributed to novelty, indicating uneven function contributions and room for refinement.", "conclusion": "The model shows promise for enhancing creative output; future work should dissect function contributions, optimize or replace underperforming components, and test across domains for generalizability."}}
{"id": "2510.20068", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20068", "abs": "https://arxiv.org/abs/2510.20068", "authors": ["Ram Dyuthi Sristi", "Sowmya Manojna Narasimha", "Jingya Huang", "Alice Despatin", "Simon Musall", "Vikash Gilja", "Gal Mishne"], "title": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics", "comment": null, "summary": "Simultaneous recordings from thousands of neurons across multiple brain areas\nreveal rich mixtures of activity that are shared between regions and dynamics\nthat are unique to each region. Existing alignment or multi-view methods\nneglect temporal structure, whereas dynamical latent variable models capture\ntemporal dependencies but are usually restricted to a single area, assume\nlinear read-outs, or conflate shared and private signals. We introduce the\nCoupled Transformer Autoencoder (CTAE) - a sequence model that addresses both\n(i) non-stationary, non-linear dynamics and (ii) separation of shared versus\nregion-specific structure in a single framework. CTAE employs transformer\nencoders and decoders to capture long-range neural dynamics and explicitly\npartitions each region's latent space into orthogonal shared and private\nsubspaces. We demonstrate the effectiveness of CTAE on two high-density\nelectrophysiology datasets with simultaneous recordings from multiple regions,\none from motor cortical areas and the other from sensory areas. CTAE extracts\nmeaningful representations that better decode behavioral variables compared to\nexisting approaches.", "AI": {"tldr": "A transformer-based autoencoder that jointly models non-linear, non-stationary dynamics across multiple brain regions while disentangling shared vs. region-specific latent structure, yielding better behavioral decoding than prior methods.", "motivation": "To overcome the limitations of existing alignment/multi-view methods (which neglect temporal structure) and dynamical latent variable models (which are usually restricted to a single area, assume linear read-outs, or conflate shared and private signals) by providing a unified framework for cross-region neural dynamics.", "method": "Introduce Coupled Transformer Autoencoder (CTAE) using transformer encoders/decoders to capture long-range temporal dynamics. Each region has a latent space partitioned into orthogonal shared and private subspaces, enabling explicit separation of cross-region shared dynamics from region-specific activity within a single model.", "result": "Applied to two high-density electrophysiology datasets with simultaneous multi-region recordings (motor cortical areas and sensory areas). CTAE yields meaningful representations that improve decoding of behavioral variables compared to existing approaches.", "conclusion": "CTAE offers a unified framework to model non-stationary, non-linear cross-region dynamics while disentangling shared vs. private signals, improving decoding performance and providing richer insights into inter-regional brain interactions; applicable to other multi-region sequential data and open questions on interpretability and scalability."}}
{"id": "2510.20818", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20818", "abs": "https://arxiv.org/abs/2510.20818", "authors": ["Mateo Guaman Castro", "Sidharth Rajagopal", "Daniel Gorbatov", "Matt Schmittle", "Rohan Baijal", "Octi Zhang", "Rosario Scalise", "Sidharth Talia", "Emma Romig", "Celso de Melo", "Byron Boots", "Abhishek Gupta"], "title": "VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation", "comment": null, "summary": "A fundamental challenge in robot navigation lies in learning policies that\ngeneralize across diverse environments while conforming to the unique physical\nconstraints and capabilities of a specific embodiment (e.g., quadrupeds can\nwalk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that\ndecouples semantic planning from embodiment grounding: a generalist planner\nlearns from diverse, open-world data, while a specialist affordance model\nlearns the robot's physical constraints and capabilities in safe, low-cost\nsimulation. We enabled this separation by carefully designing an interface that\nlets a high-level planner propose candidate paths directly in image space that\nthe affordance model then evaluates and re-ranks. Our real-world experiments\nshow that VAMOS achieves higher success rates in both indoor and complex\noutdoor navigation than state-of-the-art model-based and end-to-end learning\nmethods. We also show that our hierarchical design enables cross-embodied\nnavigation across legged and wheeled robots and is easily steerable using\nnatural language. Real-world ablations confirm that the specialist model is key\nto embodiment grounding, enabling a single high-level planner to be deployed\nacross physically distinct wheeled and legged robots. Finally, this model\nsignificantly enhances single-robot reliability, achieving 3X higher success\nrates by rejecting physically infeasible plans. Website:\nhttps://vamos-vla.github.io/", "AI": {"tldr": "Proposes VAMOS, a hierarchical vision-language-affordance agent that decouples planning from embodiment grounding, enabling cross-embodiment navigation and improved reliability by using a generalist planner plus a specialist affordance model.", "motivation": "To solve generalization across diverse environments while respecting distinct robot embodiments, by separating semantic planning from physical grounding and leveraging open-world data plus safe simulation.", "method": "Train a generalist planner in image-space from open-world data; train a specialist affordance model in safe, low-cost simulation to capture robot constraints; integrate via an interface where planner outputs image-space candidate paths that the affordance model evaluates and re-ranks; enable cross-embodiment navigation and natural-language steering.", "result": "Real-world experiments show higher success rates than state-of-the-art model-based and end-to-end methods in indoor/outdoor navigation; demonstrates cross-embodiment navigation across legged and wheeled robots; ablations show the specialist model is key; 3x higher success by rejecting infeasible plans.", "conclusion": "A hierarchical planner-grounding approach enables robust, cross-embodiment navigation and easier steering, by decoupling planning from embodiment and grounding high-level plans in affordance evaluations; enables deployment of a single planner across diverse robots."}}
{"id": "2510.20196", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20196", "abs": "https://arxiv.org/abs/2510.20196", "authors": ["Minh Sao Khue Luu", "Margaret V. Benedichuk", "Ekaterina I. Roppert", "Roman M. Kenzhin", "Bair N. Tuchinov"], "title": "A Structured Review and Quantitative Profiling of Public Brain MRI Datasets for Foundation Model Development", "comment": null, "summary": "The development of foundation models for brain MRI depends critically on the\nscale, diversity, and consistency of available data, yet systematic assessments\nof these factors remain scarce. In this study, we analyze 54 publicly\naccessible brain MRI datasets encompassing over 538,031 to provide a\nstructured, multi-level overview tailored to foundation model development. At\nthe dataset level, we characterize modality composition, disease coverage, and\ndataset scale, revealing strong imbalances between large healthy cohorts and\nsmaller clinical populations. At the image level, we quantify voxel spacing,\norientation, and intensity distributions across 15 representative datasets,\ndemonstrating substantial heterogeneity that can influence representation\nlearning. We then perform a quantitative evaluation of preprocessing\nvariability, examining how intensity normalization, bias field correction,\nskull stripping, spatial registration, and interpolation alter voxel statistics\nand geometry. While these steps improve within-dataset consistency, residual\ndifferences persist between datasets. Finally, feature-space case study using a\n3D DenseNet121 shows measurable residual covariate shift after standardized\npreprocessing, confirming that harmonization alone cannot eliminate\ninter-dataset bias. Together, these analyses provide a unified characterization\nof variability in public brain MRI resources and emphasize the need for\npreprocessing-aware and domain-adaptive strategies in the design of\ngeneralizable brain MRI foundation models.", "AI": {"tldr": "Comprehensive survey of 54 public brain MRI datasets (over 538k images) to quantify data heterogeneity, preprocessing variability, and cross-dataset covariate shift, informing the need for preprocessing-aware and domain-adaptive strategies in foundation-model design.", "motivation": "Foundation models require large, diverse, and consistent data; existing public brain MRI resources show systematic imbalances and variability that could hinder generalization. A structured, multi-level assessment is needed to guide model development.", "method": "Analyze 54 public brain MRI datasets (n>538k images) to characterize dataset-level factors (modality, disease coverage, size) and image-level factors (voxel spacing, orientation, intensity). Quantitatively evaluate preprocessing steps (normalization, bias-field correction, skull stripping, registration, interpolation) and assess their impact on voxel statistics and geometry. Conduct a feature-space experiment using a 3D DenseNet121 to measure residual covariate shift after standardized preprocessing.", "result": "Found strong imbalance: large healthy cohorts relative to smaller clinical populations; substantial heterogeneity in voxel spacing, orientation, and intensity distributions across datasets. Preprocessing improves within-dataset consistency but leaves residual cross-dataset differences. A 3D DenseNet121 revealed measurable residual covariate shift after standard preprocessing, indicating harmonization alone cannot remove inter-dataset bias.", "conclusion": "Preprocessing-aware and domain-adaptive strategies are necessary for creating generalizable brain MRI foundation models. Future work should emphasize harmonization, robust preprocessing pipelines, and domain adaptation to mitigate inter-dataset variability."}}
{"id": "2510.20457", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20457", "abs": "https://arxiv.org/abs/2510.20457", "authors": ["Louis Mozart Kamdem Teyou", "Luke Friedrichs", "N'Dah Jean Kouagou", "Caglar Demir", "Yasir Mahmood", "Stefan Heindorf", "Axel-Cyrille Ngonga Ngomo"], "title": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$", "comment": "Accepted as a full research paper at K-CAP 2025", "summary": "Concept learning exploits background knowledge in the form of description\nlogic axioms to learn explainable classification models from knowledge bases.\nDespite recent breakthroughs in neuro-symbolic concept learning, most\napproaches still cannot be deployed on real-world knowledge bases. This is due\nto their use of description logic reasoners, which are not robust against\ninconsistencies nor erroneous data. We address this challenge by presenting a\nnovel neural reasoner dubbed EBR. Our reasoner relies on embeddings to\napproximate the results of a symbolic reasoner. We show that EBR solely\nrequires retrieving instances for atomic concepts and existential restrictions\nto retrieve or approximate the set of instances of any concept in the\ndescription logic $\\mathcal{SHOIQ}$. In our experiments, we compare EBR with\nstate-of-the-art reasoners. Our results suggest that EBR is robust against\nmissing and erroneous data in contrast to existing reasoners.", "AI": {"tldr": "Neural reasoning (EBR) is proposed to approximate a Description Logic reasoner for SHOIQ, enabling robust concept learning on real-world knowledge bases despite data inconsistencies and errors.", "motivation": "DL reasoners struggle with incompleteness and errors in real-world KBs; a robust neuro-symbolic alternative is needed to enable explainable concept learning in knowledge bases.", "method": "Introduce EBR, a neural reasoner that uses embeddings to approximate symbolic DL reasoning. It retrieves instances for atomic concepts and existential restrictions to determine the set of instances of any SHOIQ concept, avoiding full reliance on classical DL reasoners.", "result": "EBR is empirically compared with state-of-the-art reasoners and shows robustness to missing and erroneous data, outperforming or matching existing approaches in such conditions.", "conclusion": "EBR demonstrates that neural reasoning can effectively replace brittle symbolic reasoners for SHOIQ-based concept learning, enabling deployment on real-world, noisy KBs."}}
{"id": "2510.20084", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20084", "abs": "https://arxiv.org/abs/2510.20084", "authors": ["Bosong Huang", "Ming Jin", "Yuxuan Liang", "Johan Barthelemy", "Debo Cheng", "Qingsong Wen", "Chenghao Liu", "Shirui Pan"], "title": "ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models", "comment": null, "summary": "Explaining time series classification models is crucial, particularly in\nhigh-stakes applications such as healthcare and finance, where transparency and\ntrust play a critical role. Although numerous time series classification\nmethods have identified key subsequences, known as shapelets, as core features\nfor achieving state-of-the-art performance and validating their pivotal role in\nclassification outcomes, existing post-hoc time series explanation (PHTSE)\nmethods primarily focus on timestep-level feature attribution. These\nexplanation methods overlook the fundamental prior that classification outcomes\nare predominantly driven by key shapelets. To bridge this gap, we present\nShapeX, an innovative framework that segments time series into meaningful\nshapelet-driven segments and employs Shapley values to assess their saliency.\nAt the core of ShapeX lies the Shapelet Describe-and-Detect (SDD) framework,\nwhich effectively learns a diverse set of shapelets essential for\nclassification. We further demonstrate that ShapeX produces explanations which\nreveal causal relationships instead of just correlations, owing to the\natomicity properties of shapelets. Experimental results on both synthetic and\nreal-world datasets demonstrate that ShapeX outperforms existing methods in\nidentifying the most relevant subsequences, enhancing both the precision and\ncausal fidelity of time series explanations.", "AI": {"tldr": "ShapeX explains time series classifications by partitioning signals into shapelet-driven segments and using Shapley values to quantify their saliency, addressing timesteplevel attribution and aiming for causal, shapelet-based explanations.", "motivation": "Post-hoc explanations for time series largely focus on timestep-level attribution, neglecting that classification is driven by key shapelets. A shapelet-centric, causal explanation is needed for trust in high-stakes domains.", "method": "Propose ShapeX framework; segment time series into shapelet-driven segments; Shapelet Describe-and-Detect (SDD) learns diverse, informative shapelets; compute segment saliency with Shapley values; leverage atomicity of shapelets to infer causal relations.", "result": "Empirical results on synthetic and real-world datasets show ShapeX outperforms existing PHTSE methods in identifying the most relevant subsequences and enhancing both the precision and causal fidelity of explanations.", "conclusion": "ShapeX provides more faithful, causally grounded explanations for time series classification by foregrounding shapelets, suggesting a step toward more transparent, trustworthy models in high-stakes settings."}}
{"id": "2510.20549", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20549", "abs": "https://arxiv.org/abs/2510.20549", "authors": ["Marziyeh Bamdad", "Hans-Peter Hutter", "Alireza Darvishy"], "title": "Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation", "comment": "8 pages, 7 figures, 4 tables", "summary": "Despite advancements in SLAM technologies, robust operation under challenging\nconditions such as low-texture, motion-blur, or challenging lighting remains an\nopen challenge. Such conditions are common in applications such as assistive\nnavigation for the visually impaired. These challenges undermine localization\naccuracy and tracking stability, reducing navigation reliability and safety. To\novercome these limitations, we present SELM-SLAM3, a deep learning-enhanced\nvisual SLAM framework that integrates SuperPoint and LightGlue for robust\nfeature extraction and matching. We evaluated our framework using TUM RGB-D,\nICL-NUIM, and TartanAir datasets, which feature diverse and challenging\nscenarios. SELM-SLAM3 outperforms conventional ORB-SLAM3 by an average of\n87.84% and exceeds state-of-the-art RGB-D SLAM systems by 36.77%. Our framework\ndemonstrates enhanced performance under challenging conditions, such as\nlow-texture scenes and fast motion, providing a reliable platform for\ndeveloping navigation aids for the visually impaired.", "AI": {"tldr": "SELM-SLAM3 is a deep-learning-enhanced visual SLAM framework that uses learned features (SuperPoint) and robust matching (LightGlue) to improve localization and tracking under challenging conditions, outperforming ORB-SLAM3 and RGB-D SLAM baselines across multiple datasets.", "motivation": "Robust SLAM under low-texture, motion blur, and difficult lighting is essential for assistive navigation for visually impaired users. Current SLAM systems suffer degraded localization and tracking reliability in such conditions, limiting safety and navigation support.", "method": "Integrates deep feature extraction (SuperPoint) and learned feature matching (LightGlue) within the SLAM3 pipeline, replacing traditional ORB-based components to enhance robustness. Evaluated on diverse datasets (TUM RGB-D, ICL-NUIM, TartanAir) to demonstrate performance gains under challenging scenarios.", "result": "Outperforms ORB-SLAM3 by an average of 87.84% and exceeds state-of-the-art RGB-D SLAM systems by 36.77%, with notable improvements in low-texture scenes and fast-motion conditions.", "conclusion": "SELM-SLAM3 offers improved reliability for SLAM under challenging conditions, supporting robust navigation aids for the visually impaired by delivering stable localization and tracking where conventional methods struggle."}}
{"id": "2510.20206", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20206", "abs": "https://arxiv.org/abs/2510.20206", "authors": ["Bingjie Gao", "Qianli Ma", "Xiaoxue Wu", "Shuai Yang", "Guanzhou Lan", "Haonan Zhao", "Jiaxuan Chen", "Qingyang Liu", "Yu Qiao", "Xinyuan Chen", "Yaohui Wang", "Li Niu"], "title": "RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling", "comment": null, "summary": "Prompt design plays a crucial role in text-to-video (T2V) generation, yet\nuser-provided prompts are often short, unstructured, and misaligned with\ntraining data, limiting the generative potential of diffusion-based T2V models.\nWe present \\textbf{RAPO++}, a cross-stage prompt optimization framework that\nunifies training-data--aligned refinement, test-time iterative scaling, and\nlarge language model (LLM) fine-tuning to substantially improve T2V generation\nwithout modifying the underlying generative backbone. In \\textbf{Stage 1},\nRetrieval-Augmented Prompt Optimization (RAPO) enriches user prompts with\nsemantically relevant modifiers retrieved from a relation graph and refactors\nthem to match training distributions, enhancing compositionality and\nmulti-object fidelity. \\textbf{Stage 2} introduces Sample-Specific Prompt\nOptimization (SSPO), a closed-loop mechanism that iteratively refines prompts\nusing multi-source feedback -- including semantic alignment, spatial fidelity,\ntemporal coherence, and task-specific signals such as optical flow -- yielding\nprogressively improved video generation quality. \\textbf{Stage 3} leverages\noptimized prompt pairs from SSPO to fine-tune the rewriter LLM, internalizing\ntask-specific optimization patterns and enabling efficient, high-quality prompt\ngeneration even before inference. Extensive experiments across five\nstate-of-the-art T2V models and five benchmarks demonstrate that RAPO++\nachieves significant gains in semantic alignment, compositional reasoning,\ntemporal stability, and physical plausibility, outperforming existing methods\nby large margins. Our results highlight RAPO++ as a model-agnostic,\ncost-efficient, and scalable solution that sets a new standard for prompt\noptimization in T2V generation. The code is available at\nhttps://github.com/Vchitect/RAPO.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2510.20467", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.20467", "abs": "https://arxiv.org/abs/2510.20467", "authors": ["Yiwen Peng", "Thomas Bonald", "Fabian M. Suchanek"], "title": "FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic", "comment": null, "summary": "Knowledge graph alignment is the task of matching equivalent entities (that\nis, instances and classes) and relations across two knowledge graphs. Most\nexisting methods focus on pure entity-level alignment, computing the similarity\nof entities in some embedding space. They lack interpretable reasoning and need\ntraining data to work. In this paper, we propose FLORA, a simple yet effective\nmethod that (1) is unsupervised, i.e., does not require training data, (2)\nprovides a holistic alignment for entities and relations iteratively, (3) is\nbased on fuzzy logic and thus delivers interpretable results, (4) provably\nconverges, (5) allows dangling entities, i.e., entities without a counterpart\nin the other KG, and (6) achieves state-of-the-art results on major benchmarks.", "AI": {"tldr": "FLORA is an unsupervised, fuzzy-logic-based method for holistic alignment of entities and relations in knowledge graphs; it converges, handles dangling entities, and achieves state-of-the-art results without training data.", "motivation": "Current KG alignment methods mostly do entity-level alignment, lack interpretable reasoning, and require labeled training data. There is a need for an unsupervised, interpretable, and holistic approach that can align both entities and relations and tolerate missing counterparts.", "method": "FLORA performs iterative, unsupervised holistic alignment for entities and relations using fuzzy logic, yielding interpretable results, with provable convergence and support for dangling entities.", "result": "Achieves state-of-the-art results on major benchmarks, outperforming existing methods in unsupervised settings and providing interpretable reasoning rather than opaque embeddings.", "conclusion": "FLORA offers a simple yet effective unsupervised framework for KG alignment that provides interpretable, convergent, and holistic alignment of entities and relations, including support for dangling entities and strong empirical performance."}}
{"id": "2510.20085", "categories": ["cs.LG", "cs.CY", "I.2.7; G.3; I.2.1; J.4"], "pdf": "https://arxiv.org/pdf/2510.20085", "abs": "https://arxiv.org/abs/2510.20085", "authors": ["Chang Yang", "Ziyi Wang", "Wangfeng Tan", "Zhiting Tan", "Changrui Ji", "Zhiming Zhou"], "title": "Hierarchical Dual-Head Model for Suicide Risk Assessment via MentalRoBERTa", "comment": "9 pages, 7 figures, 2tables, 2025 IEEE International Conference on\n  Big Data", "summary": "Social media platforms have become important sources for identifying suicide\nrisk, but automated detection systems face multiple challenges including severe\nclass imbalance, temporal complexity in posting patterns, and the dual nature\nof risk levels as both ordinal and categorical. This paper proposes a\nhierarchical dual-head neural network based on MentalRoBERTa for suicide risk\nclassification into four levels: indicator, ideation, behavior, and attempt.\nThe model employs two complementary prediction heads operating on a shared\nsequence representation: a CORAL (Consistent Rank Logits) head that preserves\nordinal relationships between risk levels, and a standard classification head\nthat enables flexible categorical distinctions. A 3-layer Transformer encoder\nwith 8-head multi-head attention models temporal dependencies across post\nsequences, while explicit time interval embeddings capture posting behavior\ndynamics. The model is trained with a combined loss function (0.5 CORAL + 0.3\nCross-Entropy + 0.2 Focal Loss) that simultaneously addresses ordinal structure\npreservation, overconfidence reduction, and class imbalance. To improve\ncomputational efficiency, we freeze the first 6 layers (50%) of MentalRoBERTa\nand employ mixed-precision training. The model is evaluated using 5-fold\nstratified cross-validation with macro F1 score as the primary metric.", "AI": {"tldr": "A hierarchical dual-head model for four-level suicide risk classification using CORAL for ordinal relations and a standard classifier head, with temporal modeling and time-interval embeddings; trained with a composite loss; efficiency-focused via freezing layers and mixed-precision; evaluated with 5-fold cross-validation using macro F1.", "motivation": "Address challenging aspects in automated suicide risk detection: severe class imbalance, temporal posting dynamics, and the need to model risk as both ordinal and categorical.", "method": "MentalRoBERTa-based architecture; 3-layer Transformer encoder with 8-head attention; two heads (CORAL ordinal, standard classifier); time-interval embeddings; composite loss (0.5 CORAL + 0.3 Cross-Entropy + 0.2 Focal); freeze first 6 layers; mixed-precision; 5-fold stratified cross-validation; macro F1 as metric.", "result": "Not reported in abstract; methodology and evaluation protocol described.", "conclusion": "Proposes a dual-head hierarchical model to jointly model ordinal and categorical risk levels with temporal dynamics and efficiency optimizations; evaluation protocol outlined; no numeric results provided."}}
{"id": "2510.20578", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20578", "abs": "https://arxiv.org/abs/2510.20578", "authors": ["Ding Zou", "Feifan Wang", "Mengyu Ge", "Siyuan Fan", "Zongbing Zhang", "Wei Chen", "Lingfeng Wang", "Zhongyou Hu", "Wenrui Yan", "Zhengwei Gao", "Hao Wang", "Weizhao Jin", "Yu Zhang", "Hainan Zhao", "Mingliang Zhang", "Xianxian Xi", "Yaru Zhang", "Wenyuan Li", "Zhengguang Gao", "Yurui Zhu"], "title": "EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence", "comment": null, "summary": "The realization of Artificial General Intelligence (AGI) necessitates\nEmbodied AI agents capable of robust spatial perception, effective task\nplanning, and adaptive execution in physical environments. However, current\nlarge language models (LLMs) and multimodal LLMs (MLLMs) for embodied tasks\nsuffer from key limitations, including a significant gap between model design\nand agent requirements, an unavoidable trade-off between real-time latency and\nperformance, and the use of unauthentic, offline evaluation metrics. To address\nthese challenges, we propose EmbodiedBrain, a novel vision-language foundation\nmodel available in both 7B and 32B parameter sizes. Our framework features an\nagent-aligned data structure and employs a powerful training methodology that\nintegrates large-scale Supervised Fine-Tuning (SFT) with Step-Augumented Group\nRelative Policy Optimization (Step-GRPO), which boosts long-horizon task\nsuccess by integrating preceding steps as Guided Precursors. Furthermore, we\nincorporate a comprehensive reward system, including a Generative Reward Model\n(GRM) accelerated at the infrastructure level, to improve training efficiency.\nFor enable thorough validation, we establish a three-part evaluation system\nencompassing General, Planning, and End-to-End Simulation Benchmarks,\nhighlighted by the proposal and open-sourcing of a novel, challenging\nsimulation environment. Experimental results demonstrate that EmbodiedBrain\nachieves superior performance across all metrics, establishing a new\nstate-of-the-art for embodied foundation models. Towards paving the way for the\nnext generation of generalist embodied agents, we open-source all of our data,\nmodel weight, and evaluating methods, which are available at\nhttps://zterobot.github.io/EmbodiedBrain.github.io.", "AI": {"tldr": "EmbodiedBrain introduces a 7B/32B vision-language foundation model for embodied AI, combining an agent-aligned data structure, SFT with Step-GRPO, GRM rewards, and a three-part evaluation framework, achieving state-of-the-art results and open-sourcing all data and models.", "motivation": "Current LLM/MLLM approaches for embodied tasks suffer from misalignment with agent needs, latency vs. performance trade-offs, and reliance on offline evaluation metrics. A robust, end-to-end embodied agent requires integrated perception, planning, and execution with authentic, scalable evaluation.", "method": "EmbodiedBrain architecture in 7B and 32B variants; agent-aligned data structure; training via large-scale Supervised Fine-Tuning (SFT) plus Step-Augumented Group Relative Policy Optimization (Step-GRPO) to weave preceding steps as Guided Precursors; Generative Reward Model (GRM) at infrastructure level; three-part evaluation (General, Planning, End-to-End Simulation) and a novel, open simulation environment; full open-source release of data, weights, and evaluation methods.", "result": "Achieves superior performance across General, Planning, and End-to-End benchmarks, establishing a new state-of-the-art for embodied foundation models.", "conclusion": "Paves the path toward generalist embodied agents by releasing data, model weights, and evaluation tools to the community, and providing a robust, scalable framework for embodied AI research."}}
{"id": "2510.20212", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20212", "abs": "https://arxiv.org/abs/2510.20212", "authors": ["Yanghao Wang", "Zhen Wang", "Long Chen"], "title": "FlowCycle: Pursuing Cycle-Consistent Flows for Text-based Editing", "comment": null, "summary": "Recent advances in pre-trained text-to-image flow models have enabled\nremarkable progress in text-based image editing. Mainstream approaches always\nadopt a corruption-then-restoration paradigm, where the source image is first\ncorrupted into an ``intermediate state'' and then restored to the target image\nunder the prompt guidance. However, current methods construct this intermediate\nstate in a target-agnostic manner, i.e., they primarily focus on realizing\nsource image reconstruction while neglecting the semantic gaps towards the\nspecific editing target. This design inherently results in limited editability\nor inconsistency when the desired modifications substantially deviate from the\nsource. In this paper, we argue that the intermediate state should be\ntarget-aware, i.e., selectively corrupting editing-relevant contents while\npreserving editing-irrelevant ones. To this end, we propose FlowCycle, a novel\ninversion-free and flow-based editing framework that parameterizes corruption\nwith learnable noises and optimizes them through a cycle-consistent process. By\niteratively editing the source to the target and recovering back to the source\nwith dual consistency constraints, FlowCycle learns to produce a target-aware\nintermediate state, enabling faithful modifications while preserving source\nconsistency. Extensive ablations have demonstrated that FlowCycle achieves\nsuperior editing quality and consistency over state-of-the-art methods.", "AI": {"tldr": "FlowCycle is an inversion-free, flow-based editing framework that learns a target-aware intermediate state for text-to-image editing by cycle-consistency between source and target, yielding better editability and consistency than existing methods.", "motivation": "Current corruption-then-restoration methods create target-agnostic intermediate states that reconstruct the source image but ignore the intended edit target, leading to limited edits and inconsistencies when edits differ from the source.", "method": "FlowCycle parameterizes the corruption with learnable noises and optimizes them via a cycle-consistent process: iteratively edit from source to target and then recover back to the source with dual consistency constraints, yielding a target-aware intermediate state (inversion-free and flow-based).", "result": "Extensive ablations demonstrate FlowCycle achieves superior editing quality and consistency compared with state-of-the-art methods.", "conclusion": "Target-aware intermediate states enable faithful modifications while preserving source consistency, improving text-to-image editing performance over existing approaches."}}
{"id": "2510.20568", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20568", "abs": "https://arxiv.org/abs/2510.20568", "authors": ["Susan Ariel Aaronson", "Michael Moreno"], "title": "Lost in Translation: Policymakers are not really listening to Citizen Concerns about AI", "comment": null, "summary": "The worlds people have strong opinions about artificial intelligence (AI),\nand they want policymakers to listen. Governments are inviting public comment\non AI, but as they translate input into policy, much of what citizens say is\nlost. Policymakers are missing a critical opportunity to build trust in AI and\nits governance. This paper compares three countries, Australia, Colombia, and\nthe United States, that invited citizens to comment on AI risks and policies.\nUsing a landscape analysis, the authors examined how each government solicited\nfeedback and whether that input shaped governance. Yet in none of the three\ncases did citizens and policymakers establish a meaningful dialogue.\nGovernments did little to attract diverse voices or publicize calls for\ncomment, leaving most citizens unaware or unprepared to respond. In each\nnation, fewer than one percent of the population participated. Moreover,\nofficials showed limited responsiveness to the feedback they received, failing\nto create an effective feedback loop. The study finds a persistent gap between\nthe promise and practice of participatory AI governance. The authors conclude\nthat current approaches are unlikely to build trust or legitimacy in AI because\npolicymakers are not adequately listening or responding to public concerns.\nThey offer eight recommendations: promote AI literacy; monitor public feedback;\nbroaden outreach; hold regular online forums; use innovative engagement\nmethods; include underrepresented groups; respond publicly to input; and make\nparticipation easier.", "AI": {"tldr": "Public consultations on AI in Australia, Colombia, and the United States largely failed to influence policy: participation was very low (<1%), outreach was weak, and feedback loops were not established, undermining trust in AI governance. Eight recommendations aim to improve engagement and legitimacy.", "motivation": "Governments attempt to democratize AI governance by soliciting public input, but current practices risk eroding trust if input is not meaningfully considered or diverse voices are engaged.", "method": "Landscape analysis of three countries assessing how calls for public feedback on AI risks/policies were issued and whether input shaped governance; evaluation of participation levels and responsiveness.", "result": "Citizen engagement was minimal: fewer than 1% of the population participated; limited outreach led to low awareness; officials showed little responsiveness and did not create a feedback loop; governance did not meaningfully incorporate public input.", "conclusion": "Current participatory approaches to AI governance are unlikely to build trust or legitimacy. The authors propose eight recommendations to improve engagement and governance: AI literacy, monitor public feedback, broaden outreach, regular online forums, innovative engagement methods, include underrepresented groups, publicly respond to input, and simplify participation."}}
{"id": "2510.20106", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20106", "abs": "https://arxiv.org/abs/2510.20106", "authors": ["Amartya Roy", "Souvik Chakraborty"], "title": "Competition is the key: A Game Theoretic Causal Discovery Approach", "comment": null, "summary": "Causal discovery remains a central challenge in machine learning, yet\nexisting methods face a fundamental gap: algorithms like GES and GraN-DAG\nachieve strong empirical performance but lack finite-sample guarantees, while\ntheoretically principled approaches fail to scale. We close this gap by\nintroducing a game-theoretic reinforcement learning framework for causal\ndiscovery, where a DDQN agent directly competes against a strong baseline (GES\nor GraN-DAG), always warm-starting from the opponent's solution. This design\nyields three provable guarantees: the learned graph is never worse than the\nopponent, warm-starting strictly accelerates convergence, and most importantly,\nwith high probability the algorithm selects the true best candidate graph. To\nthe best of our knowledge, our result makes a first-of-its-kind progress in\nexplaining such finite-sample guarantees in causal discovery: on synthetic SEMs\n(30 nodes), the observed error probability decays with n, tightly matching\ntheory. On real-world benchmarks including Sachs, Asia, Alarm, Child, Hepar2,\nDream, and Andes, our method consistently improves upon GES and GraN-DAG while\nremaining theoretically safe. Remarkably, it scales to large graphs such as\nHepar2 (70 nodes), Dream (100 nodes), and Andes (220 nodes). Together, these\nresults establish a new class of RL-based causal discovery algorithms that are\nsimultaneously provably consistent, sample-efficient, and practically scalable,\nmarking a decisive step toward unifying empirical performance with rigorous\nfinite-sample theory.", "AI": {"tldr": "Proposes a game-theoretic RL framework for causal discovery with finite-sample guarantees, competitive with strong baselines, and scalable to large graphs.", "motivation": "Bridge the gap between empirically strong but non-guaranteed methods (GES, GraN-DAG) and theoretically principled but non-scalable approaches, by providing finite-sample guarantees and scalable RL-based solutions.", "method": "A DDQN agent competes against a baseline (GES or GraN-DAG), warm-starting from the opponent's solution; learns a policy to select graphs within a game, delivering provable guarantees including no-worse-than-opponent, accelerated convergence, and high-probability correctness.", "result": "Demonstrates error probability decay with sample size on synthetic SEMs; outperforms GES and GraN-DAG on multiple real datasets; scales to graphs with up to ~220 nodes; establishes RL-based causal discovery with consistency, sample-efficiency, and scalability.", "conclusion": "RL-based causal discovery can combine empirical performance with finite-sample guarantees, marking a step toward unifying theory and practice in causal structure learning."}}
{"id": "2510.20708", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.20708", "abs": "https://arxiv.org/abs/2510.20708", "authors": ["Samuel Soutullo", "Miguel Yermo", "David L. Vilari\u00f1o", "\u00d3scar G. Lorenzo", "Jos\u00e9 C. Cabaleiro", "Francisco F. Rivera"], "title": "ALICE-LRI: A General Method for Lossless Range Image Generation for Spinning LiDAR Sensors without Calibration Metadata", "comment": null, "summary": "3D LiDAR sensors are essential for autonomous navigation, environmental\nmonitoring, and precision mapping in remote sensing applications. To\nefficiently process the massive point clouds generated by these sensors, LiDAR\ndata is often projected into 2D range images that organize points by their\nangular positions and distances. While these range image representations enable\nefficient processing, conventional projection methods suffer from fundamental\ngeometric inconsistencies that cause irreversible information loss,\ncompromising high-fidelity applications. We present ALICE-LRI (Automatic LiDAR\nIntrinsic Calibration Estimation for Lossless Range Images), the first general,\nsensor-agnostic method that achieves lossless range image generation from\nspinning LiDAR point clouds without requiring manufacturer metadata or\ncalibration files. Our algorithm automatically reverse-engineers the intrinsic\ngeometry of any spinning LiDAR sensor by inferring critical parameters\nincluding laser beam configuration, angular distributions, and per-beam\ncalibration corrections, enabling lossless projection and complete point cloud\nreconstruction with zero point loss. Comprehensive evaluation across the\ncomplete KITTI and DurLAR datasets demonstrates that ALICE-LRI achieves perfect\npoint preservation, with zero points lost across all point clouds. Geometric\naccuracy is maintained well within sensor precision limits, establishing\ngeometric losslessness with real-time performance. We also present a\ncompression case study that validates substantial downstream benefits,\ndemonstrating significant quality improvements in practical applications. This\nparadigm shift from approximate to lossless LiDAR projections opens new\npossibilities for high-precision remote sensing applications requiring complete\ngeometric preservation.", "AI": {"tldr": "Proposes ALICE-LRI, a sensor-agnostic method for lossless range-image generation from spinning LiDAR point clouds by automatically reverse-engineering intrinsic geometry, enabling perfect point preservation with no data loss.", "motivation": "Conventional 2D range-image projections introduce geometric inconsistencies and irreversible information loss; many LiDARs lack disclosed calibration data, hindering high-fidelity processing in remote sensing and mapping.", "method": "Automatically infer laser configuration, angular distributions, and per-beam calibration corrections to recover the true 3D geometry and enable lossless 2D range-image projection and full point cloud reconstruction, without requiring manufacturer metadata.", "result": "Zero points lost across all evaluated KITTI and DurLAR datasets; geometric accuracy within sensor precision; real-time performance; validated downstream with a compression case study showing quality improvements.", "conclusion": "A paradigm shift from approximate to lossless LiDAR projections, enabling high-precision remote sensing and broad, sensor-agnostic applicability for complete geometric preservation."}}
{"id": "2510.20214", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20214", "abs": "https://arxiv.org/abs/2510.20214", "authors": ["Talha Ilyas", "Duong Nhu", "Allison Thomas", "Arie Levin", "Lim Wei Yap", "Shu Gong", "David Vera Anaya", "Yiwen Jiang", "Deval Mehta", "Ritesh Warty", "Vinayak Smith", "Maya Reddy", "Euan Wallace", "Wenlong Cheng", "Zongyuan Ge", "Faezeh Marzbanrad"], "title": "Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection", "comment": "This is the preprint version of the manuscript submitted to IEEE\n  Journal of Biomedical and Health Informatics (JBHI) for review", "summary": "Accurate fetal movement (FM) detection is essential for assessing prenatal\nhealth, as abnormal movement patterns can indicate underlying complications\nsuch as placental dysfunction or fetal distress. Traditional methods, including\nmaternal perception and cardiotocography (CTG), suffer from subjectivity and\nlimited accuracy. To address these challenges, we propose Contrastive\nUltrasound Video Representation Learning (CURL), a novel self-supervised\nlearning framework for FM detection from extended fetal ultrasound video\nrecordings. Our approach leverages a dual-contrastive loss, incorporating both\nspatial and temporal contrastive learning, to learn robust motion\nrepresentations. Additionally, we introduce a task-specific sampling strategy,\nensuring the effective separation of movement and non-movement segments during\nself-supervised training, while enabling flexible inference on arbitrarily long\nultrasound recordings through a probabilistic fine-tuning approach. Evaluated\non an in-house dataset of 92 subjects, each with 30-minute ultrasound sessions,\nCURL achieves a sensitivity of 78.01% and an AUROC of 81.60%, demonstrating its\npotential for reliable and objective FM analysis. These results highlight the\npotential of self-supervised contrastive learning for fetal movement analysis,\npaving the way for improved prenatal monitoring and clinical decision-making.", "AI": {"tldr": "A self-supervised, dual-contrastive learning framework (CURL) for fetal movement detection from long ultrasound videos, using spatial and temporal contrasts plus task-specific sampling and probabilistic fine-tuning; evaluated on 92 subjects with 30-minute sessions, achieving 78.01% sensitivity and AUROC 81.60%.", "motivation": "Fetal movement assessment is important but current methods (maternal perception, CTG) are subjective and limited; need objective, robust, scalable FM analysis from continuous ultrasound data.", "method": "CURL employs dual-contrastive loss (spatial + temporal) in a self-supervised setting; introduces a task-specific sampling strategy to separate movement/non-movement segments; enables inference on arbitrarily long videos via probabilistic fine-tuning.", "result": "On an in-house dataset of 92 subjects with 30-minute sessions, CURL achieves 78.01% sensitivity and AUROC 81.60%, indicating robust motion representations.", "conclusion": "Self-supervised contrastive learning can provide reliable, objective fetal movement analysis and support enhanced prenatal monitoring and clinical decision-making; further validation on diverse datasets is warranted."}}
{"id": "2510.20591", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20591", "abs": "https://arxiv.org/abs/2510.20591", "authors": ["Ali Rajaei", "Peter Palensky", "Jochen L. Cremer"], "title": "Transferable Graph Learning for Transmission Congestion Management via Busbar Splitting", "comment": null, "summary": "Network topology optimization (NTO) via busbar splitting can mitigate\ntransmission grid congestion and reduce redispatch costs. However, solving this\nmixed-integer non-linear problem for large-scale systems in near-real-time is\ncurrently intractable with existing solvers. Machine learning (ML) approaches\nhave emerged as a promising alternative, but they have limited generalization\nto unseen topologies, varying operating conditions, and different systems,\nwhich limits their practical applicability. This paper formulates NTO for\ncongestion management problem considering linearized AC PF, and proposes a\ngraph neural network (GNN)-accelerated approach. We develop a heterogeneous\nedge-aware message passing NN to predict effective busbar splitting actions as\ncandidate NTO solutions. The proposed GNN captures local flow patterns,\nachieves generalization to unseen topology changes, and improves\ntransferability across systems. Case studies show up to 4 orders-of-magnitude\nspeed-up, delivering AC-feasible solutions within one minute and a 2.3%\noptimality gap on the GOC 2000-bus system. These results demonstrate a\nsignificant step toward near-real-time NTO for large-scale systems with\ntopology and cross-system generalization.", "AI": {"tldr": "A GNN-based approach for NTO via busbar splitting delivers near-real-time, AC-feasible solutions with strong generalization and large-scale performance.", "motivation": "NTO with busbar splitting aims to relieve grid congestion but is currently intractable for large systems due to mixed-integer non-linear formulations; ML offers speed but struggles to generalize to unseen topologies, operating conditions, and systems.", "method": "Formulate NTO for congestion management using linearized AC power flow and develop a heterogeneous edge-aware message passing graph neural network to predict effective busbar splitting as candidate solutions; the GNN captures local flow patterns and generalizes across unseen topology changes and cross-system transfers.", "result": "Demonstrates up to 4 orders of magnitude speed-up, delivering AC-feasible solutions within one minute and achieving about a 2.3% optimality gap on the GOC 2000-bus system.", "conclusion": "This work advances near-real-time NTO for large-scale systems by achieving topology- and cross-system generalization, moving toward practical deployment for congestion management."}}
{"id": "2510.20107", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20107", "abs": "https://arxiv.org/abs/2510.20107", "authors": ["Ayatullah Faruk Mollah"], "title": "On pattern classification with weighted dimensions", "comment": null, "summary": "Studies on various facets of pattern classification is often imperative while\nworking with multi-dimensional samples pertaining to diverse application\nscenarios. In this notion, weighted dimension-based distance measure has been\none of the vital considerations in pattern analysis as it reflects the degree\nof similarity between samples. Though it is often presumed to be settled with\nthe pervasive use of Euclidean distance, plethora of issues often surface. In\nthis paper, we present (a) a detail analysis on the impact of distance measure\nnorms and weights of dimensions along with visualization, (b) a novel weighting\nscheme for each dimension, (c) incorporation of this dimensional weighting\nschema into a KNN classifier, and (d) pattern classification on a variety of\nsynthetic as well as realistic datasets with the developed model. It has\nperformed well across diverse experiments in comparison to the traditional KNN\nunder the same experimental setups. Specifically, for gene expression datasets,\nit yields significant and consistent gain in classification accuracy (around\n10%) in all cross-validation experiments with different values of k. As such\ndatasets contain limited number of samples of high dimensions, meaningful\nselection of nearest neighbours is desirable, and this requirement is\nreasonably met by regulating the shape and size of the region enclosing the k\nnumber of reference samples with the developed weighting schema and appropriate\nnorm. It, therefore, stands as an important generalization of KNN classifier\npowered by weighted Minkowski distance with the present weighting schema.", "AI": {"tldr": "Introduces a dimension-wise weighting scheme for KNN using weighted Minkowski distance; demonstrates improved classification performance, notably around 10% gain on gene expression data.", "motivation": "Pattern classification in high-dimensional, small-sample settings often suffers from suboptimal distance measures. Euclidean distance and equal feature treatment can mislead nearest-neighbor decisions. A per-dimension weighting scheme and distance norm analysis aim to improve accuracy and robustness.", "method": "Provide a detailed analysis of distance measure norms and per-dimension weights with visualization; propose a novel per-dimension weighting scheme; incorporate this schema into a KNN classifier using weighted Minkowski distance; evaluate on synthetic and real datasets, focusing on gene-expression data.", "result": "The proposed approach outperforms traditional KNN under the same experimental setups. In gene-expression datasets, it yields a significant and consistent ~10% improvement in classification accuracy across cross-validation with varying k; the weighting scheme helps shape the neighbor region and improve robust neighbor selection in high-dimensional spaces.", "conclusion": "This work generalizes KNN by integrating a per-dimension weighted Minkowski distance, providing robust improvements in pattern classification for high-dimensional, limited-sample data; the weighting framework is effective across diverse datasets, with notable gains in gene-expression tasks."}}
{"id": "2510.20217", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20217", "abs": "https://arxiv.org/abs/2510.20217", "authors": ["Jiahuan Wang", "Yuxin Chen", "Jun Yu", "Guangming Lu", "Wenjie Pei"], "title": "EditInfinity: Image Editing with Binary-Quantized Generative Models", "comment": "28 pages, 13 figures, accepted by The Thirty-ninth Annual Conference\n  on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Adapting pretrained diffusion-based generative models for text-driven image\nediting with negligible tuning overhead has demonstrated remarkable potential.\nA classical adaptation paradigm, as followed by these methods, first infers the\ngenerative trajectory inversely for a given source image by image inversion,\nthen performs image editing along the inferred trajectory guided by the target\ntext prompts. However, the performance of image editing is heavily limited by\nthe approximation errors introduced during image inversion by diffusion models,\nwhich arise from the absence of exact supervision in the intermediate\ngenerative steps. To circumvent this issue, we investigate the\nparameter-efficient adaptation of VQ-based generative models for image editing,\nand leverage their inherent characteristic that the exact intermediate\nquantized representations of a source image are attainable, enabling more\neffective supervision for precise image inversion. Specifically, we propose\n\\emph{EditInfinity}, which adapts \\emph{Infinity}, a binary-quantized\ngenerative model, for image editing. We propose an efficient yet effective\nimage inversion mechanism that integrates text prompting rectification and\nimage style preservation, enabling precise image inversion. Furthermore, we\ndevise a holistic smoothing strategy which allows our \\emph{EditInfinity} to\nperform image editing with high fidelity to source images and precise semantic\nalignment to the text prompts. Extensive experiments on the PIE-Bench benchmark\nacross \"add\", \"change\", and \"delete\" editing operations, demonstrate the\nsuperior performance of our model compared to state-of-the-art diffusion-based\nbaselines. Code available at: https://github.com/yx-chen-ust/EditInfinity.", "AI": {"tldr": "EditInfinity adapts a binary-quantized generative model (Infinity) for text-driven image editing, enabling precise inversion and editing with minimal tuning, outperforming diffusion-based baselines.", "motivation": "Diffusion-based editing suffers from inversion errors due to lack of exact supervision in intermediate steps; leveraging exact intermediate representations in quantized models can enable more faithful inversions and stronger alignment with text prompts.", "method": "Propose EditInfinity by adapting Infinity for editing; develop an efficient image inversion mechanism with text prompting rectification and style preservation; introduce a holistic smoothing strategy to ensure fidelity to the source image and semantic alignment with prompts.", "result": "Extensive PIE-Bench experiments across add/change/delete show superior performance of EditInfinity compared to state-of-the-art diffusion-based baselines.", "conclusion": "Binary-quantized generative models with precise inversion and smoothing strategies can surpass diffusion-based approaches for text-driven image editing while maintaining negligible tuning overhead."}}
{"id": "2510.20603", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20603", "abs": "https://arxiv.org/abs/2510.20603", "authors": ["Heejin Do", "Jaehui Hwang", "Dongyoon Han", "Seong Joon Oh", "Sangdoo Yun"], "title": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation", "comment": null, "summary": "Evaluating large language models (LLMs) on final-answer correctness is the\ndominant paradigm. This approach, however, provides a coarse signal for model\nimprovement and overlooks the quality of the underlying reasoning process. We\nargue that a more granular evaluation of reasoning offers a more effective path\nto building robust models. We decompose reasoning quality into two dimensions:\nrelevance and coherence. Relevance measures if a step is grounded in the\nproblem; coherence measures if it follows logically from prior steps. To\nmeasure these aspects reliably, we introduce causal stepwise evaluation (CaSE).\nThis method assesses each reasoning step using only its preceding context,\nwhich avoids hindsight bias. We validate CaSE against human judgments on our\nnew expert-annotated benchmarks, MRa-GSM8K and MRa-MATH. More importantly, we\nshow that curating training data with CaSE-evaluated relevance and coherence\ndirectly improves final task performance. Our work provides a scalable\nframework for analyzing, debugging, and improving LLM reasoning, demonstrating\nthe practical value of moving beyond validity checks.", "AI": {"tldr": "CaSE (causal stepwise evaluation) offers a granular way to assess LLM reasoning by evaluating each step for relevance (grounded in the problem) and coherence (logically following from prior steps) using only prior context to avoid hindsight bias. It is validated against expert judgments on new benchmarks (MRa-GSM8K, MRa-MATH) and enabling CaSE-based data curation improves final task performance, providing a scalable framework for analyzing, debugging, and improving LLM reasoning beyond final-answer correctness.", "motivation": "Current evaluation of LLMs focuses on final-answer correctness, which is a coarse signal that misses the quality of the reasoning process. A fine-grained, principled measure of reasoning quality (relevance and coherence) can guide data curation and model tuning to build more robust, interpretable systems.", "method": "Introduce CaSE (causal stepwise evaluation) that assesses each reasoning step using only its preceding context to avoid hindsight bias. Measure two dimensions\u2014relevance (grounded in the problem) and coherence (logically follows from prior steps)\u2014across expert-annotated benchmarks. Validate CaSE against human judgments and demonstrate that CaSE-based data curation improves final task performance.", "result": "CaSE aligns with human judgments on expert benchmarks (MRa-GSM8K and MRa-MATH) and, when used to curate training data, leads to measurable gains in final task performance, confirming its utility for debugging and improving LLM reasoning.", "conclusion": "Moving beyond validity checks, CaSE provides a scalable framework to analyze, debug, and improve LLM reasoning, facilitating targeted data curation and model development to enhance robustness of reasoning-based capabilities."}}
{"id": "2510.20108", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20108", "abs": "https://arxiv.org/abs/2510.20108", "authors": ["Gabriel Y. Arteaga", "Marius Aasan", "Rwiddhi Chakraborty", "Martine Hjelkrem-Tan", "Thalles Silva", "Michael Kampffmeyer", "Ad\u00edn Ram\u00edrez Rivera"], "title": "Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning", "comment": null, "summary": "Prototypical self-supervised learning methods consistently suffer from\npartial prototype collapse, where multiple prototypes converge to nearly\nidentical representations. This undermines their central purpose -- providing\ndiverse and informative targets to guide encoders toward rich representations\n-- and has led practitioners to over-parameterize prototype sets or add ad-hoc\nregularizers, which mitigate symptoms rather than address the root cause. We\nempirically trace the collapse to the joint optimization of encoders and\nprototypes, which encourages a type of shortcut learning: early in training\nprototypes drift toward redundant representations that minimize loss without\nnecessarily enhancing representation diversity. To break the joint\noptimization, we introduce a fully decoupled training strategy that learns\nprototypes and encoders under separate objectives. Concretely, we model\nprototypes as a Gaussian mixture updated with an online EM-style procedure,\nindependent of the encoder's loss. This simple yet principled decoupling\neliminates prototype collapse without explicit regularization and yields\nconsistently diverse prototypes and stronger downstream performance.", "AI": {"tldr": "Decoupling prototype learning from the encoder eliminates partial prototype collapse in prototypical SSL by treating prototypes as a Gaussian mixture updated via online EM, improving diversity and downstream performance.", "motivation": "Partial prototype collapse reduces diversity of targets and degrades representation quality; existing remedies address symptoms rather than root cause; a principled decoupling may restore diversity and efficiency.", "method": "Prototypes are modeled as a Gaussian mixture; updated with an online EM-style procedure independent of the encoder's loss; the encoder is trained with its own objective, decoupling the optimization.", "result": "Eliminates prototype collapse, yields consistently diverse prototypes, and improves downstream performance without explicit regularization.", "conclusion": "Decoupling joint optimization addresses the root cause of collapse in prototypical SSL, offering a simpler, principled approach with potential broader applicability to other joint-optimization settings."}}
{"id": "2510.20229", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20229", "abs": "https://arxiv.org/abs/2510.20229", "authors": ["Ge Zheng", "Jiaye Qian", "Jiajin Tang", "Sibei Yang"], "title": "Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context", "comment": null, "summary": "Large Vision-Language Models (LVLMs) have made significant progress in recent\nyears but are also prone to hallucination issues. They exhibit more\nhallucinations in longer, free-form responses, often attributed to accumulated\nuncertainties. In this paper, we ask: Does increased hallucination result\nsolely from length-induced errors, or is there a deeper underlying mechanism?\nAfter a series of preliminary experiments and findings, we suggest that the\nrisk of hallucinations is not caused by length itself but by the increased\nreliance on context for coherence and completeness in longer responses.\nBuilding on these insights, we propose a novel \"induce-detect-suppress\"\nframework that actively induces hallucinations through deliberately designed\ncontexts, leverages induced instances for early detection of high-risk cases,\nand ultimately suppresses potential object-level hallucinations during actual\ndecoding. Our approach achieves consistent, significant improvements across all\nbenchmarks, demonstrating its efficacy. The strong detection and improved\nhallucination mitigation not only validate our framework but, more importantly,\nre-validate our hypothesis on context. Rather than solely pursuing performance\ngains, this study aims to provide new insights and serves as a first step\ntoward a deeper exploration of hallucinations in LVLMs' longer responses.", "AI": {"tldr": "LVLM hallucinations relate to reliance on context in longer responses rather than length alone; the paper proposes an induce-detect-suppress framework to trigger, detect, and mitigate hallucinations, achieving consistent improvements and validating the context-based hypothesis.", "motivation": "Motivate investigation into why LVLMs hallucinate, especially in longer, free-form outputs. Question whether length-induced errors are the sole cause or if there is a deeper mechanism, with a focus on the role of context for coherence and completeness.", "method": "Conduct preliminary experiments and develop a novel induce-detect-suppress framework: deliberately induce hallucinations through crafted contexts, use induced instances for early detection of high-risk cases, and suppress potential object-level hallucinations during decoding. Evaluate across multiple benchmarks.", "result": "The approach yields consistent, significant improvements in hallucination detection and suppression across benchmarks, supporting the framework and reinforcing the context-based hypothesis.", "conclusion": "Provides new insights into hallucinations in LVLMs\u2019 longer responses, emphasizing context over length alone and outlining a step toward deeper exploration of these phenomena."}}
{"id": "2510.20604", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20604", "abs": "https://arxiv.org/abs/2510.20604", "authors": ["Changan Liu", "Zixuan Xie", "Ahad N. Zehmakan", "Zhongzhi Zhang"], "title": "Efficient Algorithms for Computing Random Walk Centrality", "comment": "Accepted by TKDE", "summary": "Random walk centrality is a fundamental metric in graph mining for\nquantifying node importance and influence, defined as the weighted average of\nhitting times to a node from all other nodes. Despite its ability to capture\nrich graph structural information and its wide range of applications, computing\nthis measure for large networks remains impractical due to the computational\ndemands of existing methods. In this paper, we present a novel formulation of\nrandom walk centrality, underpinning two scalable algorithms: one leveraging\napproximate Cholesky factorization and sparse inverse estimation, while the\nother sampling rooted spanning trees. Both algorithms operate in near-linear\ntime and provide strong approximation guarantees. Extensive experiments on\nlarge real-world networks, including one with over 10 million nodes,\ndemonstrate the efficiency and approximation quality of the proposed\nalgorithms.", "AI": {"tldr": "Two scalable near-linear-time algorithms for computing random walk centrality in large graphs, with strong approximation guarantees: (1) approximate Cholesky factorization and sparse inverse estimation, and (2) sampling rooted spanning trees; validated on networks up to over 10 million nodes.", "motivation": "Random walk centrality captures node importance via hitting times but is prohibitively expensive on large networks; scalable approximation methods are needed to enable practical analysis at scale.", "method": "Algorithm 1 uses approximate Cholesky factorization and sparse inverse estimation to compute centrality; Algorithm 2 uses sampling of rooted spanning trees to estimate centrality. Both are designed to run in near-linear time and come with approximation guarantees.", "result": "Both algorithms achieve near-linear time complexity with provable approximation guarantees; extensive experiments on large real-world networks (including networks with over 10 million nodes) demonstrate efficiency and high-quality approximations relative to exact computation or baselines.", "conclusion": "The work provides scalable, theoretically grounded methods for random walk centrality that enable analysis of very large graphs, broadening the practical applicability of this centrality measure."}}
{"id": "2510.20119", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20119", "abs": "https://arxiv.org/abs/2510.20119", "authors": ["Arian Prabowo", "Flora D. Salim"], "title": "There is No \"apple\" in Timeseries: Rethinking TSFM through the Lens of Invariance", "comment": null, "summary": "Timeseries foundation models (TSFMs) have multiplied, yet lightweight\nsupervised baselines and even classical models often match them. We argue this\ngap stems from the naive importation of NLP or CV pipelines. In language and\nvision, large web-scale corpora densely capture human concepts i.e. there are\ncountless images and text of apples. In contrast, timeseries data is built to\ncomplement the image and text modalities. There are no timeseries dataset that\ncontains the concept apple. As a result, the scrape-everything-online paradigm\nfails for TS. We posit that progress demands a shift from opportunistic\naggregation to principled design: constructing datasets that systematically\nspan the space of invariance that preserve temporal semantics. To this end, we\nsuggest that the ontology of timeseries invariances should be built based on\nfirst principles. Only by ensuring representational completeness through\ninvariance coverage can TSFMs achieve the aligned structure necessary for\ngeneralisation, reasoning, and truly emergent behaviour.", "AI": {"tldr": "TS foundation models underperform lightweight baselines due to naive transfer from NLP/CV; progress requires principled, invariance-focused time-series dataset design that preserves temporal semantics.", "motivation": "There is no natural 'apple' concept in time series; web-scale, opportunistic data collection fails for TS. To achieve generalization and emergent behavior, we need to close the gap by designing time-series datasets that cover core invariances from first principles.", "method": "Advocates constructing datasets that systematically span the space of time-series invariances while preserving temporal semantics and proposes building an ontology of invariances based on first principles.", "result": "The work presents a theoretical design principle rather than empirical results, arguing that representational completeness via comprehensive invariance coverage is necessary for TSFMs to generalize and exhibit reasoning/emergent behavior.", "conclusion": "Principled, invariance-aware dataset design\u2014rooted in first-principles invariances\u2014is essential for TSFMs to achieve robust generalization and emergent capabilities, rather than relying on opportunistic aggregation."}}
{"id": "2510.20238", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20238", "abs": "https://arxiv.org/abs/2510.20238", "authors": ["Runsong Zhu", "Ka-Hei Hui", "Zhengzhe Liu", "Qianyi Wu", "Weiliang Tang", "Shi Qiu", "Pheng-Ann Heng", "Chi-Wing Fu"], "title": "COS3D: Collaborative Open-Vocabulary 3D Segmentation", "comment": "NeurIPS 2025. The code is publicly available at\n  \\href{https://github.com/Runsong123/COS3D}{https://github.com/Runsong123/COS3D}", "summary": "Open-vocabulary 3D segmentation is a fundamental yet challenging task,\nrequiring a mutual understanding of both segmentation and language. However,\nexisting Gaussian-splatting-based methods rely either on a single 3D language\nfield, leading to inferior segmentation, or on pre-computed class-agnostic\nsegmentations, suffering from error accumulation. To address these limitations,\nwe present COS3D, a new collaborative prompt-segmentation framework that\ncontributes to effectively integrating complementary language and segmentation\ncues throughout its entire pipeline. We first introduce the new concept of\ncollaborative field, comprising an instance field and a language field, as the\ncornerstone for collaboration. During training, to effectively construct the\ncollaborative field, our key idea is to capture the intrinsic relationship\nbetween the instance field and language field, through a novel\ninstance-to-language feature mapping and designing an efficient two-stage\ntraining strategy. During inference, to bridge distinct characteristics of the\ntwo fields, we further design an adaptive language-to-instance prompt\nrefinement, promoting high-quality prompt-segmentation inference. Extensive\nexperiments not only demonstrate COS3D's leading performance over existing\nmethods on two widely-used benchmarks but also show its high potential to\nvarious applications,~\\ie, novel image-based 3D segmentation, hierarchical\nsegmentation, and robotics. The code is publicly available at\n\\href{https://github.com/Runsong123/COS3D}{https://github.com/Runsong123/COS3D}.", "AI": {"tldr": "COS3D introduces a collaborative prompt-segmentation framework with an instance field and language field, enabling open-vocabulary 3D segmentation with improved performance and broader applicability.", "motivation": "Open-vocabulary 3D segmentation struggles due to relying on a single 3D language field or precomputed segmentations; integrating language and segmentation cues throughout the pipeline is beneficial.", "method": "Define a collaborative field consisting of an instance field and a language field; learn an instance-to-language feature mapping; two-stage training; during inference use adaptive language-to-instance prompt refinement to align the two fields.", "result": "Achieves leading performance on two standard benchmarks; demonstrates potential for image-based 3D segmentation, hierarchical segmentation, and robotics; code released.", "conclusion": "A collaborative field approach effectively fuses language and segmentation cues across the pipeline, enabling robust open-vocabulary 3D segmentation and broad applicability."}}
{"id": "2510.20621", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20621", "abs": "https://arxiv.org/abs/2510.20621", "authors": ["Riccardo Guidotti", "Martina Cinquini", "Marta Marchiori Manerba", "Mattia Setzu", "Francesco Spinnato"], "title": "Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms", "comment": null, "summary": "Interpretable-by-design models are crucial for fostering trust,\naccountability, and safe adoption of automated decision-making models in\nreal-world applications. In this paper we formalize the ground for the MIMOSA\n(Mining Interpretable Models explOiting Sophisticated Algorithms) framework, a\ncomprehensive methodology for generating predictive models that balance\ninterpretability with performance while embedding key ethical properties. We\nformally define here the supervised learning setting across diverse\ndecision-making tasks and data types, including tabular data, time series,\nimages, text, transactions, and trajectories. We characterize three major\nfamilies of interpretable models: feature importance, rule, and instance based\nmodels. For each family, we analyze their interpretability dimensions,\nreasoning mechanisms, and complexity. Beyond interpretability, we formalize\nthree critical ethical properties, namely causality, fairness, and privacy,\nproviding formal definitions, evaluation metrics, and verification procedures\nfor each. We then examine the inherent trade-offs between these properties and\ndiscuss how privacy requirements, fairness constraints, and causal reasoning\ncan be embedded within interpretable pipelines. By evaluating ethical measures\nduring model generation, this framework establishes the theoretical foundations\nfor developing AI systems that are not only accurate and interpretable but also\nfair, privacy-preserving, and causally aware, i.e., trustworthy.", "AI": {"tldr": "Proposes MIMOSA: a framework to generate interpretable predictive models across data types, embedding causality, fairness, and privacy into interpretable pipelines.", "motivation": "Trustworthy AI requires models that are interpretable and ethically aware; existing work lacks a unified framework to integrate interpretability with causal, fair, and privacy properties across diverse data types.", "method": "Formalizes supervised learning for tabular/time-series/images/text/transactions/trajectories; characterizes three interpretable model families (feature importance, rule, instance-based); analyzes interpretability dimensions, reasoning mechanisms, and complexity; provides formal definitions, evaluation metrics, and verification procedures for causality, fairness, and privacy; discusses trade-offs and how to embed ethical constraints within interpretable pipelines; outlines evaluation of ethical measures during model generation.", "result": "A theoretical framework establishing foundations for building accurate, interpretable, fair, privacy-preserving, and causally aware AI systems; defines metrics, verification procedures, and principled trade-offs to guide trustworthy model development across diverse data types.", "conclusion": "MIMOSA provides groundwork for trustworthy AI by integrating ethical properties into interpretable model design and offering a formal, verifiable pipeline for diverse decision-making tasks."}}
{"id": "2510.20148", "categories": ["cs.LG", "math.DS", "physics.med-ph", "68T07, 35Q92, 92B20, 92C50", "I.6.3; I.6.4; I.2; J.3"], "pdf": "https://arxiv.org/pdf/2510.20148", "abs": "https://arxiv.org/abs/2510.20148", "authors": ["Tingting Dan", "Xinwei Huang", "Jiaqi Ding", "Yinggang Zheng", "Guorong Wu"], "title": "Understanding Mechanistic Role of Structural and Functional Connectivity in Tau Propagation Through Multi-Layer Modeling", "comment": "42 pages, 14 figures, 64 references", "summary": "Emerging neuroimaging evidence shows that pathological tau proteins build up\nalong specific brain networks, suggesting that large-scale network architecture\nplays a key role in the progression of Alzheimer's disease (AD). However, how\nstructural connectivity (SC) and functional connectivity (FC) interact to\ninfluence tau propagation remains unclear. Leveraging an unprecedented volume\nof longitudinal neuroimaging data, we examine SC-FC interactions through a\nmulti-layer graph diffusion model. Beyond showing that connectome architecture\nconstrains tau spread, our model reveals a regionally asymmetric contribution\nof SC and FC. Specifically, FC predominantly drives tau spread in subcortical\nareas, the insula, frontal and temporal cortices, whereas SC plays a larger\nrole in occipital, parietal, and limbic regions. The relative dominance of SC\nversus FC shifts over the course of disease, with FC generally prevailing in\nearly AD and SC becoming primary in later stages. Spatial patterns of SC- and\nFC-dominant regions strongly align with the regional expression of\nAD-associated genes involved in inflammation, apoptosis, and lysosomal\nfunction, including CHUK (IKK-alpha), TMEM106B, MCL1, NOTCH1, and TH. In\nparallel, other non-modifiable risk factors (e.g., APOE genotype, sex) and\nbiological mechanisms (e.g., amyloid deposition) selectively reshape tau\npropagation by shifting dominant routes between anatomical and functional\npathways in a region-specific manner. Findings are validated in an independent\nAD cohort.", "AI": {"tldr": "A multi-layer diffusion analysis reveals region-specific SC vs FC roles in tau spread in AD, with FC dominant early and SC later, aligned with gene expression and risk factors, validated in an independent cohort.", "motivation": "To understand how large-scale brain connectivity shapes tau propagation in Alzheimer's disease (AD) and how interactions between structural connectivity (SC) and functional connectivity (FC) influence disease progression.", "method": "Utilized longitudinal neuroimaging data and a multi-layer graph diffusion model to integrate SC and FC, identifying region-specific dominance of SC versus FC in tau spread, examining how dominance shifts over disease stages, and correlating patterns with AD-related gene expression and non-modifiable risk factors; replication in an independent AD cohort.", "result": "Findings show that connectome architecture constrains tau propagation, with regionally asymmetric contributions: FC dominates tau spread in subcortical regions, the insula, and frontal/temporal cortices, while SC dominates in occipital, parietal, and limbic regions. The relative dominance shifts from FC in early AD to SC in later stages. Spatial patterns of SC- and FC-dominant regions align with expression of AD-associated genes involved in inflammation, apoptosis, and lysosomal function. Non-modifiable factors (e.g., APOE, sex) and biological mechanisms (e.g., amyloid) reshape propagation by shifting dominant routes between anatomical and functional pathways in a region-specific manner. Findings were validated in an independent AD cohort.", "conclusion": "The study highlights that large-scale connectome architecture and its dynamic SC\u2013FC interactions drive tau propagation in AD in a region- and stage-specific manner, linking molecular risk factors to network-level spread and reinforcing the validity of the multi-layer diffusion framework across cohorts."}}
{"id": "2510.20244", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20244", "abs": "https://arxiv.org/abs/2510.20244", "authors": ["Minseok Kang", "Minhyeok Lee", "Minjung Kim", "Donghyeong Kim", "Sangyoun Lee"], "title": "Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding", "comment": "Comments: 28 pages, including appendix. 5 figures. Full version of\n  the NeurIPS 2025 paper", "summary": "Video Temporal Grounding (VTG) aims to localize temporal segments in long,\nuntrimmed videos that align with a given natural language query. This task\ntypically comprises two subtasks: Moment Retrieval (MR) and Highlight Detection\n(HD). While recent advances have been progressed by powerful pretrained\nvision-language models such as CLIP and InternVideo2, existing approaches\ncommonly treat all text tokens uniformly during crossmodal attention,\ndisregarding their distinct semantic roles. To validate the limitations of this\napproach, we conduct controlled experiments demonstrating that VTG models\noverly rely on [EOS]-driven global semantics while failing to effectively\nutilize word-level signals, which limits their ability to achieve fine-grained\ntemporal alignment. Motivated by this limitation, we propose DualGround, a\ndual-branch architecture that explicitly separates global and local semantics\nby routing the [EOS] token through a sentence-level path and clustering word\ntokens into phrase-level units for localized grounding. Our method introduces\n(1) tokenrole- aware cross modal interaction strategies that align video\nfeatures with sentence-level and phrase-level semantics in a structurally\ndisentangled manner, and (2) a joint modeling framework that not only improves\nglobal sentence-level alignment but also enhances finegrained temporal\ngrounding by leveraging structured phrase-aware context. This design allows the\nmodel to capture both coarse and localized semantics, enabling more expressive\nand context-aware video grounding. DualGround achieves state-of-the-art\nperformance on both Moment Retrieval and Highlight Detection tasks across\nQVHighlights and Charades- STA benchmarks, demonstrating the effectiveness of\ndisentangled semantic modeling in video-language alignment.", "AI": {"tldr": "DualGround introduces a dual-branch, token-role aware VTG model that disentangles global sentence-level and local phrase-level semantics to improve both Moment Retrieval and Highlight Detection, achieving state-of-the-art on QVHighlights and Charades-STA.", "motivation": "Current VTG approaches treat text tokens uniformly in cross-modal attention and rely heavily on EOS-driven global semantics, neglecting word-level signals that are essential for fine-grained temporal alignment.", "method": "A dual-branch architecture with sentence-level and phrase-level pathways. It routes the EOS token through a sentence-level path and clusters word tokens into phrase-level units. It employs token-role-aware cross-modal interactions to align video features with both sentence-level and phrase-level semantics, enabling a structurally disentangled, joint modeling framework for coarse and localized grounding.", "result": "State-of-the-art performance on both Moment Retrieval and Highlight Detection tasks across the QVHighlights and Charades-STA benchmarks.", "conclusion": "Disentangled semantic modeling that separates global and local semantics enhances video-language grounding, enabling more expressive and context-aware temporal localization by capturing both coarse and fine-grained semantics."}}
{"id": "2510.20632", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20632", "abs": "https://arxiv.org/abs/2510.20632", "authors": ["Shuyi Xie", "Ziqin Liew", "Hailing Zhang", "Haibo Zhang", "Ling Hu", "Zhiqiang Zhou", "Shuman Liu", "Anxiang Zeng"], "title": "Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications", "comment": null, "summary": "Large Language Models (LLMs) excel on general-purpose NLP benchmarks, yet\ntheir capabilities in specialized domains remain underexplored. In e-commerce,\nexisting evaluations-such as EcomInstruct, ChineseEcomQA, eCeLLM, and Shopping\nMMLU-suffer from limited task diversity (e.g., lacking product guidance and\nafter-sales issues), limited task modalities (e.g., absence of multimodal\ndata), synthetic or curated data, and a narrow focus on English and Chinese,\nleaving practitioners without reliable tools to assess models on complex,\nreal-world shopping scenarios. We introduce EcomEval, a comprehensive\nmultilingual and multimodal benchmark for evaluating LLMs in e-commerce.\nEcomEval covers six categories and 37 tasks (including 8 multimodal tasks),\nsourced primarily from authentic customer queries and transaction logs,\nreflecting the noisy and heterogeneous nature of real business interactions. To\nensure both quality and scalability of reference answers, we adopt a\nsemi-automatic pipeline in which large models draft candidate responses\nsubsequently reviewed and modified by over 50 expert annotators with strong\ne-commerce and multilingual expertise. We define difficulty levels for each\nquestion and task category by averaging evaluation scores across models with\ndifferent sizes and capabilities, enabling challenge-oriented and fine-grained\nassessment. EcomEval also spans seven languages-including five low-resource\nSoutheast Asian languages-offering a multilingual perspective absent from prior\nwork.", "AI": {"tldr": "Introduces EcomEval, a multilingual and multimodal benchmark for evaluating LLMs in e-commerce, addressing gaps in prior benchmarks by including diverse tasks, multimodal data, authentic real-world data, and seven languages (including five low-resource SE Asian languages).", "motivation": "Current e-commerce benchmarks are narrow (limited task diversity, modalities, languages) and often rely on synthetic data or English/Chinese. There is a need for a realistic, multilingual, multimodal benchmark that reflects authentic customer interactions to better assess LLMs in real-world shopping scenarios.", "method": "Proposes EcomEval with 6 categories and 37 tasks (including 8 multimodal tasks). Data drawn from authentic customer queries and transaction logs. Uses a semi-automatic annotation pipeline where large models draft responses, then 50+ expert annotators review/edit. Establishes difficulty levels by averaging model performance across models of varying sizes. Covers 7 languages, including five low-resource Southeast Asian languages.", "result": "A comprehensive benchmark framework for e-commerce LLM evaluation, with multilingual and multimodal coverage, grounded in real-world data and quality-controlled reference answers, plus graded difficulty levels to enable nuanced, challenge-oriented assessment.", "conclusion": "EcomEval fills a critical gap by providing a realistic, diverse, multilingual, and multimodal evaluation resource for e-commerce LLMs, enabling more robust and applicable model assessment across real-world shopping scenarios."}}
{"id": "2510.20157", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.20157", "abs": "https://arxiv.org/abs/2510.20157", "authors": ["Xiaoming Wu", "Teng Liu", "Xin Wang", "Ming Yang", "Jiguo Yu"], "title": "ADP-VRSGP: Decentralized Learning with Adaptive Differential Privacy via Variance-Reduced Stochastic Gradient Push", "comment": null, "summary": "Differential privacy is widely employed in decentralized learning to\nsafeguard sensitive data by introducing noise into model updates. However,\nexisting approaches that use fixed-variance noise often degrade model\nperformance and reduce training efficiency. To address these limitations, we\npropose a novel approach called decentralized learning with adaptive\ndifferential privacy via variance-reduced stochastic gradient push (ADP-VRSGP).\nThis method dynamically adjusts both the noise variance and the learning rate\nusing a stepwise-decaying schedule, which accelerates training and enhances\nfinal model performance while providing node-level personalized privacy\nguarantees. To counteract the slowed convergence caused by large-variance noise\nin early iterations, we introduce a progressive gradient fusion strategy that\nleverages historical gradients. Furthermore, ADP-VRSGP incorporates\ndecentralized push-sum and aggregation techniques, making it particularly\nsuitable for time-varying communication topologies. Through rigorous\ntheoretical analysis, we demonstrate that ADP-VRSGP achieves robust convergence\nwith an appropriate learning rate, significantly improving training stability\nand speed. Experimental results validate that our method outperforms existing\nbaselines across multiple scenarios, highlighting its efficacy in addressing\nthe challenges of privacy-preserving decentralized learning.", "AI": {"tldr": "A decentralized learning method with adaptive differential privacy using a variance-reduced gradient push, which adaptively tunes noise and learning rate, uses progressive gradient fusion to speed convergence, and is robust to time-varying topologies, yielding improved performance with private, personalized guarantees.", "motivation": "Fixed-variance noise in privacy-preserving decentralized learning degrades accuracy and efficiency. There is a need for adaptive privacy mechanisms that maintain performance while providing node-level privacy and stability across time-varying networks.", "method": "Introduce ADP-VRSGP: adaptive differential privacy with variance-reduced stochastic gradient push. Key components include stepwise-decaying noise variance and learning rate, progressive gradient fusion using historical gradients, and decentralized push-sum/aggregation to accommodate time-varying communication topologies, along with theoretical convergence guarantees.", "result": "The method achieves robust convergence with a properly chosen learning rate, improves training stability and speed, and outperforms existing baselines across several scenarios according to theoretical analysis and experiments.", "conclusion": "ADP-VRSGP effectively addresses privacy-preserving decentralized learning challenges by combining adaptive noise, variance-reduced updates, and gradient fusion within a decentralized topology framework, yielding faster, more stable training with node-level privacy guarantees."}}
{"id": "2510.20247", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20247", "abs": "https://arxiv.org/abs/2510.20247", "authors": ["Shuhan Hu", "Yiru Li", "Yuanyuan Li", "Yingying Zhu"], "title": "Seeing the Unseen: Mask-Driven Positional Encoding and Strip-Convolution Context Modeling for Cross-View Object Geo-Localization", "comment": null, "summary": "Cross-view object geo-localization enables high-precision object localization\nthrough cross-view matching, with critical applications in autonomous driving,\nurban management, and disaster response. However, existing methods rely on\nkeypoint-based positional encoding, which captures only 2D coordinates while\nneglecting object shape information, resulting in sensitivity to annotation\nshifts and limited cross-view matching capability. To address these\nlimitations, we propose a mask-based positional encoding scheme that leverages\nsegmentation masks to capture both spatial coordinates and object silhouettes,\nthereby upgrading the model from \"location-aware\" to \"object-aware.\"\nFurthermore, to tackle the challenge of large-span objects (e.g., elongated\nbuildings) in satellite imagery, we design a context enhancement module. This\nmodule employs horizontal and vertical strip convolutional kernels to extract\nlong-range contextual features, enhancing feature discrimination among\nstrip-like objects. Integrating MPE and CEM, we present EDGeo, an end-to-end\nframework for robust cross-view object geo-localization. Extensive experiments\non two public datasets (CVOGL and VIGOR-Building) demonstrate that our method\nachieves state-of-the-art performance, with a 3.39% improvement in localization\naccuracy under challenging ground-to-satellite scenarios. This work provides a\nrobust positional encoding paradigm and a contextual modeling framework for\nadvancing cross-view geo-localization research.", "AI": {"tldr": "EDGeo introduces a mask-based positional encoding (MPE) and a context enhancement module (CEM) to achieve robust cross-view object geo-localization, achieving state-of-the-art results on CVOGL and VIGOR-Building with notable accuracy gains.", "motivation": "Cross-view geo-localization currently relies on 2D keypoint-based coordinates that miss object shape information, making it vulnerable to annotation shifts and limiting cross-view matching, particularly for large-span objects in satellite imagery.", "method": "Propose mask-based positional encoding using segmentation masks to capture both coordinates and object silhouettes (MPE). Introduce a context enhancement module with horizontal and vertical strip convolutions to model long-range context for elongated objects. Integrate MPE and CEM into EDGeo, an end-to-end framework.", "result": "EDGeo achieves state-of-the-art performance on two public datasets (CVOGL and VIGOR-Building), with a 3.39% improvement in localization accuracy in challenging ground-to-satellite scenarios.", "conclusion": "A robust positional encoding paradigm and contextual modeling framework for advancing cross-view geo-localization, enabling more accurate and reliable cross-view matching by incorporating object shapes and long-range context."}}
{"id": "2510.20636", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20636", "abs": "https://arxiv.org/abs/2510.20636", "authors": ["Eric Ngoiya", "Tianshu Bao"], "title": "Fluidity Index: Next-Generation Super-intelligence Benchmarks", "comment": "12", "summary": "This paper introduces the Fluidity Index (FI) to quantify model adaptability\nin dynamic, scaling environments. The benchmark evaluates response accuracy\nbased on deviations in initial, current, and future environment states,\nassessing context switching and continuity. We distinguish between closed-ended\nand open-ended benchmarks, prioritizing closed-loop open-ended real-world\nbenchmarks to test adaptability. The approach measures a model's ability to\nunderstand, predict, and adjust to state changes in scaling environments. A\ntruly super-intelligent model should exhibit at least second-order\nadaptability, enabling self-sustained computation through digital replenishment\nfor optimal fluidity.", "AI": {"tldr": "A new Fluidity Index (FI) quantifies model adaptability in dynamic, scaling environments using benchmarks across initial/current/future state deviations; emphasizes closed-loop open-ended real-world tests and posits second-order adaptability with digital replenishment as a sign of super-intelligence.", "motivation": "To provide a metric that captures a model's ability to understand, predict, and adjust to changing environment states and context switches in scaling contexts, where conventional static benchmarks fail to reflect adaptability.", "method": "Introduce FI as a benchmark metric; evaluate response accuracy based on deviations among initial, current, and future environment states; compare closed-ended vs open-ended benchmarks, prioritizing closed-loop open-ended real-world benchmarks; assess adaptability via context switching and continuity.", "result": "Proposes FI as a tool to quantify adaptability; suggests that a truly super-intelligent model would exhibit at least second-order adaptability and digital replenishment for self-sustained computation; results are conceptual or theoretical, pending empirical validation.", "conclusion": "FI provides a framework to quantify model adaptability in dynamic settings and stresses the importance of real-world closed-loop benchmarks and higher-order adaptability as a path toward more capable AI systems."}}
{"id": "2510.20169", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20169", "abs": "https://arxiv.org/abs/2510.20169", "authors": ["Tongkai Lu", "Shuai Ma", "Chongyang Tao"], "title": "Empowering Targeted Neighborhood Search via Hyper Tour for Large-Scale TSP", "comment": "12 pages", "summary": "Traveling Salesman Problem (TSP) is a classic NP-hard problem that has\ngarnered significant attention from both academia and industry. While\nneural-based methods have shown promise for solving TSPs, they still face\nchallenges in scaling to larger instances, particularly in memory constraints\nassociated with global heatmaps, edge weights, or access matrices, as well as\nin generating high-quality initial solutions and insufficient global guidance\nfor efficiently navigating vast search spaces. To address these challenges, we\npropose a Hyper Tour Guided Neighborhood Search (HyperNS) method for\nlarge-scale TSP instances. Inspired by the ``clustering first, route second\"\nstrategy, our approach initially divides the TSP instance into clusters using a\nsparse heatmap graph and abstracts them as supernodes, followed by the\ngeneration of a hyper tour to guide both the initialization and optimization\nprocesses. This method reduces the search space by focusing on edges relevant\nto the hyper tour, leading to more efficient and effective optimization.\nExperimental results on both synthetic and real-world datasets demonstrate that\nour approach outperforms existing neural-based methods, particularly in\nhandling larger-scale instances, offering a significant reduction in the gap to\nthe optimal solution.", "AI": {"tldr": "HyperNS is a scalable TSP solver that uses clustering via sparse heatmaps and a hyper tour to guide initialization and optimization, reducing the search space and improving performance on large-scale instances.", "motivation": "Neural-based TSP solvers struggle with memory limits of global representations and lack of strong global guidance, especially for large instances; there is a need for scalable initialization and efficient search navigation.", "method": "Construct a sparse heatmap graph, cluster nodes into groups, abstract clusters as supernodes, generate a hyper tour to guide both initialization and optimization, and focus the search on hyper tour-relevant edges to prune the space.", "result": "Experiments on synthetic and real-world datasets show HyperNS outperforms neural-based methods, especially on large instances, achieving a smaller gap to the optimal solution.", "conclusion": "HyperNS demonstrates a scalable, effective approach for large-scale TSP by combining clustering, hyper tour guidance, and targeted neighborhood search; potential applicability to other large combinatorial problems."}}
{"id": "2510.20256", "categories": ["cs.CV", "cs.CL", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.20256", "abs": "https://arxiv.org/abs/2510.20256", "authors": ["Guowei Zhong", "Junjie Li", "Huaiyu Zhu", "Ruohong Huan", "Yun Pan"], "title": "Calibrating Multimodal Consensus for Emotion Recognition", "comment": null, "summary": "In recent years, Multimodal Emotion Recognition (MER) has made substantial\nprogress. Nevertheless, most existing approaches neglect the semantic\ninconsistencies that may arise across modalities, such as conflicting emotional\ncues between text and visual inputs. Besides, current methods are often\ndominated by the text modality due to its strong representational capacity,\nwhich can compromise recognition accuracy. To address these challenges, we\npropose a model termed Calibrated Multimodal Consensus (CMC). CMC introduces a\nPseudo Label Generation Module (PLGM) to produce pseudo unimodal labels,\nenabling unimodal pretraining in a self-supervised fashion. It then employs a\nParameter-free Fusion Module (PFM) and a Multimodal Consensus Router (MCR) for\nmultimodal finetuning, thereby mitigating text dominance and guiding the fusion\nprocess toward a more reliable consensus. Experimental results demonstrate that\nCMC achieves performance on par with or superior to state-of-the-art methods\nacross four datasets, CH-SIMS, CH-SIMS v2, CMU-MOSI, and CMU-MOSEI, and\nexhibits notable advantages in scenarios with semantic inconsistencies on\nCH-SIMS and CH-SIMS v2. The implementation of this work is publicly accessible\nat https://github.com/gw-zhong/CMC.", "AI": {"tldr": "Calibrated Multimodal Consensus (CMC) improves MER by self-supervised unimodal pretraining via pseudo labels and a text-agnostic fusion pathway, achieving state-of-the-art or competitive results across four datasets, especially with semantic inconsistencies.", "motivation": "Semantic inconsistencies across modalities and text-dominated MER often hurt accuracy; need robust, modality-aware fusion.", "method": "CMC includes Pseudo Label Generation Module (PLGM) for pseudo unimodal labels enabling unimodal pretraining in a self-supervised fashion; a Parameter-free Fusion Module (PFM) to avoid forcing heavy reliance on any single modality; and a Multimodal Consensus Router (MCR) to guide multimodal finetuning towards a reliable consensus, mitigating text dominance.", "result": "Experimental results show CMC matches or surpasses state-of-the-art on CH-SIMS, CH-SIMS v2, CMU-MOSI, and CMU-MOSEI, with notable advantages in scenarios with semantic inconsistencies on CH-SIMS/CH-SIMS v2.", "conclusion": "CMC effectively mitigates cross-modal semantic conflicts and text bias, delivering strong MER performance, with public code at the provided GitHub link."}}
{"id": "2510.20641", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20641", "abs": "https://arxiv.org/abs/2510.20641", "authors": ["Andrea Agiollo", "Andrea Omicini"], "title": "Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges", "comment": null, "summary": "Thanks to the remarkable human-like capabilities of machine learning (ML)\nmodels in perceptual and cognitive tasks, frameworks integrating ML within\nrational agent architectures are gaining traction. Yet, the landscape remains\nfragmented and incoherent, often focusing on embedding ML into generic agent\ncontainers while overlooking the expressive power of rational\narchitectures--such as Belief-Desire-Intention (BDI) agents. This paper\npresents a fine-grained systematisation of existing approaches, using the BDI\nparadigm as a reference. Our analysis illustrates the fast-evolving literature\non rational agents enhanced by ML, and identifies key research opportunities\nand open challenges for designing effective rational ML agents.", "AI": {"tldr": "A fine-grained systematisation of ML-augmented rational agents using BDI as reference, addressing fragmentation in the literature and outlining opportunities and open challenges.", "motivation": "To address fragmentation in ML+rational-agent research and to leverage the expressive power of BDI architectures for designing effective ML-enabled agents.", "method": "Fine-grained literature survey and taxonomy that maps existing ML-augmented rational-agent approaches onto BDI primitives, identifying design patterns, gaps, and evaluation considerations.", "result": "A comprehensive taxonomy and cross-cutting insights showing how ML integrations align with Beliefs, Desires, and Intentions; highlights opportunities and open challenges for designing effective rational ML agents.", "conclusion": "BDI-centric systematisation clarifies the design space, guides future research, and calls for coherent frameworks and benchmarks to advance rational ML agents."}}
{"id": "2510.20187", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20187", "abs": "https://arxiv.org/abs/2510.20187", "authors": ["Dian Yu", "Yulai Zhao", "Kishan Panaganti", "Linfeng Song", "Haitao Mi", "Dong Yu"], "title": "Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values", "comment": "15 pages, 4 figures", "summary": "We propose Reinforcement Learning with Explicit Human Values (RLEV), a method\nthat aligns Large Language Model (LLM) optimization directly with quantifiable\nhuman value signals. While Reinforcement Learning with Verifiable Rewards\n(RLVR) effectively trains models in objective domains using binary correctness\nrewards, it overlooks that not all tasks are equally significant. RLEV extends\nthis framework by incorporating human-defined value signals directly into the\nreward function. Using exam-style data with explicit ground-truth value labels,\nRLEV consistently outperforms correctness-only baselines across multiple RL\nalgorithms and model scales. Crucially, RLEV policies not only improve\nvalue-weighted accuracy but also learn a value-sensitive termination policy:\nconcise for low-value prompts, thorough for high-value ones. We demonstrate\nthis behavior stems from value-weighted gradient amplification on\nend-of-sequence tokens. Ablation studies confirm the gain is causally linked to\nvalue alignment. RLEV remains robust under noisy value signals, such as\ndifficulty-based labels, demonstrating that optimizing for an explicit utility\nfunction offers a practical path to aligning LLMs with human priorities.", "AI": {"tldr": "RLEV introduces human-valued rewards into RL for LLMs, boosting value-weighted accuracy across models and algorithms, and enabling value-aware termination; robust to noisy value signals.", "motivation": "Not all tasks are equally important; binary correctness rewards miss human priorities. We need a way to inject explicit human value signals into LLM optimization.", "method": "Extend Reinforcement Learning with Verifiable Rewards (RLVR) by incorporating ground-truth value labels into the reward function (exam-style data). Evaluate across multiple RL algorithms and model scales; analyze value-weighted termination and gradient effects; perform ablations; test robustness to noisy value signals.", "result": "RLEV outperforms correctness-only baselines in value-weighted accuracy across settings; learns a termination policy that is concise for low-value prompts and thorough for high-value ones; ablations show this is causally linked to value alignment; robust to noisy value signals.", "conclusion": "Optimizing with explicit utility functions provides a practical path to aligning LLMs with human priorities; RLEV demonstrates effective and robust value-aligned RL for LLMs."}}
{"id": "2510.20267", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20267", "abs": "https://arxiv.org/abs/2510.20267", "authors": ["Saraf Anzum Shreya", "MD. Abu Ismail Siddique", "Sharaf Tasnim"], "title": "Real-Time Currency Detection and Voice Feedback for Visually Impaired Individuals", "comment": "20 pages, 5 tables, 8 figues", "summary": "Technologies like smartphones have become an essential in our daily lives. It\nhas made accessible to everyone including visually impaired individuals. With\nthe use of smartphone cameras, image capturing and processing have become more\nconvenient. With the use of smartphones and machine learning, the life of\nvisually impaired can be made a little easier. Daily tasks such as handling\nmoney without relying on someone can be troublesome for them. For that purpose\nthis paper presents a real-time currency detection system designed to assist\nvisually impaired individuals. The proposed model is trained on a dataset\ncontaining 30 classes of notes and coins, representing 3 types of currency: US\ndollar (USD), Euro (EUR), and Bangladeshi taka (BDT). Our approach uses a\nYOLOv8 nano model with a custom detection head featuring deep convolutional\nlayers and Squeeze-and-Excitation blocks to enhance feature extraction and\ndetection accuracy. Our model has achieved a higher accuracy of 97.73%, recall\nof 95.23%, f1-score of 95.85% and a mean Average Precision at IoU=0.5\n(mAP50(B)) of 97.21\\%. Using the voice feedback after the detection would help\nthe visually impaired to identify the currency. This paper aims to create a\npractical and efficient currency detection system to empower visually impaired\nindividuals independent in handling money.", "AI": {"tldr": "Real-time currency detection for visually impaired users using YOLOv8 nano, covering USD, EUR, and BDT with 30 classes; strong performance and on-device voice feedback.", "motivation": "Assist visually impaired individuals in handling money independently by leveraging smartphones and machine learning.", "method": "Train a YOLOv8 nano model with a custom detection head incorporating deep convolutional layers and Squeeze-and-Excitation blocks on a dataset of 30 classes representing notes and coins across USD, EUR, and BDT; provide voice feedback post-detection for usability.", "result": "Accuracy 97.73%, recall 95.23%, F1-score 95.85%, and mAP@IoU=0.5 (mAP50(B)) of 97.21%; real-time currency detection.", "conclusion": "Presents a practical, efficient currency detection system to empower visually impaired individuals, enabling independence in handling money through on-device real-time detection and voice guidance."}}
{"id": "2510.20665", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20665", "abs": "https://arxiv.org/abs/2510.20665", "authors": ["Xue Wen Tan", "Nathaniel Tan", "Galen Lee", "Stanley Kok"], "title": "The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models", "comment": null, "summary": "Evaluating the quality of reasoning traces from large language models remains\nunderstudied, labor-intensive, and unreliable: current practice relies on\nexpert rubrics, manual annotation, and slow pairwise judgments. Automated\nefforts are dominated by graph-based proxies that quantify structural\nconnectivity but do not clarify what constitutes high-quality reasoning; such\nabstractions can be overly simplistic for inherently complex processes. We\nintroduce a topological data analysis (TDA)-based evaluation framework that\ncaptures the geometry of reasoning traces and enables label-efficient,\nautomated assessment. In our empirical study, topological features yield\nsubstantially higher predictive power for assessing reasoning quality than\nstandard graph metrics, suggesting that effective reasoning is better captured\nby higher-dimensional geometric structures rather than purely relational\ngraphs. We further show that a compact, stable set of topological features\nreliably indicates trace quality, offering a practical signal for future\nreinforcement learning algorithms.", "AI": {"tldr": "A topological data analysis (TDA) framework for evaluating the quality of reasoning traces in large language models, achieving better predictive power than graph metrics and enabling label-efficient, automated assessment for reinforcement learning signals.", "motivation": "Current methods to judge reasoning quality rely on labor-intensive expert rubrics, manual annotations, and slow pairwise judgments. Graph-based proxies capture connectivity but miss the geometric structure of complex reasoning, motivating a geometry-aware approach.", "method": "Apply topological data analysis to reasoning traces to extract high-dimensional geometric features (e.g., persistent homology), compare their predictive power for reasoning quality against standard graph metrics, and identify a compact, stable feature set suitable for automated assessment and RL guidance.", "result": "Topological features outperform traditional graph metrics in predicting reasoning quality; a compact, stable feature subset reliably signals trace quality, supporting efficient label-efficient evaluation and potential integration into RL algorithms.", "conclusion": "TDA-based evaluation provides a scalable, effective approach for assessing reasoning quality in LLMs and can inform future reinforcement learning and development of higher-quality reasoning traces."}}
{"id": "2510.20199", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20199", "abs": "https://arxiv.org/abs/2510.20199", "authors": ["Jane H. Lee", "Baturay Saglam", "Spyridon Pougkakiotis", "Amin Karbasi", "Dionysis Kalogerias"], "title": "Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents", "comment": null, "summary": "Constrained optimization provides a common framework for dealing with\nconflicting objectives in reinforcement learning (RL). In most of these\nsettings, the objectives (and constraints) are expressed though the expected\naccumulated reward. However, this formulation neglects risky or even possibly\ncatastrophic events at the tails of the reward distribution, and is often\ninsufficient for high-stakes applications in which the risk involved in\noutliers is critical. In this work, we propose a framework for risk-aware\nconstrained RL, which exhibits per-stage robustness properties jointly in\nreward values and time using optimized certainty equivalents (OCEs). Our\nframework ensures an exact equivalent to the original constrained problem\nwithin a parameterized strong Lagrangian duality framework under appropriate\nconstraint qualifications, and yields a simple algorithmic recipe which can be\nwrapped around standard RL solvers, such as PPO. Lastly, we establish the\nconvergence of the proposed algorithm under common assumptions, and verify the\nrisk-aware properties of our approach through several numerical experiments.", "AI": {"tldr": "Proposes a risk-aware constrained RL framework using optimized certainty equivalents (OCEs); achieves per-stage robustness, exact duality, and a PPO-wrapped algorithm with convergence guarantees and empirical validation.", "motivation": "Traditional constrained RL optimizes expected rewards and ignores tail risk; high-stakes scenarios require accounting for risk of extreme outcomes.", "method": "Uses optimized certainty equivalents to model risk in per-step rewards and constraints; develops a parameterized strong Lagrangian duality framework; derives an algorithm that can wrap standard RL solvers (e.g., PPO); proves convergence under standard assumptions.", "result": "Establishes exact equivalence to the original constrained problem under appropriate constraint qualifications; provides a practical algorithm; demonstrates convergence and risk-aware behavior via numerical experiments.", "conclusion": "Framework enables risk-aware constrained RL with per-stage robustness, offers plug-in compatibility with existing RL solvers, and is supported by convergence guarantees and empirical validation."}}
{"id": "2510.20268", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.20268", "abs": "https://arxiv.org/abs/2510.20268", "authors": ["Guangyu Dai", "Dong Chen", "Siliang Tang", "Yueting Zhuang"], "title": "GMFVAD: Using Grained Multi-modal Feature to Improve Video Anomaly Detection", "comment": null, "summary": "Video anomaly detection (VAD) is a challenging task that detects anomalous\nframes in continuous surveillance videos. Most previous work utilizes the\nspatio-temporal correlation of visual features to distinguish whether there are\nabnormalities in video snippets. Recently, some works attempt to introduce\nmulti-modal information, like text feature, to enhance the results of video\nanomaly detection. However, these works merely incorporate text features into\nvideo snippets in a coarse manner, overlooking the significant amount of\nredundant information that may exist within the video snippets. Therefore, we\npropose to leverage the diversity among multi-modal information to further\nrefine the extracted features, reducing the redundancy in visual features, and\nwe propose Grained Multi-modal Feature for Video Anomaly Detection (GMFVAD).\nSpecifically, we generate more grained multi-modal feature based on the video\nsnippet, which summarizes the main content, and text features based on the\ncaptions of original video will be introduced to further enhance the visual\nfeatures of highlighted portions. Experiments show that the proposed GMFVAD\nachieves state-of-the-art performance on four mainly datasets. Ablation\nexperiments also validate that the improvement of GMFVAD is due to the\nreduction of redundant information.", "AI": {"tldr": "GMFVAD introduces grained multi-modal features for video anomaly detection by aligning refined video snippets with caption-based text to reduce redundancy, achieving state-of-the-art results on four datasets; ablations attribute gains to redundancy reduction.", "motivation": "To address redundancy and suboptimal fusion in prior multi-modal VAD methods by exploiting diversity across modalities with fine-grained representations.", "method": "Generate fine-grained multi-modal features from video snippets (summary of main content) and incorporate text features from video captions to enhance highlighted portions; integrate these features for anomaly detection; perform ablation studies to verify redundancy reduction as the key factor.", "result": "Achieves state-of-the-art performance on four major VAD datasets; ablation experiments confirm that improvements stem from reducing redundant visual information.", "conclusion": "Grained, caption-informed multi-modal representations can effectively refine visual features for video anomaly detection and reduce redundancy, leading to superior performance."}}
{"id": "2510.20691", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20691", "abs": "https://arxiv.org/abs/2510.20691", "authors": ["Yanlin Song", "Ben Liu", "V\u00edctor Guti\u00e9rrez-Basulto", "Zhiwei Hu", "Qianqian Xie", "Min Peng", "Sophia Ananiadou", "Jeff Z. Pan"], "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs", "comment": null, "summary": "Knowledge Graph Question Answering aims to answer natural language questions\nby reasoning over structured knowledge graphs. While large language models have\nadvanced KGQA through their strong reasoning capabilities, existing methods\ncontinue to struggle to fully exploit both the rich knowledge encoded in KGs\nand the reasoning capabilities of LLMs, particularly in complex scenarios. They\noften assume complete KG coverage and lack mechanisms to judge when external\ninformation is needed, and their reasoning remains locally myopic, failing to\nmaintain coherent multi-step planning, leading to reasoning failures even when\nrelevant knowledge exists. We propose Graph-RFT, a novel two-stage\nreinforcement fine-tuning KGQA framework with a\n'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to\nperform autonomous planning and adaptive retrieval scheduling across KG and web\nsources under incomplete knowledge conditions. Graph-RFT introduces a\nchain-of-thought fine-tuning method with a customized plan-retrieval dataset\nactivates structured reasoning and resolves the GRPO cold-start problem. It\nthen introduces a novel plan-retrieval guided reinforcement learning process\nintegrates explicit planning and retrieval actions with a multi-reward design,\nenabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired\nplanning module to decompose complex questions into ordered subquestions, and\nlogical expression to guide tool invocation for globally consistent multi-step\nreasoning. This reasoning retrieval process is optimized with a multi-reward\ncombining outcome and retrieval specific signals, enabling the model to learn\nwhen and how to combine KG and web retrieval effectively.", "AI": {"tldr": "Graph-RFT proposes a two-stage reinforcement fine-tuning KGQA framework that jointly plans and retrieves from knowledge graphs and the web to perform coherent, multi-step reasoning under incomplete knowledge.", "motivation": "Current KGQA with LLMs often assumes complete KG coverage and lacks mechanisms to judge when external information is needed; reasoning tends to be locally myopic, leading to failures even when relevant knowledge exists.", "method": "Two-stage reinforcement fine-tuning architecture named Graph-RFT with plan-KGsearch-and-Websearch-during-think paradigm; chain-of-thought fine-tuning using a plan-retrieval dataset; plan-retrieval guided RL with a multi-reward design; Cartesian-inspired planning to decompose questions; logical expression to guide tool invocation; retrieval signals to learn when/how to combine KG and web sources.", "result": "The abstract does not report empirical results; it emphasizes methodological contributions and potential benefits such as coverage-aware retrieval scheduling and globally consistent multi-step reasoning.", "conclusion": "Graph-RFT offers a principled framework to integrate planning and retrieval for KGQA under incomplete knowledge, addressing cold-start issues and enabling adaptive, structured reasoning across KG and web resources."}}
{"id": "2510.20200", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20200", "abs": "https://arxiv.org/abs/2510.20200", "authors": ["Max Hopkins", "Russell Impagliazzo", "Christopher Ye"], "title": "Approximate Replicability in Learning", "comment": "51 pages, 1 figure", "summary": "Replicability, introduced by (Impagliazzo et al. STOC '22), is the notion\nthat algorithms should remain stable under a resampling of their inputs (given\naccess to shared randomness). While a strong and interesting notion of\nstability, the cost of replicability can be prohibitive: there is no replicable\nalgorithm, for instance, for tasks as simple as threshold learning (Bun et al.\nSTOC '23). Given such strong impossibility results we ask: under what\napproximate notions of replicability is learning possible?\n  In this work, we propose three natural relaxations of replicability in the\ncontext of PAC learning: (1) Pointwise: the learner must be consistent on any\nfixed input, but not across all inputs simultaneously, (2) Approximate: the\nlearner must output hypotheses that classify most of the distribution\nconsistently, (3) Semi: the algorithm is fully replicable, but may additionally\nuse shared unlabeled samples. In all three cases, for constant replicability\nparameters, we obtain sample-optimal agnostic PAC learners: (1) and (2) are\nachievable for ``free\" using $\\Theta(d/\\alpha^2)$ samples, while (3) requires\n$\\Theta(d^2/\\alpha^2)$ labeled samples.", "AI": {"tldr": "Three relaxations of replicability in PAC learning enable sample-optimal agnostic learners. Pointwise and Approximate relaxations achieve teaching with \u0398(d/\u03b1^2) samples; the Semi relaxation with shared unlabeled data needs \u0398(d^2/\u03b1^2) labeled samples.", "motivation": "Replicability requires algorithms to be stable under input resampling with shared randomness. While appealing, it is known to be too strong (e.g., no replicable algorithm for threshold learning). The paper investigates what approximate notions of replicability still allow learning.", "method": "Introduce three natural relaxations of replicability in the PAC setting: (1) Pointwise\u2014consistency on a fixed input but not uniformly across inputs; (2) Approximate\u2014consistency on most of the distribution; (3) Semi\u2014fully replicable but augmented with shared unlabeled samples. For constant replication parameters, construct agnostic PAC learners and analyze sample complexity.", "result": "For constant replicability parameters, the paper achieves sample-optimal agnostic PAC learners: (1) and (2) with \u0398(d/\u03b1^2) samples (effectively free of additional cost), (3) with \u0398(d^2/\u03b1^2) labeled samples.", "conclusion": "Three natural relaxations of replicability restore learnability in the PAC framework, with clear trade-offs in sample complexity. Pointwise and Approximate offer low sample costs, while Semi incurs higher labeled-sample cost due to requiring full replicability plus unlabeled data. This establishes a spectrum between stability and efficiency and invites further study on constants, other concept classes, and practical algorithm design."}}
{"id": "2510.20281", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.20281", "abs": "https://arxiv.org/abs/2510.20281", "authors": ["Jiayi Zou", "Gengyun Jia", "Bing-Kun Bao"], "title": "Causal Debiasing for Visual Commonsense Reasoning", "comment": null, "summary": "Visual Commonsense Reasoning (VCR) refers to answering questions and\nproviding explanations based on images. While existing methods achieve high\nprediction accuracy, they often overlook bias in datasets and lack debiasing\nstrategies. In this paper, our analysis reveals co-occurrence and statistical\nbiases in both textual and visual data. We introduce the VCR-OOD datasets,\ncomprising VCR-OOD-QA and VCR-OOD-VA subsets, which are designed to evaluate\nthe generalization capabilities of models across two modalities. Furthermore,\nwe analyze the causal graphs and prediction shortcuts in VCR and adopt a\nbackdoor adjustment method to remove bias. Specifically, we create a dictionary\nbased on the set of correct answers to eliminate prediction shortcuts.\nExperiments demonstrate the effectiveness of our debiasing method across\ndifferent datasets.", "AI": {"tldr": "Introduces VCR-OOD datasets to test cross-modal generalization in Visual Commonsense Reasoning and proposes a backdoor debiasing approach using a dictionary of correct answers to mitigate prediction shortcuts, with experimental validation.", "motivation": "Address pervasive biases and shortcut-based predictions in VCR datasets that arise from co-occurrence statistics in both text and images, which hurt cross-modal generalization.", "method": "Analyze causal graphs and prediction shortcuts in VCR, apply backdoor adjustment to remove bias, and create a dictionary-based strategy to eliminate shortcuts; propose VCR-OOD-QA and VCR-OOD-VA subsets to evaluate cross-modal generalization.", "result": "Debiasing method shows effectiveness across different datasets, improving robustness by reducing reliance on dataset biases and prediction shortcuts.", "conclusion": "Backdoor-based debiasing combined with a dictionary of correct answers and the VCR-OOD benchmarks provides a viable approach to improve debiasing and cross-modal generalization in Visual Commonsense Reasoning."}}
{"id": "2510.20784", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20784", "abs": "https://arxiv.org/abs/2510.20784", "authors": ["Fares Fourati"], "title": "A Coherence-Based Measure of AGI", "comment": "13 pages, 1 figure, 12 tables", "summary": "Recent work by \\citet{hendrycks2025agidefinition} formalized\n\\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of\nproficiencies across cognitive domains derived from the Cattell--Horn--Carroll\n(CHC) model of human cognition. While elegant, this definition assumes\n\\textit{compensability} -- that exceptional ability in some domains can offset\nfailure in others. True general intelligence, however, should reflect\n\\textit{coherent sufficiency}: balanced competence across all essential\ndomains. We propose a coherence-aware measure of AGI based on the integral of\ngeneralized means over a continuum of compensability exponents. This\nformulation spans arithmetic, geometric, and harmonic regimes, and the\nresulting \\textit{area under the curve} (AUC) quantifies robustness under\nvarying compensability assumptions. Unlike the arithmetic mean, which rewards\nspecialization, the AUC penalizes imbalance and captures inter-domain\ndependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,\nthe coherence-adjusted AUC reveals that both systems remain far from general\ncompetence despite high arithmetic scores (e.g., GPT-5 at~24\\%). Integrating\nthe generalized mean thus yields a principled, interpretable, and stricter\nfoundation for measuring genuine progress toward AGI.", "AI": {"tldr": "Coherence-aware AGI metric using area under the curve of generalized means across compensability exponents; reveals GPT-4/5 underperform in general competence despite high arithmetic scores.", "motivation": "Current AGI definition based on arithmetic mean assumes compensability; this is incompatible with true coherent sufficiency; need a measure that penalizes imbalance across CHC domains.", "method": "Define a continuum of compensability exponents p; compute generalized mean M_p across CHC domain scores; integrate M_p over p to obtain AUC; interpret AUC as coherence-adjusted AGI; apply to published CHC scores for GPT-4 and GPT-5.", "result": "AUC-based coherence measure shows GPT-4 and GPT-5 remain far from general competence; even GPT-5's high arithmetic score (\u224824%) is not sufficient when coherence penalized; demonstrates inter-domain dependency and imbalance reduce generality.", "conclusion": "A generalized-mean integration provides a principled, interpretable, and stricter foundation for measuring progress toward AGI, correcting for compensability, and discouraging overemphasis on specialization."}}
{"id": "2510.20209", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20209", "abs": "https://arxiv.org/abs/2510.20209", "authors": ["Shumin Li"], "title": "Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset", "comment": null, "summary": "The development of accessible screening tools for early cancer detection in\ndogs represents a significant challenge in veterinary medicine. Routine\nlaboratory data offer a promising, low-cost source for such tools, but their\nutility is hampered by the non-specificity of individual biomarkers and the\nsevere class imbalance inherent in screening populations. This study assesses\nthe feasibility of cancer risk classification using the Golden Retriever\nLifetime Study (GRLS) cohort under real-world constraints, including the\ngrouping of diverse cancer types and the inclusion of post-diagnosis samples. A\ncomprehensive benchmark evaluation was conducted, systematically comparing 126\nanalytical pipelines that comprised various machine learning models, feature\nselection methods, and data balancing techniques. Data were partitioned at the\npatient level to prevent leakage. The optimal model, a Logistic Regression\nclassifier with class weighting and recursive feature elimination, demonstrated\nmoderate ranking ability (AUROC = 0.815; 95% CI: 0.793-0.836) but poor clinical\nclassification performance (F1-score = 0.25, Positive Predictive Value = 0.15).\nWhile a high Negative Predictive Value (0.98) was achieved, insufficient recall\n(0.79) precludes its use as a reliable rule-out test. Interpretability analysis\nwith SHapley Additive exPlanations (SHAP) revealed that predictions were driven\nby non-specific features like age and markers of inflammation and anemia. It is\nconcluded that while a statistically detectable cancer signal exists in routine\nlab data, it is too weak and confounded for clinically reliable discrimination\nfrom normal aging or other inflammatory conditions. This work establishes a\ncritical performance ceiling for this data modality in isolation and\nunderscores that meaningful progress in computational veterinary oncology will\nrequire integration of multi-modal data sources.", "AI": {"tldr": "A large benchmark shows routine canine lab data can detect cancer signals, but clinical discrimination is weak and multimodal data are needed.", "motivation": "There is a need for accessible, low-cost screening tools for early cancer detection in dogs. Routine laboratory data may offer a signal, but non-specific biomarkers and class imbalance hinder performance. This study benchmarks predictive capability under real-world constraints and seeks to identify limitations.", "method": "Systematic benchmarking of 126 analytical pipelines combining machine learning models, feature selection methods, and data balancing techniques. Data from the Golden Retriever Lifetime Study (GRLS) cohort. Partitioned at the patient level to prevent leakage. Investigated grouping of diverse cancer types and inclusion of post-diagnosis samples. Evaluated via AUROC, F1-score, PPV, NPV, and recall. Interpretability assessed with SHAP. The best model was Logistic Regression with class weighting and recursive feature elimination.", "result": "Best AUROC 0.815 (95% CI 0.793\u20130.836); F1-score 0.25; PPV 0.15; NPV 0.98; recall 0.79. The optimal model used logistic regression with class weighting and recursive feature elimination. SHAP indicated predictions were driven by non-specific features such as age and markers of inflammation and anemia, suggesting limited clinical discrimination beyond aging/inflammation. The study reveals a detectable cancer signal in routine data but insufficient strength/confounding for reliable rule-out discrimination.", "conclusion": "There exists a statistical cancer signal in routine canine lab data, but it is too weak and confounded for reliable clinical separation from aging or inflammatory conditions. This establishes a performance ceiling for this data modality and indicates progress in veterinary oncology will require integration of multi-modal data sources."}}
{"id": "2510.20284", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20284", "abs": "https://arxiv.org/abs/2510.20284", "authors": ["Haodong Yang", "Zhongling Huang", "Shaojie Guo", "Zhe Zhang", "Gong Cheng", "Junwei Han"], "title": "Knowledge-Informed Neural Network for Complex-Valued SAR Image Recognition", "comment": null, "summary": "Deep learning models for complex-valued Synthetic Aperture Radar (CV-SAR)\nimage recognition are fundamentally constrained by a representation trilemma\nunder data-limited and domain-shift scenarios: the concurrent, yet conflicting,\noptimization of generalization, interpretability, and efficiency. Our work is\nmotivated by the premise that the rich electromagnetic scattering features\ninherent in CV-SAR data hold the key to resolving this trilemma, yet they are\ninsufficiently harnessed by conventional data-driven models. To this end, we\nintroduce the Knowledge-Informed Neural Network (KINN), a lightweight framework\nbuilt upon a novel \"compression-aggregation-compression\" architecture. The\nfirst stage performs a physics-guided compression, wherein a novel dictionary\nprocessor adaptively embeds physical priors, enabling a compact unfolding\nnetwork to efficiently extract sparse, physically-grounded signatures. A\nsubsequent aggregation module enriches these representations, followed by a\nfinal semantic compression stage that utilizes a compact classification head\nwith self-distillation to learn maximally task-relevant and discriminative\nembeddings. We instantiate KINN in both CNN (0.7M) and Vision Transformer\n(0.95M) variants. Extensive evaluations on five SAR benchmarks confirm that\nKINN establishes a state-of-the-art in parameter-efficient recognition,\noffering exceptional generalization in data-scarce and out-of-distribution\nscenarios and tangible interpretability, thereby providing an effective\nsolution to the representation trilemma and offering a new path for trustworthy\nAI in SAR image analysis.", "AI": {"tldr": "KINN leverages physics-guided compression and knowledge integration to achieve parameter-efficient, generalizable, and interpretable CV-SAR recognition across benchmarks.", "motivation": "To resolve the CV-SAR representation trilemma (generalization, interpretability, efficiency) under data scarcity and domain shift by exploiting the rich physical scattering features.", "method": "A lightweight Knowledge-Informed Neural Network with a 'compression-aggregation-compression' pipeline: physics-guided dictionary-based compression embeds priors; a sparse-unfolding network extracts physically-grounded signatures; an aggregation stage enriches representations; a final semantic compression with self-distillation; implemented in CNN (0.7M) and Vision Transformer (0.95M).", "result": "Achieves state-of-the-art parameter efficiency with strong generalization in data-scarce and out-of-distribution scenarios and improved interpretability across five SAR benchmarks.", "conclusion": "KINN offers a viable solution to the CV-SAR representation trilemma and provides a path toward trustworthy, efficient AI in SAR image analysis."}}
{"id": "2510.20809", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20809", "abs": "https://arxiv.org/abs/2510.20809", "authors": ["Xueyan Zou", "Jianglong Ye", "Hao Zhang", "Xiaoyu Xiang", "Mingyu Ding", "Zhaojing Yang", "Yong Jae Lee", "Zhuowen Tu", "Sifei Liu", "Xiaolong Wang"], "title": "Real Deep Research for AI, Robotics and Beyond", "comment": "website: https://realdeepresearch.github.io", "summary": "With the rapid growth of research in AI and robotics now producing over\n10,000 papers annually it has become increasingly difficult for researchers to\nstay up to date. Fast evolving trends, the rise of interdisciplinary work, and\nthe need to explore domains beyond one's expertise all contribute to this\nchallenge. To address these issues, we propose a generalizable pipeline capable\nof systematically analyzing any research area: identifying emerging trends,\nuncovering cross domain opportunities, and offering concrete starting points\nfor new inquiry. In this work, we present Real Deep Research (RDR) a\ncomprehensive framework applied to the domains of AI and robotics, with a\nparticular focus on foundation models and robotics advancements. We also\nbriefly extend our analysis to other areas of science. The main paper details\nthe construction of the RDR pipeline, while the appendix provides extensive\nresults across each analyzed topic. We hope this work sheds light for\nresearchers working in the field of AI and beyond.", "AI": {"tldr": "A generalizable pipeline, Real Deep Research (RDR), to systematically analyze any research area, identifying emerging trends, cross-domain opportunities, and concrete starting points, demonstrated in AI/robotics with extensions to other sciences.", "motivation": "Researchers struggle to stay up-to-date amid explosive growth (e.g., 10k papers/year), rapid trend shifts, and increasing interdisciplinarity. A scalable, generalizable synthesis framework is needed.", "method": "Introduce RDR, a comprehensive pipeline for analyzing research areas. Apply it to AI and robotics, emphasizing foundation models and robotics advancements. The main paper describes the construction of the pipeline; the appendix presents extensive results across topics; extension to other sciences.", "result": "Proposes and demonstrates the RDR pipeline; provides results across analyzed topics (via appendix) and shows the ability to identify trends and cross-domain opportunities; provides concrete starting points for new inquiry.", "conclusion": "RDR is a generalizable, practical framework to help researchers navigate large literatures and discover interdisciplinary opportunities; applicable beyond AI/robotics to other scientific domains."}}
{"id": "2510.20219", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20219", "abs": "https://arxiv.org/abs/2510.20219", "authors": ["Ke Xing", "Yanjie Dong", "Xiaoyi Fan", "Runhao Zeng", "Victor C. M. Leung", "M. Jamal Deen", "Xiping Hu"], "title": "CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks", "comment": null, "summary": "Personalized federated learning (PFL) addresses a critical challenge of\ncollaboratively training customized models for clients with heterogeneous and\nscarce local data. Conventional federated learning, which relies on a single\nconsensus model, proves inadequate under such data heterogeneity. Its standard\naggregation method of weighting client updates heuristically or by data volume,\noperates under an equal-contribution assumption, failing to account for the\nactual utility and reliability of each client's update. This often results in\nsuboptimal personalization and aggregation bias. To overcome these limitations,\nwe introduce Contribution-Oriented PFL (CO-PFL), a novel algorithm that\ndynamically estimates each client's contribution for global aggregation. CO-PFL\nperforms a joint assessment by analyzing both gradient direction discrepancies\nand prediction deviations, leveraging information from gradient and data\nsubspaces. This dual-subspace analysis provides a principled and discriminative\naggregation weight for each client, emphasizing high-quality updates.\nFurthermore, to bolster personalization adaptability and optimization\nstability, CO-PFL cohesively integrates a parameter-wise personalization\nmechanism with mask-aware momentum optimization. Our approach effectively\nmitigates aggregation bias, strengthens global coordination, and enhances local\nperformance by facilitating the construction of tailored submodels with stable\nupdates. Extensive experiments on four benchmark datasets (CIFAR10, CIFAR10C,\nCINIC10, and Mini-ImageNet) confirm that CO-PFL consistently surpasses\nstate-of-the-art methods in in personalization accuracy, robustness,\nscalability and convergence stability.", "AI": {"tldr": "CO-PFL introduces Contribution-Oriented Federated Learning that dynamically weights client updates by estimated contribution using gradient and data subspaces, with parameter-wise personalization and mask-aware momentum, improving personalization accuracy, robustness, scalability, and convergence on benchmarks.", "motivation": "Address heterogeneity and data scarcity in federated learning. Traditional global aggregation assumes equal contribution and often weights by data volume, leading to suboptimal personalization and aggregation bias.", "method": "CO-PFL jointly assesses client contribution by analyzing gradient direction discrepancies and prediction deviations, leveraging gradient and data subspaces to compute discriminative aggregation weights. It also integrates parameter-wise personalization with mask-aware momentum optimization to adapt submodels and stabilize updates.", "result": "Empirical evaluation on CIFAR10, CIFAR10C, CINIC10, and Mini-ImageNet shows that CO-PFL consistently outperforms state-of-the-art methods in personalization accuracy, robustness, scalability, and convergence stability.", "conclusion": "CO-PFL mitigates aggregation bias, strengthens global coordination, and enhances local performance by enabling tailored submodels with stable updates under heterogeneous data distributions."}}
{"id": "2510.20285", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.20285", "abs": "https://arxiv.org/abs/2510.20285", "authors": ["Jiayi Zou", "Chaofan Chen", "Bing-Kun Bao", "Changsheng Xu"], "title": "DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering", "comment": null, "summary": "Egocentric Video Question Answering (Egocentric VideoQA) plays an important\nrole in egocentric video understanding, which refers to answering questions\nbased on first-person videos. Although existing methods have made progress\nthrough the paradigm of pre-training and fine-tuning, they ignore the unique\nchallenges posed by the first-person perspective, such as understanding\nmultiple events and recognizing hand-object interactions. To deal with these\nchallenges, we propose a Dual-Modal Counterfactual Contrastive Construction\n(DMC$^3$) framework, which contains an egocentric videoqa baseline, a\ncounterfactual sample construction module and a counterfactual sample-involved\ncontrastive optimization. Specifically, We first develop a counterfactual\nsample construction module to generate positive and negative samples for\ntextual and visual modalities through event description paraphrasing and core\ninteraction mining, respectively. Then, We feed these samples together with the\noriginal samples into the baseline. Finally, in the counterfactual\nsample-involved contrastive optimization module, we apply contrastive loss to\nminimize the distance between the original sample features and the positive\nsample features, while maximizing the distance from the negative samples.\nExperiments show that our method achieve 52.51\\% and 46.04\\% on the\n\\textit{normal} and \\textit{indirect} splits of EgoTaskQA, and 13.2\\% on\nQAEGO4D, both reaching the state-of-the-art performance.", "AI": {"tldr": "Proposes DMC^3 framework for egocentric video QA leveraging counterfactual contrastive learning to address hand-object interactions and multi-event understanding, achieving state-of-the-art results on EgoTaskQA and QAEGO4D.", "motivation": "First-person perspective introduces unique challenges: simultaneous events, hand-object interactions, and camera-viewpoint biases, which existing pre-training/fine-tuning approaches may not adequately address.", "method": "Introduce Dual-Modal Counterfactual Construction (DMC^3) consisting of: (1) counterfactual sample construction generating positive/negative samples via event description paraphrasing and core interaction mining; (2) feeding these samples with the original into a baseline egocentric video QA model; (3) counterfactual sample-involved contrastive optimization using a contrastive loss to align original and positive samples while separating negatives.", "result": "Reported results: 52.51% (normal) and 46.04% (indirect) on EgoTaskQA, and 13.2% on QAEGO4D, reported as state-of-the-art.", "conclusion": "The DMC^3 framework effectively leverages counterfactual samples and contrastive learning to address the unique challenges of egocentric video QA, improving performance on standard benchmarks."}}
{"id": "2402.01555", "categories": ["cs.CV", "cs.AI", "cs.HC", "eess.IV"], "pdf": "https://arxiv.org/pdf/2402.01555", "abs": "https://arxiv.org/abs/2402.01555", "authors": ["Samuel Adebayo", "Joost C. Dessing", "Se\u00e1n McLoone"], "title": "SLYKLatent: A Learning Framework for Gaze Estimation Using Deep Facial Feature Learning", "comment": null, "summary": "In this research, we present SLYKLatent, a novel approach for enhancing gaze\nestimation by addressing appearance instability challenges in datasets due to\naleatoric uncertainties, covariant shifts, and test domain generalization.\nSLYKLatent utilizes Self-Supervised Learning for initial training with facial\nexpression datasets, followed by refinement with a patch-based tri-branch\nnetwork and an inverse explained variance-weighted training loss function. Our\nevaluation on benchmark datasets achieves a 10.9% improvement on Gaze360,\nsupersedes top MPIIFaceGaze results with 3.8%, and leads on a subset of\nETH-XGaze by 11.6%, surpassing existing methods by significant margins.\nAdaptability tests on RAF-DB and Affectnet show 86.4% and 60.9% accuracies,\nrespectively. Ablation studies confirm the effectiveness of SLYKLatent's novel\ncomponents.", "AI": {"tldr": "SLYKLatent improves gaze estimation robustness to appearance instability via self-supervised pretraining and a patch-based tri-branch architecture with an inverse explained variance loss, achieving state-of-the-art or strong results across Gaze360, MPIIFaceGaze, and ETH-XGaze, and demonstrating solid adaptability to RAF-DB and AffectNet.", "motivation": "Gaze estimation suffers from appearance instability due to aleatoric uncertainties, covariate shifts, and varying test domains. Existing methods struggle with cross-dataset generalization and robustness to distributional changes.", "method": "A two-stage approach: (1) self-supervised pretraining on facial expression datasets to learn robust latent representations; (2) refinement using a patch-based tri-branch network, combined with an inverse explained variance-weighted training loss to emphasize uncertain or harder samples and integrate uncertainty into optimization.", "result": "On Gaze360, 10.9% absolute improvement; surpasses top MPIIFaceGaze results by 3.8%; improves ETH-XGaze subset performance by 11.6%. Adaptability tests yield 86.4% accuracy on RAF-DB and 60.9% on AffectNet. Ablation studies corroborate the contribution of each component.", "conclusion": "SLYKLatent effectively mitigates appearance instability in gaze estimation, delivering strong cross-dataset generalization and robustness while validating the novel components through ablations."}}
{"id": "2510.20220", "categories": ["cs.LG", "cs.NA", "math.NA", "G.1"], "pdf": "https://arxiv.org/pdf/2510.20220", "abs": "https://arxiv.org/abs/2510.20220", "authors": ["Iv\u00e1n Ojeda-Ruiz", "Young Ju-Lee", "Malcolm Dickens", "Leonardo Cambisaca"], "title": "Alternatives to the Laplacian for Scalable Spectral Clustering with Group Fairness Constraints", "comment": null, "summary": "Recent research has focused on mitigating algorithmic bias in clustering by\nincorporating fairness constraints into algorithmic design. Notions such as\ndisparate impact, community cohesion, and cost per population have been\nimplemented to enforce equitable outcomes. Among these, group fairness\n(balance) ensures that each protected group is proportionally represented\nwithin every cluster. However, incorporating balance as a metric of fairness\ninto spectral clustering algorithms has led to computational times that can be\nimproved. This study aims to enhance the efficiency of spectral clustering\nalgorithms by reformulating the constrained optimization problem using a new\nformulation derived from the Lagrangian method and the\nSherman-Morrison-Woodbury (SMW) identity, resulting in the Fair-SMW algorithm.\nFair-SMW employs three alternatives to the Laplacian matrix with different\nspectral gaps to generate multiple variations of Fair-SMW, achieving clustering\nsolutions with comparable balance to existing algorithms while offering\nimproved runtime performance. We present the results of Fair-SMW, evaluated\nusing the Stochastic Block Model (SBM) to measure both runtime efficiency and\nbalance across real-world network datasets, including LastFM, FacebookNet,\nDeezer, and German. We achieve an improvement in computation time that is twice\nas fast as the state-of-the-art, and also flexible enough to achieve twice as\nmuch balance.", "AI": {"tldr": "Fair-SMW: a faster spectral clustering method that enforces group fairness (balance) via a Lagrangian reformulation and Sherman-Morrison-Woodbury; explores three Laplacian variants for spectral gaps; shows ~2x speedup and potential for ~2x more balance on real networks.", "motivation": "To reduce the computational burden of enforcing group fairness constraints in spectral clustering, specifically balance, while maintaining competitive balance and solution quality.", "method": "Reformulates the constrained optimization using a Lagrangian framework and the Sherman-Morrison-Woodbury identity. Introduces Fair-SMW with three Laplacian variants (different spectral gaps) to generate multiple solutions. Evaluates on SBM for runtime and balance; tests on real networks (LastFM, FacebookNet, Deezer, German).", "result": "Fair-SMW achieves approximately 2x faster runtimes than state-of-the-art methods and can obtain up to 2x greater balance on the tested datasets; maintains balance comparable to existing algorithms.", "conclusion": "Fair-SMW offers an efficient, flexible approach to fairness-aware spectral clustering, delivering strong balance performance with significant runtime gains, validating the utility of SMW-based reformulations for constrained clustering."}}
{"id": "2510.20286", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20286", "abs": "https://arxiv.org/abs/2510.20286", "authors": ["Liangyu Chen", "Hanzhang Zhou", "Chenglin Cai", "Jianan Zhang", "Panrong Tong", "Quyu Kong", "Xu Zhang", "Chen Liu", "Yuqi Liu", "Wenxuan Wang", "Yue Wang", "Qin Jin", "Steven Hoi"], "title": "UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning", "comment": null, "summary": "GUI grounding, which maps natural-language instructions to actionable UI\nelements, is a core capability of GUI agents. Prior works largely treats\ninstructions as a static proxy for user intent, overlooking the impact of\ninstruction diversity and quality on grounding performance. Through a careful\ninvestigation of existing grounding datasets, we find a 23.3% flaw rate in\ntheir instructions and show that inference-time exploitation of instruction\ndiversity yields up to a substantial 76% relative performance improvement. In\nthis paper, we introduce the Instruction-as-Reasoning paradigm, treating\ninstructions as dynamic analytical pathways that offer distinct perspectives\nand enabling the model to select the most effective pathway during reasoning.\nTo achieve this, we propose a two-stage training framework: supervised\nfine-tuning (SFT) on synthesized, diverse instructions to instill\nmulti-perspective reasoning, followed by reinforcement learning (RL) to\noptimize pathway selection and composition. Our resulting models, UI-Ins-7B and\nUI-Ins-32B, achieve state-of-the-art results on five challenging grounding\nbenchmarks and exhibit emergent reasoning, selectively composing and\nsynthesizing novel instruction pathways at inference. In particular, UI-Ins-32B\nattains the best grounding accuracy, scoring 87.3% on UI-I2E-Bench, 57.0% on\nScreenSpot-Pro, and 84.9% on MMBench-GUI L2. Furthermore, our model\ndemonstrates strong agentic potential, achieving a 74.1% success rate on\nAndroidWorld using UI-Ins-7B as the executor. Our in-depth analysis reveals\nadditional insights such as how reasoning can be formulated to enhance rather\nthan hinder grounding performance, and how our method mitigates policy collapse\nin the SFT+RL framework. All code and model checkpoints will be publicly\nreleased in https://github.com/alibaba/UI-Ins.", "AI": {"tldr": "Instruction-as-Reasoning treats GUI instructions as dynamic reasoning pathways to improve grounding via SFT+RL, achieving state-of-the-art results across multiple benchmarks with emergent reasoning.", "motivation": "Instruction diversity and quality affect GUI grounding performance. Prior work treats instructions as static proxies for user intent, overlooking diversity and instruction flaws.", "method": "Two-stage training: (1) supervised fine-tuning on synthesized, diverse instructions to instill multi-perspective reasoning; (2) reinforcement learning to optimize pathway selection and composition. Evaluation on UI grounding benchmarks using UI-Ins-7B and UI-Ins-32B.", "result": "State-of-the-art on five grounding benchmarks. UI-Ins-32B: 87.3% on UI-I2E-Bench, 57.0% on ScreenSpot-Pro, 84.9% on MMBench-GUI L2; AndroidWorld 74.1% success with UI-Ins-7B as executor; emergent reasoning and selective pathway composition; mitigates policy collapse; code released.", "conclusion": "Instruction-as-Reasoning can enhance GUI grounding by leveraging diverse instructions and dynamic reasoning pathways, achieving strong performance and agentic potential; future work includes deeper analysis of reasoning pathways and scalability."}}
{"id": "2510.20222", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20222", "abs": "https://arxiv.org/abs/2510.20222", "authors": ["Hao Wang", "Baojun Ma"], "title": "QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models", "comment": "10 pages, 5 figures", "summary": "In real-world time series forecasting tasks, category information plays a\npivotal role in capturing inherent data patterns. This paper introduces QKCV\n(Query-Key-Category-Value) attention, an extension of the traditional QKV\nframework that incorporates a static categorical embedding C to emphasize\ncategory-specific information. As a versatile plug-in module, QKCV enhances the\nforecasting accuracy of attention-based models (e.g., Vanilla Transformer,\nInformer, PatchTST, TFT) across diverse real-world datasets. Furthermore, QKCV\ndemonstrates remarkable adaptability in fine-tuning univariate time series\nfoundation model by solely updating the static embedding C while preserving\npretrained weights, thereby reducing computational overhead and achieving\nsuperior fine-tuning performance.", "AI": {"tldr": "Extends QKV attention with a static categorical embedding C (QKCV) to encode category-specific information, boosting forecasting accuracy across attention-based TS models and enabling efficient fine-tuning by updating only C while keeping pretrained weights.", "motivation": "Real-world time series display strong category patterns; standard QKV attention may ignore category-specific signals. A lightweight, plug-in embedding that injects category information could improve accuracy and enable resource-efficient fine-tuning.", "method": "Introduce a QKCV module that augments QKV attention with a static category embedding C. Treat it as a plug-in compatible with Vanilla Transformer, Informer, PatchTST, TFT. Demonstrate that, during fine-tuning, updating only C (keeping pretrained weights) yields better performance with reduced compute.", "result": "QKCV improves forecasting accuracy across diverse real-world datasets and model families. It also enables effective univariate TS foundation model fine-tuning by updating only the static embedding, reducing computational overhead while achieving superior performance.", "conclusion": "QKCV is a versatile, effective plug-in for attention-based time series forecasting that leverages category information to enhance accuracy and enable efficient fine-tuning."}}
{"id": "2510.20287", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20287", "abs": "https://arxiv.org/abs/2510.20287", "authors": ["Sauptik Dhar", "Naveen Ramakrishnan", "Michelle Munson"], "title": "Breakdance Video classification in the age of Generative AI", "comment": "11 pages", "summary": "Large Vision Language models have seen huge application in several sports\nuse-cases recently. Most of these works have been targeted towards a limited\nsubset of popular sports like soccer, cricket, basketball etc; focusing on\ngenerative tasks like visual question answering, highlight generation. This\nwork analyzes the applicability of the modern video foundation models (both\nencoder and decoder) for a very niche but hugely popular dance sports -\nbreakdance. Our results show that Video Encoder models continue to outperform\nstate-of-the-art Video Language Models for prediction tasks. We provide\ninsights on how to choose the encoder model and provide a thorough analysis\ninto the workings of a finetuned decoder model for breakdance video\nclassification.", "AI": {"tldr": "Video encoder models outperform state-of-the-art video-language models on breakdance prediction tasks; the work also analyzes a finetuned decoder for breakdance classification and offers guidance on encoder selection.", "motivation": "To explore the applicability of modern video foundation models to a niche but popular sport (breakdance), addressing the gap beyond common sports and generative tasks, and to understand when encoder vs. decoder approaches are advantageous.", "method": "Empirical evaluation comparing video encoder models and video-language models (including decoder-based approaches) on breakdance prediction tasks; analysis of a finetuned decoder model for breakdance video classification; provision of practical insights on selecting an encoder.", "result": "Video encoder models consistently outperform state-of-the-art video-language models for prediction tasks in breakdance videos; the study provides guidance on choosing an encoder and presents a thorough analysis of a finetuned decoder for breakdance classification.", "conclusion": "For breakdance video analysis, encoder-based approaches are superior for prediction; practitioners should prioritize encoder models and rely on the provided insights for encoder selection, while the decoder finetuning analysis sheds light on classification dynamics."}}
{"id": "2510.20225", "categories": ["cs.LG", "cs.AI", "68T07 (Artificial neural networks and deep learning), 62F15\n  (Bayesian inference)"], "pdf": "https://arxiv.org/pdf/2510.20225", "abs": "https://arxiv.org/abs/2510.20225", "authors": ["Insu Jeon", "Minui Hong", "Junhyeog Yun", "Gunhee Kim"], "title": "Federated Learning via Meta-Variational Dropout", "comment": "Published in the Proceedings of the Advances in Neural Information\n  Processing Systems (NeurIPS) 2023, Main Conference Track", "summary": "Federated Learning (FL) aims to train a global inference model from remotely\ndistributed clients, gaining popularity due to its benefit of improving data\nprivacy. However, traditional FL often faces challenges in practical\napplications, including model overfitting and divergent local models due to\nlimited and non-IID data among clients. To address these issues, we introduce a\nnovel Bayesian meta-learning approach called meta-variational dropout (MetaVD).\nMetaVD learns to predict client-dependent dropout rates via a shared\nhypernetwork, enabling effective model personalization of FL algorithms in\nlimited non-IID data settings. We also emphasize the posterior adaptation view\nof meta-learning and the posterior aggregation view of Bayesian FL via the\nconditional dropout posterior. We conducted extensive experiments on various\nsparse and non-IID FL datasets. MetaVD demonstrated excellent classification\naccuracy and uncertainty calibration performance, especially for\nout-of-distribution (OOD) clients. MetaVD compresses the local model parameters\nneeded for each client, mitigating model overfitting and reducing communication\ncosts. Code is available at https://github.com/insujeon/MetaVD.", "AI": {"tldr": "MetaVD is a Bayesian meta-learning approach for Federated Learning that uses a shared hypernetwork to predict client-specific dropout rates (meta-variational dropout), enabling personalized models in limited, non-IID data settings; it improves accuracy and uncertainty calibration (especially for OOD clients) while compressing local parameters to reduce overfitting and communication costs.", "motivation": "Federated Learning models suffer from overfitting and divergent local models when client data are limited and non-IID. There is a need for personalizing models to each client and for reliable uncertainty estimates, while also reducing communication overhead.", "method": "Meta-variational dropout (MetaVD) uses a shared hypernetwork to predict client-dependent dropout rates. This enables per-client personalization by conditioning dropout on the client. The approach emphasizes the posterior adaptation view of meta-learning and the posterior aggregation view of Bayesian FL via the conditional dropout posterior. It also achieves parameter compression to mitigate overfitting and communication costs.", "result": "Experiments on sparse and non-IID FL datasets show MetaVD achieves excellent classification accuracy and uncertainty calibration, particularly for out-of-distribution (OOD) clients, and reduces the amount of local parameters needed per client, thereby lowering communication costs.", "conclusion": "MetaVD provides effective personalization for FL under limited non-IID data, with improved accuracy, better uncertainty calibration for OOD clients, and reduced communication overhead; a codebase is available for replication."}}
{"id": "2510.20291", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20291", "abs": "https://arxiv.org/abs/2510.20291", "authors": ["LinFeng Li", "Jian Zhao", "Zepeng Yang", "Yuhang Song", "Bojun Lin", "Tianle Zhang", "Yuchen Yuan", "Chi Zhang", "Xuelong Li"], "title": "A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization", "comment": null, "summary": "We present a winning solution to RoboSense 2025 Track 4: Cross-Modal Drone\nNavigation. The task retrieves the most relevant geo-referenced image from a\nlarge multi-platform corpus (satellite/drone/ground) given a natural-language\nquery. Two obstacles are severe inter-platform heterogeneity and a domain gap\nbetween generic training descriptions and platform-specific test queries. We\nmitigate these with a domain-aligned preprocessing pipeline and a\nMixture-of-Experts (MoE) framework: (i) platform-wise partitioning, satellite\naugmentation, and removal of orientation words; (ii) an LLM-based caption\nrefinement pipeline to align textual semantics with the distinct visual\ncharacteristics of each platform. Using BGE-M3 (text) and EVA-CLIP (image), we\ntrain three platform experts using a progressive two-stage, hard-negative\nmining strategy to enhance discriminative power, and fuse their scores at\ninference. The system tops the official leaderboard, demonstrating robust\ncross-modal geo-localization under heterogeneous viewpoints.", "AI": {"tldr": "Domain-aligned, MoE-based cross-modal geo-localization for heterogeneous multi-platform data; uses platform-wise specialization, satellite augmentation, orientation-word removal, and LLM-based caption refinement; achieves top leaderboard on RoboSense 2025 Track 4.", "motivation": "Inter-platform heterogeneity and a domain gap between generic training descriptions and platform-specific test queries hinder cross-modal geo-localization across satellite, drone, and ground imagery.", "method": "Domain-aligned preprocessing: platform-wise partitioning, satellite augmentation, removal of orientation words; LLM-based caption refinement to align textual semantics with platform visuals; train three platform experts via progressive two-stage hard-negative mining; fuse expert scores at inference; use BGE-M3 (text) and EVA-CLIP (image).", "result": "Top of the official leaderboard on RoboSense 2025 Track 4, demonstrating robust cross-modal geo-localization under heterogeneous viewpoints.", "conclusion": "A combination of domain-aligned preprocessing and Mixture-of-Experts with platform specialization can effectively mitigate cross-platform heterogeneity and domain gap for cross-modal geo-localization."}}
{"id": "2510.20228", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20228", "abs": "https://arxiv.org/abs/2510.20228", "authors": ["Yago del Valle Inclan Redondo", "Enrique Arriaga-Varela", "Dmitry Lyamzin", "Pablo Cervantes", "Tiago Ramalho"], "title": "Sparse Local Implicit Image Function for sub-km Weather Downscaling", "comment": null, "summary": "We introduce SpLIIF to generate implicit neural representations and enable\narbitrary downscaling of weather variables. We train a model from sparse\nweather stations and topography over Japan and evaluate in- and\nout-of-distribution accuracy predicting temperature and wind, comparing it to\nboth an interpolation baseline and CorrDiff. We find the model to be up to 50%\nbetter than both CorrDiff and the baseline at downscaling temperature, and\naround 10-20% better for wind.", "AI": {"tldr": "SpLIIF adopts implicit neural representations to enable arbitrary downscaling of weather fields; trained on sparse stations and topography over Japan; outperforms interpolation and CorrDiff in predicting temperature and wind, with up to ~50% gains for temperature and 10\u201320% for wind.", "motivation": "Downgridding/downscaling weather variables from sparse observations is challenging; conventional interpolation and diffusion priors (e.g., CorrDiff) struggle with out-of-distribution generalization. Implicit neural representations can model high-resolution fields conditional on arbitrary coordinates and auxiliary data (topography) to improve accuracy and generalization.", "method": "Train SpLIIF, an INR-based model, on sparse weather stations and topographic features over Japan. Evaluate both in-distribution and out-of-distribution accuracy for temperature and wind; compare against a simple interpolation baseline and CorrDiff. Allow arbitrary downscaling resolution at inference.", "result": "The model achieves up to ~50% better performance than CorrDiff and the baseline for temperature downscaling, and ~10\u201320% better performance for wind.", "conclusion": "SpLIIF demonstrates that implicit neural representations can effectively enable high-quality, arbitrarily scalable downscaling of weather variables from sparse data, with superior generalization relative to interpolation and CorrDiff, especially for temperature."}}
{"id": "2510.20322", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20322", "abs": "https://arxiv.org/abs/2510.20322", "authors": ["Zelin Peng", "Zhengqin Xu", "Qingyang Liu", "Xiaokang Yang", "Wei Shen"], "title": "HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models", "comment": "Accepted by NeurIPS2025", "summary": "Multi-modal large language models (MLLMs) have emerged as a transformative\napproach for aligning visual and textual understanding. They typically require\nextremely high computational resources (e.g., thousands of GPUs) for training\nto achieve cross-modal alignment at multi-granularity levels. We argue that a\nkey source of this inefficiency lies in the vision encoders they widely equip\nwith, e.g., CLIP and SAM, which lack the alignment with language at\nmulti-granularity levels. To address this issue, in this paper, we leverage\nhyperbolic space, which inherently models hierarchical levels and thus provides\na principled framework for bridging the granularity gap between visual and\ntextual modalities at an arbitrary granularity level. Concretely, we propose an\nefficient training paradigm for MLLMs, dubbed as HyperET, which can optimize\nvisual representations to align with their textual counterparts at an arbitrary\ngranularity level through dynamic hyperbolic radius adjustment in hyperbolic\nspace. HyperET employs learnable matrices with M\\\"{o}bius multiplication\noperations, implemented via three effective configurations: diagonal scaling\nmatrices, block-diagonal matrices, and banded matrices, providing a flexible\nyet efficient parametrization strategy. Comprehensive experiments across\nmultiple MLLM benchmarks demonstrate that HyperET consistently improves both\nexisting pre-training and fine-tuning MLLMs clearly with less than 1\\%\nadditional parameters.", "AI": {"tldr": "HyperET introduces a parameter-efficient, hyperbolic-space alignment framework to bridge the granularity gap between vision and language in multi-modal LLMs. By dynamic hyperbolic radius adjustment and M\u00f6bius-matrix parametrizations (diagonal, block-diagonal, banded), it enables cross-modal alignment at arbitrary granularity with less than 1% extra parameters, improving pre-training and fine-tuning results across benchmarks.", "motivation": "Current MLLMs require massive computational resources partly due to vision encoders (e.g., CLIP, SAM) that lack multi-granularity language alignment. Hyperbolic space, with its natural hierarchical structure, offers a principled way to align visual and textual representations across granularity levels, potentially reducing resource demands.", "method": "Propose HyperET, a training paradigm that optimizes visual representations to align with textual counterparts at arbitrary granularity via dynamic hyperbolic radius adjustment in hyperbolic space. It uses learnable M\u00f6bius-multiplication matrices with three efficient configurations: diagonal scaling, block-diagonal, and banded matrices, enabling flexible and parameter-efficient parametrization. Applicable to both pre-training and fine-tuning of MLLMs.", "result": "Experimental results across multiple MLLM benchmarks show consistent performance improvements over existing pre-training and fine-tuning approaches, with less than 1% additional parameters.", "conclusion": "HyperET demonstrates that hyperbolic geometry provides a principled and efficient mechanism to bridge granularity gaps between vision and language, enabling more efficient cross-modal alignment and potentially reducing overall computational resources required for MLLMs."}}
{"id": "2510.20235", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20235", "abs": "https://arxiv.org/abs/2510.20235", "authors": ["Woohyeon Byeon", "Giseung Park", "Jongseong Chae", "Amir Leshem", "Youngchul Sung"], "title": "Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach", "comment": "Accepted to NeurIPS 2025", "summary": "In this paper, we propose a provably convergent and practical framework for\nmulti-objective reinforcement learning with max-min criterion. From a\ngame-theoretic perspective, we reformulate max-min multi-objective\nreinforcement learning as a two-player zero-sum regularized continuous game and\nintroduce an efficient algorithm based on mirror descent. Our approach\nsimplifies the policy update while ensuring global last-iterate convergence. We\nprovide a comprehensive theoretical analysis on our algorithm, including\niteration complexity under both exact and approximate policy evaluations, as\nwell as sample complexity bounds. To further enhance performance, we modify the\nproposed algorithm with adaptive regularization. Our experiments demonstrate\nthe convergence behavior of the proposed algorithm in tabular settings, and our\nimplementation for deep reinforcement learning significantly outperforms\nprevious baselines in many MORL environments.", "AI": {"tldr": "Proposes a provably convergent, practical MORL framework for max-min objectives via a regularized two-player zero-sum game solved by mirror descent, with theoretical guarantees and adaptive regularization; demonstrates strong empirical performance.", "motivation": "Addresses the challenge of stable, convergent optimization in multi-objective RL under a max-min criterion, by casting MORL as a two-player game and providing convergence guarantees and practical algorithms.", "method": "Reformulates max-min MORL as a two-player zero-sum regularized continuous game and solves it with a mirror-descent-based algorithm. The approach yields a simple policy update, guarantees global last-iterate convergence, and includes adaptive regularization. Theoretical analysis covers iteration and sample complexity under exact/approximately evaluated policies.", "result": "The algorithm achieves global last-iterate convergence. It provides iteration and sample complexity bounds and shows that adaptive regularization enhances performance. Empirical results demonstrate convergence in tabular settings and superior performance of the deep-RL implementation over prior baselines across multiple MORL environments.", "conclusion": "The work delivers a provably convergent, practical MORL framework for max-min objectives with a simple policy update, robust theoretical guarantees, and empirical effectiveness, including benefits from adaptive regularization and scalability to deep RL."}}
{"id": "2510.20331", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20331", "abs": "https://arxiv.org/abs/2510.20331", "authors": ["Kangli Wang", "Qianxi Yi", "Yuqi Ye", "Shihao Li", "Wei Gao"], "title": "AnyPcc: Compressing Any Point Cloud with a Single Universal Model", "comment": "11 pages, 5 figures", "summary": "Generalization remains a critical challenge for deep learning-based point\ncloud geometry compression. We argue this stems from two key limitations: the\nlack of robust context models and the inefficient handling of\nout-of-distribution (OOD) data. To address both, we introduce AnyPcc, a\nuniversal point cloud compression framework. AnyPcc first employs a Universal\nContext Model that leverages priors from both spatial and channel-wise grouping\nto capture robust contextual dependencies. Second, our novel Instance-Adaptive\nFine-Tuning (IAFT) strategy tackles OOD data by synergizing explicit and\nimplicit compression paradigms. It fine-tunes a small subset of network weights\nfor each instance and incorporates them into the bitstream, where the marginal\nbit cost of the weights is dwarfed by the resulting savings in geometry\ncompression. Extensive experiments on a benchmark of 15 diverse datasets\nconfirm that AnyPcc sets a new state-of-the-art in point cloud compression. Our\ncode and datasets will be released to encourage reproducible research.", "AI": {"tldr": "AnyPcc proposes a universal point cloud compression framework that combines a Universal Context Model with Instance-Adaptive Fine-Tuning, achieving state-of-the-art generalization and compression across 15 diverse datasets, with code release planned.", "motivation": "Generalization remains difficult in DL-based point cloud geometry compression due to weak contextual modeling and poor handling of out-of-distribution data; robust context models and per-instance adaptation are needed.", "method": "Introduce a Universal Context Model leveraging priors from spatial and channel-wise grouping to capture robust dependencies, and an Instance-Adaptive Fine-Tuning (IAFT) strategy that fine-tunes a small subset of weights per instance, embedding them into the bitstream where their cost is outweighed by geometry savings.", "result": "Extensive experiments on 15 diverse datasets show state-of-the-art compression performance, validating both robust context modeling and IAFT for OOD data.", "conclusion": "AnyPcc offers improved generalization and compression efficiency; IAFT effectively handles OOD data, and the work includes a commitment to releasing code and datasets for reproducibility."}}
{"id": "2510.20236", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20236", "abs": "https://arxiv.org/abs/2510.20236", "authors": ["Teng Jiek See", "Daokun Zhang", "Mario Boley", "David K. Chalmers"], "title": "Layer-to-Layer Knowledge Mixing in Graph Neural Network for Chemical Property Prediction", "comment": null, "summary": "Graph Neural Networks (GNNs) are the currently most effective methods for\npredicting molecular properties but there remains a need for more accurate\nmodels. GNN accuracy can be improved by increasing the model complexity but\nthis also increases the computational cost and memory requirement during\ntraining and inference. In this study, we develop Layer-to-Layer Knowledge\nMixing (LKM), a novel self-knowledge distillation method that increases the\naccuracy of state-of-the-art GNNs while adding negligible computational\ncomplexity during training and inference. By minimizing the mean absolute\ndistance between pre-existing hidden embeddings of GNN layers, LKM efficiently\naggregates multi-hop and multi-scale information, enabling improved\nrepresentation of both local and global molecular features. We evaluated LKM\nusing three diverse GNN architectures (DimeNet++, MXMNet, and PAMNet) using\ndatasets of quantum chemical properties (QM9, MD17 and Chignolin). We found\nthat the LKM method effectively reduces the mean absolute error of quantum\nchemical and biophysical property predictions by up to 9.8% (QM9), 45.3% (MD17\nEnergy), and 22.9% (Chignolin). This work demonstrates the potential of LKM to\nsignificantly improve the accuracy of GNNs for chemical property prediction\nwithout any substantial increase in training and inference cost.", "AI": {"tldr": "Layer-to-Layer Knowledge Mixing (LKM) is a self-knowledge distillation approach for GNNs that aligns hidden embeddings across layers to fuse multi-hop information, boosting molecular property predictions with minimal overhead.", "motivation": "GNNs improve with larger, more complex models but incur higher training/inference costs. There is a need for more accurate chemical property predictions without substantial computational overhead.", "method": "LKM minimizes the mean absolute distance between hidden embeddings of different GNN layers (self-distillation). This encourages cross-layer information sharing and effectively aggregates multi-hop/multi-scale representations without adding significant computational cost. Evaluated on three GNN architectures (DimeNet++, MXMNet, PAMNet) and datasets (QM9, MD17, Chignolin).", "result": "LKM reduces prediction errors by up to 9.8% on QM9, 45.3% on MD17 Energy, and 22.9% on Chignolin, demonstrating significant accuracy gains with negligible increases in training and inference cost.", "conclusion": "LKM is a practical and effective self-knowledge distillation method for GNNs in chemical property prediction, improving accuracy without substantially increasing computation or memory requirements."}}
{"id": "2510.20348", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20348", "abs": "https://arxiv.org/abs/2510.20348", "authors": ["Seunghoon Lee", "Jeongwoo Choi", "Byunggwan Son", "Jaehyeon Moon", "Jeimin Jeon", "Bumsub Ham"], "title": "AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models", "comment": "Accepted to NeurIPS 2025", "summary": "We present in this paper a novel post-training quantization (PTQ) method,\ndubbed AccuQuant, for diffusion models. We show analytically and empirically\nthat quantization errors for diffusion models are accumulated over denoising\nsteps in a sampling process. To alleviate the error accumulation problem,\nAccuQuant minimizes the discrepancies between outputs of a full-precision\ndiffusion model and its quantized version within a couple of denoising steps.\nThat is, it simulates multiple denoising steps of a diffusion sampling process\nexplicitly for quantization, accounting the accumulated errors over multiple\ndenoising steps, which is in contrast to previous approaches to imitating a\ntraining process of diffusion models, namely, minimizing the discrepancies\nindependently for each step. We also present an efficient implementation\ntechnique for AccuQuant, together with a novel objective, which reduces a\nmemory complexity significantly from $\\mathcal{O}(n)$ to $\\mathcal{O}(1)$,\nwhere $n$ is the number of denoising steps. We demonstrate the efficacy and\nefficiency of AccuQuant across various tasks and diffusion models on standard\nbenchmarks.", "AI": {"tldr": "A post-training quantization method, AccuQuant, for diffusion models that accounts for accumulated quantization errors across denoising steps, improves accuracy while reducing memory from O(n) to O(1), and shows strong performance on standard benchmarks.", "motivation": "Quantization errors in diffusion models accumulate during the sampling process, making naive PTQ approaches ineffective. There is a need for a PTQ method that explicitly accounts for step-by-step error propagation and that is memory-efficient.", "method": "AccuQuant minimizes the discrepancy between the outputs of a full-precision diffusion model and its quantized version over a short sequence of denoising steps, effectively simulating multiple steps during quantization. It contrasts with prior work that mimics training by minimizing per-step discrepancies independently. The authors also introduce an efficient implementation and a novel objective that reduces memory complexity from O(n) to O(1) with respect to the number of denoising steps.", "result": "Empirical and analytical results show that quantization errors accumulate over denoising steps and that AccuQuant effectively mitigates this accumulation. The method demonstrates improved efficiency (memory) and strong performance across diffusion models and standard benchmarks.", "conclusion": "AccuQuant provides a memory-efficient PTQ approach for diffusion models that explicitly accounts for error accumulation across denoising steps, achieving strong empirical results on standard benchmarks and enabling more practical deployment of quantized diffusion models."}}
{"id": "2510.20242", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.20242", "abs": "https://arxiv.org/abs/2510.20242", "authors": ["Stephan Rabanser", "Nicolas Papernot"], "title": "What Does It Take to Build a Performant Selective Classifier?", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "Selective classifiers improve model reliability by abstaining on inputs the\nmodel deems uncertain. However, few practical approaches achieve the\ngold-standard performance of a perfect-ordering oracle that accepts examples\nexactly in order of correctness. Our work formalizes this shortfall as the\nselective-classification gap and present the first finite-sample decomposition\nof this gap to five distinct sources of looseness: Bayes noise, approximation\nerror, ranking error, statistical noise, and implementation- or shift-induced\nslack. Crucially, our analysis reveals that monotone post-hoc calibration --\noften believed to strengthen selective classifiers -- has limited impact on\nclosing this gap, since it rarely alters the model's underlying score ranking.\nBridging the gap therefore requires scoring mechanisms that can effectively\nreorder predictions rather than merely rescale them. We validate our\ndecomposition on synthetic two-moons data and on real-world vision and language\nbenchmarks, isolating each error component through controlled experiments. Our\nresults confirm that (i) Bayes noise and limited model capacity can account for\nsubstantial gaps, (ii) only richer, feature-aware calibrators meaningfully\nimprove score ordering, and (iii) data shift introduces a separate slack that\ndemands distributionally robust training. Together, our decomposition yields a\nquantitative error budget as well as actionable design guidelines that\npractitioners can use to build selective classifiers which approximate ideal\noracle behavior more closely.", "AI": {"tldr": "The paper defines the selective-classification gap, decomposes it into five sources (Bayes noise, approximation error, ranking error, statistical noise, and shift-induced slack), and shows that scoring/ranking quality\u2014not simple calibration\u2014drives performance toward an ideal oracle. It validates with synthetic and real data and provides practical guidelines to improve score ordering and robustness.", "motivation": "To understand why selective classifiers fall short of a perfect-ordering oracle and to quantify the sources of error, enabling targeted improvements and principled design of abstention mechanisms.", "method": "Finite-sample decomposition of the gap into five components; theoretical framing of Bayes noise, approximation error, ranking error, statistical noise, and shift-induced slack; analysis of monotone post-hoc calibration; controlled experiments on synthetic (two-moons) and real-world vision/lang benchmarks to isolate each component.", "result": "Findings show that Bayes noise and limited model capacity explain substantial portions of the gap; monotone calibration rarely improves score ordering; richer, feature-aware calibrators that reorder predictions meaningfully reduce the gap; data shift introduces a separate slack requiring distributionally robust training; the work provides a quantitative error budget and actionable design guidelines.", "conclusion": "Bringing selective classifiers closer to ideal oracle behavior requires scoring mechanisms that can effectively reorder predictions rather than only rescale them, along with robust training strategies to handle data shift. The decomposition offers actionable guidance for practitioners to design more reliable abstention-based systems."}}
{"id": "2510.20385", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20385", "abs": "https://arxiv.org/abs/2510.20385", "authors": ["Yunpeng Bai", "Haoxiang Li", "Qixing Huang"], "title": "Positional Encoding Field", "comment": "8 pages, 9 figures", "summary": "Diffusion Transformers (DiTs) have emerged as the dominant architecture for\nvisual generation, powering state-of-the-art image and video models. By\nrepresenting images as patch tokens with positional encodings (PEs), DiTs\ncombine Transformer scalability with spatial and temporal inductive biases. In\nthis work, we revisit how DiTs organize visual content and discover that patch\ntokens exhibit a surprising degree of independence: even when PEs are\nperturbed, DiTs still produce globally coherent outputs, indicating that\nspatial coherence is primarily governed by PEs. Motivated by this finding, we\nintroduce the Positional Encoding Field (PE-Field), which extends positional\nencodings from the 2D plane to a structured 3D field. PE-Field incorporates\ndepth-aware encodings for volumetric reasoning and hierarchical encodings for\nfine-grained sub-patch control, enabling DiTs to model geometry directly in 3D\nspace. Our PE-Field-augmented DiT achieves state-of-the-art performance on\nsingle-image novel view synthesis and generalizes to controllable spatial image\nediting.", "AI": {"tldr": "PE-Field extends positional encodings into a 3D field for diffusion transformers, showing that spatial coherence in DiTs is largely driven by PEs. This enables 3D geometry modeling and improves novel view synthesis and controllable editing, achieving state-of-the-art results.", "motivation": "Address the observation that 2D patch tokens in diffusion transformers lose coherence when PEs are perturbed, suggesting that PEs govern spatial structure. Extend this idea to 3D to enable volumetric reasoning and fine-grained control in DiTs for improved 3D-aware generation and editing.", "method": "1) Empirically analyze patch token independence under perturbations to PEs in DiTs. 2) Propose PE-Field, a 3D extension of positional encodings with depth-aware encodings for volumetric reasoning and hierarchical encodings for sub-patch control. 3) Integrate PE-Field into DiTs and evaluate on single-image novel view synthesis and spatial image editing tasks.", "result": "PE-Field-augmented DiTs achieve state-of-the-art performance on single-image novel view synthesis and demonstrate controllable spatial image editing, validating the effectiveness of 3D geometric encoding in diffusion transformers.", "conclusion": "Extending positional encodings to a structured 3D field enables explicit 3D geometry modeling in diffusion transformers, improving 3D-aware generation and editing while confirming that PEs play a central role in enforcing spatial coherence."}}
{"id": "2510.20250", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20250", "abs": "https://arxiv.org/abs/2510.20250", "authors": ["Zhiqin Yang", "Yonggang Zhang", "Chenxin Li", "Yiu-ming Cheung", "Bo Han", "Yixuan Yuan"], "title": "FedGPS: Statistical Rectification Against Data Heterogeneity in Federated Learning", "comment": "35 pages, 15 figures, 21 tables", "summary": "Federated Learning (FL) confronts a significant challenge known as data\nheterogeneity, which impairs model performance and convergence. Existing\nmethods have made notable progress in addressing this issue. However, improving\nperformance in certain heterogeneity scenarios remains an overlooked question:\n\\textit{How robust are these methods to deploy under diverse heterogeneity\nscenarios?} To answer this, we conduct comprehensive evaluations across varied\nheterogeneity scenarios, showing that most existing methods exhibit limited\nrobustness. Meanwhile, insights from these experiments highlight that sharing\nstatistical information can mitigate heterogeneity by enabling clients to\nupdate with a global perspective. Motivated by this, we propose \\textbf{FedGPS}\n(\\textbf{Fed}erated \\textbf{G}oal-\\textbf{P}ath \\textbf{S}ynergy), a novel\nframework that seamlessly integrates statistical distribution and gradient\ninformation from others. Specifically, FedGPS statically modifies each client's\nlearning objective to implicitly model the global data distribution using\nsurrogate information, while dynamically adjusting local update directions with\ngradient information from other clients at each round. Extensive experiments\nshow that FedGPS outperforms state-of-the-art methods across diverse\nheterogeneity scenarios, validating its effectiveness and robustness. The code\nis available at: https://github.com/CUHK-AIM-Group/FedGPS.", "AI": {"tldr": "FedGPS improves robustness to data heterogeneity in federated learning by integrating global distribution surrogate information and cross-client gradients; it outperforms state-of-the-art methods across heterogeneous scenarios and is open-sourced.", "motivation": "Data heterogeneity hurts FL performance and convergence; existing methods often lack robustness across diverse heterogeneity settings; leveraging shared statistical information can help align client updates with a global perspective.", "method": "FedGPS statically modifies each client's objective to implicitly model the global data distribution using surrogate information, and dynamically adjusts local update directions with gradient information from other clients at each round.", "result": "Extensive experiments show FedGPS consistently outperforms state-of-the-art methods across diverse heterogeneity scenarios, demonstrating effectiveness and robustness.", "conclusion": "FedGPS is an effective and robust framework for FL under data heterogeneity; code is available at the provided GitHub URL."}}
{"id": "2510.20393", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.20393", "abs": "https://arxiv.org/abs/2510.20393", "authors": ["Qing Wang", "Chong-Wah Ngo", "Yu Cao", "Ee-Peng Lim"], "title": "Mitigating Cross-modal Representation Bias for Multicultural Image-to-Recipe Retrieval", "comment": "ACM Multimedia 2025", "summary": "Existing approaches for image-to-recipe retrieval have the implicit\nassumption that a food image can fully capture the details textually documented\nin its recipe. However, a food image only reflects the visual outcome of a\ncooked dish and not the underlying cooking process. Consequently, learning\ncross-modal representations to bridge the modality gap between images and\nrecipes tends to ignore subtle, recipe-specific details that are not visually\napparent but are crucial for recipe retrieval. Specifically, the\nrepresentations are biased to capture the dominant visual elements, resulting\nin difficulty in ranking similar recipes with subtle differences in use of\ningredients and cooking methods. The bias in representation learning is\nexpected to be more severe when the training data is mixed of images and\nrecipes sourced from different cuisines. This paper proposes a novel causal\napproach that predicts the culinary elements potentially overlooked in images,\nwhile explicitly injecting these elements into cross-modal representation\nlearning to mitigate biases. Experiments are conducted on the standard\nmonolingual Recipe1M dataset and a newly curated multilingual multicultural\ncuisine dataset. The results indicate that the proposed causal representation\nlearning is capable of uncovering subtle ingredients and cooking actions and\nachieves impressive retrieval performance on both monolingual and multilingual\nmulticultural datasets.", "AI": {"tldr": "Proposes a causal representation learning framework that predicts and injects overlooked culinary elements into image\u2013recipe representations, improving cross-modal retrieval on mono- and multilingual multicultural datasets.", "motivation": "Images capture visuals but miss cooking processes and subtle recipe details; cross-modal representations are biased toward dominant visuals, especially when data mixes cuisines; need to reveal and utilize recipe-specific elements for better retrieval.", "method": "Introduce a causal approach that predicts culinary elements unseen in images and explicitly injects these elements into cross-modal learning to reduce bias.", "result": "Experiments on Recipe1M and a newly curated multilingual multicultural cuisine dataset show the method uncovers subtle ingredients and cooking actions and achieves strong retrieval performance across monolingual and multilingual settings.", "conclusion": "Causal representation learning helps recover latent recipe details, mitigates modality bias, and enhances image-to-recipe retrieval across diverse cuisines."}}
{"id": "2510.20264", "categories": ["cs.LG", "I.2.6; I.2.8; I.2.9"], "pdf": "https://arxiv.org/pdf/2510.20264", "abs": "https://arxiv.org/abs/2510.20264", "authors": ["Thomas Rupf", "Marco Bagatella", "Marin Vlastelica", "Andreas Krause"], "title": "Optimistic Task Inference for Behavior Foundation Models", "comment": null, "summary": "Behavior Foundation Models (BFMs) are capable of retrieving high-performing\npolicy for any reward function specified directly at test-time, commonly\nreferred to as zero-shot reinforcement learning (RL). While this is a very\nefficient process in terms of compute, it can be less so in terms of data: as a\nstandard assumption, BFMs require computing rewards over a non-negligible\ninference dataset, assuming either access to a functional form of rewards, or\nsignificant labeling efforts. To alleviate these limitations, we tackle the\nproblem of task inference purely through interaction with the environment at\ntest-time. We propose OpTI-BFM, an optimistic decision criterion that directly\nmodels uncertainty over reward functions and guides BFMs in data collection for\ntask inference. Formally, we provide a regret bound for well-trained BFMs\nthrough a direct connection to upper-confidence algorithms for linear bandits.\nEmpirically, we evaluate OpTI-BFM on established zero-shot benchmarks, and\nobserve that it enables successor-features-based BFMs to identify and optimize\nan unseen reward function in a handful of episodes with minimal compute\noverhead. Code is available at https://github.com/ThomasRupf/opti-bfm.", "AI": {"tldr": "OpTI-BFM introduces an optimistic data-collection criterion that models uncertainty over reward functions to guide task inference for Behavior Foundation Models (BFMs). It provides a regret bound linking to linear bandits and shows empirically that few episodes with minimal compute suffice to identify and optimize unseen rewards; code available.", "motivation": "BFMs excel at zero-shot policy retrieval but typically require non-negligible reward evaluations or labeled data to infer tasks. This work aims to reduce data requirements by enabling task inference through test-time interaction, making BFMs more data-efficient in practice.", "method": "Introduce OpTI-BFM, an optimistic decision criterion that models uncertainty over reward functions and uses it to guide environment data collection during task inference. The authors connect the method to upper-confidence bounds for linear bandits, derive a regret bound for well-trained BFMs, and apply the approach to successor-features-based BFMs to collect informative data with minimal compute.", "result": "Empirical evaluation on standard zero-shot RL benchmarks shows that OpTI-BFM enables successor-features-based BFMs to identify and optimize unseen reward functions within a handful of episodes, with minimal compute overhead. Code is released at the provided GitHub link.", "conclusion": "OpTI-BFM offers a theoretically grounded and practically efficient solution for test-time task inference in BFMs, reducing data requirements while preserving or enhancing zero-shot RL performance."}}
{"id": "2510.20438", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20438", "abs": "https://arxiv.org/abs/2510.20438", "authors": ["Saif Ur Rehman Khan", "Muhammad Nabeel Asim", "Sebastian Vollmer", "Andreas Dengel"], "title": "Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment", "comment": null, "summary": "This paper presents the FuzzyDistillViT-MobileNet model, a novel approach for\nlung cancer (LC) classification, leveraging dynamic fuzzy logic-driven\nknowledge distillation (KD) to address uncertainty and complexity in disease\ndiagnosis. Unlike traditional models that rely on static KD with fixed weights,\nour method dynamically adjusts the distillation weight using fuzzy logic,\nenabling the student model to focus on high-confidence regions while reducing\nattention to ambiguous areas. This dynamic adjustment improves the model\nability to handle varying uncertainty levels across different regions of LC\nimages. We employ the Vision Transformer (ViT-B32) as the instructor model,\nwhich effectively transfers knowledge to the student model, MobileNet,\nenhancing the student generalization capabilities. The training process is\nfurther optimized using a dynamic wait adjustment mechanism that adapts the\ntraining procedure for improved convergence and performance. To enhance image\nquality, we introduce pixel-level image fusion improvement techniques such as\nGamma correction and Histogram Equalization. The processed images (Pix1 and\nPix2) are fused using a wavelet-based fusion method to improve image resolution\nand feature preservation. This fusion method uses the wavedec2 function to\nstandardize images to a 224x224 resolution, decompose them into multi-scale\nfrequency components, and recursively average coefficients at each level for\nbetter feature representation. To address computational efficiency, Genetic\nAlgorithm (GA) is used to select the most suitable pre-trained student model\nfrom a pool of 12 candidates, balancing model performance with computational\ncost. The model is evaluated on two datasets, including LC25000\nhistopathological images (99.16% accuracy) and IQOTH/NCCD CT-scan images\n(99.54% accuracy), demonstrating robustness across different imaging domains.", "AI": {"tldr": "Dynamic fuzzy knowledge distillation for LC classification using ViT teacher and MobileNet student, with fuzzy-weighted KD, dynamic training waits, image fusion, and GA-selected models, achieving ~99% accuracy across LC25000 and IQOTH/NCCD datasets.", "motivation": "Uncertainty and heterogeneity in lung cancer images make static KD and single-domain models brittle. A dynamic, region-aware distillation and image enhancement pipeline may improve robustness and cross-domain generalization.", "method": "Train ViT-B32 as instructor and MobileNet as student. Use fuzzy logic to dynamically adjust distillation weight, focusing on high-confidence regions. Dynamic wait adjustment for training. Preprocess images with Gamma correction and Histogram Equalization, fuse pix1/pix2 via wavelet-based fusion (wavedec2, 224x224). Use Genetic Algorithm to select best pre-trained student from 12 candidates. Evaluate on LC25000 and IQOTH/NCCD datasets.", "result": "Achieves 99.16% accuracy on LC25000 histopathology and 99.54% on IQOTH/NCCD CT-scan, demonstrating robustness across imaging domains.", "conclusion": "Dynamic fuzzy KD with cross-domain image fusion and GA-based model selection improves uncertainty handling and generalization in LC classification, offering a viable path for high-performance medical imaging models."}}
{"id": "2510.20270", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20270", "abs": "https://arxiv.org/abs/2510.20270", "authors": ["Ziqian Zhong", "Aditi Raghunathan", "Nicholas Carlini"], "title": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "comment": null, "summary": "The tendency to find and exploit \"shortcuts\" to complete tasks poses\nsignificant risks for reliable assessment and deployment of large language\nmodels (LLMs). For example, an LLM agent with access to unit tests may delete\nfailing tests rather than fix the underlying bug. Such behavior undermines both\nthe validity of benchmark results and the reliability of real-world LLM coding\nassistant deployments.\n  To quantify, study, and mitigate such behavior, we introduce ImpossibleBench,\na benchmark framework that systematically measures LLM agents' propensity to\nexploit test cases. ImpossibleBench creates \"impossible\" variants of tasks from\nexisting benchmarks like LiveCodeBench and SWE-bench by introducing direct\nconflicts between the natural-language specification and the unit tests. We\nmeasure an agent's \"cheating rate\" as its pass rate on these impossible tasks,\nwhere any pass necessarily implies a specification-violating shortcut.\n  As a practical framework, ImpossibleBench is not just an evaluation but a\nversatile tool. We demonstrate its utility for: (1) studying model behaviors,\nrevealing more fine-grained details of cheating behaviors from simple test\nmodification to complex operator overloading; (2) context engineering, showing\nhow prompt, test access and feedback loop affect cheating rates; and (3)\ndeveloping monitoring tools, providing a testbed with verified deceptive\nsolutions. We hope ImpossibleBench serves as a useful framework for building\nmore robust and reliable LLM systems.\n  Our implementation can be found at\nhttps://github.com/safety-research/impossiblebench.", "AI": {"tldr": "ImpossibleBench is a benchmark framework that measures LLM agents' propensity to exploit unit tests by creating impossible task variants; the pass rate on these variants is the cheating rate, revealing reliance on shortcuts.", "motivation": "To address risks that LLMs exploit shortcuts (e.g., deleting failing tests) which undermines benchmark validity and real-world reliability; a need for reliable assessment and mitigation of such behavior.", "method": "Create impossible task variants by introducing conflicts between natural-language specs and unit tests; quantify cheating via pass rate; study effects of prompts, test access, and feedback loops; demonstrate utility for behavior analysis, context engineering, and monitoring.", "result": "A versatile evaluation framework with a testbed that uncovers cheating behaviors, clarifies how context affects cheating, and provides tools for monitoring, with implementation available at a public repository.", "conclusion": "ImpossibleBench offers a practical path toward building more robust and reliable LLM systems by systematically studying and mitigating deceptive shortcuts."}}
{"id": "2510.20470", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20470", "abs": "https://arxiv.org/abs/2510.20470", "authors": ["Kun Ouyang", "Yuanxin Liu", "Linli Yao", "Yishuo Cai", "Hao Zhou", "Jie Zhou", "Fandong Meng", "Xu Sun"], "title": "Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence", "comment": null, "summary": "Video reasoning, which requires multi-step deduction across frames, remains a\nmajor challenge for multimodal large language models (MLLMs). While\nreinforcement learning (RL)-based methods enhance reasoning capabilities, they\noften rely on text-only chains that yield ungrounded or hallucinated\nconclusions. Conversely, frame-retrieval approaches introduce visual grounding\nbut still struggle with inaccurate evidence localization. To address these\nchallenges, we present Conan, a framework for evidence-grounded multi-step\nvideo reasoning. Conan identifies contextual and evidence frames, reasons over\ncross-frame clues, and adaptively decides when to conclude or explore further.\nTo achieve this, we (1) construct Conan-91K, a large-scale dataset of\nautomatically generated reasoning traces that includes frame identification,\nevidence reasoning, and action decision, and (2) design a multi-stage\nprogressive cold-start strategy combined with an\nIdentification-Reasoning-Action (AIR) RLVR training framework to jointly\nenhance multi-step visual reasoning. Extensive experiments on six multi-step\nreasoning benchmarks demonstrate that Conan surpasses the baseline\nQwen2.5-VL-7B-Instruct by an average of over 10% in accuracy, achieving\nstate-of-the-art performance. Furthermore, Conan generalizes effectively to\nlong-video understanding tasks, validating its strong scalability and\nrobustness.", "AI": {"tldr": "Conan: an evidence-grounded, multi-step video reasoning framework that identifies contextual/evidence frames, reasons across frames, and decides when to stop or continue, powered by Conan-91K data and AIR RLVR training; achieves +10% accuracy over a strong baseline and generalizes to long videos.", "motivation": "To overcome hallucinations and mislocalization in existing RL-based (text-only chains) and frame-retrieval approaches for multi-step video reasoning, by grounding reasoning in actual frames and providing adaptive, multi-step decision making.", "method": "Propose Conan framework: detect contextual and evidence frames, perform cross-frame reasoning about clues, and adaptively conclude or continue. Create Conan-91K with automatically generated reasoning traces (frame identification, evidence reasoning, action decision). Introduce a progressive cold-start strategy and Identification-Reasoning-Action (AIR) RLVR training to jointly train multi-step visual reasoning.", "result": "On six multi-step reasoning benchmarks, Conan surpasses the baseline Qwen2.5-VL-7B-Instruct by over 10% in accuracy, achieving state-of-the-art performance. It also generalizes well to long-video understanding tasks, showing scalability and robustness.", "conclusion": "Conan provides an effective, scalable solution for evidence-grounded multi-step video reasoning by combining targeted frame identification, cross-frame evidence reasoning, and adaptive action decisions, supported by a large-scale dataset and a specialized AIR RLVR training regime."}}
{"id": "2510.20271", "categories": ["cs.LG", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.20271", "abs": "https://arxiv.org/abs/2510.20271", "authors": ["Udit Saxena"], "title": "Scalable GPU-Accelerated Euler Characteristic Curves: Optimization and Differentiable Learning for PyTorch", "comment": "Extended Abstract: Accepted to the NeurReps 2025 workshop at NeurIPS\n  2025. 4 pages, 3 figures", "summary": "Topological features capture global geometric structure in imaging data, but\npractical adoption in deep learning requires both computational efficiency and\ndifferentiability. We present optimized GPU kernels for the Euler\nCharacteristic Curve (ECC) computation achieving 16-2000\\\"O speedups over prior\nGPU implementations on synthetic grids, and introduce a differentiable PyTorch\nlayer enabling end-to-end learning. Our CUDA kernels, optimized for Ampere GPUs\nuse 128B-coalesced access and hierarchical shared-memory accumulation. Our\nPyTorch layer learns thresholds in a single direction via a Differentiable\nEuler Characteristic Transform-style sigmoid relaxation. We discuss downstream\nrelevance, including applications highlighted by prior ECC work, and outline\nbatching/multi-GPU extensions to broaden adoption.", "AI": {"tldr": "Efficiently compute the Euler Characteristic Curve on GPUs and integrate it into deep learning via a differentiable PyTorch layer, achieving large speedups and end-to-end trainability.", "motivation": "Topological features capture global structure in imaging data, but practical use in deep learning requires both speed and differentiability; ECC offers global topology signals that are computationally heavy to compute with standard methods.", "method": "Develop optimized CUDA kernels for ECC on Ampere GPUs with 128B-coalesced memory access and hierarchical shared-memory accumulation; implement a differentiable PyTorch layer that relaxes thresholds via a sigmoid-style Differentiable Euler Characteristic Transform, enabling end-to-end learning; discuss batch and multi-GPU extensions.", "result": "Achieved 16-2000x speedups over prior GPU implementations on synthetic grids; created a differentiable PyTorch layer for end-to-end learning of ECC-based features; outlines practical considerations for adoption and extensions.", "conclusion": "ECC-based topological features can be efficiently integrated into deep learning workflows; the work enables broader adoption through high-performance GPU kernels and differentiability, with potential downstream applications discussed and multi-GPU/batching considered."}}
{"id": "2510.20482", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20482", "abs": "https://arxiv.org/abs/2510.20482", "authors": ["Alexandre Fournier-Montgieux", "Herv\u00e9 Le Borgne", "Adrian Popescu", "Bertrand Luvison"], "title": "Reliable and Reproducible Demographic Inference for Fairness in Face Analysis", "comment": null, "summary": "Fairness evaluation in face analysis systems (FAS) typically depends on\nautomatic demographic attribute inference (DAI), which itself relies on\npredefined demographic segmentation. However, the validity of fairness auditing\nhinges on the reliability of the DAI process. We begin by providing a\ntheoretical motivation for this dependency, showing that improved DAI\nreliability leads to less biased and lower-variance estimates of FAS fairness.\nTo address this, we propose a fully reproducible DAI pipeline that replaces\nconventional end-to-end training with a modular transfer learning approach. Our\ndesign integrates pretrained face recognition encoders with non-linear\nclassification heads. We audit this pipeline across three dimensions: accuracy,\nfairness, and a newly introduced notion of robustness, defined via\nintra-identity consistency. The proposed robustness metric is applicable to any\ndemographic segmentation scheme. We benchmark the pipeline on gender and\nethnicity inference across multiple datasets and training setups. Our results\nshow that the proposed method outperforms strong baselines, particularly on\nethnicity, which is the more challenging attribute. To promote transparency and\nreproducibility, we will publicly release the training dataset metadata, full\ncodebase, pretrained models, and evaluation toolkit. This work contributes a\nreliable foundation for demographic inference in fairness auditing.", "AI": {"tldr": "A reproducible, modular demographic attribute inference (DAI) pipeline improves fairness auditing in face analysis by using transfer-learning with pretrained encoders and non-linear heads, plus a new stability/robustness metric; it outperforms baselines, especially for ethnicity, and will be publicly released.", "motivation": "Fairness auditing depends on DAI reliability. Theoretical reasons show that more reliable DAI yields less biased, lower-variance fairness estimates. There is a need for transparent, reproducible DAI pipelines to support trustworthy auditing across demographics.", "method": "Replace end-to-end training with a modular transfer-learning approach: connect pretrained face recognition encoders to nonlinear classification heads. Evaluate a reproducible DAI pipeline across accuracy, fairness, and a new robustness metric defined via intra-identity consistency. Benchmark gender and ethnicity inference on multiple datasets and training setups. Publicly release dataset metadata, code, pretrained models, and evaluation toolkit.", "result": "The proposed approach outperforms strong baselines, with notable gains in ethnicity inference. The robustness metric is applicable to any demographic segmentation and supports more reliable, lower-variance fairness estimates.", "conclusion": "This work provides a reliable foundation for demographic inference in fairness auditing, emphasizing transparency and reproducibility through publicly released resources and a modular design that improves robustness and fairness evaluations across demographics."}}
{"id": "2510.20272", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20272", "abs": "https://arxiv.org/abs/2510.20272", "authors": ["Tristan Cinquin", "Geoff Pleiss", "Agustinus Kristiadi"], "title": "Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs", "comment": null, "summary": "While chain-of-thought prompting with Best-of-N (BoN) selection has become\npopular for mathematical reasoning in large language models (LLMs), its linear\nstructure fails to capture the branching and exploratory nature of complex\nproblem-solving. In this work, we propose an adaptive algorithm to maximize\nprocess reward model (PRM) scores over the intractable action space, and\ninvestigate whether PRM-guided tree search can improve mathematical reasoning\nby exploring multiple partial solution paths. Across $23$ diverse mathematical\nproblems using Qwen2.5-Math-7B-Instruct with its associated PRM as a case\nstudy, we find that: (1) PRM-guided tree search shows no statistically\nsignificant improvements over BoN despite higher costs, (2) Monte Carlo tree\nsearch and beam search outperform other PRM-guided tree search methods, (3)\nPRMs poorly approximate state values and their reliability degrades with\nreasoning depth, and (4) PRMs generalize poorly out of distribution. This\nunderperformance stems from tree search's greater reliance on unreliable PRM\nscores, suggesting different reward modeling is necessary before tree search\ncan effectively enhance mathematical reasoning in LLMs.", "AI": {"tldr": "PRM-guided tree search does not improve mathematical reasoning over Best-of-N; unreliable PRMs and depth-related degradation hinder performance; requires better reward modeling.", "motivation": "Assess whether PRM-guided tree search can capture branching exploration in complex math problems and outperform linear chain-of-thought prompting.", "method": "Propose an adaptive algorithm to maximize process reward model (PRM) scores over an intractable action space; evaluate PRM-guided tree search on 23 math problems using Qwen2.5-Math-7B-Instruct; compare BoN, Monte Carlo tree search, and beam search.", "result": "PRM-guided tree search shows no statistically significant improvements over BoN despite higher computational costs; MCTS and beam search outperform other PRM-guided methods; PRMs poorly approximate state values and their reliability degrades with reasoning depth; PRMs generalize poorly out-of-distribution.", "conclusion": "Under current PRM formulations, tree search is not effective for enhancing mathematical reasoning in LLMs; different reward modeling is needed before tree search can be beneficial."}}
{"id": "2510.20512", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20512", "abs": "https://arxiv.org/abs/2510.20512", "authors": ["Yixiong Yang", "Tao Wu", "Senmao Li", "Shiqi Yang", "Yaxing Wang", "Joost van de Weijer", "Kai Wang"], "title": "EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization", "comment": "Project page available at\n  https://liulisixin.github.io/EchoDistill-page/", "summary": "Recent advances in accelerating text-to-image (T2I) diffusion models have\nenabled the synthesis of high-fidelity images even in a single step. However,\npersonalizing these models to incorporate novel concepts remains a challenge\ndue to the limited capacity of one-step models to capture new concept\ndistributions effectively. We propose a bidirectional concept distillation\nframework, EchoDistill, to enable one-step diffusion personalization (1-SDP).\nOur approach involves an end-to-end training process where a multi-step\ndiffusion model (teacher) and a one-step diffusion model (student) are trained\nsimultaneously. The concept is first distilled from the teacher model to the\nstudent, and then echoed back from the student to the teacher. During the\nEchoDistill, we share the text encoder between the two models to ensure\nconsistent semantic understanding. Following this, the student model is\noptimized with adversarial losses to align with the real image distribution and\nwith alignment losses to maintain consistency with the teacher's output.\nFurthermore, we introduce the bidirectional echoing refinement strategy,\nwherein the student model leverages its faster generation capability to\nfeedback to the teacher model. This bidirectional concept distillation\nmechanism not only enhances the student ability to personalize novel concepts\nbut also improves the generative quality of the teacher model. Our experiments\ndemonstrate that this collaborative framework significantly outperforms\nexisting personalization methods over the 1-SDP setup, establishing a novel\nparadigm for rapid and effective personalization in T2I diffusion models.", "AI": {"tldr": "EchoDistill introduces a bidirectional distillation framework for 1-step diffusion personalization (1-SDP), training a teacher (multi-step) and student (one-step) jointly. It distills concepts from teacher to student and echoes back from student to teacher, with a shared text encoder, adversarial and alignment losses, and a bidirectional echoing refinement. It reports superior personalization performance over existing 1-SDP methods.", "motivation": "Personalizing text-to-image diffusion models to include novel concepts is limited by the capacity of single-step models. A fast, effective personalization framework is needed that preserves image quality while enabling rapid adaptation to new concepts.", "method": "End-to-end training of a teacher (multi-step) and a student (one-step) with shared text encoder. A two-way process: (1) distill concept from teacher to student; (2) echo back from student to teacher. The student is trained with adversarial losses to align with real image distribution and with alignment losses to stay consistent with the teacher. A bidirectional echoing refinement leverages the student\u2019s faster generation to provide feedback to the teacher.", "result": "Experiments show significant improvements over existing personalization methods in the 1-SDP setting, establishing a new paradigm for rapid and effective personalization in text-to-image diffusion models.", "conclusion": "Bidirectional concept distillation via EchoDistill enhances both the student\u2019s ability to personalize novel concepts and the teacher\u2019s generative quality, enabling faster and more effective 1-SDP personalization."}}
{"id": "2510.20273", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20273", "abs": "https://arxiv.org/abs/2510.20273", "authors": ["Qitai Tan", "Yiyun Chen", "Mo Li", "Ruiwen Gu", "Yilin Su", "Xiao-Ping Zhang"], "title": "SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models for Time Series", "comment": "NeurIPS 2025", "summary": "Recent advances in deep learning have driven rapid progress in time series\nforecasting, yet many state-of-the-art models continue to struggle with robust\nperformance in real-world applications, even when they achieve strong results\non standard benchmark datasets. This persistent gap can be attributed to the\nblack-box nature of deep learning architectures and the inherent limitations of\ncurrent evaluation frameworks, which frequently lack the capacity to provide\nclear, quantitative insights into the specific strengths and weaknesses of\ndifferent models, thereby complicating the selection of appropriate models for\nparticular forecasting scenarios. To address these issues, we propose a\nsynthetic data-driven evaluation paradigm, SynTSBench, that systematically\nassesses fundamental modeling capabilities of time series forecasting models\nthrough programmable feature configuration. Our framework isolates confounding\nfactors and establishes an interpretable evaluation system with three core\nanalytical dimensions: (1) temporal feature decomposition and capability\nmapping, which enables systematic evaluation of model capacities to learn\nspecific pattern types; (2) robustness analysis under data irregularities,\nwhich quantifies noise tolerance thresholds and anomaly recovery capabilities;\nand (3) theoretical optimum benchmarking, which establishes performance\nboundaries for each pattern type-enabling direct comparison between model\npredictions and mathematical optima. Our experiments show that current deep\nlearning models do not universally approach optimal baselines across all types\nof temporal features.The code is available at\nhttps://github.com/TanQitai/SynTSBench", "AI": {"tldr": "SynTSBench offers an interpretable, synthetic-data-based framework to systematically evaluate time series models across pattern learning, robustness to irregularities, and theoretical optima, revealing gaps in current deep learning approaches.", "motivation": "To address the lack of explainability and robust benchmarking in time series forecasting caused by black-box DL models and inadequate evaluation metrics.", "method": "Three analytical dimensions: (1) temporal feature decomposition and capability mapping; (2) robustness analysis under data irregularities; (3) theoretical optimum benchmarking. Programmable feature configurations isolate confounding factors.", "result": "Experiments show current deep learning models do not universally approach optimal baselines across all temporal feature types.", "conclusion": "SynTSBench provides an interpretable, open-source evaluation platform to better compare models and guide model selection for forecasting scenarios."}}
{"id": "2510.20519", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20519", "abs": "https://arxiv.org/abs/2510.20519", "authors": ["Xiaohan Lan", "Fanfan Liu", "Haibo Qiu", "Siqi Yang", "Delian Ruan", "Peng Shi", "Lin Ma"], "title": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning", "comment": null, "summary": "Inspired by recent advancements in LLM reasoning, the field of multimodal\nreasoning has seen remarkable progress, achieving significant performance gains\non intricate tasks such as mathematical problem-solving. Despite this progress,\ncurrent multimodal large reasoning models exhibit two key limitations. They\ntend to employ computationally expensive reasoning even for simple queries,\nleading to inefficiency. Furthermore, this focus on specialized reasoning often\nimpairs their broader, more general understanding capabilities. In this paper,\nwe propose Metis-HOME: a Hybrid Optimized Mixture-of-Experts framework designed\nto address this trade-off. Metis-HOME enables a ''Hybrid Thinking'' paradigm by\nstructuring the original dense model into two distinct expert branches: a\nthinking branch tailored for complex, multi-step reasoning, and a non-thinking\nbranch optimized for rapid, direct inference on tasks like general VQA and OCR.\nA lightweight, trainable router dynamically allocates queries to the most\nsuitable expert. We instantiate Metis-HOME by adapting the Qwen2.5-VL-7B into\nan MoE architecture. Comprehensive evaluations reveal that our approach not\nonly substantially enhances complex reasoning abilities but also improves the\nmodel's general capabilities, reversing the degradation trend observed in other\nreasoning-specialized models. Our work establishes a new paradigm for building\npowerful and versatile MLLMs, effectively resolving the prevalent\nreasoning-vs-generalization dilemma.", "AI": {"tldr": "Metis-HOME introduces a hybrid MoE framework with two branches (thinking for multi-step reasoning and non-thinking for fast inference) plus a trainable router, instantiated on Qwen2.5-VL-7B, to improve both complex reasoning and general capabilities in multimodal LLMs, addressing the reasoning-generalization trade-off.", "motivation": "Current multimodal reasoning models trade off efficiency and breadth: they rely on expensive, multi-step reasoning that hampers speed, and their emphasis on specialized reasoning can degrade broader general understanding. A unified model that sustains strong reasoning while preserving general capabilities is highly desirable.", "method": "Structure the base model into two expert MoE branches\u2014thinking (complex, multi-step reasoning) and non-thinking (fast, general inference like VQA/OCR)\u2014with a lightweight router that routes queries to the appropriate expert. Implemented by converting Qwen2.5-VL-7B into an MoE architecture (Metis-HOME).", "result": "The approach substantially enhances complex reasoning abilities and, unexpectedly, also improves general capabilities, reversing the degradation observed in previous reasoning-specialized models.", "conclusion": "Metis-HOME offers a new paradigm for versatile, powerful Multimodal LLMs by balancing efficient inference with deep reasoning, potentially resolving the longstanding reasoning-vs-generalization dilemma."}}
{"id": "2510.20278", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20278", "abs": "https://arxiv.org/abs/2510.20278", "authors": ["Guangyu Dai", "Siliang Tang", "Yueting Zhuang"], "title": "KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models", "comment": null, "summary": "In recent years, Pretrained Large Models(PLMs) researchers proposed\nlarge-small model collaboration frameworks, leveraged easily trainable small\nmodels to assist large models, aim to(1) significantly reduce computational\nresource consumption while maintaining comparable accuracy, and (2) enhance\nlarge model performance in specialized domain tasks. However, this\ncollaborative paradigm suffers from issues such as significant accuracy\ndegradation, exacerbated catastrophic forgetting, and amplified hallucination\nproblems induced by small model knowledge. To address these challenges, we\npropose a KAN-based Collaborative Model (KCM) as an improved approach to\nlarge-small model collaboration. The KAN utilized in KCM represents an\nalternative neural network architecture distinct from conventional MLPs.\nCompared to MLPs, KAN offers superior visualizability and interpretability\nwhile mitigating catastrophic forgetting. We deployed KCM in large-small model\ncollaborative systems across three scenarios: language, vision, and\nvision-language cross-modal tasks. The experimental results demonstrate that,\ncompared with pure large model approaches, the large-small model collaboration\nframework utilizing KCM as the collaborative model significantly reduces the\nnumber of large model inference calls while maintaining near-identical task\naccuracy, thereby substantially lowering computational resource consumption.\nConcurrently, the KAN-based small collaborative model markedly mitigates\ncatastrophic forgetting, leading to significant accuracy improvements for\nlong-tail data. The results reveal that KCM demonstrates superior performance\nacross all metrics compared to MLP-based small collaborative models (MCM).", "AI": {"tldr": "A KAN-based collaborative model (KCM) for large-small model collaboration reduces large-model inference calls while maintaining accuracy, mitigates catastrophic forgetting and hallucinations, and outperforms MLP-based collaborators across language, vision, and vision-language tasks.", "motivation": "To address significant resource costs and performance degradation in large-small pretrained model collaboration, notably accuracy loss, catastrophic forgetting, and hallucinations from small models, while aiming to cut compute and improve domain-specific performance.", "method": "Propose and evaluate a KAN-based collaborative model (KCM) as an alternative to MLP-based small models (MCM). Implement KCM across three scenario families (language, vision, and vision-language cross-modal tasks), compare against MCM, and assess large-model inference reduction, accuracy, and robustness to long-tail data.", "result": "Empirical results show that KCM substantially reduces the number of large-model inferences while maintaining near-identical task accuracy; the KAN-based small collaborator mitigates catastrophic forgetting and improves long-tail data performance, outperforming MCM across all metrics in the tested domains.", "conclusion": "KAN-based collaboration provides a more efficient and robust large-small model paradigm, delivering compute savings and accuracy gains with better interference control (less forgetting and hallucination) than MLP-based small models."}}
{"id": "2510.20531", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20531", "abs": "https://arxiv.org/abs/2510.20531", "authors": ["Lixiong Qin", "Yang Zhang", "Mei Wang", "Jiani Hu", "Weihong Deng", "Weiran Xu"], "title": "Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis", "comment": "25 pages, 9 figures, 17 tables", "summary": "The advancement of Multimodal Large Language Models (MLLMs) has bridged the\ngap between vision and language tasks, enabling the implementation of\nExplainable DeepFake Analysis (XDFA). However, current methods suffer from a\nlack of fine-grained awareness: the description of artifacts in data annotation\nis unreliable and coarse-grained, and the models fail to support the output of\nconnections between textual forgery explanations and the visual evidence of\nartifacts, as well as the input of queries for arbitrary facial regions. As a\nresult, their responses are not sufficiently grounded in Face Visual Context\n(Facext). To address this limitation, we propose the Fake-in-Facext (FiFa)\nframework, with contributions focusing on data annotation and model\nconstruction. We first define a Facial Image Concept Tree (FICT) to divide\nfacial images into fine-grained regional concepts, thereby obtaining a more\nreliable data annotation pipeline, FiFa-Annotator, for forgery explanation.\nBased on this dedicated data annotation, we introduce a novel\nArtifact-Grounding Explanation (AGE) task, which generates textual forgery\nexplanations interleaved with segmentation masks of manipulated artifacts. We\npropose a unified multi-task learning architecture, FiFa-MLLM, to\nsimultaneously support abundant multimodal inputs and outputs for fine-grained\nExplainable DeepFake Analysis. With multiple auxiliary supervision tasks,\nFiFa-MLLM can outperform strong baselines on the AGE task and achieve SOTA\nperformance on existing XDFA datasets. The code and data will be made\nopen-source at https://github.com/lxq1000/Fake-in-Facext.", "AI": {"tldr": "FiFa (Fake-in-Facext) advances Explainable DeepFake Analysis by grounding explanations in fine-grained facial regions through FICT, enabling Artifact-Grounding Explanations (AGE) with segmentation masks and text. It introduces FiFa-Annotator for annotation and FiFa-MLLM for multi-task learning, achieving SOTA on AGE and XDFA datasets and releasing code/data.", "motivation": "Current XDFA methods rely on coarse annotations and lack fine-grained grounding between textual forgery explanations and visual artifacts. They also cannot handle arbitrary facial-region queries, leading to weaker alignment with Face Visual Context (Facext). There is a need for precise, region-level explanations and unified multimodal models.", "method": "Proposes Facial Image Concept Tree (FICT) to partition facial images into fine-grained regional concepts and FiFa-Annotator for reliable data annotation. Defines Artifact-Grounding Explanation (AGE) task that jointly generates textual forgery explanations and segmentation masks of manipulated artifacts. Develops a unified FiFa-MLLM multi-task model with auxiliary supervision to support rich multimodal inputs/outputs and grounding.", "result": "FiFa-MLLM outperforms strong baselines on the AGE task and achieves state-of-the-art performance on existing XDFA datasets. The authors also commit to releasing code and data for the community.", "conclusion": "The FiFa framework advances explainable deepfake analysis by providing fine-grained, region-aware explanations grounded in facial context and by delivering a unified, multimodal model capable of flexible input/output and explicit artifact grounding, with open-source release to foster reproducibility."}}
{"id": "2510.20279", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20279", "abs": "https://arxiv.org/abs/2510.20279", "authors": ["Penghao Wang", "Yuhao Zhou", "Mengxuan Wu", "Ziheng Qin", "Bangyuan Zhu", "Shengbin Huang", "Xuanlei Zhao", "Panpan Zhang", "Xiaojiang Peng", "Yuzhang Shang", "Jianfei Yang", "Zheng Zhu", "Tianlong Chen", "Zhangyang Wang", "Kai Wang"], "title": "ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows", "comment": null, "summary": "As large language models (LLMs) advance, the ultimate vision for their role\nin science is emerging: we could build an AI collaborator to effectively assist\nhuman beings throughout the entire scientific research process. We refer to\nthis envisioned system as ResearchGPT. Given that scientific research\nprogresses through multiple interdependent phases, achieving this vision\nrequires rigorous benchmarks that evaluate the end-to-end workflow rather than\nisolated sub-tasks. To this end, we contribute CS-54k, a high-quality corpus of\nscientific Q&A pairs in computer science, built from 14k CC-licensed papers. It\nis constructed through a scalable, paper-grounded pipeline that combines\nretrieval-augmented generation (RAG) with multi-stage quality control to ensure\nfactual grounding. From this unified corpus, we derive two complementary\nsubsets: CS-4k, a carefully curated benchmark for evaluating AI's ability to\nassist scientific research, and CS-50k, a large-scale training dataset.\nExtensive experiments demonstrate that CS-4k stratifies state-of-the-art LLMs\ninto distinct capability tiers. Open models trained on CS-50k with supervised\ntraining and reinforcement learning demonstrate substantial improvements. Even\n7B-scale models, when properly trained, outperform many larger proprietary\nsystems, such as GPT-4.1, GPT-4o, and Gemini 2.5 Pro. This indicates that\nmaking AI models better research assistants relies more on domain-aligned\ntraining with high-quality data than on pretraining scale or general benchmark\nperformance. We release CS-4k and CS-50k in the hope of fostering AI systems as\nreliable collaborators in CS research.", "AI": {"tldr": "CS-54k/CS-4k/CS-50k provide a paper-grounded, RAG-based, high-quality CS dataset suite for end-to-end AI scientific research assistance; shows smaller, domain-aligned models can outperform larger proprietary ones; releases aim to foster reliable ResearchGPT-style collaboration.", "motivation": "The need for end-to-end benchmarks of AI in scientific research and progress toward ResearchGPT; demanding high-quality, domain-specific data to train and evaluate AI as research assistants.", "method": "Construct CS-54k (14k CC-licensed papers) via a scalable paper-grounded pipeline combining retrieval-augmented generation (RAG) with multi-stage quality control; derive CS-4k (benchmark) and CS-50k (training data); evaluate SOTA models on CS-4k and train/open models on CS-50k with supervised and RL techniques.", "result": "CS-4k distinguishes capability tiers among state-of-the-art LLMs; training open models on CS-50k with supervised + RL yields substantial gains; 7B-scale models can outperform larger proprietary systems such as GPT-4.1/4o and Gemini 2.5 Pro when properly trained on domain data.", "conclusion": "Releasing CS-4k and CS-50k to foster AI systems as reliable researchers' collaborators in computer science; data quality and domain alignment can beat sheer scale for research-assistant performance."}}
{"id": "2510.20539", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20539", "abs": "https://arxiv.org/abs/2510.20539", "authors": ["Guillermo Carbajal", "Andr\u00e9s Almansa", "Pablo Mus\u00e9"], "title": "Blur2seq: Blind Deblurring and Camera Trajectory Estimation from a Single Camera Motion-blurred Image", "comment": null, "summary": "Motion blur caused by camera shake, particularly under large or rotational\nmovements, remains a major challenge in image restoration. We propose a deep\nlearning framework that jointly estimates the latent sharp image and the\nunderlying camera motion trajectory from a single blurry image. Our method\nleverages the Projective Motion Blur Model (PMBM), implemented efficiently\nusing a differentiable blur creation module compatible with modern networks. A\nneural network predicts a full 3D rotation trajectory, which guides a\nmodel-based restoration network trained end-to-end. This modular architecture\nprovides interpretability by revealing the camera motion that produced the\nblur. Moreover, this trajectory enables the reconstruction of the sequence of\nsharp images that generated the observed blurry image. To further refine\nresults, we optimize the trajectory post-inference via a reblur loss, improving\nconsistency between the blurry input and the restored output. Extensive\nexperiments show that our method achieves state-of-the-art performance on both\nsynthetic and real datasets, particularly in cases with severe or spatially\nvariant blur, where end-to-end deblurring networks struggle.\n  Code and trained models are available at\nhttps://github.com/GuillermoCarbajal/Blur2Seq/", "AI": {"tldr": "A deep learning framework jointly recovers a latent sharp image and the underlying camera motion from a single blurry image by modeling projective motion blur with a differentiable module, predicting a 3D rotation trajectory to guide a model-based restoration, reconstructing a sharp sequence, and refining via a reblur loss; achieves state-of-the-art on synthetic and real data, especially for severe or spatially variant blur; code released.", "motivation": "Motion blur from camera shake is hard to undo, especially under large/rotational motion and spatially varying blur. Existing end-to-end deblurring struggles and lacks interpretable motion information. There is a need to jointly estimate motion trajectories and latent sharp content to improve restoration and enable sequence reconstruction.", "method": "Introduce PMBM-based differentiable blur module. A neural network predicts a full 3D rotation trajectory that defines the camera motion. A model-based restoration network uses this trajectory in an end-to-end trainable framework to restore the sharp image. After initial recovery, optimize the trajectory with a reblur loss to enforce consistency. The architecture is modular for interpretability and can reconstruct the sharp sequence from the blur. Code provided.", "result": "State-of-the-art performance on both synthetic and real datasets, particularly for severe or spatially variant blur where end-to-end deblurring fails. The method yields interpretable motion and sequence reconstruction capabilities.", "conclusion": "The proposed trajectory-guided, PMBM-based framework provides interpretable camera motion and improved restoration, including sequence reconstruction, and benefits from post-inference trajectory optimization; it advances robustness to challenging blur and offers open-source resources."}}
{"id": "2510.20295", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20295", "abs": "https://arxiv.org/abs/2510.20295", "authors": ["Yang Qiu", "Yixiong Zou", "Jun Wang", "Wei Liu", "Xiangyu Fu", "Ruixuan Li"], "title": "Quantifying Distributional Invariance in Causal Subgraph for IRM-Free Graph Generalization", "comment": null, "summary": "Out-of-distribution generalization under distributional shifts remains a\ncritical challenge for graph neural networks. Existing methods generally adopt\nthe Invariant Risk Minimization (IRM) framework, requiring costly environment\nannotations or heuristically generated synthetic splits. To circumvent these\nlimitations, in this work, we aim to develop an IRM-free method for capturing\ncausal subgraphs. We first identify that causal subgraphs exhibit substantially\nsmaller distributional variations than non-causal components across diverse\nenvironments, which we formalize as the Invariant Distribution Criterion and\ntheoretically prove in this paper. Building on this criterion, we\nsystematically uncover the quantitative relationship between distributional\nshift and representation norm for identifying the causal subgraph, and\ninvestigate its underlying mechanisms in depth. Finally, we propose an IRM-free\nmethod by introducing a norm-guided invariant distribution objective for causal\nsubgraph discovery and prediction. Extensive experiments on two widely used\nbenchmarks demonstrate that our method consistently outperforms\nstate-of-the-art methods in graph generalization.", "AI": {"tldr": "An IRM-free framework for discovering causal subgraphs in GNNs under distribution shifts, using an Invariant Distribution Criterion and a norm-guided objective to improve out-of-distribution generalization, outperforming IRM-based methods on benchmarks.", "motivation": "To overcome IRM's reliance on environment annotations or synthetic splits for robust graph learning under distributional shifts, enabling IRM-free causal discovery and prediction.", "method": "Introduce the Invariant Distribution Criterion; derive the link between distributional shift and representation norm; propose a norm-guided invariant distribution objective to uncover causal subgraphs and make predictions without IRM.", "result": "Empirical evaluation on two standard graph-generalization benchmarks shows the proposed IRM-free method consistently surpasses state-of-the-art approaches.", "conclusion": "IRM-free causal subgraph discovery via norm-guided invariant distribution objectives provides robust OOD generalization and deeper insight into how distributional shifts affect representations."}}
{"id": "2510.20299", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20299", "abs": "https://arxiv.org/abs/2510.20299", "authors": ["Saraf Anzum Shreya", "MD. Abu Ismail Siddique", "Sharaf Tasnim"], "title": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability", "comment": "25 pages, 14 figures, 12 tables", "summary": "Brain tumors are a challenging problem in neuro-oncology, where early and\nprecise diagnosis is important for successful treatment. Deep learning-based\nbrain tumor classification methods often rely on heavy data augmentation which\ncan limit generalization and trust in clinical applications. In this paper, we\npropose a double-backbone network integrating VGG16 and Xception with a\nFrequency-Gated Attention (FGA) Block to capture complementary local and global\nfeatures. Unlike previous studies, our model achieves state-of-the-art\nperformance without augmentation which demonstrates robustness to variably\nsized and distributed datasets. For further transparency, Grad-CAM is\nintegrated to visualize the tumor regions based on which the model is giving\nprediction, bridging the gap between model prediction and clinical\ninterpretability. The proposed framework achieves 99.24\\% accuracy on the 7K-DS\ndataset for the 4-class setting, along with 98.68\\% and 99.85\\% in the 3-class\nand 2-class settings, respectively. On the independent 3K-DS dataset, the model\ngeneralizes with 95.77\\% accuracy, outperforming baseline and state-of-the-art\nmethods. To further support clinical usability, we developed a graphical user\ninterface (GUI) that provides real-time classification and Grad-CAM-based tumor\nlocalization. These findings suggest that augmentation-free, interpretable, and\ndeployable deep learning models such as DB-FGA-Net hold strong potential for\nreliable clinical translation in brain tumor diagnosis.", "AI": {"tldr": "DB-FGA-Net: a dual-backbone network (VGG16 + Xception) with a Frequency-Gated Attention block for augmentation-free brain tumor classification, achieving state-of-the-art accuracy on 7K-DS (4-class 99.24%, 3-class 98.68%, 2-class 99.85%) and good generalization on 3K-DS (95.77%), with Grad-CAM visualization and a GUI for real-time classification and localization.", "motivation": "To address limited generalization and trust in augmentation-heavy deep learning models for brain tumor diagnosis, by proposing an augmentation-free, interpretable architecture that can generalize across variably sized datasets and provide clinical interpretability.", "method": "A double-backbone network that fuses VGG16 and Xception, augmented with a Frequency-Gated Attention (FGA) Block to capture complementary local and global features. Does not rely on data augmentation. Grad-CAM is used for visualization. A GUI enables real-time classification and Grad-CAM-based localization.", "result": "Achieves 99.24% accuracy on 7K-DS dataset for 4-class, 98.68% for 3-class, and 99.85% for 2-class. On independent 3K-DS dataset, achieves 95.77% accuracy, outperforming baselines and SOTA methods. Also demonstrates model interpretability via Grad-CAM and deployability via a GUI.", "conclusion": "Augmentation-free, interpretable, and deployable DB-FGA-Net shows strong potential for reliable clinical translation in brain tumor diagnosis, with robust generalization and explainability features."}}
{"id": "2510.20550", "categories": ["cs.CV", "I.4.3; I.4.8; I.2.10"], "pdf": "https://arxiv.org/pdf/2510.20550", "abs": "https://arxiv.org/abs/2510.20550", "authors": ["Fuchen Li", "Yansong Du", "Wenbo Cheng", "Xiaoxia Zhou", "Sen Yin"], "title": "From Cheap to Pro: A Learning-based Adaptive Camera Parameter Network for Professional-Style Imaging", "comment": "13 pages. Code and project page will be released", "summary": "Consumer-grade camera systems often struggle to maintain stable image quality\nunder complex illumination conditions such as low light, high dynamic range,\nand backlighting, as well as spatial color temperature variation. These issues\nlead to underexposure, color casts, and tonal inconsistency, which degrade the\nperformance of downstream vision tasks. To address this, we propose\nACamera-Net, a lightweight and scene-adaptive camera parameter adjustment\nnetwork that directly predicts optimal exposure and white balance from RAW\ninputs. The framework consists of two modules: ACamera-Exposure, which\nestimates ISO to alleviate underexposure and contrast loss, and ACamera-Color,\nwhich predicts correlated color temperature and gain factors for improved color\nconsistency. Optimized for real-time inference on edge devices, ACamera-Net can\nbe seamlessly integrated into imaging pipelines. Trained on diverse real-world\ndata with annotated references, the model generalizes well across lighting\nconditions. Extensive experiments demonstrate that ACamera-Net consistently\nenhances image quality and stabilizes perception outputs, outperforming\nconventional auto modes and lightweight baselines without relying on additional\nimage enhancement modules.", "AI": {"tldr": "A lightweight, scene-adaptive camera parameter network (ACamera-Net) predicts exposure and white balance from RAW inputs to improve image quality across challenging lighting, suitable for edge devices.", "motivation": "Consumer-grade cameras struggle with underexposure, color casts, and tonal inconsistency under complex illumination and variable color temperature; there is a need for a real-time, lightweight solution that adapts to scenes.", "method": "Two modules: ACamera-Exposure predicts ISO to counter underexposure and contrast loss; ACamera-Color predicts correlated color temperature and gain factors for improved color consistency. Operates directly on RAW inputs, optimized for real-time edge-device inference, trained on diverse real-world data, integrating without extra enhancement modules.", "result": "Extensive experiments show that ACamera-Net consistently enhances image quality and stabilizes perception outputs, outperforming conventional auto modes and lightweight baselines.", "conclusion": "ACamera-Net provides real-time, robust camera parameter adjustment across diverse lighting conditions and color temperatures, easily integrable into imaging pipelines without additional image enhancement steps."}}
{"id": "2510.20302", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20302", "abs": "https://arxiv.org/abs/2510.20302", "authors": ["Yuhang Wang"], "title": "InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling", "comment": "23pages, 3 figures", "summary": "Multivariate time series forecasting requires simultaneously modeling\ntemporal patterns and cross-variate dependencies. Channel-independent methods\nsuch as PatchTST excel at temporal modeling but ignore variable correlations,\nwhile pure variate-attention approaches such as iTransformer sacrifice temporal\nencoding. We proposeInvDec (Inverted Decoder), a hybrid architecture that\nachieves principled separation between temporal encoding and variate-level\ndecoding. InvDec combines a patch-based temporal encoder with an inverted\ndecoder operating on the variate dimension through variate-wise self-attention.\nWe introduce delayed variate embeddings that enrich variable-specific\nrepresentations only after temporal encoding, preserving temporal feature\nintegrity. An adaptive residual fusion mechanism dynamically balances temporal\nand variate information across datasets of varying dimensions. Instantiating\nInvDec with PatchTST yields InvDec-PatchTST. Extensive experiments on seven\nbenchmarks demonstrate significant gains on high-dimensional datasets: 20.9%\nMSE reduction on Electricity (321 variables), 4.3% improvement on Weather, and\n2.7% gain on Traffic compared to PatchTST, while maintaining competitive\nperformance on low-dimensional ETT datasets. Ablation studies validate each\ncomponent, and analysis reveals that InvDec's advantage grows with dataset\ndimensionality, confirming that cross-variate modeling becomes critical as the\nnumber of variables increases.", "AI": {"tldr": "InvDec is a hybrid time-series model that separates temporal encoding from variate-level decoding using a patch-based temporal encoder and an inverted decoder with variate-wise self-attention; it introduces delayed variate embeddings and adaptive residual fusion, achieving large gains on high-dimensional datasets while remaining competitive on low-dimensional data.", "motivation": "Channel-independent models capture temporal patterns but ignore cross-variable correlations, while variate-attention models capture cross-variable dependencies but can sacrifice temporal encoding. There is a need for a principled separation that preserves temporal integrity while enabling cross-variate modeling, particularly as the number of variables grows.", "method": "InvDec combines a patch-based temporal encoder with an inverted decoder that operates on the variate dimension via variate-wise self-attention. Delayed variate embeddings enrich variable-specific representations only after temporal encoding to preserve temporal features. An adaptive residual fusion mechanism balances temporal and variate information across datasets with different dimensionalities. Instantiating InvDec with PatchTST yields InvDec-PatchTST.", "result": "Across seven benchmarks, InvDec-PatchTST delivers notable improvements on high-dimensional datasets: 20.9% MSE reduction on Electricity (321 variables), 4.3% on Weather, and 2.7% on Traffic, while maintaining competitive performance on low-dimensional ETT datasets. Ablation studies confirm the contribution of each component, and analyses show InvDec\u2019s advantage grows with dataset dimensionality, highlighting the importance of cross-variate modeling as variable count increases.", "conclusion": "A principled separation of temporal encoding and variate-level decoding enables effective cross-variate modeling without compromising temporal information. The approach scales favorably with dimensionality, suggesting cross-variable dependencies become increasingly crucial for accurate multivariate time series forecasting."}}
{"id": "2510.20558", "categories": ["cs.CV", "cs.GR", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.20558", "abs": "https://arxiv.org/abs/2510.20558", "authors": ["Xiaohan Sun", "Carol O'Sullivan"], "title": "From Far and Near: Perceptual Evaluation of Crowd Representations Across Levels of Detail", "comment": null, "summary": "In this paper, we investigate how users perceive the visual quality of crowd\ncharacter representations at different levels of detail (LoD) and viewing\ndistances. Each representation: geometric meshes, image-based impostors, Neural\nRadiance Fields (NeRFs), and 3D Gaussians, exhibits distinct trade-offs between\nvisual fidelity and computational performance. Our qualitative and quantitative\nresults provide insights to guide the design of perceptually optimized LoD\nstrategies for crowd rendering.", "AI": {"tldr": "The paper analyzes perceptual quality of crowd representations across LoD and viewing distances, comparing meshes, impostors, NeRFs, and 3D Gaussians, to derive perceptually driven LoD strategies for crowd rendering.", "motivation": "To design efficient, perceptually-optimized crowd rendering by understanding how different representations and viewing conditions affect perceived quality and performance.", "method": "Qualitative and quantitative experiments evaluating visual fidelity and computational cost across four representation types and multiple LoD levels and viewing distances; metrics likely include perceptual quality and runtime performance.", "result": "Each representation offers distinct trade-offs between fidelity and efficiency; findings quantify these trade-offs and indicate how to balance them for perceptual quality at target distances, enabling perceptually optimized LoD decisions.", "conclusion": "The work provides guidance for selecting representations and LoD settings to achieve perceptual quality goals while maintaining performance in crowd rendering."}}
{"id": "2510.20327", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20327", "abs": "https://arxiv.org/abs/2510.20327", "authors": ["Fengyuan Yu", "Yuyuan Li", "Xiaohua Feng", "Junjie Fang", "Tao Wang", "Chaochao Chen"], "title": "LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems", "comment": "Accepted by ACM Multimedia 2025", "summary": "With the growing demand for safeguarding sensitive user information in\nrecommender systems, recommendation attribute unlearning is receiving\nincreasing attention. Existing studies predominantly focus on single-attribute\nunlearning. However, privacy protection requirements in the real world often\ninvolve multiple sensitive attributes and are dynamic. Existing\nsingle-attribute unlearning methods cannot meet these real-world requirements\ndue to i) CH1: the inability to handle multiple unlearning requests\nsimultaneously, and ii) CH2: the lack of efficient adaptability to dynamic\nunlearning needs. To address these challenges, we propose LEGO, a lightweight\nand efficient multiple-attribute unlearning framework. Specifically, we divide\nthe multiple-attribute unlearning process into two steps: i) Embedding\nCalibration removes information related to a specific attribute from user\nembedding, and ii) Flexible Combination combines these embeddings into a single\nembedding, protecting all sensitive attributes. We frame the unlearning process\nas a mutual information minimization problem, providing LEGO a theoretical\nguarantee of simultaneous unlearning, thereby addressing CH1. With the two-step\nframework, where Embedding Calibration can be performed in parallel and\nFlexible Combination is flexible and efficient, we address CH2. Extensive\nexperiments on three real-world datasets across three representative\nrecommendation models demonstrate the effectiveness and efficiency of our\nproposed framework. Our code and appendix are available at\nhttps://github.com/anonymifish/lego-rec-multiple-attribute-unlearning.", "AI": {"tldr": "LEGO enables simultaneous multi-attribute unlearning in recommender systems with a two-step, parallelizable framework using mutual information minimization.", "motivation": "In real-world privacy, multiple sensitive attributes must be unlearned and adaptively managed; single-attribute methods cannot handle multiple or dynamic unlearning requests.", "method": "Two-step process: (i) Embedding Calibration removes attribute-related information from user embeddings; (ii) Flexible Combination fuses calibrated embeddings into a single protected embedding. The learning objective minimizes mutual information to guarantee simultaneous unlearning and supports parallelization.", "result": "Empirical results on three real-world datasets across three recommendation models demonstrate effectiveness and efficiency; code and appendix available.", "conclusion": "LEGO offers theoretical guarantees for simultaneous multi-attribute unlearning, supports dynamic adaptation, and is practical for deployment in real-world recommender systems."}}
{"id": "2510.20349", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20349", "abs": "https://arxiv.org/abs/2510.20349", "authors": ["Estelle Chigot", "Dennis G. Wilson", "Meriem Ghrib", "Fabrice Jimenez", "Thomas Oberlin"], "title": "Synthetic Data for Robust Runway Detection", "comment": null, "summary": "Deep vision models are now mature enough to be integrated in industrial and\npossibly critical applications such as autonomous navigation. Yet, data\ncollection and labeling to train such models requires too much efforts and\ncosts for a single company or product. This drawback is more significant in\ncritical applications, where training data must include all possible conditions\nincluding rare scenarios. In this perspective, generating synthetic images is\nan appealing solution, since it allows a cheap yet reliable covering of all the\nconditions and environments, if the impact of the synthetic-to-real\ndistribution shift is mitigated. In this article, we consider the case of\nrunway detection that is a critical part in autonomous landing systems\ndeveloped by aircraft manufacturers. We propose an image generation approach\nbased on a commercial flight simulator that complements a few annotated real\nimages. By controlling the image generation and the integration of real and\nsynthetic data, we show that standard object detection models can achieve\naccurate prediction. We also evaluate their robustness with respect to adverse\nconditions, in our case nighttime images, that were not represented in the real\ndata, and show the interest of using a customized domain adaptation strategy.", "AI": {"tldr": "Synthetic data from a flight simulator, combined with a small set of real labeled images and a custom domain adaptation strategy, enables accurate runway detection and robustness to nighttime conditions.", "motivation": "Data collection and labeling for deep vision models are costly, especially for critical applications requiring coverage of rare scenarios; synthetic data offers scalable coverage but risks a synthetic-to-real distribution shift.", "method": "Generate images with a commercial flight simulator to control conditions; augment with a few annotated real images; integrate real and synthetic data to train standard object detectors; apply a customized domain adaptation strategy to mitigate the synthetic-to-real gap; evaluate robustness under adverse nighttime conditions.", "result": "Standard object detection models trained with real+synthetic data achieve accurate runway predictions; robustness to nighttime conditions improves with the customized domain adaptation strategy, demonstrating viability of the approach.", "conclusion": "Synthetic data paired with targeted domain adaptation can reduce data collection costs while maintaining accuracy for runway detection, and the approach is promising for other critical perception tasks."}}
{"id": "2510.20579", "categories": ["cs.CV", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.20579", "abs": "https://arxiv.org/abs/2510.20579", "authors": ["Jiahao Meng", "Xiangtai Li", "Haochen Wang", "Yue Tan", "Tao Zhang", "Lingdong Kong", "Yunhai Tong", "Anran Wang", "Zhiyang Teng", "Yujing Wang", "Zhuochen Wang"], "title": "Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence", "comment": null, "summary": "Most video reasoning models only generate textual reasoning traces without\nindicating when and where key evidence appears. Recent models such as OpenAI-o3\nhave sparked wide interest in evidence-centered reasoning for images, yet\nextending this ability to videos is more challenging, as it requires joint\ntemporal tracking and spatial localization across dynamic scenes. We introduce\nOpen-o3 Video, a non-agent framework that integrates explicit spatio-temporal\nevidence into video reasoning, and carefully collect training data and design\ntraining strategies to address the aforementioned challenges. The model\nhighlights key timestamps, objects, and bounding boxes alongside its answers,\nallowing reasoning to be grounded in concrete visual observations. To enable\nthis functionality, we first curate and build two high-quality datasets,\nSTGR-CoT-30k for SFT and STGR-RL-36k for RL, with carefully constructed\ntemporal and spatial annotations, since most existing datasets offer either\ntemporal spans for videos or spatial boxes on images, lacking unified\nspatio-temporal supervision and reasoning traces. Then, we adopt a cold-start\nreinforcement learning strategy with multiple specially designed rewards that\njointly encourage answer accuracy, temporal alignment, and spatial precision.\nOn V-STAR benchmark, Open-o3 Video achieves state-of-the-art performance,\nraising mAM by 14.4% and mLGM by 24.2% on the Qwen2.5-VL baseline. Consistent\nimprovements are also observed on a broad range of video understanding\nbenchmarks, including VideoMME, WorldSense, VideoMMMU, and TVGBench. Beyond\naccuracy, the reasoning traces produced by Open-o3 Video also provide valuable\nsignals for test-time scaling, enabling confidence-aware verification and\nimproving answer reliability.", "AI": {"tldr": "Open-o3 Video introduces explicit spatio-temporal evidence for video reasoning with curated STGR datasets and a cold-start RL training strategy, achieving state-of-the-art results and producing grounding traces.", "motivation": "To bring evidence-centered reasoning to videos by providing unified spatio-temporal supervision and explicit visual traces, addressing the challenge of joint temporal tracking and spatial localization in dynamic scenes.", "method": "Non-agent Open-o3 Video framework that generates reasoning traces with key timestamps, objects, and bounding boxes; introduces STGR-CoT-30k (SFT) and STGR-RL-36k (RL) datasets with temporal and spatial annotations; uses cold-start reinforcement learning with rewards for accuracy, temporal alignment, and spatial precision.", "result": "State-of-the-art on the V-STAR benchmark (mAM +14.4%, mLGM +24.2% over Qwen2.5-VL baseline); consistent improvements across VideoMME, WorldSense, VideoMMMU, TVGBench; reasoning traces enable confidence-aware verification and improve answer reliability.", "conclusion": "Explicit spatio-temporal grounding in video reasoning can substantially improve accuracy and reliability, providing useful traces for test-time scaling and verification across a broad range of video understanding tasks."}}
{"id": "2510.20369", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20369", "abs": "https://arxiv.org/abs/2510.20369", "authors": ["Zhenghao Xu", "Qin Lu", "Qingru Zhang", "Liang Qiu", "Ilgee Hong", "Changlong Yu", "Wenlin Yao", "Yao Liu", "Haoming Jiang", "Lihong Li", "Hyokun Yun", "Tuo Zhao"], "title": "Ask a Strong LLM Judge when Your Reward Model is Uncertain", "comment": "NeurIPS 2025, 18 pages", "summary": "Reward model (RM) plays a pivotal role in reinforcement learning with human\nfeedback (RLHF) for aligning large language models (LLMs). However, classical\nRMs trained on human preferences are vulnerable to reward hacking and\ngeneralize poorly to out-of-distribution (OOD) inputs. By contrast, strong LLM\njudges equipped with reasoning capabilities demonstrate superior\ngeneralization, even without additional training, but incur significantly\nhigher inference costs, limiting their applicability in online RLHF. In this\nwork, we propose an uncertainty-based routing framework that efficiently\ncomplements a fast RM with a strong but costly LLM judge. Our approach\nformulates advantage estimation in policy gradient (PG) methods as pairwise\npreference classification, enabling principled uncertainty quantification to\nguide routing. Uncertain pairs are forwarded to the LLM judge, while confident\nones are evaluated by the RM. Experiments on RM benchmarks demonstrate that our\nuncertainty-based routing strategy significantly outperforms random judge\ncalling at the same cost, and downstream alignment results showcase its\neffectiveness in improving online RLHF.", "AI": {"tldr": "An uncertainty-driven routing framework blends a fast reward model (RM) with a costly but strong LLM judge for RLHF, routing uncertain instances to the LLM while fast cases stay with the RM to improve efficiency and alignment robustness.", "motivation": "Classical reward models trained on human preferences can be hacked and generalize poorly to out-of-distribution inputs, while strong LLM judges excel at generalization but are too costly for online RLHF. A hybrid, uncertainty-aware approach aims to get the best of both worlds.", "method": "Formulate the policy-gradient advantage estimation as a pairwise preference classification and use principled uncertainty quantification to route uncertain preference pairs to the LLM judge; confident pairs are evaluated by the fast RM, while uncertain ones are escalated to the costly LLM judge.", "result": "Empirical results on RM benchmarks show the uncertainty-based routing outperforms random judge calling at the same cost, and downstream alignment improves in online RLHF.", "conclusion": "An uncertainty-guided routing framework effectively combines a fast RM with a strong but costly LLM judge, achieving improved efficiency and alignment robustness in online RLHF; the approach is validated on RM benchmarks and downstream tasks."}}
{"id": "2510.20586", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20586", "abs": "https://arxiv.org/abs/2510.20586", "authors": ["Muhammad Atif Butt", "Alexandra Gomez-Villa", "Tao Wu", "Javier Vazquez-Corral", "Joost Van De Weijer", "Kai Wang"], "title": "GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models", "comment": null, "summary": "Recent years have seen impressive advances in text-to-image generation, with\nimage generative or unified models producing high-quality images from text. Yet\nthese models still struggle with fine-grained color controllability, often\nfailing to accurately match colors specified in text prompts. While existing\nbenchmarks evaluate compositional reasoning and prompt adherence, none\nsystematically assess color precision. Color is fundamental to human visual\nperception and communication, critical for applications from art to design\nworkflows requiring brand consistency. However, current benchmarks either\nneglect color or rely on coarse assessments, missing key capabilities such as\ninterpreting RGB values or aligning with human expectations. To this end, we\npropose GenColorBench, the first comprehensive benchmark for text-to-image\ncolor generation, grounded in color systems like ISCC-NBS and CSS3/X11,\nincluding numerical colors which are absent elsewhere. With 44K color-focused\nprompts covering 400+ colors, it reveals models' true capabilities via\nperceptual and automated assessments. Evaluations of popular text-to-image\nmodels using GenColorBench show performance variations, highlighting which\ncolor conventions models understand best and identifying failure modes. Our\nGenColorBench assessments will guide improvements in precise color generation.\nThe benchmark will be made public upon acceptance.", "AI": {"tldr": "GenColorBench \u2013 the first comprehensive benchmark for text-to-image color generation. It uses ISCC-NBS and CSS3/X11 color systems with 44K prompts spanning 400+ colors to assess perceptual and automated color accuracy, revealing model strengths, weaknesses, and color-convention comprehension; public upon acceptance.", "motivation": "Color precision is critical in art, design, and branding, yet current T2I benchmarks neglect fine-grained color control and numerical color prompts. A dedicated benchmark is needed to quantify how well models interpret and reproduce specified colors.", "method": "Ground prompts in established color systems (ISCC-NBS, CSS3/X11), include numeric color specifications, assemble ~44K color-focused prompts covering 400+ colors, and evaluate models with perceptual and automated color metrics to assess adherence and human-aligned expectations; analyze which conventions models understand best and identify common failure modes.", "result": "Preliminary evaluations show performance variability across color conventions, indicating some colors and systems are better understood by current models; the benchmark exposes failure modes and gaps in color precision not captured by existing benchmarks.", "conclusion": "GenColorBench addresses a critical gap in evaluating precise color generation in text-to-image models and is expected to guide targeted improvements; the benchmark will be public upon acceptance."}}
{"id": "2510.20383", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20383", "abs": "https://arxiv.org/abs/2510.20383", "authors": ["Shuhei Aikawa", "Aru Suzuki", "Kei Yoshitake", "Kanata Teshigawara", "Akira Iwabuchi", "Ken Kobayashi", "Kazuhide Nakata"], "title": "Hierarchical Time Series Forecasting with Robust Reconciliation", "comment": null, "summary": "This paper focuses on forecasting hierarchical time-series data, where each\nhigher-level observation equals the sum of its corresponding lower-level time\nseries. In such contexts, the forecast values should be coherent, meaning that\nthe forecast value of each parent series exactly matches the sum of the\nforecast values of its child series. Existing hierarchical forecasting methods\ntypically generate base forecasts independently for each series and then apply\na reconciliation procedure to adjust them so that the resulting forecast values\nare coherent across the hierarchy. These methods generally derive an optimal\nreconciliation, using a covariance matrix of the forecast error. In practice,\nhowever, the true covariance matrix is unknown and has to be estimated from\nfinite samples in advance. This gap between the true and estimated covariance\nmatrix may degrade forecast performance. To address this issue, we propose a\nrobust optimization framework for hierarchical reconciliation that accounts for\nuncertainty in the estimated covariance matrix. We first introduce an\nuncertainty set for the estimated covariance matrix and formulate a\nreconciliation problem that minimizes the worst-case expected squared error\nover this uncertainty set. We show that our problem can be cast as a\nsemidefinite optimization problem. Numerical experiments demonstrate that the\nproposed robust reconciliation method achieved better forecast performance than\nexisting hierarchical forecasting methods, which indicates the effectiveness of\nintegrating uncertainty into the reconciliation process.", "AI": {"tldr": "Proposes a robust hierarchical forecast reconciliation under covariance uncertainty using semidefinite programming; improves forecast accuracy by accounting for estimation error.", "motivation": "Hierarchical time-series forecasts require coherent sums; standard reconciliation relies on a known covariance of forecast errors; in practice this covariance is unknown and estimated with error, which can hurt performance.", "method": "Define an uncertainty set for the estimated covariance; formulate a worst-case minimization of expected squared error; recast as semidefinite program for tractable solution.", "result": "Numerical experiments show the robust method outperforms traditional reconciliation methods that ignore covariance uncertainty.", "conclusion": "Incorporating uncertainty into the reconciliation process yields more robust forecasts in hierarchical time-series settings."}}
{"id": "2510.20596", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20596", "abs": "https://arxiv.org/abs/2510.20596", "authors": ["Ziyu Ye", "Chen Ju", "Chaofan Ma", "Xiaoyun Zhang"], "title": "Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation", "comment": "MICCAI 2021", "summary": "Deep learning models have achieved great success on various vision\nchallenges, but a well-trained model would face drastic performance degradation\nwhen applied to unseen data. Since the model is sensitive to domain shift,\nunsupervised domain adaptation attempts to reduce the domain gap and avoid\ncostly annotation of unseen domains. This paper proposes a novel framework for\ncross-modality segmentation via similarity-based prototypes. In specific, we\nlearn class-wise prototypes within an embedding space, then introduce a\nsimilarity constraint to make these prototypes representative for each semantic\nclass while separable from different classes. Moreover, we use dictionaries to\nstore prototypes extracted from different images, which prevents the\nclass-missing problem and enables the contrastive learning of prototypes, and\nfurther improves performance. Extensive experiments show that our method\nachieves better results than other state-of-the-art methods.", "AI": {"tldr": "A cross-modality unsupervised domain adaptation framework that learns class-wise prototypes in an embedding space, enforces similarity-based constraints, and uses dictionaries of prototypes across images to enable contrastive learning, achieving state-of-the-art results.", "motivation": "Deep models fail under domain shift; unsupervised domain adaptation is needed for cross-modality segmentation to bridge the gap between source and unseen target domains without extra annotations.", "method": "Learn class-wise prototypes in a learned embedding space; apply similarity constraints to make prototypes representative for their class and separable from others; maintain dictionaries of prototypes extracted from multiple images to prevent class-missing and enable prototype-level contrastive learning.", "result": "Experimental results show our method achieves better performance than existing state-of-the-art methods on cross-modality segmentation tasks.", "conclusion": "Similarity-based prototype learning with dictionary-powered prototype storage effectively improves cross-modality unsupervised domain adaptation by promoting representative, separable class prototypes and robust contrastive learning."}}
{"id": "2510.20387", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20387", "abs": "https://arxiv.org/abs/2510.20387", "authors": ["Baoqing Yue", "Jinyuan Zhou", "Zixi Wei", "Jingtao Zhan", "Qingyao Ai", "Yiqun Liu"], "title": "Relative-Based Scaling Law for Neural Language Models", "comment": null, "summary": "Scaling laws aim to accurately predict model performance across different\nscales. Existing scaling-law studies almost exclusively rely on cross-entropy\nas the evaluation metric. However, cross-entropy provides only a partial view\nof performance: it measures the absolute probability assigned to the correct\ntoken, but ignores the relative ordering between correct and incorrect tokens.\nYet, relative ordering is crucial for language models, such as in\ngreedy-sampling scenario. To address this limitation, we investigate scaling\nfrom the perspective of relative ordering. We first propose the Relative-Based\nProbability (RBP) metric, which quantifies the probability that the correct\ntoken is ranked among the top predictions. Building on this metric, we\nestablish the Relative-Based Scaling Law, which characterizes how RBP improves\nwith increasing model size. Through extensive experiments on four datasets and\nfour model families spanning five orders of magnitude, we demonstrate the\nrobustness and accuracy of this law. Finally, we illustrate the broad\napplication of this law with two examples, namely providing a deeper\nexplanation of emergence phenomena and facilitating finding fundamental\ntheories of scaling laws. In summary, the Relative-Based Scaling Law\ncomplements the cross-entropy perspective and contributes to a more complete\nunderstanding of scaling large language models. Thus, it offers valuable\ninsights for both practical development and theoretical exploration.", "AI": {"tldr": "Introduces Relative-Based Probability (RBP) and its Relative-Based Scaling Law as a ranking-based complement to cross-entropy for evaluating language model performance; validated across diverse datasets and model families, with applications to emergence and theory discovery.", "motivation": "Cross-entropy only measures absolute probability of the correct token and ignores the relative ordering among tokens. A metric capturing ranking of the correct token among top predictions can better reflect practical settings like greedy sampling and provide deeper scaling insights.", "method": "Define the Relative-Based Probability (RBP) metric to measure the likelihood that the correct token ranks among the top predictions. Derive the Relative-Based Scaling Law describing how RBP improves with model size. Validate the law through extensive experiments on four datasets and four model families spanning five orders of magnitude, and demonstrate two broad applications.", "result": "The Relative-Based Scaling Law shows robust, accurate scaling of RBP with model size across diverse settings; RBP increases as models scale, offering a complementary perspective to cross-entropy for understanding model performance and scaling.", "conclusion": "RBP-based scaling provides a complementary lens to cross-entropy, enriching practical development and theoretical exploration of scaling laws and emergence phenomena in large language models."}}
{"id": "2510.20605", "categories": ["cs.CV", "cs.AI", "I.4.5; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.20605", "abs": "https://arxiv.org/abs/2510.20605", "authors": ["Mark He Huang", "Lin Geng Foo", "Christian Theobalt", "Ying Sun", "De Wen Soh"], "title": "OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects", "comment": "NeurIPS 2025 (Spotlight)", "summary": "Free-moving object reconstruction from monocular video remains challenging,\nparticularly without reliable pose or depth cues and under arbitrary object\nmotion. We introduce OnlineSplatter, a novel online feed-forward framework\ngenerating high-quality, object-centric 3D Gaussians directly from RGB frames\nwithout requiring camera pose, depth priors, or bundle optimization. Our\napproach anchors reconstruction using the first frame and progressively refines\nthe object representation through a dense Gaussian primitive field, maintaining\nconstant computational cost regardless of video sequence length. Our core\ncontribution is a dual-key memory module combining latent appearance-geometry\nkeys with explicit directional keys, robustly fusing current frame features\nwith temporally aggregated object states. This design enables effective\nhandling of free-moving objects via spatial-guided memory readout and an\nefficient sparsification mechanism, ensuring comprehensive yet compact object\ncoverage. Evaluations on real-world datasets demonstrate that OnlineSplatter\nsignificantly outperforms state-of-the-art pose-free reconstruction baselines,\nconsistently improving with more observations while maintaining constant memory\nand runtime.", "AI": {"tldr": "OnlineSplatter proposes a real-time, pose-free monocular object reconstruction framework that represents the object with a dense field of 3D Gaussian primitives, learned online from RGB frames using a dual-key memory, achieving constant memory/time independent of sequence length while progressively refining from the first frame.", "motivation": "Reconstructing moving objects from monocular video without reliable pose or depth cues is highly challenging and currently limits practical applications. There is a need for online, setup-free methods that deliver high-quality 3D object representations with predictable efficiency.", "method": "The approach anchors on the first frame and builds a dense Gaussian primitive field for the object. It uses an online feed-forward network with a dual-key memory module (latent appearance-geometry keys plus explicit directional keys) to fuse current frame features with temporally aggregated object states. A spatial-guided memory readout and sparsification enable complete yet compact coverage. Computational cost remains constant with respect to sequence length.", "result": "On real-world datasets, OnlineSplatter outperforms pose-free reconstruction baselines, with performance improving as more frames are observed, while memory and runtime stay constant.", "conclusion": "The method enables robust, online, pose-free 3D object reconstruction from RGB video, maintaining efficiency and improving with more observations through a dual-key memory and Gaussian primitive representation."}}
{"id": "2510.20408", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.20408", "abs": "https://arxiv.org/abs/2510.20408", "authors": ["Tom Maus", "Asma Atamna", "Tobias Glasmachers"], "title": "Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control", "comment": "Preprint (submitted version) to be presented at the 13th\n  International Conference on Industrial Engineering and Applications\n  (ICIEA-EU), Milan, 2026. The final Version of Record will appear in the\n  official conference proceedings", "summary": "Autonomous control of multi-stage industrial processes requires both local\nspecialization and global coordination. Reinforcement learning (RL) offers a\npromising approach, but its industrial adoption remains limited due to\nchallenges such as reward design, modularity, and action space management. Many\nacademic benchmarks differ markedly from industrial control problems, limiting\ntheir transferability to real-world applications. This study introduces an\nenhanced industry-inspired benchmark environment that combines tasks from two\nexisting benchmarks, SortingEnv and ContainerGym, into a sequential recycling\nscenario with sorting and pressing operations. We evaluate two control\nstrategies: a modular architecture with specialized agents and a monolithic\nagent governing the full system, while also analyzing the impact of action\nmasking. Our experiments show that without action masking, agents struggle to\nlearn effective policies, with the modular architecture performing better. When\naction masking is applied, both architectures improve substantially, and the\nperformance gap narrows considerably. These results highlight the decisive role\nof action space constraints and suggest that the advantages of specialization\ndiminish as action complexity is reduced. The proposed benchmark thus provides\na valuable testbed for exploring practical and robust multi-agent RL solutions\nin industrial automation, while contributing to the ongoing debate on\ncentralization versus specialization.", "AI": {"tldr": "Introduces an industry-inspired benchmark combining SortingEnv and ContainerGym into a sequential recycling task and compares modular vs monolithic RL controllers, showing action masking is a key enabler and that specialization benefits shrink as action complexity is reduced.", "motivation": "Address the gap between academic RL benchmarks and real industrial control problems by creating a realistic, multi-stage benchmark that emphasizes modularity, reward design, and action space management; investigate centralization vs specialization in control policies.", "method": "Create an enhanced benchmark environment that merges two existing benchmarks into a sequential process with sorting and pressing. Evaluate two control strategies: a modular multi-agent architecture with specialized agents and a single monolithic agent; analyze the impact of action masking on learning performance.", "result": "Without action masking, the modular architecture learns policies better than the monolithic agent. With action masking, both architectures improve substantially and the performance gap narrows. Action space constraints prove decisive for practical learning and suggest specialization advantages diminish with reduced action complexity.", "conclusion": "The benchmark provides a valuable testbed for practical multi-agent RL in industrial automation and informs the ongoing debate on centralization versus specialization, highlighting the crucial role of action masking in enabling learning and the context-dependent value of specialization."}}
{"id": "2510.20622", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20622", "abs": "https://arxiv.org/abs/2510.20622", "authors": ["Yuan Sheng", "Yanbin Hao", "Chenxu Li", "Shuo Wang", "Xiangnan He"], "title": "SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding", "comment": null, "summary": "Long video understanding remains challenging due to its complex, diverse, and\ntemporally scattered content. Although video large language models (Video-LLMs)\ncan process videos lasting tens of minutes, applying them to truly long\nsequences is computationally prohibitive and often leads to unfocused or\ninconsistent reasoning. A promising solution is to select only the most\ninformative frames, yet existing approaches typically ignore temporal\ndependencies or rely on unimodal evidence, limiting their ability to provide\ncomplete and query-relevant context. We propose a Semantic-Visual Consensus\nEvidence Selection (SeViCES) framework for effective and reliable long video\nunderstanding. SeViCES is training-free and model-agnostic, and introduces two\nkey components. The Semantic-Visual Consensus Frame Selection (SVCFS) module\nselects frames through (1) a temporal-aware semantic branch that leverages LLM\nreasoning over captions, and (2) a cluster-guided visual branch that aligns\nembeddings with semantic scores via mutual information. The Answer Consensus\nRefinement (ACR) module further resolves inconsistencies between semantic- and\nvisual-based predictions by fusing evidence and constraining the answer space.\nExtensive experiments on long video understanding benchmarks show that SeViCES\nconsistently outperforms state-of-the-art methods in both accuracy and\nrobustness, demonstrating the importance of consensus-driven evidence selection\nfor Video-LLMs.", "AI": {"tldr": "SeViCES is a training-free, model-agnostic framework that improves long video understanding by consensus-based evidence selection. It combines a temporal-aware semantic frame-selection module (LLM reasoning over captions) with a cluster-guided visual module (MI-aligned embeddings) and an Answer Consensus Refinement to fuse semantic/visual evidence and constrain answers, yielding state-of-the-art accuracy and robustness on long-video benchmarks.", "motivation": "Long videos pose challenges due to computationally expensive Video-LLMs and the need for coherent reasoning over temporally scattered content. Existing frame-selection methods often disregard temporal dependencies or rely on unimodal cues, leading to incomplete and inconsistent answers.", "method": "SeViCES comprises two main components. (1) Semantic-Visual Consensus Frame Selection (SVCFS): a temporal-aware semantic branch that uses LLM reasoning over captions and a cluster-guided visual branch that aligns embeddings with semantic scores via mutual information to select informative frames. (2) Answer Consensus Refinement (ACR): fuses semantic- and visual-based predictions and constrains the answer space to resolve inconsistencies. The approach is training-free and model-agnostic.", "result": "Extensive experiments on long video understanding benchmarks show that SeViCES consistently outperforms state-of-the-art methods in both accuracy and robustness, demonstrating the value of consensus-driven evidence selection for Video-LLMs.", "conclusion": "Consensus-driven evidence selection is crucial for reliable long video understanding with Video-LLMs. SeViCES provides an effective, training-free framework that improves accuracy and robustness by integrating semantic and visual cues and refining answers."}}
{"id": "2510.20413", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20413", "abs": "https://arxiv.org/abs/2510.20413", "authors": ["Aditya Gopalan", "Sayak Ray Chowdhury", "Debangshu Banerjee"], "title": "Why DPO is a Misspecified Estimator and How to Fix It", "comment": null, "summary": "Direct alignment algorithms such as Direct Preference Optimization (DPO)\nfine-tune models based on preference data, using only supervised learning\ninstead of two-stage reinforcement learning with human feedback (RLHF). We show\nthat DPO encodes a statistical estimation problem over reward functions induced\nby a parametric policy class. When the true reward function that generates\npreferences cannot be realized via the policy class, DPO becomes misspecified,\nresulting in failure modes such as preference order reversal, worsening of\npolicy reward, and high sensitivity to the input preference data distribution.\nOn the other hand, we study the local behavior of two-stage RLHF for a\nparametric class and relate it to a natural gradient step in policy space. Our\nfine-grained geometric characterization allows us to propose AuxDPO, which\nintroduces additional auxiliary variables in the DPO loss function to help move\ntowards the RLHF solution in a principled manner and mitigate the\nmisspecification in DPO. We empirically demonstrate the superior performance of\nAuxDPO on didactic bandit settings as well as LLM alignment tasks.", "AI": {"tldr": "Direct Preference Optimization (DPO) can be misspecified when the true reward function cannot be realized by the policy class, leading to failure modes like preference reversals and sensitivity to data; the authors propose AuxDPO, adding auxiliary variables to align with RLHF, with empirical gains on bandit tasks and LLM alignment.", "motivation": "To understand why supervised DPO can underperform RLHF in aligning models, identify misspecification modes, and develop a principled fix that bridges DPO and RLHF.", "method": "Treat DPO as a statistical estimation of reward functions induced by a parametric policy class; analyze the local behavior of two-stage RLHF as a natural gradient step in policy space; propose AuxDPO by introducing auxiliary variables into the DPO loss to move toward the RLHF solution; validate with experiments on didactic bandit settings and large language model alignment tasks.", "result": "Characterizes misspecification-driven failure modes in DPO (preference reversal, reward degradation, input distribution sensitivity) and demonstrates that AuxDPO mitigates these issues and achieves superior performance in the tested tasks.", "conclusion": "Misspecification is a key weakness of DPO; AuxDPO provides a principled mechanism to mitigate this gap and better approximate RLHF outcomes, improving alignment performance."}}
{"id": "2510.20634", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20634", "abs": "https://arxiv.org/abs/2510.20634", "authors": ["Zhenhuan Zhou", "Jingbo Zhu", "Yuchen Zhang", "Xiaohang Guan", "Peng Wang", "Tao Li"], "title": "Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges", "comment": "52 pages, 24 figures. Under Review", "summary": "Efficient analysis and processing of dental images are crucial for dentists\nto achieve accurate diagnosis and optimal treatment planning. However, dental\nimaging inherently poses several challenges, such as low contrast, metallic\nartifacts, and variations in projection angles. Combined with the subjectivity\narising from differences in clinicians' expertise, manual interpretation often\nproves time-consuming and prone to inconsistency. Artificial intelligence\n(AI)-based automated dental image analysis (DIA) offers a promising solution to\nthese issues and has become an integral part of computer-aided dental diagnosis\nand treatment. Among various AI technologies, deep learning (DL) stands out as\nthe most widely applied and influential approach due to its superior feature\nextraction and representation capabilities. To comprehensively summarize recent\nprogress in this field, we focus on the two fundamental aspects of DL\nresearch-datasets and models. In this paper, we systematically review 260\nstudies on DL applications in DIA, including 49 papers on publicly available\ndental datasets and 211 papers on DL-based algorithms. We first introduce the\nbasic concepts of dental imaging and summarize the characteristics and\nacquisition methods of existing datasets. Then, we present the foundational\ntechniques of DL and categorize relevant models and algorithms according to\ndifferent DIA tasks, analyzing their network architectures, optimization\nstrategies, training methods, and performance. Furthermore, we summarize\ncommonly used training and evaluation metrics in the DIA domain. Finally, we\ndiscuss the current challenges of existing research and outline potential\nfuture directions. We hope that this work provides a valuable and systematic\nreference for researchers in this field. All supplementary materials and\ndetailed comparison tables will be made publicly available on GitHub.", "AI": {"tldr": "A systematic review of deep learning in dental image analysis (DIA), synthesizing 260 studies: 49 public datasets and 211 DL-based algorithms; catalogs datasets, models, tasks, metrics; discusses challenges and future directions; GitHub resources.", "motivation": "Dental imaging faces low contrast, artifacts, projection-angle variability; clinical subjectivity; AI-based DIA can improve accuracy and efficiency; comprehensive synthesis needed to guide research and practice.", "method": "Systematic review of 260 studies on DL in DIA; categorizes datasets by acquisition and characteristics; analyzes models by DIA tasks; examines architectures, optimization, training strategies; summarizes training and evaluation metrics; discusses challenges and future directions; supplementary materials and comparison tables publicly available on GitHub.", "result": "Provides a structured taxonomy of models and tasks, summarizes dataset characteristics and performance trends, highlights commonly used metrics, and identifies key challenges (data availability, standardization, generalization, artifacts).", "conclusion": "The review serves as a valuable reference for researchers; outlines current challenges and potential future directions in DIA DL research; provides public resources to facilitate further work."}}
{"id": "2510.20414", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20414", "abs": "https://arxiv.org/abs/2510.20414", "authors": ["Sishun Liu", "Ke Deng", "Xiuzhen Zhang", "Yongli Ren", "Yan Wang"], "title": "Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes", "comment": "NeurIPS 2025 poster", "summary": "Marked Temporal Point Process (MTPP) has been well studied to model the event\ndistribution in marked event streams, which can be used to predict the mark and\narrival time of the next event. However, existing studies overlook that the\ndistribution of event marks is highly imbalanced in many real-world\napplications, with some marks being frequent but others rare. The imbalance\nposes a significant challenge to the performance of the next event prediction,\nespecially for events of rare marks. To address this issue, we propose a\nthresholding method, which learns thresholds to tune the mark probability\nnormalized by the mark's prior probability to optimize mark prediction, rather\nthan predicting the mark directly based on the mark probability as in existing\nstudies. In conjunction with this method, we predict the mark first and then\nthe time. In particular, we develop a novel neural MTPP model to support\neffective time sampling and estimation of mark probability without\ncomputationally expensive numerical improper integration. Extensive experiments\non real-world datasets demonstrate the superior performance of our solution\nagainst various baselines for the next event mark and time prediction. The code\nis available at https://github.com/undes1red/IFNMTPP.", "AI": {"tldr": "A thresholding-based approach tackles imbalanced marks in Marked Temporal Point Processes (MTPP) by recalibrating mark probabilities with class priors, predicting the mark first and then the time, and employing a neural MTPP model that enables efficient time sampling without costly numerical integration; it achieves superior next-event mark and time prediction on real datasets, with code available.", "motivation": "In real-world event streams, the distribution over marks is highly imbalanced, causing poor prediction for rare marks when using standard MTPP models that predict marks directly from raw probabilities. This imbalance motivates a method that decouples prediction from priors and focuses on optimizing calibrated mark prediction rather than raw probability.", "method": "Introduce a thresholding mechanism that learns thresholds to adjust the raw mark probability using the mark's prior probability, effectively normalizing by class priors to optimize the correct mark prediction. The model first predicts the mark and then the arrival time. Develop a neural MTPP framework that supports efficient time sampling and accurate estimation of mark probabilities without expensive numerical improper integration.", "result": "Extensive experiments on real-world datasets show superior performance of the proposed method against various baselines for both next-event mark and time prediction.", "conclusion": "The proposed thresholding-driven MTPP approach mitigates the adverse effects of mark imbalance, improving predictive accuracy for both the next-event mark and its timestamp; the method is validated on real data and code is publicly available."}}
{"id": "2510.20639", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20639", "abs": "https://arxiv.org/abs/2510.20639", "authors": ["Ibrahim Ethem Hamamci", "Sezgin Er", "Suprosanna Shit", "Hadrien Reynaud", "Dong Yang", "Pengfei Guo", "Marc Edgar", "Daguang Xu", "Bernhard Kainz", "Bjoern Menze"], "title": "Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging", "comment": "NeurIPS 2025", "summary": "Recent progress in vision-language modeling for 3D medical imaging has been\nfueled by large-scale computed tomography (CT) corpora with paired free-text\nreports, stronger architectures, and powerful pretrained models. This has\nenabled applications such as automated report generation and text-conditioned\n3D image synthesis. Yet, current approaches struggle with high-resolution,\nlong-sequence volumes: contrastive pretraining often yields vision encoders\nthat are misaligned with clinical language, and slice-wise tokenization blurs\nfine anatomy, reducing diagnostic performance on downstream tasks. We introduce\nBTB3D (Better Tokens for Better 3D), a causal convolutional encoder-decoder\nthat unifies 2D and 3D training and inference while producing compact,\nfrequency-aware volumetric tokens. A three-stage training curriculum enables\n(i) local reconstruction, (ii) overlapping-window tiling, and (iii)\nlong-context decoder refinement, during which the model learns from short slice\nexcerpts yet generalizes to scans exceeding 300 slices without additional\nmemory overhead. BTB3D sets a new state-of-the-art on two key tasks: it\nimproves BLEU scores and increases clinical F1 by 40% over CT2Rep, CT-CHAT, and\nMerlin for report generation; and it reduces FID by 75% and halves FVD compared\nto GenerateCT and MedSyn for text-to-CT synthesis, producing anatomically\nconsistent 512*512*241 volumes. These results confirm that precise\nthree-dimensional tokenization, rather than larger language backbones alone, is\nessential for scalable vision-language modeling in 3D medical imaging. The\ncodebase is available at: https://github.com/ibrahimethemhamamci/BTB3D", "AI": {"tldr": "BTB3D introduces compact, frequency-aware 3D tokens via a causal conv encoder-decoder and a three-stage training curriculum to unify 2D/3D training, achieving state-of-the-art in CT report generation and text-to-CT synthesis.", "motivation": "To address misalignment between vision encoders and clinical language and the loss of anatomical detail from slice-wise tokenization when modeling long, high-resolution 3D CT scans for vision-language tasks.", "method": "A causal convolutional encoder-decoder BTB3D that produces volumetric tokens; three-stage training: local reconstruction, overlapping-window tiling, long-context decoder refinement; handles >300 slices with no extra memory overhead; unifies 2D/3D training and inference.", "result": "State-of-the-art improvements: report generation with BLEU/clinical F1 up ~40% over baselines (CT2Rep, CT-CHAT, Merlin); text-to-CT synthesis: FID reduced by ~75% and FVD halved vs GenerateCT/MedSyn; anatomically consistent 512x512x241 volumes; generalizes to >300 slices.", "conclusion": "Precise 3D tokenization is essential for scalable vision-language modeling in 3D medical imaging; relying on larger language backbones alone is insufficient; release code at GitHub."}}
{"id": "2510.20428", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20428", "abs": "https://arxiv.org/abs/2510.20428", "authors": ["Xuran Li", "Jingyi Wang"], "title": "An Empirical Study of Sample Selection Strategies for Large Language Model Repair", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed in real-world systems,\nyet they can produce toxic or biased outputs that undermine safety and trust.\nPost-hoc model repair provides a practical remedy, but the high cost of\nparameter updates motivates selective use of repair data. Despite extensive\nprior work on data selection for model training, it remains unclear which\nsampling criteria are most effective and efficient when applied specifically to\nbehavioral repair of large generative models. Our study presents a systematic\nanalysis of sample prioritization strategies for LLM repair. We evaluate five\nrepresentative selection methods, including random sampling, K-Center,\ngradient-norm-based selection(GraNd), stratified coverage (CCS), and a\nSemantic-Aware Prioritized Sampling (SAPS) approach we proposed. Repair\neffectiveness and trade-offs are assessed through toxicity reduction,\nperplexity on WikiText-2 and LAMBADA, and three composite metrics: the Repair\nProximity Score (RPS), the Overall Performance Score (OPS), and the Repair\nEfficiency Score (RES). Experimental results show that SAPS achieves the best\nbalance between detoxification, utility preservation, and efficiency,\ndelivering comparable or superior repair outcomes with substantially less data.\nRandom sampling remains effective for large or robust models, while\nhigh-overhead methods such as CCS and GraNd provide limited benefit. The\noptimal data proportion depends on model scale and repair method, indicating\nthat sample selection should be regarded as a tunable component of repair\npipelines. Overall, these findings establish selection-based repair as an\nefficient and scalable paradigm for maintaining LLM reliability.", "AI": {"tldr": "SAPS (Semantic-Aware Prioritized Sampling) bests other data-selection methods for LLM repair, achieving strong detoxification with less data; random sampling works well for very large/robust models; CCS and GraNd offer limited gains; optimal data amount depends on model size and method.", "motivation": "To reduce the cost of post-hoc LLM repair by selectively choosing repair data, enabling effective toxicity removal and behavior alignment without heavy parameter updates.", "method": "Systematic comparison of five sampling strategies (Random, K-Center, GraNd, CCS, SAPS) for behavioral repair of LLMs. Evaluation metrics include toxicity reduction, perplexity on WikiText-2 and LAMBADA, and composite scores (RPS, OPS, RES). Experiments across model scales to assess trade-offs between repair effectiveness and data efficiency.", "result": "SAPS achieves the best balance among detoxification, utility preservation, and efficiency, delivering repair outcomes comparable or superior to baselines with substantially less data. Random sampling remains competitive for large/robust models. CCS and GraNd yield limited improvements. The optimal data proportion is model-scale and method dependent.", "conclusion": "Selection-based repair is a scalable, efficient paradigm for maintaining LLM reliability. Data sampling should be tuned as part of repair pipelines to optimize toxicity reduction and utility retention while minimizing data and computational costs."}}
{"id": "2510.20661", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20661", "abs": "https://arxiv.org/abs/2510.20661", "authors": ["Chen Zhao", "En Ci", "Yunzhe Xu", "Tiehan Fan", "Shanyan Guan", "Yanhao Ge", "Jian Yang", "Ying Tai"], "title": "UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset", "comment": "Accepted by NeurIPS 2025", "summary": "Ultra-high-resolution (UHR) text-to-image (T2I) generation has seen notable\nprogress. However, two key challenges remain : 1) the absence of a large-scale\nhigh-quality UHR T2I dataset, and (2) the neglect of tailored training\nstrategies for fine-grained detail synthesis in UHR scenarios. To tackle the\nfirst challenge, we introduce \\textbf{UltraHR-100K}, a high-quality dataset of\n100K UHR images with rich captions, offering diverse content and strong visual\nfidelity. Each image exceeds 3K resolution and is rigorously curated based on\ndetail richness, content complexity, and aesthetic quality. To tackle the\nsecond challenge, we propose a frequency-aware post-training method that\nenhances fine-detail generation in T2I diffusion models. Specifically, we\ndesign (i) \\textit{Detail-Oriented Timestep Sampling (DOTS)} to focus learning\non detail-critical denoising steps, and (ii) \\textit{Soft-Weighting Frequency\nRegularization (SWFR)}, which leverages Discrete Fourier Transform (DFT) to\nsoftly constrain frequency components, encouraging high-frequency detail\npreservation. Extensive experiments on our proposed UltraHR-eval4K benchmarks\ndemonstrate that our approach significantly improves the fine-grained detail\nquality and overall fidelity of UHR image generation. The code is available at\n\\href{https://github.com/NJU-PCALab/UltraHR-100k}{here}.", "AI": {"tldr": "Introduces UltraHR-100K, a 100k high-quality ultra-high-resolution image-text dataset, and a frequency-aware post-training approach with DOTS and SWFR to improve fine-grained detail in text-to-image diffusion models; experiments show improved detail and fidelity; code released.", "motivation": "To address two main gaps in UHR T2I: (1) the lack of a large-scale, high-quality UHR T2I dataset, and (2) the need for training strategies that enhance fine-grained detail synthesis in UHR generation.", "method": "Dataset: UltraHR-100K with >3K resolution and rich captions. Post-training methods: (i) DOTS\u2014Detail-Oriented Timestep Sampling to emphasize detail-critical denoising steps; (ii) SWFR\u2014Soft-Weighting Frequency Regularization using Discrete Fourier Transform to softly constrain high-frequency components and preserve details.", "result": "Extensive experiments on UltraHR-eval4K benchmarks show significant improvements in fine-grained detail quality and overall image fidelity in UHR T2I generation; code available at the provided GitHub link.", "conclusion": "The combination of a high-quality UHR dataset and a frequency-aware post-training strategy effectively enhances fine-grained detail synthesis in UHR text-to-image diffusion models and sets a resource for future research."}}
{"id": "2510.20448", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20448", "abs": "https://arxiv.org/abs/2510.20448", "authors": ["Xuan Lin", "Aocheng Ding", "Tengfei Ma", "Hua Liang", "Zhe Quan"], "title": "MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction", "comment": null, "summary": "Drug combinations offer therapeutic benefits but also carry the risk of\nadverse drug-drug interactions (DDIs), especially under complex molecular\nstructures. Accurate DDI event prediction requires capturing fine-grained\ninter-drug relationships, which are critical for modeling metabolic mechanisms\nsuch as enzyme-mediated competition. However, existing approaches typically\nrely on isolated drug representations and fail to explicitly model atom-level\ncross-molecular interactions, limiting their effectiveness across diverse\nmolecular complexities and DDI type distributions. To address these\nlimitations, we propose MolBridge, a novel atom-level joint graph refinement\nframework for robust DDI event prediction. MolBridge constructs a joint graph\nthat integrates atomic structures of drug pairs, enabling direct modeling of\ninter-drug associations. A central challenge in such joint graph settings is\nthe potential loss of information caused by over-smoothing when modeling\nlong-range atomic dependencies. To overcome this, we introduce a structure\nconsistency module that iteratively refines node features while preserving the\nglobal structural context. This joint design allows MolBridge to effectively\nlearn both local and global interaction outperforms state-of-the-art baselines,\nachieving superior performance across long-tail and inductive scenarios.\npatterns, yielding robust representations across both frequent and rare DDI\ntypes. Extensive experiments on two benchmark datasets show that MolBridge\nconsistently. These results demonstrate the advantages of fine-grained graph\nrefinement in improving the accuracy, robustness, and mechanistic\ninterpretability of DDI event prediction.This work contributes to Web Mining\nand Content Analysis by developing graph-based methods for mining and analyzing\ndrug-drug interaction networks.", "AI": {"tldr": "MolBridge introduces an atom-level joint graph refinement framework that directly models inter-drug atom-level interactions to predict DDI events, using a structure-consistency module to mitigate over-smoothing, achieving robust and interpretable results across long-tail and inductive scenarios.", "motivation": "Accurate DDI prediction requires capturing fine-grained inter-drug relationships, including atom-level cross-molecular interactions, which current isolated-drug representations fail to model, especially across diverse molecular complexities and uneven DDI type distributions.", "method": "Construct a joint graph that integrates atomic structures of drug pairs and apply a structure consistency module that iteratively refines node features while preserving global context to mitigate over-smoothing, enabling learning of both local and global interactions.", "result": "MolBridge outperforms state-of-the-art baselines on two benchmark datasets, with robust performance on long-tail and inductive scenarios and across frequent and rare DDI types, demonstrating improved accuracy, robustness, and mechanistic interpretability.", "conclusion": "The approach advances graph-based drug safety analysis by enabling fine-grained atom-level coupling and joint graph refinement, contributing to Web Mining and Content Analysis through improved DDI network analysis."}}
{"id": "2510.20439", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20439", "abs": "https://arxiv.org/abs/2510.20439", "authors": ["Quannian Zhang", "Michael R\u00f6der", "Nikit Srivastava", "N'Dah Jean Kouagou", "Axel-Cyrille Ngonga Ngomo"], "title": "Explainable Benchmarking through the Lense of Concept Learning", "comment": "Accepted as full research paper at K-CAP 2025", "summary": "Evaluating competing systems in a comparable way, i.e., benchmarking them, is\nan undeniable pillar of the scientific method. However, system performance is\noften summarized via a small number of metrics. The analysis of the evaluation\ndetails and the derivation of insights for further development or use remains a\ntedious manual task with often biased results. Thus, this paper argues for a\nnew type of benchmarking, which is dubbed explainable benchmarking. The aim of\nexplainable benchmarking approaches is to automatically generate explanations\nfor the performance of systems in a benchmark. We provide a first instantiation\nof this paradigm for knowledge-graph-based question answering systems. We\ncompute explanations by using a novel concept learning approach developed for\nlarge knowledge graphs called PruneCEL. Our evaluation shows that PruneCEL\noutperforms state-of-the-art concept learners on the task of explainable\nbenchmarking by up to 0.55 points F1 measure. A task-driven user study with 41\nparticipants shows that in 80\\% of the cases, the majority of participants can\naccurately predict the behavior of a system based on our explanations. Our code\nand data are available at https://github.com/dice-group/PruneCEL/tree/K-cap2025", "AI": {"tldr": "Proposes explainable benchmarking for KG QA; introduces PruneCEL, a concept-learning method; shows improved explainability and a user study suggesting explanations help users predict system behavior; code release provided.", "motivation": "Benchmarking often reduces results to a few metrics, lacking explanations that would help interpret performance and guide future work; explainable benchmarking aims to automatically generate explanations for benchmark results.", "method": "Introduce PruneCEL, a novel concept-learning approach for large knowledge graphs, and instantiate explainable benchmarking for KG QA systems; generate explanations of system behavior by learning explainable concepts.", "result": "PruneCEL outperforms state-of-the-art concept learners on explainable benchmarking by up to 0.55 points F1; a task-driven user study with 41 participants showed 80% of cases where participants could accurately predict system behavior based on the explanations; code and data are available at the provided GitHub repository.", "conclusion": "Explainable benchmarking with PruneCEL demonstrates promise for interpretable evaluation of KG QA systems, enabling insights for development and use; the work provides a concrete instantiation and resources for replication."}}
{"id": "2510.20669", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20669", "abs": "https://arxiv.org/abs/2510.20669", "authors": ["Debojyoti Ghosh", "Adrijit Goswami"], "title": "HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing Maps and Spiking Dynamics for Waste Classification", "comment": null, "summary": "Accurate waste classification is vital for achieving sustainable waste\nmanagement and reducing the environmental footprint of urbanization.\nMisclassification of recyclable materials contributes to landfill accumulation,\ninefficient recycling, and increased greenhouse gas emissions. To address these\nissues, this study introduces HybridSOMSpikeNet, a hybrid deep learning\nframework that integrates convolutional feature extraction, differentiable\nself-organization, and spiking-inspired temporal processing to enable\nintelligent and energy-efficient waste classification. The proposed model\nemploys a pre-trained ResNet-152 backbone to extract deep spatial\nrepresentations, followed by a Differentiable Soft Self-Organizing Map\n(Soft-SOM) that enhances topological clustering and interpretability. A spiking\nneural head accumulates temporal activations over discrete time steps,\nimproving robustness and generalization. Trained on a ten-class waste dataset,\nHybridSOMSpikeNet achieved a test accuracy of 97.39%, outperforming several\nstate-of-the-art architectures while maintaining a lightweight computational\nprofile suitable for real-world deployment. Beyond its technical innovations,\nthe framework provides tangible environmental benefits. By enabling precise and\nautomated waste segregation, it supports higher recycling efficiency, reduces\ncontamination in recyclable streams, and minimizes the ecological and\noperational costs of waste processing. The approach aligns with global\nsustainability priorities, particularly the United Nations Sustainable\nDevelopment Goals (SDG 11 and SDG 12), by contributing to cleaner cities,\ncircular economy initiatives, and intelligent environmental management systems.", "AI": {"tldr": "HybridSOMSpikeNet is a hybrid deep learning framework that fuses CNN-based feature extraction, differentiable self-organizing maps, and spiking temporal processing to achieve high-accuracy, energy-efficient waste classification (97.39% on a 10-class dataset) with interpretability and eco-friendly benefits.", "motivation": "Misclassification of recyclable materials drives landfill growth, increases recycling contamination, and raises emissions; there is a need for accurate, efficient, and deployable waste classification systems.", "method": "Uses a ResNet-152 backbone to extract spatial features; Soft-SOM differentiable self-organizing map for topology-preserving clustering; a spiking neural head accumulates temporal activations across discrete time steps; trained on a ten-class waste dataset; aims for lightweight computation.", "result": "Achieves 97.39% test accuracy, surpassing several SOTA architectures; maintains a lightweight compute profile suitable for real-world deployment.", "conclusion": "Offers tangible environmental benefits by enabling precise automated waste sorting, increasing recycling efficiency, reducing stream contamination, and lowering processing costs; supports SDG 11 (sustainable cities) and SDG 12 (responsible consumption and production)."}}
{"id": "2510.20468", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20468", "abs": "https://arxiv.org/abs/2510.20468", "authors": ["Tom\u00e1\u0161 Sou\u010dek", "Sylvestre-Alvise Rebuffi", "Pierre Fernandez", "Nikola Jovanovi\u0107", "Hady Elsahar", "Valeriu Lacatusu", "Tuan Tran", "Alexandre Mourachko"], "title": "Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models", "comment": "NeurIPS 2025", "summary": "Recent years have seen a surge in interest in digital content watermarking\ntechniques, driven by the proliferation of generative models and increased\nlegal pressure. With an ever-growing percentage of AI-generated content\navailable online, watermarking plays an increasingly important role in ensuring\ncontent authenticity and attribution at scale. There have been many works\nassessing the robustness of watermarking to removal attacks, yet, watermark\nforging, the scenario when a watermark is stolen from genuine content and\napplied to malicious content, remains underexplored. In this work, we\ninvestigate watermark forging in the context of widely used post-hoc image\nwatermarking. Our contributions are as follows. First, we introduce a\npreference model to assess whether an image is watermarked. The model is\ntrained using a ranking loss on purely procedurally generated images without\nany need for real watermarks. Second, we demonstrate the model's capability to\nremove and forge watermarks by optimizing the input image through\nbackpropagation. This technique requires only a single watermarked image and\nworks without knowledge of the watermarking model, making our attack much\nsimpler and more practical than attacks introduced in related work. Third, we\nevaluate our proposed method on a variety of post-hoc image watermarking\nmodels, demonstrating that our approach can effectively forge watermarks,\nquestioning the security of current watermarking approaches. Our code and\nfurther resources are publicly available.", "AI": {"tldr": "Proposes a backpropagation-based watermark forging attack for post-hoc image watermarking, using a procedurally trained watermark detector; capable of removing/forging watermarks from a single watermarked image without knowing the watermarking model.", "motivation": "As AI-generated content proliferates, watermarking is needed to verify authenticity and attribution. Forging watermarks represents a practical, underexplored threat that existing work on robustness to removal attacks does not address.", "method": "1) Train a watermark-detection preference model with a ranking loss on procedurally generated data (no real watermarks). 2) Attack by backpropagating on the input image to remove or forge the watermark, using the detector as guidance. Requires only a single watermarked image and no knowledge of the watermarking model; evaluate across various post-hoc watermarking systems.", "result": "The method successfully forges watermarks across multiple post-hoc watermarking models, demonstrating a practical and simple attack that does not require model access; code and resources are released.", "conclusion": "This work questions the security of current post-hoc watermarking schemes and highlights the need for forging-resistant defenses and broader threat models; suggests directions for developing more robust watermarking mechanisms and evaluation benchmarks."}}
{"id": "2510.20673", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20673", "abs": "https://arxiv.org/abs/2510.20673", "authors": ["Jinhee Kim", "Jae Jun An", "Kang Eun Jeon", "Jong Hwan Ko"], "title": "Efficient Multi-bit Quantization Network Training via Weight Bias Correction and Bit-wise Coreset Sampling", "comment": null, "summary": "Multi-bit quantization networks enable flexible deployment of deep neural\nnetworks by supporting multiple precision levels within a single model.\nHowever, existing approaches suffer from significant training overhead as\nfull-dataset updates are repeated for each supported bit-width, resulting in a\ncost that scales linearly with the number of precisions. Additionally, extra\nfine-tuning stages are often required to support additional or intermediate\nprecision options, further compounding the overall training burden. To address\nthis issue, we propose two techniques that greatly reduce the training overhead\nwithout compromising model utility: (i) Weight bias correction enables shared\nbatch normalization and eliminates the need for fine-tuning by neutralizing\nquantization-induced bias across bit-widths and aligning activation\ndistributions; and (ii) Bit-wise coreset sampling strategy allows each child\nmodel to train on a compact, informative subset selected via gradient-based\nimportance scores by exploiting the implicit knowledge transfer phenomenon.\nExperiments on CIFAR-10/100, TinyImageNet, and ImageNet-1K with both ResNet and\nViT architectures demonstrate that our method achieves competitive or superior\naccuracy while reducing training time up to 7.88x. Our code is released at\nhttps://github.com/a2jinhee/EMQNet_jk.", "AI": {"tldr": "Two techniques reduce training overhead in multi-bit quantization networks: weight bias correction for shared batch norm across bit-widths, and bit-wise coreset sampling for efficient per-bitwidth training; together achieving competitive accuracy with up to 7.88x faster training on CIFAR-10/100, TinyImageNet, and ImageNet-1K with ResNet/ViT.", "motivation": "Multi-bit quantization networks incur training costs that scale linearly with the number of supported bit-widths and often require extra fine-tuning for new precisions, hindering deployment efficiency.", "method": "i) Weight bias correction neutralizes quantization-induced bias and aligns activation distributions across bit-widths to enable shared batch normalization and avoid full-dataset fine-tuning; ii) Bit-wise coreset sampling selects a compact, informative subset for each child model using gradient-based importance scores, exploiting implicit knowledge transfer.", "result": "Empirical results on CIFAR-10/100, TinyImageNet, and ImageNet-1K with ResNet and ViT show competitive or superior accuracy while reducing training time by up to 7.88x.", "conclusion": "The approach substantially lowers training overhead for multi-bit quantization networks without sacrificing accuracy, facilitating efficient multi-precision deployment."}}
{"id": "2510.20486", "categories": ["cs.LG", "cs.AI", "physics.ao-ph", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.20486", "abs": "https://arxiv.org/abs/2510.20486", "authors": ["Fangjian Zhang", "Xiaoyong Zhuge", "Wenlan Wang", "Haixia Xiao", "Yuying Zhu", "Siyang Cheng"], "title": "Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval", "comment": "26 pages", "summary": "Artificial intelligence has advanced quantitative remote sensing, yet its\neffectiveness is constrained by imbalanced label distribution. This imbalance\nleads conventionally trained models to favor common samples, which in turn\ndegrades retrieval performance for rare ones. Rainfall retrieval exemplifies\nthis issue, with performance particularly compromised for heavy rain. This\nstudy proposes Hurdle-Inversion Model Debiasing Learning (IMDL) framework.\nFollowing a divide-and-conquer strategy, imbalance in the rain distribution is\ndecomposed into two components: zero inflation, defined by the predominance of\nnon-rain samples; and long tail, defined by the disproportionate abundance of\nlight-rain samples relative to heavy-rain samples. A hurdle model is adopted to\nhandle the zero inflation, while IMDL is proposed to address the long tail by\ntransforming the learning object into an unbiased ideal inverse model.\nComprehensive evaluation via statistical metrics and case studies investigating\nrainy weather in eastern China confirms Hurdle-IMDL's superiority over\nconventional, cost-sensitive, generative, and multi-task learning methods. Its\nkey advancements include effective mitigation of systematic underestimation and\na marked improvement in the retrieval of heavy-to-extreme rain. IMDL offers a\ngeneralizable approach for addressing imbalance in distributions of\nenvironmental variables, enabling enhanced retrieval of rare yet high-impact\nevents.", "AI": {"tldr": "Proposes Hurdle-IMDL to debias rainfall retrieval under imbalanced label distributions by separating zero inflation and long-tail; uses a hurdle model for zero inflation and an unbiased inverse-model learning objective for long tail; demonstrated superior performance, especially for heavy rainfall, across eastern China case studies; generalizable to environmental variables.", "motivation": "Imbalanced label distributions in quantitative remote sensing bias model training, causing underperformance for rare/heavy rainfall and similar high-impact events.", "method": "Divide-and-conquer: decompose imbalance into zero inflation and long tail; apply hurdle model to zero inflation; transform learning objective to unbiased ideal inverse model with IMDL for long tail.", "result": "Empirical evaluation shows IMDL outperforms conventional, cost-sensitive, generative, and multi-task methods; reduces systematic underestimation and improves heavy-to-extreme rainfall retrieval; case studies in eastern China confirm effectiveness.", "conclusion": "IMDL offers a generalizable framework for addressing distribution imbalance in environmental variables, enabling improved retrieval of rare but high-impact events."}}
{"id": "2510.20454", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20454", "abs": "https://arxiv.org/abs/2510.20454", "authors": ["Lawrence Clegg", "John Cartlidge"], "title": "Intransitive Player Dominance and Market Inefficiency in Tennis Forecasting: A Graph Neural Network Approach", "comment": "39 pages, 8 figures", "summary": "Intransitive player dominance, where player A beats B, B beats C, but C beats\nA, is common in competitive tennis. Yet, there are few known attempts to\nincorporate it within forecasting methods. We address this problem with a graph\nneural network approach that explicitly models these intransitive relationships\nthrough temporal directed graphs, with players as nodes and their historical\nmatch outcomes as directed edges. We find the bookmaker Pinnacle Sports poorly\nhandles matches with high intransitive complexity and posit that our\ngraph-based approach is uniquely positioned to capture relational dynamics in\nthese scenarios. When selectively betting on higher intransitivity matchups\nwith our model (65.7% accuracy, 0.215 Brier Score), we achieve significant\npositive returns of 3.26% ROI with Kelly staking over 1903 bets, suggesting a\nmarket inefficiency in handling intransitive matchups that our approach\nsuccessfully exploits.", "AI": {"tldr": "Graph neural network captures intransitive relationships in tennis matchups to improve forecasting, achieving positive ROI on selective bets by exploiting a market inefficiency.", "motivation": "Intransitive dominance (A beats B, B beats C, C beats A) is common in tennis but rarely modeled in forecasts; markets may misprice such relational dynamics, creating exploitable inefficiencies.", "method": "Model uses temporal directed graphs with players as nodes and historical match outcomes as directed edges; a graph neural network learns relational, time-evolving features to forecast match results, evaluating on higher-intransitivity matchups with metrics like accuracy, Brier score, and ROI via Kelly staking across ~1.9k bets.", "result": "On higher-intransitivity matchups, the model achieves 65.7% accuracy and a 0.215 Brier score, delivering a 3.26% ROI over 1,903 bets under Kelly staking.", "conclusion": "Graph-based relational modeling can capture intransitive dynamics and reveal market inefficiencies in betting environments; further validation and robust comparisons are warranted to assess generalizability and practical deployment."}}
{"id": "2510.20696", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20696", "abs": "https://arxiv.org/abs/2510.20696", "authors": ["Jing Bi", "Guangyu Sun", "Ali Vosoughi", "Chen Chen", "Chenliang Xu"], "title": "Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward", "comment": "5 pages", "summary": "Multimodal large language models (MLLMs) that integrate visual and textual\nreasoning leverage chain-of-thought (CoT) prompting to tackle complex visual\ntasks, yet continue to exhibit visual hallucinations and an over-reliance on\ntextual priors. We present a systematic diagnosis of state-of-the-art\nvision-language models using a three-stage evaluation framework, uncovering key\nfailure modes. To address these, we propose an agent-based architecture that\ncombines LLM reasoning with lightweight visual modules, enabling fine-grained\nanalysis and iterative refinement of reasoning chains. Our results highlight\nfuture visual reasoning models should focus on integrating a broader set of\nspecialized tools for analyzing visual content. Our system achieves significant\ngains (+10.3 on MMMU, +6.0 on MathVista over a 7B baseline), matching or\nsurpassing much larger models. We will release our framework and evaluation\nsuite to facilitate future research.", "AI": {"tldr": "A diagnostic study of state-of-the-art vision-language models reveals persistent failures in multimodal reasoning (e.g., visual hallucinations and reliance on textual priors). It proposes an agent-based architecture that couples LLM reasoning with lightweight visual modules to enable fine-grained analysis and iterative refinement, achieving notable gains on benchmarks and promising broader tool integration, with a community-ready framework and evaluation suite.", "motivation": "To address persistent visual hallucinations and textual priors in multimodal large language models by systematically diagnosing failure modes and enabling detailed analysis and iterative improvement of reasoning chains.", "method": "Three-stage evaluation framework to assess state-of-the-art vision-language models; introduce an agent-based architecture that integrates LLM-based reasoning with lightweight visual analysis modules to enable fine-grained, iterative refinement of reasoning chains.", "result": "Significant performance gains over a 7B baseline (+10.3 MMMU, +6.0 MathVista); performance matching or surpassing larger models; capability for granular analysis and iterative reasoning; framework and evaluation suite to be released for community use.", "conclusion": "Future visual reasoning models should integrate a broader set of specialized visual analysis tools; the proposed framework provides a scalable path for diagnosing and improving multimodal reasoning and will be released to facilitate research."}}
{"id": "2510.20707", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20707", "abs": "https://arxiv.org/abs/2510.20707", "authors": ["Xuyang Liu", "Xiyan Gui", "Yuchao Zhang", "Linfeng Zhang"], "title": "Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models", "comment": "Our code is available at https://github.com/xuyang-liu16/MixKV", "summary": "Recent large vision-language models (LVLMs) demonstrate remarkable\ncapabilities in processing extended multi-modal sequences, yet the resulting\nkey-value (KV) cache expansion creates a critical memory bottleneck that\nfundamentally limits deployment scalability. While existing KV cache\ncompression methods focus on retaining high-importance KV pairs to minimize\nstorage, they often overlook the modality-specific semantic redundancy patterns\nthat emerge distinctively in multi-modal KV caches. In this work, we first\nanalyze how, beyond simple importance, the KV cache in LVLMs exhibits varying\nlevels of redundancy across attention heads. We show that relying solely on\nimportance can only cover a subset of the full KV cache information\ndistribution, leading to potential loss of semantic coverage. To address this,\nwe propose \\texttt{MixKV}, a novel method that mixes importance with diversity\nfor optimized KV cache compression in LVLMs. \\texttt{MixKV} adapts to head-wise\nsemantic redundancy, selectively balancing diversity and importance when\ncompressing KV pairs. Extensive experiments demonstrate that \\texttt{MixKV}\nconsistently enhances existing methods across multiple LVLMs. Under extreme\ncompression (budget=64), \\texttt{MixKV} improves baseline methods by an average\nof \\textbf{5.1\\%} across five multi-modal understanding benchmarks and achieves\nremarkable gains of \\textbf{8.0\\%} and \\textbf{9.0\\%} for SnapKV and AdaKV on\nGUI grounding tasks, all while maintaining comparable inference efficiency.\nFurthermore, \\texttt{MixKV} extends seamlessly to LLMs with comparable\nperformance gains. Our code is available at\n\\href{https://github.com/xuyang-liu16/MixKV}{\\textcolor{citeblue}{https://github.com/xuyang-liu16/MixKV}}.", "AI": {"tldr": "MixKV blends importance and diversity to compress KV caches in LVLMs by exploiting head-wise semantic redundancy, yielding consistent gains under extreme compression and extending to LLMs; code released.", "motivation": "KV cache growth in large vision-language models creates a memory bottleneck that limits deployment; existing compression methods focus on importance and neglect modality-specific redundancy patterns across attention heads.", "method": "Introduce MixKV that adaptively balances diversity and importance for head-wise KV compression, exploiting cross-head redundancy to preserve semantic coverage while reducing storage; applicable to multi-modal KV caches and extendable to LLMs; code released.", "result": "Under extreme compression (budget=64), MixKV improves baseline methods by an average of 5.1% across five multi-modal understanding benchmarks; achieves 8.0% and 9.0% gains for SnapKV and AdaKV on GUI grounding tasks; maintains comparable inference efficiency; extends to LLMs with comparable gains.", "conclusion": "MixKV effectively captures head-wise redundancy to optimize KV-cache compression in LVLMs and can generalize to LLMs, offering practical memory savings without sacrificing performance."}}
{"id": "2510.20477", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20477", "abs": "https://arxiv.org/abs/2510.20477", "authors": ["Rui Zhu", "Song-Lin Lv", "Zi-Kang Wang", "Lan-Zhe Guo"], "title": "Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models", "comment": null, "summary": "Exploiting unlabeled data through semi-supervised learning (SSL) or\nleveraging pre-trained models via fine-tuning are two prevailing paradigms for\naddressing label-scarce scenarios. Recently, growing attention has been given\nto combining fine-tuning of pre-trained vision-language models (VLMs) with SSL,\nforming the emerging paradigm of semi-supervised fine-tuning. However, existing\nmethods often suffer from model bias and hyperparameter sensitivity, due to\nreliance on prediction consistency or pre-defined confidence thresholds. To\naddress these limitations, we propose a simple yet effective plug-and-play\nmethodology named\n$\\underline{\\textbf{Bi-Co}}$nsistency-$\\underline{\\textbf{G}}$uided\nSelf-Training (Bi-CoG), which assigns high-quality and low-bias pseudo-labels,\nby simultaneously exploiting inter-model and intra-model consistency, along\nwith an error-aware dynamic pseudo-label assignment strategy. Both theoretical\nanalysis and extensive experiments over 14 datasets demonstrate the\neffectiveness of Bi-CoG, which consistently and significantly improves the\nperformance of existing methods.", "AI": {"tldr": "Bi-CoG introduces a plug-and-play semi-supervised fine-tuning method for vision-language models that reduces bias and hyperparameter sensitivity by using both inter-model and intra-model consistency along with an error-aware, dynamic pseudo-labeling strategy, showing strong gains across 14 datasets.", "motivation": "Label scarcity in vision-language model fine-tuning and limitations of existing SSL approaches that rely on fixed confidence thresholds or prediction consistency, which can induce bias and sensitivity to hyperparameters.", "method": "Bi-CoG (Bi-Consistency-Guided Self-Training) combines inter-model and intra-model consistency to quality-pick pseudo-labels. It features an error-aware dynamic pseudo-label assignment strategy and is designed as a plug-and-play module that can be added to pre-trained VLM fine-tuning processes.", "result": "Theoretical analysis and extensive experiments on 14 datasets demonstrate that Bi-CoG consistently and significantly improves performance over existing methods.", "conclusion": "Bi-CoG provides a robust, low-bias, and hyperparameter-tolerant approach to semi-supervised fine-tuning of vision-language models, with broad applicability and strong empirical gains."}}
{"id": "2510.20556", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20556", "abs": "https://arxiv.org/abs/2510.20556", "authors": ["Alexandre Benoit", "Catherine Aitken", "Yu He"], "title": "Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics", "comment": "21 pages, 5 figures, conference", "summary": "Graph rewiring has emerged as a key technique to alleviate over-squashing in\nGraph Neural Networks (GNNs) and Graph Transformers by modifying the graph\ntopology to improve information flow. While effective, rewiring inherently\nalters the graph's structure, raising the risk of distorting important\ntopology-dependent signals. Yet, despite the growing use of rewiring, little is\nknown about which structural properties must be preserved to ensure both\nperformance gains and structural fidelity. In this work, we provide the first\nsystematic analysis of how rewiring affects a range of graph structural\nmetrics, and how these changes relate to downstream task performance. We study\nseven diverse rewiring strategies and correlate changes in local and global\ngraph properties with node classification accuracy. Our results reveal a\nconsistent pattern: successful rewiring methods tend to preserve local\nstructure while allowing for flexibility in global connectivity. These findings\noffer new insights into the design of effective rewiring strategies, bridging\nthe gap between graph theory and practical GNN optimization.", "AI": {"tldr": "Systematic empirical study of graph rewiring methods for GNNs/Graph Transformers. Seven strategies analyzed; preserving local structure while allowing global connectivity changes yields better performance and fidelity; insights to guide rewiring design and metric selection.", "motivation": "To understand which graph structural properties must be preserved during rewiring to achieve performance gains without distorting topology-dependent signals, bridging graph theory and practical GNN optimization.", "method": "Empirically evaluate seven diverse rewiring strategies on graphs, measuring changes in a range of local and global structural metrics (e.g., clustering, degree distribution, modularity, global efficiency, centrality measures) and correlating these with downstream node classification accuracy to identify patterns between metric changes and performance.", "result": "A consistent pattern emerges: successful rewiring methods tend to preserve local structure while allowing flexibility in global connectivity. Changes in local properties are tightly linked to preserving performance/fidelity, while global connectivity changes can be tolerated or even beneficial if local structure is maintained; correlations between specific metric changes and accuracy were observed across strategies.", "conclusion": "Design rewiring algorithms with a priority on preserving local topology (e.g., clusters, motifs) and permit flexible or altered global connectivity. The study provides practical guidelines and metrics to monitor when applying rewiring and helps align graph-theoretic properties with GNN optimization goals."}}
{"id": "2510.20726", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20726", "abs": "https://arxiv.org/abs/2510.20726", "authors": ["Jiacheng Chen", "Ziyu Jiang", "Mingfu Liang", "Bingbing Zhuang", "Jong-Chyi Su", "Sparsh Garg", "Ying Wu", "Manmohan Chandraker"], "title": "AutoScape: Geometry-Consistent Long-Horizon Scene Generation", "comment": "ICCV 2025. Project page: https://auto-scape.github.io", "summary": "This paper proposes AutoScape, a long-horizon driving scene generation\nframework. At its core is a novel RGB-D diffusion model that iteratively\ngenerates sparse, geometrically consistent keyframes, serving as reliable\nanchors for the scene's appearance and geometry. To maintain long-range\ngeometric consistency, the model 1) jointly handles image and depth in a shared\nlatent space, 2) explicitly conditions on the existing scene geometry (i.e.,\nrendered point clouds) from previously generated keyframes, and 3) steers the\nsampling process with a warp-consistent guidance. Given high-quality RGB-D\nkeyframes, a video diffusion model then interpolates between them to produce\ndense and coherent video frames. AutoScape generates realistic and\ngeometrically consistent driving videos of over 20 seconds, improving the\nlong-horizon FID and FVD scores over the prior state-of-the-art by 48.6\\% and\n43.0\\%, respectively.", "AI": {"tldr": "AutoScape is a diffusion-based framework for long-horizon driving scene generation that uses RGB-D keyframes as anchors; it jointly models image and depth in a shared latent space, conditions on existing geometry, uses warp-guided sampling, and interpolates with a video diffusion model to produce 20+ second driving videos, achieving state-of-the-art improvements in long-horizon FID and FVD.", "motivation": "To address the challenge of producing long, coherent, geometrically consistent driving videos, mitigating drift and inconsistency across many frames, and leveraging geometry-aware diffusion.", "method": "1) RGB-D diffusion model generates sparse keyframes with joint image-depth latent space. 2) Condition on previously generated scene geometry via rendered point clouds. 3) Warp-consistent guidance guides sampling for long-range consistency. 4) A video diffusion model interpolates between high-quality RGB-D keyframes to dense frames, producing over 20 seconds of video.", "result": "Outperforms previous state-of-the-art on long-horizon metrics, with improvements of 48.6% in long-horizon FID and 43.0% in FVD. Produces realistic, geometrically consistent driving videos of 20+ seconds.", "conclusion": "AutoScape demonstrates that combining geometry-conditioned diffusion with warp-guided sampling and keyframe interpolation can achieve long-horizon, coherent driving videos, significantly improving evaluation metrics over prior work."}}
{"id": "2510.20540", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20540", "abs": "https://arxiv.org/abs/2510.20540", "authors": ["Abdulmomen Ghalkha", "Zhuojun Tian", "Chaouki Ben Issaid", "Mehdi Bennis"], "title": "SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment", "comment": "5 pages, 3 figures, 1 table", "summary": "Conventional multimodal alignment methods assume mutual redundancy across all\nmodalities, an assumption that fails in real-world distributed scenarios. We\npropose SheafAlign, a sheaf-theoretic framework for decentralized multimodal\nalignment that replaces single-space alignment with multiple comparison spaces.\nThis approach models pairwise modality relations through sheaf structures and\nleverages decentralized contrastive learning-based objectives for training.\nSheafAlign overcomes the limitations of prior methods by not requiring mutual\nredundancy among all modalities, preserving both shared and unique information.\nExperiments on multimodal sensing datasets show superior zero-shot\ngeneralization, cross-modal alignment, and robustness to missing modalities,\nwith 50\\% lower communication cost than state-of-the-art baselines.", "AI": {"tldr": "SheafAlign introduces a decentralized, sheaf-theoretic framework for multimodal alignment that relaxes the mutual-redundancy assumption, using pairwise comparison spaces and decentralized contrastive learning to preserve both shared and unique information, achieving better zero-shot generalization, cross-modal alignment, robustness to missing modalities, and 50% lower communication cost.", "motivation": "Real-world multimodal data often exhibit non-redundant or only partially overlapping information across modalities. Traditional single-space alignment assumes mutual redundancy across all modalities, leading to information loss and poor scalability in distributed settings.", "method": "Model pairwise modality relations as local 'sheaf' structures represented by multiple comparison spaces; apply decentralized contrastive learning objectives to train without requiring all modalities to be jointly redundant; reduce inter-modality communication by operating in local spaces.", "result": "Empirical experiments on multimodal sensing datasets show superior zero-shot generalization, improved cross-modal alignment, robustness to missing modalities, and about 50% reduction in communication cost compared to state-of-the-art baselines.", "conclusion": "SheafAlign overcomes the limitations of prior methods by preserving both shared and unique information in a decentralized, multi-space alignment framework and delivering efficient communication for distributed multimodal systems."}}
{"id": "2510.20754", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20754", "abs": "https://arxiv.org/abs/2510.20754", "authors": ["Nima Torbati", "Anastasia Meshcheryakova", "Ramona Woitek", "Diana Mechtcheriakova", "Amirreza Mahbod"], "title": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for Tissue Segmentation in Histopathology", "comment": "5 pages", "summary": "Automated histopathological image analysis plays a vital role in\ncomputer-aided diagnosis of various diseases. Among developed algorithms, deep\nlearning-based approaches have demonstrated excellent performance in multiple\ntasks, including semantic tissue segmentation in histological images. In this\nstudy, we propose a novel approach based on attention-driven feature fusion of\nconvolutional neural networks (CNNs) and vision transformers (ViTs) within a\nunified dual-encoder model to improve semantic segmentation performance.\nEvaluation on two publicly available datasets showed that our model achieved\n{\\mu}IoU/{\\mu}Dice scores of 76.79%/86.87% on the GCPS dataset and\n64.93%/76.60% on the PUMA dataset, outperforming state-of-the-art and baseline\nbenchmarks. The implementation of our method is publicly available in a GitHub\nrepository: https://github.com/NimaTorbati/ACS-SegNet", "AI": {"tldr": "A dual-encoder CNN+ViT model with attention-driven feature fusion improves semantic segmentation in histopathology, achieving state-of-the-art results on GCPS and PUMA datasets.", "motivation": "Enhance semantic tissue segmentation in histopathology by leveraging complementary local (CNN) and global (ViT) representations through attention-based fusion.", "method": "Unified dual-encoder architecture that fuses CNN and ViT features via attention mechanisms for semantic segmentation; evaluated on GCPS and PUMA with standard metrics.", "result": "MuIoU/muDice: GCPS 76.79%/86.87%; PUMA 64.93%/76.60%; outperforms state-of-the-art and baselines; code released on GitHub.", "conclusion": "The approach effectively harnesses CNN and ViT strengths for histopathological segmentation and provides reproducible results with open-source implementation."}}
{"id": "2510.20542", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20542", "abs": "https://arxiv.org/abs/2510.20542", "authors": ["Jacopo Di Ventura", "Jan Felix Kleuker", "Aske Plaat", "Thomas Moerland"], "title": "A Unified Framework for Zero-Shot Reinforcement Learning", "comment": null, "summary": "Zero-shot reinforcement learning (RL) has emerged as a setting for developing\ngeneral agents in an unsupervised manner, capable of solving downstream tasks\nwithout additional training or planning at test-time. Unlike conventional RL,\nwhich optimizes policies for a fixed reward, zero-shot RL requires agents to\nencode representations rich enough to support immediate adaptation to any\nobjective, drawing parallels to vision and language foundation models. Despite\ngrowing interest, the field lacks a common analytical lens.\n  We present the first unified framework for zero-shot RL. Our formulation\nintroduces a consistent notation and taxonomy that organizes existing\napproaches and allows direct comparison between them. Central to our framework\nis the classification of algorithms into two families: direct representations,\nwhich learn end-to-end mappings from rewards to policies, and compositional\nrepresentations, which decompose the representation leveraging the substructure\nof the value function. Within this framework, we highlight shared principles\nand key differences across methods, and we derive an extended bound for\nsuccessor-feature methods, offering a new perspective on their performance in\nthe zero-shot regime. By consolidating existing work under a common lens, our\nframework provides a principled foundation for future research in zero-shot RL\nand outlines a clear path toward developing more general agents.", "AI": {"tldr": "Unified framework for zero-shot RL, organizing methods into direct and compositional representations; extends successor-feature bounds and sets a principled foundation for future zero-shot RL research.", "motivation": "Zero-shot RL lacks a common analytical lens and a unified vocabulary, hindering cross-method comparison and progress toward general agents. A principled framework can clarify assumptions, enable fair benchmarking, and guide future research.", "method": "Introduce consistent notation and taxonomy for zero-shot RL, classify existing approaches into two families (direct representations and compositional representations), and derive an extended bound for successor-feature methods.", "result": "Clarifies shared principles and differences across methods, provides an extended bound for successor-feature approaches, and consolidates existing work under a common framework to facilitate cross-method analysis and comparison.", "conclusion": "The framework offers a principled foundation for future zero-shot RL research and outlines a clear path toward developing more general agents."}}
{"id": "2510.20766", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20766", "abs": "https://arxiv.org/abs/2510.20766", "authors": ["Noam Issachar", "Guy Yariv", "Sagie Benaim", "Yossi Adi", "Dani Lischinski", "Raanan Fattal"], "title": "DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion", "comment": null, "summary": "Diffusion Transformer models can generate images with remarkable fidelity and\ndetail, yet training them at ultra-high resolutions remains extremely costly\ndue to the self-attention mechanism's quadratic scaling with the number of\nimage tokens. In this paper, we introduce Dynamic Position Extrapolation\n(DyPE), a novel, training-free method that enables pre-trained diffusion\ntransformers to synthesize images at resolutions far beyond their training\ndata, with no additional sampling cost. DyPE takes advantage of the spectral\nprogression inherent to the diffusion process, where low-frequency structures\nconverge early, while high-frequencies take more steps to resolve.\nSpecifically, DyPE dynamically adjusts the model's positional encoding at each\ndiffusion step, matching their frequency spectrum with the current stage of the\ngenerative process. This approach allows us to generate images at resolutions\nthat exceed the training resolution dramatically, e.g., 16 million pixels using\nFLUX. On multiple benchmarks, DyPE consistently improves performance and\nachieves state-of-the-art fidelity in ultra-high-resolution image generation,\nwith gains becoming even more pronounced at higher resolutions. Project page is\navailable at https://noamissachar.github.io/DyPE/.", "AI": {"tldr": "A training-free method (Dynamic Position Extrapolation, DyPE) lets pre-trained diffusion transformers synthesize ultra-high-resolution images beyond their training data by dynamically adjusting positional encodings to the diffusion step's spectral progression, achieving state-of-the-art fidelity with no extra sampling cost (e.g., 16M-pixel images with FLUX).", "motivation": "Address the quadratic scaling of self-attention when generating ultra-high-resolution images with diffusion transformers and enable resolution extrapolation without retraining, by leveraging the diffusion process's spectral progression.", "method": "Dynamic Position Extrapolation (DyPE) dynamically adjusts the model's positional encoding at each diffusion step to align with the current frequency spectrum of the generative process, enabling resolution extrapolation without additional training or sampling costs.", "result": "Across benchmarks, DyPE yields consistent performance gains and state-of-the-art fidelity in ultra-high-resolution image generation, with larger gains as resolution increases; enables generation of very high-resolution images (e.g., 16M pixels) using FLUX, without extra sampling cost.", "conclusion": "DyPE unlocks scalable ultra-high-resolution image generation from pre-trained diffusion transformers without retraining, by spectrally aligning positional encodings to the diffusion process; shows strong empirical gains and potential for further spectral-based methods."}}
{"id": "2510.20771", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20771", "abs": "https://arxiv.org/abs/2510.20771", "authors": ["Huijie Zhang", "Aliaksandr Siarohin", "Willi Menapace", "Michael Vasilkovsky", "Sergey Tulyakov", "Qing Qu", "Ivan Skorokhodov"], "title": "AlphaFlow: Understanding and Improving MeanFlow Models", "comment": null, "summary": "MeanFlow has recently emerged as a powerful framework for few-step generative\nmodeling trained from scratch, but its success is not yet fully understood. In\nthis work, we show that the MeanFlow objective naturally decomposes into two\nparts: trajectory flow matching and trajectory consistency. Through gradient\nanalysis, we find that these terms are strongly negatively correlated, causing\noptimization conflict and slow convergence. Motivated by these insights, we\nintroduce $\\alpha$-Flow, a broad family of objectives that unifies trajectory\nflow matching, Shortcut Model, and MeanFlow under one formulation. By adopting\na curriculum strategy that smoothly anneals from trajectory flow matching to\nMeanFlow, $\\alpha$-Flow disentangles the conflicting objectives, and achieves\nbetter convergence. When trained from scratch on class-conditional ImageNet-1K\n256x256 with vanilla DiT backbones, $\\alpha$-Flow consistently outperforms\nMeanFlow across scales and settings. Our largest $\\alpha$-Flow-XL/2+ model\nachieves new state-of-the-art results using vanilla DiT backbones, with FID\nscores of 2.58 (1-NFE) and 2.15 (2-NFE).", "AI": {"tldr": "MeanFlow's objective splits into trajectory flow matching and trajectory consistency, which conflict in gradients; alpha-Flow unifies these with curriculum annealing, improving convergence and achieving SOTA FID on ImageNet-1K 256x256 with DiT backbones.", "motivation": "To understand MeanFlow's failure modes and improve training from scratch for high-resolution generative modeling, by addressing optimization conflicts between two objective terms.", "method": "Decompose MeanFlow into two terms, analyze gradient correlation; propose alpha-Flow family parameter alpha to interpolate between trajectory flow matching and MeanFlow; implement curriculum annealing from TFM to MeanFlow; train from scratch on class-conditional ImageNet-1K 256x256 using vanilla DiT backbones; evaluate with FID at 1-NFE and 2-NFE.", "result": "alpha-Flow consistently outperforms MeanFlow across scales; largest alpha-Flow-XL/2+ achieves FID 2.58 (1-NFE) and 2.15 (2-NFE) on ImageNet-1K 256x256 with vanilla DiT backbones.", "conclusion": "Curriculum-based annealing to disentangle conflicting gradient terms yields faster convergence and better generative quality; the alpha-Flow framework unifies trajectory flow matching, Shortcut Model, and MeanFlow under a single formulation, enabling SOTA results with standard architectures."}}
{"id": "2510.20607", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20607", "abs": "https://arxiv.org/abs/2510.20607", "authors": ["Alexandru Oarga", "Yilun Du"], "title": "Generalizable Reasoning through Compositional Energy Minimization", "comment": null, "summary": "Generalization is a key challenge in machine learning, specifically in\nreasoning tasks, where models are expected to solve problems more complex than\nthose encountered during training. Existing approaches typically train\nreasoning models in an end-to-end fashion, directly mapping input instances to\nsolutions. While this allows models to learn useful heuristics from data, it\noften results in limited generalization beyond the training distribution. In\nthis work, we propose a novel approach to reasoning generalization by learning\nenergy landscapes over the solution spaces of smaller, more tractable\nsubproblems. At test time, we construct a global energy landscape for a given\nproblem by combining the energy functions of multiple subproblems. This\ncompositional approach enables the incorporation of additional constraints\nduring inference, allowing the construction of energy landscapes for problems\nof increasing difficulty. To improve the sample quality from this newly\nconstructed energy landscape, we introduce Parallel Energy Minimization (PEM).\nWe evaluate our approach on a wide set of reasoning problems. Our method\noutperforms existing state-of-the-art methods, demonstrating its ability to\ngeneralize to larger and more complex problems. Project website can be found\nat: https://alexoarga.github.io/compositional_reasoning/", "AI": {"tldr": "A compositional energy-based reasoning framework: learn local energy landscapes on tractable subproblems, compose them into a global energy landscape at inference time, and use Parallel Energy Minimization to improve sampling, enabling generalization to larger, more complex problems.", "motivation": "Generalization in reasoning tasks is limited by end-to-end training; exploiting compositional structure and energy-based modeling can constrain search and scale reasoning to harder problems.", "method": "Train energy functions on smaller subproblems to capture their solution spaces; at test time, compose these local energies to form a global landscape for the given problem; apply Parallel Energy Minimization (PEM) to improve sample quality from the constructed landscape; evaluate on a broad set of reasoning tasks.", "result": "The approach outperforms existing state-of-the-art methods on a wide set of reasoning problems, demonstrating improved generalization to larger and more complex problems.", "conclusion": "Compositional energy landscapes enable scalable generalization in reasoning by modularizing subproblems and coordinating them during inference; PEM enhances sample quality, supporting constraint-incorporated, more flexible inference."}}
{"id": "2510.20590", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20590", "abs": "https://arxiv.org/abs/2510.20590", "authors": ["Simon Schindler", "Christoph Binder", "Lukas L\u00fcrzer", "Stefan Huber"], "title": "Embedding the MLOps Lifecycle into OT Reference Models", "comment": null, "summary": "Machine Learning Operations (MLOps) practices are increas- ingly adopted in\nindustrial settings, yet their integration with Opera- tional Technology (OT)\nsystems presents significant challenges. This pa- per analyzes the fundamental\nobstacles in combining MLOps with OT en- vironments and proposes a systematic\napproach to embed MLOps prac- tices into established OT reference models. We\nevaluate the suitability of the Reference Architectural Model for Industry 4.0\n(RAMI 4.0) and the International Society of Automation Standard 95 (ISA-95) for\nMLOps integration and present a detailed mapping of MLOps lifecycle compo-\nnents to RAMI 4.0 exemplified by a real-world use case. Our findings\ndemonstrate that while standard MLOps practices cannot be directly transplanted\nto OT environments, structured adaptation using existing reference models can\nprovide a pathway for successful integration.", "AI": {"tldr": "MLOps needs careful adaptation for OT environments using RAMI 4.0 and ISA-95; direct transplantation fails, but a structured mapping and an exemplar use case enable practical integration.", "motivation": "OT systems pose unique constraints (safety, reliability, lifecycle, interoperability). The paper seeks to bridge MLOps with OT by leveraging established reference models to facilitate industrial deployment.", "method": "Evaluate RAMI 4.0 and ISA-95 for MLOps integration; map MLOps lifecycle components to RAMI 4.0; illustrate with a real-world use case.", "result": "Standard MLOps practices cannot be directly transplanted into OT environments; however, a structured adaptation using RAMI 4.0 and ISA-95 enables a viable integration path, demonstrated through a lifecycle component mapping and a real-world example.", "conclusion": "A systematic approach that adapts existing OT reference models is essential to successfully embed MLOps in OT contexts; direct transplantation is insufficient."}}
{"id": "2510.20776", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20776", "abs": "https://arxiv.org/abs/2510.20776", "authors": ["Binbin Huang", "Haobin Duan", "Yiqun Zhao", "Zibo Zhao", "Yi Ma", "Shenghua Gao"], "title": "CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image", "comment": "project page at https://cupid3d.github.io", "summary": "This work proposes a new generation-based 3D reconstruction method, named\nCupid, that accurately infers the camera pose, 3D shape, and texture of an\nobject from a single 2D image. Cupid casts 3D reconstruction as a conditional\nsampling process from a learned distribution of 3D objects, and it jointly\ngenerates voxels and pixel-voxel correspondences, enabling robust pose and\nshape estimation under a unified generative framework. By representing both\ninput camera poses and 3D shape as a distribution in a shared 3D latent space,\nCupid adopts a two-stage flow matching pipeline: (1) a coarse stage that\nproduces initial 3D geometry with associated 2D projections for pose recovery;\nand (2) a refinement stage that integrates pose-aligned image features to\nenhance structural fidelity and appearance details. Extensive experiments\ndemonstrate Cupid outperforms leading 3D reconstruction methods with an over 3\ndB PSNR gain and an over 10% Chamfer Distance reduction, while matching\nmonocular estimators on pose accuracy and delivering superior visual fidelity\nover baseline 3D generative models. For an immersive view of the 3D results\ngenerated by Cupid, please visit cupid3d.github.io.", "AI": {"tldr": "Cupid is a generation-based method for single-image 3D reconstruction that jointly infers camera pose, 3D shape, and texture by sampling from a learned distribution in a shared latent space. It uses a two-stage coarse-to-refinement pipeline to produce voxels and pixel-voxel correspondences, achieving state-of-the-art-like gains in PSNR and Chamfer Distance while matching pose accuracy of monocular estimators.", "motivation": "To robustly recover 3D geometry and appearance from a single image by unifying pose estimation and 3D generation within a probabilistic, conditional framework that can jointly model voxels and pixel-voxel correspondences, thereby improving accuracy and visual fidelity.", "method": "Formulates 3D reconstruction as conditional sampling from a learned distribution of 3D objects. Simultaneously generates voxels and pixel-voxel correspondences in a shared 3D latent space. Employs a two-stage flow matching pipeline: (1) a coarse stage that yields initial 3D geometry with 2D projections for pose recovery; (2) a refinement stage that incorporates pose-aligned image features to enhance fidelity and texture.", "result": "Extensive experiments show Cupid achieves over 3 dB PSNR gain and more than 10% improvement in Chamfer Distance over leading methods, while matching monocular estimators on pose accuracy and delivering superior visual fidelity versus baseline 3D generative models.", "conclusion": "Cupid demonstrates that a unified generative framework with joint voxel and pixel-voxel reasoning in a shared latent space enables robust single-image 3D reconstruction of pose, shape, and texture, delivering strong quantitative gains and high-quality renderings; an immersive view is available at the project site."}}
{"id": "2510.20609", "categories": ["cs.LG", "cs.AI", "cs.IR", "cs.LG, cs.IR, cs.SE, cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20609", "abs": "https://arxiv.org/abs/2510.20609", "authors": ["Timur Galimzyanov", "Olga Kolomyttseva", "Egor Bogomolov"], "title": "Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets", "comment": null, "summary": "We study retrieval design for code-focused generation tasks under realistic\ncompute budgets. Using two complementary tasks from Long Code Arena -- code\ncompletion and bug localization -- we systematically compare retrieval\nconfigurations across various context window sizes along three axes: (i)\nchunking strategy, (ii) similarity scoring, and (iii) splitting granularity.\n(1) For PL-PL, sparse BM25 with word-level splitting is the most effective and\npractical, significantly outperforming dense alternatives while being an order\nof magnitude faster. (2) For NL-PL, proprietary dense encoders (Voyager-3\nfamily) consistently beat sparse retrievers, however requiring 100x larger\nlatency. (3) Optimal chunk size scales with available context: 32-64 line\nchunks work best at small budgets, and whole-file retrieval becomes competitive\nat 16000 tokens. (4) Simple line-based chunking matches syntax-aware splitting\nacross budgets. (5) Retrieval latency varies by up to 200x across\nconfigurations; BPE-based splitting is needlessly slow, and BM25 + word\nsplitting offers the best quality-latency trade-off. Thus, we provide\nevidence-based recommendations for implementing effective code-oriented RAG\nsystems based on task requirements, model constraints, and computational\nefficiency.", "AI": {"tldr": "Systematic evaluation of retrieval configurations for code-focused RAG under realistic compute budgets, yielding practical recommendations.", "motivation": "To identify cost-effective, high-quality retrieval setups for code-oriented generation tasks by comparing chunking, similarity scoring, and splitting granularity across tasks and budget levels.", "method": "Experiments on two Long Code Arena tasks (code completion, bug localization) across various context window sizes. Compare retrieval configurations along three axes: (i) chunking strategy, (ii) similarity scoring, (iii) splitting granularity. Tested PL-PL (sparse BM25 with word-level splitting vs dense), NL-PL (denseVoyager-3 vs sparse), and varied chunk sizes (32-64 line chunks to whole-file). Measured quality and retrieval latency.", "result": "Key findings: (1) PL-PL: BM25 with word-level splitting outperforms dense alternatives and is much faster; (2) NL-PL: dense Voyager-3 encoders outperform sparse retrievers but with ~100x higher latency; (3) Optimal chunk size scales with budget: 32-64 line chunks best at small budgets; whole-file retrieval competitive at ~16000 tokens; (4) Line-based chunking matches syntax-aware splitting across budgets; (5) Retrieval latency varies up to ~200x across configurations; BM25 + word splitting provides best quality-latency trade-off.", "conclusion": "The study offers evidence-based recommendations for building code-oriented RAG systems under budget and model constraints, guiding choices of chunking, scoring, and granularity to balance retrieval quality and latency."}}
{"id": "2510.20794", "categories": ["cs.CV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20794", "abs": "https://arxiv.org/abs/2510.20794", "authors": ["Lei Cheng", "Siyang Cao"], "title": "Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common Feature", "comment": "accepted to IEEE Transactions on Intelligent Transportation Systems\n  (T-ITS)", "summary": "This paper presents a Multi-Object Tracking (MOT) framework that fuses radar\nand camera data to enhance tracking efficiency while minimizing manual\ninterventions. Contrary to many studies that underutilize radar and assign it a\nsupplementary role--despite its capability to provide accurate range/depth\ninformation of targets in a world 3D coordinate system--our approach positions\nradar in a crucial role. Meanwhile, this paper utilizes common features to\nenable online calibration to autonomously associate detections from radar and\ncamera. The main contributions of this work include: (1) the development of a\nradar-camera fusion MOT framework that exploits online radar-camera calibration\nto simplify the integration of detection results from these two sensors, (2)\nthe utilization of common features between radar and camera data to accurately\nderive real-world positions of detected objects, and (3) the adoption of\nfeature matching and category-consistency checking to surpass the limitations\nof mere position matching in enhancing sensor association accuracy. To the best\nof our knowledge, we are the first to investigate the integration of\nradar-camera common features and their use in online calibration for achieving\nMOT. The efficacy of our framework is demonstrated by its ability to streamline\nthe radar-camera mapping process and improve tracking precision, as evidenced\nby real-world experiments conducted in both controlled environments and actual\ntraffic scenarios. Code is available at\nhttps://github.com/radar-lab/Radar_Camera_MOT", "AI": {"tldr": "A radar\u2013camera fusion MOT framework that uses online calibration and shared features to fuse detections, improving 3D positioning and tracking accuracy with real-world validations; code released.", "motivation": "Radar provides accurate range/depth information in 3D space but is often underutilized in MOT; there is a need for online calibration and effective fusion to reduce manual intervention and improve association.", "method": "Develop a radar-camera fusion MOT framework; employ online radar\u2013camera calibration to align detections; exploit common features to derive real-world positions; use feature matching and category-consistency checks to improve sensor association beyond simple position matching; validate with real-world experiments in controlled and traffic environments; release code.", "result": "Streamlines radar-camera mapping process and improves tracking precision; demonstrated in controlled and traffic scenarios; open-source code available.", "conclusion": "First to investigate integration of radar\u2013camera common features and online calibration for MOT; approach reduces manual intervention and enhances fusion accuracy; code provided."}}
{"id": "2510.20611", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20611", "abs": "https://arxiv.org/abs/2510.20611", "authors": ["Mirza Raquib", "Niloy Das", "Farida Siddiqi Prity", "Arafath Al Fahim", "Saydul Akbar Murad", "Mohammad Amzad Hossain", "MD Jiabul Hoque", "Mohammad Ali Moni"], "title": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection", "comment": null, "summary": "Breast cancer is considered the most critical and frequently diagnosed cancer\nin women worldwide, leading to an increase in cancer-related mortality. Early\nand accurate detection is crucial as it can help mitigate possible threats\nwhile improving survival rates. In terms of prediction, conventional diagnostic\nmethods are often limited by variability, cost, and, most importantly, risk of\nmisdiagnosis. To address these challenges, machine learning (ML) has emerged as\na powerful tool for computer-aided diagnosis, with feature selection playing a\nvital role in improving model performance and interpretability. This research\nstudy proposes an integrated framework that incorporates customized Particle\nSwarm Optimization (PSO) for feature selection. This framework has been\nevaluated on a comprehensive set of 29 different models, spanning classical\nclassifiers, ensemble techniques, neural networks, probabilistic algorithms,\nand instance-based algorithms. To ensure interpretability and clinical\nrelevance, the study uses cross-validation in conjunction with explainable AI\nmethods. Experimental evaluation showed that the proposed approach achieved a\nsuperior score of 99.1\\% across all performance metrics, including accuracy and\nprecision, while effectively reducing dimensionality and providing transparent,\nmodel-agnostic explanations. The results highlight the potential of combining\nswarm intelligence with explainable ML for robust, trustworthy, and clinically\nmeaningful breast cancer diagnosis.", "AI": {"tldr": "An integrated PSO-based feature selection framework evaluated on 29 models for breast cancer diagnosis, achieving 99.1% performance with dimensionality reduction and explainable, model-agnostic explanations.", "motivation": "Conventional diagnostic methods suffer from variability, cost, and misdiagnosis risk; need for accurate, interpretable, low-cost diagnosis; feature selection and explainability to improve performance and clinical relevance.", "method": "Customized Particle Swarm Optimization for feature selection integrated with a broad evaluation over 29 models (classical, ensemble, neural, probabilistic, instance-based); cross-validation combined with explainable AI to ensure interpretability and clinical relevance.", "result": "Superior performance of 99.1% across metrics (accuracy, precision); effective dimensionality reduction; transparent model-agnostic explanations.", "conclusion": "Swarm intelligence combined with explainable ML yields robust, trustworthy, and clinically meaningful breast cancer diagnosis; shows promise for high-performance, interpretable CAD systems."}}
{"id": "2510.20608", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20608", "abs": "https://arxiv.org/abs/2510.20608", "authors": ["Yuta Kawamoto", "Hideaki Iiduka"], "title": "Convergence Analysis of SGD under Expected Smoothness", "comment": "23 pages, 11 figures, AISTATS 2026", "summary": "Stochastic gradient descent (SGD) is the workhorse of large-scale learning,\nyet classical analyses rely on assumptions that can be either too strong\n(bounded variance) or too coarse (uniform noise). The expected smoothness (ES)\ncondition has emerged as a flexible alternative that ties the second moment of\nstochastic gradients to the objective value and the full gradient. This paper\npresents a self-contained convergence analysis of SGD under ES. We (i) refine\nES with interpretations and sampling-dependent constants; (ii) derive bounds of\nthe expectation of squared full gradient norm; and (iii) prove $O(1/K)$ rates\nwith explicit residual errors for various step-size schedules. All proofs are\ngiven in full detail in the appendix. Our treatment unifies and extends recent\nthreads (Khaled and Richt\\'arik, 2020; Umeda and Iiduka, 2025).", "AI": {"tldr": "Convergence analysis of SGD under the expected smoothness (ES) condition, providing self-contained proofs, refined ES constants, bounds on squared full gradient norm, and O(1/K) convergence with explicit residuals; unifies and extends prior ES-based SGD work.", "motivation": "Standard SGD analyses rely on strong bounded-variance or coarse noise assumptions. The ES condition offers a flexible, objective-value\u2013dependent link between gradient moments and the objective, enabling robust convergence results under more realistic stochastic gradients. The paper aims to formalize this under ES, quantify constants, and connect to prior work.", "method": "Develops a self-contained convergence analysis under ES; refines ES with sampling-dependent constants; derives bounds on the expected squared full gradient norm; analyzes SGD with various step-size schedules; provides full proofs in the appendix.", "result": "Establishes O(1/K) convergence rates with explicit residual errors for several step-size schedules; provides explicit bounds for the expected squared full gradient norm under ES; unifies and extends prior results (Khaled & Richt\u00e1rik 2020; Umeda & Iiduka 2025).", "conclusion": "The ES-based framework yields a unified, extensible analysis of SGD with detailed bounds and proofs, clarifying the role of constants and residual terms, and reinforcing ES as a robust alternative to traditional variance assumptions."}}
{"id": "2510.20803", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20803", "abs": "https://arxiv.org/abs/2510.20803", "authors": ["Xiaolong Wang", "Lixiang Ru", "Ziyuan Huang", "Kaixiang Ji", "Dandan Zheng", "Jingdong Chen", "Jun Zhou"], "title": "ARGenSeg: Image Segmentation with Autoregressive Image Generation Model", "comment": "Accepted to NeurIPS 2025, 18 pages", "summary": "We propose a novel AutoRegressive Generation-based paradigm for image\nSegmentation (ARGenSeg), achieving multimodal understanding and pixel-level\nperception within a unified framework. Prior works integrating image\nsegmentation into multimodal large language models (MLLMs) typically employ\neither boundary points representation or dedicated segmentation heads. These\nmethods rely on discrete representations or semantic prompts fed into\ntask-specific decoders, which limits the ability of the MLLM to capture\nfine-grained visual details. To address these challenges, we introduce a\nsegmentation framework for MLLM based on image generation, which naturally\nproduces dense masks for target objects. We leverage MLLM to output visual\ntokens and detokenize them into images using an universal VQ-VAE, making the\nsegmentation fully dependent on the pixel-level understanding of the MLLM. To\nreduce inference latency, we employ a next-scale-prediction strategy to\ngenerate required visual tokens in parallel. Extensive experiments demonstrate\nthat our method surpasses prior state-of-the-art approaches on multiple\nsegmentation datasets with a remarkable boost in inference speed, while\nmaintaining strong understanding capabilities.", "AI": {"tldr": "ARGenSeg introduces an autoregressive generation-based segmentation paradigm for MLLMs, producing dense pixel-level masks by detokenizing visual tokens through a VQ-VAE, with a next-scale-prediction strategy for parallel token generation, achieving SOTA performance with faster inference.", "motivation": "Current multimodal LLM-based segmentation relies on discrete boundary points or dedicated heads, which hamper fine-grained pixel-level perception and seamless multimodal integration. A generation-based, pixel-dense approach promises unified, detailed segmentation within MLLMs.", "method": "Propose ARGenSeg: an image-generation-centric segmentation framework where the MLLM outputs visual tokens that are detokenized into images via a universal VQ-VAE to obtain dense masks. Introduce next-scale-prediction to generate tokens in parallel, reducing latency.", "result": "Extensive experiments show ARGenSeg surpasses prior state-of-the-art on multiple segmentation datasets and offers substantial inference speed gains while preserving strong multimodal understanding.", "conclusion": "Demonstrates the viability and benefits of an image-generation-based segmentation paradigm within MLLMs, enabling dense pixel-level segmentation in a unified, faster framework and suggesting a promising direction for future MLLM-enabled segmentation research."}}
{"id": "2510.20629", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20629", "abs": "https://arxiv.org/abs/2510.20629", "authors": ["Mingxuan Liu", "Yilin Ning", "Haoyuan Wang", "Chuan Hong", "Matthew Engelhard", "Danielle S. Bitterman", "William G. La Cava", "Nan Liu"], "title": "Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach", "comment": null, "summary": "As machine learning models become increasingly integrated into healthcare,\nstructural inequities and social biases embedded in clinical data can be\nperpetuated or even amplified by data-driven models. In survival analysis,\ncensoring and time dynamics can further add complexity to fair model\ndevelopment. Additionally, algorithmic fairness approaches often overlook\ndisparities in cross-group rankings, e.g., high-risk Black patients may be\nranked below lower-risk White patients who do not experience the event of\nmortality. Such misranking can reinforce biological essentialism and undermine\nequitable care. We propose a Fairness-Aware Survival Modeling (FASM), designed\nto mitigate algorithmic bias regarding both intra-group and cross-group risk\nrankings over time. Using breast cancer prognosis as a representative case and\napplying FASM to SEER breast cancer data, we show that FASM substantially\nimproves fairness while preserving discrimination performance comparable to\nfairness-unaware survival models. Time-stratified evaluations show that FASM\nmaintains stable fairness over a 10-year horizon, with the greatest\nimprovements observed during the mid-term of follow-up. Our approach enables\nthe development of survival models that prioritize both accuracy and equity in\nclinical decision-making, advancing fairness as a core principle in clinical\ncare.", "AI": {"tldr": "Introduces Fairness-Aware Survival Modeling (FASM) to reduce intra- and cross-group risk misranking over time in survival analysis, demonstrated on SEER breast cancer data with maintained predictive performance.", "motivation": "Clinical data carry structural inequities and biases; misranking across groups (e.g., Black vs White) can lead to inequitable care. Survival analysis adds censoring and time dynamics, making fairness harder. There is a need for methods that address both intra- and cross-group risk rankings over time.", "method": "Develop FASM to mitigate algorithmic bias in both intra-group and cross-group risk rankings across time. Apply FASM to SEER breast cancer data. Evaluate fairness over a 10-year horizon using time-stratified analyses, comparing fairness and discrimination with fairness-unaware models.", "result": "FASM substantially improves fairness while preserving discrimination (predictive) performance comparable to fairness-unaware models. Time-stratified evaluations show stable fairness over a 10-year horizon, with the greatest improvements during the mid-term follow-up.", "conclusion": "FASM enables survival models that balance accuracy and equity, reinforcing fairness as a core principle in clinical decision-making and potentially reducing disparities in breast cancer prognosis and care."}}
{"id": "2510.20807", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20807", "abs": "https://arxiv.org/abs/2510.20807", "authors": ["Dean L Slack", "G Thomas Hudson", "Thomas Winterbottom", "Noura Al Moubayed"], "title": "Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers", "comment": "14 pages, 14 figures", "summary": "Inspired by the performance and scalability of autoregressive large language\nmodels (LLMs), transformer-based models have seen recent success in the visual\ndomain. This study investigates a transformer adaptation for video prediction\nwith a simple end-to-end approach, comparing various spatiotemporal\nself-attention layouts. Focusing on causal modeling of physical simulations\nover time; a common shortcoming of existing video-generative approaches, we\nattempt to isolate spatiotemporal reasoning via physical object tracking\nmetrics and unsupervised training on physical simulation datasets. We introduce\na simple yet effective pure transformer model for autoregressive video\nprediction, utilizing continuous pixel-space representations for video\nprediction. Without the need for complex training strategies or latent\nfeature-learning components, our approach significantly extends the time\nhorizon for physically accurate predictions by up to 50% when compared with\nexisting latent-space approaches, while maintaining comparable performance on\ncommon video quality metrics. In addition, we conduct interpretability\nexperiments to identify network regions that encode information useful to\nperform accurate estimations of PDE simulation parameters via probing models,\nand find that this generalizes to the estimation of out-of-distribution\nsimulation parameters. This work serves as a platform for further\nattention-based spatiotemporal modeling of videos via a simple, parameter\nefficient, and interpretable approach.", "AI": {"tldr": "A pure transformer, autoregressive model predicts videos directly in pixel space, using causal spatiotemporal attention to model physical simulations; it outperforms latent-space methods by up to 50% in prediction horizon while keeping video quality, and it enables interpretability studies on PDE parameter estimation.", "motivation": "Investigate whether end-to-end, pixel-space, autoregressive transformers can effectively perform video prediction with causal spatiotemporal reasoning, avoiding latent feature learning and complex training tricks, and to understand interpretability related to physical parameter estimation.", "method": "An end-to-end pure transformer for autoregressive video prediction using continuous pixel-space representations. Explores various spatiotemporal self-attention layouts focused on causality. Trains on physical simulation datasets with unsupervised learning and incorporates physical object-tracking metrics to assess spatiotemporal reasoning.", "result": "The model extends the prediction horizon for physically accurate predictions by up to 50% compared with existing latent-space approaches, while achieving comparable video-quality metrics. Interpretability experiments identify network regions encoding information for estimating PDE parameters, and this generalizes to out-of-distribution parameters.", "conclusion": "A simple, parameter-efficient, and interpretable pixel-space transformer serves as a platform for attention-based spatiotemporal video modeling, demonstrating strong causal reasoning and robustness in physical simulations without latent components."}}
{"id": "2510.20812", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.20812", "abs": "https://arxiv.org/abs/2510.20812", "authors": ["Yuhan Liu", "Lianhui Qin", "Shengjie Wang"], "title": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation", "comment": null, "summary": "Large Vision-Language Models (VLMs) have achieved remarkable progress in\nmultimodal understanding, yet they struggle when reasoning over\ninformation-intensive images that densely interleave textual annotations with\nfine-grained graphical elements. The main challenges lie in precisely\nlocalizing critical cues in dense layouts and multi-hop reasoning to integrate\ndispersed evidence. We propose Speculative Verdict (SV), a training-free\nframework inspired by speculative decoding that combines multiple lightweight\ndraft experts with a large verdict model. In the draft stage, small VLMs act as\ndraft experts to generate reasoning paths that provide diverse localization\ncandidates; in the verdict stage, a strong VLM synthesizes these paths to\nproduce the final answer, minimizing computational cost while recovering\ncorrect answers. To further improve efficiency and accuracy, SV introduces a\nconsensus expert selection mechanism that forwards only high-agreement\nreasoning paths to the verdict. Empirically, SV achieves consistent gains on\nchallenging information-intensive and high-resolution visual question answering\nbenchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K.\nBy synthesizing correct insights from multiple partially accurate reasoning\npaths, SV achieves both error correction and cost-efficiency compared to large\nproprietary models or training pipelines. Code is available at\nhttps://github.com/Tinaliu0123/speculative-verdict", "AI": {"tldr": "SV uses training-free speculative decoding with multiple lightweight draft experts and a strong verdict model to propose, filter, and synthesize reasoning paths for dense visual-text tasks, improving accuracy and efficiency.", "motivation": "Large Vision-Language Models struggle with information-dense images that mix text with fine-grained visuals; precise localization and multi-hop reasoning are computationally expensive, motivating a training-free, multi-expert, verdict-based approach.", "method": "In the draft stage, small VLMs act as draft experts to generate diverse reasoning paths with localization candidates. In the verdict stage, a strong VLM synthesizes these paths into the final answer. A consensus expert selection mechanism forwards only high-agreement paths to the verdict, and the framework is training-free.", "result": "SV achieves consistent gains on information-intensive and high-resolution VQA benchmarks\u2014InfographicVQA, ChartMuseum, ChartQAPro, HR-Bench 4K\u2014demonstrating error correction and cost-efficiency compared to large proprietary models or training pipelines.", "conclusion": "SV demonstrates that aggregating multiple partially accurate reasoning paths via a verdict model can recover correct insights while reducing computational cost, offering a practical, training-free route to improved reasoning in VLMs."}}
{"id": "2510.20671", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20671", "abs": "https://arxiv.org/abs/2510.20671", "authors": ["Subham Kumar", "Prakrithi Shivaprakash", "Koustav Rudra", "Lekhansh Shukla", "Animesh Mukherjee"], "title": "GRACE: GRaph-based Addiction Care prEdiction", "comment": null, "summary": "Determining the appropriate locus of care for addiction patients is one of\nthe most critical clinical decisions that affects patient treatment outcomes\nand effective use of resources. With a lack of sufficient specialized treatment\nresources, such as inpatient beds or staff, there is an unmet need to develop\nan automated framework for the same. Current decision-making approaches suffer\nfrom severe class imbalances in addiction datasets. To address this limitation,\nwe propose a novel graph neural network (GRACE) framework that formalizes locus\nof care prediction as a structured learning problem. Further, we perform\nextensive feature engineering and propose a new approach of obtaining an\nunbiased meta-graph to train a GNN to overcome the class imbalance problem.\nExperimental results in real-world data show an improvement of 11-35% in terms\nof the F1 score of the minority class over competitive baselines. The codes and\nnote embeddings are available at https://anonymous.4open.science/r/GRACE-F8E1/.", "AI": {"tldr": "Graph neural network GRACE for predicting locus of care in addiction treatment, addressing class imbalance with an unbiased meta-graph; shows 11-35% improvement in minority-class F1 on real data; code and embeddings released.", "motivation": "Determining the appropriate locus of care for addiction patients is critical but constrained by limited specialized resources. Existing decision methods suffer from severe class imbalance in addiction datasets, necessitating an automated framework to improve decision quality and resource use.", "method": "Formalizes locus-of-care prediction as a structured learning problem using a graph neural network (GRACE). Performs extensive feature engineering and introduces an unbiased meta-graph to train the GNN and mitigate class imbalance.", "result": "Real-world experiments show an 11-35% improvement in F1 score for the minority class over competitive baselines.", "conclusion": "The GRACE framework demonstrates the potential of graph-based, structured learning to improve locus-of-care decisions under resource constraints, and the authors provide code and note embeddings for reproducibility."}}
{"id": "2510.20615", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20615", "abs": "https://arxiv.org/abs/2510.20615", "authors": ["Yang Han", "Pengyu Wang", "Kai Yu", "Xin Chen", "Lu Chen"], "title": "MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure Elucidation", "comment": "NeurIPS 2025, We provide the data and code at\n  https://github.com/OpenDFM/MS-BART", "summary": "Mass spectrometry (MS) plays a critical role in molecular identification,\nsignificantly advancing scientific discovery. However, structure elucidation\nfrom MS data remains challenging due to the scarcity of annotated spectra.\nWhile large-scale pretraining has proven effective in addressing data scarcity\nin other domains, applying this paradigm to mass spectrometry is hindered by\nthe complexity and heterogeneity of raw spectral signals. To address this, we\npropose MS-BART, a unified modeling framework that maps mass spectra and\nmolecular structures into a shared token vocabulary, enabling cross-modal\nlearning through large-scale pretraining on reliably computed\nfingerprint-molecule datasets. Multi-task pretraining objectives further\nenhance MS-BART's generalization by jointly optimizing denoising and\ntranslation task. The pretrained model is subsequently transferred to\nexperimental spectra through finetuning on fingerprint predictions generated\nwith MIST, a pre-trained spectral inference model, thereby enhancing robustness\nto real-world spectral variability. While finetuning alleviates the\ndistributional difference, MS-BART still suffers molecular hallucination and\nrequires further alignment. We therefore introduce a chemical feedback\nmechanism that guides the model toward generating molecules closer to the\nreference structure. Extensive evaluations demonstrate that MS-BART achieves\nSOTA performance across 5/12 key metrics on MassSpecGym and NPLIB1 and is\nfaster by one order of magnitude than competing diffusion-based methods, while\ncomprehensive ablation studies systematically validate the model's\neffectiveness and robustness.", "AI": {"tldr": "MS-BART introduces a unified cross-modal pretraining framework that maps mass spectra and molecular structures into a shared token space, enabling robust structure elucidation from MS data. It achieves state-of-the-art performance on key metrics, runs substantially faster than diffusion-based methods, and uses a chemical-feedback mechanism to reduce molecular hallucinations.", "motivation": "Elucidating molecular structures from mass spectrometry (MS) data is challenging due to limited annotated spectra, data scarcity, and the heterogeneity of raw spectra. There is a need to leverage large-scale pretraining to improve generalization, but cross-domain spectral complexity hinders straightforward adaptation.", "method": "MS-BART maps mass spectra and molecular structures into a shared token vocabulary to enable cross-modal pretraining on fingerprint\u2013molecule datasets. It uses multi-task pretraining with denoising and translation objectives, and transfers to experimental spectra by finetuning on fingerprint predictions from MIST (a pre-trained spectral inference model). A chemical feedback mechanism guides outputs toward reference structures, addressing molecular hallucination. The model is evaluated with ablations, and compared against diffusion-based methods on MassSpecGym and NPLIB1 datasets.", "result": "MS-BART achieves state-of-the-art performance on 5 out of 12 key metrics across MassSpecGym and NPLIB1. It is faster by about an order of magnitude compared to competing diffusion-based approaches. Ablation studies validate the contributions of cross-modal pretraining, multi-task objectives, fingerprint-level finetuning, and chemical feedback for robustness and accuracy.", "conclusion": "Cross-modal pretraining that aligns spectra and chemical structures in a shared token space can significantly improve MS-based structure elucidation. The combination of finetuning on fingerprint predictions and a chemical feedback loop mitigates distributional shifts and hallucination, yielding robust performance and runtime advantages over diffusion-based methods; future work could further refine alignment and reduce remaining hallucinations."}}
{"id": "2510.20814", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20814", "abs": "https://arxiv.org/abs/2510.20814", "authors": ["Ritik Shah", "Marco F Duarte"], "title": "SpectraMorph: Structured Latent Learning for Self-Supervised Hyperspectral Super-Resolution", "comment": null, "summary": "Hyperspectral sensors capture dense spectra per pixel but suffer from low\nspatial resolution, causing blurred boundaries and mixed-pixel effects.\nCo-registered companion sensors such as multispectral, RGB, or panchromatic\ncameras provide high-resolution spatial detail, motivating hyperspectral\nsuper-resolution through the fusion of hyperspectral and multispectral images\n(HSI-MSI). Existing deep learning based methods achieve strong performance but\nrely on opaque regressors that lack interpretability and often fail when the\nMSI has very few bands. We propose SpectraMorph, a physics-guided\nself-supervised fusion framework with a structured latent space. Instead of\ndirect regression, SpectraMorph enforces an unmixing bottleneck: endmember\nsignatures are extracted from the low-resolution HSI, and a compact multilayer\nperceptron predicts abundance-like maps from the MSI. Spectra are reconstructed\nby linear mixing, with training performed in a self-supervised manner via the\nMSI sensor's spectral response function. SpectraMorph produces interpretable\nintermediates, trains in under a minute, and remains robust even with a\nsingle-band (pan-chromatic) MSI. Experiments on synthetic and real-world\ndatasets show SpectraMorph consistently outperforming state-of-the-art\nunsupervised/self-supervised baselines while remaining very competitive against\nsupervised baselines.", "AI": {"tldr": "SpectraMorph offers a physics-guided, self-supervised fusion framework for hyperspectral super-resolution that enforces a unmixing bottleneck for interpretable, robust fusion even with very limited MSI bands.", "motivation": "Hyperspectral images have rich spectral information but low spatial resolution, causing mixed pixels; high-resolution MSI/ RGB provide spatial detail but lack spectral richness. There is a need for interpretable, robust fusion methods that work with few spectral bands and do not rely on opaque regressors.", "method": "SpectraMorph uses a structured latent space with an unmixing bottleneck: endmember signatures are derived from the low-res HSI, while a compact MLP predicts abundance-like maps from the MSI. Spectra are reconstructed via linear spectral mixing, trained self-supervised using the MSI sensor's spectral response function.", "result": "Experiments on synthetic and real datasets show SpectraMorph consistently outperforms state-of-the-art unsupervised/self-supervised baselines and remains very competitive against supervised baselines. It trains in under a minute, produces interpretable intermediates, and is robust even with a single-band MSI (pan).", "conclusion": "A principled, interpretable fusion framework that leverages physics-based unmixing and self-supervision achieves strong performance and robustness for HSI-MSI fusion, including extreme cases with very limited MSI bands."}}
{"id": "2510.20683", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20683", "abs": "https://arxiv.org/abs/2510.20683", "authors": ["Georgios Mentzelopoulos", "Ioannis Asmanis", "Konrad P. Kording", "Eva L. Dyer", "Kostas Daniilidis", "Flavia Vitale"], "title": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks", "comment": null, "summary": "Brain-computer interfaces (BCIs) promise to enable vital functions, such as\nspeech and prosthetic control, for individuals with neuromotor impairments.\nCentral to their success are neural decoders, models that map neural activity\nto intended behavior. Current learning-based decoding approaches fall into two\nclasses: simple, causal models that lack generalization, or complex, non-causal\nmodels that generalize and scale offline but struggle in real-time settings.\nBoth face a common challenge, their reliance on power-hungry artificial neural\nnetwork backbones, which makes integration into real-world, resource-limited\nsystems difficult. Spiking neural networks (SNNs) offer a promising\nalternative. Because they operate causally these models are suitable for\nreal-time use, and their low energy demands make them ideal for\nbattery-constrained environments. To this end, we introduce Spikachu: a\nscalable, causal, and energy-efficient neural decoding framework based on SNNs.\nOur approach processes binned spikes directly by projecting them into a shared\nlatent space, where spiking modules, adapted to the timing of the input,\nextract relevant features; these latent representations are then integrated and\ndecoded to generate behavioral predictions. We evaluate our approach on 113\nrecording sessions from 6 non-human primates, totaling 43 hours of recordings.\nOur method outperforms causal baselines when trained on single sessions using\nbetween 2.26 and 418.81 times less energy. Furthermore, we demonstrate that\nscaling up training to multiple sessions and subjects improves performance and\nenables few-shot transfer to unseen sessions, subjects, and tasks. Overall,\nSpikachu introduces a scalable, online-compatible neural decoding framework\nbased on SNNs, whose performance is competitive relative to state-of-the-art\nmodels while consuming orders of magnitude less energy.", "AI": {"tldr": "Spikachu is a scalable, causal, energy-efficient spiking neural network decoder for brain-computer interfaces that processes binned spikes in a shared latent space to achieve competitive performance with orders of magnitude energy savings, and supports few-shot transfer across sessions and subjects.", "motivation": "Deliver real-time, low-power neural decoding for BCIs while maintaining generalization and scalability, addressing limitations of simple causal models and complex offline non-causal models that are energy-intensive.", "method": "A Spiking Neural Network-based decoding framework that directly processes binned spikes, projects them into a shared latent space, uses timing-adapted spiking modules to extract features, integrates latent representations, and decodes behavioral predictions. Evaluated on 113 sessions from 6 non-human primates (~43 hours). Compared to causal baselines, showing much lower energy consumption (2.26x to 418.81x) and improved performance with multi-session training enabling few-shot transfer.", "result": "Spikachu outperforms causal baselines in single-session settings while consuming significantly less energy. Scaling training across multiple sessions and subjects improves performance and enables few-shot transfer to unseen sessions, subjects, and tasks.", "conclusion": "Spikachu demonstrates that a scalable, online-compatible SNN-based decoder can achieve competitive decoding performance with substantially reduced energy consumption, making it a strong candidate for real-world, battery-powered BCI deployments."}}
{"id": "2510.20616", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20616", "abs": "https://arxiv.org/abs/2510.20616", "authors": ["Aki Rehn", "Linzh Zhao", "Mikko A. Heikkil\u00e4", "Antti Honkela"], "title": "On Optimal Hyperparameters for Differentially Private Deep Transfer Learning", "comment": "25 pages, 30 figures", "summary": "Differentially private (DP) transfer learning, i.e., fine-tuning a pretrained\nmodel on private data, is the current state-of-the-art approach for training\nlarge models under privacy constraints. We focus on two key hyperparameters in\nthis setting: the clipping bound $C$ and batch size $B$. We show a clear\nmismatch between the current theoretical understanding of how to choose an\noptimal $C$ (stronger privacy requires smaller $C$) and empirical outcomes\n(larger $C$ performs better under strong privacy), caused by changes in the\ngradient distributions. Assuming a limited compute budget (fixed epochs), we\ndemonstrate that the existing heuristics for tuning $B$ do not work, while\ncumulative DP noise better explains whether smaller or larger batches perform\nbetter. We also highlight how the common practice of using a single $(C,B)$\nsetting across tasks can lead to suboptimal performance. We find that\nperformance drops especially when moving between loose and tight privacy and\nbetween plentiful and limited compute, which we explain by analyzing clipping\nas a form of gradient re-weighting and examining cumulative DP noise.", "AI": {"tldr": "In DP transfer learning, the common hyperparameters C (clip bound) and B (batch size) show a theory-vs-practice mismatch: larger C can help under strong privacy, contrary to the belief that smaller C is always better for privacy. Batch-size heuristics fail under fixed compute, while cumulative DP noise better explains performance. Across tasks, a single (C,B) setting hurts results, with bigger drops when moving between privacy and compute regimes.", "motivation": "To understand and improve hyperparameter tuning for differentially private fine-tuning of large pretrained models, specifically how clipping bound and batch size interact with privacy constraints and compute budgets, and why theory and empirical results diverge.", "method": "Theoretical and empirical analysis of DP-SGD with varying clip bound C and batch size B under different privacy budgets and fixed compute. Examine gradient distributions, clipping as gradient re-weighting, and accumulation of DP noise (cumulative DP). Evaluate across tasks to see cross-task effects of using a single (C,B).", "result": "There is a clear mismatch between theory and practice: stronger privacy does not necessarily require smaller C; larger C can improve performance under strong privacy due to changes in gradient distributions. Existing heuristics for B tuning fail under fixed compute budgets; cumulative DP noise provides a better explanation for when smaller versus larger batches are advantageous. Using a single (C,B) across tasks leads to suboptimal performance and larger performance drops when transitioning between privacy regimes and compute regimes. Clipping acts as a form of gradient re-weighting, which, together with cumulative DP noise, explains these trends.", "conclusion": "Hyperparameter tuning for DP transfer learning should account for gradient distribution changes and cumulative DP noise, and must be adapted per task and regime (privacy vs compute). One-size-fits-all (C,B) settings are suboptimal; developing DP-aware tuning strategies that consider how clipping reweights gradients and how DP noise accumulates is crucial for robust performance across tasks and privacy/compute regimes."}}
{"id": "2510.20819", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20819", "abs": "https://arxiv.org/abs/2510.20819", "authors": ["Nimrod Berman", "Omkar Joglekar", "Eitan Kosman", "Dotan Di Castro", "Omri Azencot"], "title": "Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge", "comment": null, "summary": "Recent advances in generative modeling have positioned diffusion models as\nstate-of-the-art tools for sampling from complex data distributions. While\nthese models have shown remarkable success across single-modality domains such\nas images and audio, extending their capabilities to Modality Translation (MT),\ntranslating information across different sensory modalities, remains an open\nchallenge. Existing approaches often rely on restrictive assumptions, including\nshared dimensionality, Gaussian source priors, and modality-specific\narchitectures, which limit their generality and theoretical grounding. In this\nwork, we propose the Latent Denoising Diffusion Bridge Model (LDDBM), a\ngeneral-purpose framework for modality translation based on a latent-variable\nextension of Denoising Diffusion Bridge Models. By operating in a shared latent\nspace, our method learns a bridge between arbitrary modalities without\nrequiring aligned dimensions. We introduce a contrastive alignment loss to\nenforce semantic consistency between paired samples and design a\ndomain-agnostic encoder-decoder architecture tailored for noise prediction in\nlatent space. Additionally, we propose a predictive loss to guide training\ntoward accurate cross-domain translation and explore several training\nstrategies to improve stability. Our approach supports arbitrary modality pairs\nand performs strongly on diverse MT tasks, including multi-view to 3D shape\ngeneration, image super-resolution, and multi-view scene synthesis.\nComprehensive experiments and ablations validate the effectiveness of our\nframework, establishing a new strong baseline in general modality translation.\nFor more information, see our project page:\nhttps://sites.google.com/view/lddbm/home.", "AI": {"tldr": "LDDBM offers a latent-variable diffusion bridge approach for general modality translation across arbitrary modalities by learning a shared latent space with contrastive alignment and predictive losses, outperforming existing MT methods and establishing a strong new baseline.", "motivation": "Current modality translation methods rely on restrictive assumptions (shared dimensionality, Gaussian priors, modality-specific architectures) and lack a unified theoretical framework. There is a need for a general, domain-agnostic approach to cross-modal translation that can handle arbitrary modality pairs.", "method": "Propose Latent Denoising Diffusion Bridge Model (LDDBM): a latent-variable extension of denoising diffusion bridge models operating in a shared latent space; a domain-agnostic encoder-decoder architecture for latent-space noise prediction; a contrastive alignment loss to enforce semantic consistency between paired samples; a predictive loss to guide training toward accurate cross-domain translation; multiple training strategies to improve stability; supports arbitrary modality pairs.", "result": "Demonstrates strong performance on diverse modality translation tasks including multi-view to 3D shape generation, image super-resolution, and multi-view scene synthesis; comprehensive experiments and ablations validate effectiveness and establish a new strong baseline in general modality translation.", "conclusion": "LDDBM provides a general, flexible, and stable framework for modality translation that transcends restrictive priors and dimensional mismatches, enabling broad cross-modal translation and setting a foundation for future work in general modality translation."}}
{"id": "2510.20627", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20627", "abs": "https://arxiv.org/abs/2510.20627", "authors": ["Lukas Miklautz", "Chengzhi Shi", "Andrii Shkabrii", "Theodoros Thirimachos Davarakis", "Prudence Lam", "Claudia Plant", "Jennifer Dy", "Stratis Ioannidis"], "title": "H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition", "comment": "Accepted at NeurIPS 2025", "summary": "We introduce H-SPLID, a novel algorithm for learning salient feature\nrepresentations through the explicit decomposition of salient and non-salient\nfeatures into separate spaces. We show that H-SPLID promotes learning\nlow-dimensional, task-relevant features. We prove that the expected prediction\ndeviation under input perturbations is upper-bounded by the dimension of the\nsalient subspace and the Hilbert-Schmidt Independence Criterion (HSIC) between\ninputs and representations. This establishes a link between robustness and\nlatent representation compression in terms of the dimensionality and\ninformation preserved. Empirical evaluations on image classification tasks show\nthat models trained with H-SPLID primarily rely on salient input components, as\nindicated by reduced sensitivity to perturbations affecting non-salient\nfeatures, such as image backgrounds. Our code is available at\nhttps://github.com/neu-spiral/H-SPLID.", "AI": {"tldr": "H-SPLID learns salient and non-salient features in separate latent spaces, producing compact, task-relevant representations; robustness to perturbations is upper-bounded by the salient subspace dimension and HSIC, with empirical gains on image classification showing reduced sensitivity to background perturbations; code is released.", "motivation": "To enhance robustness and generalization by explicitly disentangling salient features from nuisance features, linking robustness to latent representation compression via a measurable dependence (HSIC).", "method": "Introduce H-SPLID, an algorithm that explicitly decomposes representations into salient and non-salient subspaces. Derive an upper bound on expected prediction deviation under input perturbations that depends on the salient subspace dimension and the HSIC between inputs and representations. Validate empirically on image classification, showing models favor salient components.", "result": "The paper establishes a theoretical bound tying robustness to the dimensionality of salient representations and their dependence with inputs via HSIC. Empirically, models trained with H-SPLID rely more on salient input components and exhibit reduced sensitivity to perturbations/changes in non-salient features (e.g., backgrounds).", "conclusion": "H-SPLID provides a principled framework for learning robust, compact representations by separating salient from non-salient features, with a proven perturbation bound and empirical evidence; code is publicly available for replication."}}
{"id": "2510.20820", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20820", "abs": "https://arxiv.org/abs/2510.20820", "authors": ["Guocheng Gordon Qian", "Ruihang Zhang", "Tsai-Shien Chen", "Yusuf Dalva", "Anujraaj Argo Goyal", "Willi Menapace", "Ivan Skorokhodov", "Meng Dong", "Arpit Sahni", "Daniil Ostashev", "Ju Hu", "Sergey Tulyakov", "Kuan-Chieh Jackson Wang"], "title": "LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas", "comment": "9 pages, preprint", "summary": "Despite their impressive visual fidelity, existing personalized generative\nmodels lack interactive control over spatial composition and scale poorly to\nmultiple subjects. To address these limitations, we present LayerComposer, an\ninteractive framework for personalized, multi-subject text-to-image generation.\nOur approach introduces two main contributions: (1) a layered canvas, a novel\nrepresentation in which each subject is placed on a distinct layer, enabling\nocclusion-free composition; and (2) a locking mechanism that preserves selected\nlayers with high fidelity while allowing the remaining layers to adapt flexibly\nto the surrounding context. Similar to professional image-editing software, the\nproposed layered canvas allows users to place, resize, or lock input subjects\nthrough intuitive layer manipulation. Our versatile locking mechanism requires\nno architectural changes, relying instead on inherent positional embeddings\ncombined with a new complementary data sampling strategy. Extensive experiments\ndemonstrate that LayerComposer achieves superior spatial control and identity\npreservation compared to the state-of-the-art methods in multi-subject\npersonalized image generation.", "AI": {"tldr": "LayerComposer introduces a layered, interactive canvas for multi-subject personalized text-to-image generation, featuring per-subject layers and a locking mechanism to preserve fidelity while allowing other layers to adapt, enabling occlusion-free composition and superior spatial control relative to prior methods.", "motivation": "Current personalized multi-subject T2I models struggle with interactive spatial control, occlusion-free composition, and fidelity across multiple subjects. A layer-based representation and a locking mechanism could provide intuitive, professional-grade control without altering model architectures.", "method": "Propose LayerComposer with a layered canvas where each subject occupies a distinct layer, enabling occlusion-free composition. Introduce a locking mechanism that preserves selected layers\u2019 content with high fidelity while letting other layers adapt to context. This mechanism relies on inherent positional embeddings and a novel data sampling strategy, requiring no architectural changes.", "result": "Empirical evaluations show LayerComposer achieves superior spatial control and identity preservation compared to state-of-the-art multi-subject personalized image generation methods.", "conclusion": "LayerComposer enables precise, interactive control over multi-subject generation through a layer-based representation and a non-invasive locking mechanism, delivering improved composition quality and identity fidelity without modifying underlying architectures."}}
{"id": "2510.20718", "categories": ["cs.LG", "cs.AI", "I.2.0; J.6"], "pdf": "https://arxiv.org/pdf/2510.20718", "abs": "https://arxiv.org/abs/2510.20718", "authors": ["Daniel Sorensen", "Bappaditya Dey", "Minjin Hwang", "Sandip Halder"], "title": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series", "comment": "17 pages, 27 figures", "summary": "Semiconductor manufacturing is an extremely complex and precision-driven\nprocess, characterized by thousands of interdependent parameters collected\nacross diverse tools and process steps. Multi-variate time-series analysis has\nemerged as a critical field for real-time monitoring and fault detection in\nsuch environments. However, anomaly prediction in semiconductor fabrication\npresents several critical challenges, including high dimensionality of sensor\ndata and severe class imbalance due to the rarity of true faults. Furthermore,\nthe complex interdependencies between variables complicate both anomaly\nprediction and root-cause-analysis. This paper proposes two novel approaches to\nadvance the field from anomaly detection to anomaly prediction, an essential\nstep toward enabling real-time process correction and proactive fault\nprevention. The proposed anomaly prediction framework contains two main stages:\n(a) training a forecasting model on a dataset assumed to contain no anomalies,\nand (b) performing forecast on unseen time series data. The forecast is\ncompared with the forecast of the trained signal. Deviations beyond a\npredefined threshold are flagged as anomalies. The two approaches differ in the\nforecasting model employed. The first assumes independence between variables by\nutilizing the N-BEATS model for univariate time series forecasting. The second\nlifts this assumption by utilizing a Graph Neural Network (GNN) to capture\ninter-variable relationships. Both models demonstrate strong forecasting\nperformance up to a horizon of 20 time points and maintain stable anomaly\nprediction up to 50 time points. The GNN consistently outperforms the N-BEATS\nmodel while requiring significantly fewer trainable parameters and lower\ncomputational cost. These results position the GNN as promising solution for\nonline anomaly forecasting to be deployed in manufacturing environments.", "AI": {"tldr": "Forecast-based anomaly prediction for semiconductor manufacturing using univariate N-BEATS and a Graph Neural Network to capture inter-variable dependencies; GNN achieves higher accuracy with fewer parameters, enabling online anomaly forecasting for proactive fault prevention.", "motivation": "High-dimensional, imbalanced, and interdependent multivariate time-series data in semiconductor fabrication make fault prediction challenging; advancing from anomaly detection to proactive anomaly prediction enables real-time process correction and prevention.", "method": "Two-stage approach: (a) train a forecasting model on data assumed anomaly-free; (b) forecast on unseen data and flag anomalies where observed deviations exceed a threshold. Two variants: (1) univariate N-BEATS assuming variable independence; (2) Graph Neural Network capturing inter-variable relationships.", "result": "Forecasting performance up to 20 time steps; anomaly prediction remains stable up to 50 time steps. The GNN consistently outperforms N-BEATS and does so with significantly fewer trainable parameters and lower computational cost.", "conclusion": "Graph-based online anomaly forecasting is a promising solution for manufacturing, enabling real-time process correction and proactive fault prevention."}}
{"id": "2510.20822", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20822", "abs": "https://arxiv.org/abs/2510.20822", "authors": ["Yihao Meng", "Hao Ouyang", "Yue Yu", "Qiuyu Wang", "Wen Wang", "Ka Leong Cheng", "Hanlin Wang", "Yixuan Li", "Cheng Chen", "Yanhong Zeng", "Yujun Shen", "Huamin Qu"], "title": "HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives", "comment": "Project page and code: https://holo-cine.github.io/", "summary": "State-of-the-art text-to-video models excel at generating isolated clips but\nfall short of creating the coherent, multi-shot narratives, which are the\nessence of storytelling. We bridge this \"narrative gap\" with HoloCine, a model\nthat generates entire scenes holistically to ensure global consistency from the\nfirst shot to the last. Our architecture achieves precise directorial control\nthrough a Window Cross-Attention mechanism that localizes text prompts to\nspecific shots, while a Sparse Inter-Shot Self-Attention pattern (dense within\nshots but sparse between them) ensures the efficiency required for minute-scale\ngeneration. Beyond setting a new state-of-the-art in narrative coherence,\nHoloCine develops remarkable emergent abilities: a persistent memory for\ncharacters and scenes, and an intuitive grasp of cinematic techniques. Our work\nmarks a pivotal shift from clip synthesis towards automated filmmaking, making\nend-to-end cinematic creation a tangible future. Our code is available at:\nhttps://holo-cine.github.io/.", "AI": {"tldr": "HoloCine generates end-to-end, coherent multi-shot cinematic scenes with directorial control via Window Cross-Attention and efficient Sparse Inter-Shot Self-Attention, advancing narrative coherence.", "motivation": "Current text-to-video models produce isolated clips and fail to deliver coherent, long-form narratives; there is a need for end-to-end cinematic generation with global consistency across shots.", "method": "Window Cross-Attention localizes text prompts to specific shots to control narrative direction; Sparse Inter-Shot Self-Attention is dense within shots but sparse across shots to maintain efficiency for minute-scale generation; holistic scene generation with memory for characters/scenes and emergent cinematic capabilities.", "result": "Achieves state-of-the-art narrative coherence, exhibits persistent memory for characters and scenes, and demonstrates emergent cinematic techniques; code is released for reproducibility.", "conclusion": "Marks a shift from clip synthesis toward automated filmmaking, moving toward end-to-end cinematic creation as a tangible future."}}
{"id": "2510.20733", "categories": ["cs.LG", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.20733", "abs": "https://arxiv.org/abs/2510.20733", "authors": ["Yujia Zheng", "Zhuokai Zhao", "Zijian Li", "Yaqi Xie", "Mingze Gao", "Lizhu Zhang", "Kun Zhang"], "title": "Thought Communication in Multiagent Collaboration", "comment": "NeurIPS 2025 Spotlight", "summary": "Natural language has long enabled human cooperation, but its lossy,\nambiguous, and indirect nature limits the potential of collective intelligence.\nWhile machines are not subject to these constraints, most LLM-based multi-agent\nsystems still rely solely on natural language, exchanging tokens or their\nembeddings. To go beyond language, we introduce a new paradigm, thought\ncommunication, which enables agents to interact directly mind-to-mind, akin to\ntelepathy. To uncover these latent thoughts in a principled way, we formalize\nthe process as a general latent variable model, where agent states are\ngenerated by an unknown function of underlying thoughts. We prove that, in a\nnonparametric setting without auxiliary information, both shared and private\nlatent thoughts between any pair of agents can be identified. Moreover, the\nglobal structure of thought sharing, including which agents share which\nthoughts and how these relationships are structured, can also be recovered with\ntheoretical guarantees. Guided by the established theory, we develop a\nframework that extracts latent thoughts from all agents prior to communication\nand assigns each agent the relevant thoughts, along with their sharing\npatterns. This paradigm naturally extends beyond LLMs to all modalities, as\nmost observational data arise from hidden generative processes. Experiments on\nboth synthetic and real-world benchmarks validate the theory and demonstrate\nthe collaborative advantages of thought communication. We hope this work\nilluminates the potential of leveraging the hidden world, as many challenges\nremain unsolvable through surface-level observation alone, regardless of\ncompute or data scale.", "AI": {"tldr": "A latent 'thought communication' paradigm for multi-agent systems that identifies and transfers hidden thoughts (latent variables) to improve cooperation, with nonparametric identifiability guarantees and a practical framework, validated on synthetic and real data.", "motivation": "Natural language is lossy and ambiguous, limiting collective intelligence. To unlock cooperation beyond surface-level language, this work proposes direct mind-to-mind thought communication, underpinned by theory that latent thoughts can be identified and shared even without auxiliary information, and a framework to extract and assign thoughts to agents.", "method": "Formulate the problem as a general latent variable model where agent states are generated by underlying thoughts; prove identifiability of both shared and private latent thoughts between any pair of agents in a nonparametric setting without auxiliary information; infer the global structure of thought sharing; develop a framework that extracts latent thoughts from all agents before communication and assigns relevant thoughts to each agent with sharing patterns; extend beyond LLMs to all modalities.", "result": "Theoretical guarantees of identifiability and recoverable thought-sharing structure; empirical validation on synthetic and real-world benchmarks showing collaborative advantages of thought communication.", "conclusion": "The work highlights a hidden layer of information that can enhance coordination beyond surface observations; many challenges remain unsolved with surface data alone, regardless of compute or data scale; the paradigm extends beyond LLMs to all modalities and may generalize to various observational domains."}}
{"id": "2510.20637", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20637", "abs": "https://arxiv.org/abs/2510.20637", "authors": ["Hyun Jong Yang", "Hyunsoo Kim", "Hyeonho Noh", "Seungnyun Kim", "Byonghyo Shim"], "title": "Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges", "comment": null, "summary": "Large language models (LLMs) and large multimodal models (LMMs) have achieved\nunprecedented breakthrough, showcasing remarkable capabilities in natural\nlanguage understanding, generation, and complex reasoning. This transformative\npotential has positioned them as key enablers for 6G autonomous communications\namong machines, vehicles, and humanoids. In this article, we provide an\noverview of task-oriented autonomous communications with LLMs/LMMs, focusing on\nmultimodal sensing integration, adaptive reconfiguration, and\nprompt/fine-tuning strategies for wireless tasks. We demonstrate the framework\nthrough three case studies: LMM-based traffic control, LLM-based robot\nscheduling, and LMM-based environment-aware channel estimation. From\nexperimental results, we show that the proposed LLM/LMM-aided autonomous\nsystems significantly outperform conventional and discriminative deep learning\n(DL) model-based techniques, maintaining robustness under dynamic objectives,\nvarying input parameters, and heterogeneous multimodal conditions where\nconventional static optimization degrades.", "AI": {"tldr": "LLMs/LMMs enable task-oriented autonomous communications in 6G by integrating multimodal sensing, adaptive reconfiguration, and prompting/fine-tuning; demonstrated in traffic control, robot scheduling, and environment-aware channel estimation with superior robustness and performance over traditional DL methods.", "motivation": "Address limitations of traditional discriminative DL and static optimization in dynamic, multimodal wireless environments; need for adaptable, reasoning-based autonomy in 6G networks.", "method": "Propose a framework combining LLMs/LMMs for multimodal sensing integration and adaptive system reconfiguration; apply three case studies to illustrate; compare against conventional DL methods.", "result": "LLM/LMM-aided systems significantly outperform conventional/discriminative DL approaches, maintain robustness under dynamic objectives, input variations, and heterogeneous multimodal data.", "conclusion": "LLM/LMM-driven autonomous communications are promising for future 6G, enabling resilient, context-aware wireless tasks; further research needed on integration, prompting strategies, and real-time constraints."}}
{"id": "2510.20640", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20640", "abs": "https://arxiv.org/abs/2510.20640", "authors": ["Fiza Hussain", "Anson Bastos", "Anjaly Parayil", "Ayush Choure", "Chetan Bansal", "Rujia Wang", "Saravan Rajmohan"], "title": "Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems", "comment": null, "summary": "In this paper, we present DiRecGNN, an attention-enhanced entity\nrecommendation framework for monitoring cloud services at Microsoft. We provide\ninsights on the usefulness of this feature as perceived by the cloud service\nowners and lessons learned from deployment. Specifically, we introduce the\nproblem of recommending the optimal subset of attributes (dimensions) that\nshould be tracked by an automated watchdog (monitor) for cloud services. To\nbegin, we construct the monitor heterogeneous graph at production-scale. The\ninteraction dynamics of these entities are often characterized by limited\nstructural and engagement information, resulting in inferior performance of\nstate-of-the-art approaches. Moreover, traditional methods fail to capture the\ndependencies between entities spanning a long range due to their homophilic\nnature. Therefore, we propose an attention-enhanced entity ranking model\ninspired by transformer architectures. Our model utilizes a multi-head\nattention mechanism to focus on heterogeneous neighbors and their attributes,\nand further attends to paths sampled using random walks to capture long-range\ndependencies. We also employ multi-faceted loss functions to optimize for\nrelevant recommendations while respecting the inherent sparsity of the data.\nEmpirical evaluations demonstrate significant improvements over existing\nmethods, with our model achieving a 43.1% increase in MRR. Furthermore, product\nteams who consumed these features perceive the feature as useful and rated it\n4.5 out of 5.", "AI": {"tldr": "Attention-enhanced DiRecGNN ranks entities to decide which attributes to monitor for cloud services; achieves 43.1% MRR gain; users rate usefulness 4.5/5.", "motivation": "Address the problem of selecting a subset of attributes (dimensions) to monitor with a watchdog in production cloud services; overcome data sparsity and long-range dependencies in monitor heterogeneous graphs.", "method": "Propose DiRecGNN with multi-head attention over heterogeneous neighbors and attributes; uses random-walk sampled paths to capture long-range dependencies; transformer-inspired attention; multi-faceted loss to handle sparsity and optimize relevance of recommendations.", "result": "Empirical evaluations show significant improvements over baselines, including 43.1% increase in MRR.", "conclusion": "Feature is useful to product teams; deployment yields practical insights; attention-based relational modeling is effective for attribute subset recommendations in cloud monitoring."}}
{"id": "2510.20800", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20800", "abs": "https://arxiv.org/abs/2510.20800", "authors": ["Shiva Sreeram", "Alaa Maalouf", "Pratyusha Sharma", "Daniela Rus"], "title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "comment": null, "summary": "Recently, Sharma et al. suggested a method called Layer-SElective-Rank\nreduction (LASER) which demonstrated that pruning high-order components of\ncarefully chosen LLM's weight matrices can boost downstream accuracy -- without\nany gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each\nrequiring full-dataset forward passes) makes it impractical for rapid\ndeployment. We demonstrate that this overhead can be removed and find that: (i)\nOnly a small, carefully chosen subset of matrices needs to be inspected --\neliminating the layer-by-layer sweep, (ii) The gradient of each matrix's\nsingular values pinpoints which matrices merit reduction, (iii) Increasing the\nfactorization search space by allowing matrices rows to cluster around multiple\nsubspaces and then decomposing each cluster separately further reduces\noverfitting on the original training data and further lifts accuracy by up to\n24.6 percentage points, and finally, (iv) we discover that evaluating on just\n100 samples rather than the full training data -- both for computing the\nindicative gradients and for measuring the final accuracy -- suffices to\nfurther reduce the search time; we explain that as adaptation to downstream\ntasks is dominated by prompting style, not dataset size. As a result, we show\nthat combining these findings yields a fast and robust adaptation algorithm for\ndownstream tasks. Overall, with a single gradient step on 100 examples and a\nquick scan of the top candidate layers and factorization techniques, we can\nadapt LLMs to new datasets -- entirely without fine-tuning.", "AI": {"tldr": "LASER pruning can boost downstream accuracy without fine-tuning by selective rank reduction; this work speeds up LASER by focusing on key matrices, using gradient signals to pick matrices, clustering rows into multiple subspaces for factorization, and using only 100 samples for evaluation; overall yields fast, robust adaptation with up to 24.6 pp gain.", "motivation": "Original LASER requires exhaustive per-matrix search with full dataset passes, which is impractical for rapid deployment; need efficient, gradient-guided, data-efficient method to adapt LLMs to downstream tasks without gradient-based fine-tuning.", "method": "1) identify a small subset of matrices to inspect instead of layer-by-layer sweep; 2) use the gradient of each matrix\u2019s singular values to indicate which matrices matter; 3) enlarge factorization search by clustering matrix rows into multiple subspaces and decompose each cluster; 4) evaluate using just 100 samples for gradient calculation and final accuracy to reduce search time; 5) combine these steps into a single-step gradient adaptation with minimal sweeps.", "result": "Achieves up to 24.6 percentage point improvement in downstream accuracy; reduces search time; demonstrates strong adaptation with one gradient step on 100 examples and a quick scan of candidates, without fine-tuning.", "conclusion": "Proposes a fast, robust, data-efficient adaptation algorithm for downstream tasks via criterion-driven matrix pruning/factorization, enabling near-immediate deployment of LLMs without gradient-based fine-tuning."}}
{"id": "2510.20644", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20644", "abs": "https://arxiv.org/abs/2510.20644", "authors": ["Reuben Dorent", "Polina Golland", "William Wells III"], "title": "Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound for Representation Learning", "comment": "Accepted at NeurIPS 2025. Code available at\n  https://github.com/ReubenDo/JSDlowerbound/", "summary": "Mutual Information (MI) is a fundamental measure of statistical dependence\nwidely used in representation learning. While direct optimization of MI via its\ndefinition as a Kullback-Leibler divergence (KLD) is often intractable, many\nrecent methods have instead maximized alternative dependence measures, most\nnotably, the Jensen-Shannon divergence (JSD) between joint and product of\nmarginal distributions via discriminative losses. However, the connection\nbetween these surrogate objectives and MI remains poorly understood. In this\nwork, we bridge this gap by deriving a new, tight, and tractable lower bound on\nKLD as a function of JSD in the general case. By specializing this bound to\njoint and marginal distributions, we demonstrate that maximizing the JSD-based\ninformation increases a guaranteed lower bound on mutual information.\nFurthermore, we revisit the practical implementation of JSD-based objectives\nand observe that minimizing the cross-entropy loss of a binary classifier\ntrained to distinguish joint from marginal pairs recovers a known variational\nlower bound on the JSD. Extensive experiments demonstrate that our lower bound\nis tight when applied to MI estimation. We compared our lower bound to\nstate-of-the-art neural estimators of variational lower bound across a range of\nestablished reference scenarios. Our lower bound estimator consistently\nprovides a stable, low-variance estimate of a tight lower bound on MI. We also\ndemonstrate its practical usefulness in the context of the Information\nBottleneck framework. Taken together, our results provide new theoretical\njustifications and strong empirical evidence for using discriminative learning\nin MI-based representation learning.", "AI": {"tldr": "Derives a tight, tractable lower bound on KL divergence as a function of Jensen-Shannon divergence, tying JSD-based objectives to a guaranteed lower bound on mutual information (MI); shows cross-entropy training for a joint vs marginal classifier recovers a variational bound on JSD; empirically, the bound is tight for MI estimation and yields a stable, low-variance MI estimator, with practical benefits in Information Bottleneck and MI-based representation learning.", "motivation": "Mutual information is a foundational measure in representation learning, but its direct computation via KL divergence is often intractable. While JSD-based, discriminative objectives are popular surrogates, their connection to MI is unclear. This work seeks a theoretical and practical link by bounding KL divergence in terms of JSD, thereby validating JSD-based methods as MI surrogates.", "method": "Develop a new, tight, and tractable lower bound on KL divergence as a function of JSD in the general case. Specialize the bound to joint and marginal distributions to show that maximizing JSD-based information increases a guaranteed lower bound on MI. Revisit practical JSD-based objectives: show that cross-entropy loss of a binary classifier distinguishing joint from marginal pairs recovers a known variational lower bound on the JSD. Conduct extensive experiments comparing the bound to state-of-the-art neural estimators of variational lower bounds across established reference scenarios, demonstrating tightness and low variance. Apply the bound within the Information Bottleneck framework to illustrate practical usefulness.", "result": "The proposed lower bound is tight and provides a stable, low-variance estimator of a lower bound on MI. It offers theoretical justification for using discriminative (JSD-based) objectives in MI-based representation learning and demonstrates empirical benefits across standard MI estimation benchmarks and the Information Bottleneck context.", "conclusion": "The work provides both theoretical justification and empirical evidence that discriminative JSD-based objectives can reliably bound MI from below. This strengthens the use of JSD-based surrogates in MI-based representation learning and supports their integration with Information Bottleneck methods."}}
{"id": "2510.20651", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20651", "abs": "https://arxiv.org/abs/2510.20651", "authors": ["Quan Li", "Wenchao Yu", "Suhang Wang", "Minhua Lin", "Lingwei Chen", "Wei Cheng", "Haifeng Chen"], "title": "xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion", "comment": null, "summary": "Extreme events frequently occur in real-world time series and often carry\nsignificant practical implications. In domains such as climate and healthcare,\nthese events, such as floods, heatwaves, or acute medical episodes, can lead to\nserious consequences. Accurate forecasting of such events is therefore of\nsubstantial importance. Most existing time series forecasting models are\noptimized for overall performance within the prediction window, but often\nstruggle to accurately predict extreme events, such as high temperatures or\nheart rate spikes. The main challenges are data imbalance and the neglect of\nvaluable information contained in intermediate events that precede extreme\nevents. In this paper, we propose xTime, a novel framework for extreme event\nforecasting in time series. xTime leverages knowledge distillation to transfer\ninformation from models trained on lower-rarity events, thereby improving\nprediction performance on rarer ones. In addition, we introduce a mixture of\nexperts (MoE) mechanism that dynamically selects and fuses outputs from expert\nmodels across different rarity levels, which further improves the forecasting\nperformance for extreme events. Experiments on multiple datasets show that\nxTime achieves consistent improvements, with forecasting accuracy on extreme\nevents improving from 3% to 78%.", "AI": {"tldr": "xTime introduces a knowledge-distillation-driven, mixture-of-experts framework for extreme-event forecasting in time series, addressing data imbalance and leveraging intermediate events to boost rare-event accuracy.", "motivation": "Extreme events in domains like climate and healthcare can have severe consequences. Most forecasting models optimize overall performance and miss rare extremes due to data imbalance and underutilization of informative intermediate events.", "method": "xTime employs two key components: (1) knowledge distillation from models trained on lower-rarity events to transfer information to rarer extremes; (2) a mixture-of-experts mechanism that dynamically selects and fuses outputs from expert models across different rarity levels to improve extreme-event forecasts.", "result": "Experiments on multiple datasets show consistent improvements in extreme-event forecasting. Extreme-event accuracy improves substantially, with reported gains ranging from about 3% to 78% across datasets.", "conclusion": "The xTime framework effectively tackles data imbalance and exploits information from preceding intermediate events; its knowledge distillation and MoE components yield substantial improvements in extreme-event forecasting."}}
{"id": "2510.20666", "categories": ["cs.LG", "eess.SP", "68T05, 68T07, 62F15, 94A12"], "pdf": "https://arxiv.org/pdf/2510.20666", "abs": "https://arxiv.org/abs/2510.20666", "authors": ["Mariona Jaramillo-Civill", "Luis Gonz\u00e1lez-Gudi\u00f1o", "Tales Imbiriba", "Pau Closas"], "title": "Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of Experts", "comment": "5 pages, 4 figures, Submitted to ICASSPW 2026", "summary": "Global Navigation Satellite System (GNSS) signals are vulnerable to jamming,\nparticularly in urban areas where multipath and shadowing distort received\npower. Previous data-driven approaches achieved reasonable localization but\npoorly reconstructed the received signal strength (RSS) field due to limited\nspatial context. We propose a hybrid Bayesian mixture-of-experts framework that\nfuses a physical path-loss (PL) model and a convolutional neural network (CNN)\nthrough log-linear pooling. The PL expert ensures physical consistency, while\nthe CNN leverages building-height maps to capture urban propagation effects.\nBayesian inference with Laplace approximation provides posterior uncertainty\nover both the jammer position and RSS field. Experiments on urban ray-tracing\ndata show that localization accuracy improves and uncertainty decreases with\nmore training points, while uncertainty concentrates near the jammer and along\nurban canyons where propagation is most sensitive.", "AI": {"tldr": "A hybrid Bayesian mixture-of-experts combines a physics-based path-loss model with a CNN to localize GNSS jammers and reconstruct the RSS field in urban areas, with uncertainty quantified via Laplace approximation; experiments show improved localization and focused uncertainty near critical propagation regions.", "motivation": "GNSS signals are easily jammed, especially in cities where multipath and shadowing distort signal strength. Existing data-driven approaches give reasonable localization but fail to reconstruct the RSS field well due to limited spatial context; a physically consistent, context-aware model is needed.", "method": "A hybrid mixture-of-experts framework fuses a physical path-loss (PL) model and a CNN through log-linear pooling. The PL expert enforces physical consistency; the CNN uses building-height maps to capture urban propagation effects. Bayesian inference with a Laplace approximation yields posterior distributions over jammer position and the RSS field.", "result": "On urban ray-tracing data, localization accuracy improves as more training points are used, and the posterior uncertainty decreases. Uncertainty concentrates near the jammer and along urban canyons where propagation is most sensitive to changes in position.", "conclusion": "The proposed physics-informed Bayesian framework improves RSS-field reconstruction and jammer localization in urban GNSS scenarios, providing meaningful uncertainty quantification and leveraging urban geometry via building-height maps."}}
{"id": "2510.20668", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20668", "abs": "https://arxiv.org/abs/2510.20668", "authors": ["Jinbin Bai", "Yu Lei", "Hecong Wu", "Yuchen Zhu", "Shufan Li", "Yi Xin", "Xiangtai Li", "Molei Tao", "Aditya Grover", "Ming-Hsuan Yang"], "title": "From Masks to Worlds: A Hitchhiker's Guide to World Models", "comment": "Github: https://github.com/M-E-AGI-Lab/Awesome-World-Models", "summary": "This is not a typical survey of world models; it is a guide for those who\nwant to build worlds. We do not aim to catalog every paper that has ever\nmentioned a ``world model\". Instead, we follow one clear road: from early\nmasked models that unified representation learning across modalities, to\nunified architectures that share a single paradigm, then to interactive\ngenerative models that close the action-perception loop, and finally to\nmemory-augmented systems that sustain consistent worlds over time. We bypass\nloosely related branches to focus on the core: the generative heart, the\ninteractive loop, and the memory system. We show that this is the most\npromising path towards true world models.", "AI": {"tldr": "A constructive blueprint linking masked multimodal representation learning, unified architectures, interactive generative systems, and memory-augmented memory to form robust world models; not a survey, but a guided roadmap.", "motivation": "Provide a practical guide to building world models, unify disparate strands of work, and emphasize a core architecture consisting of generative core, interactive loop, and memory system.", "method": "Conceptual synthesis and narrative progression: identify a sequence from early masked multimodal representations to unified architectures, then to interactive generative loops and finally to memory-augmented systems; explicitly bypass loosely related branches to focus on core components.", "result": "A coherent roadmap and justification for pursuing a unified world-model paradigm, arguing that the outlined progression is the most promising path toward true world models.", "conclusion": "If followed, the roadmap should advance the development of robust, persistent world models by centering on the generative core, the action-perception loop, and memory for consistency over time."}}
{"id": "2510.20762", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.20762", "abs": "https://arxiv.org/abs/2510.20762", "authors": ["Jan Sobotka", "Luca Baroni", "J\u00e1n Antol\u00edk"], "title": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs", "comment": "Accepted to NeurIPS 2025", "summary": "Decoding visual stimuli from neural population activity is crucial for\nunderstanding the brain and for applications in brain-machine interfaces.\nHowever, such biological data is often scarce, particularly in primates or\nhumans, where high-throughput recording techniques, such as two-photon imaging,\nremain challenging or impossible to apply. This, in turn, poses a challenge for\ndeep learning decoding techniques. To overcome this, we introduce MEIcoder, a\nbiologically informed decoding method that leverages neuron-specific most\nexciting inputs (MEIs), a structural similarity index measure loss, and\nadversarial training. MEIcoder achieves state-of-the-art performance in\nreconstructing visual stimuli from single-cell activity in primary visual\ncortex (V1), especially excelling on small datasets with fewer recorded\nneurons. Using ablation studies, we demonstrate that MEIs are the main drivers\nof the performance, and in scaling experiments, we show that MEIcoder can\nreconstruct high-fidelity natural-looking images from as few as 1,000-2,500\nneurons and less than 1,000 training data points. We also propose a unified\nbenchmark with over 160,000 samples to foster future research. Our results\ndemonstrate the feasibility of reliable decoding in early visual system and\nprovide practical insights for neuroscience and neuroengineering applications.", "AI": {"tldr": "MEIcoder is a biologically informed decoder that uses neuron-specific most exciting inputs (MEIs), an SSIM loss, and adversarial training to reconstruct visual stimuli from sparse neural activity. It sets state-of-the-art performance on V1 with small datasets and scales to thousands of neurons with limited data, and it introduces a large unified benchmark to spur future work.", "motivation": "Deep learning decoding from neural data is often hampered by scarcity, especially in primates/humans. Biological priors (MEIs) and robust training goals can enable reliable image reconstruction from limited recordings, advancing neuroscience and neuroengineering applications.", "method": "MEIcoder leverages neuron-specific MEIs as guiding inputs, optimizes with a structural similarity index (SSIM) loss, and incorporates adversarial training to improve perceptual quality. The authors perform ablation to show MEIs are the main driver and demonstrate scaling to 1,000\u20132,500 neurons with fewer than 1,000 training samples; they also propose a unified benchmark with >160k samples.", "result": "Achieves state-of-the-art reconstruction of visual stimuli from single-cell activity in V1, particularly excelling on small datasets; MEIs identified as the primary driver of performance; scalable to larger neural populations with limited data; provides a substantial benchmarking dataset to facilitate future research.", "conclusion": "The approach demonstrates the feasibility of reliable visual decoding in the early visual system under data constraints and offers practical guidance for neuroscience and neuroengineering, along with a standardized benchmark to accelerate progress."}}
{"id": "2510.20709", "categories": ["cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.20709", "abs": "https://arxiv.org/abs/2510.20709", "authors": ["Haozhe Shan", "Sun Minni", "Lea Duncker"], "title": "Separating the what and how of compositional computation to enable reuse and continual learning", "comment": null, "summary": "The ability to continually learn, retain and deploy skills to accomplish\ngoals is a key feature of intelligent and efficient behavior. However, the\nneural mechanisms facilitating the continual learning and flexible\n(re-)composition of skills remain elusive. Here, we study continual learning\nand the compositional reuse of learned computations in recurrent neural network\n(RNN) models using a novel two-system approach: one system that infers what\ncomputation to perform, and one that implements how to perform it. We focus on\na set of compositional cognitive tasks commonly studied in neuroscience. To\nconstruct the what system, we first show that a large family of tasks can be\nsystematically described by a probabilistic generative model, where\ncompositionality stems from a shared underlying vocabulary of discrete task\nepochs. The shared epoch structure makes these tasks inherently compositional.\nWe first show that this compositionality can be systematically described by a\nprobabilistic generative model. Furthermore, We develop an unsupervised online\nlearning approach that can learn this model on a single-trial basis, building\nits vocabulary incrementally as it is exposed to new tasks, and inferring the\nlatent epoch structure as a time-varying computational context within a trial.\nWe implement the how system as an RNN whose low-rank components are composed\naccording to the context inferred by the what system. Contextual inference\nfacilitates the creation, learning, and reuse of low-rank RNN components as new\ntasks are introduced sequentially, enabling continual learning without\ncatastrophic forgetting. Using an example task set, we demonstrate the efficacy\nand competitive performance of this two-system learning framework, its\npotential for forward and backward transfer, as well as fast compositional\ngeneralization to unseen tasks.", "AI": {"tldr": "A two-system continual learning framework for RNNs: a 'what' system infers the computation (epoch structure) via a probabilistic generative model; a 'how' system implements it with context-driven low-rank RNN components. Learned online on single trials; enables continual learning without forgetting and fast generalization to new tasks.", "motivation": "Understand mechanisms enabling continual learning and flexible recomposition of skills; study how to infer task structure and implement it efficiently in neural networks.", "method": "Two-system architecture: what system uses unsupervised online learning to learn a generative model of task epochs, incremental vocabulary, and time-varying context inference; how system is an RNN with low-rank components whose assembly is dictated by inferred context; demonstration on a set of compositional cognitive tasks.", "result": "Shows competitive performance, supports forward/backward transfer, and fast compositional generalization to unseen tasks; demonstrates potential to mitigate catastrophic forgetting.", "conclusion": "Proposes a framework that enables continual learning and compositional reuse by coupling probabilistic inference of task structure with modular, context-driven network components; a promising direction for scalable generalization in continual learning."}}
{"id": "2510.20714", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20714", "abs": "https://arxiv.org/abs/2510.20714", "authors": ["Fardin Ganjkhanloo", "Emmett Springer", "Erik H. Hoyer", "Daniel L. Young", "Kimia Ghobadi"], "title": "Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool", "comment": "19 pages, 7 figures, 4 tables", "summary": "In this study we aim to better align fall risk prediction from the Johns\nHopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically\nmeaningful measures via a data-driven modelling approach. We conducted a\nretrospective analysis of 54,209 inpatient admissions from three Johns Hopkins\nHealth System hospitals between March 2022 and October 2023. A total of 20,208\nadmissions were included as high fall risk encounters, and 13,941 were included\nas low fall risk encounters. To incorporate clinical knowledge and maintain\ninterpretability, we employed constrained score optimization (CSO) models on\nJHFRAT assessment data and additional electronic health record (EHR) variables.\nThe model demonstrated significant improvements in predictive performance over\nthe current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). The constrained\nscore optimization models performed similarly with and without the EHR\nvariables. Although the benchmark black-box model (XGBoost), improves upon the\nperformance metrics of the knowledge-based constrained logistic regression\n(AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk\nlabelling. This evidence-based approach provides a robust foundation for health\nsystems to systematically enhance inpatient fall prevention protocols and\npatient safety using data-driven optimization techniques, contributing to\nimproved risk assessment and resource allocation in healthcare settings.", "AI": {"tldr": "CSO models on JHFRAT with EHR data improve inpatient fall risk prediction (AUC 0.91 vs 0.86), with XGBoost at 0.94 but CSO offers robustness and interpretability.", "motivation": "Align fall risk scoring with clinically meaningful measures, improve predictive performance, and maintain interpretability while leveraging EHR data.", "method": "Retrospective cohort of 54,209 inpatient admissions across three Johns Hopkins hospitals; 20,208 high-risk and 13,941 low-risk; apply constrained score optimization (CSO) models on JHFRAT and extra EHR vars; compare to JHFRAT and XGBoost; assess robustness to risk labeling.", "result": "CSO AUC-ROC 0.91 vs JHFRAT 0.86; CSO with/without EHR vars similar; XGBoost AUC 0.94; CSO more robust to label variations.", "conclusion": "Data-driven constrained scoring can robustly improve inpatient fall risk assessment and resource allocation while preserving interpretability, supporting safer care delivery."}}
{"id": "2510.20725", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20725", "abs": "https://arxiv.org/abs/2510.20725", "authors": ["Jasmine Bayrooti", "Sattar Vakili", "Amanda Prorok", "Carl Henrik Ek"], "title": "No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes with Gaussian Processes", "comment": "Appearing in NeurIPS, 2025", "summary": "Thompson sampling (TS) is a powerful and widely used strategy for sequential\ndecision-making, with applications ranging from Bayesian optimization to\nreinforcement learning (RL). Despite its success, the theoretical foundations\nof TS remain limited, particularly in settings with complex temporal structure\nsuch as RL. We address this gap by establishing no-regret guarantees for TS\nusing models with Gaussian marginal distributions. Specifically, we consider TS\nin episodic RL with joint Gaussian process (GP) priors over rewards and\ntransitions. We prove a regret bound of\n$\\mathcal{\\tilde{O}}(\\sqrt{KH\\Gamma(KH)})$ over $K$ episodes of horizon $H$,\nwhere $\\Gamma(\\cdot)$ captures the complexity of the GP model. Our analysis\naddresses several challenges, including the non-Gaussian nature of value\nfunctions and the recursive structure of Bellman updates, and extends classical\ntools such as the elliptical potential lemma to multi-output settings. This\nwork advances the understanding of TS in RL and highlights how structural\nassumptions and model uncertainty shape its performance in finite-horizon\nMarkov Decision Processes.", "AI": {"tldr": "No-regret guarantees for Thompson sampling in episodic RL with Gaussian marginal models, achieving tilde O(sqrt(K H \u0393(KH))).", "motivation": "To strengthen the theoretical foundations of Thompson sampling in reinforcement learning, addressing complex temporal structure and non-Gaussian value functions by using Gaussian process priors over rewards and transitions.", "method": "Prove regret bound for Thompson sampling in episodic RL with joint GP priors over rewards and transitions; extend elliptical potential lemma to multi-output settings; address non-Gaussian value functions and the recursive Bellman updates, resulting in a finite-horizon regret bound depending on GP complexity \u0393(KH).", "result": "Regret bound tilde O(sqrt(K H \u0393(KH))) over K episodes of horizon H; \u0393 captures the GP model complexity of the underlying priors; analysis handles non-Gaussian value functions and multi-output Bellman updates.", "conclusion": "Advances the theoretical understanding of Thompson sampling in reinforcement learning, illustrating how model structure and uncertainty quantification influence performance in finite-horizon MDPs and guiding future work on GP-based RL algorithms."}}
{"id": "2510.20736", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20736", "abs": "https://arxiv.org/abs/2510.20736", "authors": ["Tsai Hor Chan", "Feng Wu", "Yihang Chen", "Guosheng Yin", "Lequan Yu"], "title": "Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process", "comment": "Accepted by NeruIPS 2025", "summary": "Developing effective multimodal fusion approaches has become increasingly\nessential in many real-world scenarios, such as health care and finance. The\nkey challenge is how to preserve the feature expressiveness in each modality\nwhile learning cross-modal interactions. Previous approaches primarily focus on\nthe cross-modal alignment, while over-emphasis on the alignment of marginal\ndistributions of modalities may impose excess regularization and obstruct\nmeaningful representations within each modality. The Dirichlet process (DP)\nmixture model is a powerful Bayesian non-parametric method that can amplify the\nmost prominent features by its richer-gets-richer property, which allocates\nincreasing weights to them. Inspired by this unique characteristic of DP, we\npropose a new DP-driven multimodal learning framework that automatically\nachieves an optimal balance between prominent intra-modal representation\nlearning and cross-modal alignment. Specifically, we assume that each modality\nfollows a mixture of multivariate Gaussian distributions and further adopt DP\nto calculate the mixture weights for all the components. This paradigm allows\nDP to dynamically allocate the contributions of features and select the most\nprominent ones, leveraging its richer-gets-richer property, thus facilitating\nmultimodal feature fusion. Extensive experiments on several multimodal datasets\ndemonstrate the superior performance of our model over other competitors.\nAblation analysis further validates the effectiveness of DP in aligning\nmodality distributions and its robustness to changes in key hyperparameters.\nCode is anonymously available at https://github.com/HKU-MedAI/DPMM.git", "AI": {"tldr": "A Dirichlet process\u2013driven multimodal learning framework that balances intra-modal expressiveness with cross-modal alignment by modelling each modality as a DP-weighted Gaussian mixture, enabling adaptive feature selection and improved fusion across datasets.", "motivation": "To preserve rich representations within each modality while enabling cross-modal interactions; conventional alignment-focused approaches can over-regularize and degrade intra-modal information. The Dirichlet process offers a richer-gets-richer mechanism to emphasize prominent features and allocate contributions dynamically.", "method": "Each modality is treated as a mixture of multivariate Gaussians. A Dirichlet process is used to infer the mixture weights, allowing DP to dynamically allocate and emphasize prominent features (rich-get-richer). This framework facilitates multimodal fusion by balancing intra-modal representation learning and cross-modal alignment. The approach includes ablation studies and evaluations on multiple multimodal datasets, with code released at the provided GitHub URL.", "result": "The proposed DP-driven framework achieves superior performance compared with baseline competitors on several multimodal datasets. Ablation analyses substantiate the effectiveness of DP in facilitating alignment while preserving intra-modal representations; the results are robust to key hyperparameters.", "conclusion": "A DP-driven multimodal learning paradigm can automatically balance prominent intra-modal representations with cross-modal alignment, leveraging the DP's rich-get-richer property to emphasize important features. The approach shows strong empirical gains and is complemented by ablation studies and a publicly available implementation."}}
{"id": "2510.20783", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20783", "abs": "https://arxiv.org/abs/2510.20783", "authors": ["Anna M\u00e9sz\u00e1ros", "Patrik Reizinger", "Ferenc Husz\u00e1r"], "title": "Out-of-distribution Tests Reveal Compositionality in Chess Transformers", "comment": null, "summary": "Chess is a canonical example of a task that requires rigorous reasoning and\nlong-term planning. Modern decision Transformers - trained similarly to LLMs -\nare able to learn competent gameplay, but it is unclear to what extent they\ntruly capture the rules of chess. To investigate this, we train a 270M\nparameter chess Transformer and test it on out-of-distribution scenarios,\ndesigned to reveal failures of systematic generalization. Our analysis shows\nthat Transformers exhibit compositional generalization, as evidenced by strong\nrule extrapolation: they adhere to fundamental syntactic rules of the game by\nconsistently choosing valid moves even in situations very different from the\ntraining data. Moreover, they also generate high-quality moves for OOD puzzles.\nIn a more challenging test, we evaluate the models on variants including\nChess960 (Fischer Random Chess) - a variant of chess where starting positions\nof pieces are randomized. We found that while the model exhibits basic strategy\nadaptation, they are inferior to symbolic AI algorithms that perform explicit\nsearch, but gap is smaller when playing against users on Lichess. Moreover, the\ntraining dynamics revealed that the model initially learns to move only its own\npieces, suggesting an emergent compositional understanding of the game.", "AI": {"tldr": "Transformers can generalize to some rule-based, compositional aspects of chess and solve many OOD puzzles, but still lag behind explicit search-based symbolic AIs in Chess960; training dynamics suggest emergent compositional understanding.", "motivation": "Evaluate whether modern chess transformers learn underlying rules and compositional generalization beyond training distributions; assess OOD generalization and variant handling; compare with symbolic AI and human play.", "method": "Train a 270M-parameter chess Transformer; design out-of-distribution tests to probe rule extrapolation; evaluate on Chess960; compare against symbolic AI search-based algorithms; play against Lichess users; analyze training dynamics (e.g., early emergence of moving only own pieces).", "result": "Evidence of compositional generalization and rule extrapolation; strong performance on OOD puzzles; Chess960 results show basic strategy adaptation but inferior to symbolic AI; the gap narrows when playing humans on Lichess; training dynamics indicate an emergent understanding, with initial bias to moving only the model's own pieces.", "conclusion": "Transformers capture some rule-based generalization but rely on heuristics and do not yet replace explicit search in complex or highly varied settings; results motivate hybrid approaches and deeper study of emergent learning dynamics in game-playing agents."}}
{"id": "2510.20792", "categories": ["cs.LG", "cs.CL", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2510.20792", "abs": "https://arxiv.org/abs/2510.20792", "authors": ["Liang Ye", "Shengqin Chen", "Jiazhu Dai"], "title": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation", "comment": null, "summary": "The rapid progress of graph generation has raised new security concerns,\nparticularly regarding backdoor vulnerabilities. While prior work has explored\nbackdoor attacks in image diffusion and unconditional graph generation,\nconditional, especially text-guided graph generation remains largely\nunexamined. This paper proposes BadGraph, a backdoor attack method targeting\nlatent diffusion models for text-guided graph generation. BadGraph leverages\ntextual triggers to poison training data, covertly implanting backdoors that\ninduce attacker-specified subgraphs during inference when triggers appear,\nwhile preserving normal performance on clean inputs. Extensive experiments on\nfour benchmark datasets (PubChem, ChEBI-20, PCDes, MoMu) demonstrate the\neffectiveness and stealth of the attack: less than 10% poisoning rate can\nachieves 50% attack success rate, while 24% suffices for over 80% success rate,\nwith negligible performance degradation on benign samples. Ablation studies\nfurther reveal that the backdoor is implanted during VAE and diffusion training\nrather than pretraining. These findings reveal the security vulnerabilities in\nlatent diffusion models of text-guided graph generation, highlight the serious\nrisks in models' applications such as drug discovery and underscore the need\nfor robust defenses against the backdoor attack in such diffusion models.", "AI": {"tldr": "BadGraph is a backdoor attack on latent diffusion models for text-guided graph generation, enabling attacker-specified subgraphs when triggers appear, with low poisoning and stealthy performance.", "motivation": "Text-guided graph generation via diffusion models poses new security risks. Backdoor vulnerabilities in such conditional graph generation, especially for drug-related domains, are underexplored and require defense.", "method": "The attack poisons training data with textual triggers, implanting backdoors during VAE and diffusion model training (not pretraining). At inference, triggers induce attacker-specified subgraphs in generated graphs while preserving normal performance on clean inputs.", "result": "Experiments on PubChem, ChEBI-20, PCDes, MoMu show that with less than 10% poisoning rate, attack success can reach 50%; with 24% poisoning, success exceeds 80%, and benign performance is largely unaffected. Ablations show the backdoor is implanted during VAE and diffusion training.", "conclusion": "Latent diffusion models for text-guided graph generation are susceptible to covert backdoor attacks with practical poisoning levels, posing serious risks in applications like drug discovery; defenses against such backdoors are needed."}}
{"id": "2510.20817", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20817", "abs": "https://arxiv.org/abs/2510.20817", "authors": ["Anthony GX-Chen", "Jatin Prakash", "Jeff Guo", "Rob Fergus", "Rajesh Ranganath"], "title": "KL-Regularized Reinforcement Learning is Designed to Mode Collapse", "comment": null, "summary": "It is commonly believed that optimizing the reverse KL divergence results in\n\"mode seeking\", while optimizing forward KL results in \"mass covering\", with\nthe latter being preferred if the goal is to sample from multiple diverse\nmodes. We show -- mathematically and empirically -- that this intuition does\nnot necessarily transfer well to doing reinforcement learning with\nreverse/forward KL regularization (e.g. as commonly used with language models).\nInstead, the choice of reverse/forward KL determines the family of optimal\ntarget distributions, parameterized by the regularization coefficient. Mode\ncoverage depends primarily on other factors, such as regularization strength,\nand relative scales between rewards and reference probabilities. Further, we\nshow commonly used settings such as low regularization strength and equal\nverifiable rewards tend to specify unimodal target distributions, meaning the\noptimization objective is, by construction, non-diverse. We leverage these\ninsights to construct a simple, scalable, and theoretically justified\nalgorithm. It makes minimal changes to reward magnitudes, yet optimizes for a\ntarget distribution which puts high probability over all high-quality sampling\nmodes. In experiments, this simple modification works to post-train both Large\nLanguage Models and Chemical Language Models to have higher solution quality\nand diversity, without any external signals of diversity, and works with both\nforward and reverse KL when using either naively fails.", "AI": {"tldr": "KL direction (forward vs reverse) in RL with KL regularization does not simply map to mode-seeking vs mass-covering. The optimal target distribution is shaped by the regularization coefficient and reward/reference scales; common settings tend to yield unimodal, non-diverse targets. A simple, scalable algorithm can steer toward a high-quality, multi-mode distribution by minimal reward adjustments, improving both LLMs and chemical language models without extra diversity signals, and working with either KL direction when tuned.", "motivation": "Challenge the conventional wisdom that reverse KL implies mode-seeking and forward KL implies mass-covering in RL with KL regularization, and understand how these dynamics affect diversity and quality in language and chemical language models. Provide a principled method to achieve diverse, high-quality sampling without external signals.", "method": "Theoretically analyze how KL direction and regularization shape the optimal target distribution and how factors like regularization strength and reward/reference scales impact mode coverage. Identify conditions (e.g., low regularization, equal rewards) that lead to unimodal targets. Propose a simple, scalable algorithm that minimally perturbs rewards to steer toward a target distribution placing high probability on all high-quality modes. Validate empirically by post-training Large Language Models and Chemical Language Models, measuring quality and diversity across forward/reverse KL settings.", "result": "The analysis shows that KL direction alone does not guarantee mode behavior in RL; mode coverage depends on regularization strength and reward/reference scales. Under common settings, targets are unimodal, limiting diversity. The proposed algorithm successfully post-trains models to achieve higher solution quality and diversity without external diversity signals, effective for both forward and reverse KL when properly tuned; naive applications fail.", "conclusion": "KL direction and regularization jointly determine the target distribution in RL-based generation. Appropriate tuning enables diverse, high-quality sampling without external diversity prompts. The authors provide a simple, scalable, theoretically grounded method compatible with both forward and reverse KL, demonstrated on LLMs and chemical language models."}}
