{"id": "2511.05371", "categories": ["cs.CG"], "pdf": "https://arxiv.org/pdf/2511.05371", "abs": "https://arxiv.org/abs/2511.05371", "authors": ["M. de Berg", "B. M. P. Jansen", "J. S. K. Lamme"], "title": "Star-Based Separators for Intersection Graphs of $c$-Colored Pseudo-Segments", "comment": "23 pages, 8 figures", "summary": "The Planar Separator Theorem, which states that any planar graph\n$\\mathcal{G}$ has a separator consisting of $O(\\sqrt{n})$ nodes whose removal\npartitions $\\mathcal{G}$ into components of size at most $\\tfrac{2n}{3}$, is a\nwidely used tool to obtain fast algorithms on planar graphs. Intersection\ngraphs of disks, which generalize planar graphs, do not admit such separators.\nIt has recently been shown that disk graphs do admit so-called clique-based\nseparators that consist of $O(\\sqrt{n})$ cliques. This result has been\ngeneralized to intersection graphs of various other types of disk-like objects.\nUnfortunately, segment intersection graphs do not admit small clique-based\nseparators, because they can contain arbitrarily large bicliques. This is true\neven in the simple case of axis-aligned segments.\n  In this paper we therefore introduce biclique-based separators (and, in\nparticular, star-based separators), which are separators consisting of a small\nnumber of bicliques (or stars). We prove that any $c$-oriented set of $n$\nsegments in the plane, where $c$ is a constant, admits a star-based separator\nconsisting of $O(\\sqrt{n})$ stars. In fact, our result is more general, as it\napplies to any set of $n$ pseudo-segments that is partitioned into $c$ subsets\nsuch that the pseudo-segments in the same subset are pairwise disjoint. We\nextend our result to intersection graphs of $c$-oriented polygons. These\nresults immediately lead to an almost-exact distance oracle for such\nintersection graphs, which has $O(n\\sqrt{n})$ storage and $O(\\sqrt{n})$ query\ntime, and that can report the hop-distance between any two query nodes in the\nintersection graph with an additive error of at most 2. This is the first\ndistance oracle for such types of intersection graphs that has subquadratic\nstorage and sublinear query time and that only has an additive error.", "AI": {"tldr": "Introduces star-based (biclique-based) separators for intersection graphs of c-oriented segments and polygons, achieving O(sqrt(n)) separators, and presents a distance oracle with subquadratic storage and sublinear query time with additive-2 error.", "motivation": "Planar separator theorems do not directly yield efficient separators for non-planar geometric intersection graphs like segment and polygon intersection graphs; a separator structure based on bicliques/stars could enable faster algorithms.", "method": "Define star-based separators and biclique-based separators; prove existence for c-oriented segments (and pseudo-segments partitioned into c disjoint subsets) and extend to c-oriented polygons; derive separator size O(sqrt(n)); design a distance oracle leveraging these separators.", "result": "Proves that any c-oriented set of n segments can be separated by O(sqrt(n)) stars; extends to c-oriented pseudo-segments and polygons; yields an almost-exact distance oracle with O(n sqrt(n)) storage, O(sqrt(n)) query time, and additive error at most 2; this is the first such oracle with subquadratic storage and sublinear query time with additive error.", "conclusion": "Star-based/biclique-based separators provide efficient structural tools for geometric intersection graphs where clique-based separators fail; they enable fast, space-efficient distance queries and broaden applicability of separator techniques to a wider class of geometric graphs."}}
{"id": "2511.04685", "categories": ["cs.AI", "math.OC", "90-04", "F.2.2"], "pdf": "https://arxiv.org/pdf/2511.04685", "abs": "https://arxiv.org/abs/2511.04685", "authors": ["Daniela Guericke", "Rolf van der Hulst", "Asal Karimpour", "Ieke Schrader", "Matthias Walter"], "title": "A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024", "comment": "23 pages, 2 figures, 10 tables", "summary": "We report about the algorithm, implementation and results submitted to the\nIntegrated Healthcare Timetabling Competition 2024 by Team Twente, which scored\nthird in the competition. Our approach combines mixed-integer programming,\nconstraint programming and simulated annealing in a 3-phase solution approach\nbased on decomposition into subproblems. Next to describing our approach and\ndescribing our design decisions, we share our insights and, for the first time,\nlower bounds on the optimal solution values for the benchmark instances. We\nfinally highlight open problems for which we think that addressing them could\nimprove our approach even further.", "AI": {"tldr": "Team Twente's entry to the Integrated Healthcare Timetabling Competition 2024 uses a 3-phase, decomposition-based hybrid of mixed-integer programming, constraint programming, and simulated annealing to solve healthcare timetabling; achieved 3rd place and provides the first lower bounds on optimal values for benchmark instances; discusses design choices and outlines open problems for improvement.", "motivation": "Healthcare timetabling is a hard combinatorial optimization problem; providing effective algorithms and understanding (including lower bounds) helps gauge solution quality and pushes progress in benchmark contexts.", "method": "A 3-phase solution approach based on decomposition into subproblems that integrates mixed-integer programming (MIP), constraint programming (CP), and simulated annealing (SA). The paper also discusses design decisions and implementation details.", "result": "The approach secured third place in the competition; it also presents for the first time lower bounds on the optimal solution values for the benchmark instances and shares insights gleaned from the process.", "conclusion": "Open problems are highlighted with suggested directions that could further improve the approach; the work introduces lower bounds and points to future research opportunities to enhance performance."}}
{"id": "2511.04758", "categories": ["cs.RO", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04758", "abs": "https://arxiv.org/abs/2511.04758", "authors": ["Caelan Garrett", "Fabio Ramos"], "title": "ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling", "comment": "Project website: https://schedulestream.github.io", "summary": "Bimanual and humanoid robots are appealing because of their human-like\nability to leverage multiple arms to efficiently complete tasks. However,\ncontrolling multiple arms at once is computationally challenging due to the\ngrowth in the hybrid discrete-continuous action space. Task and Motion Planning\n(TAMP) algorithms can efficiently plan in hybrid spaces but generally produce\nplans, where only one arm is moving at a time, rather than schedules that allow\nfor parallel arm motion. In order to extend TAMP to produce schedules, we\npresent ScheduleStream, the first general-purpose framework for planning &\nscheduling with sampling operations. ScheduleStream models temporal dynamics\nusing hybrid durative actions, which can be started asynchronously and persist\nfor a duration that's a function of their parameters. We propose\ndomain-independent algorithms that solve ScheduleStream problems without any\napplication-specific mechanisms. We apply ScheduleStream to Task and Motion\nPlanning & Scheduling (TAMPAS), where we use GPU acceleration within samplers\nto expedite planning. We compare ScheduleStream algorithms to several ablations\nin simulation and find that they produce more efficient solutions. We\ndemonstrate ScheduleStream on several real-world bimanual robot tasks at\nhttps://schedulestream.github.io.", "AI": {"tldr": "ScheduleStream is a general-purpose planning and scheduling framework with sampling-based methods that enables parallel, asynchronous, and durative actions for multi-arm robots, improving planning efficiency over traditional single-arm TAMP approaches.", "motivation": "Controlling multiple arms leads to a hybrid discrete-continuous action space and traditional TAMP often yields plans with only one arm moving at a time, failing to exploit parallelism and causing inefficiency.", "method": "Introduce ScheduleStream with hybrid durative actions that can start asynchronously and have duration dependent on parameters; develop domain-independent algorithms; integrate with TAMPAS by using GPU-accelerated samplers to speed planning.", "result": "In simulations, ScheduleStream and its variants produce more efficient solutions than ablations; real-world bimanual tasks demonstrate feasibility; the work provides empirical support for scheduling capabilities and parallel arm motion.", "conclusion": "ScheduleStream is the first general-purpose framework for planning and scheduling with sampling operations and can be effectively applied to TAMPAS to enable parallel arm motion and faster planning, with GPU acceleration contributing to practical performance gains."}}
{"id": "2511.04727", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04727", "abs": "https://arxiv.org/abs/2511.04727", "authors": ["Ali Faraz", "Akash", "Shaharukh Khan", "Raja Kolla", "Akshat Patidar", "Suranjan Goswami", "Abhinav Ravi", "Chandra Khatri", "Shubham Agarwal"], "title": "IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs", "comment": null, "summary": "Vision-language models (VLMs) have demonstrated impressive generalization\nacross multimodal tasks, yet most evaluation benchmarks remain Western-centric,\nleaving open questions about their performance in culturally diverse and\nmultilingual settings. To address this gap, we introduce IndicVisionBench, the\nfirst large-scale benchmark centered on the Indian subcontinent. Covering\nEnglish and 10 Indian languages, our benchmark spans 3 multimodal tasks,\nincluding Optical Character Recognition (OCR), Multimodal Machine Translation\n(MMT), and Visual Question Answering (VQA), covering 6 kinds of question types.\nOur final benchmark consists of a total of ~5K images and 37K+ QA pairs across\n13 culturally grounded topics. In addition, we release a paired parallel corpus\nof annotations across 10 Indic languages, creating a unique resource for\nanalyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum\nof 8 models, from proprietary closed-source systems to open-weights medium and\nlarge-scale models. Our experiments reveal substantial performance gaps,\nunderscoring the limitations of current VLMs in culturally diverse contexts. By\ncentering cultural diversity and multilinguality, IndicVisionBench establishes\na reproducible evaluation framework that paves the way for more inclusive\nmultimodal research.", "AI": {"tldr": "Intro of IndicVisionBench, a large-scale, multilingual, culturally grounded VLM benchmark for India, spanning OCR, MMT, and VQA across English + 10 Indic languages; ~5K images and 37K+ QA pairs over 13 topics; assesses 8 models and uncovers substantial multilingual/cultural gaps, with a parallel Indic-language corpus for bias analysis.", "motivation": "Western-centric benchmarks inadequately assess VLMs in multilingual and culturally diverse settings; need a benchmark covering Indian languages, scripts, and culturally grounded content to evaluate and mitigate biases.", "method": "Construct a large-scale benchmark: 3 multimodal tasks (OCR, MMT, VQA) across English + 10 Indic languages, 13 culturally grounded topics, ~5K images and 37K+ QA pairs; provide a parallel corpus of annotations in 10 Indic languages; evaluate 8 models (closed-source and open-weight).", "result": "The study reveals substantial performance gaps for current VLMs in multilingual and culturally diverse contexts; models lag on Indic languages and culturally grounded content, indicating biases and limitations; provides a reproducible evaluation framework.", "conclusion": "IndicVisionBench enables inclusive, reproducible multimodal evaluation in multilingual/culturally diverse settings and should drive more inclusive research and bias analysis in VLMs."}}
{"id": "2511.04686", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04686", "abs": "https://arxiv.org/abs/2511.04686", "authors": ["Pratik Poudel"], "title": "Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity", "comment": "14 pages, 2 figures", "summary": "The Key-Value (KV) cache is integral to efficient autoregressive inference in\nlarge language models (LLMs), yet its unbounded growth in stateful multi-turn\nscenarios presents major challenges. This paper examines the interplay between\nKV cache management strategies, the architectural context limits of models like\nmeta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of\npositional encodings. Through empirical analysis using a stateful benchmarking\nframework, we show that LLM generation quality degrades sharply when the\naccumulated KV cache approaches or exceeds the model's trained context window\n(e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory\nexhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via\nAttentionTop), can worsen performance if they disrupt positional coherence.\nBecause LLMs rely on consistent positional signals (e.g., RoPE), compacting a\ncache by removing non-contiguous tokens can scramble these signals and lead to\ndegenerative outputs. We further show that simple strategies preserving\ncontiguous context blocks (e.g., keeping an initial \"gist\") can yield more\ncoherent generations than complex or positionally disruptive ones. We advocate\nfor eviction techniques that respect architectural limits, preserve positional\nstructure, and view \"cache health\" holistically beyond mere size.", "AI": {"tldr": "KV cache growth in LLMs is not benign; eviction must respect positional encodings and the model's context window; simple strategies that preserve contiguous context blocks outperform aggressive or non-contiguous eviction.", "motivation": "To understand how unbounded KV cache growth in stateful, multi-turn LLM inference interacts with architectural context limits and positional encodings, and how eviction strategies affect generation quality.", "method": "Empirical analysis using a stateful benchmarking framework across models (e.g., Meta-Llama-3-8b-instruct). Systematically varied KV cache size and eviction policies (including high-retention ones like 99% via AttentionTop) to assess impact on generation quality and positional coherence.", "result": "Generation quality degrades sharply as the accumulated KV cache approaches or exceeds the model\u2019s trained context window (e.g., 8192 tokens). High-retention eviction can worsen performance if it disrupts positional coherence. Compacting the cache by removing non-contiguous tokens can scramble positional signals (e.g., RoPE) and degrade outputs. Simpler strategies that preserve contiguous context blocks (e.g., keeping an initial gist) yield more coherent generations than complex or position-disruptive ones.", "conclusion": "Eviction strategies should respect architectural context limits, preserve positional structure, and treat cache health holistically rather than size alone."}}
{"id": "2511.04855", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04855", "abs": "https://arxiv.org/abs/2511.04855", "authors": ["Vojtech Franc", "Jakub Paplham"], "title": "Epistemic Reject Option Prediction", "comment": null, "summary": "In high-stakes applications, predictive models must not only produce accurate\npredictions but also quantify and communicate their uncertainty. Reject-option\nprediction addresses this by allowing the model to abstain when prediction\nuncertainty is high. Traditional reject-option approaches focus solely on\naleatoric uncertainty, an assumption valid only when large training data makes\nthe epistemic uncertainty negligible. However, in many practical scenarios,\nlimited data makes this assumption unrealistic. This paper introduces the\nepistemic reject-option predictor, which abstains in regions of high epistemic\nuncertainty caused by insufficient data. Building on Bayesian learning, we\nredefine the optimal predictor as the one that minimizes expected regret -- the\nperformance gap between the learned model and the Bayes-optimal predictor with\nfull knowledge of the data distribution. The model abstains when the regret for\na given input exceeds a specified rejection cost. To our knowledge, this is the\nfirst principled framework that enables learning predictors capable of\nidentifying inputs for which the training data is insufficient to make reliable\ndecisions.", "AI": {"tldr": "A Bayesian, regret-based abstention framework (epistemic reject-option) that abstains in inputs with high epistemic uncertainty due to limited data; defines abstention via regret relative to Bayes-optimal predictor and a rejection cost.", "motivation": "High-stakes settings require not just accuracy but reliable uncertainty estimates; traditional reject-option focuses on aleatoric uncertainty and fails when data are scarce, making epistemic uncertainty important.", "method": "Define the optimal predictor as one that minimizes expected regret to the Bayes-optimal predictor with full distribution knowledge; abstain when the input's regret exceeds a specified rejection cost; builds on Bayesian learning to quantify epistemic uncertainty and guide abstention.", "result": "Proposes a principled framework for identifying inputs where training data are insufficient for reliable decisions; formalizes regret-based abstention and shows how to implement an epistemic reject-option predictor (novelty claim: first principled framework of this kind).", "conclusion": "This work introduces the first principled framework for epistemic reject-option prediction, enabling learning predictors that abstain in regions with insufficient data to make reliable decisions."}}
{"id": "2511.04769", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04769", "abs": "https://arxiv.org/abs/2511.04769", "authors": ["Phat Nguyen", "Tsun-Hsuan Wang", "Zhang-Wei Hong", "Erfan Aasi", "Andrew Silva", "Guy Rosman", "Sertac Karaman", "Daniela Rus"], "title": "ReGen: Generative Robot Simulation via Inverse Design", "comment": null, "summary": "Simulation plays a key role in scaling robot learning and validating\npolicies, but constructing simulations remains a labor-intensive process. This\npaper introduces ReGen, a generative simulation framework that automates\nsimulation design via inverse design. Given a robot's behavior -- such as a\nmotion trajectory or an objective function -- and its textual description,\nReGen infers plausible scenarios and environments that could have caused the\nbehavior. ReGen leverages large language models to synthesize scenarios by\nexpanding a directed graph that encodes cause-and-effect relationships,\nrelevant entities, and their properties. This structured graph is then\ntranslated into a symbolic program, which configures and executes a robot\nsimulation environment. Our framework supports (i) augmenting simulations based\non ego-agent behaviors, (ii) controllable, counterfactual scenario generation,\n(iii) reasoning about agent cognition and mental states, and (iv) reasoning\nwith distinct sensing modalities, such as braking due to faulty GPS signals. We\ndemonstrate ReGen in autonomous driving and robot manipulation tasks,\ngenerating more diverse, complex simulated environments compared to existing\nsimulations with high success rates, and enabling controllable generation for\ncorner cases. This approach enhances the validation of robot policies and\nsupports data or simulation augmentation, advancing scalable robot learning for\nimproved generalization and robustness. We provide code and example videos at:\nhttps://regen-sim.github.io/", "AI": {"tldr": "ReGen is a generative simulation framework that uses large language models to inverse-design plausible driving/manipulation scenarios from a robot's observed behavior, converting a cause\u2013effect graph into executable simulations to yield diverse, controllable environments for robust policy learning.", "motivation": "Constructing realistic simulations is labor-intensive and often lacks diversity; scalable, controllable simulation generation is needed to validate and generalize robot policies.", "method": "Use LLMs to expand a directed causal graph encoding entities, properties, and relationships from a robot's behavior and description; convert the graph into a symbolic program that configures a simulator; support ego-agent augmentation, counterfactuals, cognition state reasoning, and multi-sensing modalities.", "result": "Produces more diverse and complex simulated environments than existing simulators, with high success rates and controllable generation of corner cases in autonomous driving and manipulation tasks; includes code and example videos.", "conclusion": "ReGen enables scalable validation and data/simulation augmentation for robust, generalizable robot learning."}}
{"id": "2511.04729", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04729", "abs": "https://arxiv.org/abs/2511.04729", "authors": ["Rucha Deshpande", "Tahsin Rahman", "Miguel Lago", "Adarsh Subbaswamy", "Jana G. Delfino", "Ghada Zamzmi", "Elim Thompson", "Aldo Badano", "Seyed Kahaki"], "title": "Knowledge-based anomaly detection for identifying network-induced shape artifacts", "comment": "15 pages, 11 figures", "summary": "Synthetic data provides a promising approach to address data scarcity for\ntraining machine learning models; however, adoption without proper quality\nassessments may introduce artifacts, distortions, and unrealistic features that\ncompromise model performance and clinical utility. This work introduces a novel\nknowledge-based anomaly detection method for detecting network-induced shape\nartifacts in synthetic images. The introduced method utilizes a two-stage\nframework comprising (i) a novel feature extractor that constructs a\nspecialized feature space by analyzing the per-image distribution of angle\ngradients along anatomical boundaries, and (ii) an isolation forest-based\nanomaly detector. We demonstrate the effectiveness of the method for\nidentifying network-induced shape artifacts in two synthetic mammography\ndatasets from models trained on CSAW-M and VinDr-Mammo patient datasets\nrespectively. Quantitative evaluation shows that the method successfully\nconcentrates artifacts in the most anomalous partition (1st percentile), with\nAUC values of 0.97 (CSAW-syn) and 0.91 (VMLO-syn). In addition, a reader study\ninvolving three imaging scientists confirmed that images identified by the\nmethod as containing network-induced shape artifacts were also flagged by human\nreaders with mean agreement rates of 66% (CSAW-syn) and 68% (VMLO-syn) for the\nmost anomalous partition, approximately 1.5-2 times higher than the least\nanomalous partition. Kendall-Tau correlations between algorithmic and human\nrankings were 0.45 and 0.43 for the two datasets, indicating reasonable\nagreement despite the challenging nature of subtle artifact detection. This\nmethod is a step forward in the responsible use of synthetic data, as it allows\ndevelopers to evaluate synthetic images for known anatomic constraints and\npinpoint and address specific issues to improve the overall quality of a\nsynthetic dataset.", "AI": {"tldr": "Two-stage knowledge-based anomaly detector for synthetic mammography detects network-induced shape artifacts; uses a gradient-angle feature space and an isolation forest; validated on CSAW-M-syn and VMLO-syn with high AUC and reasonable human agreement.", "motivation": "Ensure quality and clinical utility of synthetic data by identifying artifacts that can distort model performance.", "method": "Stage 1: develop a feature extractor that builds a specialized feature space by analyzing per-image distributions of angle gradients along anatomical boundaries. Stage 2: apply an isolation forest anomaly detector. Evaluated on two synthetic mammography datasets derived from CSAW-M and VinDr-Mammo; includes a reader study with imaging scientists.", "result": "Artifacts concentrated in the most anomalous 1st percentile; AUCs 0.97 (CSAW-syn) and 0.91 (VMLO-syn). Reader study: mean agreement 66% and 68% with Kendall-Tau 0.45 and 0.43, indicating reasonable agreement.", "conclusion": "The approach supports responsible use of synthetic data by identifying and pinpointing shape artifact issues tied to anatomical constraints, guiding improvements to synthetic datasets."}}
{"id": "2511.04718", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04718", "abs": "https://arxiv.org/abs/2511.04718", "authors": ["Yue Xun", "Jiaxing Xu", "Wenbo Gao", "Chen Yang", "Shujun Wang"], "title": "Ada-FCN: Adaptive Frequency-Coupled Network for fMRI-Based Brain Disorder Classification", "comment": "11 pages, 2 figures, conference", "summary": "Resting-state fMRI has become a valuable tool for classifying brain disorders\nand constructing brain functional connectivity networks\n  by tracking BOLD signals across brain regions. However, existing mod els\nlargely neglect the multi-frequency nature of neuronal oscillations,\n  treating BOLD signals as monolithic time series. This overlooks the cru cial\nfact that neurological disorders often manifest as disruptions within\n  specific frequency bands, limiting diagnostic sensitivity and specificity.\n  While some methods have attempted to incorporate frequency informa tion, they\noften rely on predefined frequency bands, which may not be\n  optimal for capturing individual variability or disease-specific alterations.\n  To address this, we propose a novel framework featuring Adaptive Cas cade\nDecomposition to learn task-relevant frequency sub-bands for each\n  brain region and Frequency-Coupled Connectivity Learning to capture\n  both intra- and nuanced cross-band interactions in a unified functional\n  network. This unified network informs a novel message-passing mecha nism\nwithin our Unified-GCN, generating refined node representations\n  for diagnostic prediction. Experimental results on the ADNI and ABIDE\n  datasets demonstrate superior performance over existing methods. The\n  code is available at https://github.com/XXYY20221234/Ada-FCN.", "AI": {"tldr": "Adaptive Cascade Decomposition and Frequency-Coupled Connectivity Learning within a Unified-GCN for rs-fMRI-based diagnosis, learning individualized frequency sub-bands and cross-band interactions.", "motivation": "Current rs-fMRI models treat BOLD signals as a monolithic time series, neglecting multi-frequency information. Neurological disorders often manifest in disruptions within specific frequency bands, and predefined bands fail to capture individual variability.", "method": "Adaptive Cascade Decomposition to learn task-relevant frequency sub-bands per brain region; Frequency-Coupled Connectivity Learning to capture intra- and cross-band interactions in a unified functional network; integrated into a Unified-GCN with a novel message-passing mechanism for diagnostic prediction.", "result": "Demonstrates superior diagnostic performance on ADNI and ABIDE datasets compared to existing methods; code available at GitHub.", "conclusion": "Introduces a unified framework that jointly learns frequency sub-bands and cross-band connectivity to enhance rs-fMRI-based diagnosis, with potential for personalized brain-network representations."}}
{"id": "2511.04880", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04880", "abs": "https://arxiv.org/abs/2511.04880", "authors": ["Yu Bai", "Yukai Miao", "Dawei Wang", "Li Chen", "Fei Long", "Rundi Zhai", "Dan Li", "Yanyu Ren", "Tianfeng Liu", "Hongtao Xie", "Ce Yang", "Xuhui Cai"], "title": "DMA: Online RAG Alignment with Human Feedback", "comment": null, "summary": "Retrieval-augmented generation (RAG) systems often rely on static retrieval,\nlimiting adaptation to evolving intent and content drift. We introduce Dynamic\nMemory Alignment (DMA), an online learning framework that systematically\nincorporates multi-granularity human feedback to align ranking in interactive\nsettings. DMA organizes document-, list-, and response-level signals into a\ncoherent learning pipeline: supervised training for pointwise and listwise\nrankers, policy optimization driven by response-level preferences, and\nknowledge distillation into a lightweight scorer for low-latency serving.\nThroughout this paper, memory refers to the model's working memory, which is\nthe entire context visible to the LLM for In-Context Learning.\n  We adopt a dual-track evaluation protocol mirroring deployment: (i)\nlarge-scale online A/B ablations to isolate the utility of each feedback\nsource, and (ii) few-shot offline tests on knowledge-intensive benchmarks.\nOnline, a multi-month industrial deployment further shows substantial\nimprovements in human engagement. Offline, DMA preserves competitive\nfoundational retrieval while yielding notable gains on conversational QA\n(TriviaQA, HotpotQA). Taken together, these results position DMA as a\nprincipled approach to feedback-driven, real-time adaptation in RAG without\nsacrificing baseline capability.", "AI": {"tldr": "DMA is an online learning framework that uses multi-granularity human feedback to dynamically align RAG ranking, improving engagement and knowledge-intensive QA while preserving baseline retrieval capabilities.", "motivation": "RAG systems often rely on static retrieval, leading to adaptation lag when user intents and content drift occur. There is a need for online, feedback-driven adaptation that can update ranking and behavior in real time.", "method": "DMA collects signals at document-, list-, and response-level and trains pointwise and listwise rankers in supervised fashion; uses policy optimization guided by response-level preferences; distills knowledge into a lightweight scorer for low-latency serving; memory here refers to the model's working memory/context for in-context learning.", "result": "Online A/B ablations and a multi-month industrial deployment show substantial improvements in human engagement; offline, DMA preserves competitive retrieval while yielding gains on conversational QA benchmarks (TriviaQA, HotpotQA).", "conclusion": "DMA provides a principled framework for feedback-driven, real-time adaptation in retrieval-augmented generation without sacrificing baseline capabilities."}}
{"id": "2511.04812", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04812", "abs": "https://arxiv.org/abs/2511.04812", "authors": ["Zixuan Huang", "Huaidian Hou", "Dmitry Berenson"], "title": "Unified Multimodal Diffusion Forcing for Forceful Manipulation", "comment": "Project website: https://unified-df.github.io", "summary": "Given a dataset of expert trajectories, standard imitation learning\napproaches typically learn a direct mapping from observations (e.g., RGB\nimages) to actions. However, such methods often overlook the rich interplay\nbetween different modalities, i.e., sensory inputs, actions, and rewards, which\nis crucial for modeling robot behavior and understanding task outcomes. In this\nwork, we propose Multimodal Diffusion Forcing, a unified framework for learning\nfrom multimodal robot trajectories that extends beyond action generation.\nRather than modeling a fixed distribution, MDF applies random partial masking\nand trains a diffusion model to reconstruct the trajectory. This training\nobjective encourages the model to learn temporal and cross-modal dependencies,\nsuch as predicting the effects of actions on force signals or inferring states\nfrom partial observations. We evaluate MDF on contact-rich, forceful\nmanipulation tasks in simulated and real-world environments. Our results show\nthat MDF not only delivers versatile functionalities, but also achieves strong\nperformance, and robustness under noisy observations. More visualizations can\nbe found on our website https://unified-df.github.io", "AI": {"tldr": "Multimodal Diffusion Forcing (MDF) introduces a diffusion-based, partially masked reconstruction objective to learn from multimodal robot trajectories (observations, actions, rewards, etc.), enabling cross-modal and temporal understanding beyond direct action prediction.", "motivation": "Standard imitation learning often maps observations to actions and overlooks the rich interplay among modalities (sensory inputs, actions, rewards). Capturing these cross-modal and temporal dependencies is crucial for robust, task-relevant robot behavior and understanding outcomes.", "method": "MDF applies random partial masking to multimodal trajectory data and trains a diffusion model to reconstruct the full trajectory, encouraging learning of temporal dynamics and cross-modal relationships such as how actions affect force signals or how states can be inferred from partial observations.", "result": "Empirical evaluations on contact-rich, forceful manipulation tasks in simulation and on real hardware show MDF provides versatile capabilities, strong performance, and robustness to noisy observations.", "conclusion": "A unified, diffusion-based framework for multimodal imitation learning that goes beyond action generation, enabling cross-modal reasoning and more robust robot behavior across modalities."}}
{"id": "2511.04753", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04753", "abs": "https://arxiv.org/abs/2511.04753", "authors": ["Zonglin Lyu", "Ming Li", "Xinxin Liu", "Chen Chen"], "title": "CPO: Condition Preference Optimization for Controllable Image Generation", "comment": null, "summary": "To enhance controllability in text-to-image generation, ControlNet introduces\nimage-based control signals, while ControlNet++ improves pixel-level cycle\nconsistency between generated images and the input control signal. To avoid the\nprohibitive cost of back-propagating through the sampling process, ControlNet++\noptimizes only low-noise timesteps (e.g., $t < 200$) using a single-step\napproximation, which not only ignores the contribution of high-noise timesteps\nbut also introduces additional approximation errors. A straightforward\nalternative for optimizing controllability across all timesteps is Direct\nPreference Optimization (DPO), a fine-tuning method that increases model\npreference for more controllable images ($I^{w}$) over less controllable ones\n($I^{l}$). However, due to uncertainty in generative models, it is difficult to\nensure that win--lose image pairs differ only in controllability while keeping\nother factors, such as image quality, fixed. To address this, we propose\nperforming preference learning over control conditions rather than generated\nimages. Specifically, we construct winning and losing control signals,\n$\\mathbf{c}^{w}$ and $\\mathbf{c}^{l}$, and train the model to prefer\n$\\mathbf{c}^{w}$. This method, which we term \\textit{Condition Preference\nOptimization} (CPO), eliminates confounding factors and yields a low-variance\ntraining objective. Our approach theoretically exhibits lower contrastive loss\nvariance than DPO and empirically achieves superior results. Moreover, CPO\nrequires less computation and storage for dataset curation. Extensive\nexperiments show that CPO significantly improves controllability over the\nstate-of-the-art ControlNet++ across multiple control types: over $10\\%$ error\nrate reduction in segmentation, $70$--$80\\%$ in human pose, and consistent\n$2$--$5\\%$ reductions in edge and depth maps.", "AI": {"tldr": "Introduces Condition Preference Optimization (CPO) to boost controllability in text-to-image generation by learning preferences over control signals (c^w vs c^l) rather than generated images, yielding lower-variance training and better results than DPO, with reduced compute and data needs.", "motivation": "Improve controllability in diffusion-based text-to-image models (e.g., ControlNet++) while avoiding high computational cost and confounding factors that tie controllability to image quality. Prior approaches either rely on low-noise timestep approximations or optimize over images, which can degrade training signal and add variance.", "method": "Propose Condition Preference Optimization (CPO): construct winning and losing control signals (c^w, c^l) and train the model to prefer c^w. This eliminates confounding factors, yields a lower-variance contrastive loss than Direct Preference Optimization (DPO), and reduces computation/storage for dataset curation.", "result": "Empirically, CPO significantly improves controllability over ControlNet++ across multiple control types, achieving over 10% error rate reduction in segmentation, 70\u201380% in human pose, and 2\u20135% reductions in edge and depth maps.", "conclusion": "CPO provides a more reliable and efficient means to tune controllability in diffusion-based T2I models, outperforming DPO and ControlNet++ in both variance and practical performance while reducing data preparation costs."}}
{"id": "2511.04722", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04722", "abs": "https://arxiv.org/abs/2511.04722", "authors": ["Qianyang Li", "Xingjun Zhang", "Peng Tao", "Shaoxun Wang", "Yancheng Pan", "Jia Wei"], "title": "AWEMixer: Adaptive Wavelet-Enhanced Mixer Network for Long-Term Time Series Forecasting", "comment": null, "summary": "Forecasting long-term time series in IoT environments remains a significant\nchallenge due to the non-stationary and multi-scale characteristics of sensor\nsignals. Furthermore, error accumulation causes a decrease in forecast quality\nwhen predicting further into the future. Traditional methods are restricted to\noperate in time-domain, while the global frequency information achieved by\nFourier transform would be regarded as stationary signals leading to blur the\ntemporal patterns of transient events. We propose AWEMixer, an Adaptive\nWavelet-Enhanced Mixer Network including two innovative components: 1) a\nFrequency Router designs to utilize the global periodicity pattern achieved by\nFast Fourier Transform to adaptively weight localized wavelet subband, and 2) a\nCoherent Gated Fusion Block to achieve selective integration of prominent\nfrequency features with multi-scale temporal representation through\ncross-attention and gating mechanism, which realizes accurate time-frequency\nlocalization while remaining robust to noise. Seven public benchmarks validate\nthat our model is more effective than recent state-of-the-art models.\nSpecifically, our model consistently achieves performance improvement compared\nwith transformer-based and MLP-based state-of-the-art models in long-sequence\ntime series forecasting. Code is available at\nhttps://github.com/hit636/AWEMixer", "AI": {"tldr": "AWEMixer introduces an Adaptive Wavelet-Enhanced Mixer Network for long-term IoT time-series forecasting, combining a Frequency Router and a Coherent Gated Fusion Block to achieve robust time-frequency localization and improved long-horizon accuracy over Transformer/MLP baselines.", "motivation": "Long-term forecasting in IoT is challenging due to non-stationarity and multi-scale sensor signals; error accumulation worsens far-future forecasts; Fourier-based global views blur transient events in time-domain representations.", "method": "Proposes AWEMixer: Frequency Router uses FFT-based global periodicity to adaptively weight localized wavelet subbands; Coherent Gated Fusion Block uses cross-attention and gating to selectively fuse prominent frequency features across multi-scale temporal representations, enabling accurate time-frequency localization while resisting noise.", "result": "Evaluated on seven public benchmarks; outperformed recent state-of-the-art transformer- and MLP-based models in long-sequence forecasting; publicly available code.", "conclusion": "Demonstrates that adaptively combining wavelet-localized features with global frequency cues yields robust, accurate long-horizon forecasts for non-stationary, multi-scale IoT data."}}
{"id": "2511.04898", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04898", "abs": "https://arxiv.org/abs/2511.04898", "authors": ["Yule Wen", "Yixin Ye", "Yanzhe Zhang", "Diyi Yang", "Hao Zhu"], "title": "Real-Time Reasoning Agents in Evolving Environments", "comment": "30 pages", "summary": "Agents in the real world must make not only logical but also timely\njudgments. This requires continuous awareness of the dynamic environment:\nhazards emerge, opportunities arise, and other agents act, while the agent's\nreasoning is still unfolding. Despite advances in language model reasoning,\nexisting approaches fail to account for this dynamic nature. We introduce\nreal-time reasoning as a new problem formulation for agents in evolving\nenvironments and build Real-Time Reasoning Gym to demonstrate it. We study two\nparadigms for deploying language models in agents: (1) reactive agents, which\nemploy language models with bounded reasoning computation for rapid responses,\nand (2) planning agents, which allow extended reasoning computation for complex\nproblems. Our experiments show that even state-of-the-art models struggle with\nmaking logical and timely judgments in either paradigm. To address this\nlimitation, we propose AgileThinker, which simultaneously engages both\nreasoning paradigms. AgileThinker consistently outperforms agents engaging only\none reasoning paradigm as the task difficulty and time pressure rise,\neffectively balancing reasoning depth and response latency. Our work\nestablishes real-time reasoning as a critical testbed for developing practical\nagents and provides a foundation for research in temporally constrained AI\nsystems, highlighting a path toward real-time capable agents.", "AI": {"tldr": "A framework for real-time reasoning in dynamic environments that blends reactive and planning language-model agents using AgileThinker, showing improvements over single-paradigm approaches under time pressure.", "motivation": "Agents operating in the real world must make timely judgments amid changing environments; current LLM reasoning approaches are too slow or not temporally constrained, necessitating a real-time reasoning testbed and methods.", "method": "Introduce Real-Time Reasoning Gym as a testbed; evaluate two paradigms\u2014reactive agents with bounded reasoning for fast responses, and planning agents with extended reasoning for complex tasks; propose AgileThinker that combines both paradigms; conduct experiments to compare performance under varying task difficulty and time pressure.", "result": "State-of-the-art models struggle to consistently make logical and timely judgments; AgileThinker outperforms agents relying on a single paradigm, especially as task difficulty or time pressure rises, by balancing reasoning depth and latency.", "conclusion": "Real-time reasoning is a critical testbed for practical agents and lays a foundation for temporally constrained AI research, pointing toward the development of real-time capable agents."}}
{"id": "2511.04827", "categories": ["cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.04827", "abs": "https://arxiv.org/abs/2511.04827", "authors": ["Tobias Fischer", "Wolf Vollprecht", "Bas Zalmstra", "Ruben Arts", "Tim de Jager", "Alejandro Fontan", "Adam D Hines", "Michael Milford", "Silvio Traversaro", "Daniel Claes", "Scarlett Raine"], "title": "Pixi: Unified Software Development and Distribution for Robotics and AI", "comment": "20 pages, 3 figures, 11 code snippets", "summary": "The reproducibility crisis in scientific computing constrains robotics\nresearch. Existing studies reveal that up to 70% of robotics algorithms cannot\nbe reproduced by independent teams, while many others fail to reach deployment\nbecause creating shareable software environments remains prohibitively complex.\nThese challenges stem from fragmented, multi-language, and hardware-software\ntoolchains that lead to dependency hell. We present Pixi, a unified\npackage-management framework that addresses these issues by capturing exact\ndependency states in project-level lockfiles, ensuring bit-for-bit\nreproducibility across platforms. Its high-performance SAT solver achieves up\nto 10x faster dependency resolution than comparable tools, while integration of\nthe conda-forge and PyPI ecosystems removes the need for multiple managers.\nAdopted in over 5,300 projects since 2023, Pixi reduces setup times from hours\nto minutes and lowers technical barriers for researchers worldwide. By enabling\nscalable, reproducible, collaborative research infrastructure, Pixi accelerates\nprogress in robotics and AI.", "AI": {"tldr": "Pixi is a unified, lockfile-based package-management framework for robotics/AI that ensures bit-for-bit reproducibility across platforms by capturing exact dependency states and fast SAT-based resolution, integrating conda-forge and PyPI to simplify workflows.", "motivation": "The reproducibility crisis in scientific computing and robotics arises from fragmented, multi-language, hardware-specific toolchains and complex environments, leading to unrepeatable results and deployment barriers.", "method": "Develop Pixi to (1) capture exact dependency states in project-level lockfiles, (2) employ a high-performance SAT solver for fast dependency resolution, and (3) integrate conda-forge and PyPI ecosystems to unify package management across environments.", "result": "Pixi achieves up to 10x faster dependency resolution, has been adopted in over 5,300 projects since 2023, and cuts setup times from hours to minutes, lowering barriers for reproducible research.", "conclusion": "Pixi enables scalable, reproducible, collaborative research infrastructure for robotics and AI by unifying package ecosystems and mitigating dependency fragmentation."}}
{"id": "2511.04766", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04766", "abs": "https://arxiv.org/abs/2511.04766", "authors": ["Dhenenjay Yadav", "Rohan Sawai"], "title": "DARN: Dynamic Adaptive Regularization Networks for Efficient and Robust Foundation Model Adaptation", "comment": null, "summary": "Foundation models (FMs) offer powerful representations for geospatial\nanalysis, but adapting them effectively remains challenging. Standard\nadaptation methods, whether full fine-tuning or efficient frozen-backbone\napproaches, typically employ decoders with fixed regularization strategies,\nfailing to account for the significant heterogeneity in satellite imagery. We\nintroduce Dynamic Adaptive Regularization Networks (DARN), a novel decoder\narchitecture designed to address this limitation. DARN integrates three key\ninnovations: (1) a lightweight Task Complexity Predictor (TCP) that estimates\nper-sample difficulty, (2) Adaptive Dropout Modulation (ADM), dynamically\nadjusting dropout rates (from 0.1 to 0.5) based on predicted complexity, and\n(3) Dynamic Capacity Gating (DCG) that modulates channel activation. We provide\ntheoretical justifications linking DARN's optimization to stationary point\nconvergence and its mechanism to adaptive information bottlenecks. Empirically,\nDARN demonstrates exceptional performance across both major adaptation\nparadigms. In full fine-tuning (unfrozen backbone), DARN achieves a new\nstate-of-the-art on the multi-task GeoBench benchmark (86.66% mIoU, +5.56 pp\nover prior SOTA). In efficient adaptation (frozen backbone), DARN achieves\nSOTA-competitive accuracy (90.5% mIoU on Sen1Floods11) while delivering\nsubstantial advantages crucial for real-world deployment: superior\nout-of-distribution (OOD) generalization (+9.5 pp mIoU on AI4SmallFarms),\nenhanced robustness (17% relative reduction in corruption error), and improved\nperformance on minority classes. DARN offers a more intelligent, robust, and\nefficient approach to leveraging FMs in critical geospatial applications.", "AI": {"tldr": "Dynamic Adaptive Regularization Networks (DARN) tailor decoders to per-sample complexity in geospatial FM adaptation, yielding state-of-the-art performance and improved robustness across both full fine-tuning and frozen-backbone settings.", "motivation": "Standard adaptation methods with fixed regularization fail to account for the heavy heterogeneity in satellite imagery; there is a need for per-sample adaptive regularization to improve generalization and efficiency in foundation-model-based geospatial analysis.", "method": "DARN integrates three components: (1) Task Complexity Predictor (TCP) that estimates per-sample difficulty, (2) Adaptive Dropout Modulation (ADM) that adjusts dropout rates (0.1 to 0.5) based on predicted complexity, and (3) Dynamic Capacity Gating (DCG) that modulates channel activation. The paper provides theoretical justifications linking DARN to stationary-point convergence and adaptive information bottlenecks.", "result": "Empirically, DARN achieves state-of-the-art performance across adaptation paradigms: in full fine-tuning (unfrozen backbone) it sets new SOTA on GeoBench with 86.66% mIoU (+5.56 percentage points). In efficient adaptation (frozen backbone), it reaches SOTA-competitive 90.5% mIoU on Sen1Floods11, with substantial advantages: +9.5 pp mIoU in out-of-distribution generalization on AI4SmallFarms, 17% relative reduction in corruption error, and improved performance on minority classes.", "conclusion": "DARN offers a more intelligent, robust, and deployment-friendly approach to leveraging foundation models for critical geospatial applications by integrating adaptive regularization mechanisms that respond to per-sample complexity."}}
{"id": "2511.04723", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04723", "abs": "https://arxiv.org/abs/2511.04723", "authors": ["Mohamadreza Akbari Pour", "Mohamad Sadeq Karimi", "Amir Hossein Mazloumi"], "title": "Temporal convolutional and fusional transformer model with Bi-LSTM encoder-decoder for multi-time-window remaining useful life prediction", "comment": null, "summary": "Health prediction is crucial for ensuring reliability, minimizing downtime,\nand optimizing maintenance in industrial systems. Remaining Useful Life (RUL)\nprediction is a key component of this process; however, many existing models\nstruggle to capture fine-grained temporal dependencies while dynamically\nprioritizing critical features across time for robust prognostics. To address\nthese challenges, we propose a novel framework that integrates Temporal\nConvolutional Networks (TCNs) for localized temporal feature extraction with a\nmodified Temporal Fusion Transformer (TFT) enhanced by Bi-LSTM encoder-decoder.\nThis architecture effectively bridges short- and long-term dependencies while\nemphasizing salient temporal patterns. Furthermore, the incorporation of a\nmulti-time-window methodology improves adaptability across diverse operating\nconditions. Extensive evaluations on benchmark datasets demonstrate that the\nproposed model reduces the average RMSE by up to 5.5%, underscoring its\nimproved predictive accuracy compared to state-of-the-art methods. By closing\ncritical gaps in current approaches, this framework advances the effectiveness\nof industrial prognostic systems and highlights the potential of advanced\ntime-series transformers for RUL prediction.", "AI": {"tldr": "A novel hybrid model for RUL prediction that combines Temporal Convolutional Networks with a Bi-LSTM-augmented Temporal Fusion Transformer and a multi-time-window strategy, achieving up to 5.5% RMSE reduction over state-of-the-art methods.", "motivation": "Accurate Remaining Useful Life prediction requires capturing fine-grained temporal dependencies and dynamically prioritizing features across time across varying operating conditions in industrial systems.", "method": "The approach integrates Temporal Convolutional Networks (TCNs) for localized temporal feature extraction with a modified Temporal Fusion Transformer (TFT) enhanced by a Bi-LSTM encoder\u2013decoder. A multi-time-window methodology improves adaptability across diverse operating conditions, bridging short- and long-term dependencies and emphasizing salient temporal patterns.", "result": "Extensive evaluations on benchmark datasets show the proposed model reduces average RMSE by up to 5.5% compared to state-of-the-art methods, indicating improved predictive accuracy for RUL.", "conclusion": "The framework advances industrial prognostics by addressing gaps in temporal feature modeling and highlights the potential of advanced time-series transformers for robust RUL prediction across varying conditions."}}
{"id": "2511.04956", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04956", "abs": "https://arxiv.org/abs/2511.04956", "authors": ["Maria Mahbub", "Vanessa Lama", "Sanjay Das", "Brian Starks", "Christopher Polchek", "Saffell Silvers", "Lauren Deck", "Prasanna Balaprakash", "Tirthankar Ghosal"], "title": "ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property", "comment": null, "summary": "High-Risk Property (HRP) classification is critical at U.S. Department of\nEnergy (DOE) sites, where inventories include sensitive and often dual-use\nequipment. Compliance must track evolving rules designated by various export\ncontrol policies to make transparent and auditable decisions. Traditional\nexpert-only workflows are time-consuming, backlog-prone, and struggle to keep\npace with shifting regulatory boundaries. We demo ORCHID, a modular agentic\nsystem for HRP classification that pairs retrieval-augmented generation (RAG)\nwith human oversight to produce policy-based outputs that can be audited. Small\ncooperating agents, retrieval, description refiner, classifier, validator, and\nfeedback logger, coordinate via agent-to-agent messaging and invoke tools\nthrough the Model Context Protocol (MCP) for model-agnostic on-premise\noperation. The interface follows an Item to Evidence to Decision loop with\nstep-by-step reasoning, on-policy citations, and append-only audit bundles\n(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID\nimproves accuracy and traceability over a non-agentic baseline while deferring\nuncertain items to Subject Matter Experts (SMEs). The demonstration shows\nsingle item submission, grounded citations, SME feedback capture, and\nexportable audit artifacts, illustrating a practical path to trustworthy LLM\nassistance in sensitive DOE compliance workflows.", "AI": {"tldr": "ORCHID is a modular, agent-based system that uses retrieval-augmented generation (RAG) and human oversight to classify high-risk property (HRP) at DOE sites, delivering auditable, policy-based outputs with on-premise operation.", "motivation": "To replace slow, backlog-prone expert-only HRP classification with a framework that maintains policy alignment, transparency, and auditability amid evolving export-control rules, while keeping data on-site.", "method": "A cooperative multi-agent architecture (retrieval, description refiner, classifier, validator, feedback logger) that communicates via agent-to-agent messaging and the Model Context Protocol (MCP). It implements an Item\u2013Evidence\u2013Decision loop with step-by-step reasoning, grounded citations, and append-only audit bundles (run-cards, prompts, evidence) for auditable outputs, all operable on-premise.", "result": "Preliminary tests on real HRP cases show improved accuracy and traceability versus a non-agentic baseline, with uncertain items deferred to SMEs; demonstration includes single-item submissions, grounded citations, SME feedback capture, and exportable audit artifacts.", "conclusion": "ORCHID demonstrates a practical, auditable path for trustworthy LLM-assisted DOE compliance workflows, balancing automation with SME oversight and on-premise governance."}}
{"id": "2511.04831", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04831", "abs": "https://arxiv.org/abs/2511.04831", "authors": ["NVIDIA", ":", "Mayank Mittal", "Pascal Roth", "James Tigue", "Antoine Richard", "Octi Zhang", "Peter Du", "Antonio Serrano-Mu\u00f1oz", "Xinjie Yao", "Ren\u00e9 Zurbr\u00fcgg", "Nikita Rudin", "Lukasz Wawrzyniak", "Milad Rakhsha", "Alain Denzler", "Eric Heiden", "Ales Borovicka", "Ossama Ahmed", "Iretiayo Akinola", "Abrar Anwar", "Mark T. Carlson", "Ji Yuan Feng", "Animesh Garg", "Renato Gasoto", "Lionel Gulich", "Yijie Guo", "M. Gussert", "Alex Hansen", "Mihir Kulkarni", "Chenran Li", "Wei Liu", "Viktor Makoviychuk", "Grzegorz Malczyk", "Hammad Mazhar", "Masoud Moghani", "Adithyavairavan Murali", "Michael Noseworthy", "Alexander Poddubny", "Nathan Ratliff", "Welf Rehberg", "Clemens Schwarke", "Ritvik Singh", "James Latham Smith", "Bingjie Tang", "Ruchik Thaker", "Matthew Trepte", "Karl Van Wyk", "Fangzhou Yu", "Alex Millane", "Vikram Ramasamy", "Remo Steiner", "Sangeeta Subramanian", "Clemens Volk", "CY Chen", "Neel Jawale", "Ashwin Varghese Kuruttukulam", "Michael A. Lin", "Ajay Mandlekar", "Karsten Patzwaldt", "John Welsh", "Huihua Zhao", "Fatima Anes", "Jean-Francois Lafleche", "Nicolas Mo\u00ebnne-Loccoz", "Soowan Park", "Rob Stepinski", "Dirk Van Gelder", "Chris Amevor", "Jan Carius", "Jumyung Chang", "Anka He Chen", "Pablo de Heras Ciechomski", "Gilles Daviet", "Mohammad Mohajerani", "Julia von Muralt", "Viktor Reutskyy", "Michael Sauter", "Simon Schirm", "Eric L. Shi", "Pierre Terdiman", "Kenny Vilella", "Tobias Widmer", "Gordon Yeoman", "Tiffany Chen", "Sergey Grizan", "Cathy Li", "Lotus Li", "Connor Smith", "Rafael Wiltz", "Kostas Alexis", "Yan Chang", "David Chu", "Linxi \"Jim\" Fan", "Farbod Farshidian", "Ankur Handa", "Spencer Huang", "Marco Hutter", "Yashraj Narang", "Soha Pouya", "Shiwei Sheng", "Yuke Zhu", "Miles Macklin", "Adam Moravanszky", "Philipp Reist", "Yunrong Guo", "David Hoeller", "Gavriel State"], "title": "Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning", "comment": "Code and documentation are available here:\n  https://github.com/isaac-sim/IsaacLab", "summary": "We present Isaac Lab, the natural successor to Isaac Gym, which extends the\nparadigm of GPU-native robotics simulation into the era of large-scale\nmulti-modal learning. Isaac Lab combines high-fidelity GPU parallel physics,\nphotorealistic rendering, and a modular, composable architecture for designing\nenvironments and training robot policies. Beyond physics and rendering, the\nframework integrates actuator models, multi-frequency sensor simulation, data\ncollection pipelines, and domain randomization tools, unifying best practices\nfor reinforcement and imitation learning at scale within a single extensible\nplatform. We highlight its application to a diverse set of challenges,\nincluding whole-body control, cross-embodiment mobility, contact-rich and\ndexterous manipulation, and the integration of human demonstrations for skill\nacquisition. Finally, we discuss upcoming integration with the differentiable,\nGPU-accelerated Newton physics engine, which promises new opportunities for\nscalable, data-efficient, and gradient-based approaches to robot learning. We\nbelieve Isaac Lab's combination of advanced simulation capabilities, rich\nsensing, and data-center scale execution will help unlock the next generation\nof breakthroughs in robotics research.", "AI": {"tldr": "Isaac Lab is a GPU-native robotics simulation platform that scales RL and imitation learning with high-fidelity physics, photorealistic rendering, rich sensing, and data pipelines, aiming to integrate a differentiable Newton engine for data-efficient, gradient-based learning.", "motivation": "To unify and scale simulation, sensing, and data collection for robotics research at data-center scale, enabling broad experimentation across whole-body control, dexterous manipulation, cross-embodiment mobility, and leveraging human demonstrations.", "method": "Extend Isaac Gym with a modular, GPU-accelerated framework that combines high-fidelity parallel physics, photorealistic rendering, actuator models, multi-frequency sensor simulation, data collection pipelines, and domain randomization; supports reinforcement and imitation learning in a unified platform; outlines future integration with a differentiable, GPU-accelerated Newton physics engine.", "result": "Presents a comprehensive, scalable framework and set of capabilities for robotics simulation and learning, demonstrated through applications to whole-body control, cross-embodiment mobility, contact-rich manipulation, and human demonstrations; emphasizes a unified platform for RL/IL at scale and potential data-efficient gradient-based methods via Newton integration.", "conclusion": "Isaac Lab, with its advanced simulation capabilities, rich sensing, and large-scale execution, is positioned to accelerate next-generation robotics research by unifying best practices and enabling scalable, data-efficient learning and experimentation."}}
{"id": "2511.04773", "categories": ["cs.CV", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.04773", "abs": "https://arxiv.org/abs/2511.04773", "authors": ["Shirin Ermis", "Cesar Aybar", "Lilli Freischem", "Stella Girtsou", "Kyriaki-Margarita Bintsi", "Emiliano Diaz Salas-Porras", "Michael Eisinger", "William Jones", "Anna Jungbluth", "Benoit Tremblay"], "title": "Global 3D Reconstruction of Clouds & Tropical Cyclones", "comment": null, "summary": "Accurate forecasting of tropical cyclones (TCs) remains challenging due to\nlimited satellite observations probing TC structure and difficulties in\nresolving cloud properties involved in TC intensification. Recent research has\ndemonstrated the capabilities of machine learning methods for 3D cloud\nreconstruction from satellite observations. However, existing approaches have\nbeen restricted to regions where TCs are uncommon, and are poorly validated for\nintense storms. We introduce a new framework, based on a\npre-training--fine-tuning pipeline, that learns from multiple satellites with\nglobal coverage to translate 2D satellite imagery into 3D cloud maps of\nrelevant cloud properties. We apply our model to a custom-built TC dataset to\nevaluate performance in the most challenging and relevant conditions. We show\nthat we can - for the first time - create global instantaneous 3D cloud maps\nand accurately reconstruct the 3D structure of intense storms. Our model not\nonly extends available satellite observations but also provides estimates when\nobservations are missing entirely. This is crucial for advancing our\nunderstanding of TC intensification and improving forecasts.", "AI": {"tldr": "A cross-satellite 2D-to-3D cloud reconstruction framework using a pre-training\u2013fine-tuning pipeline to produce global instantaneous 3D cloud maps of tropical cyclones, enabling accurate reconstruction of intense storms and recovery of data when observations are missing.", "motivation": "Accurate TC forecasts are hindered by sparse, incomplete satellite information about TC 3D structure and cloud processes; existing 3D reconstruction methods are limited to rare regions and poorly validated for strong hurricanes.", "method": "Train a model on multi-satellite 2D imagery to infer 3D cloud properties; pre-train on globally sourced data, then fine-tune on a custom-built tropical cyclone dataset; produce global instantaneous 3D cloud maps and perform reconstructions even when observations are missing.", "result": "First demonstration of global instantaneous 3D cloud maps for TCs; accurate reconstruction of intense storm structures; extended observational coverage and robustness to missing observations.", "conclusion": "This framework advances TC science by enabling better understanding of intensification mechanisms and improving forecasts through 3D cloud reconstructions across the globe, including data-sparse situations."}}
{"id": "2511.04751", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04751", "abs": "https://arxiv.org/abs/2511.04751", "authors": ["Matteo Cercola", "Michele Lomuscio", "Dario Piga", "Simone Formentin"], "title": "Regularized GLISp for sensor-guided human-in-the-loop optimization", "comment": null, "summary": "Human-in-the-loop calibration is often addressed via preference-based\noptimization, where algorithms learn from pairwise comparisons rather than\nexplicit cost evaluations. While effective, methods such as Preferential\nBayesian Optimization or Global optimization based on active preference\nlearning with radial basis functions (GLISp) treat the system as a black box\nand ignore informative sensor measurements. In this work, we introduce a\nsensor-guided regularized extension of GLISp that integrates measurable\ndescriptors into the preference-learning loop through a physics-informed\nhypothesis function and a least-squares regularization term. This injects\ngrey-box structure, combining subjective feedback with quantitative sensor\ninformation while preserving the flexibility of preference-based search.\nNumerical evaluations on an analytical benchmark and on a human-in-the-loop\nvehicle suspension tuning task show faster convergence and superior final\nsolutions compared to baseline GLISp.", "AI": {"tldr": "Sensor-guided regularized extension of GLISp that adds physics-informed descriptors and regularization to preference-based optimization, creating a grey-box approach that improves convergence and final performance over standard GLISp.", "motivation": "Standard preference-based optimization methods (e.g., Preferential Bayesian Optimization, GLISp) treat the system as a black box and miss informative sensor measurements. Incorporating quantitative sensor descriptors can inject domain knowledge and guide the search more efficiently.", "method": "Introduce a sensor-guided regularized extension of GLISp. Integrate measurable descriptors into the preference-learning loop via a physics-informed hypothesis function and a least-squares regularization term, creating a grey-box structure that combines subjective feedback with sensor data while keeping the flexibility of preference-based search.", "result": "Numerical evaluations on an analytical benchmark and a human-in-the-loop vehicle suspension tuning task show faster convergence and superior final solutions compared to baseline GLISp.", "conclusion": "Grey-box, sensor-informed preference learning with regularization improves both convergence speed and solution quality over standard black-box preference-based methods, while retaining flexibility."}}
{"id": "2511.05182", "categories": ["cs.AI", "cs.CY", "H.4.2; I.2.3; I.2.6; I.2.8; J.7"], "pdf": "https://arxiv.org/pdf/2511.05182", "abs": "https://arxiv.org/abs/2511.05182", "authors": ["Johan Schubert", "Patrik Hansen", "Pontus H\u00f6rling", "Ronnie Johansson"], "title": "Autonomous generation of different courses of action in mechanized combat operations", "comment": "In Proceedings of the 30th International Command and Control Research\n  & Technology Symposium, Stockholm, Sweden, 3-6 November 2025, paper 009", "summary": "In this paper, we propose a methodology designed to support decision-making\nduring the execution phase of military ground combat operations, with a focus\non one's actions. This methodology generates and evaluates recommendations for\nvarious courses of action for a mechanized battalion, commencing with an\ninitial set assessed by their anticipated outcomes. It systematically produces\nthousands of individual action alternatives, followed by evaluations aimed at\nidentifying alternative courses of action with superior outcomes. These\nalternatives are appraised in light of the opponent's status and actions,\nconsidering unit composition, force ratios, types of offense and defense, and\nanticipated advance rates. Field manuals evaluate battle outcomes and\nadvancement rates. The processes of generation and evaluation work\nconcurrently, yielding a variety of alternative courses of action. This\napproach facilitates the management of new course generation based on\npreviously evaluated actions. As the combat unfolds and conditions evolve,\nrevised courses of action are formulated for the decision-maker within a\nsequential decision-making framework.", "AI": {"tldr": "A decision-support method for real-time military execution that generates and evaluates thousands of action alternatives for a mechanized battalion, updating recommendations as conditions evolve to aid sequential commander decisions.", "motivation": "To improve decision quality and speed in dynamic ground combat by systematically exploring a large space of courses of action (COAs) and continuously updating them as the engagement unfolds.", "method": "Generate thousands of action alternatives for a mechanized battalion, evaluate them against the opponent's status/actions, considering unit composition, force ratios, offense/defense types, and anticipated advance rates. Use field manuals to assess battle outcomes and progress rates. Generation and evaluation occur concurrently, with prior evaluated actions guiding new COA generation. As conditions evolve, formulate revised COAs within a sequential decision-making framework for the commander.", "result": "A large pool of viable COAs with superior expected outcomes and a mechanism to update and refine options in real time as the battle unfolds, enabling the decision-maker to consider multiple routes through a dynamic environment.", "conclusion": "The approach supports dynamic, sequential decision-making in combat by enabling rapid generation, evaluation, and refinement of action options to improve engagement outcomes."}}
{"id": "2511.04835", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04835", "abs": "https://arxiv.org/abs/2511.04835", "authors": ["Shubham Natraj", "Bruno Sinopoli", "Yiannis Kantaros"], "title": "Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning", "comment": null, "summary": "Sampling-based motion planners (SBMPs) are widely used to compute dynamically\nfeasible robot paths. However, their reliance on uniform sampling often leads\nto poor efficiency and slow planning in complex environments. We introduce a\nnovel non-uniform sampling strategy that integrates into existing SBMPs by\nbiasing sampling toward `certified' regions. These regions are constructed by\n(i) generating an initial, possibly infeasible, path using any heuristic path\npredictor (e.g., A* or vision-language models) and (ii) applying conformal\nprediction to quantify the predictor's uncertainty. This process yields\nprediction sets around the initial-guess path that are guaranteed, with\nuser-specified probability, to contain the optimal solution. To our knowledge,\nthis is the first non-uniform sampling approach for SBMPs that provides such\nprobabilistically correct guarantees on the sampling regions. Extensive\nevaluations demonstrate that our method consistently finds feasible paths\nfaster and generalizes better to unseen environments than existing baselines.", "AI": {"tldr": "A non-uniform sampling method for SBMPs uses conformal-prediction-based certified regions around an initial heuristic path; it provides probabilistic guarantees that the optimal solution lies within sampled regions, improving planning speed and generalization.", "motivation": "Uniform sampling in sampling-based motion planners is often inefficient in complex environments; there is a need to bias sampling toward promising regions while still providing probabilistic guarantees on finding the optimal path.", "method": "1) Generate an initial path with a heuristic predictor (e.g., A*, vision-language model). 2) Apply conformal prediction to quantify the predictor's uncertainty and form prediction sets around the initial path. 3) Use these certified regions to bias SBMP sampling toward promising areas. 4) Integrate the approach into existing SBMP frameworks, maintaining probabilistic guarantees on the sampling region.", "result": "Empirical evaluations show faster discovery of feasible paths and better generalization to unseen environments compared with baselines; the authors claim this is the first method to provide probabilistic guarantees on SBMP sampling regions.", "conclusion": "Non-uniform, certifiably-guided sampling can significantly improve SBMP efficiency while offering probabilistic guarantees, enabling effective use of heuristic predictors within motion planning."}}
{"id": "2511.04779", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04779", "abs": "https://arxiv.org/abs/2511.04779", "authors": ["Andrea Aspesi", "Andrea Simpsi", "Aaron Tognoli", "Simone Mentasti", "Luca Merigo", "Matteo Matteucci"], "title": "EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear", "comment": "International Joint Conference on Neural Networks (IJCNN), 2025", "summary": "Event-based cameras are becoming a popular solution for efficient, low-power\neye tracking. Due to the sparse and asynchronous nature of event data, they\nrequire less processing power and offer latencies in the microsecond range.\nHowever, many existing solutions are limited to validation on powerful GPUs,\nwith no deployment on real embedded devices. In this paper, we present EETnet,\na convolutional neural network designed for eye tracking using purely\nevent-based data, capable of running on microcontrollers with limited\nresources. Additionally, we outline a methodology to train, evaluate, and\nquantize the network using a public dataset. Finally, we propose two versions\nof the architecture: a classification model that detects the pupil on a grid\nsuperimposed on the original image, and a regression model that operates at the\npixel level.", "AI": {"tldr": "Proposes EETnet, a CNN for eye tracking from event-based data that runs on microcontrollers with limited resources, featuring two architectures: a grid-based pupil classification model and a pixel-level regression model; includes training/evaluation/quantization workflow on a public dataset.", "motivation": "Enable embedded deployment of event-based eye tracking, addressing the gap where prior work is validated mainly on GPUs and not on resource-constrained devices.", "method": "Design of a convolutional neural network (EETnet) tailored for sparse, asynchronous event data; development of two variants\u2014(1) grid-based classification to locate the pupil on a superimposed grid, and (2) pixel-level regression for precise localization; outline of a training, evaluation, and quantization pipeline using a public dataset.", "result": "Demonstrates feasibility of running on microcontrollers with limited resources; provides a practical workflow for training, evaluating, and quantizing the network on public data; presents two architectural options for pupil localization from event data.", "conclusion": "EETnet enables embedded, low-power eye tracking from event data and offers both a grid-based classifier and a pixel-level regression model, along with a complete methodology for training and deployment on public datasets."}}
{"id": "2511.04760", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04760", "abs": "https://arxiv.org/abs/2511.04760", "authors": ["Vaibhav Singh", "Eugene Belilovsky", "Rahaf Aljundi"], "title": "When Data Falls Short: Grokking Below the Critical Threshold", "comment": "6 pages", "summary": "In this paper, we investigate the phenomenon of grokking, where models\nexhibit delayed generalization following overfitting on training data. We focus\non data-scarce regimes where the number of training samples falls below the\ncritical threshold, making grokking unobservable, and on practical scenarios\ninvolving distribution shift. We first show that Knowledge Distillation (KD)\nfrom a model that has already grokked on a distribution (p1) can induce and\naccelerate grokking on a different distribution (p2), even when the available\ndata lies below the critical threshold. This highlights the value of KD for\ndeployed models that must adapt to new distributions under limited data. We\nthen study training on the joint distribution (p1, p2) and demonstrate that\nwhile standard supervised training fails when either distribution has\ninsufficient data, distilling from models grokked on the individual\ndistributions enables generalization. Finally, we examine a continual\npretraining setup, where a grokked model transitions from p1 to p2, and find\nthat KD both accelerates generalization and mitigates catastrophic forgetting,\nachieving strong performance even with only 10% of the data. Together, our\nresults provide new insights into the mechanics of grokking under knowledge\ntransfer and underscore the central role of KD in enabling generalization in\nlow-data and evolving distribution settings.", "AI": {"tldr": "KD from a grokked model on one distribution can induce, accelerate, and stabilize grokking on a second distribution under limited data, and KD aids generalization in joint and continual training with distribution shifts.", "motivation": "Grokking represents delayed generalization after overfitting; in data-scarce regimes grokking may be unobservable, yet real-world systems must adapt to shifting distributions with limited data. Understanding how knowledge transfer (KD) can enable or speed up generalization under such constraints is practically important for deployed models.", "method": "1) Demonstrate KD from a grokked model on distribution p1 to induce/accelerate grokking on distribution p2 with data below the critical threshold. 2) Train on the joint distribution (p1, p2) and assess whether standard supervised training fails with insufficient data and whether KD from grokked models enables generalization. 3) Explore continual pretraining where a grokked model moves from p1 to p2 and evaluate whether KD mitigates catastrophic forgetting and improves performance with limited data (~10%).", "result": "KD can induce and accelerate grokking on a new distribution under low-data conditions. Distilling from grokked models enables generalization when training on the joint distribution would fail due to data gaps. In continual pretraining, KD both speeds up generalization and reduces forgetting, yielding strong performance with only 10% data.", "conclusion": "Knowledge Distillation is central to enabling generalization under low data and evolving distributions, offering practical strategies for adapting models via transfer learning when grokking is otherwise hard to observe or maintain."}}
{"id": "2511.05311", "categories": ["cs.AI", "cs.LG", "cs.RO", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.05311", "abs": "https://arxiv.org/abs/2511.05311", "authors": ["Valeriu Dimidov", "Faisal Hawlader", "Sasan Jafarnejad", "Rapha\u00ebl Frank"], "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance", "comment": null, "summary": "Economic constraints, limited availability of datasets for reproducibility\nand shortages of specialized expertise have long been recognized as key\nchallenges to the adoption and advancement of predictive maintenance (PdM) in\nthe automotive sector. Recent progress in large language models (LLMs) presents\nan opportunity to overcome these barriers and speed up the transition of PdM\nfrom research to industrial practice. Under these conditions, we explore the\npotential of LLM-based agents to support PdM cleaning pipelines. Specifically,\nwe focus on maintenance logs, a critical data source for training\nwell-performing machine learning (ML) models, but one often affected by errors\nsuch as typos, missing fields, near-duplicate entries, and incorrect dates. We\nevaluate LLM agents on cleaning tasks involving six distinct types of noise.\nOur findings show that LLMs are effective at handling generic cleaning tasks\nand offer a promising foundation for future industrial applications. While\ndomain-specific errors remain challenging, these results highlight the\npotential for further improvements through specialized training and enhanced\nagentic capabilities.", "AI": {"tldr": "LLM-based agents can effectively clean maintenance logs with common data quality issues, enabling PdM deployment; domain-specific errors still need targeted training.", "motivation": "Overcome economic constraints, data scarcity, and lack of specialized expertise hindering predictive maintenance (PdM) adoption in the automotive sector by leveraging LLMs to automate data cleaning in maintenance logs.", "method": "Evaluate LLM-based agents on cleaning tasks across six noise types in maintenance logs and assess performance and generalizability.", "result": "LLMs handle generic cleaning tasks effectively and show promise for industrial deployment; domain-specific errors remain challenging; improvements likely with domain-adapted training and enhanced agent capabilities.", "conclusion": "LLMs provide a promising foundation for PdM data cleaning, but practical deployment requires targeted, domain-adapted training to address domain-specific noise."}}
{"id": "2511.04837", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04837", "abs": "https://arxiv.org/abs/2511.04837", "authors": ["Cameron Robinson", "Ganghee Jang"], "title": "Design Exploration for Protection and Cleaning of Solar Panels with Case Studies for Space Missions", "comment": "4 pages, 3 figures (5 assets)", "summary": "Solar energy is used for many mission-critical applications including space\nexploration, sensor systems to monitor wildfires, etc. Their operation can be\nlimited or even terminated if solar panels are covered with dust or hit by\nspace debris. To address this issue, we designed panel cleaning mechanisms and\ntested protective materials. For cleaning mechanisms, we designed and compared\na wiper system and a rail system. For protective materials, we found through\ncollision tests that polycarbonate was very promising, though the most\nimportant factor was layering a soft material between the panel's surface and a\nhard material. In the cleaning system comparisons, the wiper-based system was\nmore efficient than the rail-based system in terms of cost, cleaning speed, and\ntotal power consumption.", "AI": {"tldr": "Design and evaluation of panel cleaning mechanisms and protective materials to keep solar panels operational under dust and debris; wiper cleaning outperforms rail cleaning; soft interlayer with polycarbonate is promising as protective strategy.", "motivation": "Solar panels in space and harsh terrestrial environments are at risk from dust, debris, and collision; maintaining performance is essential for mission-critical applications.", "method": "Compared two cleaning mechanisms (wiper vs rail) and tested protective materials via collision tests; assessed cost, cleaning speed, and total power consumption; found polycarbonate promising with a soft interlayer; emphasized interfacial layering as key.", "result": "Wiper-based cleaning system is more efficient than rail-based in cost, cleaning speed, and total power consumption. Polycarbonate emerges as a promising protective material, with the most important factor being a soft material layer between the panel surface and the hard material.", "conclusion": "Recommend wiper-based cleaning for efficiency and durability; adopt a protective strategy that includes a soft interlayer between hard materials and the panel surface to maximize protection against dust and debris."}}
{"id": "2511.04797", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04797", "abs": "https://arxiv.org/abs/2511.04797", "authors": ["Jim James", "Ben Wilson", "Simon Lucey", "James Hays"], "title": "3D Gaussian Point Encoders", "comment": "10 pages, 3 figures, 3 tables", "summary": "In this work, we introduce the 3D Gaussian Point Encoder, an explicit\nper-point embedding built on mixtures of learned 3D Gaussians. This explicit\ngeometric representation for 3D recognition tasks is a departure from widely\nused implicit representations such as PointNet. However, it is difficult to\nlearn 3D Gaussian encoders in end-to-end fashion with standard optimizers. We\ndevelop optimization techniques based on natural gradients and distillation\nfrom PointNets to find a Gaussian Basis that can reconstruct PointNet\nactivations. The resulting 3D Gaussian Point Encoders are faster and more\nparameter efficient than traditional PointNets. As in the 3D reconstruction\nliterature where there has been considerable interest in the move from implicit\n(e.g., NeRF) to explicit (e.g., Gaussian Splatting) representations, we can\ntake advantage of computational geometry heuristics to accelerate 3D Gaussian\nPoint Encoders further. We extend filtering techniques from 3D Gaussian\nSplatting to construct encoders that run 2.7 times faster as a comparable\naccuracy PointNet while using 46% less memory and 88% fewer FLOPs. Furthermore,\nwe demonstrate the effectiveness of 3D Gaussian Point Encoders as a component\nin Mamba3D, running 1.27 times faster and achieving a reduction in memory and\nFLOPs by 42% and 54% respectively. 3D Gaussian Point Encoders are lightweight\nenough to achieve high framerates on CPU-only devices.", "AI": {"tldr": "Introduces 3D Gaussian Point Encoders that use mixtures of learned 3D Gaussians as explicit per-point embeddings; achieves faster, more memory-efficient 3D recognition via end-to-end optimization with natural gradients and distillation from PointNet, plus acceleration for CPU deployment and integration into Mamba3D.", "motivation": "Explicit geometric representations can offer speed and memory advantages over implicit networks (e.g., PointNet) for 3D recognition; training Gaussian-based encoders end-to-end is challenging and requires novel optimization and distillation techniques.", "method": "Constructs per-point embeddings as mixtures of learned 3D Gaussians; optimizes them with natural gradients and distillation from PointNet activations to align Gaussian basis with PointNet representations; applies 3D Gaussian Splatting-inspired filtering/acceleration to speed up encoding; demonstrates scalability and CPU-friendly performance and integration into Mamba3D.", "result": "3D Gaussian Point Encoders are faster and more parameter-efficient than PointNets (2.7x faster at comparable accuracy, 46% less memory, 88% fewer FLOPs); in Mamba3D, 1.27x faster with 42% memory and 54% FLOPs reductions; capable of high framerates on CPU-only devices.", "conclusion": "Explicit Gaussian-based encoders are a viable, efficient alternative to implicit 3D networks for recognition tasks, enabling substantial speedups and broad CPU deployment, with effective integration into existing systems like Mamba3D."}}
{"id": "2511.04768", "categories": ["cs.LG", "cs.AR", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.04768", "abs": "https://arxiv.org/abs/2511.04768", "authors": ["Rubens Lacouture", "Nathan Zhang", "Ritvik Sharma", "Marco Siracusa", "Fredrik Kjolstad", "Kunle Olukotun", "Olivia Hsu"], "title": "FuseFlow: A Fusion-Centric Compilation Framework for Sparse Deep Learning on Streaming Dataflow", "comment": null, "summary": "As deep learning models scale, sparse computation and specialized dataflow\nhardware have emerged as powerful solutions to address efficiency. We propose\nFuseFlow, a compiler that converts sparse machine learning models written in\nPyTorch to fused sparse dataflow graphs for reconfigurable dataflow\narchitectures (RDAs). FuseFlow is the first compiler to support general\ncross-expression fusion of sparse operations. In addition to fusion across\nkernels (expressions), FuseFlow also supports optimizations like\nparallelization, dataflow ordering, and sparsity blocking. It targets a\ncycle-accurate dataflow simulator for microarchitectural analysis of fusion\nstrategies. We use FuseFlow for design-space exploration across four real-world\nmachine learning applications with sparsity, showing that full fusion (entire\ncross-expression fusion across all computation in an end-to-end model) is not\nalways optimal for sparse models-fusion granularity depends on the model\nitself. FuseFlow also provides a heuristic to identify and prune suboptimal\nconfigurations. Using Fuseflow, we achieve performance improvements, including\na ~2.7x speedup over an unfused baseline for GPT-3 with BigBird block-sparse\nattention.", "AI": {"tldr": "FuseFlow is a PyTorch-to-fused sparse dataflow compiler for reconfigurable dataflow architectures (RDAs). It enables cross-expression fusion of sparse operations, along with optimizations like parallelization, dataflow ordering, and sparsity blocking, and uses a cycle-accurate simulator for design-space exploration. Full cross-expression fusion is not always optimal; a heuristic helps prune suboptimal configurations. It reports up to ~2.7x speedup over unfused baselines on GPT-3 with BigBird block-sparse attention.", "motivation": "As sparse computation and specialized dataflow hardware rise in importance, there is a need for compilers that can fuse sparse operations across expressions and map them effectively to RDAs. The paper investigates how fusion granularity affects performance and provides tooling for exploration.", "method": "Introduce FuseFlow, a compiler that translates PyTorch models into fused sparse dataflow graphs for RDAs, supporting cross-expression fusion and optimizations (parallelization, dataflow ordering, sparsity blocking). It targets a cycle-accurate dataflow simulator to analyze fusion strategies and performs design-space exploration across four real-world sparsity-enabled ML apps, along with a heuristic to prune suboptimal configurations.", "result": "Demonstrates that full fusion across all computation is not universally optimal; fusion granularity should be chosen per model. Shows performance improvements, including about 2.7x speedup over an unfused baseline for GPT-3 with BigBird block-sparse attention.", "conclusion": "Fusion granularity is model-dependent; FuseFlow enables systematic exploration and optimization of fused sparse dataflow mappings on RDAs, achieving substantial speedups and guiding fusion strategy decisions."}}
{"id": "2511.05375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05375", "abs": "https://arxiv.org/abs/2511.05375", "authors": ["Sijie Yang", "Jiatong Li", "Filip Biljecki"], "title": "Reasoning Is All You Need for Urban Planning AI", "comment": "Submitted to AAAI 2026 Workshop AI4UP", "summary": "AI has proven highly successful at urban planning analysis -- learning\npatterns from data to predict future conditions. The next frontier is\nAI-assisted decision-making: agents that recommend sites, allocate resources,\nand evaluate trade-offs while reasoning transparently about constraints and\nstakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,\nReAct, and multi-agent collaboration frameworks -- now make this vision\nachievable.\n  This position paper presents the Agentic Urban Planning AI Framework for\nreasoning-capable planning agents that integrates three cognitive layers\n(Perception, Foundation, Reasoning) with six logic components (Analysis,\nGeneration, Verification, Evaluation, Collaboration, Decision) through a\nmulti-agents collaboration framework. We demonstrate why planning decisions\nrequire explicit reasoning capabilities that are value-based (applying\nnormative principles), rule-grounded (guaranteeing constraint satisfaction),\nand explainable (generating transparent justifications) -- requirements that\nstatistical learning alone cannot fulfill. We compare reasoning agents with\nstatistical learning, present a comprehensive architecture with benchmark\nevaluation metrics, and outline critical research challenges. This framework\nshows how AI agents can augment human planners by systematically exploring\nsolution spaces, verifying regulatory compliance, and deliberating over\ntrade-offs transparently -- not replacing human judgment but amplifying it with\ncomputational reasoning capabilities.", "AI": {"tldr": "Reasoning-capable urban planning agents: a three-layer (Perception, Foundation, Reasoning) and six-component (Analysis, Generation, Verification, Evaluation, Collaboration, Decision) architecture for AI-assisted planning, enhanced by multi-agent collaboration; aims for value-based, rule-grounded, explainable decisions that augment\u2014not replace\u2014human planners; outlines architecture, metrics, and challenges.", "motivation": "Current AI in urban planning is strong at pattern learning but lacks explicit, normative, and explainable reasoning aligned with constraints and stakeholder values. This framework seeks to move toward prescriptive, transparent AI agents that can justify decisions and collaborate with humans.", "method": "Proposes the Agentic Urban Planning AI Framework combining three cognitive layers and six logic components within a multi-agent collaboration setup. Builds on CoT prompting, ReAct, and multi-agent reasoning to enable explicit reasoning, constraint satisfaction, and trade-off deliberation. Includes architectural design, proposed benchmark metrics, and discussion of research challenges.", "result": "A conceptual, architecture-level framework (not an empirical study) with defined components, evaluation metrics, and a roadmap for implementing reasoning-enabled planning agents. Demonstrates how such agents can explore solution spaces, verify regulatory compliance, and transparently justify decisions.", "conclusion": "Reasoning-capable planning agents can amplify human planning judgment by providing normative, rule-grounded, and explainable deliberations. They aim to augment, not replace, human planners by enhancing exploration, verification, and transparent justification of trade-offs."}}
{"id": "2511.04976", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04976", "abs": "https://arxiv.org/abs/2511.04976", "authors": ["Xin Nie", "Zhiyuan Cheng", "Yuan Zhang", "Chao Ji", "Jiajia Wu", "Yuhan Zhang", "Jia Pan"], "title": "iFlyBot-VLM Technical Report", "comment": null, "summary": "We introduce iFlyBot-VLM, a general-purpose Vision-Language Model (VLM) used\nto improve the domain of Embodied Intelligence. The central objective of\niFlyBot-VLM is to bridge the cross-modal semantic gap between high-dimensional\nenvironmental perception and low-level robotic motion control. To this end, the\nmodel abstracts complex visual and spatial information into a body-agnostic and\ntransferable Operational Language, thereby enabling seamless perception-action\nclosed-loop coordination across diverse robotic platforms. The architecture of\niFlyBot-VLM is systematically designed to realize four key functional\ncapabilities essential for embodied intelligence: 1) Spatial Understanding and\nMetric Reasoning; 2) Interactive Target Grounding; 3) Action Abstraction and\nControl Parameter Generation; 4) Task Planning and Skill Sequencing. We\nenvision iFlyBot-VLM as a scalable and generalizable foundation model for\nembodied AI, facilitating the progression from specialized task-oriented\nsystems toward generalist, cognitively capable agents. We conducted evaluations\non 10 current mainstream embodied intelligence-related VLM benchmark datasets,\nsuch as Blink and Where2Place, and achieved optimal performance while\npreserving the model's general capabilities. We will publicly release both the\ntraining data and model weights to foster further research and development in\nthe field of Embodied Intelligence.", "AI": {"tldr": "Introduces iFlyBot-VLM, a general-purpose Vision-Language Model for Embodied Intelligence that bridges perception and robotic control via a transferable Operational Language, enabling four core capabilities, evaluated on 10 mainstream VLM benchmarks with claimed optimal performance, and plans public release of data and weights.", "motivation": "Bridge the semantic gap between high-dimensional environmental perception and low-level robotic motion control, enabling seamless perception-action loops across diverse robotic platforms and moving toward a generalist embodied AI foundation.", "method": "Proposes four capabilities: (1) Spatial Understanding and Metric Reasoning; (2) Interactive Target Grounding; (3) Action Abstraction and Control Parameter Generation; (4) Task Planning and Skill Sequencing. Develops a body-agnostic, transferable Operational Language to unify perception-action. Evaluates on 10 mainstream embodied-intelligence VLM benchmarks (e.g., Blink, Where2Place) and intends to publicly release training data and model weights.", "result": "Reported optimal performance on the evaluated benchmarks while preserving the model\u2019s general capabilities, suggesting strong cross-domain generalization and robust perception-action coordination.", "conclusion": "iFlyBot-VLM is positioned as a scalable, generalizable foundation model for embodied AI, aiming to replace task-specific systems with cognitively capable, generalist agents. Public release of data and weights is planned to advance research in the field."}}
{"id": "2511.04803", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2.10; I.4.6"], "pdf": "https://arxiv.org/pdf/2511.04803", "abs": "https://arxiv.org/abs/2511.04803", "authors": ["Shuo Zhao", "Jianxu Chen"], "title": "Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose", "comment": "Accepted to IEEE BIBM 2025 Workshop; 6 pages; 4 figures; 5 tables;\n  IEEEtran class. Code: https://github.com/MMV-Lab/biomedseg-efficiency", "summary": "Generalist biomedical image segmentation models such as Cellpose are\nincreasingly applied across diverse imaging modalities and cell types. However,\ntwo critical challenges remain underexplored: (1) the extent of training data\nredundancy and (2) the impact of cross domain transfer on model retention. In\nthis study, we conduct a systematic empirical analysis of these challenges\nusing Cellpose as a case study. First, to assess data redundancy, we propose a\nsimple dataset quantization (DQ) strategy for constructing compact yet diverse\ntraining subsets. Experiments on the Cyto dataset show that image segmentation\nperformance saturates with only 10% of the data, revealing substantial\nredundancy and potential for training with minimal annotations. Latent space\nanalysis using MAE embeddings and t-SNE confirms that DQ selected patches\ncapture greater feature diversity than random sampling. Second, to examine\ncatastrophic forgetting, we perform cross domain finetuning experiments and\nobserve significant degradation in source domain performance, particularly when\nadapting from generalist to specialist domains. We demonstrate that selective\nDQ based replay reintroducing just 5-10% of the source data effectively\nrestores source performance, while full replay can hinder target adaptation.\nAdditionally, we find that training domain sequencing improves generalization\nand reduces forgetting in multi stage transfer. Our findings highlight the\nimportance of data centric design in biomedical image segmentation and suggest\nthat efficient training requires not only compact subsets but also retention\naware learning strategies and informed domain ordering. The code is available\nat https://github.com/MMV-Lab/biomedseg-efficiency.", "AI": {"tldr": "Data-centric compression enables training with small yet diverse subsets; selective replay mitigates forgetting; domain sequencing aids cross-domain generalization in Cellpose.", "motivation": "Investigate data redundancy and cross-domain forgetting in generalist biomedical segmentation to improve data efficiency and retention-aware transfer.", "method": "Introduce dataset quantization (DQ) to select compact diverse subsets; validate via MAE embeddings and t-SNE; conduct cross-domain finetuning with and without replay; evaluate multi-stage domain sequencing; apply across Cyto dataset using Cellpose.", "result": "Segmentation saturates at ~10% data; DQ subsets capture greater feature diversity; cross-domain transfer causes significant forgetting; selective 5-10% source replay restores performance and can aid adaptation; full replay can hamper; domain sequencing improves generalization and reduces forgetting; code released.", "conclusion": "Data-centric strategies and retention-aware learning are crucial for efficient and robust cross-domain biomedical segmentation; proper domain ordering and replay policies can reduce forgetting while enabling adaptation."}}
{"id": "2511.04774", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.04774", "abs": "https://arxiv.org/abs/2511.04774", "authors": ["Liu Jiang", "Zerui Bao", "Shiqi Sheng", "Di Zhu"], "title": "SLOFetch: Compressed-Hierarchical Instruction Prefetching for Cloud Microservices", "comment": null, "summary": "Large-scale networked services rely on deep soft-ware stacks and microservice\norchestration, which increase instruction footprints and create frontend stalls\nthat inflate tail latency and energy. We revisit instruction prefetching for\nthese cloud workloads and present a design that aligns with SLO driven and self\noptimizing systems. Building on the Entangling Instruction Prefetcher (EIP), we\nintroduce a Compressed Entry that captures up to eight destinations around a\nbase using 36 bits by exploiting spatial clustering, and a Hierarchical\nMetadata Storage scheme that keeps only L1 resident and frequently queried\nentries on chip while virtualizing bulk metadata into lower levels. We further\nadd a lightweight Online ML Controller that scores prefetch profitability using\ncontext features and a bandit adjusted threshold. On data center applications,\nour approach preserves EIP like speedups with smaller on chip state and\nimproves efficiency for networked services in the ML era.", "AI": {"tldr": "A scalable, ML-guided instruction prefetching extension to EIP that compresses metadata, uses hierarchical on-chip/off-chip storage, and adapts prefetch decisions to SLO-driven cloud workloads, preserving speedups with reduced on-chip state.", "motivation": "Cloud-scale services with deep software stacks and microservice orchestration increase instruction footprints, frontend stalls, tail latency, and energy; there is a need for adaptive, low-overhead prefetching that aligns with SLOs and ML-era workloads.", "method": "Extend Entangling Instruction Prefetcher (EIP) with a Compressed Entry (up to eight destinations around a base using 36 bits) exploiting spatial clustering; implement Hierarchical Metadata Storage to keep L1-resident, frequently queried entries on-chip while virtualizing bulk metadata to lower levels; add a lightweight Online ML Controller to score prefetch profitability using context features and a bandit-adjusted threshold.", "result": "Data center applications maintain EIP-like speedups while reducing on-chip state; improved efficiency for networked services in ML-era workloads.", "conclusion": "The proposed combination enables fast, adaptive prefetching with lower on-chip state and improved efficiency under SLO-driven, self-optimizing cloud environments, aligning prefetching with ML-era workloads."}}
{"id": "2511.04992", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04992", "abs": "https://arxiv.org/abs/2511.04992", "authors": ["Bibekananda Patra", "Sandipan Bandyopadhyay"], "title": "A semi-analytical approach for computing the largest singularity-free spheres of a class of 6-6 Stewart-Gough platforms for specified orientation workspaces", "comment": null, "summary": "This article presents a method for computing the largest singularity-free\nsphere (SFS) of a 6-6 Stewart-Gough platform manipulator (SGPM) over a\nspecified orientation workspace. For a fixed orientation of the moving\nplatform, the SFS is computed analytically. This process is repeated over a set\nof samples generated within the orientation workspace, and the smallest among\nthem is designated as the desired SFS for the given orientation workspace.\nNumerical experiments are performed on four distinct architectures of the SGPM\nto understand their relative performances w.r.t. SFS volumes over the same\norientation workspace. This study demonstrates the potential utility of the\nproposed computational method both in analysis and design of SGPMs.", "AI": {"tldr": "Analytical-per-orientation method to compute the largest singularity-free sphere (SFS) for a 6-6 Stewart-Gough platform under a fixed orientation, with sampling over the orientation workspace and comparison across four SGPM architectures.", "motivation": "Singularities constrain motion in parallel manipulators; quantifying safe operating regions via the SFS helps in analysis and design; comparing architectures informs design choices for larger singularity-free volumes.", "method": "For a fixed moving-platform orientation, compute the SFS analytically. Repeat across a set of orientation samples in the workspace and designate the smallest SFS as the SFS for that orientation workspace. Perform numerical experiments on four SGPM architectures to compare their SFS volumes within the same orientation workspace.", "result": "The method yields comparative SFS volumes across four SGPM architectures, illustrating the utility of the approach for analysis and design, though specific numerical results are not provided in the abstract.", "conclusion": "The proposed computational method offers a practical tool to evaluate and guide SGPM design by characterizing singularity-free regions across orientations."}}
{"id": "2511.04811", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T07, 68U10", "I.2.10; I.4.6; J.3"], "pdf": "https://arxiv.org/pdf/2511.04811", "abs": "https://arxiv.org/abs/2511.04811", "authors": ["Shuo Zhao", "Yu Zhou", "Jianxu Chen"], "title": "An Active Learning Pipeline for Biomedical Image Instance Segmentation with Minimal Human Intervention", "comment": "6 pages, 4 figures, presented at Bildverarbeitung f\\\"ur die Medizin\n  (BVM) 2025, Wiesbaden, Germany", "summary": "Biomedical image segmentation is critical for precise structure delineation\nand downstream analysis. Traditional methods often struggle with noisy data,\nwhile deep learning models such as U-Net have set new benchmarks in\nsegmentation performance. nnU-Net further automates model configuration, making\nit adaptable across datasets without extensive tuning. However, it requires a\nsubstantial amount of annotated data for cross-validation, posing a challenge\nwhen only raw images but no labels are available. Large foundation models offer\nzero-shot generalizability, but may underperform on specific datasets with\nunique characteristics, limiting their direct use for analysis. This work\naddresses these bottlenecks by proposing a data-centric AI workflow that\nleverages active learning and pseudo-labeling to combine the strengths of\ntraditional neural networks and large foundation models while minimizing human\nintervention. The pipeline starts by generating pseudo-labels from a foundation\nmodel, which are then used for nnU-Net's self-configuration. Subsequently, a\nrepresentative core-set is selected for minimal manual annotation, enabling\neffective fine-tuning of the nnU-Net model. This approach significantly reduces\nthe need for manual annotations while maintaining competitive performance,\nproviding an accessible solution for biomedical researchers to apply\nstate-of-the-art AI techniques in their segmentation tasks. The code is\navailable at https://github.com/MMV-Lab/AL_BioMed_img_seg.", "AI": {"tldr": "A data-centric AI pipeline combines foundation-model pseudo-labels with nnU-Net, using core-set active learning to minimize manual labeling while preserving segmentation performance.", "motivation": "nnU-Net automates model configuration but needs large annotated datasets; foundation models offer zero-shot generalization but may underperform on data with unique characteristics; there is a need to reduce human labeling while leveraging both traditional and foundation-model strengths.", "method": "Generate pseudo-labels with a foundation model, use them to drive nnU-Net self-configuration, then select a representative core-set for minimal manual annotation to fine-tune nnU-Net; employs an active-learning loop to balance labeling effort and model performance.", "result": "The approach reduces manual annotation requirements while maintaining competitive segmentation performance and makes state-of-the-art AI techniques more accessible to biomedical researchers; code is available at the stated GitHub repository.", "conclusion": "A data-centric workflow that fuses foundation-model guidance with traditional segmentation networks via active learning can mitigate labeling needs and broaden applicability of advanced AI in biomedical image segmentation."}}
{"id": "2511.04789", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04789", "abs": "https://arxiv.org/abs/2511.04789", "authors": ["Xiaoda Wang", "Yuji Zhao", "Kaiqiao Han", "Xiao Luo", "Sanne van Rooij", "Jennifer Stevens", "Lifang He", "Liang Zhan", "Yizhou Sun", "Wei Wang", "Carl Yang"], "title": "Conditional Neural ODE for Longitudinal Parkinson's Disease Progression Forecasting", "comment": "Accepted to IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM) 2025", "summary": "Parkinson's disease (PD) shows heterogeneous, evolving brain-morphometry\npatterns. Modeling these longitudinal trajectories enables mechanistic insight,\ntreatment development, and individualized 'digital-twin' forecasting. However,\nexisting methods usually adopt recurrent neural networks and transformer\narchitectures, which rely on discrete, regularly sampled data while struggling\nto handle irregular and sparse magnetic resonance imaging (MRI) in PD cohorts.\nMoreover, these methods have difficulty capturing individual heterogeneity\nincluding variations in disease onset, progression rate, and symptom severity,\nwhich is a hallmark of PD. To address these challenges, we propose CNODE\n(Conditional Neural ODE), a novel framework for continuous, individualized PD\nprogression forecasting. The core of CNODE is to model morphological brain\nchanges as continuous temporal processes using a neural ODE model. In addition,\nwe jointly learn patient-specific initial time and progress speed to align\nindividual trajectories into a shared progression trajectory. We validate CNODE\non the Parkinson's Progression Markers Initiative (PPMI) dataset. Experimental\nresults show that our method outperforms state-of-the-art baselines in\nforecasting longitudinal PD progression.", "AI": {"tldr": "CNODE uses conditional neural ODEs to model continuous PD brain morphometry trajectories, aligning patient-specific timelines to a shared progression path, and outperforms baselines on the PPMI dataset.", "motivation": "PD exhibits heterogeneous, evolving brain-morphometry with irregular and sparse MRI data; traditional RNN/Transformer models struggle to handle irregular sampling and individual heterogeneity, limiting mechanistic understanding and forecasting.", "method": "A continuous-time neural ODE framework that models morphological brain changes as a continuous process; jointly learns patient-specific initial time and progression speed to align individual trajectories into a shared progression trajectory; validated on the PPMI dataset.", "result": "CNODE outperforms state-of-the-art baselines in forecasting longitudinal PD progression on the PPMI dataset.", "conclusion": "CNODE enables more accurate, continuous-time forecasting of PD progression, addressing irregular sampling and heterogeneity, with potential for mechanistic insight and digital-twin applications."}}
{"id": "2511.04994", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.04994", "abs": "https://arxiv.org/abs/2511.04994", "authors": ["Xingyuan Zhou", "Peter Paik", "S. Farokh Atashzar"], "title": "Encoding Biomechanical Energy Margin into Passivity-based Synchronization for Networked Telerobotic Systems", "comment": null, "summary": "Maintaining system stability and accurate position tracking is imperative in\nnetworked robotic systems, particularly for haptics-enabled human-robot\ninteraction. Recent literature has integrated human biomechanics into the\nstabilizers implemented for teleoperation, enhancing force preservation while\nguaranteeing convergence and safety. However, position desynchronization due to\nimperfect communication and non-passive behaviors remains a challenge. This\npaper proposes a two-port biomechanics-aware passivity-based synchronizer and\nstabilizer, referred to as TBPS2. This stabilizer optimizes position\nsynchronization by leveraging human biomechanics while reducing the\nstabilizer's conservatism in its activation. We provide the mathematical design\nsynthesis of the stabilizer and the proof of stability. We also conducted a\nseries of grid simulations and systematic experiments, comparing their\nperformance with that of state-of-the-art solutions under varying time delays\nand environmental conditions.", "AI": {"tldr": "TBPS2 offers a biomechanics-aware, two-port passivity-based stabilizer to improve position synchronization in networked haptic teleoperation, reducing conservatism while ensuring stability; validated via simulations and experiments under various delays and conditions.", "motivation": "Maintain system stability and accurate position tracking in networked robotic/haptic systems, addressing desynchronization caused by imperfect communication and non-passive behaviors, by integrating human biomechanics into stabilizers.", "method": "Propose TBPS2: a two-port biomechanics-aware passivity-based synchronizer and stabilizer. Provide mathematical design synthesis and a stability proof. Validate through grid simulations and systematic experiments, comparing against state-of-the-art under varying time delays and environmental conditions.", "result": "TBPS2 optimizes position synchronization and reduces conservatism in stabilization activation. The design is proven stable, and simulations/experiments show favorable performance compared with state-of-the-art under delayed and diverse conditions.", "conclusion": "TBPS2 advances biomechanics-aware stability in teleoperation by combining a two-port passivity-based framework with reduced activation conservatism, with theoretical guarantees and empirical validation across delays and environments."}}
{"id": "2511.04848", "categories": ["cs.CV", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.04848", "abs": "https://arxiv.org/abs/2511.04848", "authors": ["Manuel Wei\u00df", "Lukas Baumg\u00e4rtner", "Roland Herzog", "Stephan Schmidt"], "title": "Geometry Denoising with Preferred Normal Vectors", "comment": null, "summary": "We introduce a new paradigm for geometry denoising using prior knowledge\nabout the surface normal vector. This prior knowledge comes in the form of a\nset of preferred normal vectors, which we refer to as label vectors. A\nsegmentation problem is naturally embedded in the denoising process. The\nsegmentation is based on the similarity of the normal vector to the elements of\nthe set of label vectors. Regularization is achieved by a total variation term.\nWe formulate a split Bregman (ADMM) approach to solve the resulting\noptimization problem. The vertex update step is based on second-order shape\ncalculus.", "AI": {"tldr": "A geometry denoising framework that uses prior surface normals (label vectors) to drive joint denoising and segmentation, regularized by total variation, solved via split Bregman (ADMM), with vertex updates via second-order shape calculus.", "motivation": "To leverage prior knowledge of surface normals to improve denoising quality and simultaneously perform segmentation by classifying normals relative to a predefined set of label vectors.", "method": "Introduce label vectors as prior normal directions; embed segmentation by normal-vector similarity to these labels; apply total variation regularization; solve the resulting optimization with a split Bregman / ADMM approach; update vertex positions using second-order shape calculus.", "result": "The abstract presents the formulation and algorithm, but does not report empirical results; it demonstrates a principled framework for joint denoising and segmentation with a novel optimization approach.", "conclusion": "Proposes a new paradigm for geometry denoising using normal-label priors, integrated segmentation, and a tractable solver; future work likely includes empirical validation and comparison with existing methods."}}
{"id": "2511.04790", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.04790", "abs": "https://arxiv.org/abs/2511.04790", "authors": ["Caroline Uhler", "Jiaqi Zhang"], "title": "Causal Structure and Representation Learning with Biomedical Applications", "comment": "This article has successfully completed peer review and will appear\n  in the Proceedings of the International Congress of Mathematicians 2026. Both\n  authors contributed equally to this work", "summary": "Massive data collection holds the promise of a better understanding of\ncomplex phenomena and, ultimately, better decisions. Representation learning\nhas become a key driver of deep learning applications, as it allows learning\nlatent spaces that capture important properties of the data without requiring\nany supervised annotations. Although representation learning has been hugely\nsuccessful in predictive tasks, it can fail miserably in causal tasks including\npredicting the effect of a perturbation/intervention. This calls for a marriage\nbetween representation learning and causal inference. An exciting opportunity\nin this regard stems from the growing availability of multi-modal data\n(observational and perturbational, imaging-based and sequencing-based, at the\nsingle-cell level, tissue-level, and organism-level). We outline a statistical\nand computational framework for causal structure and representation learning\nmotivated by fundamental biomedical questions: how to effectively use\nobservational and perturbational data to perform causal discovery on observed\ncausal variables; how to use multi-modal views of the system to learn causal\nvariables; and how to design optimal perturbations.", "AI": {"tldr": "A framework integrating representation learning with causal inference to leverage multi-modal observational and perturbational data for causal discovery, learning causal representations, and designing perturbations in biomedical contexts.", "motivation": "Prediction-focused representation learning often fails for causal tasks; there is a need for causal-aware representations and strategies to combine observational and perturbational data across modalities to uncover true causal structure.", "method": "A statistical and computational framework that couples representation learning with causal inference to (i) perform causal discovery on observed causal variables using observational and perturbational data, (ii) learn causal variables from multi-modal views, and (iii) design optimal perturbations.", "result": "Conceptual framework; outlines methodological pathways and potential applications without reporting empirical results in the abstract.", "conclusion": "The proposed framework aims to integrate multi-modal data, representation learning, and causal inference to enable causal discovery and perturbation design in biomedical contexts."}}
{"id": "2511.05007", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05007", "abs": "https://arxiv.org/abs/2511.05007", "authors": ["Baiye Cheng", "Tianhai Liang", "Suning Huang", "Maanping Shao", "Feihong Zhang", "Botian Xu", "Zhengrong Xue", "Huazhe Xu"], "title": "MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery", "comment": null, "summary": "Diffusion policies have emerged as a powerful framework for robotic\nvisuomotor control, yet they often lack the robustness to recover from subtask\nfailures in long-horizon, multi-stage tasks and their learned representations\nof observations are often difficult to interpret. In this work, we propose the\nMixture of Experts-Enhanced Diffusion Policy (MoE-DP), where the core idea is\nto insert a Mixture of Experts (MoE) layer between the visual encoder and the\ndiffusion model. This layer decomposes the policy's knowledge into a set of\nspecialized experts, which are dynamically activated to handle different phases\nof a task. We demonstrate through extensive experiments that MoE-DP exhibits a\nstrong capability to recover from disturbances, significantly outperforming\nstandard baselines in robustness. On a suite of 6 long-horizon simulation\ntasks, this leads to a 36% average relative improvement in success rate under\ndisturbed conditions. This enhanced robustness is further validated in the real\nworld, where MoE-DP also shows significant performance gains. We further show\nthat MoE-DP learns an interpretable skill decomposition, where distinct experts\ncorrespond to semantic task primitives (e.g., approaching, grasping). This\nlearned structure can be leveraged for inference-time control, allowing for the\nrearrangement of subtasks without any re-training.Our video and code are\navailable at the https://moe-dp-website.github.io/MoE-DP-Website/.", "AI": {"tldr": "Mixture of Experts-Enhanced Diffusion Policy (MoE-DP) inserts a Mixture of Experts layer between the visual encoder and the diffusion policy to obtain robust, interpretable visuomotor control. Dynamic experts handle different task phases; achieves robustness gains and interpretable skill decomposition; 6 long-horizon tasks show 36% relative success improvement under disturbances; validated in real world; enables inference-time subtask rearrangement without retraining; code/video available.", "motivation": "Long-horizon visuomotor tasks suffer from subtask failures and brittle representations; need robust recovery and interpretable, modular policy components.", "method": "Introduce a MoE layer between visual encoder and diffusion model, with multiple specialized experts activated dynamically to cover different task phases; train to decompose policy knowledge into experts; evaluate robustness and interpretability; compare with baselines.", "result": "36% average relative improvement in success rate under disturbed conditions across 6 simulation tasks; real-world validation; interpretable skill decomposition where experts align with semantic primitives (e.g., approaching, grasping); inference-time control by rearranging subtasks without retraining.", "conclusion": "MoE-DP improves robustness and interpretability in diffusion-based visuomotor policies; modular expert decomposition enables flexible, disturbance-resilient control and reordering of subtasks without re-training; results supported by sim and real-world experiments; code/video available."}}
{"id": "2511.04864", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04864", "abs": "https://arxiv.org/abs/2511.04864", "authors": ["Kyle Fogarty", "Chenyue Cai", "Jing Yang", "Zhilin Guo", "Cengiz \u00d6ztireli"], "title": "Self-Supervised Implicit Attention Priors for Point Cloud Reconstruction", "comment": "Accepted at 3DV 2026", "summary": "Recovering high-quality surfaces from irregular point cloud is ill-posed\nunless strong geometric priors are available. We introduce an implicit\nself-prior approach that distills a shape-specific prior directly from the\ninput point cloud itself and embeds it within an implicit neural\nrepresentation. This is achieved by jointly training a small dictionary of\nlearnable embeddings with an implicit distance field; at every query location,\nthe field attends to the dictionary via cross-attention, enabling the network\nto capture and reuse repeating structures and long-range correlations inherent\nto the shape. Optimized solely with self-supervised point cloud reconstruction\nlosses, our approach requires no external training data. To effectively\nintegrate this learned prior while preserving input fidelity, the trained field\nis then sampled to extract densely distributed points and analytic normals via\nautomatic differentiation. We integrate the resulting dense point cloud and\ncorresponding normals into a robust implicit moving least squares (RIMLS)\nformulation. We show this hybrid strategy preserves fine geometric details in\nthe input data, while leveraging the learned prior to regularize sparse\nregions. Experiments show that our method outperforms both classical and\nlearning-based approaches in generating high-fidelity surfaces with superior\ndetail preservation and robustness to common data degradations.", "AI": {"tldr": "Unsupervised implicit self-prior for surface reconstruction from irregular point clouds using a dictionary-augmented implicit field and RIMLS.", "motivation": "Reconstructing high-quality surfaces from sparse/noisy/irregular point clouds is ill-posed without priors; propose self-derived priors to regularize reconstruction.", "method": "Train a small dictionary of learnable embeddings jointly with an implicit distance field. At each query location, cross-attention to dictionary; use self-supervised losses to learn the prior from the input data alone; sample the trained field to obtain dense points and analytic normals via automatic differentiation; integrate into a robust implicit moving least squares (RIMLS) framework for final surface extraction.", "result": "Outperforms classical and learning-based methods in fidelity and detail preservation; robust to common data degradations; captures repeating structures and long-range correlations; requires no external training data.", "conclusion": "A self-derived, dictionary-augmented implicit prior paired with RIMLS yields high-fidelity surfaces from irregular point clouds, preserving fine geometry while regularizing sparse regions without relying on external datasets."}}
{"id": "2511.04791", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04791", "abs": "https://arxiv.org/abs/2511.04791", "authors": ["Lei Gao", "Chaoyi Jiang", "Hossein Entezari Zarch", "Daniel Wong", "Murali Annavaram"], "title": "DuetServe: Harmonizing Prefill and Decode for LLM Serving via Adaptive GPU Multiplexing", "comment": null, "summary": "Modern LLM serving systems must sustain high throughput while meeting strict\nlatency SLOs across two distinct inference phases: compute-intensive prefill\nand memory-bound decode phases. Existing approaches either (1) aggregate both\nphases on shared GPUs, leading to interference between prefill and decode\nphases, which degrades time-between-tokens (TBT); or (2) disaggregate the two\nphases across GPUs, improving latency but wasting resources through duplicated\nmodels and KV cache transfers. We present DuetServe, a unified LLM serving\nframework that achieves disaggregation-level isolation within a single GPU.\nDuetServe operates in aggregated mode by default and dynamically activates\nSM-level GPU spatial multiplexing when TBT degradation is predicted. Its key\nidea is to decouple prefill and decode execution only when needed through\nfine-grained, adaptive SM partitioning that provides phase isolation only when\ncontention threatens latency service level objectives (SLOs). DuetServe\nintegrates (1) an attention-aware roofline model to forecast iteration latency,\n(2) a partitioning optimizer that selects the optimal SM split to maximize\nthroughput under TBT constraints, and (3) an interruption-free execution engine\nthat eliminates CPU-GPU synchronization overhead. Evaluations show that\nDuetServe improves total throughput by up to 1.3x while maintaining low\ngeneration latency compared to state-of-the-art frameworks.", "AI": {"tldr": "DuetServe is a unified LLM serving framework that achieves disaggregation-like isolation inside a single GPU by adaptively partitioning SMs to separate prefill and decode when contention threatens latency, yielding up to 1.3x throughput with low latency.", "motivation": "Existing approaches either run prefill and decode on shared GPUs (causing interference and degraded TBT) or fully disaggregate across GPUs (wasting resources). There is a need for high-throughput LLM serving that maintains strict latency SLOs without incurring cross-GPU costs.", "method": "Operate in aggregated mode by default and dynamically activate SM-level spatial multiplexing when TBT degradation is predicted. Decouple prefill and decode only when needed via fine-grained adaptive SM partitioning that provides phase isolation under contention. Components include (1) an attention-aware roofline model to forecast iteration latency, (2) a partitioning optimizer to select the optimal SM split to maximize throughput under TBT constraints, and (3) an interruption-free execution engine that eliminates CPU-GPU synchronization overhead.", "result": "Evaluations show DuetServe improves total throughput by up to 1.3x while maintaining low generation latency compared to state-of-the-art frameworks.", "conclusion": "DuetServe demonstrates that adaptive, fine-grained GPU partitioning can achieve near-disaggregated isolation within a single GPU, balancing throughput and latency without the overhead of full cross-GPU disaggregation."}}
{"id": "2511.05026", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05026", "abs": "https://arxiv.org/abs/2511.05026", "authors": ["Xingyuan Zhou", "Peter Paik", "S. Farokh Atashzar"], "title": "Tunable Passivity Control for Centralized Multiport Networked Systems", "comment": null, "summary": "Centralized Multiport Networked Dynamic (CMND) systems have emerged as a key\narchitecture with applications in several complex network systems, such as\nmultilateral telerobotics and multi-agent control. These systems consist of a\nhub node/subsystem connecting with multiple remote nodes/subsystems via a\nnetworked architecture. One challenge for this system is stability, which can\nbe affected by non-ideal network artifacts. Conventional passivity-based\napproaches can stabilize the system under specialized applications like\nsmall-scale networked systems. However, those conventional passive stabilizers\nhave several restrictions, such as distributing compensation across subsystems\nin a decentralized manner, limiting flexibility, and, at the same time, relying\non the restrictive assumptions of node passivity. This paper synthesizes a\ncentralized optimal passivity-based stabilization framework for CMND systems.\nIt consists of a centralized passivity observer monitoring overall energy flow\nand an optimal passivity controller that distributes the just-needed\ndissipation among various nodes, guaranteeing strict passivity and, thus, L2\nstability. The proposed data-driven model-free approach, i.e., Tunable\nCentralized Optimal Passivity Control (TCoPC), optimizes total performance\nbased on the prescribed dissipation distribution strategy while ensuring\nstability. The controller can put high dissipation loads on some sub-networks\nwhile relaxing the dissipation on other nodes. Simulation results demonstrate\nthe proposed frameworks performance in a complex task under different\ntime-varying delay scenarios while relaxing the remote nodes minimum phase and\npassivity assumption, enhancing the scalability and generalizability.", "AI": {"tldr": "A centralized, data-driven passivity-based stabilization framework for CMND systems, introducing Tunable Centralized Optimal Passivity Control (TCoPC) with a centralized passivity observer to distribute dissipation and ensure L2 stability under time-varying delays, relaxing node passivity assumptions and improving scalability.", "motivation": "Stability of Centralized Multiport Networked Dynamic (CMND) systems with network-induced artifacts; limitations of conventional distributed passive controllers; need for centralized, optimal, model-free stabilization to guarantee strict passivity and scalability.", "method": "Combine a centralized passivity observer with a tunable centralized optimal passivity controller (TCoPC). The controller optimizes dissipation distribution across sub-nets in a data-driven, model-free manner to guarantee strict passivity and L2 stability, even with time-varying delays and relaxed node-passivity requirements.", "result": "Simulation results show effective stabilization and performance under varying delays, with flexibility in dissipation allocation and improved scalability and generalizability while relaxing minimum-phase and passivity assumptions.", "conclusion": "The proposed TCoPC framework provides a centralized, data-driven route to guarantee strict passivity and L2 stability for CMND systems, enabling flexible dissipation distribution, robustness to delays, and enhanced scalability across complex networked dynamics."}}
{"id": "2511.04871", "categories": ["cs.CV", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.04871", "abs": "https://arxiv.org/abs/2511.04871", "authors": ["Gabriel Girard", "Manon Edde", "F\u00e9lix Dumais", "Yoan David", "Matthieu Dumont", "Guillaume Theaud", "Jean-Christophe Houde", "Arnaud Bor\u00e9", "Maxime Descoteaux", "Pierre-Marc Jodoin"], "title": "Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications", "comment": "39 pages, 11 figures", "summary": "Diffusion-weighted magnetic resonance imaging (DW-MRI) derived scalar maps\nare effective for assessing neurodegenerative diseases and microstructural\nproperties of white matter in large number of brain conditions. However, DW-MRI\ninherently limits the combination of data from multiple acquisition sites\nwithout harmonization to mitigate scanner-specific biases. While the widely\nused ComBAT method reduces site effects in research, its reliance on linear\ncovariate relationships, homogeneous populations, fixed site numbers, and well\npopulated sites constrains its clinical use. To overcome these limitations, we\npropose Clinical-ComBAT, a method designed for real-world clinical scenarios.\nClinical-ComBAT harmonizes each site independently, enabling flexibility as new\ndata and clinics are introduced. It incorporates a non-linear polynomial data\nmodel, site-specific harmonization referenced to a normative site, and variance\npriors adaptable to small cohorts. It further includes hyperparameter tuning\nand a goodness-of-fit metric for harmonization assessment. We demonstrate its\neffectiveness on simulated and real data, showing improved alignment of\ndiffusion metrics and enhanced applicability for normative modeling.", "AI": {"tldr": "Clinical-ComBAT is a flexible, site-specific, non-linear harmonization method for diffusion-weighted MRI that enables incremental integration of new clinics, improving cross-site alignment and enabling normative modeling beyond traditional ComBAT.", "motivation": "To overcome ComBAT's limitations in real-world clinical multi-site DW-MRI studies, including linear covariate assumptions, homogeneous populations, fixed site counts, and poorly populated sites, by providing a scalable, non-linear, site-referenced harmonization approach suitable for growing clinical data.", "method": "Harmonize each site independently using a non-linear polynomial data model with site-specific harmonization referenced to a normative site; incorporate variance priors that adapt to small cohorts; include hyperparameter tuning and a goodness-of-fit metric; applicable to simulated and real data to support normative modeling.", "result": "Showed improved alignment of diffusion metrics across sites and enhanced applicability for normative modeling in both simulated and real datasets.", "conclusion": "Clinical-ComBAT offers a practical, flexible solution for multi-site DW-MRI harmonization in clinical settings, enabling incremental data integration and better cross-site comparability, with potential to support normative analyses."}}
{"id": "2511.04804", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04804", "abs": "https://arxiv.org/abs/2511.04804", "authors": ["Chaymae Yahyati", "Ismail Lamaakal", "Khalid El Makkaoui", "Ibrahim Ouahbi", "Yassine Maleh"], "title": "Simplex-FEM Networks (SiFEN): Learning A Triangulated Function Approximator", "comment": null, "summary": "We introduce Simplex-FEM Networks (SiFEN), a learned piecewise-polynomial\npredictor that represents f: R^d -> R^k as a globally C^r finite-element field\non a learned simplicial mesh in an optionally warped input space. Each query\nactivates exactly one simplex and at most d+1 basis functions via barycentric\ncoordinates, yielding explicit locality, controllable smoothness, and\ncache-friendly sparsity. SiFEN pairs degree-m Bernstein-Bezier polynomials with\na light invertible warp and trains end-to-end with shape regularization,\nsemi-discrete OT coverage, and differentiable edge flips. Under standard\nshape-regularity and bi-Lipschitz warp assumptions, SiFEN achieves the classic\nFEM approximation rate M^(-m/d) with M mesh vertices. Empirically, on synthetic\napproximation tasks, tabular regression/classification, and as a drop-in head\non compact CNNs, SiFEN matches or surpasses MLPs and KANs at matched parameter\nbudgets, improves calibration (lower ECE/Brier), and reduces inference latency\ndue to geometric locality. These properties make SiFEN a compact,\ninterpretable, and theoretically grounded alternative to dense MLPs and\nedge-spline networks.", "AI": {"tldr": "SiFEN is a learned finite-element style network that uses a learned simplicial mesh and piecewise Bernstein polynomials to achieve locality, smoothness control, and FEM-like approximation guarantees, with improved calibration and lower latency compared to MLPs and edge-spline nets.", "motivation": "To combine finite-element theory with learning for locality, interpretability, and theoretical guarantees, addressing limitations of dense MLPs and existing geometric nets in tabular regression/classification and as CNN heads.", "method": "Learned globally C^r finite-element field on a learned simplicial mesh in a warped input space. Each query activates one simplex and at most d+1 Bernstein-B\u00e9zier basis functions via barycentric coordinates. Uses a light invertible warp; trained end-to-end with shape regularization, semi-discrete OT coverage, and differentiable edge flips. Assumes shape-regularity and bi-Lipschitz warp, yielding FEM-like approximation rates.", "result": "Under standard assumptions, SiFEN achieves the FEM approximation rate M^(-m/d) with M mesh vertices. Empirically, it matches or surpasses MLPs and KANs at equal parameter budgets on synthetic tasks, tabular regression/classification, and as a drop-in head for compact CNNs; it improves calibration (lower ECE/Brier) and reduces inference latency due to geometric locality.", "conclusion": "SiFEN provides a compact, interpretable, and theoretically grounded alternative to dense MLPs and edge-spline networks, combining FEM theory with learnable meshes for strong performance, calibration, and efficiency."}}
{"id": "2511.05033", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05033", "abs": "https://arxiv.org/abs/2511.05033", "authors": ["Jennifer K. Leestma", "Siddharth R. Nathella", "Christoph P. O. Nuesslein", "Snehil Mathur", "Gregory S. Sawicki", "Aaron J. Young"], "title": "Epically Powerful: An open-source software and mechatronics infrastructure for wearable robotic systems", "comment": "11 pages, 5 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "Epically Powerful is an open-source robotics infrastructure that streamlines\nthe underlying framework of wearable robotic systems - managing communication\nprotocols, clocking, actuator commands, visualization, sensor data acquisition,\ndata logging, and more - while also providing comprehensive guides for hardware\nselection, system assembly, and controller implementation. Epically Powerful\ncontains a code base enabling simplified user implementation via Python that\nseamlessly interfaces with various commercial state-of-the-art quasi-direct\ndrive (QDD) actuators, single-board computers, and common sensors, provides\nexample controllers, and enables real-time visualization. To further support\ndevice development, the package also includes a recommended parts list and\ncompatibility guide and detailed documentation on hardware and software\nimplementation. The goal of Epically Powerful is to lower the barrier to\ndeveloping and deploying custom wearable robotic systems without a\npre-specified form factor, enabling researchers to go from raw hardware to\nmodular, robust devices quickly and effectively. Though originally designed\nwith wearable robotics in mind, Epically Powerful is broadly applicable to\nother robotic domains that utilize QDD actuators, single-board computers, and\nsensors for closed-loop control.", "AI": {"tldr": "Epically Powerful is an open-source software and hardware infrastructure that simplifies building wearable robotics by providing a Python-based interface, real-time visualization, and comprehensive hardware guides, targeting QDD actuators, SBCs, and sensors to accelerate development from raw hardware to modular, deployable devices.", "motivation": "Wearable robotics development is often hindered by fragmented toolchains and lack of standardized software for integration of actuators, sensors, timing, data logging, and visualization. This work aims to lower barriers and speed prototyping by delivering a cohesive, extensible framework with documentation and example controllers.", "method": "Develop an open-source software stack (Epically Powerful) with a Python interface that integrates quasi-direct drive actuators, single-board computers, and common sensors. Include real-time visualization, data logging, and timing support, plus a hardware compatibility guide, example controllers, and a parts list to facilitate hardware selection and assembly.", "result": "A modular framework and documentation suite that enables rapid development of wearable robotic systems and beyond, providing interfaces, controllers, and visualization to move from raw hardware to robust, deployable devices with reduced engineering effort.", "conclusion": "Epically Powerful lowers the barrier to designing and deploying custom wearable robotics (and other systems using QDD actuators) by offering an extensible, well-documented infrastructure that supports hardware diversity and rapid prototyping without prescribing a fixed form factor."}}
{"id": "2511.04872", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04872", "abs": "https://arxiv.org/abs/2511.04872", "authors": ["James Ndubuisi", "Fernando Auat", "Marta Vallejo"], "title": "Validating Vision Transformers for Otoscopy: Performance and Data-Leakage Effects", "comment": null, "summary": "This study evaluates the efficacy of vision transformer models, specifically\nSwin transformers, in enhancing the diagnostic accuracy of ear diseases\ncompared to traditional convolutional neural networks. With a reported 27%\nmisdiagnosis rate among specialist otolaryngologists, improving diagnostic\naccuracy is crucial. The research utilised a real-world dataset from the\nDepartment of Otolaryngology at the Clinical Hospital of the Universidad de\nChile, comprising otoscopic videos of ear examinations depicting various middle\nand external ear conditions. Frames were selected based on the Laplacian and\nShannon entropy thresholds, with blank frames removed. Initially, Swin v1 and\nSwin v2 transformer models achieved accuracies of 100% and 99.1%, respectively,\nmarginally outperforming the ResNet model (99.5%). These results surpassed\nmetrics reported in related studies. However, the evaluation uncovered a\ncritical data leakage issue in the preprocessing step, affecting both this\nstudy and related research using the same raw dataset. After mitigating the\ndata leakage, model performance decreased significantly. Corrected accuracies\nwere 83% for both Swin v1 and Swin v2, and 82% for the ResNet model. This\nfinding highlights the importance of rigorous data handling in machine learning\nstudies, especially in medical applications. The findings indicate that while\nvision transformers show promise, it is essential to find an optimal balance\nbetween the benefits of advanced model architectures and those derived from\neffective data preprocessing. This balance is key to developing a reliable\nmachine learning model for diagnosing ear diseases.", "AI": {"tldr": "Swin transformer models were tested against ResNet on ear-disease diagnosis using otoscopic videos; initial near-perfect accuracies were inflated due to data leakage in preprocessing; after correcting leakage, accuracies dropped to ~82\u201383% for all models, underscoring the critical role of data handling and preprocessing in medical ML evaluation.", "motivation": "Reduce misdiagnosis of ear diseases (27% misdiagnosis among specialists) by improving automated diagnostic accuracy with advanced architectures, exploring whether vision transformers outperform CNNs on real-world otoscopic video data.", "method": "Real-world dataset from a Chilean hospital (otoscopic videos). Frames were selected using Laplacian variance and Shannon entropy; blank frames removed. Models compared: Swin v1, Swin v2, and ResNet. Initial evaluation suggested very high accuracy, but data leakage in preprocessing was later identified and mitigated, leading to lower, more realistic performance.", "result": "Initial accuracies: Swin v1 100%, Swin v2 99.1%, ResNet 99.5%. After addressing data leakage, corrected accuracies were ~83% for Swin v1/v2 and 82% for ResNet.", "conclusion": "Vision transformers show potential for ear-disease diagnosis, but robust data handling is essential. Data leakage can dramatically inflate results; future work should prioritize rigorous validation, transparent preprocessing, and per-patient splits to ensure reliable performance estimates."}}
{"id": "2511.04805", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04805", "abs": "https://arxiv.org/abs/2511.04805", "authors": ["Yushu Zhao", "Zheng Wang", "Minjia Zhang"], "title": "PuzzleMoE: Efficient Compression of Large Mixture-of-Experts Models via Sparse Expert Merging and Bit-packed inference", "comment": null, "summary": "Mixture-of-Experts (MoE) models have shown strong potential in scaling\nlanguage models efficiently by activating only a small subset of experts per\ninput. However, their widespread deployment remains limited due to the high\nmemory overhead associated with storing all expert parameters, particularly as\nthe number of experts increases. To address this challenge, prior works have\nexplored expert dropping and merging strategies, yet they often suffer from\nperformance drop at high compression ratios. In this paper, we introduce\nPuzzleMoE, a training-free MoE compression method that achieves both high\naccuracy and efficient inference through two key innovations: First, PuzzleMoE\nperforms sparse expert merging by identifying element-wise weight redundancy\nand specialization. It uses a dual-mask to capture both shared and\nexpert-specific parameters. Second, to avoid the overhead of storing binary\nmasks and signs, PuzzleMoE introduces a bit-packed encoding scheme that reuses\nunderutilized exponent bits, enabling efficient MoE inference on GPUs.\nExtensive experiments demonstrate that PuzzleMoE can compress MoE models by up\nto 50% while maintaining accuracy across various tasks. Specifically, it\noutperforms prior MoE compression methods by up to 16.7% on MMLU at 50%\ncompression ratio, and achieves up to 1.28\\times inference speedup.", "AI": {"tldr": "PuzzleMoE is a training-free compression method for mixture-of-experts (MoE) models that merges experts by exploiting element-wise weight redundancy and specialization, using a dual-mask to capture shared and expert-specific parameters and a bit-packed encoding scheme to avoid storing masks/signs, yielding up to 50% compression with maintained accuracy and up to 1.28x speedup.", "motivation": "Mixture-of-Experts (MoE) offer scalable language modeling but incur large memory overhead due to many expert parameters. High compression is needed for deployment, yet existing dropping/merging methods often degrade performance at high compression ratios.", "method": "1) Sparse expert merging via dual-mask that identifies element-wise redundancy and specialization, capturing both shared and expert-specific parameters. 2) Bit-packed encoding scheme that reuses underutilized exponent bits to avoid storing binary masks and signs, enabling efficient GPU inference without extra mask storage.", "result": "Experiments show up to 50% compression with maintained accuracy across various tasks. Outperforms prior MoE compression methods by up to 16.7% on MMLU at 50% compression and yields up to 1.28x inference speedup.", "conclusion": "PuzzleMoE enables training-free compression of MoE models with strong accuracy retention and efficiency, facilitating practical deployment of large MoE models while reducing memory and compute overhead."}}
{"id": "2511.05052", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05052", "abs": "https://arxiv.org/abs/2511.05052", "authors": ["Zihao Li", "Yiming Zhu", "Zhe Zhong", "Qinyuan Ren", "Yijiang Huang"], "title": "TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments", "comment": null, "summary": "Robotic manipulation in complex, constrained spaces is vital for widespread\napplications but challenging, particularly when navigating narrow passages with\nelongated objects. Existing planning methods often fail in these low-clearance\nscenarios due to the sampling difficulties or the local minima. This work\nproposes Topology-Aware Planning for Object Manipulation (TAPOM), which\nexplicitly incorporates task-space topological analysis to enable efficient\nplanning. TAPOM uses a high-level analysis to identify critical pathways and\ngenerate guiding keyframes, which are utilized in a low-level planner to find\nfeasible configuration space trajectories. Experimental validation demonstrates\nsignificantly high success rates and improved efficiency over state-of-the-art\nmethods on low-clearance manipulation tasks. This approach offers broad\nimplications for enhancing manipulation capabilities of robots in complex\nreal-world environments.", "AI": {"tldr": "A topology-aware planning framework TAPOM improves low-clearance robotic manipulation by combining task-space topology analysis with guiding keyframes to steer a low-level planner, yielding higher success rates and efficiency.", "motivation": "In narrow passages with elongated objects, existing planners struggle due to sampling difficulties and local minima, limiting manipulation in real-world constrained environments.", "method": "TAPOM performs high-level topology analysis to identify critical pathways and generate guiding keyframes, which are used to steer a low-level configuration-space trajectory planner to feasible solutions.", "result": "Experiments show significantly higher success rates and improved efficiency compared with state-of-the-art methods on low-clearance manipulation tasks.", "conclusion": "Topology-aware planning broadens robotic manipulation capabilities in complex real-world environments and has wide applicability for constrained-space manipulation."}}
{"id": "2511.04886", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04886", "abs": "https://arxiv.org/abs/2511.04886", "authors": ["Ahmad Elallaf", "Nathan Jacobs", "Xinyue Ye", "Mei Chen", "Gongbo Liang"], "title": "Beta Distribution Learning for Reliable Roadway Crash Risk Assessment", "comment": "Accepted to AAAI 2026", "summary": "Roadway traffic accidents represent a global health crisis, responsible for\nover a million deaths annually and costing many countries up to 3% of their\nGDP. Traditional traffic safety studies often examine risk factors in\nisolation, overlooking the spatial complexity and contextual interactions\ninherent in the built environment. Furthermore, conventional Neural\nNetwork-based risk estimators typically generate point estimates without\nconveying model uncertainty, limiting their utility in critical\ndecision-making. To address these shortcomings, we introduce a novel geospatial\ndeep learning framework that leverages satellite imagery as a comprehensive\nspatial input. This approach enables the model to capture the nuanced spatial\npatterns and embedded environmental risk factors that contribute to fatal crash\nrisks. Rather than producing a single deterministic output, our model estimates\na full Beta probability distribution over fatal crash risk, yielding accurate\nand uncertainty-aware predictions--a critical feature for trustworthy AI in\nsafety-critical applications. Our model outperforms baselines by achieving a\n17-23% improvement in recall, a key metric for flagging potential dangers,\nwhile delivering superior calibration. By providing reliable and interpretable\nrisk assessments from satellite imagery alone, our method enables safer\nautonomous navigation and offers a highly scalable tool for urban planners and\npolicymakers to enhance roadway safety equitably and cost-effectively.", "AI": {"tldr": "Geospatial DL using satellite imagery to predict fatal crash risk with Beta-distributed uncertainty, improving recall and calibration.", "motivation": "Traditional traffic safety studies analyze risk factors in isolation and overlook spatial/contextual interactions in the built environment; conventional NN risk estimators lack quantified uncertainty, hindering decisions in safety-critical domains.", "method": "A geospatial deep learning framework that uses satellite imagery as the sole spatial input to model fatal crash risk and outputs a Beta distribution, providing uncertainty-aware predictions rather than a point estimate.", "result": "The approach achieves a 17-23% improvement in recall over baselines and shows superior calibration, enabling reliable risk assessments from imagery alone.", "conclusion": "The method offers scalable, uncertainty-aware risk assessments from satellite imagery that can enhance autonomous navigation, urban planning, and policy decisions for roadway safety."}}
{"id": "2511.04807", "categories": ["cs.LG", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.04807", "abs": "https://arxiv.org/abs/2511.04807", "authors": ["Matthew D. Kvalheim", "Eduardo D. Sontag"], "title": "Autoencoding Dynamics: Topological Limitations and Capabilities", "comment": null, "summary": "Given a \"data manifold\" $M\\subset \\mathbb{R}^n$ and \"latent space\"\n$\\mathbb{R}^\\ell$, an autoencoder is a pair of continuous maps consisting of an\n\"encoder\" $E\\colon \\mathbb{R}^n\\to \\mathbb{R}^\\ell$ and \"decoder\" $D\\colon\n\\mathbb{R}^\\ell\\to \\mathbb{R}^n$ such that the \"round trip\" map $D\\circ E$ is\nas close as possible to the identity map $\\mbox{id}_M$ on $M$. We present\nvarious topological limitations and capabilites inherent to the search for an\nautoencoder, and describe capabilities for autoencoding dynamical systems\nhaving $M$ as an invariant manifold.", "AI": {"tldr": "A theoretical study of autoencoders for data on a manifold, detailing the topological limits and possibilities of reconstruction, and outlining when such autoencoders can preserve or encode the dynamics of systems with the manifold as an invariant.", "motivation": "Understand fundamental topological constraints on representing manifold-valued data with latent spaces, and assess the feasibility of learning dynamical systems constrained to an invariant manifold via autoencoders.", "method": "The authors analyze the existence and quality of encoders E and decoders D that make D\u2218E approximate the identity on the data manifold M, exploring topological limitations; they also characterize capabilities for autoencoding dynamical systems where M is invariant, potentially deriving conditions and constructions.", "result": "Identification of intrinsic topological limitations on autoencoder expressivity for manifolds and demonstration of certain capabilities to encode dynamical systems with M invariant, including possible constructive or theoretical results linking manifold topology to achievable reconstruction/latents.", "conclusion": "Autoencoders are constrained by the topology of the data manifold; however, under suitable conditions related to the manifold and dynamics, one can achieve faithful autoencoding and meaningful dynamic representations on the latent space."}}
{"id": "2511.05129", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05129", "abs": "https://arxiv.org/abs/2511.05129", "authors": ["Bin Fan", "Jianjian Jiang", "Zhuohao Li", "Yixiang He", "Xiaoming Wu", "Yihan Yang", "Shengbang Liu", "Weishi Zheng"], "title": "Decomposed Object Manipulation via Dual-Actor Policy", "comment": "9 pages, 7 figures, 5 tables", "summary": "Object manipulation, which focuses on learning to perform tasks on similar\nparts across different types of objects, can be divided into an approaching\nstage and a manipulation stage. However, previous works often ignore this\ncharacteristic of the task and rely on a single policy to directly learn the\nwhole process of object manipulation. To address this problem, we propose a\nnovel Dual-Actor Policy, termed DAP, which explicitly considers different\nstages and leverages heterogeneous visual priors to enhance each stage.\nSpecifically, we introduce an affordance-based actor to locate the functional\npart in the manipulation task, thereby improving the approaching process.\nFollowing this, we propose a motion flow-based actor to capture the movement of\nthe component, facilitating the manipulation process. Finally, we introduce a\ndecision maker to determine the current stage of DAP and select the\ncorresponding actor. Moreover, existing object manipulation datasets contain\nfew objects and lack the visual priors needed to support training. To address\nthis, we construct a simulated dataset, the Dual-Prior Object Manipulation\nDataset, which combines the two visual priors and includes seven tasks,\nincluding two challenging long-term, multi-stage tasks. Experimental results on\nour dataset, the RoboTwin benchmark and real-world scenarios illustrate that\nour method consistently outperforms the SOTA method by 5.55%, 14.7% and 10.4%\non average respectively.", "AI": {"tldr": "A dual-actor policy for object manipulation that separates approaching and manipulation stages with stage-aware decision making and two visual priors, achieving better performance than SOTA on multiple benchmarks.", "motivation": "Object manipulation across similar parts requires distinct strategies for the approaching and manipulation stages. Relying on a single policy with limited priors hampers generalization and efficiency across diverse objects.", "method": "Propose Dual-Actor Policy (DAP) with an affordance-based actor to locate the functional part and guide the approaching stage, a motion flow-based actor to model the component's movement for the manipulation stage, and a decision maker to switch between actors based on the current stage. Address data scarcity by constructing the Dual-Prior Object Manipulation Dataset that combines both visual priors and includes seven tasks, including long-term multi-stage tasks. Evaluate on the RoboTwin benchmark and real-world scenarios.", "result": "DAP achieves consistent improvements over the state-of-the-art: on average by 5.55% on the Dual-Prior Object Manipulation Dataset, 14.7% on RoboTwin, and 10.4% in real-world scenarios.", "conclusion": "Integrating stage-aware policies with complementary visual priors and a stage-detection module yields robust multi-stage object manipulation, demonstrating strong performance gains across simulated and real environments. The proposed dataset also provides a resource for training and evaluating stage-aware manipulation methods; future work could explore additional priors, more stages, and closer sim-to-real alignment."}}
{"id": "2511.04920", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04920", "abs": "https://arxiv.org/abs/2511.04920", "authors": ["Hu Gao", "Xiaoning Lei", "Ying Zhang", "Xichen Xu", "Guannan Jiang", "Lizhuang Ma"], "title": "Learning to Restore Multi-Degraded Images via Ingredient Decoupling and Task-Aware Path Adaptation", "comment": null, "summary": "Image restoration (IR) aims to recover clean images from degraded\nobservations. Despite remarkable progress, most existing methods focus on a\nsingle degradation type, whereas real-world images often suffer from multiple\ncoexisting degradations, such as rain, noise, and haze coexisting in a single\nimage, which limits their practical effectiveness. In this paper, we propose an\nadaptive multi-degradation image restoration network that reconstructs images\nby leveraging decoupled representations of degradation ingredients to guide\npath selection. Specifically, we design a degradation ingredient decoupling\nblock (DIDBlock) in the encoder to separate degradation ingredients\nstatistically by integrating spatial and frequency domain information,\nenhancing the recognition of multiple degradation types and making their\nfeature representations independent. In addition, we present fusion block\n(FBlock) to integrate degradation information across all levels using learnable\nmatrices. In the decoder, we further introduce a task adaptation block\n(TABlock) that dynamically activates or fuses functional branches based on the\nmulti-degradation representation, flexibly selecting optimal restoration paths\nunder diverse degradation conditions. The resulting tightly integrated\narchitecture, termed IMDNet, is extensively validated through experiments,\nshowing superior performance on multi-degradation restoration while maintaining\nstrong competitiveness on single-degradation tasks.", "AI": {"tldr": "An adaptive multi-degradation image restoration network (IMDNet) decouples degradation ingredients to guide restoration paths, achieving strong multi-degradation restoration and competitive single-degradation performance.", "motivation": "Real-world images suffer from multiple coexisting degradations; existing methods targeting single degradations fail to generalize to mixtures; decoupling degradation factors can enable flexible, adaptive restoration.", "method": "Introduce DIDBlock to separate degradation ingredients by combining spatial and frequency-domain cues; introduce FBlock to fuse degradation information across levels with learnable matrices; introduce TABLock (TABlock) to dynamically activate or fuse branches based on multi-degradation representation; encoder-decoder architecture IMDNet guided by multi-degradation representation to dynamically activate/fuse branches and select optimal restoration paths.", "result": "Experiments show superior performance for multi-degradation restoration and strong competitiveness for single-degradation tasks, demonstrating effectiveness of decoupled degradation representations and adaptive path selection.", "conclusion": "Decoupled degradation representations with adaptive path selection enable robust multi-degradation restoration and maintain performance on single-degradation tasks; the approach offers a flexible framework for handling complex real-world degradations."}}
{"id": "2511.04808", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04808", "abs": "https://arxiv.org/abs/2511.04808", "authors": ["Raymond Fan", "Bryce Sandlund", "Lin Myat Ko"], "title": "Sharp Minima Can Generalize: A Loss Landscape Perspective On Data", "comment": null, "summary": "The volume hypothesis suggests deep learning is effective because it is\nlikely to find flat minima due to their large volumes, and flat minima\ngeneralize well. This picture does not explain the role of large datasets in\ngeneralization. Measuring minima volumes under varying amounts of training data\nreveals sharp minima which generalize well exist, but are unlikely to be found\ndue to their small volumes. Increasing data changes the loss landscape, such\nthat previously small generalizing minima become (relatively) large.", "AI": {"tldr": "The abstract challenges the volume-based view of generalization by showing that dataset size reshapes the loss landscape: although sharp, generalizing minima exist, they are rare when data is scarce due to small volumes; as data increases, previously small generalizing minima inflate in volume and become more accessible.", "motivation": "To explain generalization in deep learning beyond the volume hypothesis by examining how varying amounts of training data affect the geometry of minima and their generalization properties.", "method": "Empirically measure minima volumes under different training data sizes and analyze how the loss landscape changes as data increases.", "result": "Sharp minima that generalize can exist but are unlikely to be found when their volumes are small; increasing data alters the landscape so that those previously small generalizing minima become relatively large and more likely to be found.", "conclusion": "Volume-based explanations are incomplete; dataset size actively reshapes the loss landscape, enabling generalizing minima to emerge with larger data, suggesting a more dynamic relationship between data, volume, and generalization."}}
{"id": "2511.05158", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05158", "abs": "https://arxiv.org/abs/2511.05158", "authors": ["Sahar Salimpour", "Iacopo Catalano", "Tomi Westerlund", "Mohsen Falahi", "Jorge Pe\u00f1a Queralta"], "title": "Follow-Me in Micro-Mobility with End-to-End Imitation Learning", "comment": null, "summary": "Autonomous micro-mobility platforms face challenges from the perspective of\nthe typical deployment environment: large indoor spaces or urban areas that are\npotentially crowded and highly dynamic. While social navigation algorithms have\nprogressed significantly, optimizing user comfort and overall user experience\nover other typical metrics in robotics (e.g., time or distance traveled) is\nunderstudied. Specifically, these metrics are critical in commercial\napplications. In this paper, we show how imitation learning delivers smoother\nand overall better controllers, versus previously used manually-tuned\ncontrollers. We demonstrate how DAAV's autonomous wheelchair achieves\nstate-of-the-art comfort in follow-me mode, in which it follows a human\noperator assisting persons with reduced mobility (PRM). This paper analyzes\ndifferent neural network architectures for end-to-end control and demonstrates\ntheir usability in real-world production-level deployments.", "AI": {"tldr": "Imitation learning improves comfort in autonomous wheelchair follow-me mode, outperforming manually-tuned controllers; evaluates multiple end-to-end NN architectures for production deployments.", "motivation": "Deployment environments for autonomous micro-mobility (large indoor spaces, crowded urban areas) are challenging, with user comfort and experience as critical metrics alongside traditional ones like time or distance, especially for commercial applications.", "method": "Train controllers via imitation learning and compare different end-to-end neural network architectures; validate on DAAV's autonomous wheelchair in follow-me mode; assess usability in real-world production-level deployments.", "result": "Imitation learning produces smoother, higher-comfort controllers and achieves state-of-the-art comfort in follow-me mode; demonstrates viability of various neural architectures for production deployments.", "conclusion": "Imitation learning is effective for optimizing user comfort and overall UX in autonomous micro-mobility; end-to-end architectures are viable for real-world deployments; comfort should be a central evaluation metric in design."}}
{"id": "2511.04948", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04948", "abs": "https://arxiv.org/abs/2511.04948", "authors": ["Haoxin Lv", "Ijazul Haq", "Jin Du", "Jiaxin Ma", "Binnian Zhu", "Xiaobing Dang", "Chaoan Liang", "Ruxu Du", "Yingjie Zhang", "Muhammad Saqib"], "title": "A benchmark multimodal oro-dental dataset for large vision-language models", "comment": null, "summary": "The advancement of artificial intelligence in oral healthcare relies on the\navailability of large-scale multimodal datasets that capture the complexity of\nclinical practice. In this paper, we present a comprehensive multimodal\ndataset, comprising 8775 dental checkups from 4800 patients collected over\neight years (2018-2025), with patients ranging from 10 to 90 years of age. The\ndataset includes 50000 intraoral images, 8056 radiographs, and detailed textual\nrecords, including diagnoses, treatment plans, and follow-up notes. The data\nwere collected under standard ethical guidelines and annotated for\nbenchmarking. To demonstrate its utility, we fine-tuned state-of-the-art large\nvision-language models, Qwen-VL 3B and 7B, and evaluated them on two tasks:\nclassification of six oro-dental anomalies and generation of complete\ndiagnostic reports from multimodal inputs. We compared the fine-tuned models\nwith their base counterparts and GPT-4o. The fine-tuned models achieved\nsubstantial gains over these baselines, validating the dataset and underscoring\nits effectiveness in advancing AI-driven oro-dental healthcare solutions. The\ndataset is publicly available, providing an essential resource for future\nresearch in AI dentistry.", "AI": {"tldr": "A large, publicly available multimodal dental dataset (8775 checkups, 50k images, 8k radiographs, annotations) used to fine-tune Qwen-VL 3B/7B for six oro-dental anomaly classification and diagnostic report generation; shows improvements over baselines and GPT-4o.", "motivation": "To overcome scarcity of integrated multimodal data in dentistry and to advance AI-driven diagnostic and reporting capabilities.", "method": "Assembled eight-year dataset (2018-2025) from ages 10\u201390; includes images, radiographs, and textual records; annotated for benchmarking; fine-tuned Qwen-VL 3B and 7B on two tasks; evaluated against base models and GPT-4o.", "result": "Fine-tuned models achieved substantial gains on both tasks compared with baselines; validates dataset usefulness; dataset is publicly available.", "conclusion": "Dataset is a valuable resource to drive AI dentistry research and real-world applications; encourages further multimodal AI development in oral healthcare."}}
{"id": "2511.04814", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "68T07, 62H30, 62P10", "I.2.6; I.2.1; I.5.1; I.5.2"], "pdf": "https://arxiv.org/pdf/2511.04814", "abs": "https://arxiv.org/abs/2511.04814", "authors": ["Sebastian Ojeda", "Rafael Velasquez", "Nicol\u00e1s Aparicio", "Juanita Puentes", "Paula C\u00e1rdenas", "Nicol\u00e1s Andrade", "Gabriel Gonz\u00e1lez", "Sergio Rinc\u00f3n", "Carolina Mu\u00f1oz-Camargo", "Pablo Arbel\u00e1ez"], "title": "A Standardized Benchmark for Multilabel Antimicrobial Peptide Classification", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025). Camera-ready version. Code: https://github.com/BCV-Uniandes/ESCAPE.\n  Dataset DOI: https://doi.org/10.7910/DVN/C69MCD", "summary": "Antimicrobial peptides have emerged as promising molecules to combat\nantimicrobial resistance. However, fragmented datasets, inconsistent\nannotations, and the lack of standardized benchmarks hinder computational\napproaches and slow down the discovery of new candidates. To address these\nchallenges, we present the Expanded Standardized Collection for Antimicrobial\nPeptide Evaluation (ESCAPE), an experimental framework integrating over 80.000\npeptides from 27 validated repositories. Our dataset separates antimicrobial\npeptides from negative sequences and incorporates their functional annotations\ninto a biologically coherent multilabel hierarchy, capturing activities across\nantibacterial, antifungal, antiviral, and antiparasitic classes. Building on\nESCAPE, we propose a transformer-based model that leverages sequence and\nstructural information to predict multiple functional activities of peptides.\nOur method achieves up to a 2.56% relative average improvement in mean Average\nPrecision over the second-best method adapted for this task, establishing a new\nstate-of-the-art multilabel peptide classification. ESCAPE provides a\ncomprehensive and reproducible evaluation framework to advance AI-driven\nantimicrobial peptide research.", "AI": {"tldr": "ESCAPE is a large, standardized dataset for antimicrobial peptides with multilabel activity annotations, combined with a transformer-based classifier that achieves state-of-the-art results.", "motivation": "Fragmented datasets, inconsistent annotations, and lack of standardized benchmarks hinder AI-driven antimicrobial peptide discovery; a coherent, reproducible framework is needed.", "method": "Assembles over 80,000 peptides from 27 repositories into ESCAPE, clearly separating active peptides from negatives and encoding functional annotations in a multilabel hierarchy; develops a transformer-based model that uses sequence and structural features to predict multiple activities (antibacterial, antifungal, antiviral, antiparasitic).", "result": "The model achieves up to 2.56% relative improvement in mean Average Precision over the second-best method and sets a new state-of-the-art for multilabel peptide classification; ESCAPE provides a comprehensive, reproducible evaluation framework.", "conclusion": "ESCAPE offers a robust, scalable resource and methodology that can accelerate AI-driven antimicrobial peptide discovery by enabling consistent benchmarking and improved predictive performance."}}
{"id": "2511.05185", "categories": ["cs.RO", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.05185", "abs": "https://arxiv.org/abs/2511.05185", "authors": ["Adri\u00e1n Campazas-Vega", "Claudia \u00c1lvarez-Aparicio", "David Sobr\u00edn-Hidalgo", "Laura Inyesto-Alonso", "Francisco Javier Rodr\u00edguez-Lera", "Vicente Matell\u00e1n-Olivera", "\u00c1ngel Manuel Guerrero-Higueras"], "title": "Procedimiento de auditor\u00eda de ciberseguridad para sistemas aut\u00f3nomos: metodolog\u00eda, amenazas y mitigaciones", "comment": "32 pages, in Spanish language, 7 tables, 12 Figures. White paper\n  under the TESCAC project", "summary": "The deployment of autonomous systems has experienced remarkable growth in\nrecent years, driven by their integration into sectors such as industry,\nmedicine, logistics, and domestic environments. This expansion is accompanied\nby a series of security issues that entail significant risks due to the\ncritical nature of autonomous systems, especially those operating in\nhuman-interaction environments. Furthermore, technological advancement and the\nhigh operational and architectural complexity of autonomous systems have\nresulted in an increased attack surface. This article presents a specific\nsecurity auditing procedure for autonomous systems, based on a layer-structured\nmethodology, a threat taxonomy adapted to the robotic context, and a set of\nconcrete mitigation measures. The validity of the proposed approach is\ndemonstrated through four practical case studies applied to representative\nrobotic platforms: the Vision 60 military quadruped from Ghost Robotics, the A1\nrobot from Unitree Robotics, the UR3 collaborative arm from Universal Robots,\nand the Pepper social robot from Aldebaran Robotics.", "AI": {"tldr": "A security auditing framework for autonomous systems using a layered approach, tailored robot threat taxonomy, and concrete mitigations; validated via four real-world robotic case studies.", "motivation": "Autonomous systems are expanding into critical and human-interactive domains, which increases security risks and attack surfaces due to complexity and integration with diverse environments.", "method": "Introduce a layer-structured security auditing procedure, adapt a threat taxonomy to robotics, and provide concrete mitigation measures; validate the approach through four case studies on Ghost Robotics Vision 60, Unitree A1, Universal Robots UR3, and Pepper by Aldebaran.", "result": "Demonstrates the feasibility and relevance of the proposed framework across different robotic platforms, offering actionable mitigation guidance and a basis for systematic security audits.", "conclusion": "The framework offers a practical, cross-platform approach to security auditing for autonomous systems and could inform standardization and tooling; further work could address quantitative validation, broader domain generalization, and automation of the auditing process."}}
{"id": "2511.04949", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04949", "abs": "https://arxiv.org/abs/2511.04949", "authors": ["Tharindu Fernando", "Clinton Fookes", "Sridha Sridharan"], "title": "DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning", "comment": null, "summary": "Rapid advances in generative AI have led to increasingly realistic deepfakes,\nposing growing challenges for law enforcement and public trust. Existing\npassive deepfake detectors struggle to keep pace, largely due to their\ndependence on specific forgery artifacts, which limits their ability to\ngeneralize to new deepfake types. Proactive deepfake detection using watermarks\nhas emerged to address the challenge of identifying high-quality synthetic\nmedia. However, these methods often struggle to balance robustness against\nbenign distortions with sensitivity to malicious tampering. This paper\nintroduces a novel deep learning framework that harnesses high-dimensional\nlatent space representations and the Multi-Agent Adversarial Reinforcement\nLearning (MAARL) paradigm to develop a robust and adaptive watermarking\napproach. Specifically, we develop a learnable watermark embedder that operates\nin the latent space, capturing high-level image semantics, while offering\nprecise control over message encoding and extraction. The MAARL paradigm\nempowers the learnable watermarking agent to pursue an optimal balance between\nrobustness and fragility by interacting with a dynamic curriculum of benign and\nmalicious image manipulations simulated by an adversarial attacker agent.\nComprehensive evaluations on the CelebA and CelebA-HQ benchmarks reveal that\nour method consistently outperforms state-of-the-art approaches, achieving\nimprovements of over 4.5% on CelebA and more than 5.3% on CelebA-HQ under\nchallenging manipulation scenarios.", "AI": {"tldr": "Proposes a latent-space watermarking framework with MAARL for proactive deepfake detection, outperforming state-of-the-art under manipulations on CelebA/CelebA-HQ.", "motivation": "Passive deepfake detectors struggle to generalize to new forgery types; existing watermarking methods balance robustness and tampering sensitivity; need robust, adaptive proactive detection.", "method": "A learnable watermark embedder operating in latent space capturing high-level semantics; uses Multi-Agent Adversarial Reinforcement Learning with an attacker agent and a benign manipulations curriculum to balance robustness and fragility; evaluated on CelebA/CelebA-HQ.", "result": "Outperforms state-of-the-art by >4.5% on CelebA and >5.3% on CelebA-HQ under challenging manipulations.", "conclusion": "The MAARL-based latent watermarking framework provides robust, adaptive proactive deepfake detection with strong generalization to manipulated media."}}
{"id": "2511.04825", "categories": ["cs.LG", "math.AT", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.04825", "abs": "https://arxiv.org/abs/2511.04825", "authors": ["Luigi Caputi", "Nicholas Meadows", "Henri Riihim\u00e4ki"], "title": "Persistent reachability homology in machine learning applications", "comment": "19 pages; any comments welcome", "summary": "We explore the recently introduced persistent reachability homology (PRH) of\ndigraph data, i.e. data in the form of directed graphs. In particular, we study\nthe effectiveness of PRH in network classification task in a key neuroscience\nproblem: epilepsy detection. PRH is a variation of the persistent homology of\ndigraphs, more traditionally based on the directed flag complex (DPH). A main\nadvantage of PRH is that it considers the condensations of the digraphs\nappearing in the persistent filtration and thus is computed from smaller\ndigraphs. We compare the effectiveness of PRH to that of DPH and we show that\nPRH outperforms DPH in the classification task. We use the Betti curves and\ntheir integrals as topological features and implement our pipeline on support\nvector machine.", "AI": {"tldr": "PRH on directed graphs improves epilepsy-detection classification vs DPH, using Betti-curve features with an SVM.", "motivation": "To improve network-based epilepsy detection by applying persistent reachability homology to digraphs and to assess its advantage over directed flag complex-based topology.", "method": "Compute PRH on digraphs (which condenses graphs in the persistent filtration for smaller subgraphs) and compare with DPH. Extract Betti curves and their integrals as topological features and feed them into a support vector machine for classification.", "result": "PRH outperforms DPH in the epilepsy-detection classification task.", "conclusion": "PRH\u2019s condensation-based reduction yields more discriminative topological features for this problem, making PRH a promising tool for network neuroscience classification tasks."}}
{"id": "2511.05199", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05199", "abs": "https://arxiv.org/abs/2511.05199", "authors": ["Yichen Zhu", "Feifei Feng"], "title": "Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation", "comment": "Accepted by IROS 2025", "summary": "Robots operating in complex and uncertain environments face considerable\nchallenges. Advanced robotic systems often rely on extensive datasets to learn\nmanipulation tasks. In contrast, when humans are faced with unfamiliar tasks,\nsuch as assembling a chair, a common approach is to learn by watching video\ndemonstrations. In this paper, we propose a novel method for learning robot\npolicies by Retrieving-from-Video (RfV), using analogies from human\ndemonstrations to address manipulation tasks. Our system constructs a video\nbank comprising recordings of humans performing diverse daily tasks. To enrich\nthe knowledge from these videos, we extract mid-level information, such as\nobject affordance masks and hand motion trajectories, which serve as additional\ninputs to enhance the robot model's learning and generalization capabilities.\nWe further feature a dual-component system: a video retriever that taps into an\nexternal video bank to fetch task-relevant video based on task specification,\nand a policy generator that integrates this retrieved knowledge into the\nlearning cycle. This approach enables robots to craft adaptive responses to\nvarious scenarios and generalize to tasks beyond those in the training data.\nThrough rigorous testing in multiple simulated and real-world settings, our\nsystem demonstrates a marked improvement in performance over conventional\nrobotic systems, showcasing a significant breakthrough in the field of\nrobotics.", "AI": {"tldr": "A retrieval-from-video framework uses human demonstrations and mid-level cues to train robots via a video retriever and policy generator, improving manipulation performance and generalization.", "motivation": "Robots struggle with manipulation in complex and uncertain environments with limited data; humans learn by watching videos; leveraging abundant human demonstrations and mid-level signals can boost learning and generalization.", "method": "Construct a video bank of human task demonstrations; extract mid-level information such as object affordance masks and hand motion trajectories; implement a dual-component system: a video retriever that fetches task-relevant videos from an external bank based on task specification, and a policy generator that integrates retrieved knowledge into the learning loop.", "result": "Demonstrates a marked improvement in performance over conventional robotic systems across multiple simulated and real-world tests, with better generalization to unseen tasks.", "conclusion": "RfV is a promising direction for robot learning, showing that external video retrieval and mid-level representations can enhance manipulation policy learning and generalization; future work could broaden the video bank and refine the mid-level cues."}}
{"id": "2511.04951", "categories": ["cs.CV", "D.4; I.3.2; I.3.7"], "pdf": "https://arxiv.org/pdf/2511.04951", "abs": "https://arxiv.org/abs/2511.04951", "authors": ["Hexu Zhao", "Xiwen Min", "Xiaoteng Liu", "Moonjun Gong", "Yiming Li", "Ang Li", "Saining Xie", "Jinyang Li", "Aurojit Panda"], "title": "CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting", "comment": "Accepted to appear in the 2026 ACM International Conference on\n  Architectural Support for Programming Languages and Operating Systems", "summary": "3D Gaussian Splatting (3DGS) is an increasingly popular novel view synthesis\napproach due to its fast rendering time, and high-quality output. However,\nscaling 3DGS to large (or intricate) scenes is challenging due to its large\nmemory requirement, which exceed most GPU's memory capacity. In this paper, we\ndescribe CLM, a system that allows 3DGS to render large scenes using a single\nconsumer-grade GPU, e.g., RTX4090. It does so by offloading Gaussians to CPU\nmemory, and loading them into GPU memory only when necessary. To reduce\nperformance and communication overheads, CLM uses a novel offloading strategy\nthat exploits observations about 3DGS's memory access pattern for pipelining,\nand thus overlap GPU-to-CPU communication, GPU computation and CPU computation.\nFurthermore, we also exploit observation about the access pattern to reduce\ncommunication volume. Our evaluation shows that the resulting implementation\ncan render a large scene that requires 100 million Gaussians on a single\nRTX4090 and achieve state-of-the-art reconstruction quality.", "AI": {"tldr": "A system (CLM) enables 3D Gaussian Splatting to render large scenes on a single consumer GPU by offloading Gaussians to CPU memory and streaming them on demand, using a pipelined, access-pattern-aware strategy to overlap CPU/GPU computation and reduce data transfer, achieving 100M Gaussians on RTX4090 with state-of-the-art quality.", "motivation": "3DGS is fast and high-quality but memory-hungry; scaling to large/intricate scenes exceeds GPU memory; need a cost-effective solution on consumer hardware.", "method": "Offload Gaussians to CPU memory; stream/load them into GPU on demand; use a pipelined overlap of GPU-CPU communication, GPU compute, CPU compute; exploit memory access patterns to reduce communication volume.", "result": "Demonstrates rendering a large scene with 100 million Gaussians on RTX4090; achieves state-of-the-art reconstruction quality.", "conclusion": "CLM enables scalable 3DGS on a single consumer GPU; memory offloading with access-pattern-aware scheduling is effective; broadens practicality for large-scale novel view synthesis."}}
{"id": "2511.04834", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04834", "abs": "https://arxiv.org/abs/2511.04834", "authors": ["Jiwoo Shin", "Byeonghu Na", "Mina Kang", "Wonhyeok Choi", "Il-chul Moon"], "title": "Prompt-Based Safety Guidance Is Ineffective for Unlearned Text-to-Image Diffusion Models", "comment": "Accepted at NeurIPS 2025 Workshop on Generative and Protective AI for\n  Content Creation", "summary": "Recent advances in text-to-image generative models have raised concerns about\ntheir potential to produce harmful content when provided with malicious input\ntext prompts. To address this issue, two main approaches have emerged: (1)\nfine-tuning the model to unlearn harmful concepts and (2) training-free\nguidance methods that leverage negative prompts. However, we observe that\ncombining these two orthogonal approaches often leads to marginal or even\ndegraded defense performance. This observation indicates a critical\nincompatibility between two paradigms, which hinders their combined\neffectiveness. In this work, we address this issue by proposing a conceptually\nsimple yet experimentally robust method: replacing the negative prompts used in\ntraining-free methods with implicit negative embeddings obtained through\nconcept inversion. Our method requires no modification to either approach and\ncan be easily integrated into existing pipelines. We experimentally validate\nits effectiveness on nudity and violence benchmarks, demonstrating consistent\nimprovements in defense success rate while preserving the core semantics of\ninput prompts.", "AI": {"tldr": "A simple method replaces explicit negative prompts with implicit negative embeddings derived from concept inversion to boost defense performance against harmful prompts, addressing incompatibility between fine-tuning harmful concepts and training-free negative prompts without modifying existing pipelines.", "motivation": "Text-to-image models can produce harmful content; but defense strategies\u2014fine-tuning to unlearn harm and training-free negative prompts\u2014are often incompatible, reducing defense effectiveness when combined.", "method": "Replace the negative prompts used in training-free methods with implicit negative embeddings obtained via concept inversion, integrating without modifying either approach.", "result": "The proposed method yields consistent improvements in defense success rate on nudity and violence benchmarks while preserving the original input prompts' core semantics.", "conclusion": "Implicit negative embeddings from concept inversion can reconcile the two defense paradigms, providing a simple, deployment-friendly improvement to defense performance without changing existing pipelines."}}
{"id": "2511.05203", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05203", "abs": "https://arxiv.org/abs/2511.05203", "authors": ["Linus Nwankwo", "Bj\u00f6rn Ellensohn", "Christian Rauch", "Elmar Rueckert"], "title": "Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space", "comment": null, "summary": "Today's autonomous agents can understand free-form natural language\ninstructions and execute long-horizon tasks in a manner akin to human-level\nreasoning. These capabilities are mostly driven by large-scale pre-trained\nfoundation models (FMs). However, the approaches with which these models are\ngrounded for human-robot interaction (HRI) perpetuate a master-apprentice\nmodel, where the apprentice (embodied agent) passively receives and executes\nthe master's (human's) commands without reciprocal learning. This reactive\ninteraction approach does not capture the co-adaptive dynamics inherent in\neveryday multi-turn human-human interactions. To address this, we propose a\nSymbiotic Interactive Learning (SIL) approach that enables both the master and\nthe apprentice to co-adapt through mutual, bidirectional interactions. We\nformalised SIL as a co-adaptation process within a shared latent task space,\nwhere the agent and human maintain joint belief states that evolve based on\ninteraction history. This enables the agent to move beyond reactive execution\nto proactive clarification, adaptive suggestions, and shared plan refinement.\nTo realise these novel behaviours, we leveraged pre-trained FMs for spatial\nperception and reasoning, alongside a lightweight latent encoder that grounds\nthe models' outputs into task-specific representations. Furthermore, to ensure\nstability as the tasks evolve, we augment SIL with a memory architecture that\nprevents the forgetting of learned task-space representations. We validate SIL\non both simulated and real-world embodied tasks, including instruction\nfollowing, information retrieval, query-oriented reasoning, and interactive\ndialogues. Demos and resources are public\nat:~\\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}.", "AI": {"tldr": "SIL enables mutual, bidirectional learning between human and embodied agent, moving from reactive instruction-following to proactive clarification and shared plan refinement through a shared latent task space and memory.", "motivation": "Current HRI grounding relies on a master\u2013apprentice model where the embodied agent passively executes commands, lacking bidirectional learning and co-adaptation. This limits handling of long-horizon tasks and smooth human\u2013robot collaboration; there's a need to emulate the bidirectional dynamics of human\u2013human interaction.", "method": "Formalize Symbiotic Interactive Learning (SIL) as a co-adaptation process in a shared latent task space with joint belief states that evolve via interaction history. Enable proactive clarification, adaptive suggestions, and shared plan refinement. Leverage pre-trained foundation models for spatial perception and reasoning, use a lightweight latent encoder to ground outputs into task-specific representations, and employ a memory architecture to prevent forgetting. Validate on simulated and real-world embodied tasks (instruction following, information retrieval, query-oriented reasoning, and interactive dialogues). Public demos/resources at the provided URL.", "result": "Demonstrated across both simulated and real-world embodied tasks, showing that agents can engage in proactive, bidirectional interactions and plan refinement with humans; memory mechanisms help stabilize evolving task representations. Demos and resources are publicly available at the stated URL.", "conclusion": "SIL enables symbiotic, bidirectional learning in HRI, moving beyond reactive execution toward proactive collaboration, plan refinement, and sustained adaptation. The work provides public resources to facilitate replication and further study."}}
{"id": "2511.04963", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04963", "abs": "https://arxiv.org/abs/2511.04963", "authors": ["Xiongri Shen", "Jiaqi Wang", "Yi Zhong", "Zhenxi Song", "Leilei Zhao", "Yichen Wei", "Lingyan Liang", "Shuqiang Wang", "Baiying Lei", "Demao Deng", "Zhiguo Zhang"], "title": "Pattern-Aware Diffusion Synthesis of fMRI/dMRI with Tissue and Microstructural Refinement", "comment": null, "summary": "Magnetic resonance imaging (MRI), especially functional MRI (fMRI) and\ndiffusion MRI (dMRI), is essential for studying neurodegenerative diseases.\nHowever, missing modalities pose a major barrier to their clinical use.\nAlthough GAN- and diffusion model-based approaches have shown some promise in\nmodality completion, they remain limited in fMRI-dMRI synthesis due to (1)\nsignificant BOLD vs. diffusion-weighted signal differences between fMRI and\ndMRI in time/gradient axis, and (2) inadequate integration of disease-related\nneuroanatomical patterns during generation. To address these challenges, we\npropose PDS, introducing two key innovations: (1) a pattern-aware dual-modal 3D\ndiffusion framework for cross-modality learning, and (2) a tissue refinement\nnetwork integrated with a efficient microstructure refinement to maintain\nstructural fidelity and fine details. Evaluated on OASIS-3, ADNI, and in-house\ndatasets, our method achieves state-of-the-art results, with PSNR/SSIM scores\nof 29.83 dB/90.84\\% for fMRI synthesis (+1.54 dB/+4.12\\% over baselines) and\n30.00 dB/77.55\\% for dMRI synthesis (+1.02 dB/+2.2\\%). In clinical validation,\nthe synthesized data show strong diagnostic performance, achieving\n67.92\\%/66.02\\%/64.15\\% accuracy (NC vs. MCI vs. AD) in hybrid real-synthetic\nexperiments. Code is available in \\href{https://github.com/SXR3015/PDS}{PDS\nGitHub Repository}", "AI": {"tldr": "A pattern-aware dual-modal 3D diffusion model (PDS) for cross-modality synthesis of fMRI and dMRI, with a tissue refinement network to preserve structure. It achieves state-of-the-art image quality and competitive clinical accuracy across multiple datasets, with code released.", "motivation": "Missing imaging modalities hinder clinical use; existing GAN- and diffusion-model approaches struggle to bridge fMRI and dMRI due to (1) substantial signal differences along time/gradient axes and (2) inadequate incorporation of disease-related neuroanatomical patterns during generation.", "method": "Introduces a pattern-aware dual-modal 3D diffusion framework for cross-modality learning and a tissue refinement network with efficient microstructure refinement to maintain structural fidelity and fine details.", "result": "Achieves state-of-the-art metrics: PSNR/SSIM for fMRI synthesis = 29.83 dB / 90.84% (improved by +1.54 dB / +4.12% over baselines); for dMRI synthesis = 30.00 dB / 77.55% (improved by +1.02 dB / +2.2%). Clinical validation shows diagnostic accuracy in hybrid real-synthetic experiments as NC vs MCI vs AD: 67.92% / 66.02% / 64.15%. Datasets: OASIS-3, ADNI, and in-house; code available on GitHub.", "conclusion": "PDS effectively addresses cross-modality fMRI-dMRI synthesis challenges by leveraging pattern-aware cross-modal learning and tissue refinement, yielding high-fidelity results and clinically useful performance; the authors provide code for reproducibility."}}
{"id": "2511.04838", "categories": ["cs.LG", "math.SP", "q-bio.MN"], "pdf": "https://arxiv.org/pdf/2511.04838", "abs": "https://arxiv.org/abs/2511.04838", "authors": ["Brenda Nogueira", "Meng Jiang", "Nitesh V. Chawla", "Nuno Moniz"], "title": "SPECTRA: Spectral Target-Aware Graph Augmentation for Imbalanced Molecular Property Regression", "comment": null, "summary": "In molecular property prediction, the most valuable compounds (e.g., high\npotency) often occupy sparse regions of the target space. Standard Graph Neural\nNetworks (GNNs) commonly optimize for the average error, underperforming on\nthese uncommon but critical cases, with existing oversampling methods often\ndistorting molecular topology. In this paper, we introduce SPECTRA, a Spectral\nTarget-Aware graph augmentation framework that generates realistic molecular\ngraphs in the spectral domain. SPECTRA (i) reconstructs multi-attribute\nmolecular graphs from SMILES; (ii) aligns molecule pairs via (Fused)\nGromov-Wasserstein couplings to obtain node correspondences; (iii) interpolates\nLaplacian eigenvalues, eigenvectors and node features in a stable share-basis;\nand (iv) reconstructs edges to synthesize physically plausible intermediates\nwith interpolated targets. A rarity-aware budgeting scheme, derived from a\nkernel density estimation of labels, concentrates augmentation where data are\nscarce. Coupled with a spectral GNN using edge-aware Chebyshev convolutions,\nSPECTRA densifies underrepresented regions without degrading global accuracy.\nOn benchmarks, SPECTRA consistently improves error in relevant target ranges\nwhile maintaining competitive overall MAE, and yields interpretable synthetic\nmolecules whose structure reflects the underlying spectral geometry. Our\nresults demonstrate that spectral, geometry-aware augmentation is an effective\nand efficient strategy for imbalanced molecular property regression.", "AI": {"tldr": "Spectral, geometry-aware augmentation (SPECTRA) improves targeted-range molecular property regression by generating realistic, spectrally interpolated augmented graphs that align with molecular geometry, boosting rare-case performance while maintaining overall MAE.", "motivation": "In molecular property prediction, valuable compounds often lie in sparse regions of the target space. Standard GNNs optimize for average error and underperform on these rare but critical cases; existing oversampling methods can distort molecular topology.", "method": "SPECTRA reconstructs multi-attribute molecular graphs from SMILES; aligns molecule pairs using (Fused) Gromov-Wasserstein couplings to obtain node correspondences; interpolates Laplacian eigenvalues, eigenvectors and node features in a shared basis; reconstructs edges to synthesize physically plausible intermediates with interpolated targets; applies a rarity-aware budget via kernel density estimation to focus augmentation where data are scarce; uses a spectral GNN with edge-aware Chebyshev convolutions.", "result": "On benchmarks, SPECTRA consistently improves error in relevant target ranges while maintaining competitive overall MAE, and yields interpretable synthetic molecules whose structures reflect the underlying spectral geometry.", "conclusion": "Spectral, geometry-aware augmentation is an effective and efficient approach for addressing imbalanced molecular property regression without sacrificing global accuracy."}}
{"id": "2511.05234", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05234", "abs": "https://arxiv.org/abs/2511.05234", "authors": ["Philipp Dahlinger", "Niklas Freymuth", "Tai Hoang", "Tobias W\u00fcrth", "Michael Volpp", "Luise K\u00e4rger", "Gerhard Neumann"], "title": "Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning", "comment": "35 pages. Submitted to Transactions on Machine Learning Research\n  (TMLR)", "summary": "Simulating object deformations is a critical challenge across many scientific\ndomains, including robotics, manufacturing, and structural mechanics. Learned\nGraph Network Simulators (GNSs) offer a promising alternative to traditional\nmesh-based physics simulators. Their speed and inherent differentiability make\nthem particularly well suited for applications that require fast and accurate\nsimulations, such as robotic manipulation or manufacturing optimization.\nHowever, existing learned simulators typically rely on single-step\nobservations, which limits their ability to exploit temporal context. Without\nthis information, these models fail to infer, e.g., material properties.\nFurther, they rely on auto-regressive rollouts, which quickly accumulate error\nfor long trajectories. We instead frame mesh-based simulation as a\ntrajectory-level meta-learning problem. Using Conditional Neural Processes, our\nmethod enables rapid adaptation to new simulation scenarios from limited\ninitial data while capturing their latent simulation properties. We utilize\nmovement primitives to directly predict fast, stable and accurate simulations\nfrom a single model call. The resulting approach, Movement-primitive\nMeta-MeshGraphNet (M3GN), provides higher simulation accuracy at a fraction of\nthe runtime cost compared to state-of-the-art GNSs across several tasks.", "AI": {"tldr": "A trajectory-level meta-learning framework for learned graph network simulators (M3GN) that uses Conditional Neural Processes and movement primitives to rapidly adapt to new deformation scenarios, delivering faster and more accurate mesh-based simulations than existing GNSs.", "motivation": "Existing learned simulators rely on single-step observations and autoregressive rollouts, which limit learning of material properties and cause error accumulation over long trajectories. There is a need for temporally aware, fast-adapting simulators in applications like robotics, manufacturing, and structural mechanics.", "method": "Frame mesh-based simulation as a trajectory-level meta-learning problem using Conditional Neural Processes to enable rapid adaptation to new scenarios from limited initial data. Employ movement primitives to predict fast, stable, and accurate simulations from a single model call. The proposed model is Movement-primitive Meta-MeshGraphNet (M3GN).", "result": "M3GN achieves higher simulation accuracy at a fraction of the runtime cost compared to state-of-the-art GNSs across multiple tasks.", "conclusion": "The trajectory-level meta-learning approach with Conditional Neural Processes and movement primitives yields fast, accurate, and adaptable mesh-based simulations (M3GN), enabling more effective and scalable simulations in engineering and robotics."}}
{"id": "2511.04970", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04970", "abs": "https://arxiv.org/abs/2511.04970", "authors": ["Jian Wang", "Yixing Yong", "Haixia Bi", "Lijun He", "Fan Li"], "title": "Learning Fourier shapes to probe the geometric world of deep neural networks", "comment": "20 pages, 5 figures", "summary": "While both shape and texture are fundamental to visual recognition, research\non deep neural networks (DNNs) has predominantly focused on the latter, leaving\ntheir geometric understanding poorly probed. Here, we show: first, that\noptimized shapes can act as potent semantic carriers, generating\nhigh-confidence classifications from inputs defined purely by their geometry;\nsecond, that they are high-fidelity interpretability tools that precisely\nisolate a model's salient regions; and third, that they constitute a new,\ngeneralizable adversarial paradigm capable of deceiving downstream visual\ntasks. This is achieved through an end-to-end differentiable framework that\nunifies a powerful Fourier series to parameterize arbitrary shapes, a winding\nnumber-based mapping to translate them into the pixel grid required by DNNs,\nand signal energy constraints that enhance optimization efficiency while\nensuring physically plausible shapes. Our work provides a versatile framework\nfor probing the geometric world of DNNs and opens new frontiers for challenging\nand understanding machine perception.", "AI": {"tldr": "Optimized geometric shapes, parameterized by Fourier series and rasterized via a winding-number map, can act as semantic carriers, serve as precise interpretability tools, and form a new, generalizable adversarial paradigm for DNNs within a differentiable energy-constrained framework.", "motivation": "To explore the geometric dimension of deep neural networks beyond texture bias, enabling geometry-driven classification, interpretation, and adversarial testing.", "method": "An end-to-end differentiable pipeline that (1) parameterizes arbitrary shapes with a powerful Fourier series, (2) uses a winding-number-based mapping to convert shapes into the DNN's pixel grid, and (3) applies signal energy constraints to improve optimization efficiency and enforce physically plausible shapes.", "result": "Optimized shapes can yield high-confidence classifications using purely geometric inputs, serve as high-fidelity interpretability tools that precisely isolate salient regions, and establish a new, generalizable adversarial paradigm that can deceive downstream visual tasks.", "conclusion": "The framework provides a versatile toolset for probing the geometric aspects of DNNs and opens new directions for challenging and understanding machine perception."}}
{"id": "2511.04844", "categories": ["cs.LG", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2511.04844", "abs": "https://arxiv.org/abs/2511.04844", "authors": ["Matthew S. Zhang", "Stephen Huan", "Jerry Huang", "Nicholas M. Boffi", "Sitan Chen", "Sinho Chewi"], "title": "Sublinear iterations can suffice even for DDPMs", "comment": null, "summary": "SDE-based methods such as denoising diffusion probabilistic models (DDPMs)\nhave shown remarkable success in real-world sample generation tasks. Prior\nanalyses of DDPMs have been focused on the exponential Euler discretization,\nshowing guarantees that generally depend at least linearly on the dimension or\ninitial Fisher information. Inspired by works in log-concave sampling (Shen and\nLee, 2019), we analyze an integrator -- the denoising diffusion randomized\nmidpoint method (DDRaM) -- that leverages an additional randomized midpoint to\nbetter approximate the SDE. Using a recently-developed analytic framework\ncalled the \"shifted composition rule\", we show that this algorithm enjoys\nfavorable discretization properties under appropriate smoothness assumptions,\nwith sublinear $\\widetilde{O}(\\sqrt{d})$ score evaluations needed to ensure\nconvergence. This is the first sublinear complexity bound for pure DDPM\nsampling -- prior works which obtained such bounds worked instead with\nODE-based sampling and had to make modifications to the sampler which deviate\nfrom how they are used in practice. We also provide experimental validation of\nthe advantages of our method, showing that it performs well in practice with\npre-trained image synthesis models.", "AI": {"tldr": "Introduces the denoising diffusion randomized midpoint method (DDRaM) for DDPMs, achieving sublinear sampling complexity with respect to dimension, via a randomized midpoint integrator and the shifted composition rule. Provides theoretical guarantees (O\u02dc(\u221ad) score evaluations) and empirical validation on pre-trained image models, contrasting with prior Euler/ODE-based samplers.", "motivation": "To overcome limitations of previous DDPM discretizations (notably exponential Euler) whose guarantees scale at least linearly with dimension or Fisher information, and to obtain sublinear sampling complexity. Motivated by log-concave sampling insights (Shen & Lee, 2019) and the shifted composition rule framework.", "method": "Proposes DDRaM, an integrator that uses a randomized midpoint within the diffusion process to approximate the SDE. Analyzed under smoothness assumptions using the shifted composition rule, yielding favorable discretization properties and sublinear complexity. Provides experimental validation on pre-trained image synthesis models.", "result": "Proves a sublinear bound of ~O(\u221ad) score evaluations needed to ensure convergence for pure DDPM sampling. This is the first such sublinear complexity result for DDPM sampling (previous bounds relied on ODE-based sampling or required sampler modifications). Experimental results corroborate practical performance gains.", "conclusion": "DDRaM achieves favorable discretization properties with sublinear sampling complexity under reasonable smoothness assumptions, representing a first sublinear bound for pure DDPM sampling and showing practical effectiveness for image generation with pre-trained models."}}
{"id": "2511.05275", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05275", "abs": "https://arxiv.org/abs/2511.05275", "authors": ["Hokyun Im", "Euijin Jeong", "Jianlong Fu", "Andrey Kolobov", "Youngwoon Lee"], "title": "TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models", "comment": "Project webpage : https://jellyho.github.io/TwinVLA/", "summary": "Vision-language-action models (VLAs) trained on large-scale robotic datasets\nhave demonstrated strong performance on manipulation tasks, including bimanual\ntasks. However, because most public datasets focus on single-arm\ndemonstrations, adapting VLAs for bimanual tasks typically requires substantial\nadditional bimanual data and fine-tuning. To address this challenge, we\nintroduce TwinVLA, a modular framework that composes two copies of a pretrained\nsingle-arm VLA into a coordinated bimanual VLA. Unlike monolithic\ncross-embodiment models trained on mixtures of single-arm and bimanual data,\nTwinVLA improves both data efficiency and performance by composing pretrained\nsingle-arm policies. Across diverse bimanual tasks in real-world and simulation\nsettings, TwinVLA outperforms a comparably-sized monolithic RDT-1B model\nwithout requiring any bimanual pretraining. Furthermore, it narrows the gap to\nstate-of-the-art model, $\\pi_0$ which rely on extensive proprietary bimanual\ndata and compute cost. These results establish our modular composition approach\nas a data-efficient and scalable path toward high-performance bimanual\nmanipulation, leveraging public single-arm data.", "AI": {"tldr": "TwinVLA introduces a modular approach that pairs two pretrained single-arm VLAs to form a coordinated bimanual policy, achieving data-efficient high performance without bimanual pretraining.", "motivation": "Public datasets are dominated by single-arm demonstrations, making end-to-end bimanual VLA training data-intensive. A modular method that reuses existing single-arm data could enable effective bimanual manipulation with less data and compute.", "method": "Create TwinVLA by composing two copies of a pretrained single-arm VLA into a coordinated bimanual system. The framework is modular and does not require bimanual pretraining. The approach is evaluated on diverse bimanual tasks in real-world and simulation, and compared against a monolithic cross-embodiment model and strong baselines like RDT-1B and \u03c00.", "result": "TwinVLA achieves superior data efficiency and performance relative to a comparably-sized monolithic model and outperforms baselines without bimanual pretraining. It narrows the gap to the state-of-the-art \u03c00, which relies on extensive proprietary bimanual data and compute. The results support modular composition as a scalable, data-efficient path for high-performance bimanual manipulation.", "conclusion": "Modular composition of pretrained single-arm VLAs is a viable and scalable strategy for bimanual manipulation, enabling competitive performance using public single-arm data and avoiding large-scale bimanual pretraining."}}
{"id": "2511.04972", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04972", "abs": "https://arxiv.org/abs/2511.04972", "authors": ["Dylan Peek", "Matthew P. Skerritt", "Siddharth Pritam", "Stephan Chalup"], "title": "Challenges in 3D Data Synthesis for Training Neural Networks on Topological Features", "comment": "10 pages", "summary": "Topological Data Analysis (TDA) involves techniques of analyzing the\nunderlying structure and connectivity of data. However, traditional methods\nlike persistent homology can be computationally demanding, motivating the\ndevelopment of neural network-based estimators capable of reducing\ncomputational overhead and inference time. A key barrier to advancing these\nmethods is the lack of labeled 3D data with class distributions and diversity\ntailored specifically for supervised learning in TDA tasks. To address this, we\nintroduce a novel approach for systematically generating labeled 3D datasets\nusing the Repulsive Surface algorithm, allowing control over topological\ninvariants, such as hole count. The resulting dataset offers varied geometry\nwith topological labeling, making it suitable for training and benchmarking\nneural network estimators. This paper uses a synthetic 3D dataset to train a\ngenus estimator network, created using a 3D convolutional transformer\narchitecture. An observed decrease in accuracy as deformations increase\nhighlights the role of not just topological complexity, but also geometric\ncomplexity, when training generalized estimators. This dataset fills a gap in\nlabeled 3D datasets and generation for training and evaluating models and\ntechniques for TDA.", "AI": {"tldr": "Synthetic labeled 3D dataset for TDA developed via Repulsive Surface algorithm; enables training of neural genus estimators; shows topology alone isn't enough\u2014geometric complexity affects performance.", "motivation": "There is a lack of labeled 3D data with class distributions tailored for supervised learning in TDA tasks, making it hard to train and benchmark neural estimators that approximate persistent-homology computations.", "method": "Use the Repulsive Surface algorithm to systematically generate 3D shapes with controllable topological invariants (e.g., hole count) and attach genus-based labels. Train a genus estimator using a 3D convolutional transformer architecture. Evaluate how geometric deformations impact performance.", "result": "The estimator's accuracy decreases as deformations increase, indicating that geometric complexity, not just topological complexity, affects generalization. The dataset fills a gap in labeled 3D data for training/evaluating TDA-focused ML methods.", "conclusion": "The work provides a useful synthetic labeled 3D dataset for training and benchmarking neural estimators in TDA and highlights the need to account for geometric complexity when building generalized models."}}
{"id": "2511.04845", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04845", "abs": "https://arxiv.org/abs/2511.04845", "authors": ["Jingchen Bi", "Rodrigo Mesa-Arango"], "title": "Investigating U.S. Consumer Demand for Food Products with Innovative Transportation Certificates Based on Stated Preferences and Machine Learning Approaches", "comment": null, "summary": "This paper utilizes a machine learning model to estimate the consumer's\nbehavior for food products with innovative transportation certificates in the\nU.S. Building on previous research that examined demand for food products with\nsupply chain traceability using stated preference analysis, transportation\nfactors were identified as significant in consumer food purchasing choices.\nConsequently, a second experiment was conducted to pinpoint the specific\ntransportation attributes valued by consumers. A machine learning model was\napplied, and five innovative certificates related to transportation were\nproposed: Transportation Mode, Internet of Things (IoT), Safety measures,\nEnergy Source, and Must Arrive By Dates (MABDs). The preference experiment also\nincorporated product-specific and decision-maker factors for control purposes.\nThe findings reveal a notable inclination toward safety and energy certificates\nwithin the transportation domain of the U.S. food supply chain. Additionally,\nthe study examined the influence of price, product type, certificates, and\ndecision-maker factors on purchasing choices. Ultimately, the study offers\ndata-driven recommendations for improving food supply chain systems.", "AI": {"tldr": "ML-based analysis of consumer demand for innovative transportation certificates in U.S. food supply; finds safety and energy certificates most valued; price/product/decision-maker factors affect choices; offers data-driven supply chain recommendations.", "motivation": "To understand how transportation-related certifications influence consumer demand for food products and identify which transport attributes drive preferences, extending prior work on supply chain traceability and stated-preference methods.", "method": "Two experiments using a machine learning model. First identifies the significance of transportation factors in consumer choices for food with traceability. Second isolates specific transportation attributes (five certificates: Transportation Mode, IoT, Safety measures, Energy Source, Must Arrive By Dates) and controls for product-specific and decision-maker factors. Includes price, product type, certificates, and decision-maker factors as variables.", "result": "Consumers show a notable preference for safety and energy certificates in transportation. The model reveals the impact of price and product type, as well as certificates and decision-maker factors, on purchasing choices. The study yields data-driven recommendations to improve food supply chain systems.", "conclusion": "Findings support incorporating safety and energy-related transportation certifications into policy and business strategies to enhance consumer welfare and supply chain efficiency; demonstrates how ML can quantify attribute-level demand for traceability certificates."}}
{"id": "2511.05307", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05307", "abs": "https://arxiv.org/abs/2511.05307", "authors": ["Akua K. Dickson", "Juan C. Pacheco Garcia", "Andrew P. Sabelhaus"], "title": "Force-Safe Environment Maps and Real-Time Detection for Soft Robot Manipulators", "comment": null, "summary": "Soft robot manipulators have the potential for deployment in delicate\nenvironments to perform complex manipulation tasks. However, existing obstacle\ndetection and avoidance methods do not consider limits on the forces that\nmanipulators may exert upon contact with delicate obstacles. This work\nintroduces a framework that maps force safety criteria from task space (i.e.\npositions along the robot's body) to configuration space (i.e. the robot's\njoint angles) and enables real-time force safety detection. We incorporate\nlimits on allowable environmental contact forces for given task-space\nobstacles, and map them into configuration space (C-space) through the\nmanipulator's forward kinematics. This formulation ensures that configurations\nclassified as safe are provably below the maximum force thresholds, thereby\nallowing us to determine force-safe configurations of the soft robot\nmanipulator in real-time. We validate our approach in simulation and hardware\nexperiments on a two-segment pneumatic soft robot manipulator. Results\ndemonstrate that the proposed method accurately detects force safety during\ninteractions with deformable obstacles, thereby laying the foundation for\nreal-time safe planning of soft manipulators in delicate, cluttered\nenvironments.", "AI": {"tldr": "A force-safety aware framework for soft robot manipulators that maps contact-force limits from task space to configuration space to enable real-time force-safe manipulation in delicate environments, validated on a two-segment pneumatic soft arm.", "motivation": "Delicate obstacles require strict force limits; current obstacle avoidance often ignores interaction forces, risking damage. There is a need for real-time force-safety guarantees that respect environmental contact-force limits.", "method": "Map force safety criteria from task space to configuration space via forward kinematics, incorporating allowable contact-force limits for obstacles. Classify configurations as safe if the predicted forces remain below thresholds, enabling real-time force-safe planning. Validation performed in simulation and hardware on a two-segment pneumatic soft robot.", "result": "The approach accurately detects force safety during interactions with deformable obstacles in both simulation and hardware experiments, enabling real-time force-safe planning foundations for soft manipulators.", "conclusion": "Provides a provable notion of force safety for soft robot manipulators, enabling real-time safe planning in delicate, cluttered environments and paving the way for deployment in contact-rich tasks."}}
{"id": "2511.04977", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.04977", "abs": "https://arxiv.org/abs/2511.04977", "authors": ["Heng Er Metilda Chee", "Jiayin Wang", "Zhiqiang Guo", "Weizhi Ma", "Min Zhang"], "title": "GSE: Evaluating Sticker Visual Semantic Similarity via a General Sticker Encoder", "comment": null, "summary": "Stickers have become a popular form of visual communication, yet\nunderstanding their semantic relationships remains challenging due to their\nhighly diverse and symbolic content. In this work, we formally {define the\nSticker Semantic Similarity task} and introduce {Triple-S}, the first benchmark\nfor this task, consisting of 905 human-annotated positive and negative sticker\npairs. Through extensive evaluation, we show that existing pretrained vision\nand multimodal models struggle to capture nuanced sticker semantics. To address\nthis, we propose the {General Sticker Encoder (GSE)}, a lightweight and\nversatile model that learns robust sticker embeddings using both Triple-S and\nadditional datasets. GSE achieves superior performance on unseen stickers, and\ndemonstrates strong results on downstream tasks such as emotion classification\nand sticker-to-sticker retrieval. By releasing both Triple-S and GSE, we\nprovide standardized evaluation tools and robust embeddings, enabling future\nresearch in sticker understanding, retrieval, and multimodal content\ngeneration. The Triple-S benchmark and GSE have been publicly released and are\navailable here.", "AI": {"tldr": "Introduces Triple-S, the first benchmark for Sticker Semantic Similarity with 905 labeled sticker pairs, and General Sticker Encoder (GSE), a lightweight model that learns robust sticker embeddings using Triple-S and additional data; GSE excels on unseen stickers and downstream tasks; resources released for future research.", "motivation": "Stickers are a popular, symbolic visual language whose semantic relationships are difficult to quantify; there is a need for standardized evaluation and robust embeddings to advance sticker understanding, retrieval, and multimodal content generation.", "method": "Define the Sticker Semantic Similarity task and build Triple-S as the first benchmark with 905 human-annotated sticker pairs. Propose General Sticker Encoder (GSE), a lightweight model trained on Triple-S and additional datasets to produce robust sticker embeddings. Evaluate on unseen stickers and downstream tasks like emotion classification and sticker-to-sticker retrieval.", "result": "GSE achieves superior performance on unseen stickers and shows strong results on downstream tasks. Triple-S and GSE are publicly released to enable standardized evaluation and embeddings for sticker understanding and retrieval.", "conclusion": "The work provides standardized evaluation tools and robust embeddings that advance sticker understanding and multimodal content generation, facilitating future research in sticker-related tasks."}}
{"id": "2511.04847", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04847", "abs": "https://arxiv.org/abs/2511.04847", "authors": ["Arthur Chen", "Zuxin Liu", "Jianguo Zhang", "Akshara Prabhakar", "Zhiwei Liu", "Shelby Heinecke", "Silvio Savarese", "Victor Zhong", "Caiming Xiong"], "title": "Grounded Test-Time Adaptation for LLM Agents", "comment": "Preprint. Under review", "summary": "Large language model (LLM)-based agents struggle to generalize to novel and\ncomplex environments, such as unseen websites or new sets of functions, due to\na fundamental mismatch between their pre-training and test-time conditions.\nThis challenge stems from two distinct failure modes: a syntactic\nmisunderstanding of environment-specific components like observation formats,\nand a semantic misunderstanding of state-transition dynamics, which are only\nrevealed at test time. To address these issues, we propose two distinct and\ncomplementary strategies for adapting LLM agents by leveraging\nenvironment-specific information available during deployment. First, an online\ndistributional adaptation method parameterizes environmental nuances by\nlearning a lightweight adaptation vector that biases the model's output\ndistribution, enabling rapid alignment with an environment response format.\nSecond, a deployment-time dynamics grounding method employs a persona-driven\nexploration phase to systematically probe and learn the environment's causal\ndynamics before task execution, equipping the agent with a nonparametric world\nmodel. We evaluate these strategies across diverse agentic benchmarks,\nincluding function calling and web navigation. Our empirical results show the\neffectiveness of both strategies across all benchmarks with minimal\ncomputational cost. We find that dynamics grounding is particularly effective\nin complex environments where unpredictable dynamics pose a major obstacle,\ndemonstrating a robust path toward more generalizable and capable LLM-based\nagents. For example, on the WebArena multi-site split, this method increases\nthe agent's success rate from 2% to 23%.", "AI": {"tldr": "Two deployment-time adaptation strategies for LLM agents: online distributional adaptation to align outputs with environment formats, and dynamics grounding via persona-driven exploration to learn environment dynamics and a nonparametric world model; demonstrated on function calling and web navigation with notable gains (e.g., WebArena from 2% to 23%).", "motivation": "LLM agents fail to generalize to novel environments due to mismatches between pretraining and test-time conditions, including syntactic misunderstandings of environment data formats and semantic misunderstandings of state dynamics, which only reveal at test time.", "method": "1) online distributional adaptation: learn a lightweight adaptation vector that biases the model's output distribution to match environment response formats; 2) deployment-time dynamics grounding: a persona-driven exploration phase to probe the environment, learn causal dynamics, and construct a nonparametric world model for planning.", "result": "Both strategies improve performance across diverse benchmarks (function calling, web navigation) with minimal computational cost; dynamics grounding is especially effective in complex, unpredictable dynamics settings; WebArena multi-site split shows success rate rising from 2% to 23%.", "conclusion": "The two strategies are complementary and enable more generalizable and capable LLM-based agents; dynamics grounding provides a robust path to handle unpredictable dynamics and enhances generalization to new environments with modest overhead."}}
{"id": "2511.05379", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05379", "abs": "https://arxiv.org/abs/2511.05379", "authors": ["Eric Godden", "Jacquie Groenewegen", "Matthew K. X. J. Pan"], "title": "ETHOS: A Robotic Encountered-Type Haptic Display for Social Interaction in Virtual Reality", "comment": "8 pages", "summary": "We present ETHOS (Encountered-Type Haptics for On-demand Social Interaction),\na dynamic encountered-type haptic display (ETHD) that enables natural physical\ncontact in virtual reality (VR) during social interactions such as handovers,\nfist bumps, and high-fives. The system integrates a torque-controlled robotic\nmanipulator with interchangeable passive props (silicone hand replicas and a\nbaton), marker-based physical-virtual registration via a ChArUco board, and a\nsafety monitor that gates motion based on the user's head and hand pose. We\nintroduce two control strategies: (i) a static mode that presents a stationary\nprop aligned with its virtual counterpart, consistent with prior ETHD\nbaselines, and (ii) a dynamic mode that continuously updates prop position by\nexponentially blending an initial mid-point trajectory with real-time hand\ntracking, generating a unique contact point for each interaction. Bench tests\nshow static colocation accuracy of 5.09 +/- 0.94 mm, while user interactions\nachieved temporal alignment with an average contact latency of 28.53 +/- 31.21\nms across all interaction and control conditions. These results demonstrate the\nfeasibility of recreating socially meaningful haptics in VR. By incorporating\nessential safety and control mechanisms, ETHOS establishes a practical\nfoundation for high-fidelity, dynamic interpersonal interactions in virtual\nenvironments.", "AI": {"tldr": "ETHOS is a dynamic encountered-type haptic display for natural VR social touch, using a torque-controlled manipulator with interchangeable props, marker-based registration, and safety gating; it offers static and dynamic control modes with measurable alignment (\u22485 mm) and contact latency (~29 ms).", "motivation": "To enable natural, contact-rich social interactions in VR (e.g., handovers, fist bumps, high-fives) by addressing the limitations of static haptic displays and enhancing realism through dynamic prop positioning and safety controls.", "method": "Hardware: torque-controlled robotic manipulator; interchangeable passive props (silicone hand replicas, baton); marker-based physical-virtual registration using a ChArUco board; safety monitor gating motion by head/hand pose. Control strategies: (i) static mode with stationary prop aligned to virtual counterpart, (ii) dynamic mode that updates prop position via exponential blending of an initial mid-point trajectory with real-time hand tracking to create a unique contact point per interaction. Evaluation included bench tests for colocated accuracy and user experiments measuring contact latency.", "result": "Static colocated accuracy: 5.09 \u00b1 0.94 mm. User interactions achieved average contact latency of 28.53 \u00b1 31.21 ms across all conditions. The system demonstrates feasibility of recreating socially meaningful haptics in VR, with safety and control mechanisms enabling high-fidelity dynamic interpersonal interactions.", "conclusion": "ETHOS provides a practical foundation for high-fidelity, dynamic interpersonal haptics in VR, balancing realistic contact with safety through well-integrated hardware, tracking, and control strategies."}}
{"id": "2511.05017", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.05017", "abs": "https://arxiv.org/abs/2511.05017", "authors": ["Aakriti Agrawal", "Gouthaman KV", "Rohith Aralikatti", "Gauri Jagatap", "Jiaxin Yuan", "Vijay Kamarshi", "Andrea Fanelli", "Furong Huang"], "title": "Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings", "comment": null, "summary": "In this work, we identify an inherent bias in prevailing LVLM architectures\ntoward the language modality, largely resulting from the common practice of\nsimply appending visual embeddings to the input text sequence. To address this,\nwe propose a simple yet effective method that refines textual embeddings by\nintegrating average-pooled visual features. Our approach demonstrably improves\nvisual grounding and significantly reduces hallucinations on established\nbenchmarks. While average pooling offers a straightforward, robust, and\nefficient means of incorporating visual information, we believe that more\nsophisticated fusion methods could further enhance visual grounding and\ncross-modal alignment. Given that the primary focus of this work is to\nhighlight the modality imbalance and its impact on hallucinations -- and to\nshow that refining textual embeddings with visual information mitigates this\nissue -- we leave exploration of advanced fusion strategies for future work.", "AI": {"tldr": "A lightweight fusion of average-pooled visual features into textual embeddings to reduce modality bias and hallucinations in LVLMs, improving visual grounding.", "motivation": "Prevailing LVLM architectures exhibit an inherent bias toward language because visual information is often appended to text input, causing modality imbalance and hallucinations. A simple method to rebalance by enriching textual embeddings with visual cues aims to improve grounding.", "method": "Refine textual embeddings by integrating average-pooled visual features into the text representation. The approach is simple, robust, and efficient, avoiding complex cross-modal fusion.", "result": "The method improves visual grounding and significantly reduces hallucinations on established benchmarks.", "conclusion": "Average-pooling provides a simple, robust means to incorporate visual information and mitigate modality imbalance. The authors acknowledge that more sophisticated fusion strategies could further enhance cross-modal alignment and grounding and leave such exploration for future work."}}
{"id": "2511.04854", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.04854", "abs": "https://arxiv.org/abs/2511.04854", "authors": ["Alvaro Prat", "Leo Zhang", "Charlotte M. Deane", "Yee Whye Teh", "Garrett M. Morris"], "title": "SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3) Diffusion", "comment": "Preprint", "summary": "Determining the binding pose of a ligand to a protein, known as molecular\ndocking, is a fundamental task in drug discovery. Generative approaches promise\nfaster, improved, and more diverse pose sampling than physics-based methods,\nbut are often hindered by chemically implausible outputs, poor\ngeneralisability, and high computational cost. To address these challenges, we\nintroduce a novel fragmentation scheme, leveraging inductive biases from\nstructural chemistry, to decompose ligands into rigid-body fragments. Building\non this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion\nmodel that generates poses by learning to reassemble these rigid bodies within\nthe binding pocket. By operating at the level of fragments in SE(3), SigmaDock\nexploits well-established geometric priors while avoiding overly complex\ndiffusion processes and unstable training dynamics. Experimentally, we show\nSigmaDock achieves state-of-the-art performance, reaching Top-1 success rates\n(RMSD<2 & PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8%\nreported by recent deep learning approaches, whilst demonstrating consistent\ngeneralisation to unseen proteins. SigmaDock is the first deep learning\napproach to surpass classical physics-based docking under the PB train-test\nsplit, marking a significant leap forward in the reliability and feasibility of\ndeep learning for molecular modelling.", "AI": {"tldr": "A fragment-based SE(3) diffusion model (SigmaDock) for ligand docking achieves state-of-the-art pose generation, generalizes to new proteins, and even surpasses classical physics-based docking on PB train-test.", "motivation": "Address weaknesses of generative docking methods (chemically implausible outputs, limited generalizability, high computational cost) by introducing chemically informed fragmentation and geometric priors.", "method": "Fragment ligands into rigid-body pieces and apply SigmaDock, an SE(3) Riemannian diffusion model, to reassemble these fragments inside the binding pocket, leveraging fragment-level geometry to simplify diffusion and improve stability.", "result": "Achieves Top-1 success rate (RMSD<2 & PB-valid) >79.9% on PoseBusters, substantially higher than recent DL methods (12.7\u201330.8%); demonstrates generalization to unseen proteins; first DL approach to surpass physics-based docking under PB train-test split.", "conclusion": "Fragment-based SE(3) diffusion for docking markedly improves reliability and generalizability of deep learning docking, representing a significant advance over both prior DL methods and classical physics-based docking."}}
{"id": "2511.05397", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05397", "abs": "https://arxiv.org/abs/2511.05397", "authors": ["Samarth Chopra", "Alex McMoil", "Ben Carnovale", "Evan Sokolson", "Rajkumar Kubendran", "Samuel Dickerson"], "title": "EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation", "comment": "Submitted to ICRA 2026", "summary": "While Vision-Language-Action (VLA) models map visual inputs and language\ninstructions directly to robot actions, they often rely on costly hardware and\nstruggle in novel or cluttered scenes. We introduce EverydayVLA, a 6-DOF\nmanipulator that can be assembled for under $300, capable of modest payloads\nand workspace. A single unified model jointly outputs discrete and continuous\nactions, and our adaptive-horizon ensemble monitors motion uncertainty to\ntrigger on-the-fly re-planning for safe, reliable operation. On LIBERO,\nEverydayVLA matches state-of-the-art success rates, and in real-world tests it\noutperforms prior methods by 49% in-distribution and 34.9% out-of-distribution.\nBy combining a state-of-the-art VLA with cost-effective hardware, EverydayVLA\ndemocratizes access to a robotic foundation model and paves the way for\neconomical use in homes and research labs alike. Experiment videos and details:\nhttps://everydayvla.github.io/", "AI": {"tldr": "Low-cost, assemble-it-yourself 6-DOF robot uses a unified vision-language-action model with adaptive re-planning, achieving strong performance and enabling broader access to robotic foundation models.", "motivation": "VLA models for robotics often rely on expensive hardware and underperform in novel or cluttered scenes. There is a need for affordable, reliable, and broadly accessible robotic systems that can operate in real-world environments.", "method": "Introduces EverydayVLA, a ~$300 6-DOF manipulator; a single unified model outputs discrete and continuous actions; an adaptive-horizon ensemble monitors motion uncertainty to trigger on-the-fly re-planning for safe operation; evaluated on LIBERO and in real-world tests.", "result": "On LIBERO, EverydayVLA matches state-of-the-art success rates; in real-world tests it outperforms prior methods by 49% in-distribution and 34.9% out-of-distribution.", "conclusion": "Coupling a state-of-the-art VLA framework with cost-effective hardware democratizes access to a robotic foundation model, enabling economical use in homes and research labs; experiment videos and details are provided."}}
{"id": "2511.05034", "categories": ["cs.CV", "cs.AI", "I.4.9; I.2.10"], "pdf": "https://arxiv.org/pdf/2511.05034", "abs": "https://arxiv.org/abs/2511.05034", "authors": ["Jing Jin", "Xu Liu", "Te Gao", "Zhihong Shi", "Yixiong Liang", "Ruiqing Zheng", "Hulin Kuang", "Min Zeng", "Shichao Kan"], "title": "Dynamic Residual Encoding with Slide-Level Contrastive Learning for End-to-End Whole Slide Image Representation", "comment": "8pages, 3figures, published to ACM Digital Library", "summary": "Whole Slide Image (WSI) representation is critical for cancer subtyping,\ncancer recognition and mutation prediction.Training an end-to-end WSI\nrepresentation model poses significant challenges, as a standard gigapixel\nslide can contain tens of thousands of image tiles, making it difficult to\ncompute gradients of all tiles in a single mini-batch due to current GPU\nlimitations. To address this challenge, we propose a method of dynamic residual\nencoding with slide-level contrastive learning (DRE-SLCL) for end-to-end WSI\nrepresentation. Our approach utilizes a memory bank to store the features of\ntiles across all WSIs in the dataset. During training, a mini-batch usually\ncontains multiple WSIs. For each WSI in the batch, a subset of tiles is\nrandomly sampled and their features are computed using a tile encoder. Then,\nadditional tile features from the same WSI are selected from the memory bank.\nThe representation of each individual WSI is generated using a residual\nencoding technique that incorporates both the sampled features and those\nretrieved from the memory bank. Finally, the slide-level contrastive loss is\ncomputed based on the representations and histopathology reports ofthe WSIs\nwithin the mini-batch. Experiments conducted over cancer subtyping, cancer\nrecognition, and mutation prediction tasks proved the effectiveness of the\nproposed DRE-SLCL method.", "AI": {"tldr": "A dynamic residual encoding with slide-level contrastive learning (DRE-SLCL) approach for end-to-end WSI representation leverages a memory bank of tile features, sampling tiles per WSI per batch, retrieving additional tiles from memory, and fusing them via residual encoding to produce slide representations for slide-level contrastive learning across WSIs.", "motivation": "Whole-slide images contain tens of thousands of tiles, making end-to-end training with full gradient flow infeasible on standard GPUs. There is a need for scalable, discriminative slide-level representations that can leverage local tile information without exhaustively processing all tiles in every batch.", "method": "In each training batch, sample a subset of tiles per WSI and compute their features with a tile encoder. Retrieve additional tile features for the same WSI from a memory bank that stores features across all WSIs. Use a residual encoding scheme to combine sampled and retrieved features into a single WSI representation. Compute a slide-level contrastive loss using the produced representations and the corresponding histopathology reports within the batch.", "result": "Experiments on cancer subtyping, recognition, and mutation prediction show that DRE-SLCL effectively learns end-to-end WSI representations, outperforming baselines on these tasks.", "conclusion": "DRE-SLCL provides a scalable and effective end-to-end framework for WSI representation learning by integrating memory-based tile retrieval with residual encoding and slide-level contrastive learning to leverage both local and global slide information."}}
{"id": "2511.04856", "categories": ["cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.04856", "abs": "https://arxiv.org/abs/2511.04856", "authors": ["Thore Gerlach", "Michael Schenk", "Verena Kain"], "title": "Quantum Boltzmann Machines for Sample-Efficient Reinforcement Learning", "comment": null, "summary": "We introduce theoretically grounded Continuous Semi-Quantum Boltzmann\nMachines (CSQBMs) that supports continuous-action reinforcement learning. By\ncombining exponential-family priors over visible units with quantum Boltzmann\ndistributions over hidden units, CSQBMs yield a hybrid quantum-classical model\nthat reduces qubit requirements while retaining strong expressiveness.\nCrucially, gradients with respect to continuous variables can be computed\nanalytically, enabling direct integration into Actor-Critic algorithms.\nBuilding on this, we propose a continuous Q-learning framework that replaces\nglobal maximization by efficient sampling from the CSQBM distribution, thereby\novercoming instability issues in continuous control.", "AI": {"tldr": "Introduces Continuous Semi-Quantum Boltzmann Machines (CSQBMs) for continuous-action RL; a hybrid quantum-classical model enabling analytic gradients and sampling-based Q-learning to improve stability.", "motivation": "Aim to reduce qubit requirements while preserving expressiveness in reinforcement learning, and to enable analytic gradient computation for seamless integration into Actor-Critic methods; address instability in continuous control.", "method": "Form CSQBMs by combining exponential-family priors over visible units with quantum Boltzmann distributions over hidden units, creating a hybrid model. Derive analytic gradients w.r.t. continuous variables. Propose a continuous Q-learning framework that uses sampling from the CSQBM distribution instead of global maximization and integrate into Actor-Critic architectures.", "result": "Establishes a theoretically grounded hybrid model with reduced quantum resource needs, tractable gradient computations for continuous actions, and a sampling-based Q-learning approach that can stabilize training in continuous control tasks.", "conclusion": "CSQBMs offer a promising quantum-inspired pathway for efficient and stable continuous-action RL, combining strong expressiveness with analytic tractability and sampling-based optimization."}}
{"id": "2511.04902", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04902", "abs": "https://arxiv.org/abs/2511.04902", "authors": ["Shuvendu Roy", "Hossein Hajimirsadeghi", "Mengyao Zhai", "Golnoosh Samei"], "title": "You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Workshop: MATH-AI", "summary": "Recent advances in large language models have demonstrated the promise of\nunsupervised reinforcement learning (RL) methods for enhancing reasoning\ncapabilities without external supervision. However, the generalizability of\nthese label-free RL approaches to smaller base models with limited reasoning\ncapabilities remains unexplored. In this work, we systematically investigate\nthe performance of label-free RL methods across different model sizes and\nreasoning strengths, from 0.5B to 7B parameters. Our empirical analysis reveals\ncritical limitations: label-free RL is highly dependent on the base model's\npre-existing reasoning capability, with performance often degrading below\nbaseline levels for weaker models. We find that smaller models fail to generate\nsufficiently long or diverse chain-of-thought reasoning to enable effective\nself-reflection, and that training data difficulty plays a crucial role in\ndetermining success. To address these challenges, we propose a simple yet\neffective method for label-free RL that utilizes curriculum learning to\nprogressively introduce harder problems during training and mask no-majority\nrollouts during training. Additionally, we introduce a data curation pipeline\nto generate samples with predefined difficulty. Our approach demonstrates\nconsistent improvements across all model sizes and reasoning capabilities,\nproviding a path toward more robust unsupervised RL that can bootstrap\nreasoning abilities in resource-constrained models. We make our code available\nat https://github.com/BorealisAI/CuMa", "AI": {"tldr": "Label-free RL effectiveness hinges on base model reasoning; curriculum learning and data curation can robustly boost performance across 0.5B\u20137B models.", "motivation": "Investigate generalizability of label-free RL to smaller models; identify limitations when base model has limited reasoning ability; understand role of data difficulty in success.", "method": "Systematically evaluate label-free RL across model sizes (0.5B\u20137B). Propose curriculum learning to progressively introduce harder problems and mask non-majority rollouts. Introduce a data curation pipeline to generate samples with predefined difficulty.", "result": "Observe consistent improvements across all model sizes and reasoning capabilities; reveal that weaker models struggle to generate sufficient chain-of-thought; highlight the importance of data difficulty; demonstrate robustness gains with curriculum and data curation.", "conclusion": "Provides a path toward more robust unsupervised RL that can bootstrap reasoning abilities in resource-constrained models; code is released for reproducibility."}}
{"id": "2511.05402", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05402", "abs": "https://arxiv.org/abs/2511.05402", "authors": ["Muhammad Saud Ul Hassan", "Derek Vasquez", "Hamza Asif", "Christian Hubicki"], "title": "Stable and Robust SLIP Model Control via Energy Conservation-Based Feedback Cancellation for Quadrupedal Applications", "comment": null, "summary": "In this paper, we present an energy-conservation based control architecture\nfor stable dynamic motion in quadruped robots. We model the robot as a\nSpring-loaded Inverted Pendulum (SLIP), a model well-suited to represent the\nbouncing motion characteristic of running gaits observed in various biological\nquadrupeds and bio-inspired robotic systems. The model permits leg-orientation\ncontrol during flight and leg-length control during stance, a design choice\ninspired by natural quadruped behaviors and prevalent in robotic quadruped\nsystems. Our control algorithm uses the reduced-order SLIP dynamics of the\nquadruped to track a stable parabolic spline during stance, which is calculated\nusing the principle of energy conservation. Through simulations based on the\ndesign specifications of an actual quadruped robot, Ghost Robotics Minitaur, we\ndemonstrate that our control algorithm generates stable bouncing gaits.\nAdditionally, we illustrate the robustness of our controller by showcasing its\nability to maintain stable bouncing even when faced with up to a 10% error in\nsensor measurements.", "AI": {"tldr": "An energy-conservation-based control architecture for stable dynamic quadruped running using a SLIP model, enabling leg orientation in flight and leg-length control during stance to track a stable parabolic spline; simulations on Ghost Robotics Minitaur show robust bouncing, even with up to 10% sensor error.", "motivation": "To achieve robust, dynamic running gaits in quadrupeds by leveraging a reduced-order SLIP model and energy-conserving control to replicate stable bouncing behavior observed in biological and bio-inspired robots.", "method": "Model the quadruped with a spring-loaded inverted pendulum (SLIP). Use leg orientation control in flight and leg-length control in stance. Compute a target stable parabolic spline during stance via energy conservation, and validate via simulations based on Ghost Robotics Minitaur.", "result": "The control law enables stable bouncing gaits in simulation and demonstrates robustness to sensor measurement errors up to 10%.", "conclusion": "An energy-conservation-based SLIP controller can achieve stable, robust dynamic locomotion in quadrupeds, suggesting viability for bio-inspired quadruped robots and potential real-world deployment."}}
{"id": "2511.05038", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05038", "abs": "https://arxiv.org/abs/2511.05038", "authors": ["Zhengxuan Li", "Qinhui Yang", "Yiyu Zhuang", "Chuan Guo", "Xinxin Zuo", "Xiaoxiao Long", "Yao Yao", "Xun Cao", "Qiu Shen", "Hao Zhu"], "title": "Pressure2Motion: Hierarchical Motion Synthesis from Ground Pressure with Text Guidance", "comment": null, "summary": "We present Pressure2Motion, a novel motion capture algorithm that synthesizes\nhuman motion from a ground pressure sequence and text prompt. It eliminates the\nneed for specialized lighting setups, cameras, or wearable devices, making it\nsuitable for privacy-preserving, low-light, and low-cost motion capture\nscenarios. Such a task is severely ill-posed due to the indeterminate nature of\nthe pressure signals to full-body motion. To address this issue, we introduce\nPressure2Motion, a generative model that leverages pressure features as input\nand utilizes a text prompt as a high-level guiding constraint. Specifically,\nour model utilizes a dual-level feature extractor that accurately interprets\npressure data, followed by a hierarchical diffusion model that discerns\nbroad-scale movement trajectories and subtle posture adjustments. Both the\nphysical cues gained from the pressure sequence and the semantic guidance\nderived from descriptive texts are leveraged to guide the motion generation\nwith precision. To the best of our knowledge, Pressure2Motion is a pioneering\nwork in leveraging both pressure data and linguistic priors for motion\ngeneration, and the established MPL benchmark is the first benchmark for this\ntask. Experiments show our method generates high-fidelity, physically plausible\nmotions, establishing a new state-of-the-art for this task. The codes and\nbenchmarks will be publicly released upon publication.", "AI": {"tldr": "Pressure2Motion synthesizes human motion from ground pressure sequences plus text prompts, enabling privacy-preserving, camera-free motion capture; it uses a dual-level feature extractor and a hierarchical diffusion model, and introduces the MPL benchmark with claimed state-of-the-art results.", "motivation": "Mocap from pressure data is severely ill-posed due to the indeterminate mapping from pressure signals to full-body motion; there is a need for privacy-preserving, low-cost, camera-free mocap, and linguistic priors may help constrain the generation.", "method": "A dual-level pressure feature extractor interprets pressure data; a hierarchical diffusion model generates motion by modeling broad trajectories and fine postures; text prompts serve as high-level guidance constraints; a new MPL benchmark is established for this task.", "result": "Experiments report high-fidelity, physically plausible motions and state-of-the-art performance on the MPL benchmark; codes and benchmarks will be released publicly.", "conclusion": "Pressure2Motion pioneers the use of both pressure data and linguistic priors for motion generation, establishing a new research direction and providing a standard benchmark (MPL) for this task; this approach promises privacy-preserving, low-cost mocap applications."}}
{"id": "2511.04865", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04865", "abs": "https://arxiv.org/abs/2511.04865", "authors": ["Esha Sharma", "Lauren Davis", "Julie Ivy", "Min Chi"], "title": "FoodRL: A Reinforcement Learning Ensembling Framework For In-Kind Food Donation Forecasting", "comment": null, "summary": "Food banks are crucial for alleviating food insecurity, but their\neffectiveness hinges on accurately forecasting highly volatile in-kind\ndonations to ensure equitable and efficient resource distribution. Traditional\nforecasting models often fail to maintain consistent accuracy due to\nunpredictable fluctuations and concept drift driven by seasonal variations and\nnatural disasters such as hurricanes in the Southeastern U.S. and wildfires in\nthe West Coast. To address these challenges, we propose FoodRL, a novel\nreinforcement learning (RL) based metalearning framework that clusters and\ndynamically weights diverse forecasting models based on recent performance and\ncontextual information. Evaluated on multi-year data from two structurally\ndistinct U.S. food banks-one large regional West Coast food bank affected by\nwildfires and another state-level East Coast food bank consistently impacted by\nhurricanes, FoodRL consistently outperforms baseline methods, particularly\nduring periods of disruption or decline. By delivering more reliable and\nadaptive forecasts, FoodRL can facilitate the redistribution of food equivalent\nto 1.7 million additional meals annually, demonstrating its significant\npotential for social impact as well as adaptive ensemble learning for\nhumanitarian supply chains.", "AI": {"tldr": "FoodRL is a reinforcement learning\u2013based metalearning framework that ensembles diverse forecasting models to predict volatile in-kind donations for food banks, achieving more accurate forecasts and potential social impact (up to 1.7M additional meals annually) especially during disruptions.", "motivation": "Forecasting highly volatile in-kind donations is challenged by concept drift from seasonal variation and disasters; traditional models struggle to adapt. There is a need for adaptive, context-aware ensemble methods to support equitable resource distribution in humanitarian supply chains.", "method": "Reinforcement-learning-based metalearning framework that clusters and dynamically weights forecasting models based on recent performance and contextual information; evaluated on two structurally distinct U.S. food banks (West Coast wildfire-impacted and East Coast hurricane-impacted).", "result": "FoodRL consistently outperforms baseline methods, particularly during disruption periods; improved forecast reliability and potential redistribution of sufficient food to meet about 1.7 million additional meals annually.", "conclusion": "Adaptive ensemble learning via RL-based metalearning can enhance forecasting under volatility and concept drift in humanitarian logistics, with notable social impact; broader validation across more sites would strengthen its generalizability."}}
{"id": "2511.04909", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04909", "abs": "https://arxiv.org/abs/2511.04909", "authors": ["Paula Rodriguez-Diaz", "Kirk Bansak Elisabeth Paulson"], "title": "A Dual Perspective on Decision-Focused Learning: Scalable Training via Dual-Guided Surrogates", "comment": null, "summary": "Many real-world decisions are made under uncertainty by solving optimization\nproblems using predicted quantities. This predict-then-optimize paradigm has\nmotivated decision-focused learning, which trains models with awareness of how\nthe optimizer uses predictions, improving the performance of downstream\ndecisions. Despite its promise, scaling is challenging: state-of-the-art\nmethods either differentiate through a solver or rely on task-specific\nsurrogates, both of which require frequent and expensive calls to an optimizer,\noften a combinatorial one. In this paper, we leverage dual variables from the\ndownstream problem to shape learning and introduce Dual-Guided Loss (DGL), a\nsimple, scalable objective that preserves decision alignment while reducing\nsolver dependence. We construct DGL specifically for combinatorial selection\nproblems with natural one-of-many constraints, such as matching, knapsack, and\nshortest path. Our approach (a) decouples optimization from gradient updates by\nsolving the downstream problem only periodically; (b) between refreshes, trains\non dual-adjusted targets using simple differentiable surrogate losses; and (c)\nas refreshes become less frequent, drives training cost toward standard\nsupervised learning while retaining strong decision alignment. We prove that\nDGL has asymptotically diminishing decision regret, analyze runtime complexity,\nand show on two problem classes that DGL matches or exceeds state-of-the-art\nDFL methods while using far fewer solver calls and substantially less training\ntime. Code is available at https://github.com/paularodr/Dual-Guided-Learning.", "AI": {"tldr": "Dual-Guided Learning (DGL) is a scalable, decision-aligned learning objective for predict-then-optimize that minimizes reliance on expensive solvers by periodically refreshing dual variables and training with dual-adjusted targets. It matches or surpasses state-of-the-art differentiable learning (DFL) on combinatorial problems while drastically reducing solver calls and training time.", "motivation": "In decision-making under uncertainty, predictions feed optimization; standard training ignores the downstream optimizer, leading to suboptimal decisions. Differentiating through solvers or using surrogates is costly. DGL leverages dual information to ensure alignment between predictions and optimal decisions with fewer solver invocations.", "method": "For combinatorial one-of-many constraints (matching, knapsack, shortest path), DGL periodically solves the downstream problem to obtain dual variables, then trains between refreshes using differentiable surrogates augmented with dual-adjusted targets. As refresh frequency decreases, training approaches standard supervised learning while preserving decision alignment.", "result": "Proves asymptotically diminishing decision regret; analyzes runtime; empirical results on two problem classes show DGL matches or exceeds state-of-the-art DFL with far fewer solver calls and substantially less training time.", "conclusion": "DGL offers a scalable, decision-aligned alternative to full differentiable optimization, enabling practical deployment for large-scale decision problems with limited solver usage; code available."}}
{"id": "2511.05426", "categories": ["cs.RO", "J.2"], "pdf": "https://arxiv.org/pdf/2511.05426", "abs": "https://arxiv.org/abs/2511.05426", "authors": ["Luca Girardi", "Gabriel Maquignaz", "Stefano Mintchev"], "title": "Bioinspired Soft Quadrotors Jointly Unlock Agility, Squeezability, and Collision Resilience", "comment": "26 pages, 12 figures, 2 tables, 9 videos (not yet disclosed, awaiting\n  peer review)", "summary": "Natural flyers use soft wings to seamlessly enable a wide range of flight\nbehaviours, including agile manoeuvres, squeezing through narrow passageways,\nand withstanding collisions. In contrast, conventional quadrotor designs rely\non rigid frames that support agile flight but inherently limit collision\nresilience and squeezability, thereby constraining flight capabilities in\ncluttered environments. Inspired by the anisotropic stiffness and distributed\nmass-energy structures observed in biological organisms, we introduce\nFlexiQuad, a soft-frame quadrotor design approach that limits this trade-off.\nWe demonstrate a 405-gram FlexiQuad prototype, three orders of magnitude more\ncompliant than conventional quadrotors, yet capable of acrobatic manoeuvres\nwith peak speeds above 80 km/h and linear and angular accelerations exceeding 3\ng and 300 rad/s$^2$, respectively. Analysis demonstrates it can replicate\naccelerations of rigid counterparts up to a thrust-to-weight ratio of 8.\nSimultaneously, FlexiQuad exhibits fourfold higher collision resilience,\nsurviving frontal impacts at 5 m/s without damage and reducing destabilising\nforces in glancing collisions by a factor of 39. Its frame can fully compress,\nenabling flight through gaps as narrow as 70% of its nominal width. Our\nanalysis identifies an optimal structural softness range, from 0.006 to 0.77\nN/mm, comparable to that of natural flyers' wings, whereby agility,\nsqueezability, and collision resilience are jointly achieved for FlexiQuad\nmodels from 20 to 3000 grams. FlexiQuad expands hovering drone capabilities in\ncomplex environments, enabling robust physical interactions without\ncompromising flight performance.", "AI": {"tldr": "Soft-frame quadrotor FlexiQuad combines high deformability with agile flight, enabling squeezability and collision resilience, with a 405 g prototype achieving speeds over 80 km/h, accelerations up to 3 g linear and 300 rad/s^2, thrust-to-weight up to 8, and improved collision resilience; optimal softness 0.006\u20130.77 N/mm, scalable from 20\u20133000 g.", "motivation": "To overcome the limitations of rigid quadrotors in cluttered environments by introducing a soft-frame design inspired by natural flyers' anisotropic stiffness and distributed mass-energy, enabling safety-critical interactions without sacrificing performance.", "method": "Design and test a soft-frame quadrotor (FlexiQuad) ~405 g; characterize flight performance (speed, accelerations), collision resilience (frontal/glancing), and compressibility through gaps; perform parametric analysis of frame softness to identify an optimal range; assess scalability to other masses (20\u20133000 g).", "result": "Prototype demonstrates high-speed acrobatics and extreme accelerations while being far more compliant; thrust-to-weight up to 8 comparable to rigid quads; fourfold higher collision resilience; survivable frontal impacts at 5 m/s; reduced forces in glancing collisions by 39x; enables passage through gaps equal to 70% of nominal width; optimal softness 0.006\u20130.77 N/mm; scalable 20\u20133000 g.", "conclusion": "FlexiQuad expands drone capabilities in cluttered environments by enabling robust physical interactions without sacrificing flight performance; identifies a practical softness window and suggests broad applicability across sizes."}}
{"id": "2511.05044", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05044", "abs": "https://arxiv.org/abs/2511.05044", "authors": ["Xinyu Chen", "Yiran Wang", "Gaoyang Pang", "Jiafu Hao", "Chentao Yue", "Luping Zhou", "Yonghui Li"], "title": "Medical Referring Image Segmentation via Next-Token Mask Prediction", "comment": "This work has been submitted to the IEEE Transactions on Medical\n  Imaging for possible publication", "summary": "Medical Referring Image Segmentation (MRIS) involves segmenting target\nregions in medical images based on natural language descriptions. While\nachieving promising results, recent approaches usually involve complex design\nof multimodal fusion or multi-stage decoders. In this work, we propose\nNTP-MRISeg, a novel framework that reformulates MRIS as an autoregressive\nnext-token prediction task over a unified multimodal sequence of tokenized\nimage, text, and mask representations. This formulation streamlines model\ndesign by eliminating the need for modality-specific fusion and external\nsegmentation models, supports a unified architecture for end-to-end training.\nIt also enables the use of pretrained tokenizers from emerging large-scale\nmultimodal models, enhancing generalization and adaptability. More importantly,\nto address challenges under this formulation-such as exposure bias, long-tail\ntoken distributions, and fine-grained lesion edges-we propose three novel\nstrategies: (1) a Next-k Token Prediction (NkTP) scheme to reduce cumulative\nprediction errors, (2) Token-level Contrastive Learning (TCL) to enhance\nboundary sensitivity and mitigate long-tail distribution effects, and (3) a\nmemory-based Hard Error Token (HET) optimization strategy that emphasizes\ndifficult tokens during training. Extensive experiments on the QaTa-COV19 and\nMosMedData+ datasets demonstrate that NTP-MRISeg achieves new state-of-the-art\nperformance, offering a streamlined and effective alternative to traditional\nMRIS pipelines.", "AI": {"tldr": "Reframe MRIS as autoregressive next-token prediction over a unified multimodal sequence, enabling a simple, end-to-end architecture that leverages pretrained tokenizers; introduces NkTP, TCL, and HET to tackle exposure bias, long-tail token distributions, and fine-grained edges, achieving state-of-the-art on QaTa-COV19 and MosMedData+.", "motivation": "MRIS tasks traditionally rely on complex multimodal fusion modules and multi-stage decoders, making models bulky and harder to train end-to-end. A unified, token-based formulation could simplify design, leverage pretrained multimodal tokenizers, and improve generalization across datasets.", "method": "Formulates MRIS as autoregressive next-token prediction over a single multimodal sequence containing image, text, and mask tokens. Utilizes pretrained tokenizers from large multimodal models. Introduces three strategies: (1) Next-k Token Prediction (NkTP) to reduce error accumulation, (2) Token-level Contrastive Learning (TCL) to sharpen boundaries and mitigate long-tail token frequencies, and (3) memory-based Hard Error Token (HET) optimization to emphasize difficult tokens during training.", "result": "On QaTa-COV19 and MosMedData+ datasets, the approach achieves new state-of-the-art performance, while offering a streamlined, end-to-end pipeline without modality-specific fusion or external segmentation models.", "conclusion": "Reframing MRIS as a unified autoregressive token prediction task with targeted training strategies yields superior performance and a simpler, more adaptable architecture, highlighting the viability of token-based, end-to-end MRIS models leveraging pretrained multimodal tokenizers."}}
{"id": "2511.04883", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04883", "abs": "https://arxiv.org/abs/2511.04883", "authors": ["Di Chen", "Jia Li", "Michael Zhang"], "title": "Self-Interest and Systemic Benefits: Emergence of Collective Rationality in Mixed Autonomy Traffic Through Deep Reinforcement Learning", "comment": null, "summary": "Autonomous vehicles (AVs) are expected to be commercially available in the\nnear future, leading to mixed autonomy traffic consisting of both AVs and\nhuman-driven vehicles (HVs). Although numerous studies have shown that AVs can\nbe deployed to benefit the overall traffic system performance by incorporating\nsystem-level goals into their decision making, it is not clear whether the\nbenefits still exist when agents act out of self-interest -- a trait common to\nall driving agents, both human and autonomous. This study aims to understand\nwhether self-interested AVs can bring benefits to all driving agents in mixed\nautonomy traffic systems. The research is centered on the concept of collective\nrationality (CR). This concept, originating from game theory and behavioral\neconomics, means that driving agents may cooperate collectively even when\npursuing individual interests. Our recent research has proven the existence of\nCR in an analytical game-theoretical model and empirically in mixed\nhuman-driven traffic. In this paper, we demonstrate that CR can be attained\namong driving agents trained using deep reinforcement learning (DRL) with a\nsimple reward design. We examine the extent to which self-interested traffic\nagents can achieve CR without directly incorporating system-level objectives.\nResults show that CR consistently emerges in various scenarios, which indicates\nthe robustness of this property. We also postulate a mechanism to explain the\nemergence of CR in the microscopic and dynamic environment and verify it based\non simulation evidence. This research suggests the possibility of leveraging\nadvanced learning methods (such as federated learning) to achieve collective\ncooperation among self-interested driving agents in mixed-autonomy systems.", "AI": {"tldr": "Self-interested DRL-driven autonomous vehicles in mixed traffic can naturally develop collective rationality (CR), enabling cooperation and potential system-wide benefits without explicit optimization, across diverse scenarios.", "motivation": "To determine whether CR can emerge among DRL-trained driving agents in mixed-autonomy traffic, addressing whether selfish incentives undermine system-wide gains and exploring mechanisms for cooperative behavior.", "method": "Train autonomous-vehicle agents with a simple reward design using deep reinforcement learning, simulate mixed traffic with AVs and HVs across multiple scenarios, evaluate emergence and robustness of CR, propose a mechanism explaining CR emergence, verify via simulation, and discuss implications for federated learning as a route to promote cooperation.", "result": "CR emerges consistently across scenarios among self-interested DRL agents, indicating robust cooperative behavior without explicit system-level objectives; a mechanism is proposed and simulation-supported; Federated learning is suggested as a potential approach to facilitate such cooperation.", "conclusion": "CR among self-interested driving agents trained with DRL is attainable, implying that system-wide benefits can arise without hard-coding global objectives, and offering directions for future research and applications in mixed autonomy with learning-based agents."}}
{"id": "2511.05005", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.05005", "abs": "https://arxiv.org/abs/2511.05005", "authors": ["Dongsu Lee", "Daehee Lee", "Amy Zhang"], "title": "Multi-agent Coordination via Flow Matching", "comment": null, "summary": "This work presents MAC-Flow, a simple yet expressive framework for\nmulti-agent coordination. We argue that requirements of effective coordination\nare twofold: (i) a rich representation of the diverse joint behaviors present\nin offline data and (ii) the ability to act efficiently in real time. However,\nprior approaches often sacrifice one for the other, i.e., denoising\ndiffusion-based solutions capture complex coordination but are computationally\nslow, while Gaussian policy-based solutions are fast but brittle in handling\nmulti-agent interaction. MAC-Flow addresses this trade-off by first learning a\nflow-based representation of joint behaviors, and then distilling it into\ndecentralized one-step policies that preserve coordination while enabling fast\nexecution. Across four different benchmarks, including $12$ environments and\n$34$ datasets, MAC-Flow alleviates the trade-off between performance and\ncomputational cost, specifically achieving about $\\boldsymbol{\\times14.5}$\nfaster inference compared to diffusion-based MARL methods, while maintaining\ngood performance. At the same time, its inference speed is similar to that of\nprior Gaussian policy-based offline multi-agent reinforcement learning (MARL)\nmethods.", "AI": {"tldr": "MAC-Flow learns a flow-based joint-behavior model offline and distills it into decentralized one-step policies, achieving strong coordination with a large speedup.", "motivation": "There is a trade-off in multi-agent coordination between rich offline representations of joint behaviors and fast real-time execution. Diffusion-based methods offer expressive coordination but are computationally slow, while Gaussian-policy methods are fast but brittle with multi-agent interactions.", "method": "A two-stage approach: (1) learn a flow-based representation of joint behaviors from offline data; (2) distill this into decentralized one-step policies that preserve coordination for fast execution.", "result": "MAC-Flow achieves about 14.5x faster inference than diffusion-based MARL methods while maintaining good performance; its speed is comparable to prior Gaussian-policy offline MARL methods across extensive benchmarks (12 environments, 34 datasets).", "conclusion": "MAC-Flow successfully balances rich coordination representation with real-time efficiency, offering a practical solution that combines the strengths of diffusion-based and policy-based offline MARL."}}
{"id": "2511.05055", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05055", "abs": "https://arxiv.org/abs/2511.05055", "authors": ["Mingyu Sung", "Hyeonmin Choe", "Il-Min Kim", "Sangseok Yun", "Jae Mo Kang"], "title": "No Pose Estimation? No Problem: Pose-Agnostic and Instance-Aware Test-Time Adaptation for Monocular Depth Estimation", "comment": null, "summary": "Monocular depth estimation (MDE), inferring pixel-level depths in single RGB\nimages from a monocular camera, plays a crucial and pivotal role in a variety\nof AI applications demanding a three-dimensional (3D) topographical scene. In\nthe real-world scenarios, MDE models often need to be deployed in environments\nwith different conditions from those for training. Test-time (domain)\nadaptation (TTA) is one of the compelling and practical approaches to address\nthe issue. Although there have been notable advancements in TTA for MDE,\nparticularly in a self-supervised manner, existing methods are still\nineffective and problematic when applied to diverse and dynamic environments.\nTo break through this challenge, we propose a novel and high-performing TTA\nframework for MDE, named PITTA. Our approach incorporates two key innovative\nstrategies: (i) pose-agnostic TTA paradigm for MDE and (ii) instance-aware\nimage masking. Specifically, PITTA enables highly effective TTA on a pretrained\nMDE network in a pose-agnostic manner without resorting to any camera pose\ninformation. Besides, our instance-aware masking strategy extracts\ninstance-wise masks for dynamic objects (e.g., vehicles, pedestrians, etc.)\nfrom a segmentation mask produced by a pretrained panoptic segmentation\nnetwork, by removing static objects including background components. To further\nboost performance, we also present a simple yet effective edge extraction\nmethodology for the input image (i.e., a single monocular image) and depth map.\nExtensive experimental evaluations on DrivingStereo and Waymo datasets with\nvarying environmental conditions demonstrate that our proposed framework,\nPITTA, surpasses the existing state-of-the-art techniques with remarkable\nperformance improvements in MDE during TTA.", "AI": {"tldr": "A new test-time adaptation framework for monocular depth estimation, PITTA, achieves high performance under varying conditions using pose-agnostic adaptation, instance-aware masking of dynamic objects, and edge-enhanced cues.", "motivation": "Monocular depth estimation suffers from domain shifts between training and real-world test environments. Test-time adaptation (TTA) is practical but existing self-supervised methods struggle in dynamic, diverse settings. There is a need for pose-agnostic TTA that does not rely on camera poses and can effectively handle moving objects.", "method": "PITTA introduces two main strategies: (i) a pose-agnostic TTA paradigm for MDE that operates without camera pose information, and (ii) instance-aware masking that derives object-level masks for dynamic elements (vehicles, pedestrians) from a pretrained panoptic segmentation network, removing static background. An edge extraction component is also added to enhance input images and depth maps. The method is evaluated on DrivingStereo and Waymo datasets under varying conditions.", "result": "PITTA surpasses existing state-of-the-art TTA methods for monocular depth estimation, delivering notable performance gains on DrivingStereo and Waymo across varying environmental conditions.", "conclusion": "PITTA provides an effective, pose-agnostic TTA framework for MDE that leverages instance-aware masking and edge-enhanced cues to better handle dynamic scenes and domain shifts, achieving superior generalization under test-time variations."}}
{"id": "2511.05057", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05057", "abs": "https://arxiv.org/abs/2511.05057", "authors": ["Yuanxiang Huangfu", "Chaochao Wang", "Weilei Wang"], "title": "Role-SynthCLIP: A Role Play Driven Diverse Synthetic Data Approach", "comment": null, "summary": "The effectiveness of Contrastive Language-Image Pre-training (CLIP) models\ncritically depends on the semantic diversity and quality of their training\ndata. However, while existing synthetic data generation methods primarily focus\non increasing data volume, such emphasis often leads to limited semantic\ndiversity and redundant or shallow captions. To address this limitation, we\npropose Role-SynthCLIP, a novel data synthesis framework that leverages\nmulti-perspective role-playing prompts (e.g., a compositional analyst, an\ninterpreter of image context) to guide Multimodal Large Language Models (MLLMs)\nin generating semantically diverse captions from distinct viewpoints. This\nmechanism enhances the semantic diversity and fine-grained image-text alignment\nof synthetic pairs, thereby improving caption expressiveness and accuracy while\nkeeping the total number of image-text pairs unchanged. Experimental results\ndemonstrate the effectiveness and efficiency of our method. A CLIP-B/16 model\ntrained on only 1 million Role-SynthCLIP pairs achieves a Recall@1 of 64.1% on\nthe MS COCO validation set, surpassing the best existing synthetic data\nbaseline (trained on 5M pairs) by 2.8 percentage points. The code and trained\nmodels are released at https://github.com/huangfu170/Role-SynthCLIP.", "AI": {"tldr": "Role-SynthCLIP uses multi-perspective prompts to generate semantically diverse captions for CLIP training, achieving strong results with fewer synthetic pairs.", "motivation": "To overcome limited semantic diversity and shallow captions in existing synthetic data, where simply increasing data volume yields diminishing returns for image-text alignment.", "method": "Utilize Multimodal LLMs guided by role-playing prompts (e.g., compositional analyst, image-context interpreter) to generate diverse captions from distinct viewpoints, keeping the total number of image-text pairs constant and improving caption expressiveness and alignment.", "result": "A CLIP-B/16 model trained on 1M Role-SynthCLIP pairs achieves Recall@1 64.1% on MS COCO val, beating the best synthetic baseline (trained on 5M pairs) by 2.8 percentage points.", "conclusion": "Role-SynthCLIP demonstrates effective and efficient synthetic data generation that enhances semantic diversity and image-text alignment; code and models are released."}}
{"id": "2511.04904", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.04904", "abs": "https://arxiv.org/abs/2511.04904", "authors": ["Bassel Al Omari", "Michael Matthews", "Alexander Rutherford", "Jakob Nicolaus Foerster"], "title": "Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale", "comment": null, "summary": "Progress in multi-agent reinforcement learning (MARL) requires challenging\nbenchmarks that assess the limits of current methods. However, existing\nbenchmarks often target narrow short-horizon challenges that do not adequately\nstress the long-term dependencies and generalization capabilities inherent in\nmany multi-agent systems. To address this, we first present\n\\textit{Craftax-MA}: an extension of the popular open-ended RL environment,\nCraftax, that supports multiple agents and evaluates a wide range of general\nabilities within a single environment. Written in JAX, \\textit{Craftax-MA} is\nexceptionally fast with a training run using 250 million environment\ninteractions completing in under an hour. To provide a more compelling\nchallenge for MARL, we also present \\textit{Craftax-Coop}, an extension\nintroducing heterogeneous agents, trading and more mechanics that require\ncomplex cooperation among agents for success. We provide analysis demonstrating\nthat existing algorithms struggle with key challenges in this benchmark,\nincluding long-horizon credit assignment, exploration and cooperation, and\nargue for its potential to drive long-term research in MARL.", "AI": {"tldr": "Presents Craftax-MA and Craftax-Coop, scalable MARL benchmarks extending Craftax; fast in JAX; reveal long-horizon credit assignment, exploration, and cooperation challenges; aims to drive long-term MARL research.", "motivation": "Need challenging, generalizable benchmarks for MARL that test long-term dependencies and multi-agent cooperation beyond short-horizon tasks.", "method": "Extend Craftax with multiple agents (Craftax-MA) in JAX; add heterogeneous agents, trading, and cooperative mechanics in Craftax-Coop to require coordination; evaluate with metrics on long-horizon credit assignment, exploration, and cooperation.", "result": "Existing MARL algorithms struggle on these challenges; benchmark runs are fast (250M interactions under an hour); empirical justification that benchmarks stress key MARL difficulties.", "conclusion": "Craftax-MA and Craftax-Coop offer a compelling, fast, general benchmark suite to push MARL research toward long-horizon, cooperative, and generalizable capabilities."}}
{"id": "2511.05355", "categories": ["cs.LG", "cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05355", "abs": "https://arxiv.org/abs/2511.05355", "authors": ["Tzu-Yuan Huang", "Armin Lederer", "Dai-Jie Wu", "Xiaobing Dai", "Sihua Zhang", "Stefan Sosnowski", "Shao-Hua Sun", "Sandra Hirche"], "title": "SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning", "comment": null, "summary": "Flow matching (FM) has shown promising results in data-driven planning.\nHowever, it inherently lacks formal guarantees for ensuring state and action\nconstraints, whose satisfaction is a fundamental and crucial requirement for\nthe safety and admissibility of planned trajectories on various systems.\nMoreover, existing FM planners do not ensure the dynamical consistency, which\npotentially renders trajectories inexecutable. We address these shortcomings by\nproposing SAD-Flower, a novel framework for generating Safe, Admissible, and\nDynamically consistent trajectories. Our approach relies on an augmentation of\nthe flow with a virtual control input. Thereby, principled guidance can be\nderived using techniques from nonlinear control theory, providing formal\nguarantees for state constraints, action constraints, and dynamic consistency.\nCrucially, SAD-Flower operates without retraining, enabling test-time\nsatisfaction of unseen constraints. Through extensive experiments across\nseveral tasks, we demonstrate that SAD-Flower outperforms various\ngenerative-model-based baselines in ensuring constraint satisfaction.", "AI": {"tldr": "SAD-Flower augments flow-based planning with a virtual control input to guarantee safety and dynamical feasibility at test time, providing state/action constraint satisfaction without retraining and outperforming baselines.", "motivation": "Flow matching (FM) lacks formal guarantees for state/action constraints and dynamic consistency, risking unsafe or infeasible trajectories in data-driven planning.", "method": "Introduce a virtual control augmentation to the flow; apply nonlinear control theory to derive formal guarantees for state constraints, action constraints, and dynamic consistency; operate at test time without retraining.", "result": "Empirical experiments show SAD-Flower outperforms generative-model baselines in constraint satisfaction across multiple tasks.", "conclusion": "SAD-Flower provides a safe, admissible, and dynamically consistent trajectory generation framework, extending flow matching with formal guarantees and test-time adaptability for unseen constraints."}}
{"id": "2511.05059", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05059", "abs": "https://arxiv.org/abs/2511.05059", "authors": ["Mingyu Sheng", "Jianan Fan", "Dongnan Liu", "Guoyan Zheng", "Ron Kikinis", "Weidong Cai"], "title": "SurgiATM: A Physics-Guided Plug-and-Play Model for Deep Learning-Based Smoke Removal in Laparoscopic Surgery", "comment": "10 pages, 5 figures, 6 tables. Code available at\n  https://github.com/MingyuShengSMY/SurgiATM", "summary": "During laparoscopic surgery, smoke generated by tissue cauterization can\nsignificantly degrade the visual quality of endoscopic frames, increasing the\nrisk of surgical errors and hindering both clinical decision-making and\ncomputer-assisted visual analysis. Consequently, removing surgical smoke is\ncritical to ensuring patient safety and maintaining operative efficiency. In\nthis study, we propose the Surgical Atmospheric Model (SurgiATM) for surgical\nsmoke removal. SurgiATM statistically bridges a physics-based atmospheric model\nand data-driven deep learning models, combining the superior generalizability\nof the former with the high accuracy of the latter. Furthermore, SurgiATM is\ndesigned as a lightweight, plug-and-play module that can be seamlessly\nintegrated into diverse surgical desmoking architectures to enhance their\naccuracy and stability, better meeting clinical requirements. It introduces\nonly two hyperparameters and no additional trainable weights, preserving the\noriginal network architecture with minimal computational and modification\noverhead. We conduct extensive experiments on three public surgical datasets\nwith ten desmoking methods, involving multiple network architectures and\ncovering diverse procedures, including cholecystectomy, partial nephrectomy,\nand diaphragm dissection. The results demonstrate that incorporating SurgiATM\ncommonly reduces the restoration errors of existing models and relatively\nenhances their generalizability, without adding any trainable layers or\nweights. This highlights the convenience, low cost, effectiveness, and\ngeneralizability of the proposed method. The code for SurgiATM is released at\nhttps://github.com/MingyuShengSMY/SurgiATM.", "AI": {"tldr": "SurgiATM is a lightweight, plug-and-play module that improves surgical smoke removal by bridging physics-based atmospheric modeling with data-driven DL, adding two hyperparameters and no extra trainable weights, yielding better accuracy and generalization across datasets and methods.", "motivation": "Surgical smoke degrades endoscopic visualization, increasing error risk and hindering both clinical decision-making and computer-assisted analysis. A robust, generalizable desmoking approach is needed that can generalize across procedures with minimal overhead.", "method": "Introduce SurgiATM as a statistical bridge between a physics-based atmospheric model and data-driven networks. It requires only two hyperparameters and adds no trainable weights, functioning as a plug-and-play module that can be integrated into existing desmoking architectures. Evaluated on three public surgical datasets across multiple procedures (cholecystectomy, partial nephrectomy, diaphragm dissection) and ten desmoking methods with various network architectures.", "result": "Incorporation of SurgiATM consistently reduces restoration errors and enhances generalizability of existing desmoking models without adding trainable layers or weights, with minimal computational/architectural overhead. The method demonstrates broad compatibility across methods and procedures; code is released.", "conclusion": "SurgiATM offers a convenient, low-cost, and effective enhancement for surgical desmoking, enabling easier integration into diverse pipelines and improving reliability for clinical decision-making and computer-assisted analysis."}}
{"id": "2511.04907", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.04907", "abs": "https://arxiv.org/abs/2511.04907", "authors": ["Lunjia Hu", "Haipeng Luo", "Spandan Senapati", "Vatsal Sharan"], "title": "Efficient Swap Multicalibration of Elicitable Properties", "comment": null, "summary": "Multicalibration [HJKRR18] is an algorithmic fairness perspective that\ndemands that the predictions of a predictor are correct conditional on\nthemselves and membership in a collection of potentially overlapping subgroups\nof a population. The work of [NR23] established a surprising connection between\nmulticalibration for an arbitrary property $\\Gamma$ (e.g., mean or median) and\nproperty elicitation: a property $\\Gamma$ can be multicalibrated if and only if\nit is elicitable, where elicitability is the notion that the true property\nvalue of a distribution can be obtained by solving a regression problem over\nthe distribution. In the online setting, [NR23] proposed an inefficient\nalgorithm that achieves $\\sqrt T$ $\\ell_2$-multicalibration error for a\nhypothesis class of group membership functions and an elicitable property\n$\\Gamma$, after $T$ rounds of interaction between a forecaster and adversary.\n  In this paper, we generalize multicalibration for an elicitable property\n$\\Gamma$ from group membership functions to arbitrary bounded hypothesis\nclasses and introduce a stronger notion -- swap multicalibration, following\n[GKR23]. Subsequently, we propose an oracle-efficient algorithm which, when\ngiven access to an online agnostic learner, achieves $T^{1/(r+1)}$\n$\\ell_r$-swap multicalibration error with high probability (for $r\\ge2$) for a\nhypothesis class with bounded sequential Rademacher complexity and an\nelicitable property $\\Gamma$. For the special case of $r=2$, this implies an\noracle-efficient algorithm that achieves $T^{1/3}$ $\\ell_2$-swap\nmulticalibration error, which significantly improves on the previously\nestablished bounds for the problem [NR23, GMS25, LSS25a], and completely\nresolves an open question raised in [GJRR24] on the possibility of an\noracle-efficient algorithm that achieves $\\sqrt{T}$ $\\ell_2$-mean\nmulticalibration error by answering it in a strongly affirmative sense.", "AI": {"tldr": "Extends multicalibration to arbitrary bounded hypothesis classes via swap multicalibration and delivers an oracle-efficient algorithm achieving fast convergence rates in swap multicalibration, resolving open questions about efficient mean multicalibration.", "motivation": "To generalize multicalibration from group membership functions to arbitrary bounded hypothesis classes, and to link elicitable properties with multicalibrated predictions, while achieving computationally efficient (oracle-efficient) guarantees with strong, quantitative error bounds.", "method": "Introduce swap multicalibration (generalizing mean/elicitable multicalibration). Propose an oracle-efficient algorithm that uses an online agnostic learner and relies on bounded sequential Rademacher complexity. Achieves T^{1/(r+1)} ell_r-swap multicalibration error for r>=2; special case r=2 yields T^{1/3} ell_2-swap multicalibration error.", "result": "The proposed approach yields provable high-probability bounds: swap multicalibration error scales as T^{1/(r+1)} for ell_r with r>=2; in the r=2 case, ell_2 error is O(T^{1/3}). This improves on previous bounds for mean multicalibration and related works (NR23, GMS25, LSS25a) and resolves an open question from GJRR24 about achieving sqrt(T) ell_2-mean multicalibration via an oracle-efficient method.", "conclusion": "The paper broadens multicalibration theory to arbitrary bounded hypothesis classes through swap multicalibration and provides an oracle-efficient, provably fast-converging algorithm, achieving near-optimal rates and closing an important open problem in mean multicalibration efficiency."}}
{"id": "2511.05396", "categories": ["cs.LG", "cs.AI", "cs.RO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.05396", "abs": "https://arxiv.org/abs/2511.05396", "authors": ["Yiting He", "Zhishuai Liu", "Weixin Wang", "Pan Xu"], "title": "Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction", "comment": "53 pages, 6 figures, 3 tables. Published in Proceedings of the 42nd\n  International Conference on Machine Learning (ICML 2025)", "summary": "Off-dynamics reinforcement learning (RL), where training and deployment\ntransition dynamics are different, can be formulated as learning in a robust\nMarkov decision process (RMDP) where uncertainties in transition dynamics are\nimposed. Existing literature mostly assumes access to generative models\nallowing arbitrary state-action queries or pre-collected datasets with a good\nstate coverage of the deployment environment, bypassing the challenge of\nexploration. In this work, we study a more realistic and challenging setting\nwhere the agent is limited to online interaction with the training environment.\nTo capture the intrinsic difficulty of exploration in online RMDPs, we\nintroduce the supremal visitation ratio, a novel quantity that measures the\nmismatch between the training dynamics and the deployment dynamics. We show\nthat if this ratio is unbounded, online learning becomes exponentially hard. We\npropose the first computationally efficient algorithm that achieves sublinear\nregret in online RMDPs with $f$-divergence based transition uncertainties. We\nalso establish matching regret lower bounds, demonstrating that our algorithm\nachieves optimal dependence on both the supremal visitation ratio and the\nnumber of interaction episodes. Finally, we validate our theoretical results\nthrough comprehensive numerical experiments.", "AI": {"tldr": "Introduces supremal visitation ratio to quantify exploration difficulty in online RMDPs with transition uncertainty; proves unbounded ratio makes online learning exponentially hard; provides a computationally efficient algorithm achieving sublinear regret under f-divergence uncertainty, with matching lower bounds and empirical validation.", "motivation": "Addresses the gap in online reinforcement learning when training and deployment dynamics differ (off-dynamics RL). Existing work relies on generative models or good offline coverage; this work studies learning with only online interaction and robust transition uncertainty, a realistically challenging setting.", "method": "Defines supremal visitation ratio to capture training-deployment dynamics mismatch. Formulates online RMDPs with f-divergence based transition uncertainty sets. Proposes a computationally efficient online algorithm achieving sublinear regret. Establishes upper regret bounds dependent on the supremal visitation ratio and episode count, and proves matching lower bounds. Validates results with numerical experiments.", "result": "The proposed algorithm attains sublinear regret in online RMDPs under f-divergence transition uncertainty. The regret bounds are shown to be optimal with respect to the supremal visitation ratio and the number of interaction episodes. Empirical experiments corroborate the theoretical findings and illustrate practical performance.", "conclusion": "This work advances online RL under model misspecification by introducing a quantifiable exploration difficulty measure (supremal visitation ratio) and delivering an algorithm with optimal regret guarantees under f-divergence uncertainty. It lays groundwork for robust online planning under dynamics mismatch and suggests directions for extending to broader uncertainty sets and scalability."}}
{"id": "2511.05073", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05073", "abs": "https://arxiv.org/abs/2511.05073", "authors": ["Jun Li", "Yanwei Xu", "Keran Li", "Xiaoli Zhang"], "title": "Deep learning models are vulnerable, but adversarial examples are even more vulnerable", "comment": "25 pages,12 figures", "summary": "Understanding intrinsic differences between adversarial examples and clean\nsamples is key to enhancing DNN robustness and detection against adversarial\nattacks. This study first empirically finds that image-based adversarial\nexamples are notably sensitive to occlusion. Controlled experiments on CIFAR-10\nused nine canonical attacks (e.g., FGSM, PGD) to generate adversarial examples,\npaired with original samples for evaluation. We introduce Sliding Mask\nConfidence Entropy (SMCE) to quantify model confidence fluctuation under\nocclusion. Using 1800+ test images, SMCE calculations supported by Mask Entropy\nField Maps and statistical distributions show adversarial examples have\nsignificantly higher confidence volatility under occlusion than originals.\nBased on this, we propose Sliding Window Mask-based Adversarial Example\nDetection (SWM-AED), which avoids catastrophic overfitting of conventional\nadversarial training. Evaluations across classifiers and attacks on CIFAR-10\ndemonstrate robust performance, with accuracy over 62% in most cases and up to\n96.5%.", "AI": {"tldr": "Adversarial examples exhibit higher confidence volatility under occlusion than clean samples; the authors introduce SMCE to quantify this, and propose SWM-AED for detecting adversarial examples, achieving robust detection on CIFAR-10 across multiple attacks without overfitting, with accuracies typically above 62% and up to 96.5%.", "motivation": "To understand intrinsic differences between adversarial and clean samples, focusing on occlusion sensitivity; to improve robustness and detection without costly adversarial training.", "method": "Empirical CIFAR-10 study with nine attacks (e.g., FGSM, PGD); define Sliding Mask Confidence Entropy (SMCE) to measure confidence fluctuation under occlusion; use Mask Entropy Field Maps and distributions; propose Sliding Window Mask-based Adversarial Example Detection (SWM-AED) to mitigate overfitting; evaluate across classifiers and attacks.", "result": "SMCE analyses show adversarial examples have significantly higher confidence volatility under occlusion; SWM-AED yields robust detection performance, with CIFAR-10 accuracy results typically >62% and up to 96.5% in some settings.", "conclusion": "Occlusion-induced confidence volatility is a distinguishing feature of adversarial inputs; the SWM-AED method provides effective, training-light detection across attacks and classifiers, offering a practical defense improvement."}}
{"id": "2511.04998", "categories": ["cs.LG", "cs.AI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.04998", "abs": "https://arxiv.org/abs/2511.04998", "authors": ["Daniel S. Lee", "Mayra S. Haedo-Cruz", "Chen Jiang", "Oshin Miranda", "LiRong Wang"], "title": "BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records", "comment": "20 pages, 2 figures, 6 tables, 2 supplementary figures, 4\n  supplementary tables, submitted to Journal of Biomedical Informatics on 6\n  Nov, 2025", "summary": "Transformer-based deep learning models have shown promise for disease risk\nprediction using electronic health records(EHRs), but modeling temporal\ndependencies remains a key challenge due to irregular visit intervals and lack\nof uniform structure. We propose a Bi-Positional Embedding Transformer Encoder\nor BiPETE for single-disease prediction, which integrates rotary positional\nembeddings to encode relative visit timing and sinusoidal embeddings to\npreserve visit order. Without relying on large-scale pretraining, BiPETE is\ntrained on EHR data from two mental health cohorts-depressive disorder and\npost-traumatic stress disorder (PTSD)-to predict the risk of alcohol and\nsubstance use disorders (ASUD). BiPETE outperforms baseline models, improving\nthe area under the precision-recall curve (AUPRC) by 34% and 50% in the\ndepression and PTSD cohorts, respectively. An ablation study further confirms\nthe effectiveness of the dual positional encoding strategy. We apply the\nIntegrated Gradients method to interpret model predictions, identifying key\nclinical features associated with ASUD risk and protection, such as abnormal\ninflammatory, hematologic, and metabolic markers, as well as specific\nmedications and comorbidities. Overall, these key clinical features identified\nby the attribution methods contribute to a deeper understanding of the risk\nassessment process and offer valuable clues for mitigating potential risks. In\nsummary, our study presents a practical and interpretable framework for disease\nrisk prediction using EHR data, which can achieve strong performance.", "AI": {"tldr": "BiPETE: a Bi-Positional Embedding Transformer Encoder for single-disease risk prediction on EHRs, combining rotary relative-timing and sinusoidal order encodings to handle irregular visit intervals; trained on depressive disorder and PTSD cohorts to predict ASUD; achieves large AUPRC gains and provides interpretable insights via Integrated Gradients.", "motivation": "Modeling temporal dependencies in EHR data with irregular visit intervals and nonuniform structure is challenging; there is a need for accurate and interpretable risk prediction without heavy pretraining.", "method": "Propose BiPETE with dual positional encodings: rotary embeddings for relative visit timing and sinusoidal embeddings to preserve visit order; train on two mental health cohorts to predict ASUD risk; evaluate with AUPRC; conduct ablation; apply Integrated Gradients for interpretation.", "result": "BiPETE improves AUPRC by 34% in depression and 50% in PTSD cohorts over baselines; ablation supports the dual encoding; interpretable features include inflammatory/hematologic/metabolic markers, medications, comorbidities linked to ASUD risk/protection.", "conclusion": "BiPETE offers a practical, interpretable framework for EHR-based disease risk prediction with strong performance, leveraging dual positional encodings to handle temporal irregularities."}}
{"id": "2511.05092", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05092", "abs": "https://arxiv.org/abs/2511.05092", "authors": ["Ruolin Li", "Min Liu", "Yuan Bian", "Zhaoyang Li", "Yuzhen Li", "Xueping Wang", "Yaonan Wang"], "title": "A Dual-stage Prompt-driven Privacy-preserving Paradigm for Person Re-Identification", "comment": "10 pages, 6 figures", "summary": "With growing concerns over data privacy, researchers have started using\nvirtual data as an alternative to sensitive real-world images for training\nperson re-identification (Re-ID) models. However, existing virtual datasets\nproduced by game engines still face challenges such as complex construction and\npoor domain generalization, making them difficult to apply in real scenarios.\nTo address these challenges, we propose a Dual-stage Prompt-driven\nPrivacy-preserving Paradigm (DPPP). In the first stage, we generate rich\nprompts incorporating multi-dimensional attributes such as pedestrian\nappearance, illumination, and viewpoint that drive the diffusion model to\nsynthesize diverse data end-to-end, building a large-scale virtual dataset\nnamed GenePerson with 130,519 images of 6,641 identities. In the second stage,\nwe propose a Prompt-driven Disentanglement Mechanism (PDM) to learn\ndomain-invariant generalization features. With the aid of contrastive learning,\nwe employ two textual inversion networks to map images into pseudo-words\nrepresenting style and content, respectively, thereby constructing\nstyle-disentangled content prompts to guide the model in learning\ndomain-invariant content features at the image level. Experiments demonstrate\nthat models trained on GenePerson with PDM achieve state-of-the-art\ngeneralization performance, surpassing those on popular real and virtual Re-ID\ndatasets.", "AI": {"tldr": "A two-stage prompt-driven framework (DPPP) creates a large synthetic Re-ID dataset (GenePerson) via diffusion prompts and learns domain-invariant features with a prompt-driven disentanglement mechanism (PDM), achieving state-of-the-art generalization.", "motivation": "Privacy concerns and limited applicability of real data push the use of virtual data for Re-ID. Existing synthetic datasets from game engines are hard to construct and suffer from poor domain generalization, hindering real-world transfer.", "method": "Stage 1: Use multi-dimensional prompts (appearance, illumination, viewpoint) to drive diffusion models to synthesize diverse person images, building GenePerson with 130,519 images across 6,641 identities. Stage 2: Apply a Prompt-driven Disentanglement Mechanism (PDM) with contrastive learning; employ two textual inversion networks to map images to pseudo-words for style and content, creating style-disentangled content prompts to learn domain-invariant content features at the image level.", "result": "Models trained on GenePerson with PDM achieve state-of-the-art generalization in Re-ID, outperforming popular real and virtual datasets.", "conclusion": "The DPPP framework effectively leverages privacy-preserving synthetic data and style-content disentanglement to improve cross-domain generalization for person Re-ID, indicating strong potential for scalable, domain-generalizable synthetic datasets."}}
{"id": "2511.04918", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04918", "abs": "https://arxiv.org/abs/2511.04918", "authors": ["A. Ganapathi Rao", "Sathish Krishna Anumula", "Aditya Kumar Singh", "Renukhadevi M", "Y. Jeevan Nagendra Kumar", "Tammineni Rama Tulasi"], "title": "Machine Learning Algorithms in Statistical Modelling Bridging Theory and Application", "comment": "9 Pages, 4 Figures", "summary": "It involves the completely novel ways of integrating ML algorithms with\ntraditional statistical modelling that has changed the way we analyze data, do\npredictive analytics or make decisions in the fields of the data. In this\npaper, we study some ML and statistical model connections to understand ways in\nwhich some modern ML algorithms help 'enrich' conventional models; we\ndemonstrate how new algorithms improve performance, scale, flexibility and\nrobustness of the traditional models. It shows that the hybrid models are of\ngreat improvement in predictive accuracy, robustness, and interpretability", "AI": {"tldr": "Hybrid ML + traditional statistical models can outperform standalone models in accuracy, robustness, and interpretability, by enriching conventional approaches with modern ML techniques.", "motivation": "To understand how integrating ML algorithms with classical statistics can improve data analysis, predictive analytics, and decision-making across data-driven fields.", "method": "Analytical examination of connections between ML methods and statistical models, showing how newer algorithms enrich conventional models, with demonstrations of performance, scalability, flexibility, and robustness gains in hybrid systems.", "result": "Hybrid models yield notable improvements in predictive accuracy, robustness, scalability, and interpretability over traditional approaches.", "conclusion": "Integrating ML with traditional statistics provides substantial benefits and should be considered a central strategy for modern predictive modeling and decision-making."}}
{"id": "2511.05095", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05095", "abs": "https://arxiv.org/abs/2511.05095", "authors": ["Fuyang Liu", "Jiaqi Xu", "Xiaowei Hu"], "title": "Real-World Adverse Weather Image Restoration via Dual-Level Reinforcement Learning with High-Quality Cold Start", "comment": "Accepted by NeurIPS 2025", "summary": "Adverse weather severely impairs real-world visual perception, while existing\nvision models trained on synthetic data with fixed parameters struggle to\ngeneralize to complex degradations. To address this, we first construct\nHFLS-Weather, a physics-driven, high-fidelity dataset that simulates diverse\nweather phenomena, and then design a dual-level reinforcement learning\nframework initialized with HFLS-Weather for cold-start training. Within this\nframework, at the local level, weather-specific restoration models are refined\nthrough perturbation-driven image quality optimization, enabling reward-based\nlearning without paired supervision; at the global level, a meta-controller\ndynamically orchestrates model selection and execution order according to scene\ndegradation. This framework enables continuous adaptation to real-world\nconditions and achieves state-of-the-art performance across a wide range of\nadverse weather scenarios. Code is available at\nhttps://github.com/xxclfy/AgentRL-Real-Weather", "AI": {"tldr": "Proposes HFLS-Weather and a dual-level RL framework for robust perception under adverse weather, combining physics-driven data with local restoration learned via perturbation rewards and a global meta-controller for dynamic model orchestration; achieves state-of-the-art results and enables continuous adaptation.", "motivation": "Real-world vision systems struggle to generalize to complex weather degradations. Synthetic datasets with fixed parameters fail to capture real-world variability. High-fidelity, physics-based data plus adaptive training can bridge the sim-to-real gap.", "method": "1) Construct HFLS-Weather, a physics-driven, high-fidelity weather dataset. 2) Initialize a dual-level reinforcement learning framework with HFLS-Weather for cold-start training. Local level: refine weather-specific restoration models via perturbation-driven image quality optimization with reward-based learning, without paired supervision. Global level: a meta-controller dynamically selects models and their execution order based on scene degradation.", "result": "Achieves state-of-the-art performance across a wide range of adverse weather scenarios. Enables continuous adaptation to real-world conditions. Code is released at the provided GitHub link.", "conclusion": "The framework effectively addresses generalization to adverse weather by combining high-fidelity data, perturbation-driven local learning, and a global orchestration strategy, reducing reliance on paired supervision and supporting ongoing adaptation to real-world conditions."}}
{"id": "2511.04934", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04934", "abs": "https://arxiv.org/abs/2511.04934", "authors": ["Hadi Reisizadeh", "Jiajun Ruan", "Yiwei Chen", "Soumyadeep Pal", "Sijia Liu", "Mingyi Hong"], "title": "Leak@$k$: Unlearning Does Not Make LLMs Forget Under Probabilistic Decoding", "comment": null, "summary": "Unlearning in large language models (LLMs) is critical for regulatory\ncompliance and for building ethical generative AI systems that avoid producing\nprivate, toxic, illegal, or copyrighted content. Despite rapid progress, in\nthis work we show that \\textit{almost all} existing unlearning methods fail to\nachieve true forgetting in practice. Specifically, while evaluations of these\n`unlearned' models under deterministic (greedy) decoding often suggest\nsuccessful knowledge removal using standard benchmarks (as has been done in the\nliterature), we show that sensitive information reliably resurfaces when models\nare sampled with standard probabilistic decoding. To rigorously capture this\nvulnerability, we introduce \\texttt{leak@$k$}, a new meta-evaluation metric\nthat quantifies the likelihood of forgotten knowledge reappearing when\ngenerating $k$ samples from the model under realistic decoding strategies.\nUsing three widely adopted benchmarks, TOFU, MUSE, and WMDP, we conduct the\nfirst large-scale, systematic study of unlearning reliability using our newly\ndefined \\texttt{leak@$k$} metric. Our findings demonstrate that knowledge\nleakage persists across methods and tasks, underscoring that current\nstate-of-the-art unlearning techniques provide only limited forgetting and\nhighlighting the urgent need for more robust approaches to LLM unlearning.", "AI": {"tldr": "Most unlearning methods fail to truly forget in LLMs; leakage resurfaces under probabilistic decoding; introduces leak@k metric and large-scale evaluation across TOFU, MUSE, WMDP showing persistent leakage; calls for robust unlearning approaches.", "motivation": "Regulatory compliance and ethical AI require removing sensitive information (private, toxic, illegal, copyrighted) from LLMs. Greedy decoding can mask leakage; robust forgetting must hold under realistic sampling.", "method": "Introduce leak@k metric to quantify forgetting under k-sample generation; perform large-scale evaluation across three benchmarks (TOFU, MUSE, WMDP) and multiple unlearning methods; compare outcomes under greedy vs probabilistic decoding; analyze persistence of leakage.", "result": "Knowledge leakage persists across methods and tasks; existing unlearning techniques provide only limited forgetting; standard greedy-evaluation overestimates forgetting; leak@k reveals vulnerability to reappearance of forgotten content.", "conclusion": "Current state-of-the-art unlearning techniques are insufficient; robust unlearning approaches and broader evaluation frameworks (like leak@k) are urgently needed to ensure true forgetting in LLMs."}}
{"id": "2511.05028", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05028", "abs": "https://arxiv.org/abs/2511.05028", "authors": ["Dongjin Park", "Hasung Yeo", "Joon-Woo Lee"], "title": "OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data", "comment": null, "summary": "Federated fine-tuning (FFT) adapts foundation models to decentralized data\nbut remains fragile under heterogeneous client distributions due to local\ndrift, i.e., client-level update divergences that induce systematic bias and\namplified variance in the global model. Existing aggregation and\npersonalization methods largely correct drift post hoc, which proves brittle\nunder extreme non-IID conditions. We introduce OvA-LP, a minimalist framework\nthat is, to our knowledge, the first explicitly designed to suppress drift at\nits source within the PEFT-based FFT paradigm. OvA-LP combines linear probing\non a frozen encoder with a one-vs-all head and a simple two-stage procedure,\npreserving pretrained feature geometry and decoupling logits to prevent the\nmechanisms that amplify drift. On CIFAR-100 with 100 clients, averaged over\nshard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of\nits IID accuracy, whereas state-of-the-art FFT baselines retain only 10.1%\n(PFPT) and 34.5% (FFT-MoE) under the same conditions. OvA-LP further maintains\nresilience under both symmetric and asymmetric label noise. In addition,\nprecomputing encoder features makes per-round cost nearly independent of\nencoder size. Together, these results demonstrate that OvA-LP provides a\nprincipled and efficient basis for robust FFT under heterogeneity.", "AI": {"tldr": "OvA-LP is a drift-suppressing minimal framework for federated fine-tuning (FFT) of foundation models, using linear probing on a frozen encoder with a one-vs-all head in a two-stage setup to prevent drift at the source, achieving near-IID performance under non-IID client distributions with low per-round cost.", "motivation": "In FFT with decentralized data, local drift from heterogeneous client updates biases the global model and amplifies variance. Existing aggregation/personalization methods mainly correct drift post hoc and struggle under extreme non-IID conditions.", "method": "A minimalist two-stage approach: perform linear probing on a frozen encoder with a one-vs-all head. This design preserves pretrained feature geometry and decouples logits to avoid drift amplification. Features can be precomputed so per-round cost is nearly independent of encoder size.", "result": "On CIFAR-100 with 100 clients across shard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of its IID accuracy, while state-of-the-art FFT baselines retain only 10.1% (PFPT) and 34.5% (FFT-MoE) under the same conditions. It also remains robust under symmetric and asymmetric label noise.", "conclusion": "OvA-LP provides a principled and efficient basis for robust FFT under heterogeneity by suppressing drift at its source, with strong empirical performance and favorable computational properties due to precomputed features."}}
{"id": "2511.05106", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05106", "abs": "https://arxiv.org/abs/2511.05106", "authors": ["Yasemin Turkan", "F. Boray Tek", "M. Serdar Nazl\u0131", "\u00d6yk\u00fc Eren"], "title": "Early Alzheimer's Disease Detection from Retinal OCT Images: A UK Biobank Study", "comment": null, "summary": "Alterations in retinal layer thickness, measurable using Optical Coherence\nTomography (OCT), have been associated with neurodegenerative diseases such as\nAlzheimer's disease (AD). While previous studies have mainly focused on\nsegmented layer thickness measurements, this study explored the direct\nclassification of OCT B-scan images for the early detection of AD. To our\nknowledge, this is the first application of deep learning to raw OCT B-scans\nfor AD prediction in the literature. Unlike conventional medical image\nclassification tasks, early detection is more challenging than diagnosis\nbecause imaging precedes clinical diagnosis by several years. We fine-tuned and\nevaluated multiple pretrained models, including ImageNet-based networks and the\nOCT-specific RETFound transformer, using subject-level cross-validation\ndatasets matched for age, sex, and imaging instances from the UK Biobank\ncohort. To reduce overfitting in this small, high-dimensional dataset, both\nstandard and OCT-specific augmentation techniques were applied, along with a\nyear-weighted loss function that prioritized cases diagnosed within four years\nof imaging. ResNet-34 produced the most stable results, achieving an AUC of\n0.62 in the 4-year cohort. Although below the threshold for clinical\napplication, our explainability analyses confirmed localized structural\ndifferences in the central macular subfield between the AD and control groups.\nThese findings provide a baseline for OCT-based AD prediction, highlight the\nchallenges of detecting subtle retinal biomarkers years before AD diagnosis,\nand point to the need for larger datasets and multimodal approaches.", "AI": {"tldr": "DL on raw OCT B-scans for early AD detection shows baseline feasibility; AUC ~0.62 in 4-year window; not yet clinically actionable; larger datasets and multimodal approaches needed.", "motivation": "Move beyond segmented retinal thickness measures to end-to-end DL on raw OCT data for preclinical AD detection; address the challenge that early-stage signals precede clinical diagnosis by years.", "method": "Fine-tuned multiple pretrained models (ImageNet-based and OCT-specific RETFound transformer) on raw OCT B-scans. Subject-level cross-validation on UK Biobank data matched for age, sex, and imaging instances. Applied standard and OCT-specific augmentation to reduce overfitting and used a year-weighted loss to emphasize cases diagnosed within four years.", "result": "ResNet-34 yielded the most stable performance with AUC 0.62 in the 4-year cohort. Explainability analyses revealed localized differences in the central macular subfield between AD and controls. Findings establish a baseline for OCT-based AD prediction but indicate current limitations for clinical deployment.", "conclusion": "Demonstrates feasibility of predicting AD risk from raw OCT B-scans, but performance is insufficient for clinical use. Highlights the need for larger datasets and multimodal approaches to capture subtle retinal biomarkers years before AD diagnosis."}}
{"id": "2511.04937", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04937", "abs": "https://arxiv.org/abs/2511.04937", "authors": ["Zhankun Luo", "Abolfazl Hashemi"], "title": "Structural Properties, Cycloid Trajectories and Non-Asymptotic Guarantees of EM Algorithm for Mixed Linear Regression", "comment": "Preprint of the paper submitted to IEEE Transactions on Information\n  Theory", "summary": "This work investigates the structural properties, cycloid trajectories, and\nnon-asymptotic convergence guarantees of the Expectation-Maximization (EM)\nalgorithm for two-component Mixed Linear Regression (2MLR) with unknown mixing\nweights and regression parameters. Recent studies have established global\nconvergence for 2MLR with known balanced weights and super-linear convergence\nin noiseless and high signal-to-noise ratio (SNR) regimes. However, the\ntheoretical behavior of EM in the fully unknown setting remains unclear, with\nits trajectory and convergence order not yet fully characterized. We derive\nexplicit EM update expressions for 2MLR with unknown mixing weights and\nregression parameters across all SNR regimes and analyze their structural\nproperties and cycloid trajectories. In the noiseless case, we prove that the\ntrajectory of the regression parameters in EM iterations traces a cycloid by\nestablishing a recurrence relation for the sub-optimality angle, while in high\nSNR regimes we quantify its discrepancy from the cycloid trajectory. The\ntrajectory-based analysis reveals the order of convergence: linear when the EM\nestimate is nearly orthogonal to the ground truth, and quadratic when the angle\nbetween the estimate and ground truth is small at the population level. Our\nanalysis establishes non-asymptotic guarantees by sharpening bounds on\nstatistical errors between finite-sample and population EM updates, relating\nEM's statistical accuracy to the sub-optimality angle, and proving convergence\nwith arbitrary initialization at the finite-sample level. This work provides a\nnovel trajectory-based framework for analyzing EM in Mixed Linear Regression.", "AI": {"tldr": "EM for 2-component MLR with unknown weights/parameters: explicit updates across all SNR, cycloid-like trajectory in noiseless case, linear/quadratic convergence depending on angle, plus non-asymptotic finite-sample guarantees; introduces a trajectory-based analysis framework.", "motivation": "To understand EM behavior in fully unknown 2MLR settings where mixing weights and regression parameters are unknown, addressing gaps left by prior work that assumes known/balanced weights and high SNR.", "method": "Derive explicit EM update equations for 2MLR with unknown mixing weights and regression parameters in all SNR regimes; analyze the iterative trajectory, establish cycloid trajectory in the noiseless case via a recurrence for the sub-optimality angle, quantify deviations in high SNR, derive convergence orders (linear when near-orthogonal to ground truth; quadratic when angle is small), and provide non-asymptotic finite-sample bounds linking statistical error to sub-optimality angle; prove convergence from arbitrary initialization.", "result": "Demonstrates a cycloid trajectory for parameter updates in the noiseless setting; characterizes convergence order as linear or quadratic depending on angle; provides non-asymptotic finite-sample guarantees and a trajectory-based framework for EM in 2MLR with unknown weights.", "conclusion": "Introduces a novel trajectory-based framework for analyzing EM in 2MLR with fully unknown weights, delivering both structural insights (cycloid behavior) and practical guarantees (finite-sample convergence from any initialization)."}}
{"id": "2511.05108", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05108", "abs": "https://arxiv.org/abs/2511.05108", "authors": ["J\u00f6rg Gamerdinger", "Benedict Wetzel", "Patrick Schulz", "Sven Teufel", "Oliver Bringmann"], "title": "SnowyLane: Robust Lane Detection on Snow-covered Rural Roads Using Infrastructural Elements", "comment": null, "summary": "Lane detection for autonomous driving in snow-covered environments remains a\nmajor challenge due to the frequent absence or occlusion of lane markings. In\nthis paper, we present a novel, robust and realtime capable approach that\nbypasses the reliance on traditional lane markings by detecting roadside\nfeatures,specifically vertical roadside posts called delineators, as indirect\nlane indicators. Our method first perceives these posts, then fits a smooth\nlane trajectory using a parameterized Bezier curve model, leveraging spatial\nconsistency and road geometry. To support training and evaluation in these\nchallenging scenarios, we introduce SnowyLane, a new synthetic dataset\ncontaining 80,000 annotated frames capture winter driving conditions, with\nvarying snow coverage, and lighting conditions. Compared to state-of-the-art\nlane detection systems, our approach demonstrates significantly improved\nrobustness in adverse weather, particularly in cases with heavy snow occlusion.\nThis work establishes a strong foundation for reliable lane detection in winter\nscenarios and contributes a valuable resource for future research in\nall-weather autonomous driving. The dataset is available at\nhttps://ekut-es.github.io/snowy-lane", "AI": {"tldr": "A robust, real-time lane-detection method for winter driving that does not rely on traditional lane markings but on roadside delineators; uses a Bezier-curve model to fit the lane trajectory from detected posts; introduces SnowyLane, a synthetic dataset with 80,000 annotated frames under varying snow and lighting conditions; reports improved robustness under heavy snow occlusion and provides a resource for all-weather autonomous driving research.", "motivation": "Winter driving often occludes or eliminates lane markings, undermining traditional lane-detection systems. By leveraging vertical roadside posts (delineators) as indirect lane cues and fitting a smooth Bezier lane model, the approach aims to maintain reliable lane estimation in snow and adverse weather. The SnowyLane dataset supports training and evaluation in these conditions.", "method": "Detect vertical roadside delineators from sensor data; fit a smooth lane trajectory using a parameterized Bezier curve, guided by spatial consistency and road geometry; operate in real time and evaluated on the SnowyLane dataset.", "result": "Compared to state-of-the-art lane-detection systems, the method shows significantly improved robustness in adverse weather, particularly under heavy snow occlusion, and achieves real-time performance. The SnowyLane dataset provides a valuable resource for future research.", "conclusion": "The approach establishes a strong foundation for reliable lane detection in winter scenarios by exploiting roadside cues and Bezier-based lane modeling, and contributes a large synthetic dataset to support ongoing research in all-weather autonomous driving."}}
{"id": "2511.04971", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04971", "abs": "https://arxiv.org/abs/2511.04971", "authors": ["Esha Chowdhury"], "title": "Risk Prediction of Cardiovascular Disease for Diabetic Patients with Machine Learning and Deep Learning Techniques", "comment": "24 pages with 6 table and 8 figures", "summary": "Accurate prediction of cardiovascular disease (CVD) risk is crucial for\nhealthcare institutions. This study addresses the growing prevalence of\ndiabetes and its strong link to heart disease by proposing an efficient CVD\nrisk prediction model for diabetic patients using machine learning (ML) and\nhybrid deep learning (DL) approaches. The BRFSS dataset was preprocessed by\nremoving duplicates, handling missing values, identifying categorical and\nnumerical features, and applying Principal Component Analysis (PCA) for feature\nextraction. Several ML models, including Decision Trees (DT), Random Forest\n(RF), k-Nearest Neighbors (KNN), Support Vector Machine (SVM), AdaBoost, and\nXGBoost, were implemented, with XGBoost achieving the highest accuracy of\n0.9050. Various DL models, such as Artificial Neural Networks (ANN), Deep\nNeural Networks (DNN), Recurrent Neural Networks (RNN), Convolutional Neural\nNetworks (CNN), Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), and\nGated Recurrent Unit (GRU), as well as hybrid models combining CNN with LSTM,\nBiLSTM, and GRU, were also explored. Some of these models achieved perfect\nrecall (1.00), with the LSTM model achieving the highest accuracy of 0.9050.\nOur research highlights the effectiveness of ML and DL models in predicting CVD\nrisk among diabetic patients, automating and enhancing clinical\ndecision-making. High accuracy and F1 scores demonstrate these models'\npotential to improve personalized risk management and preventive strategies.", "AI": {"tldr": "ML and DL models using BRFSS data can predict CVD risk in diabetics with about 0.905 accuracy; XGBoost (ML) and LSTM (DL) perform best; PCA preprocessing; high recall in some models; supports automated risk stratification.", "motivation": "Diabetes prevalence drives higher CVD risk; an accurate, efficient risk prediction model is needed to inform prevention and clinical decision-making for diabetic patients.", "method": "Data preprocessing included deduplication, missing-value handling, feature type identification, and PCA for feature extraction. Evaluated traditional ML models (DT, RF, KNN, SVM, AdaBoost, XGBoost) and DL models (ANN, DNN, RNN, CNN, LSTM, BiLSTM, GRU) plus hybrids (CNN+LSTM/BiLSTM/GRU) on BRFSS data.", "result": "XGBoost achieved the highest ML accuracy of 0.9050. Among DL models, LSTM achieved the highest accuracy of 0.9050, with some DL models attaining perfect recall (1.00). High accuracy and F1 scores indicate strong predictive performance and potential for clinical use.", "conclusion": "ML and DL approaches can effectively predict CVD risk in diabetic patients, aiding automated risk assessment and personalized prevention strategies; robust performance suggests practical utility in supporting clinical decisions."}}
{"id": "2511.05150", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05150", "abs": "https://arxiv.org/abs/2511.05150", "authors": ["Jingsong Liu", "Han Li", "Nassir Navab", "Peter J. Sch\u00fcffler"], "title": "From Linear Probing to Joint-Weighted Token Hierarchy: A Foundation Model Bridging Global and Cellular Representations in Biomarker Detection", "comment": null, "summary": "AI-based biomarkers can infer molecular features directly from hematoxylin &\neosin (H&E) slides, yet most pathology foundation models (PFMs) rely on global\npatch-level embeddings and overlook cell-level morphology. We present a PFM\nmodel, JWTH (Joint-Weighted Token Hierarchy), which integrates large-scale\nself-supervised pretraining with cell-centric post-tuning and attention pooling\nto fuse local and global tokens. Across four tasks involving four biomarkers\nand eight cohorts, JWTH achieves up to 8.3% higher balanced accuracy and 1.2%\naverage improvement over prior PFMs, advancing interpretable and robust\nAI-based biomarker detection in digital pathology.", "AI": {"tldr": "JWTH fuses local cell-level tokens with global patch tokens via a joint-weighted token hierarchy, enabling improved AI-based biomarker detection from H&E slides.", "motivation": "Pathology foundation models (PFMs) often rely on global patch-level embeddings and overlook cell-level morphology, limiting accuracy and interpretability across biomarkers and cohorts; there is a need to integrate cell-level cues into scalable PFMs.", "method": "JWTH combines large-scale self-supervised pretraining with cell-centric post-tuning and attention pooling to fuse local (cell-level) and global (patch-level) tokens into a joint-weighted token hierarchy.", "result": "Across four biomarker tasks and eight cohorts, JWTH achieves up to 8.3% higher balanced accuracy and a 1.2% average improvement over prior PFMs, demonstrating improved accuracy and robustness.", "conclusion": "JWTH advances interpretable and robust AI-based biomarker detection in digital pathology by integrating local cell morphology with global context through a joint-weighted token hierarchy."}}
{"id": "2511.04973", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04973", "abs": "https://arxiv.org/abs/2511.04973", "authors": ["Siyuan Li", "Yifan Sun", "Lei Cheng", "Lewen Wang", "Yang Liu", "Weiqing Liu", "Jianlong Li", "Jiang Bian", "Shikai Fang"], "title": "Less Is More: Generating Time Series with LLaMA-Style Autoregression in Simple Factorized Latent Spaces", "comment": null, "summary": "Generative models for multivariate time series are essential for data\naugmentation, simulation, and privacy preservation, yet current\nstate-of-the-art diffusion-based approaches are slow and limited to\nfixed-length windows. We propose FAR-TS, a simple yet effective framework that\ncombines disentangled factorization with an autoregressive Transformer over a\ndiscrete, quantized latent space to generate time series. Each time series is\ndecomposed into a data-adaptive basis that captures static cross-channel\ncorrelations and temporal coefficients that are vector-quantized into discrete\ntokens. A LLaMA-style autoregressive Transformer then models these token\nsequences, enabling fast and controllable generation of sequences with\narbitrary length. Owing to its streamlined design, FAR-TS achieves\norders-of-magnitude faster generation than Diffusion-TS while preserving\ncross-channel correlations and an interpretable latent space, enabling\nhigh-quality and flexible time series synthesis.", "AI": {"tldr": "FAR-TS is a fast autoregressive transformer-based framework for multivariate time-series generation that disentangles data into a data-adaptive basis and a discrete latent space, enabling length-flexible synthesis with preserved cross-channel correlations and much faster generation than diffusion methods.", "motivation": "Generative models for multivariate time series are valuable for data augmentation, simulation, and privacy, but diffusion-based methods are slow and restricted to fixed-length windows. There is a need for fast, controllable, length-flexible generation with interpretable latent representations that preserve cross-channel correlations.", "method": "Decompose each time series into a data-adaptive basis capturing static cross-channel correlations and temporal coefficients vector-quantized into discrete tokens. Train a LLaMA-style autoregressive Transformer over the token sequences to model and generate time-series of arbitrary length, enabling fast, controllable synthesis in a quantized latent space.", "result": "FAR-TS achieves orders-of-magnitude faster generation than Diffusion-TS while preserving cross-channel correlations and offering an interpretable latent space, enabling high-quality and flexible time series synthesis.", "conclusion": "The FAR-TS framework provides a simple, effective approach that combines disentangled factorization with autoregressive Transformers to enable fast, flexible, and controllable multivariate time-series generation with an interpretable latent space."}}
{"id": "2511.05152", "categories": ["cs.CV", "cs.GR", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.05152", "abs": "https://arxiv.org/abs/2511.05152", "authors": ["Adrian Azzarelli", "Nantheera Anantrasirichai", "David R Bull"], "title": "Splatography: Sparse multi-view dynamic Gaussian Splatting for filmmaking challenges", "comment": null, "summary": "Deformable Gaussian Splatting (GS) accomplishes photorealistic dynamic 3-D\nreconstruction from dense multi-view video (MVV) by learning to deform a\ncanonical GS representation. However, in filmmaking, tight budgets can result\nin sparse camera configurations, which limits state-of-the-art (SotA) methods\nwhen capturing complex dynamic features. To address this issue, we introduce an\napproach that splits the canonical Gaussians and deformation field into\nforeground and background components using a sparse set of masks for frames at\nt=0. Each representation is separately trained on different loss functions\nduring canonical pre-training. Then, during dynamic training, different\nparameters are modeled for each deformation field following common filmmaking\npractices. The foreground stage contains diverse dynamic features so changes in\ncolor, position and rotation are learned. While, the background containing\nfilm-crew and equipment, is typically dimmer and less dynamic so only changes\nin point position are learned. Experiments on 3-D and 2.5-D entertainment\ndatasets show that our method produces SotA qualitative and quantitative\nresults; up to 3 PSNR higher with half the model size on 3-D scenes. Unlike the\nSotA and without the need for dense mask supervision, our method also produces\nsegmented dynamic reconstructions including transparent and dynamic textures.\nCode and video comparisons are available online:\nhttps://interims-git.github.io/", "AI": {"tldr": "Foreground/background split of Deformable Gaussian Splatting with separate pre-training and deformation parameters enables high-quality, segmented dynamic reconstructions under sparse camera setups, achieving SotA results with reduced model size and without dense mask supervision.", "motivation": "In filmmaking, budgets often yield sparse multi-view video, which challenges state-of-the-art dynamic reconstruction methods and their ability to accurately capture complex dynamic features. There is a need for robust methods that can operate under sparse camera configurations and provide interpretable segmentation of dynamic content, including transparent textures.", "method": "Split the canonical Gaussian Splatting (GS) representation into foreground and background using sparse masks available at t=0. Pre-train each representation with separate losses for canonical stages. During dynamic training, learn distinct deformation parameters for foreground and background: foreground models dynamic color, position, and rotation changes; background (e.g., film crew and equipment) is typically dim and less dynamic, so only position changes are learned. This approach reduces reliance on dense masks and adapts to sparse camera configurations common in filmmaking.", "result": "Achieves state-of-the-art qualitative and quantitative results on 3-D and 2.5-D entertainment datasets, including up to 3 PSNR improvements with about 50% model size on 3-D scenes. The method also yields segmented dynamic reconstructions, including transparent and dynamic textures, without requiring dense mask supervision.", "conclusion": "Extends Deformable Gaussian Splatting to sparse-camera filmmaking scenarios by explicitly modeling foreground and background dynamics with separate training and deformation parameters. This enables high-quality dynamic reconstructions and interpretable segmentation under budget-constrained capture setups; code and video comparisons are available online."}}
{"id": "2511.04979", "categories": ["cs.LG", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.04979", "abs": "https://arxiv.org/abs/2511.04979", "authors": ["Gimun Bae", "Seung Jun Shin"], "title": "Scaling Up ROC-Optimizing Support Vector Machines", "comment": "15 pages, Submitted to Stat", "summary": "The ROC-SVM, originally proposed by Rakotomamonjy, directly maximizes the\narea under the ROC curve (AUC) and has become an attractive alternative of the\nconventional binary classification under the presence of class imbalance.\nHowever, its practical use is limited by high computational cost, as training\ninvolves evaluating all $O(n^2)$. To overcome this limitation, we develop a\nscalable variant of the ROC-SVM that leverages incomplete U-statistics, thereby\nsubstantially reducing computational complexity. We further extend the\nframework to nonlinear classification through a low-rank kernel approximation,\nenabling efficient training in reproducing kernel Hilbert spaces. Theoretical\nanalysis establishes an error bound that justifies the proposed approximation,\nand empirical results on both synthetic and real datasets demonstrate that the\nproposed method achieves comparable AUC performance to the original ROC-SVM\nwith drastically reduced training time.", "AI": {"tldr": "A scalable ROC-SVM via incomplete U-statistics and low-rank kernel approximation, achieving similar AUC with much faster training.", "motivation": "Directly optimizing AUC for imbalanced data is attractive but computationally expensive due to O(n^2) pairwise comparisons; a scalable alternative is needed.", "method": "Use incomplete U-statistics to approximate ROC-AUC optimization, and apply a low-rank kernel approximation to enable nonlinear RKHS training. Provides theoretical error bounds for the approximation.", "result": "Empirical results on synthetic and real datasets show comparable AUC to the original ROC-SVM with substantially reduced training time.", "conclusion": "The proposed approach delivers scalable, effective ROC optimization with provable guarantees and practical speedups, enabling efficient nonlinear ROC-SVM training."}}
{"id": "2511.05131", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.05131", "abs": "https://arxiv.org/abs/2511.05131", "authors": ["Fernando Berzal"], "title": "DL101 Neural Network Outputs and Loss Functions", "comment": null, "summary": "The loss function used to train a neural network is strongly connected to its\noutput layer from a statistical point of view. This technical report analyzes\ncommon activation functions for a neural network output layer, like linear,\nsigmoid, ReLU, and softmax, detailing their mathematical properties and their\nappropriate use cases. A strong statistical justification exists for the\nselection of the suitable loss function for training a deep learning model.\nThis report connects common loss functions such as Mean Squared Error (MSE),\nMean Absolute Error (MAE), and various Cross-Entropy losses to the statistical\nprinciple of Maximum Likelihood Estimation (MLE). Choosing a specific loss\nfunction is equivalent to assuming a specific probability distribution for the\nmodel output, highlighting the link between these functions and the Generalized\nLinear Models (GLMs) that underlie network output layers. Additional scenarios\nof practical interest are also considered, such as alternative output\nencodings, constrained outputs, and distributions with heavy tails.", "AI": {"tldr": "Analyzes activation functions for neural network outputs (linear, sigmoid, ReLU, softmax) and links loss functions (MSE, MAE, cross-entropy) to statistical principles, notably MLE and GLMs, highlighting practical considerations like alternative output encodings and heavy-tailed distributions.", "motivation": "To provide a statistically grounded justification for choosing activation functions and loss functions in neural networks by relating them to probability distributions and generalized linear models, and to address practical encoding and tail behavior.", "method": "Survey/analysis of common output activations and loss functions; establish connections to MLE, GLMs, and probability distributions; discuss scenarios with alternative encodings, constrained outputs, and heavy tails.", "result": "Clarifies that selecting a loss function corresponds to assuming a particular output distribution; maps popular losses to distributional assumptions and GLMs; provides guidelines for when to use each activation/loss pair; highlights practical considerations.", "conclusion": "A principled framework links activation choices and loss functions to statistical modeling, enabling informed design of neural networks; emphasizes the impact of output distribution assumptions and practical constraints on model behavior."}}
{"id": "2511.05168", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05168", "abs": "https://arxiv.org/abs/2511.05168", "authors": ["Alexander Lappe", "Martin A. Giese"], "title": "Another BRIXEL in the Wall: Towards Cheaper Dense Features", "comment": null, "summary": "Vision foundation models achieve strong performance on both global and\nlocally dense downstream tasks. Pretrained on large images, the recent DINOv3\nmodel family is able to produce very fine-grained dense feature maps, enabling\nstate-of-the-art performance. However, computing these feature maps requires\nthe input image to be available at very high resolution, as well as large\namounts of compute due to the squared complexity of the transformer\narchitecture. To address these issues, we propose BRIXEL, a simple knowledge\ndistillation approach that has the student learn to reproduce its own feature\nmaps at higher resolution. Despite its simplicity, BRIXEL outperforms the\nbaseline DINOv3 models by large margins on downstream tasks when the resolution\nis kept fixed. Moreover, it is able to produce feature maps that are very\nsimilar to those of the teacher at a fraction of the computational cost. Code\nand model weights are available at https://github.com/alexanderlappe/BRIXEL.", "AI": {"tldr": "BRIXEL is a distillation method letting a student reproduce high-resolution dense feature maps with far less compute, outperforming DINOv3 baselines at fixed resolution.", "motivation": "Reduce compute and high-resolution input requirements for dense, transformer-based vision models while preserving fine-grained feature maps.", "method": "Knowledge distillation where the student learns to reproduce its own feature maps at higher resolution, effectively upscaling and aligning dense representations with coaching from high-resolution targets (teacher or self-generated). The approach is simple and architecture-agnostic; yields high-res maps with lower cost.", "result": "At fixed resolution, BRIXEL significantly outperforms baseline DINOv3 on downstream tasks and produces feature maps close to the teacher\u2019s with a fraction of computation.", "conclusion": "BRIXEL provides an efficient route to dense, high-resolution visual representations, achieving strong performance with reduced compute; code and weights released."}}
{"id": "2511.04980", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04980", "abs": "https://arxiv.org/abs/2511.04980", "authors": ["Rongbin Ye", "Jiaqi Chen"], "title": "Unlocking the Black Box: A Five-Dimensional Framework for Evaluating Explainable AI in Credit Risk", "comment": null, "summary": "The financial industry faces a significant challenge modeling and risk\nportfolios: balancing the predictability of advanced machine learning models,\nneural network models, and explainability required by regulatory entities (such\nas Office of the Comptroller of the Currency, Consumer Financial Protection\nBureau). This paper intends to fill the gap in the application between these\n\"black box\" models and explainability frameworks, such as LIME and SHAP.\nAuthors elaborate on the application of these frameworks on different models\nand demonstrates the more complex models with better prediction powers could be\napplied and reach the same level of the explainability, using SHAP and LIME.\nBeyond the comparison and discussion of performances, this paper proposes a\nnovel five dimensional framework evaluating Inherent Interpretability, Global\nExplanations, Local Explanations, Consistency, and Complexity to offer a\nnuanced method for assessing and comparing model explainability beyond simple\naccuracy metrics. This research demonstrates the feasibility of employing\nsophisticated, high performing ML models in regulated financial environments by\nutilizing modern explainability techniques and provides a structured approach\nto evaluate the crucial trade offs between model performance and\ninterpretability.", "AI": {"tldr": "Introduces a five-dimensional explainability framework and demonstrates that advanced ML models in finance can be explained using SHAP/LIME, aligning performance with regulatory needs.", "motivation": "Regulators require interpretability in finance; 'black box' models risk non-compliance. While SHAP/LIME exist, there is a need for a comprehensive framework to assess explainability beyond simple accuracy and to evaluate trade-offs between performance and interpretability.", "method": "Apply SHAP and LIME to multiple models in a regulated financial setting; compare predictive performance with explainability; propose a five-dimensional framework\u2014Inherent Interpretability, Global Explanations, Local Explanations, Consistency, and Complexity\u2014and provide evaluation guidelines and a feasibility demonstration for deploying high-performing models with explainability.", "result": "Findings suggest that high-performing, more complex models can achieve explainability levels comparable to simpler models when evaluated with SHAP/LIME. The five-dimensional framework enables a nuanced assessment of interpretability beyond accuracy and demonstrates the feasibility of using sophisticated ML in regulated finance under explainability constraints.", "conclusion": "The proposed framework offers a structured method to balance model performance and interpretability, supporting the deployment of advanced ML in finance within regulatory limits. It also points to future work on refining explainability metrics and practical deployment strategies."}}
{"id": "2511.05170", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05170", "abs": "https://arxiv.org/abs/2511.05170", "authors": ["Zijiang Yang", "Hanqing Chao", "Bokai Zhao", "Yelin Yang", "Yunshuo Zhang", "Dongmei Fu", "Junping Zhang", "Le Lu", "Ke Yan", "Dakai Jin", "Minfeng Xu", "Yun Bian", "Hui Jiang"], "title": "MUSE: Multi-Scale Dense Self-Distillation for Nucleus Detection and Classification", "comment": "12 pages, 7 figures", "summary": "Nucleus detection and classification (NDC) in histopathology analysis is a\nfundamental task that underpins a wide range of high-level pathology\napplications. However, existing methods heavily rely on labor-intensive\nnucleus-level annotations and struggle to fully exploit large-scale unlabeled\ndata for learning discriminative nucleus representations. In this work, we\npropose MUSE (MUlti-scale denSE self-distillation), a novel self-supervised\nlearning method tailored for NDC. At its core is NuLo (Nucleus-based Local\nself-distillation), a coordinate-guided mechanism that enables flexible local\nself-distillation based on predicted nucleus positions. By removing the need\nfor strict spatial alignment between augmented views, NuLo allows critical\ncross-scale alignment, thus unlocking the capacity of models for fine-grained\nnucleus-level representation. To support MUSE, we design a simple yet effective\nencoder-decoder architecture and a large field-of-view semi-supervised\nfine-tuning strategy that together maximize the value of unlabeled pathology\nimages. Extensive experiments on three widely used benchmarks demonstrate that\nMUSE effectively addresses the core challenges of histopathological NDC. The\nresulting models not only surpass state-of-the-art supervised baselines but\nalso outperform generic pathology foundation models.", "AI": {"tldr": "MUSE is a self-supervised framework for nucleus detection and classification that uses NuLo, a nucleus-guided local self-distillation, enabling cross-scale local representations and achieving state-of-the-art results without heavy annotations.", "motivation": "Histopathology nucleus-level annotations are labor-intensive, and existing methods fail to fully exploit large unlabeled data for discriminative nucleus representations.", "method": "MUSE introduces NuLo (Nucleus-based Local self-distillation): a coordinate-guided mechanism for flexible local distillation based on predicted nucleus positions, relaxing strict spatial alignment between augmented views to enable cross-scale alignment. It employs an encoder\u2013decoder backbone and a large field-of-view semi-supervised fine-tuning strategy to maximize unlabeled data value.", "result": "Extensive experiments on three benchmarks show MUSE surpasses state-of-the-art supervised baselines and generic pathology foundation models.", "conclusion": "MUSE addresses core challenges in nucleus detection and classification by leveraging unlabeled data to learn fine-grained nucleus representations, achieving strong, transferable performance and outperforming existing methods."}}
{"id": "2511.04981", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04981", "abs": "https://arxiv.org/abs/2511.04981", "authors": ["Zhiqi Bu"], "title": "Deep Progressive Training: scaling up depth capacity of zero/one-layer models", "comment": null, "summary": "Model depth is a double-edged sword in deep learning: deeper models achieve\nhigher accuracy but require higher computational cost. To efficiently train\nmodels at scale, an effective strategy is the progressive training, which\nscales up model capacity during training, hence significantly reducing\ncomputation with little to none performance degradation. In this work, we study\nthe depth expansion of large models through the lens of optimization theory and\nfeature learning, offering insights on the initialization of new layers,\nhyperparameter transfer, learning rate schedule, and timing of model expansion.\nSpecifically, we propose zero/one-layer progressive training for the optimal\ntradeoff between computation and loss. For example, zero/one-layer progressive\ntraining on GPT2 can save $\\approx 80\\%$ compute, or equivalently accelerate\n$\\approx 5\\times$ while achieving almost the same loss, compared to to a fully\ntrained 60-layer model with 7B parameters.", "AI": {"tldr": "Progressive depth expansion with zero/one-layer training dramatically reduces compute while preserving loss, enabling scalable training of deep models.", "motivation": "Deep networks offer higher accuracy at the cost of increased computation. Progressive training seeks to expand model capacity during training to reduce overall training cost with minimal loss degradation.", "method": "The paper analyzes depth expansion through optimization theory and feature learning, proposing zero/one-layer progressive training. It discusses effective initialization for new layers, transfer of hyperparameters, learning rate schedules, and the timing of model expansion, with theoretical and empirical justification.", "result": "Zero/one-layer progressive training on GPT-2 can save about 80% of compute (roughly a 5x speedup) while achieving almost the same loss as a fully trained 60-layer, 7B-parameter model.", "conclusion": "Depth expansion can be made efficient and practical: careful initialization and scheduling enable substantial compute savings with negligible loss increase, making progressive training a viable approach for large-scale models."}}
{"id": "2511.05171", "categories": ["cs.LG", "cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.05171", "abs": "https://arxiv.org/abs/2511.05171", "authors": ["Davide Marincione", "Donato Crisostomi", "Roberto Dessi", "Emanuele Rodol\u00e0", "Emanuele Rossi"], "title": "Model Merging Improves Zero-Shot Generalization in Bioacoustic Foundation Models", "comment": null, "summary": "Foundation models capable of generalizing across species and tasks represent\na promising new frontier in bioacoustics, with NatureLM being one of the most\nprominent examples. While its domain-specific fine-tuning yields strong\nperformance on bioacoustic benchmarks, we observe that it also introduces\ntrade-offs in instruction-following flexibility. For instance, NatureLM\nachieves high accuracy when prompted for either the common or scientific name\nindividually, but its accuracy drops significantly when both are requested in a\nsingle prompt. We address this by applying a simple model merging strategy that\ninterpolates NatureLM with its base language model, recovering\ninstruction-following capabilities with minimal loss of domain expertise.\nFinally, we show that the merged model exhibits markedly stronger zero-shot\ngeneralization, achieving over a 200% relative improvement and setting a new\nstate-of-the-art in closed-set zero-shot classification of unseen species.", "AI": {"tldr": "Merging NatureLM with its base LM recovers instruction-following while preserving domain knowledge, leading to strong zero-shot generalization and a new SOTA for unseen species in closed-set classification.", "motivation": "To overcome the trade-off between domain-specific bioacoustic accuracy and instruction-following flexibility in foundation models, enabling better zero-shot generalization across species.", "method": "Interpolate NatureLM with its base language model (a simple model merging strategy) to balance domain expertise and instruction-following.", "result": "Merged model restores instruction-following with minimal loss of domain expertise; achieves >200% relative improvement in zero-shot generalization; sets new SOTA for closed-set zero-shot classification of unseen species.", "conclusion": "Model merging is an effective and practical approach to jointly improve instruction-following and zero-shot generalization in bioacoustic foundation models."}}
{"id": "2511.05210", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05210", "abs": "https://arxiv.org/abs/2511.05210", "authors": ["Andr\u00e9 Peter Kelm", "Max Braeschke", "Emre G\u00fclsoylu", "Simone Frintrop"], "title": "Walk the Lines 2: Contour Tracking for Detailed Segmentation", "comment": "11 pages, 6 figures. Accepted at CAIP 2025: 21st International\n  Conference on Computer Analysis of Images and Patterns, Las Palmas de Gran\n  Canaria, Spain, September 22-25, 2025. To appear in: Proceedings Part I,\n  Lecture Notes in Computer Science (LNCS), Springer Nature Switzerland", "summary": "This paper presents Walk the Lines 2 (WtL2), a unique contour tracking\nalgorithm specifically adapted for detailed segmentation of infrared (IR) ships\nand various objects in RGB.1 This extends the original Walk the Lines (WtL)\n[12], which focused solely on detailed ship segmentation in color. These\ninnovative WtLs can replace the standard non-maximum suppression (NMS) by using\ncontour tracking to refine the object contour until a 1-pixel-wide closed shape\ncan be binarized, forming a segmentable area in foreground-background\nscenarios. WtL2 broadens the application range of WtL beyond its original\nscope, adapting to IR and expanding to diverse objects within the RGB context.\nTo achieve IR segmentation, we adapt its input, the object contour detector, to\nIR ships. In addition, the algorithm is enhanced to process a wide range of RGB\nobjects, outperforming the latest generation of contour-based methods when\nachieving a closed object contour, offering high peak Intersection over Union\n(IoU) with impressive details. This positions WtL2 as a compelling method for\nspecialized applications that require detailed segmentation or high-quality\nsamples, potentially accelerating progress in several niche areas of image\nsegmentation.", "AI": {"tldr": "WtL2 extends Walk the Lines to infrared and RGB object segmentation by replacing NMS with contour tracking, refining contours to 1-pixel-wide closed shapes that binarize for segmentation. It claims high detail and IoU, broadening WtL's applicability to IR ships and diverse RGB objects.", "motivation": "To achieve detailed, high-quality segmentation for infrared ships and a broader set of RGB objects, addressing limitations of NMS-based contour methods and enabling precise, closed contours with fine details.", "method": "Adapt the input to IR ships and broaden to diverse RGB objects. Replace standard NMS with contour-tracking that iteratively refines object contours until a 1-pixel-wide closed contour forms and can be binarized, yielding a segmentable foreground region.", "result": "The approach reportedly outperforms the latest contour-based methods when achieving a closed object contour, with high peak IoU and detailed boundaries, indicating strong performance on IR ships and varied RGB objects.", "conclusion": "WtL2 broadens the Origianl WtL's scope, offering a specialized, high-detail contour-based segmentation method suitable for niche applications and potentially accelerating progress in segmentation research and practice."}}
{"id": "2511.04984", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04984", "abs": "https://arxiv.org/abs/2511.04984", "authors": ["Xinheng He", "Yijia Zhang", "Haowei Lin", "Xingang Peng", "Xiangzhe Kong", "Mingyu Li", "Jianzhu Ma"], "title": "Peptide2Mol: A Diffusion Model for Generating Small Molecules as Peptide Mimics for Targeted Protein Binding", "comment": "Abstract 1 page, main text 9 pages, references 2 pages, 4 figures.\n  Submitted to RECOMB 2026", "summary": "Structure-based drug design has seen significant advancements with the\nintegration of artificial intelligence (AI), particularly in the generation of\nhit and lead compounds. However, most AI-driven approaches neglect the\nimportance of endogenous protein interactions with peptides, which may result\nin suboptimal molecule designs. In this work, we present Peptide2Mol, an\nE(3)-equivariant graph neural network diffusion model that generates small\nmolecules by referencing both the original peptide binders and their\nsurrounding protein pocket environments. Trained on large datasets and\nleveraging sophisticated modeling techniques, Peptide2Mol not only achieves\nstate-of-the-art performance in non-autoregressive generative tasks, but also\nproduces molecules with similarity to the original peptide binder.\nAdditionally, the model allows for molecule optimization and peptidomimetic\ndesign through a partial diffusion process. Our results highlight Peptide2Mol\nas an effective deep generative model for generating and optimizing bioactive\nsmall molecules from protein binding pockets.", "AI": {"tldr": "Peptide2Mol uses an E(3)-equivariant graph neural network diffusion model to generate small molecules guided by peptide binders and pocket context, achieving state-of-the-art non-autoregressive generation and enabling peptidomimetic optimization.", "motivation": "Gap: AI-driven structure-based drug design often ignores endogenous protein\u2013peptide interactions, potentially leading to suboptimal molecules; need a method that accounts for peptide binders and pocket environments.", "method": "An E(3)-equivariant GNN diffusion model, Peptide2Mol, references original peptide binders and surrounding protein pocket; non-autoregressive generation; trained on large datasets; supports partial diffusion for optimization/peptidomimetic design.", "result": "State-of-the-art performance on non-autoregressive generative tasks; molecules exhibit similarity to the original peptide binder; enables molecule optimization and peptidomimetic design.", "conclusion": "Peptide2Mol is an effective deep generative framework for generating and optimizing bioactive small molecules from protein binding pockets, integrating endogenous interactions to improve design quality."}}
{"id": "2511.05179", "categories": ["cs.LG", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.05179", "abs": "https://arxiv.org/abs/2511.05179", "authors": ["Ragini Gupta", "Naman Raina", "Bo Chen", "Li Chen", "Claudiu Danilov", "Josh Eckhardt", "Keyshla Bernard", "Klara Nahrstedt"], "title": "No One-Model-Fits-All: Uncovering Spatio-Temporal Forecasting Trade-offs with Graph Neural Networks and Foundation Models", "comment": null, "summary": "Modern IoT deployments for environmental sensing produce high volume\nspatiotemporal data to support downstream tasks such as forecasting, typically\npowered by machine learning models. While existing filtering and strategic\ndeployment techniques optimize collected data volume at the edge, they overlook\nhow variations in sampling frequencies and spatial coverage affect downstream\nmodel performance. In many forecasting models, incorporating data from\nadditional sensors denoise predictions by providing broader spatial contexts.\nThis interplay between sampling frequency, spatial coverage and different\nforecasting model architectures remain underexplored. This work presents a\nsystematic study of forecasting models - classical models (VAR), neural\nnetworks (GRU, Transformer), spatio-temporal graph neural networks (STGNNs),\nand time series foundation models (TSFMs: Chronos Moirai, TimesFM) under\nvarying spatial sensor nodes density and sampling intervals using real-world\ntemperature data in a wireless sensor network. Our results show that STGNNs are\neffective when sensor deployments are sparse and sampling rate is moderate,\nleveraging spatial correlations via encoded graph structure to compensate for\nlimited coverage. In contrast, TSFMs perform competitively at high frequencies\nbut degrade when spatial coverage from neighboring sensors is reduced.\nCrucially, the multivariate TSFM Moirai outperforms all models by natively\nlearning cross-sensor dependencies. These findings offer actionable insights\nfor building efficient forecasting pipelines in spatio-temporal systems. All\ncode for model configurations, training, dataset, and logs are open-sourced for\nreproducibility:\nhttps://github.com/UIUC-MONET-Projects/Benchmarking-Spatiotemporal-Forecast-Models", "AI": {"tldr": "A systematic study compares forecasting models under varying sensor density and sampling rates, showing STGNNs excel with sparse coverage, TSFMs excel at high-frequency data but falter with limited spatial data, and the multivariate TSFM Moirai bests all models by learning cross-sensor dependencies; code is open-sourced.", "motivation": "To understand how sampling frequency, spatial coverage, and model architecture interact to affect forecasting performance in IoT environmental sensing, and to identify robust, efficient pipelines.", "method": "Empirical study using real-world temperature data from a wireless sensor network. The study varies: (1) spatial sensor density, (2) sampling interval. Models evaluated include classical VAR, neural networks (GRU, Transformer), spatio-temporal graph neural networks (STGNNs), and time-series foundation models (TSFMs) Chronos Moirai and TimesFM. Performance across configurations is analyzed.", "result": "STGNNs perform well when deployments are sparse and sampling is moderate, leveraging spatial correlations. TSFMs are competitive at high sampling frequencies but degrade as spatial coverage from neighbors decreases. The multivariate TSFM Moirai outperforms all others by natively learning cross-sensor dependencies.", "conclusion": "Provides actionable guidance for building efficient spatio-temporal forecasting pipelines in IoT systems; all code and datasets are open-sourced for reproducibility."}}
{"id": "2511.05219", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05219", "abs": "https://arxiv.org/abs/2511.05219", "authors": ["Jiang Lin", "Xinyu Chen", "Song Wu", "Zhiqiu Zhang", "Jizhi Zhang", "Ye Wang", "Qiang Tang", "Qian Wang", "Jian Yang", "Zili Yi"], "title": "FreeControl: Efficient, Training-Free Structural Control via One-Step Attention Extraction", "comment": "Accepted by NIPS 2025", "summary": "Controlling the spatial and semantic structure of diffusion-generated images\nremains a challenge. Existing methods like ControlNet rely on handcrafted\ncondition maps and retraining, limiting flexibility and generalization.\nInversion-based approaches offer stronger alignment but incur high inference\ncost due to dual-path denoising. We present FreeControl, a training-free\nframework for semantic structural control in diffusion models. Unlike prior\nmethods that extract attention across multiple timesteps, FreeControl performs\none-step attention extraction from a single, optimally chosen key timestep and\nreuses it throughout denoising. This enables efficient structural guidance\nwithout inversion or retraining. To further improve quality and stability, we\nintroduce Latent-Condition Decoupling (LCD): a principled separation of the key\ntimestep and the noised latent used in attention extraction. LCD provides finer\ncontrol over attention quality and eliminates structural artifacts. FreeControl\nalso supports compositional control via reference images assembled from\nmultiple sources - enabling intuitive scene layout design and stronger prompt\nalignment. FreeControl introduces a new paradigm for test-time control,\nenabling structurally and semantically aligned, visually coherent generation\ndirectly from raw images, with the flexibility for intuitive compositional\ndesign and compatibility with modern diffusion models at approximately 5\npercent additional cost.", "AI": {"tldr": "Training-free, test-time control for diffusion models via one-shot attention extraction and Latent-Condition Decoupling, enabling compositional, structurally aligned generation with minimal overhead.", "motivation": "Diffusion models offer high-quality images but struggle with precise spatial and semantic control. Existing methods rely on retraining (e.g., ControlNet) or expensive inversion-based approaches, limiting flexibility, speed, and generalizability.", "method": "FreeControl uses one-step attention extraction from a single optimally chosen key timestep and reuses it across denoising. Latent-Condition Decoupling (LCD) separates the key timestep from the noised latent used in attention extraction. It supports test-time compositional control via reference images and provides approximately 5% extra computational cost, compatible with modern diffusion models.", "result": "Achieves better structural and semantic alignment without inversion or retraining, with improved stability and image quality. Enables compositional scene design from multiple references and stronger prompt alignment, at low additional cost.", "conclusion": "Introduces a new test-time control paradigm for diffusion models, delivering structurally and semantically guided generation directly from raw images with minimal overhead and broad compatibility."}}
{"id": "2511.04988", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04988", "abs": "https://arxiv.org/abs/2511.04988", "authors": ["Runsheng Ren", "Jing Li", "Yanxiu Li", "Shixun Huang", "Jun Shen", "Wanqing Li", "John Le", "Sheng Wang"], "title": "Carbon Price Forecasting with Structural Breaks: A Comparative Study of Deep Learning Models", "comment": null, "summary": "Accurately forecasting carbon prices is essential for informed energy market\ndecision-making, guiding sustainable energy planning, and supporting effective\ndecarbonization strategies. However, it remains challenging due to structural\nbreaks and high-frequency noise caused by frequent policy interventions and\nmarket shocks. Existing studies, including the most recent baseline approaches,\nhave attempted to incorporate breakpoints but often treat denoising and\nmodeling as separate processes and lack systematic evaluation across advanced\ndeep learning architectures, limiting the robustness and the generalization\ncapability. To address these gaps, this paper proposes a comprehensive hybrid\nframework that integrates structural break detection (Bai-Perron, ICSS, and\nPELT algorithms), wavelet signal denoising, and three state-of-the-art deep\nlearning models (LSTM, GRU, and TCN). Using European Union Allowance (EUA) spot\nprices from 2007 to 2024 and exogenous features such as energy prices and\npolicy indicators, the framework constructs univariate and multivariate\ndatasets for comparative evaluation. Experimental results demonstrate that our\nproposed PELT-WT-TCN achieves the highest prediction accuracy, reducing\nforecasting errors by 22.35% in RMSE and 18.63% in MAE compared to the\nstate-of-the-art baseline model (Breakpoints with Wavelet and LSTM), and by\n70.55% in RMSE and 74.42% in MAE compared to the original LSTM without\ndecomposition from the same baseline study. These findings underscore the value\nof integrating structural awareness and multiscale decomposition into deep\nlearning architectures to enhance accuracy and interpretability in carbon price\nforecasting and other nonstationary financial time series.", "AI": {"tldr": "A hybrid framework for carbon price forecasting that jointly detects structural breaks, denoises signals via wavelets, and uses deep learning models (LSTM, GRU, TCN); the PELT-WT-TCN model achieves top accuracy on EU ETS EUA data (2007\u20132024).", "motivation": "Forecasting carbon prices is crucial for energy market decisions and decarbonization but is hindered by frequent policy-induced structural breaks and high-frequency noise. A robust, generalizable approach should unify break detection, denoising, and modeling within modern DL architectures.", "method": "A comprehensive pipeline integrating structural break detection (Bai-Perron, ICSS, PELT), wavelet-based denoising, and three DL models (LSTM, GRU, TCN). Builds univariate and multivariate datasets with exogenous features (energy prices, policy indicators). Evaluates against state-of-the-art baseline (Breakpoints with Wavelet and LSTM).", "result": "The proposed PELT-WT-TCN achieved the highest prediction accuracy, reducing RMSE by 22.35% and MAE by 18.63% compared to the Breakpoints with Wavelet and LSTM baseline; and reducing RMSE by 70.55% and MAE by 74.42% compared to the original LSTM without decomposition. Demonstrates improved robustness and interpretability for carbon price forecasting and other nonstationary financial time series.", "conclusion": "Integrating structural awareness with multiscale decomposition enhances accuracy and interpretability of carbon price forecasts and can generalize to other nonstationary financial time series; the hybrid framework is a valuable blueprint for future forecasting tasks under regime shifts."}}
{"id": "2511.05229", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05229", "abs": "https://arxiv.org/abs/2511.05229", "authors": ["Mengqi Guo", "Bo Xu", "Yanyan Li", "Gim Hee Lee"], "title": "4D3R: Motion-Aware Neural Reconstruction and Rendering of Dynamic Scenes from Monocular Videos", "comment": "17 pages, 5 figures", "summary": "Novel view synthesis from monocular videos of dynamic scenes with unknown\ncamera poses remains a fundamental challenge in computer vision and graphics.\nWhile recent advances in 3D representations such as Neural Radiance Fields\n(NeRF) and 3D Gaussian Splatting (3DGS) have shown promising results for static\nscenes, they struggle with dynamic content and typically rely on pre-computed\ncamera poses. We present 4D3R, a pose-free dynamic neural rendering framework\nthat decouples static and dynamic components through a two-stage approach. Our\nmethod first leverages 3D foundational models for initial pose and geometry\nestimation, followed by motion-aware refinement. 4D3R introduces two key\ntechnical innovations: (1) a motion-aware bundle adjustment (MA-BA) module that\ncombines transformer-based learned priors with SAM2 for robust dynamic object\nsegmentation, enabling more accurate camera pose refinement; and (2) an\nefficient Motion-Aware Gaussian Splatting (MA-GS) representation that uses\ncontrol points with a deformation field MLP and linear blend skinning to model\ndynamic motion, significantly reducing computational cost while maintaining\nhigh-quality reconstruction. Extensive experiments on real-world dynamic\ndatasets demonstrate that our approach achieves up to 1.8dB PSNR improvement\nover state-of-the-art methods, particularly in challenging scenarios with large\ndynamic objects, while reducing computational requirements by 5x compared to\nprevious dynamic scene representations.", "AI": {"tldr": "Pose-free 4D dynamic neural rendering for monocular videos, using MA-BA and MA-GS to decouple static and dynamic content, achieving higher quality with fewer computations.", "motivation": "Dynamic scenes with unknown camera poses are hard for NeRF/3DGS; dynamic content and pose estimation are major bottlenecks, limiting realism in monocular video synthesis.", "method": "Two-stage pipeline: (1) initialize pose/geometry with 3D foundational models; (2) refine motion. MA-BA blends transformer-based priors with SAM2-based dynamic segmentation for robust pose refinement; MA-GS employs control points, a deformation-field MLP, and linear blend skinning to model dynamic motion efficiently.", "result": "On real-world dynamic datasets, up to 1.8 dB PSNR improvement over state-of-the-art; especially effective with large dynamic objects. Computational cost reduced by about 5x compared to previous dynamic scene representations.", "conclusion": "4D3R enables pose-free dynamic neural rendering by decoupling static and dynamic components in a two-stage framework, delivering improved quality and efficiency through MA-BA and MA-GS."}}
{"id": "2511.05250", "categories": ["cs.CV", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.05250", "abs": "https://arxiv.org/abs/2511.05250", "authors": ["Mohamed Sanim Akremi", "Rim Slama", "Hedi Tabia"], "title": "Accurate online action and gesture recognition system using detectors and Deep SPD Siamese Networks", "comment": null, "summary": "Online continuous motion recognition is a hot topic of research since it is\nmore practical in real life application cases. Recently, Skeleton-based\napproaches have become increasingly popular, demonstrating the power of using\nsuch 3D temporal data. However, most of these works have focused on\nsegment-based recognition and are not suitable for the online scenarios. In\nthis paper, we propose an online recognition system for skeleton sequence\nstreaming composed from two main components: a detector and a classifier, which\nuse a Semi-Positive Definite (SPD) matrix representation and a Siamese network.\nThe powerful statistical representations for the skeletal data given by the SPD\nmatrices and the learning of their semantic similarity by the Siamese network\nenable the detector to predict time intervals of the motions throughout an\nunsegmented sequence. In addition, they ensure the classifier capability to\nrecognize the motion in each predicted interval. The proposed detector is\nflexible and able to identify the kinetic state continuously. We conduct\nextensive experiments on both hand gesture and body action recognition\nbenchmarks to prove the accuracy of our online recognition system which in most\ncases outperforms state-of-the-art performances.", "AI": {"tldr": "An online, end-to-end skeleton-based motion recognition system with a detector and classifier that operates on streaming data using SPD representations and a Siamese network to locate intervals and classify actions, achieving state-of-the-art performance on gesture and action benchmarks.", "motivation": "Online continuous motion recognition is more practical than segment-based methods; skeleton-based approaches are powerful but often assume pre-segmented sequences, limiting real-time applicability.", "method": "A two-component system: detector + classifier. Uses Semi-Positive Definite (SPD) matrix representations to capture statistics of skeletal data and a Siamese network to learn semantic similarity, enabling interval detection in unsegmented streams and per-interval action classification.", "result": "Extensive experiments on hand gesture and body action benchmarks show high accuracy, with performances surpassing state-of-the-art in most cases.", "conclusion": "The proposed SPD-Siamese online framework effectively enables continuous online recognition from skeletal streams, providing accurate interval detection and action classification in online settings."}}
{"id": "2511.05245", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05245", "abs": "https://arxiv.org/abs/2511.05245", "authors": ["Xincheng Yao", "Yan Luo", "Zefeng Qian", "Chongyang Zhang"], "title": "ADPretrain: Advancing Industrial Anomaly Detection via Anomaly Representation Pretraining", "comment": "Accepted by NeurIPS 2025", "summary": "The current mainstream and state-of-the-art anomaly detection (AD) methods\nare substantially established on pretrained feature networks yielded by\nImageNet pretraining. However, regardless of supervised or self-supervised\npretraining, the pretraining process on ImageNet does not match the goal of\nanomaly detection (i.e., pretraining in natural images doesn't aim to\ndistinguish between normal and abnormal). Moreover, natural images and\nindustrial image data in AD scenarios typically have the distribution shift.\nThe two issues can cause ImageNet-pretrained features to be suboptimal for AD\ntasks. To further promote the development of the AD field, pretrained\nrepresentations specially for AD tasks are eager and very valuable. To this\nend, we propose a novel AD representation learning framework specially designed\nfor learning robust and discriminative pretrained representations for\nindustrial anomaly detection. Specifically, closely surrounding the goal of\nanomaly detection (i.e., focus on discrepancies between normals and anomalies),\nwe propose angle- and norm-oriented contrastive losses to maximize the angle\nsize and norm difference between normal and abnormal features simultaneously.\nTo avoid the distribution shift from natural images to AD images, our\npretraining is performed on a large-scale AD dataset, RealIAD. To further\nalleviate the potential shift between pretraining data and downstream AD\ndatasets, we learn the pretrained AD representations based on the\nclass-generalizable representation, residual features. For evaluation, based on\nfive embedding-based AD methods, we simply replace their original features with\nour pretrained representations. Extensive experiments on five AD datasets and\nfive backbones consistently show the superiority of our pretrained features.\nThe code is available at https://github.com/xcyao00/ADPretrain.", "AI": {"tldr": "Proposes a pretrained anomaly-detection-specific representation learned via angle- and norm-oriented contrastive losses on RealIAD, evaluated by replacing features in five AD methods across five datasets/backbones, showing consistent gains over ImageNet-pretrained features; code released.", "motivation": "ImageNet pretraining is not tailored for anomaly detection and may not generalize well due to distribution shift between natural images and industrial AD data; there is a need for representations specifically designed for AD tasks.", "method": "Pretrain on RealIAD using angle-oriented contrastive loss (maximize angle between normal and abnormal features) and norm-oriented contrastive loss (maximize norm difference). Use residual, class-generalizable representations. Then evaluate by substituting pretrained features into five embedding-based AD methods across multiple datasets/backbones.", "result": "Extensive experiments across five AD datasets and five backbones show that the pretrained AD representations consistently outperform ImageNet-pretrained features when embedded into five AD methods.", "conclusion": "AD-specific pretrained representations mitigate distribution shift and improve performance over ImageNet-based features; RealIAD is effective for pretraining; the approach is generalizable to various embedding-based AD methods and datasets; code is available."}}
{"id": "2511.05263", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05263", "abs": "https://arxiv.org/abs/2511.05263", "authors": ["Qi Sun", "Dingju Zhou", "Lina Zhang"], "title": "OregairuChar: A Benchmark Dataset for Character Appearance Frequency Analysis in My Teen Romantic Comedy SNAFU", "comment": null, "summary": "The analysis of character appearance frequency is essential for understanding\nnarrative structure, character prominence, and story progression in anime. In\nthis work, we introduce OregairuChar, a benchmark dataset designed for\nappearance frequency analysis in the anime series My Teen Romantic Comedy\nSNAFU. The dataset comprises 1600 manually selected frames from the third\nseason, annotated with 2860 bounding boxes across 11 main characters.\nOregairuChar captures diverse visual challenges, including occlusion, pose\nvariation, and inter-character similarity, providing a realistic basis for\nappearance-based studies. To enable quantitative research, we benchmark several\nobject detection models on the dataset and leverage their predictions for\nfine-grained, episode-level analysis of character presence over time. This\napproach reveals patterns of character prominence and their evolution within\nthe narrative. By emphasizing appearance frequency, OregairuChar serves as a\nvaluable resource for exploring computational narrative dynamics and\ncharacter-centric storytelling in stylized media.", "AI": {"tldr": "Dataset and benchmarking for appearance-frequency analysis of characters in the anime Oregairu (My Teen Romantic Comedy SNAFU), enabling episode-level narrative insights.", "motivation": "Understanding narrative structure, character prominence, and story progression in stylized media; current lack of annotated datasets for appearance frequency.", "method": "Construct OregairuChar with 1600 manually selected frames from season 3, annotated with 2860 bounding boxes for 11 main characters; evaluate multiple object detectors on the dataset and perform episode-level analysis of character presence over time.", "result": "Object detectors yield predictions enabling fine-grained analysis of character presence; patterns of prominence and their evolution within episodes can be observed.", "conclusion": "OregairuChar is a valuable resource for computational narrative dynamics and character-centric storytelling in stylized media, enabling appearance-frequency studies."}}
{"id": "2511.05265", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05265", "abs": "https://arxiv.org/abs/2511.05265", "authors": ["Taihelong Zeng", "Yun Lin", "Yuhe Shi", "Yan Li", "Zhiqing Wei", "Xuanru Ji"], "title": "An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones", "comment": null, "summary": "The emergence of truck-drone collaborative systems in last-mile logistics has\npositioned the Traveling Salesman Problem with Drones (TSP-D) as a pivotal\nextension of classical routing optimization, where synchronized vehicle\ncoordination promises substantial operational efficiency and reduced\nenvironmental impact, yet introduces NP-hard combinatorial complexity beyond\nthe reach of conventional optimization paradigms. Deep reinforcement learning\noffers a theoretically grounded framework to address TSP-D's inherent\nchallenges through self-supervised policy learning and adaptive\ndecision-making. This study proposes a hierarchical Actor-Critic deep\nreinforcement learning framework for solving the TSP-D problem. The\narchitecture consists of two primary components: a Transformer-inspired encoder\nand an efficient Minimal Gated Unit decoder. The encoder incorporates a novel,\noptimized k-nearest neighbors sparse attention mechanism specifically for\nfocusing on relevant spatial relationships, further enhanced by the integration\nof global node features. The Minimal Gated Unit decoder processes these encoded\nrepresentations to efficiently generate solution sequences. The entire\nframework operates within an asynchronous advantage actor-critic paradigm.\nExperimental results show that, on benchmark TSP-D instances of various scales\n(N=10 to 100), the proposed model can obtain competitive or even superior\nsolutions in shorter average computation times compared to high-performance\nheuristic algorithms and existing reinforcement learning methods. Moreover,\ncompared to advanced reinforcement learning algorithm benchmarks, the proposed\nframework significantly reduces the total training time required while\nachieving superior final performance, highlighting its notable advantage in\ntraining efficiency.", "AI": {"tldr": "A hierarchical deep reinforcement learning framework for the TSP-D using a Transformer-based encoder with sparse attention and a Minimal Gated Unit decoder within an asynchronous actor-critic setup, delivering competitive solutions with faster training and inference on N=10\u2013100 instances.", "motivation": "The Traveling Salesman Problem with Drones (TSP-D) extends classical routing with truck-drone coordination, offering potential efficiency and environmental benefits but presenting NP-hard complexity. Deep reinforcement learning offers self-supervised policy learning for adaptive routing decisions, yet existing RL approaches face training efficiency and scalability challenges.", "method": "A hierarchical Actor-Critic DRL architecture: a Transformer-inspired encoder with an optimized k-NN sparse attention mechanism and global node features, coupled with a Minimal Gated Unit decoder to generate solution sequences. The model is trained within an asynchronous advantage actor-critic framework (A3C-like).", "result": "On benchmark TSP-D instances with sizes N ranging from 10 to 100, the proposed model achieves competitive or superior solution quality while exhibiting shorter average computation times compared with high-performance heuristics and existing RL methods. Additionally, it substantially reduces total training time relative to advanced RL baselines while attaining better final performance.", "conclusion": "The framework demonstrates effective and training-efficient solving of TSP-D, with architectural choices\u2014sparse attention, global features, and a compact decoder\u2014driving both solution quality and training efficiency. These contributions support scalability to moderate problem sizes and suggest applicability to broader drone-enabled VRPs, albeit with future work needed to assess scalability and real-world constraints."}}
{"id": "2511.05253", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.05253", "abs": "https://arxiv.org/abs/2511.05253", "authors": ["Tiziano Natali", "Karin A. Olthof", "Niels F. M. Kok", "Koert F. D. Kuhlmann", "Theo J. M. Ruers", "Matteo Fusaglia"], "title": "Automatic segmentation of colorectal liver metastases for ultrasound-based navigated resection", "comment": null, "summary": "Introduction: Accurate intraoperative delineation of colorectal liver\nmetastases (CRLM) is crucial for achieving negative resection margins but\nremains challenging using intraoperative ultrasound (iUS) due to low contrast,\nnoise, and operator dependency. Automated segmentation could enhance precision\nand efficiency in ultrasound-based navigation workflows.\n  Methods: Eighty-five tracked 3D iUS volumes from 85 CRLM patients were used\nto train and evaluate a 3D U-Net implemented via the nnU-Net framework. Two\nvariants were compared: one trained on full iUS volumes and another on cropped\nregions around tumors. Segmentation accuracy was assessed using Dice Similarity\nCoefficient (DSC), Hausdorff Distance (HDist.), and Relative Volume Difference\n(RVD) on retrospective and prospective datasets. The workflow was integrated\ninto 3D Slicer for real-time intraoperative use.\n  Results: The cropped-volume model significantly outperformed the full-volume\nmodel across all metrics (AUC-ROC = 0.898 vs 0.718). It achieved median DSC =\n0.74, recall = 0.79, and HDist. = 17.1 mm comparable to semi-automatic\nsegmentation but with ~4x faster execution (~ 1 min). Prospective\nintraoperative testing confirmed robust and consistent performance, with\nclinically acceptable accuracy for real-time surgical guidance.\n  Conclusion: Automatic 3D segmentation of CRLM in iUS using a cropped 3D U-Net\nprovides reliable, near real-time results with minimal operator input. The\nmethod enables efficient, registration-free ultrasound-based navigation for\nhepatic surgery, approaching expert-level accuracy while substantially reducing\nmanual workload and procedure time.", "AI": {"tldr": "Cropped-region 3D U-Net on intraoperative 3D ultrasound enables near real-time automated CRLM delineation with improved accuracy over full-volume approaches.", "motivation": "To improve intraoperative delineation of colorectal liver metastases (CRLM) by reducing noise and operator dependency in iUS, enabling automated, efficient navigation during hepatic surgery.", "method": "Train/evaluate a 3D U-Net (nnU-Net framework) on 85 tracked 3D iUS volumes from CRLM patients; compare full-volume vs cropped-tumor regions; evaluate with DSC, HDist, and RVD on retrospective and prospective data; integrate into 3D Slicer for real-time use.", "result": "Cropped-volume model outperforms full-volume (AUC-ROC 0.898 vs 0.718); median DSC 0.74, recall 0.79, HDist 17.1 mm; ~1 min per inference; robust in prospective intraoperative testing; clinically acceptable accuracy for real-time guidance.", "conclusion": "Automatic cropping-based 3D U-Net segmentation provides reliable, near real-time CRLM delineation in iUS, enabling registration-free ultrasound-guided navigation with reduced manual workload and procedure time."}}
{"id": "2511.05114", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05114", "abs": "https://arxiv.org/abs/2511.05114", "authors": ["\u00c1lvaro Guglielmin Becker", "Lana Bertoldo Rossato", "Anderson Rocha Tavares"], "title": "Usando LLMs para Programar Jogos de Tabuleiro e Varia\u00e7\u00f5es", "comment": "Accepted for presentation at the I Escola Regional de Aprendizado de\n  M\\'aquina e Intelig\\^encia Artificial da Regi\\~ao Sul, 2025, in Portuguese\n  language", "summary": "Creating programs to represent board games can be a time-consuming task.\nLarge Language Models (LLMs) arise as appealing tools to expedite this process,\ngiven their capacity to efficiently generate code from simple contextual\ninformation. In this work, we propose a method to test how capable three LLMs\n(Claude, DeepSeek and ChatGPT) are at creating code for board games, as well as\nnew variants of existing games.", "AI": {"tldr": "Three LLMs (Claude, DeepSeek, ChatGPT) are evaluated for generating code for board games and their variants; the abstract outlines a testing approach rather than reporting results.", "motivation": "Board game coding is time-consuming; LLMs could speed up development by turning simple prompts into working code.", "method": "They propose a method to test the capability of Claude, DeepSeek, and ChatGPT at producing code for board games and variants.", "result": "The abstract does not report results.", "conclusion": "No conclusions are stated; the work focuses on proposing a testing methodology for LLM-assisted board game coding."}}
{"id": "2511.05266", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05266", "abs": "https://arxiv.org/abs/2511.05266", "authors": ["Gabriel Serr\u00e3o Seabra", "Nikolaj T. M\u00fccke", "Vinicius Luiz Santos Silva", "Alexandre A. Emerick", "Denis Voskov", "Femke Vossepoel"], "title": "Integrating Score-Based Diffusion Models with Machine Learning-Enhanced Localization for Advanced Data Assimilation in Geological Carbon Storage", "comment": "Corresponding author: Gabriel Serr\\~ao Seabra", "summary": "Accurate characterization of subsurface heterogeneity is important for the\nsafe and effective implementation of geological carbon storage (GCS) projects.\nThis paper explores how machine learning methods can enhance data assimilation\nfor GCS with a framework that integrates score-based diffusion models with\nmachine learning-enhanced localization in channelized reservoirs during CO$_2$\ninjection. We employ a machine learning-enhanced localization framework that\nuses large ensembles ($N_s = 5000$) with permeabilities generated by the\ndiffusion model and states computed by simple ML algorithms to improve\ncovariance estimation for the Ensemble Smoother with Multiple Data Assimilation\n(ESMDA). We apply ML algorithms to a prior ensemble of channelized permeability\nfields, generated with the geostatistical model FLUVSIM. Our approach is\napplied on a CO$_2$ injection scenario simulated using the Delft Advanced\nResearch Terra Simulator (DARTS). Our ML-based localization maintains\nsignificantly more ensemble variance than when localization is not applied,\nwhile achieving comparable data-matching quality. This framework has practical\nimplications for GCS projects, helping improve the reliability of uncertainty\nquantification for risk assessment.", "AI": {"tldr": "Diffusion-model\u2013driven ML localization within ESMDA improves covariance estimation and preserves ensemble spread in CO2 injection simulations, keeping data fit comparable to traditional methods.", "motivation": "Need for accurate subsurface heterogeneity characterization and reliable uncertainty quantification in geological carbon storage; traditional localization can overly shrink ensemble spread and misrepresent covariance.", "method": "Generate priors with FLUVSIM channelized permeability fields; use score-based diffusion model to create permeabilities; large ensembles (Ns=5000). Apply ML-enhanced localization using ML algorithms to estimate states and permeabilities; integrate into Ensemble Smoother with Multiple Data Assimilation (ESMDA). Simulate CO2 injection in Delft Advanced Research Terra Simulator (DARTS). Compare with/without ML localization; assess variance preservation and data-misfit.", "result": "ML-based localization preserves significantly more ensemble variance than non-localized or traditional setups while achieving comparable data-matching quality; demonstrates improved covariance estimation and actionable uncertainty quantification.", "conclusion": "The integrated diffusion-ML localization framework enhances reliability of uncertainty quantification for risk assessment in GCS projects and offers practical benefits for robust risk analysis."}}
{"id": "2511.05124", "categories": ["cs.LG", "I.2.6; I.2.7"], "pdf": "https://arxiv.org/pdf/2511.05124", "abs": "https://arxiv.org/abs/2511.05124", "authors": ["Felix Divo", "Maurice Kraus", "Anh Q. Nguyen", "Hao Xue", "Imran Razzak", "Flora D. Salim", "Kristian Kersting", "Devendra Singh Dhami"], "title": "QuAnTS: Question Answering on Time Series", "comment": null, "summary": "Text offers intuitive access to information. This can, in particular,\ncomplement the density of numerical time series, thereby allowing improved\ninteractions with time series models to enhance accessibility and\ndecision-making. While the creation of question-answering datasets and models\nhas recently seen remarkable growth, most research focuses on question\nanswering (QA) on vision and text, with time series receiving minute attention.\nTo bridge this gap, we propose a challenging novel time series QA (TSQA)\ndataset, QuAnTS, for Question Answering on Time Series data. Specifically, we\npose a wide variety of questions and answers about human motion in the form of\ntracked skeleton trajectories. We verify that the large-scale QuAnTS dataset is\nwell-formed and comprehensive through extensive experiments. Thoroughly\nevaluating existing and newly proposed baselines then lays the groundwork for a\ndeeper exploration of TSQA using QuAnTS. Additionally, we provide human\nperformances as a key reference for gauging the practical usability of such\nmodels. We hope to encourage future research on interacting with time series\nmodels through text, enabling better decision-making and more transparent\nsystems.", "AI": {"tldr": "Proposes QuAnTS, a large-scale time-series QA dataset focused on human motion skeleton trajectories, plus baselines and human performance, to spur research in TSQA.", "motivation": "Time-series QA is underexplored compared with QA for vision/text. Textual access to time-series data can improve accessibility and decision-making. The authors create a dataset and baselines to bridge this gap and enable research on interacting with time-series models via text.", "method": "Introduce QuAnTS, a large-scale dataset with diverse questions and answers about human motion from tracked skeleton trajectories; validate dataset quality via extensive experiments; evaluate existing and new baselines; include human performance as a reference.", "result": "QuAnTS is shown to be well-formed and comprehensive; baseline evaluations are conducted to establish a foundation for TSQA; human performance is provided as a reference, demonstrating practical usability.", "conclusion": "The work aims to spur future research on interacting with time-series models through text, enabling better decision-making and more transparent systems."}}
{"id": "2511.05271", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05271", "abs": "https://arxiv.org/abs/2511.05271", "authors": ["Jack Hong", "Chenxiao Zhao", "ChengLin Zhu", "Weiheng Lu", "Guohai Xu", "Xing Yu"], "title": "DeepEyesV2: Toward Agentic Multimodal Model", "comment": "Homepage: https://visual-agent.github.io/", "summary": "Agentic multimodal models should not only comprehend text and images, but\nalso actively invoke external tools, such as code execution environments and\nweb search, and integrate these operations into reasoning. In this work, we\nintroduce DeepEyesV2 and explore how to build an agentic multimodal model from\nthe perspectives of data construction, training methods, and model evaluation.\nWe observe that direct reinforcement learning alone fails to induce robust\ntool-use behavior. This phenomenon motivates a two-stage training pipeline: a\ncold-start stage to establish tool-use patterns, and reinforcement learning\nstage to further refine tool invocation. We curate a diverse, moderately\nchallenging training dataset, specifically including examples where tool use is\nbeneficial. We further introduce RealX-Bench, a comprehensive benchmark\ndesigned to evaluate real-world multimodal reasoning, which inherently requires\nthe integration of multiple capabilities, including perception, search, and\nreasoning. We evaluate DeepEyesV2 on RealX-Bench and other representative\nbenchmarks, demonstrating its effectiveness across real-world understanding,\nmathematical reasoning, and search-intensive tasks. Moreover, DeepEyesV2\nexhibits task-adaptive tool invocation, tending to use image operations for\nperception tasks and numerical computations for reasoning tasks. Reinforcement\nlearning further enables complex tool combinations and allows model to\nselectively invoke tools based on context. We hope our study can provide\nguidance for community in developing agentic multimodal models.", "AI": {"tldr": "DeepEyesV2 proposes an agentic multimodal model that learns to actively use external tools via a two-stage training pipeline and a new RealX-Bench benchmark, achieving robust, context-aware tool use across perception and reasoning.", "motivation": "To enable multimodal models to go beyond passive understanding and become capable of orchestrating tool use (code, search) to handle real-world, tool-requiring tasks.", "method": "Two-stage training: cold-start to bootstrap tool-use patterns, then reinforcement learning to refine tool invocation; curated dataset emphasizing beneficial tool use; RealX-Bench benchmark for evaluation; analysis of task-adaptive tool invocation; RL enables complex tool combinations and context-based selection.", "result": "DeepEyesV2 demonstrates effectiveness across real-world understanding, mathematical reasoning, and search-intensive tasks; shows task-adaptive tool usage (image operations for perception, numerical computations for reasoning); RL improves tool repertoire and selective invocation.", "conclusion": "The study provides practical guidance for building agentic multimodal models and highlights how structured data and staged training can cultivate robust tool use in multimodal reasoning."}}
{"id": "2511.05299", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05299", "abs": "https://arxiv.org/abs/2511.05299", "authors": ["Zhenyu Yang", "Kairui Zhang", "Yuhang Hu", "Bing Wang", "Shengsheng Qian", "Bin Wen", "Fan Yang", "Tingting Gao", "Weiming Dong", "Changsheng Xu"], "title": "LiveStar: Live Streaming Assistant for Real-World Online Video Understanding", "comment": "NeurIPS 2025 Accepted", "summary": "Despite significant progress in Video Large Language Models (Video-LLMs) for\noffline video understanding, existing online Video-LLMs typically struggle to\nsimultaneously process continuous frame-by-frame inputs and determine optimal\nresponse timing, often compromising real-time responsiveness and narrative\ncoherence. To address these limitations, we introduce LiveStar, a pioneering\nlive streaming assistant that achieves always-on proactive responses through\nadaptive streaming decoding. Specifically, LiveStar incorporates: (1) a\ntraining strategy enabling incremental video-language alignment for\nvariable-length video streams, preserving temporal consistency across\ndynamically evolving frame sequences; (2) a response-silence decoding framework\nthat determines optimal proactive response timing via a single forward pass\nverification; (3) memory-aware acceleration via peak-end memory compression for\nonline inference on 10+ minute videos, combined with streaming key-value cache\nto achieve 1.53x faster inference. We also construct an OmniStar dataset, a\ncomprehensive dataset for training and benchmarking that encompasses 15 diverse\nreal-world scenarios and 5 evaluation tasks for online video understanding.\nExtensive experiments across three benchmarks demonstrate LiveStar's\nstate-of-the-art performance, achieving an average 19.5% improvement in\nsemantic correctness with 18.1% reduced timing difference compared to existing\nonline Video-LLMs, while improving FPS by 12.0% across all five OmniStar tasks.\nOur model and dataset can be accessed at https://github.com/yzy-bupt/LiveStar.", "AI": {"tldr": "LiveStar introduces an always-on proactive streaming assistant for online Video-LLMs, combining adaptive streaming decoding, incremental video-language alignment, and memory-efficient online inference to boost real-time performance and narrative coherence on long videos, validated on the OmniStar dataset.", "motivation": "Online Video-LLMs struggle to process continuous frame-by-frame inputs while determining optimal response timing, leading to latency and coherence issues for long videos.", "method": "Threefold approach: (1) incremental video-language alignment for variable-length streams to preserve temporal consistency; (2) response-silence decoding to select proactive timing via a single forward-pass verification; (3) memory-aware acceleration using peak-end memory compression and a streaming key-value cache to enable online inference on 10+ minute videos, achieving 1.53x faster inference.", "result": "State-of-the-art performance: 19.5% improvement in semantic correctness and 18.1% reduction in timing difference versus existing online Video-LLMs; 12.0% FPS improvement across five OmniStar tasks; OmniStar dataset includes 15 scenarios and 5 evaluation tasks; code released at GitHub.", "conclusion": "LiveStar enables always-on proactive responses for online video understanding, advancing real-time capabilities of Video-LLMs and providing a benchmark/dataset (OmniStar) for training and evaluation."}}
{"id": "2511.05292", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05292", "abs": "https://arxiv.org/abs/2511.05292", "authors": ["Jiaxi Yin", "Pengcheng Wang", "Han Ding", "Fei Wang"], "title": "What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs", "comment": "5 pages", "summary": "Accurate food intake detection is vital for dietary monitoring and chronic\ndisease prevention. Traditional self-report methods are prone to recall bias,\nwhile camera-based approaches raise concerns about privacy. Furthermore,\nexisting wearable-based methods primarily focus on a limited number of food\ntypes, such as hamburgers and pizza, failing to address the vast diversity of\nChinese cuisine. To bridge this gap, we propose CuisineSense, a system that\nclassifies Chinese food types by integrating hand motion cues from a smartwatch\nwith head dynamics from smart glasses. To filter out irrelevant daily\nactivities, we design a two-stage detection pipeline. The first stage\nidentifies eating states by distinguishing characteristic temporal patterns\nfrom non-eating behaviors. The second stage then conducts fine-grained food\ntype recognition based on the motions captured during food intake. To evaluate\nCuisineSense, we construct a dataset comprising 27.5 hours of IMU recordings\nacross 11 food categories and 10 participants. Experiments demonstrate that\nCuisineSense achieves high accuracy in both eating state detection and food\nclassification, offering a practical solution for unobtrusive, wearable-based\ndietary monitoring.The system code is publicly available at\nhttps://github.com/joeeeeyin/CuisineSense.git.", "AI": {"tldr": "CuisineSense combines smartwatch hand-motion cues with head-dynamics from smart glasses in a two-stage pipeline to detect eating and classify Chinese dishes across 11 categories, validated on 27.5 hours of IMU data from 10 participants, achieving high accuracy.", "motivation": "Addresses (1) recall bias in self-report dietary data, (2) privacy concerns with camera-based monitoring, and (3) limited food-type coverage of existing wearables, by focusing on the diversity of Chinese cuisine with unobtrusive devices.", "method": "Two-stage approach: Stage 1 detects eating states by extracting characteristic temporal patterns from multimodal sensor data (hand motion from a smartwatch and head dynamics from smart glasses) to filter irrelevant activities. Stage 2 performs fine-grained food-type recognition from the intake-motion cues. Uses IMU data; dataset consists of 27.5 hours across 11 food categories with 10 participants; code released publicly.", "result": "Experimental results show high accuracy for both eating-state detection and food-type classification, demonstrating the practicality of unobtrusive, wearable-based dietary monitoring.", "conclusion": "CuisineSense demonstrates feasibility of privacy-preserving, multimodal wearable systems for broad Chinese cuisine recognition, offering a practical solution for continuous dietary monitoring and enabling real-world deployment; code is publicly available."}}
{"id": "2511.05163", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05163", "abs": "https://arxiv.org/abs/2511.05163", "authors": ["Aras Erarslan", "Carlos Sevilla Salcedo", "Ville Tanskanen", "Anni Nisov", "Eero P\u00e4iv\u00e4kumpu", "Heikki Aisala", "Kaisu Honkap\u00e4\u00e4", "Arto Klami", "Petrus Mikkola"], "title": "Consecutive Preferential Bayesian Optimization", "comment": null, "summary": "Preferential Bayesian optimization allows optimization of objectives that are\neither expensive or difficult to measure directly, by relying on a minimal\nnumber of comparative evaluations done by a human expert. Generating candidate\nsolutions for evaluation is also often expensive, but this cost is ignored by\nexisting methods. We generalize preference-based optimization to explicitly\naccount for production and evaluation costs with Consecutive Preferential\nBayesian Optimization, reducing production cost by constraining comparisons to\ninvolve previously generated candidates. We also account for the perceptual\nambiguity of the oracle providing the feedback by incorporating a\nJust-Noticeable Difference threshold into a probabilistic preference model to\ncapture indifference to small utility differences. We adapt an\ninformation-theoretic acquisition strategy to this setting, selecting new\nconfigurations that are most informative about the unknown optimum under a\npreference model accounting for the perceptual ambiguity. We empirically\ndemonstrate a notable increase in accuracy in setups with high production costs\nor with indifference feedback.", "AI": {"tldr": "Introduces Consecutive Preferential Bayesian Optimization to account for production costs and perceptual ambiguity in preference-based optimization; uses constrained comparisons, a Just-Noticeable Difference threshold, and information-theoretic acquisition, achieving higher accuracy when production costs are high or feedback is indifferent.", "motivation": "Standard preference-based optimization assumes friendly (low-cost) evaluations and unambiguous feedback, but in many real-world scenarios both evaluation production costs and perceptual ambiguity of human feedback are significant. The work aims to make Bayesian optimization more practical by explicitly modeling these costs and ambiguities.", "method": "Develops Consecutive Preferential Bayesian Optimization (CPBO) that constrains comparisons to previously generated candidates to reduce production costs; incorporates a Just-Noticeable Difference (JND) threshold into a probabilistic preference model to capture indifference to small utility differences; uses an information-theoretic acquisition strategy to select configurations that maximize information about the optimum under the augmented preference model.", "result": "Empirical experiments show a notable increase in accuracy in settings with high production costs or with indifference feedback.", "conclusion": "CPBO reduces production costs while effectively handling perceptual ambiguity, improving optimization efficiency when evaluations are costly or feedback is non-discriminative."}}
{"id": "2511.05308", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05308", "abs": "https://arxiv.org/abs/2511.05308", "authors": ["Matteo Bastico", "David Ryckelynck", "Laurent Cort\u00e9", "Yannick Tillier", "Etienne Decenci\u00e8re"], "title": "Rethinking Metrics and Diffusion Architecture for 3D Point Cloud Generation", "comment": "This paper has been accepted at International Conference on 3D Vision\n  (3DV) 2026", "summary": "As 3D point clouds become a cornerstone of modern technology, the need for\nsophisticated generative models and reliable evaluation metrics has grown\nexponentially. In this work, we first expose that some commonly used metrics\nfor evaluating generated point clouds, particularly those based on Chamfer\nDistance (CD), lack robustness against defects and fail to capture geometric\nfidelity and local shape consistency when used as quality indicators. We\nfurther show that introducing samples alignment prior to distance calculation\nand replacing CD with Density-Aware Chamfer Distance (DCD) are simple yet\nessential steps to ensure the consistency and robustness of point cloud\ngenerative model evaluation metrics. While existing metrics primarily focus on\ndirectly comparing 3D Euclidean coordinates, we present a novel metric, named\nSurface Normal Concordance (SNC), which approximates surface similarity by\ncomparing estimated point normals. This new metric, when combined with\ntraditional ones, provides a more comprehensive evaluation of the quality of\ngenerated samples. Finally, leveraging recent advancements in transformer-based\nmodels for point cloud analysis, such as serialized patch attention , we\npropose a new architecture for generating high-fidelity 3D structures, the\nDiffusion Point Transformer. We perform extensive experiments and comparisons\non the ShapeNet dataset, showing that our model outperforms previous solutions,\nparticularly in terms of quality of generated point clouds, achieving new\nstate-of-the-art. Code available at\nhttps://github.com/matteo-bastico/DiffusionPointTransformer.", "AI": {"tldr": "Chamfer Distance-based metrics for 3D point clouds are brittle to defects and misalignment; we introduce Density-Aware Chamfer Distance (DCD) with an alignment prior, and a Surface Normal Concordance (SNC) metric for local surface fidelity, alongside a Diffusion Point Transformer that achieves state-of-the-art results on ShapeNet; code is released.", "motivation": "Existing evaluation metrics (CD-based) fail to robustly assess generated point clouds, missing geometric fidelity and local shape consistency. There is a need for alignment-aware, density-sensitive metrics and complementary normal-based similarity, coupled with architectures that deliver high-fidelity 3D structures.", "method": "1) Diagnose robustness issues of Chamfer Distance for point clouds. 2) Propose an alignment-prior pre-processing before distance computation. 3) Replace CD with Density-Aware Chamfer Distance (DCD). 4) Introduce Surface Normal Concordance (SNC) by comparing estimated normals to capture surface similarity. 5) Build Diffusion Point Transformer leveraging serialized patch attention for high-fidelity 3D generation. 6) Evaluate on ShapeNet with proposed metrics and baseline methods; release code.", "result": "DCD improves robustness of evaluation metrics, SNC captures surface similarity and complements traditional metrics, and the Diffusion Point Transformer achieves state-of-the-art quality in generated point clouds on ShapeNet, outperforming previous methods. Code available at the provided GitHub link.", "conclusion": "Combining a density-aware, alignment-considerate evaluation suite (DCD + SNC) with a powerful diffusion-based transformer model yields robust assessment and high-quality generation for 3D point clouds, advancing the state-of-the-art; public code is released."}}
{"id": "2511.05293", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05293", "abs": "https://arxiv.org/abs/2511.05293", "authors": ["Rui Yan", "Yibo Li", "Han Ding", "Fei Wang"], "title": "Cross-domain EEG-based Emotion Recognition with Contrastive Learning", "comment": "5 pages", "summary": "Electroencephalogram (EEG)-based emotion recognition is vital for affective\ncomputing but faces challenges in feature utilization and cross-domain\ngeneralization. This work introduces EmotionCLIP, which reformulates\nrecognition as an EEG-text matching task within the CLIP framework. A tailored\nbackbone, SST-LegoViT, captures spatial, spectral, and temporal features using\nmulti-scale convolution and Transformer modules. Experiments on SEED and\nSEED-IV datasets show superior cross-subject accuracies of 88.69% and 73.50%,\nand cross-time accuracies of 88.46% and 77.54%, outperforming existing models.\nResults demonstrate the effectiveness of multimodal contrastive learning for\nrobust EEG emotion recognition.", "AI": {"tldr": "Introduces EmotionCLIP, a CLIP-based EEG\u2013text matching framework with an SST-LegoViT backbone, achieving strong cross-subject and cross-time generalization on SEED/SEED-IV.", "motivation": "EEG-based emotion recognition suffers from limited feature utilization and poor cross-domain generalization; robust and generalizable models are needed for affective computing.", "method": "Reformulates emotion recognition as EEG\u2013text matching within the CLIP framework. Proposes SST-LegoViT to capture spatial, spectral, and temporal features via multi-scale convolution and Transformer modules. Employs multimodal contrastive learning to align EEG representations with text.", "result": "On SEED and SEED-IV, achieves cross-subject accuracies of 88.69% and 73.50%, and cross-time accuracies of 88.46% and 77.54%, outperforming existing models.", "conclusion": "Multimodal contrastive learning with EEG\u2013text alignment is effective for robust EEG emotion recognition and improves cross-domain/generalization performance."}}
{"id": "2511.05169", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05169", "abs": "https://arxiv.org/abs/2511.05169", "authors": ["Simon Baur", "Tristan Ruhwedel", "Ekin B\u00f6ke", "Zuzanna Kobus", "Gergana Lishkova", "Christoph Wetz", "Holger Amthauer", "Christoph Roderburg", "Frank Tacke", "Julian M. Rogasch", "Wojciech Samek", "Henning Jann", "Jackie Ma", "Johannes Eschrich"], "title": "Multimodal Deep Learning for Prediction of Progression-Free Survival in Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor Radionuclide Therapy", "comment": null, "summary": "Peptide receptor radionuclide therapy (PRRT) is an established treatment for\nmetastatic neuroendocrine tumors (NETs), yet long-term disease control occurs\nonly in a subset of patients. Predicting progression-free survival (PFS) could\nsupport individualized treatment planning. This study evaluates laboratory,\nimaging, and multimodal deep learning models for PFS prediction in PRRT-treated\npatients. In this retrospective, single-center study 116 patients with\nmetastatic NETs undergoing 177Lu-DOTATOC were included. Clinical\ncharacteristics, laboratory values, and pretherapeutic somatostatin receptor\npositron emission tomography/computed tomographies (SR-PET/CT) were collected.\nSeven models were trained to classify low- vs. high-PFS groups, including\nunimodal (laboratory, SR-PET, or CT) and multimodal fusion approaches.\nExplainability was evaluated by feature importance analysis and gradient maps.\nForty-two patients (36%) had short PFS (< 1 year), 74 patients long PFS (>1\nyear). Groups were similar in most characteristics, except for higher baseline\nchromogranin A (p = 0.003), elevated gamma-GT (p = 0.002), and fewer PRRT\ncycles (p < 0.001) in short-PFS patients. The Random Forest model trained only\non laboratory biomarkers reached an AUROC of 0.59 +- 0.02. Unimodal\nthree-dimensional convolutional neural networks using SR-PET or CT performed\nworse (AUROC 0.42 +- 0.03 and 0.54 +- 0.01, respectively). A multimodal fusion\nmodel laboratory values, SR-PET, and CT -augmented with a pretrained CT branch\n- achieved the best results (AUROC 0.72 +- 0.01, AUPRC 0.80 +- 0.01).\nMultimodal deep learning combining SR-PET, CT, and laboratory biomarkers\noutperformed unimodal approaches for PFS prediction after PRRT. Upon external\nvalidation, such models may support risk-adapted follow-up strategies.", "AI": {"tldr": "Multimodal deep learning model combining laboratory values, SR-PET, and CT provides best PFS prediction after PRRT in metastatic NETs (AUROC ~0.72, AUPRC ~0.80), outperforming unimodal models; external validation needed for clinical adoption.", "motivation": "Improve prediction of progression-free survival to tailor PRRT treatment and follow-up in metastatic neuroendocrine tumors.", "method": "Retrospective single-center study with 116 metastatic NET patients treated with 177Lu-DOTATOC. Collected clinical data, laboratory biomarkers, and pretherapeutic SR-PET/CT. Trained seven models: unimodal (laboratory, SR-PET, or CT) and multimodal fusion approaches; included a pretrained CT branch. Evaluated with AUROC and AUPRC; explainability via feature importance and gradient maps.", "result": "Best model: multimodal fusion of laboratory values, SR-PET, and CT with pretrained CT branch; AUROC 0.72 \u00b1 0.01, AUPRC 0.80 \u00b1 0.01. Unimodal results: laboratory-only AUROC 0.59, SR-PET CNN AUROC 0.42, CT CNN AUROC 0.54. Short PFS (<1 year) in 36% of patients; higher baseline chromogranin A, elevated gamma-GT, and fewer PRRT cycles associated with short PFS.", "conclusion": "Multimodal deep learning improves PFS prediction after PRRT over unimodal models and could support risk-adapted follow-up, pending external validation."}}
{"id": "2511.05394", "categories": ["cs.CV", "cs.AI", "cs.HC", "H.5.2; H.5.1; I.4.8; I.2.6"], "pdf": "https://arxiv.org/pdf/2511.05394", "abs": "https://arxiv.org/abs/2511.05394", "authors": ["Alexander Htet Kyaw", "Haotian Ma", "Sasa Zivkovic", "Jenny Sabin"], "title": "AI Assisted AR Assembly: Object Recognition and Computer Vision for Augmented Reality Assisted Assembly", "comment": "Accepted to the Association for Computing Machinery (ACM) Symposium\n  on Computational Fabrication (SCF '25)", "summary": "We present an AI-assisted Augmented Reality assembly workflow that uses deep\nlearning-based object recognition to identify different assembly components and\ndisplay step-by-step instructions. For each assembly step, the system displays\na bounding box around the corresponding components in the physical space, and\nwhere the component should be placed. By connecting assembly instructions with\nthe real-time location of relevant components, the system eliminates the need\nfor manual searching, sorting, or labeling of different components before each\nassembly. To demonstrate the feasibility of using object recognition for\nAR-assisted assembly, we highlight a case study involving the assembly of LEGO\nsculptures.", "AI": {"tldr": "An AI-assisted AR assembly system uses deep learning-based object recognition to identify components and overlay step-by-step instructions with bounding boxes and placement cues, demonstrated on LEGO sculpture assembly.", "motivation": "To reduce manual searching, sorting, and labeling of components in assembly tasks by leveraging AI and AR to provide real-time, component-aware guidance.", "method": "Integrates deep learning-based object recognition with an AR workflow. For each assembly step, the system displays bounding boxes around the relevant components and indicates where they should be placed in the physical space, dynamically linking instructions with real-time component locations to guide assembly. A LEGO sculpture case study demonstrates feasibility.", "result": "Feasibility is demonstrated via the LEGO case study, showing that object recognition can support AR-assisted assembly by guiding users to the correct components and placements.", "conclusion": "The approach shows promise for AI-assisted AR-guided assembly, potentially reducing manual search/sort/label tasks and streamlining assembly workflows, with scope for broader validation and extension to other domains."}}
{"id": "2511.05177", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05177", "abs": "https://arxiv.org/abs/2511.05177", "authors": ["Mathias Lundteigen Mohus", "Jingyue Li", "Zhirong Yang"], "title": "Associative Poisoning to Generative Machine Learning", "comment": null, "summary": "The widespread adoption of generative models such as Stable Diffusion and\nChatGPT has made them increasingly attractive targets for malicious\nexploitation, particularly through data poisoning. Existing poisoning attacks\ncompromising synthesised data typically either cause broad degradation of\ngenerated data or require control over the training process, limiting their\napplicability in real-world scenarios. In this paper, we introduce a novel data\npoisoning technique called associative poisoning, which compromises\nfine-grained features of the generated data without requiring control of the\ntraining process. This attack perturbs only the training data to manipulate\nstatistical associations between specific feature pairs in the generated\noutputs. We provide a formal mathematical formulation of the attack and prove\nits theoretical feasibility and stealthiness. Empirical evaluations using two\nstate-of-the-art generative models demonstrate that associative poisoning\neffectively induces or suppresses feature associations while preserving the\nmarginal distributions of the targeted features and maintaining high-quality\noutputs, thereby evading visual detection. These results suggest that\ngenerative systems used in image synthesis, synthetic dataset generation, and\nnatural language processing are susceptible to subtle, stealthy manipulations\nthat compromise their statistical integrity. To address this risk, we examine\nthe limitations of existing defensive strategies and propose a novel\ncountermeasure strategy.", "AI": {"tldr": "A stealthy data-poisoning method, associative poisoning, manipulates joint feature associations in generative outputs by poisoning training data\u2014without training-control\u2014supported by formal theory, empirical validation, and a proposed countermeasure.", "motivation": "Generative models are widespread and attractive targets; current poisoning either degrades outputs broadly or needs training access, limiting real-world risk; hence need stealthy, practical attack and defenses.", "method": "Formalize the attack; perturb training data to influence statistical associations between specific feature pairs in outputs; prove feasibility and stealthiness; validate with two state-of-the-art models showing ability to induce/suppress associations while preserving marginals and output quality.", "result": "The attack successfully modulates feature associations, preserves marginal distributions, maintains high-quality outputs, and remains visually undetectable; demonstrates vulnerability of image synthesis, synthetic data generation, and NLP pipelines; shows limitations of existing defenses.", "conclusion": "Highlights the need for robust defenses against stealthy data-poisoning attacks; proposes a countermeasure strategy and loci for future work."}}
{"id": "2511.05404", "categories": ["cs.CV", "cs.AI", "I.2.9; I.2.10"], "pdf": "https://arxiv.org/pdf/2511.05404", "abs": "https://arxiv.org/abs/2511.05404", "authors": ["Laura Alejandra Encinar Gonzalez", "John Folkesson", "Rudolph Triebel", "Riccardo Giubilato"], "title": "Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments", "comment": "Under review for ICRA 2026", "summary": "Robust loop closure detection is a critical component of Simultaneous\nLocalization and Mapping (SLAM) algorithms in GNSS-denied environments, such as\nin the context of planetary exploration. In these settings, visual place\nrecognition often fails due to aliasing and weak textures, while LiDAR-based\nmethods suffer from sparsity and ambiguity. This paper presents MPRF, a\nmultimodal pipeline that leverages transformer-based foundation models for both\nvision and LiDAR modalities to achieve robust loop closure in severely\nunstructured environments. Unlike prior work limited to retrieval, MPRF\nintegrates a two-stage visual retrieval strategy with explicit 6-DoF pose\nestimation, combining DINOv2 features with SALAD aggregation for efficient\ncandidate screening and SONATA-based LiDAR descriptors for geometric\nverification. Experiments on the S3LI dataset and S3LI Vulcano dataset show\nthat MPRF outperforms state-of-the-art retrieval methods in precision while\nenhancing pose estimation robustness in low-texture regions. By providing\ninterpretable correspondences suitable for SLAM back-ends, MPRF achieves a\nfavorable trade-off between accuracy, efficiency, and reliability,\ndemonstrating the potential of foundation models to unify place recognition and\npose estimation. Code and models will be released at github.com/DLR-RM/MPRF.", "AI": {"tldr": "A multimodal SLAM loop-closure system (MPRF) uses foundation-model features and geometric verification to robustly detect loops in GNSS-denied, low-texture environments by unifying place recognition with 6-DoF pose estimation.", "motivation": "In GNSS-denied, unstructured environments (e.g., planetary exploration), visual place recognition struggles due to aliasing and weak textures, and LiDAR can be sparse or ambiguous. There is a need for robust, efficient loop-closure that also provides pose estimates and interpretable correspondences.", "method": "MPRF integrates vision and LiDAR through transformer-based foundation models. It employs a two-stage visual retrieval using DINOv2 features with SALAD aggregation for candidate screening and explicit 6-DoF pose estimation, and uses SONATA-based LiDAR descriptors for geometric verification. The system provides interpretable correspondences suitable for SLAM back-ends.", "result": "On the S3LI and S3LI Vulcano datasets, MPRF outperforms state-of-the-art retrieval methods in precision and improves pose-estimation robustness in low-texture regions, while offering reliable, interpretable correspondences and a favorable accuracy/efficiency/reliability trade-off.", "conclusion": "Foundation-model-based multimodal SLAM can unify place recognition and pose estimation, enabling robust loop closure in challenging environments. Code and models are to be released, enabling reproducibility and broader adoption."}}
{"id": "2511.05319", "categories": ["cs.CV", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.05319", "abs": "https://arxiv.org/abs/2511.05319", "authors": ["Huanqi Wu", "Huangbiao Xu", "Runfeng Xie", "Jiaxin Cai", "Kaixin Zhang", "Xiao Ke"], "title": "$\\mathbf{S^2LM}$: Towards Semantic Steganography via Large Language Models", "comment": "35 Pages, 20 Figures", "summary": "Although steganography has made significant advancements in recent years, it\nstill struggles to embed semantically rich, sentence-level information into\ncarriers. However, in the era of AIGC, the capacity of steganography is more\ncritical than ever. In this work, we present Sentence-to-Image Steganography,\nan instance of Semantic Steganography, a novel task that enables the hiding of\narbitrary sentence-level messages within a cover image. Furthermore, we\nestablish a benchmark named Invisible Text (IVT), comprising a diverse set of\nsentence-level texts as secret messages for evaluation. Finally, we present\n$\\mathbf{S^2LM}$: Semantic Steganographic Language Model, which utilizes large\nlanguage models (LLMs) to embed high-level textual information, such as\nsentences or even paragraphs, into images. Unlike traditional bit-level\ncounterparts, $\\mathrm{S^2LM}$ enables the integration of semantically rich\ncontent through a newly designed pipeline in which the LLM is involved\nthroughout the entire process. Both quantitative and qualitative experiments\ndemonstrate that our method effectively unlocks new semantic steganographic\ncapabilities for LLMs. The source code will be released soon.", "AI": {"tldr": "A semantic steganography framework to hide sentence-level messages in images, via S^2LM and a new IVT benchmark, enabling high-level textual content embedding with LLMs.", "motivation": "Traditional steganography struggles to embed semantically rich, sentence-level content; in the era of AI-generated content, there is demand to conceal high-level information in images.", "method": "Propose Sentence-to-Image Steganography as a semantic steganography task; establish the Invisible Text (IVT) benchmark with diverse sentence-level messages; introduce S^2LM (Semantic Steganographic Language Model) that deploys large language models throughout an end-to-end pipeline to embed sentences/paragraphs into images.", "result": "Quantitative and qualitative experiments demonstrate effective embedding of semantically rich content and expanded semantic steganography capabilities for LLMs; source code will be released.", "conclusion": "Extends steganography from bit-level to semantic-level messages, enabling new applications in the AI-assisted generation era; provides a benchmark (IVT) and a generative pipeline (S^2LM) for embedding sentences in images."}}
{"id": "2511.05420", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05420", "abs": "https://arxiv.org/abs/2511.05420", "authors": ["Emad Efatinasab", "Nahal Azadi", "Davide Dalle Pezze", "Gian Antonio Susto", "Chuadhry Mujeeb Ahmed", "Mirco Rampazzo"], "title": "ProDER: A Continual Learning Approach for Fault Prediction in Evolving Smart Grids", "comment": null, "summary": "As smart grids evolve to meet growing energy demands and modern operational\nchallenges, the ability to accurately predict faults becomes increasingly\ncritical. However, existing AI-based fault prediction models struggle to ensure\nreliability in evolving environments where they are required to adapt to new\nfault types and operational zones. In this paper, we propose a continual\nlearning (CL) framework in the smart grid context to evolve the model together\nwith the environment. We design four realistic evaluation scenarios grounded in\nclass-incremental and domain-incremental learning to emulate evolving grid\nconditions. We further introduce Prototype-based Dark Experience Replay\n(ProDER), a unified replay-based approach that integrates prototype-based\nfeature regularization, logit distillation, and a prototype-guided replay\nmemory. ProDER achieves the best performance among tested CL techniques, with\nonly a 0.045 accuracy drop for fault type prediction and 0.015 for fault zone\nprediction. These results demonstrate the practicality of CL for scalable,\nreal-world fault prediction in smart grids.", "AI": {"tldr": "The paper introduces a continual learning framework for smart-grid fault prediction to cope with evolving fault types and zones, presenting ProDER, a replay-based method combining prototype regularization, logit distillation, and prototype-guided replay; it achieves minimal accuracy drop and demonstrates practicality for scalable fault prediction.", "motivation": "In smart grids, fixed AI fault predictors struggle to adapt to new fault types and operational zones; a continual learning approach is needed to evolve models in tandem with changing environments.", "method": "Develop a continual learning framework for smart-grid fault prediction, with four evaluation scenarios (class-incremental and domain-incremental). ProDER (Prototype-based Dark Experience Replay) integrates prototype-based feature regularization, logit distillation, and a prototype-guided replay memory to mitigate forgetting and improve adaptation.", "result": "ProDER achieves the best performance among tested CL techniques, with very small accuracy drops: 0.045 for fault type prediction and 0.015 for fault zone prediction.", "conclusion": "CL is practical for scalable, real-world fault prediction in smart grids, enabling models to adapt to evolving fault types and zones while maintaining accuracy."}}
{"id": "2511.05356", "categories": ["cs.CV", "I.2.10; I.4.6; I.5.1; I.5.4"], "pdf": "https://arxiv.org/pdf/2511.05356", "abs": "https://arxiv.org/abs/2511.05356", "authors": ["Manuel Gomes", "Bogdan Raducanu", "Miguel Oliveira"], "title": "Canonical Space Representation for 4D Panoptic Segmentation of Articulated Objects", "comment": "32 pages, 6 figures, 4 tables, submitted to Expert Systems With\n  Applications", "summary": "Articulated object perception presents significant challenges in computer\nvision, particularly because most existing methods ignore temporal dynamics\ndespite the inherently dynamic nature of such objects. The use of 4D temporal\ndata has not been thoroughly explored in articulated object perception and\nremains unexamined for panoptic segmentation. The lack of a benchmark dataset\nfurther hurt this field. To this end, we introduce Artic4D as a new dataset\nderived from PartNet Mobility and augmented with synthetic sensor data,\nfeaturing 4D panoptic annotations and articulation parameters. Building on this\ndataset, we propose CanonSeg4D, a novel 4D panoptic segmentation framework.\nThis approach explicitly estimates per-frame offsets mapping observed object\nparts to a learned canonical space, thereby enhancing part-level segmentation.\nThe framework employs this canonical representation to achieve consistent\nalignment of object parts across sequential frames. Comprehensive experiments\non Artic4D demonstrate that the proposed CanonSeg4D outperforms state of the\nart approaches in panoptic segmentation accuracy in more complex scenarios.\nThese findings highlight the effectiveness of temporal modeling and canonical\nalignment in dynamic object understanding, and pave the way for future advances\nin 4D articulated object perception.", "AI": {"tldr": "Artic4D provides a 4D articulated object dataset with 4D panoptic annotations and articulation parameters, and CanonSeg4D is a 4D panoptic segmentation framework that aligns parts in a canonical space over time to improve segmentation accuracy, outperforming prior methods in complex scenarios.", "motivation": "Articulated object perception faces challenges due to neglected temporal dynamics; 4D data and panoptic segmentation for articulated objects are underexplored; lack of benchmarks hampers progress.", "method": "Introduce Artic4D dataset (derived from PartNet Mobility with synthetic sensor data) with 4D panoptic annotations and articulation parameters; develop CanonSeg4D that estimates per-frame offsets to map observed parts to a learned canonical space, enabling consistent cross-frame alignment and improved part-level segmentation.", "result": "Extensive experiments on Artic4D show CanonSeg4D achieving higher panoptic segmentation accuracy than state-of-the-art methods in more complex scenarios.", "conclusion": "Temporal modeling and canonical alignment are effective for 4D articulated object understanding; the Artic4D dataset and CanonSeg4D framework pave the way for future advances in 4D articulated perception."}}
{"id": "2511.05187", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.05187", "abs": "https://arxiv.org/abs/2511.05187", "authors": ["Kamil Ciosek", "Nicol\u00f2 Felicioni", "Juan Elenter Litwin"], "title": "Linear Gradient Prediction with Control Variates", "comment": null, "summary": "We propose a new way of training neural networks, with the goal of reducing\ntraining cost. Our method uses approximate predicted gradients instead of the\nfull gradients that require an expensive backward pass. We derive a\ncontrol-variate-based technique that ensures our updates are unbiased estimates\nof the true gradient. Moreover, we propose a novel way to derive a predictor\nfor the gradient inspired by the theory of the Neural Tangent Kernel. We\nempirically show the efficacy of the technique on a vision transformer\nclassification task.", "AI": {"tldr": "Unbiased, cheaper gradient-based training by combining a control variate with an NTK-inspired gradient predictor; validated on Vision Transformer classification.", "motivation": "Training neural networks is costly due to full backpropagation; aim to reduce training cost while preserving convergence by using inexpensive gradient estimates.", "method": "Derive a control-variate-based unbiased gradient estimator using an approximate predicted gradient; propose a gradient predictor inspired by Neural Tangent Kernel (NTK); integrate into the training loop with theoretical unbiasedness guarantees; demonstrate effectiveness empirically on a vision transformer task.", "result": "Empirical results indicate reduced training cost while maintaining accuracy on a vision transformer classification task.", "conclusion": "Presents a practical pathway to cheaper neural network training via unbiased gradient estimates and NTK-inspired prediction; suggests broad applicability and directions for future work such as variance analysis and scaling to larger models."}}
{"id": "2511.05442", "categories": ["cs.LG", "cs.AI", "cs.CL", "68Uxx", "I.2.7; I.2.6; I.2.m"], "pdf": "https://arxiv.org/pdf/2511.05442", "abs": "https://arxiv.org/abs/2511.05442", "authors": ["Frauke Andersen", "William Rudman", "Ruochen Zhang", "Carsten Eickhoff"], "title": "APP: Accelerated Path Patching with Task-Specific Pruning", "comment": null, "summary": "Circuit discovery is a key step in many mechanistic interpretability\npipelines. Current methods, such as Path Patching, are computationally\nexpensive and have limited in-depth circuit analysis for smaller models. In\nthis study, we propose Accelerated Path Patching (APP), a hybrid approach\nleveraging our novel contrastive attention head pruning method to drastically\nreduce the search space of circuit discovery methods. Our Contrastive-FLAP\npruning algorithm uses techniques from causal mediation analysis to assign\nhigher pruning scores to task-specific attention heads, leading to higher\nperforming sparse models compared to traditional pruning techniques. Although\nContrastive-FLAP is successful at preserving task-specific heads that existing\npruning algorithms remove at low sparsity ratios, the circuits found by\nContrastive-FLAP alone are too large to satisfy the minimality constraint\nrequired in circuit analysis. APP first applies Contrastive-FLAP to reduce the\nsearch space on required for circuit discovery algorithms by, on average, 56\\%.\nNext, APP, applies traditional Path Patching on the remaining attention heads,\nleading to a speed up of 59.63\\%-93.27\\% compared to Path Patching applied to\nthe dense model. Despite the substantial computational saving that APP\nprovides, circuits obtained from APP exhibit substantial overlap and similar\nperformance to previously established Path Patching circuits", "AI": {"tldr": "APP speeds up circuit discovery by pruning attention heads with Contrastive-FLAP and then applying Path Patching, achieving substantial search-space reductions and speedups with circuits comparable to prior methods.", "motivation": "Circuit discovery for mechanistic interpretability is computationally expensive, and existing methods struggle with scalability and minimality requirements, especially for smaller models.", "method": "Introduce Accelerated Path Patching (APP). First prune task-specific attention heads using Contrastive-FLAP, a causal mediation-inspired contrastive pruning method that prioritizes heads important to the task, reducing the search space by about 56%. Then apply traditional Path Patching to the remaining heads to extract circuits.", "result": "APP reduces the search space by ~56% and achieves speedups of 59.63% to 93.27% compared to Path Patching on dense models. The circuits found with APP show substantial overlap and similar performance to circuits obtained by established Path Patching methods.", "conclusion": "APP provides meaningful computational savings while preserving circuit quality, though circuits exhibit substantial overlap; future work could address further reducing redundancy and tightening the minimality constraint in circuit analysis."}}
{"id": "2511.05369", "categories": ["cs.CV", "I.2.10; I.4.8; I.5.4"], "pdf": "https://arxiv.org/pdf/2511.05369", "abs": "https://arxiv.org/abs/2511.05369", "authors": ["Shiyao Xu", "Benedetta Liberatori", "G\u00fcl Varol", "Paolo Rota"], "title": "Dense Motion Captioning", "comment": "12 pages, 5 figures, accepted to 3DV 2026", "summary": "Recent advances in 3D human motion and language integration have primarily\nfocused on text-to-motion generation, leaving the task of motion understanding\nrelatively unexplored. We introduce Dense Motion Captioning, a novel task that\naims to temporally localize and caption actions within 3D human motion\nsequences. Current datasets fall short in providing detailed temporal\nannotations and predominantly consist of short sequences featuring few actions.\nTo overcome these limitations, we present the Complex Motion Dataset (CompMo),\nthe first large-scale dataset featuring richly annotated, complex motion\nsequences with precise temporal boundaries. Built through a carefully designed\ndata generation pipeline, CompMo includes 60,000 motion sequences, each\ncomposed of multiple actions ranging from at least two to ten, accurately\nannotated with their temporal extents. We further present DEMO, a model that\nintegrates a large language model with a simple motion adapter, trained to\ngenerate dense, temporally grounded captions. Our experiments show that DEMO\nsubstantially outperforms existing methods on CompMo as well as on adapted\nbenchmarks, establishing a robust baseline for future research in 3D motion\nunderstanding and captioning.", "AI": {"tldr": "Proposes Dense Motion Captioning to temporally localize and caption actions in 3D human motion; introduces CompMo, a large-scale dataset with 60,000 complex sequences and precise temporal boundaries; presents DEMO, a model that combines a large language model with a motion adapter to produce dense, temporally grounded captions; DEMO outperforms baselines on CompMo and adapted benchmarks.", "motivation": "Addresses a gap in 3D motion understanding beyond text-to-motion translation by enabling detailed temporal annotations and captioning of complex, multi-action sequences; existing datasets lack long sequences with precise action boundaries.", "method": "CompMo is built via a data generation pipeline to create long, complex motion sequences annotated with multiple actions and tight temporal extents; DEMO integrates a large language model with a simple motion adapter to generate dense, temporally grounded captions.", "result": "DEMO substantially outperforms existing methods on CompMo and adapted benchmarks, establishing a robust baseline and demonstrating the framework's effectiveness for 3D motion understanding and captioning.", "conclusion": "Introduces a new task (dense motion captioning) and a strong benchmark (CompMo) along with a capable model (DEMO) that advances 3D motion understanding and captioning, paving the way for future research."}}
{"id": "2511.05221", "categories": ["cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2511.05221", "abs": "https://arxiv.org/abs/2511.05221", "authors": ["David Bertram", "Anja Ophey", "Sinah R\u00f6ttgen", "Konstantin Kuffer", "Gereon R. Fink", "Elke Kalbe", "Clint Hansen", "Walter Maetzler", "Maximilian Kapsecker", "Lara M. Reimer", "Stephan Jonas", "Andreas T. Damgaard", "Natasha B. Bertelsen", "Casper Skjaerbaek", "Per Borghammer", "Karolien Groenewald", "Pietro-Luca Ratti", "Michele T. Hu", "No\u00e9mie Moreau", "Michael Sommerauer", "Katarzyna Bozek"], "title": "ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy", "comment": "30 pages including supplement, 4 core figures, 1 supplement figure", "summary": "Isolated rapid eye movement sleep behavior disorder (iRBD) is a major\nprodromal marker of $\\alpha$-synucleinopathies, often preceding the clinical\nonset of Parkinson's disease, dementia with Lewy bodies, or multiple system\natrophy. While wrist-worn actimeters hold significant potential for detecting\nRBD in large-scale screening efforts by capturing abnormal nocturnal movements,\nthey become inoperable without a reliable and efficient analysis pipeline. This\nstudy presents ActiTect, a fully automated, open-source machine learning tool\nto identify RBD from actigraphy recordings. To ensure generalizability across\nheterogeneous acquisition settings, our pipeline includes robust preprocessing\nand automated sleep-wake detection to harmonize multi-device data and extract\nphysiologically interpretable motion features characterizing activity patterns.\nModel development was conducted on a cohort of 78 individuals, yielding strong\ndiscrimination under nested cross-validation (AUROC = 0.95). Generalization was\nconfirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two\nindependent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To\nassess real-world robustness, leave-one-dataset-out cross-validation across the\ninternal and external cohorts demonstrated consistent performance (AUROC range\n= 0.84-0.89). A complementary stability analysis showed that key predictive\nfeatures remained reproducible across datasets, supporting the final pooled\nmulti-center model as a robust pre-trained resource for broader deployment. By\nbeing open-source and easy to use, our tool promotes widespread adoption and\nfacilitates independent validation and collaborative improvements, thereby\nadvancing the field toward a unified and generalizable RBD detection model\nusing wearable devices.", "AI": {"tldr": "Open-source ActiTect detects RBD from actigraphy with robust preprocessing and cross-cohort validation, achieving AUROC up to 0.95.", "motivation": "RBD is a key prodromal marker for \u03b1-synucleinopathies; wrist actigraphy has potential for large-scale screening but requires reliable, harmonized analysis across heterogeneous devices and settings.", "method": "ActiTect is a fully automated ML pipeline that performs preprocessing, automated sleep\u2013wake detection, and extraction of interpretable motion features from actigraphy. Development used 78 participants with nested cross-validation (AUROC 0.95). Generalization tested on blinded local set (n=31, AUROC 0.86) and two external cohorts (n=113, AUROC 0.84; n=57, AUROC 0.94). Leave-one-dataset-out CV (AUROC 0.84\u20130.89). Stability analysis shows reproducible features. The model is pooled and deployed as an open-source resource.", "result": "High discriminative performance with strong internal validation and robust cross-cohort generalization (AUROCs: 0.95, 0.86, 0.84\u20130.94; LooD CV: 0.84\u20130.89). Key predictive features remain stable across datasets, supporting a generalizable RBD detection model using wearable data.", "conclusion": "Open-source and user-friendly tool that can be widely adopted; enables independent validation and collaborative improvement, advancing toward a unified, generalizable RBD detection model using wearable actigraphy."}}
{"id": "2511.05480", "categories": ["cs.LG", "cs.AI", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.05480", "abs": "https://arxiv.org/abs/2511.05480", "authors": ["Maojiang Su", "Jerry Yao-Chieh Hu", "Sophia Pi", "Han Liu"], "title": "On Flow Matching KL Divergence", "comment": null, "summary": "We derive a deterministic, non-asymptotic upper bound on the Kullback-Leibler\n(KL) divergence of the flow-matching distribution approximation. In particular,\nif the $L_2$ flow-matching loss is bounded by $\\epsilon^2 > 0$, then the KL\ndivergence between the true data distribution and the estimated distribution is\nbounded by $A_1 \\epsilon + A_2 \\epsilon^2$. Here, the constants $A_1$ and $A_2$\ndepend only on the regularities of the data and velocity fields. Consequently,\nthis bound implies statistical convergence rates of Flow Matching Transformers\nunder the Total Variation (TV) distance. We show that, flow matching achieves\nnearly minimax-optimal efficiency in estimating smooth distributions. Our\nresults make the statistical efficiency of flow matching comparable to that of\ndiffusion models under the TV distance. Numerical studies on synthetic and\nlearned velocities corroborate our theory.", "AI": {"tldr": "Summary generation failed", "motivation": "Motivation analysis unavailable", "method": "Method extraction failed", "result": "Result analysis unavailable", "conclusion": "Conclusion extraction failed"}}
{"id": "2511.05393", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05393", "abs": "https://arxiv.org/abs/2511.05393", "authors": ["Zehui Feng", "Tian Qiu", "Tong Wu", "Junxuan Li", "Huayuan Xu", "Ting Han"], "title": "PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Visual Quality Assessment via Preference-Response Disentangled Policy Optimization", "comment": "27 pages, 14 figures, under review as a conference paper", "summary": "Visual Quality Assessment (QA) seeks to predict human perceptual judgments of\nvisual fidelity. While recent multimodal large language models (MLLMs) show\npromise in reasoning about image and video quality, existing approaches mainly\nrely on supervised fine-tuning or rank-only objectives, resulting in shallow\nreasoning, poor score calibration, and limited cross-domain generalization. We\npropose PreResQ-R1, a Preference-Response Disentangled Reinforcement Learning\nframework that unifies absolute score regression and relative ranking\nconsistency within a single reasoning-driven optimization scheme. Unlike prior\nQA methods, PreResQ-R1 introduces a dual-branch reward formulation that\nseparately models intra-sample response coherence and inter-sample preference\nalignment, optimized via Group Relative Policy Optimization (GRPO). This design\nencourages fine-grained, stable, and interpretable chain-of-thought reasoning\nabout perceptual quality. To extend beyond static imagery, we further design a\nglobal-temporal and local-spatial data flow strategy for Video Quality\nAssessment. Remarkably, with reinforcement fine-tuning on only 6K images and\n28K videos, PreResQ-R1 achieves state-of-the-art results across 10 IQA and 5\nVQA benchmarks under both SRCC and PLCC metrics, surpassing by margins of 5.30%\nand textbf2.15% in IQA task, respectively. Beyond quantitative gains, it\nproduces human-aligned reasoning traces that reveal the perceptual cues\nunderlying quality judgments. Code and model are available.", "AI": {"tldr": "Introduces PreResQ-R1, a dual-branch RL framework for visual QA that unifies absolute scoring and relative preferences, extended to video, achieving state-of-the-art results with interpretable reasoning traces.", "motivation": "Current multimodal LLM approaches to visual quality assessment rely on supervised fine-tuning or ranking objectives, leading to shallow reasoning, miscalibration, and limited cross-domain generalization. A unified, reasoning-driven optimization with disentangled rewards aims to improve calibration, generalization, and interpretability.", "method": "Proposes a dual-branch reward formulation: intra-sample response coherence and inter-sample preference alignment, optimized via Group Relative Policy Optimization (GRPO). Extends to videos with global-temporal and local-spatial data flow. Reinforcement fine-tuning on 6k images and 28k videos.", "result": "Achieves state-of-the-art across 10 IQA and 5 VQA benchmarks under SRCC and PLCC, with IQA gains of 5.30% (SRCC) and 2.15% (PLCC). Produces human-aligned reasoning traces.", "conclusion": "The method delivers fine-grained, stable, and interpretable perceptual-quality reasoning, with strong cross-domain performance and reduced reliance on large-scale supervision; code and model are available."}}
{"id": "2511.05236", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05236", "abs": "https://arxiv.org/abs/2511.05236", "authors": ["Rui Wu", "Lizheng Wang", "Yongjun Li"], "title": "The Causal Round Trip: Generating Authentic Counterfactuals by Eliminating Information Loss", "comment": "50 pages, 10 figures. Submitted to the Journal of Machine Learning\n  Research (JMLR). Keywords: Causal Inference, Diffusion Models, Causal\n  Information Conservation, Structural Causal Models, Counterfactual\n  Generation, BELM, Structural Reconstruction Error", "summary": "Judea Pearl's vision of Structural Causal Models (SCMs) as engines for\ncounterfactual reasoning hinges on faithful abduction: the precise inference of\nlatent exogenous noise. For decades, operationalizing this step for complex,\nnon-linear mechanisms has remained a significant computational challenge. The\nadvent of diffusion models, powerful universal function approximators, offers a\npromising solution. However, we argue that their standard design, optimized for\nperceptual generation over logical inference, introduces a fundamental flaw for\nthis classical problem: an inherent information loss we term the Structural\nReconstruction Error (SRE). To address this challenge, we formalize the\nprinciple of Causal Information Conservation (CIC) as the necessary condition\nfor faithful abduction. We then introduce BELM-MDCM, the first diffusion-based\nframework engineered to be causally sound by eliminating SRE by construction\nthrough an analytically invertible mechanism. To operationalize this framework,\na Targeted Modeling strategy provides structural regularization, while a Hybrid\nTraining Objective instills a strong causal inductive bias. Rigorous\nexperiments demonstrate that our Zero-SRE framework not only achieves\nstate-of-the-art accuracy but, more importantly, enables the high-fidelity,\nindividual-level counterfactuals required for deep causal inquiries. Our work\nprovides a foundational blueprint that reconciles the power of modern\ngenerative models with the rigor of classical causal theory, establishing a new\nand more rigorous standard for this emerging field.", "AI": {"tldr": "A diffusion-based causal framework (BELM-MDCM) eliminates information loss in diffusion-based abduction to enable accurate, individual-level counterfactuals in SCMs, achieving state-of-the-art results.", "motivation": "Faithful abduction in Structural Causal Models requires precise inference of latent exogenous noise. Diffusion models are powerful but their standard design causes information loss (SRE), hindering counterfactual reasoning. A framework that preserves causal information is needed.", "method": "Formalize Causal Information Conservation (CIC) as a necessary condition for faithful abduction. Propose BELM-MDCM, an invertible diffusion-based architecture that eliminates SRE. Introduce Targeted Modeling for structural regularization and a Hybrid Training Objective to inject strong causal inductive bias.", "result": "Zero-SRE framework delivers state-of-the-art accuracy and, crucially, enables high-fidelity, individual-level counterfactuals suitable for deep causal inquiries, as demonstrated by rigorous experiments.", "conclusion": "This work provides a foundational blueprint uniting modern generative models with classical causal theory, establishing a new rigorous standard for diffusion-based causal inference and high-quality counterfactuals."}}
{"id": "2511.05483", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05483", "abs": "https://arxiv.org/abs/2511.05483", "authors": ["Abigail Lin"], "title": "DGTN: Graph-Enhanced Transformer with Diffusive Attention Gating Mechanism for Enzyme DDG Prediction", "comment": null, "summary": "Predicting the effect of amino acid mutations on enzyme thermodynamic\nstability (DDG) is fundamental to protein engineering and drug design. While\nrecent deep learning approaches have shown promise, they often process sequence\nand structure information independently, failing to capture the intricate\ncoupling between local structural geometry and global sequential patterns. We\npresent DGTN (Diffused Graph-Transformer Network), a novel architecture that\nco-learns graph neural network (GNN) weights for structural priors and\ntransformer attention through a diffusion mechanism. Our key innovation is a\nbidirectional diffusion process where: (1) GNN-derived structural embeddings\nguide transformer attention via learnable diffusion kernels, and (2)\ntransformer representations refine GNN message passing through\nattention-modulated graph updates. We provide rigorous mathematical analysis\nshowing this co-learning scheme achieves provably better approximation bounds\nthan independent processing. On ProTherm and SKEMPI benchmarks, DGTN achieves\nstate-of-the-art performance (Pearson Rho = 0.87, RMSE = 1.21 kcal/mol), with\n6.2% improvement over best baselines. Ablation studies confirm the diffusion\nmechanism contributes 4.8 points to correlation. Our theoretical analysis\nproves the diffused attention converges to optimal structure-sequence coupling,\nwith convergence rate O(1/sqrt(T) ) where T is diffusion steps. This work\nestablishes a principled framework for integrating heterogeneous protein\nrepresentations through learnable diffusion.", "AI": {"tldr": "DGTN fuses graph priors and transformer attention via diffusion to predict enzyme mutations' effects on stability, achieving state-of-the-art on benchmark datasets with theoretical guarantees.", "motivation": "Existing methods process sequence and structure separately and fail to capture coupling between local geometry and global sequence patterns; need a unified diffusion-based co-learning framework.", "method": "Proposes bidirectional diffusion: GNN-derived structural embeddings guide transformer attention through learnable diffusion kernels; transformer representations refine GNN message passing via attention-modulated updates; provides mathematical analysis with convergence bounds.", "result": "On ProTherm and SKEMPI, achieves state-of-the-art Pearson Rho ~0.87 and RMSE ~1.21 kcal/mol, ~6.2% improvement over baselines; ablation shows diffusion contributes ~4.8 points to correlation; theoretical convergence rate O(1/sqrt(T)).", "conclusion": "Establishes a principled framework for integrating heterogeneous protein representations via learnable diffusion, enabling improved structure-sequence coupling and predictive accuracy."}}
{"id": "2511.05489", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.05489", "abs": "https://arxiv.org/abs/2511.05489", "authors": ["Junwen Pan", "Qizhe Zhang", "Rui Zhang", "Ming Lu", "Xin Wan", "Yuan Zhang", "Chang Liu", "Qi She"], "title": "TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning", "comment": "22 pages, 17 figures. Official code:\n  https://github.com/Time-Search/TimeSearch-R", "summary": "Temporal search aims to identify a minimal set of relevant frames from tens\nof thousands based on a given query, serving as a foundation for accurate\nlong-form video understanding. Existing works attempt to progressively narrow\nthe search space. However, these approaches typically rely on a hand-crafted\nsearch process, lacking end-to-end optimization for learning optimal search\nstrategies. In this paper, we propose TimeSearch-R, which reformulates temporal\nsearch as interleaved text-video thinking, seamlessly integrating searching\nvideo clips into the reasoning process through reinforcement learning (RL).\nHowever, applying RL training methods, such as Group Relative Policy\nOptimization (GRPO), to video reasoning can result in unsupervised intermediate\nsearch decisions. This leads to insufficient exploration of the video content\nand inconsistent logical reasoning. To address these issues, we introduce GRPO\nwith Completeness Self-Verification (GRPO-CSV), which gathers searched video\nframes from the interleaved reasoning process and utilizes the same policy\nmodel to verify the adequacy of searched frames, thereby improving the\ncompleteness of video reasoning. Additionally, we construct datasets\nspecifically designed for the SFT cold-start and RL training of GRPO-CSV,\nfiltering out samples with weak temporal dependencies to enhance task\ndifficulty and improve temporal search capabilities. Extensive experiments\ndemonstrate that TimeSearch-R achieves significant improvements on temporal\nsearch benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as\nlong-form video understanding benchmarks like VideoMME and MLVU. Notably,\nTimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1%\nimprovement over the base model Qwen2.5-VL and 2.0% over the advanced video\nreasoning model Video-R1. Our code is available at\nhttps://github.com/Time-Search/TimeSearch-R.", "AI": {"tldr": "TimeSearch-R uses interleaved text-video reasoning with reinforcement learning to perform end-to-end temporal search; introduces GRPO-CSV to ensure complete reasoning and prepares datasets for SFT cold-start and RL training; achieves state-of-the-art results on multiple benchmarks.", "motivation": "To overcome hand-crafted, non-end-to-end temporal search strategies and improve exploration and completeness in identifying minimal relevant frames for long-form video understanding.", "method": "Proposes TimeSearch-R, an RL-based framework that interleaves search with reasoning, enhances GRPO with Completeness Self-Verification (GRPO-CSV), and builds targeted datasets by filtering for temporal dependencies.", "result": "Demonstrates significant improvements on Haystack-LVBench, Haystack-Ego4D, VideoMME, and MLVU; achieves new state-of-the-art on LongVideoBench with 4.1% improvement over Qwen2.5-VL and 2.0% over Video-R1.", "conclusion": "End-to-end RL-based temporal search with self-verification improves temporal search completeness and long-form video understanding; code is released at the provided GitHub URL."}}
{"id": "2511.05403", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05403", "abs": "https://arxiv.org/abs/2511.05403", "authors": ["Zicong Fan", "Edoardo Remelli", "David Dimond", "Fadime Sener", "Liuhao Ge", "Bugra Tekin", "Cem Keskin", "Shreyas Hampali"], "title": "PALM: A Dataset and Baseline for Learning Multi-subject Hand Prior", "comment": null, "summary": "The ability to grasp objects, signal with gestures, and share emotion through\ntouch all stem from the unique capabilities of human hands. Yet creating\nhigh-quality personalized hand avatars from images remains challenging due to\ncomplex geometry, appearance, and articulation, particularly under\nunconstrained lighting and limited views. Progress has also been limited by the\nlack of datasets that jointly provide accurate 3D geometry, high-resolution\nmultiview imagery, and a diverse population of subjects. To address this, we\npresent PALM, a large-scale dataset comprising 13k high-quality hand scans from\n263 subjects and 90k multi-view images, capturing rich variation in skin tone,\nage, and geometry. To show its utility, we present a baseline PALM-Net, a\nmulti-subject prior over hand geometry and material properties learned via\nphysically based inverse rendering, enabling realistic, relightable\nsingle-image hand avatar personalization. PALM's scale and diversity make it a\nvaluable real-world resource for hand modeling and related research.", "AI": {"tldr": "PALM introduces a large-scale hand dataset and a baseline avatar model, enabling realistic, relightable single-image hand personalization by leveraging 13k scans, 263 subjects, and 90k multi-view images.", "motivation": "Addresses challenges in high-quality hand avatar creation due to complex geometry, appearance, articulation, and lighting; highlights lack of datasets with accurate 3D geometry, high-res multiview imagery, and diverse subjects.", "method": "Dataset collection (PALM): 13k high-quality hand scans from 263 subjects and 90k multiview images; baseline PALM-Net: learning a multi-subject prior over hand geometry and material properties via physically based inverse rendering to enable relightable hand avatars from a single image.", "result": "PALM provides scale and diversity as a real-world resource; PALM-Net demonstrates realistic, relightable hand avatars from single images, validating the utility of the dataset for hand modeling and related research.", "conclusion": "PALM stands as a valuable resource for advancing hand modeling, enabling improved avatars and broader research contributions; suggests paths for future work in personalization and relighting."}}
{"id": "2511.05289", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05289", "abs": "https://arxiv.org/abs/2511.05289", "authors": ["Marius Fracarolli", "Michael Staniek", "Stefan Riezler"], "title": "Embedding-Space Data Augmentation to Prevent Membership Inference Attacks in Clinical Time Series Forecasting", "comment": "Accepted as a proceedings paper at Machine Learning for Health (ML4H)\n  symposium 2025, December 1-2, 2025, San Diego, United States, 15 pages", "summary": "Balancing strong privacy guarantees with high predictive performance is\ncritical for time series forecasting (TSF) tasks involving Electronic Health\nRecords (EHR). In this study, we explore how data augmentation can mitigate\nMembership Inference Attacks (MIA) on TSF models. We show that retraining with\nsynthetic data can substantially reduce the effectiveness of loss-based MIAs by\nreducing the attacker's true-positive to false-positive ratio. The key\nchallenge is generating synthetic samples that closely resemble the original\ntraining data to confuse the attacker, while also introducing enough novelty to\nenhance the model's ability to generalize to unseen data. We examine multiple\naugmentation strategies - Zeroth-Order Optimization (ZOO), a variant of ZOO\nconstrained by Principal Component Analysis (ZOO-PCA), and MixUp - to\nstrengthen model resilience without sacrificing accuracy. Our experimental\nresults show that ZOO-PCA yields the best reductions in TPR/FPR ratio for MIA\nattacks without sacrificing performance on test data.", "AI": {"tldr": "Data augmentation via synthetic samples (ZOO, ZOO-PCA, MixUp) reduces membership inference attacks on time-series forecasting models trained on EHR data, with ZOO-PCA offering the best privacy gains without harming accuracy.", "motivation": "Protect privacy in EHR-based TSF against MIAs while preserving predictive performance; investigate how synthetic data can confuse attackers and improve generalization.", "method": "Train TSF models with synthetic data produced by three augmentation strategies (ZOO, ZOO-PCA, MixUp); evaluate resistance to loss-based MIA by measuring true-positive to false-positive ratio; compare test accuracy.", "result": "ZOO-PCA most effectively reduces the MIA TPR/FPR ratio while maintaining test performance; ZOO and MixUp provide less pronounced privacy gains or potential trade-offs.", "conclusion": "ZOO-PCA is a promising augmentation approach to bolster privacy in TSF on EHR without sacrificing accuracy; data augmentation strategy choice crucial for MIA resilience."}}
{"id": "2511.05421", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05421", "abs": "https://arxiv.org/abs/2511.05421", "authors": ["Aupendu Kar", "Krishnendu Ghosh", "Prabir Kumar Biswas"], "title": "Sharing the Learned Knowledge-base to Estimate Convolutional Filter Parameters for Continual Image Restoration", "comment": "This paper has been accepted to ACM ICVGIP 2025", "summary": "Continual learning is an emerging topic in the field of deep learning, where\na model is expected to learn continuously for new upcoming tasks without\nforgetting previous experiences. This field has witnessed numerous\nadvancements, but few works have been attempted in the direction of image\nrestoration. Handling large image sizes and the divergent nature of various\ndegradation poses a unique challenge in the restoration domain. However,\nexisting works require heavily engineered architectural modifications for new\ntask adaptation, resulting in significant computational overhead.\nRegularization-based methods are unsuitable for restoration, as different\nrestoration challenges require different kinds of feature processing. In this\ndirection, we propose a simple modification of the convolution layer to adapt\nthe knowledge from previous restoration tasks without touching the main\nbackbone architecture. Therefore, it can be seamlessly applied to any deep\narchitecture without any structural modifications. Unlike other approaches, we\ndemonstrate that our model can increase the number of trainable parameters\nwithout significantly increasing computational overhead or inference time.\nExperimental validation demonstrates that new restoration tasks can be\nintroduced without compromising the performance of existing tasks. We also show\nthat performance on new restoration tasks improves by adapting the knowledge\nfrom the knowledge base created by previous restoration tasks. The code is\navailable at https://github.com/aupendu/continual-restore.", "AI": {"tldr": "A lightweight continual-learning approach for image restoration using a simple convolution modification that preserves the backbone, enabling scalable addition of restoration tasks with modest overhead.", "motivation": "Continual learning in image restoration is underexplored due to large image sizes, diverse degradations, and the need to adapt without heavy architecture changes or regu\u200blarization-based methods.", "method": "Introduce a minimal modification to convolution layers to transfer knowledge from previous restoration tasks, effectively creating a task-specific but backbone-agnostic adapter; can be applied to any deep architecture; increases trainable parameters without significant compute overhead; relies on building a knowledge base from prior tasks.", "result": "Experiments show new restoration tasks can be added without degrading existing task performance; new-task performance improves by leveraging prior knowledge; modest computational overhead; code released.", "conclusion": "The approach enables scalable continual restoration with minimal architectural changes and can be integrated into existing models; potential extension to other domains."}}
{"id": "2511.05313", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05313", "abs": "https://arxiv.org/abs/2511.05313", "authors": ["Jatin Prakash", "Aahlad Puli", "Rajesh Ranganath"], "title": "Attention and Compression is all you need for Controllably Efficient Language Models", "comment": "Preprint", "summary": "The quadratic cost of attention in transformers motivated the development of\nefficient approaches: namely sparse and sliding window attention, convolutions\nand linear attention. Although these approaches result in impressive reductions\nin compute and memory, they often trade-off with quality, specifically\nin-context recall performance. Moreover, apriori fixing this quality-compute\ntradeoff means being suboptimal from the get-go: some downstream applications\nrequire more memory for in-context recall, while others require lower latency\nand memory. Further, these approaches rely on heuristic choices that\nartificially restrict attention, or require handcrafted and complex recurrent\nstate update rules, or they must be carefully composed with attention at\nspecific layers to form a hybrid architecture that complicates the design\nprocess, especially at scale. To address above issues, we propose Compress &\nAttend Transformer (CAT), a conceptually simple architecture employing two\nsimple ingredients only: dense attention and compression. CAT decodes chunks of\ntokens by attending to compressed chunks of the sequence so far. Compression\nresults in decoding from a reduced sequence length that yields compute and\nmemory savings, while choosing a particular chunk size trades-off quality for\nefficiency. Moreover, CAT can be trained with multiple chunk sizes at once,\nunlocking control of quality-compute trade-offs directly at test-time without\nany retraining, all in a single adaptive architecture. In exhaustive\nevaluations on common language modeling tasks, in-context recall, and\nlong-context understanding, a single adaptive CAT model outperforms existing\nefficient baselines, including hybrid architectures, across different\ncompute-memory budgets. Further, a single CAT matches dense transformer in\nlanguage modeling across model scales while being 1.4-3x faster and requiring\n2-9x lower total memory usage.", "AI": {"tldr": "CAT (Compress & Attend Transformer) is a simple, adaptive transformer that uses dense attention on compressed chunks to trade compute for memory. It supports multiple chunk sizes during training to allow test-time quality\u2013compute trade-offs without retraining, and achieves strong efficiency with competitive quality on language modeling and long-context tasks.", "motivation": "The quadratic attention cost in transformers forces reliance on efficiency tricks (sparse, sliding, convolutions, linear attention) that degrade quality. A flexible approach is needed that allows varying the quality\u2013compute trade-off at test time without complex hybrids or handcrafted states.", "method": "CAT uses two ingredients: dense attention and compression. Tokens are decoded by attending to compressed chunks of the past sequence. Compression reduces the effective sequence length, lowering compute/memory. A chunk size controls the quality/computation trade-off. The model can be trained with multiple chunk sizes simultaneously, enabling test-time adaptation without retraining.", "result": "In exhaustive evaluations, CAT outperforms existing efficient baselines (including hybrids) across various compute-memory budgets. It matches dense transformers in language modeling across model scales while being 1.4\u20133x faster and using 2\u20139x less total memory.", "conclusion": "A single adaptive CAT model provides flexible quality\u2013compute trade-offs using compression and dense attention, offering simpler design, competitive quality, and substantial efficiency gains for long-context language tasks."}}
{"id": "2511.05432", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05432", "abs": "https://arxiv.org/abs/2511.05432", "authors": ["Dogucan Yaman", "Seymanur Akti", "Fevziye Irem Eyiokur", "Alexander Waibel"], "title": "Shared Latent Representation for Joint Text-to-Audio-Visual Synthesis", "comment": null, "summary": "We propose a text-to-talking-face synthesis framework leveraging latent\nspeech representations from HierSpeech++. A Text-to-Vec module generates\nWav2Vec2 embeddings from text, which jointly condition speech and face\ngeneration. To handle distribution shifts between clean and TTS-predicted\nfeatures, we adopt a two-stage training: pretraining on Wav2Vec2 embeddings and\nfinetuning on TTS outputs. This enables tight audio-visual alignment, preserves\nspeaker identity, and produces natural, expressive speech and synchronized\nfacial motion without ground-truth audio at inference. Experiments show that\nconditioning on TTS-predicted latent features outperforms cascaded pipelines,\nimproving both lip-sync and visual realism.", "AI": {"tldr": "Two-stage text-to-talking-face synthesis using Wav2Vec2 latent embeddings generated from text, with pretraining on Wav2Vec2 features and finetuning on TTS outputs to align audio-visuals; achieves natural speech, synchronized facial motion, and preserved speaker identity without needing ground-truth audio at inference.", "motivation": "To achieve tight audio-visual alignment in talking-face synthesis under distribution shifts between clean embeddings and TTS-predicted features, while preserving speaker identity and avoiding the need for ground-truth audio during inference, and to surpass cascaded pipelines.", "method": "A Text-to-Vec module converts text into Wav2Vec2 embeddings that condition both speech and face generation. The approach leverages latent representations from HierSpeech++ and employs a two-stage training regime: (1) pretraining on Wav2Vec2 embeddings, (2) finetuning on TTS outputs to align predicted features with realistic audio-visual behavior. This avoids reliance on ground-truth audio at inference and aims for tight audio-visual alignment and natural, expressive speech.", "result": "Empirical results show that conditioning on TTS-predicted latent features outperforms cascaded pipelines, improving lip-sync accuracy and visual realism while preserving speaker identity and producing synchronized facial motion without external audio.", "conclusion": "The proposed framework demonstrates robust audio-visual alignment and high-quality talking-face synthesis by training to map text to TTS-predicted latent features, outperforming cascaded baselines and eliminating the need for ground-truth audio at inference."}}
{"id": "2511.05325", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05325", "abs": "https://arxiv.org/abs/2511.05325", "authors": ["Janet Jenq", "Hongda Shen"], "title": "Turning Adversaries into Allies: Reversing Typographic Attacks for Multimodal E-Commerce Product Retrieval", "comment": null, "summary": "Multimodal product retrieval systems in e-commerce platforms rely on\neffectively combining visual and textual signals to improve search relevance\nand user experience. However, vision-language models such as CLIP are\nvulnerable to typographic attacks, where misleading or irrelevant text embedded\nin images skews model predictions. In this work, we propose a novel method that\nreverses the logic of typographic attacks by rendering relevant textual content\n(e.g., titles, descriptions) directly onto product images to perform\nvision-text compression, thereby strengthening image-text alignment and\nboosting multimodal product retrieval performance. We evaluate our method on\nthree vertical-specific e-commerce datasets (sneakers, handbags, and trading\ncards) using six state-of-the-art vision foundation models. Our experiments\ndemonstrate consistent improvements in unimodal and multimodal retrieval\naccuracy across categories and model families. Our findings suggest that\nvisually rendering product metadata is a simple yet effective enhancement for\nzero-shot multimodal retrieval in e-commerce applications.", "AI": {"tldr": "Render product metadata text onto images to boost vision-text alignment and improve zero-shot multimodal retrieval in e-commerce.", "motivation": "Vision-language models are vulnerable to typographic attacks where embedded text misleads predictions; strengthening image-text alignment is needed for robust multimodal retrieval.", "method": "Visually render relevant textual content (titles, descriptions) onto product images to perform vision-text compression, evaluate across three e-commerce categories on six vision foundation models.", "result": "Consistent improvements in unimodal and multimodal retrieval accuracy across categories and model families on three datasets.", "conclusion": "Visually rendering product metadata is a simple yet effective enhancement for zero-shot multimodal retrieval in e-commerce, mitigating typographic attacks."}}
{"id": "2511.05449", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05449", "abs": "https://arxiv.org/abs/2511.05449", "authors": ["Tuan Anh Tran", "Duy M. H. Nguyen", "Hoai-Chau Tran", "Michael Barz", "Khoa D. Doan", "Roger Wattenhofer", "Ngo Anh Vien", "Mathias Niepert", "Daniel Sonntag", "Paul Swoboda"], "title": "How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?", "comment": "Accepted at NeurIPS 2025", "summary": "Recent advances in 3D point cloud transformers have led to state-of-the-art\nresults in tasks such as semantic segmentation and reconstruction. However,\nthese models typically rely on dense token representations, incurring high\ncomputational and memory costs during training and inference. In this work, we\npresent the finding that tokens are remarkably redundant, leading to\nsubstantial inefficiency. We introduce gitmerge3D, a globally informed graph\ntoken merging method that can reduce the token count by up to 90-95% while\nmaintaining competitive performance. This finding challenges the prevailing\nassumption that more tokens inherently yield better performance and highlights\nthat many current models are over-tokenized and under-optimized for\nscalability. We validate our method across multiple 3D vision tasks and show\nconsistent improvements in computational efficiency. This work is the first to\nassess redundancy in large-scale 3D transformer models, providing insights into\nthe development of more efficient 3D foundation architectures. Our code and\ncheckpoints are publicly available at https://gitmerge3d.github.io", "AI": {"tldr": "Gitmerge3D: a graph-based token merging method that cuts 3D transformer tokens by 90-95% while preserving performance, revealing redundancy and boosting efficiency.", "motivation": "3D point cloud transformers are highly tokenized, leading to large compute and memory costs. There is likely significant token redundancy; reducing tokens could yield more scalable, efficient models without sacrificing accuracy.", "method": "Globally informed graph token merging (gitmerge3D) that merges tokens across the entire point cloud using a graph-based strategy, dramatically reducing token counts while preserving task performance.", "result": "Token counts can be reduced by up to 90-95% with competitive performance across 3D vision tasks (e.g., semantic segmentation, reconstruction). The work is among the first to quantify and exploit redundancy in large-scale 3D transformers and demonstrates practical efficiency gains.", "conclusion": "Token redundancy exists in 3D transformers; many models are over-tokenized. gitmerge3D offers a path toward more efficient 3D foundation architectures, with code and checkpoints released for reproducibility."}}
{"id": "2511.05330", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.05330", "abs": "https://arxiv.org/abs/2511.05330", "authors": ["Jan-Hendrik Ewering", "Robin E. Herrmann", "Niklas Wahlstr\u00f6m", "Thomas B. Sch\u00f6n", "Thomas Seel"], "title": "Learning Dynamics from Input-Output Data with Hamiltonian Gaussian Processes", "comment": "17 pages, 5 figures", "summary": "Embedding non-restrictive prior knowledge, such as energy conservation laws,\nin learning-based approaches is a key motive to construct physically consistent\nmodels from limited data, relevant for, e.g., model-based control. Recent work\nincorporates Hamiltonian dynamics into Gaussian Process (GP) regression to\nobtain uncertainty-quantifying models that adhere to the underlying physical\nprinciples. However, these works rely on velocity or momentum data, which is\nrarely available in practice. In this paper, we consider dynamics learning with\nnon-conservative Hamiltonian GPs, and address the more realistic problem\nsetting of learning from input-output data. We provide a fully Bayesian scheme\nfor estimating probability densities of unknown hidden states, of GP\nhyperparameters, as well as of structural hyperparameters, such as damping\ncoefficients. Considering the computational complexity of GPs, we take\nadvantage of a reduced-rank GP approximation and leverage its properties for\ncomputationally efficient prediction and training. The proposed method is\nevaluated in a nonlinear simulation case study and compared to a\nstate-of-the-art approach that relies on momentum measurements.", "AI": {"tldr": "A Bayesian non-conservative Hamiltonian GP framework learns dynamics from input-output data (no velocity info) with a reduced-rank GP; it estimates hidden states, GP hyperparameters, and damping, enabling uncertainty-aware predictions.", "motivation": "To construct physically consistent dynamic models from limited data by embedding Hamiltonian structure and damping into Gaussian Process regression, even when velocity or momentum data are unavailable.", "method": "Develop a fully Bayesian scheme to infer densities over unknown hidden states, GP hyperparameters, and structural hyperparameters (e.g., damping). Use a reduced-rank GP approximation for scalable training and prediction, applied to non-conservative Hamiltonian dynamics learned from input-output data.", "result": "Evaluated on a nonlinear simulation case study, comparing against a state-of-the-art method that relies on momentum measurements; the approach provides uncertainty-aware predictions and adheres to the underlying physical principles even with IO data.", "conclusion": "Non-conservative Hamiltonian GPs learned from input-output data via a Bayesian reduced-rank framework are feasible and computationally efficient, enabling physically consistent dynamics modeling and uncertainty quantification when velocity data are unavailable."}}
{"id": "2511.05461", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05461", "abs": "https://arxiv.org/abs/2511.05461", "authors": ["Olivier Dietrich", "Merlin Alfredsson", "Emilia Arens", "Nando Metzger", "Torben Peters", "Linus Scheibenreif", "Jan Dirk Wegner", "Konrad Schindler"], "title": "The Potential of Copernicus Satellites for Disaster Response: Retrieving Building Damage from Sentinel-1 and Sentinel-2", "comment": null, "summary": "Natural disasters demand rapid damage assessment to guide humanitarian\nresponse. Here, we investigate whether medium-resolution Earth observation\nimages from the Copernicus program can support building damage assessment,\ncomplementing very-high resolution imagery with often limited availability. We\nintroduce xBD-S12, a dataset of 10,315 pre- and post-disaster image pairs from\nboth Sentinel-1 and Sentinel-2, spatially and temporally aligned with the\nestablished xBD benchmark. In a series of experiments, we demonstrate that\nbuilding damage can be detected and mapped rather well in many disaster\nscenarios, despite the moderate 10$\\,$m ground sampling distance. We also find\nthat, for damage mapping at that resolution, architectural sophistication does\nnot seem to bring much advantage: more complex model architectures tend to\nstruggle with generalization to unseen disasters, and geospatial foundation\nmodels bring little practical benefit. Our results suggest that Copernicus\nimages are a viable data source for rapid, wide-area damage assessment and\ncould play an important role alongside VHR imagery. We release the xBD-S12\ndataset, code, and trained models to support further research.", "AI": {"tldr": "Medium-resolution Copernicus Sentinel-1/2 images (10 m GSD) can support rapid, wide-area building damage mapping, complementing VHR imagery; introduces xBD-S12 dataset, showing damage can be detected well in many disasters; complex models and geospatial foundation models provide limited extra benefit; dataset and models released.", "motivation": "Need for fast, large-area post-disaster damage assessment when very-high-resolution data are limited or unavailable, to complement existing benchmarks and enable rapid humanitarian response.", "method": "Create xBD-S12 by assembling 10,315 pre- and post-disaster image pairs from Sentinel-1 and Sentinel-2, aligned with the xBD benchmark; conduct experiments across multiple disaster scenarios to assess damage detection/mapping at ~10 m GSD; compare architectural complexity and the utility of geospatial foundation models; release dataset, code, and trained models.", "result": "Building damage can be detected and mapped at 10 m resolution in many disaster scenarios; more complex model architectures do not consistently improve generalization to unseen disasters; geospatial foundation models yield little practical benefit; Copernicus data are viable for rapid, wide-area damage assessment and can complement VHR images.", "conclusion": "Copernicus images offer a viable data source for rapid, wide-area damage assessment and should play an important role alongside very-high-resolution imagery; public release of xBD-S12 dataset, code, and trained models facilitates further research."}}
{"id": "2511.05464", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05464", "abs": "https://arxiv.org/abs/2511.05464", "authors": ["Jakub Paplham", "Vojtech Franc"], "title": "Photo Dating by Facial Age Aggregation", "comment": null, "summary": "We introduce a novel method for Photo Dating which estimates the year a\nphotograph was taken by leveraging information from the faces of people present\nin the image. To facilitate this research, we publicly release CSFD-1.6M, a new\ndataset containing over 1.6 million annotated faces, primarily from movie\nstills, with identity and birth year annotations. Uniquely, our dataset\nprovides annotations for multiple individuals within a single image, enabling\nthe study of multi-face information aggregation. We propose a probabilistic\nframework that formally combines visual evidence from modern face recognition\nand age estimation models, and career-based temporal priors to infer the photo\ncapture year. Our experiments demonstrate that aggregating evidence from\nmultiple faces consistently improves the performance and the approach\nsignificantly outperforms strong, scene-based baselines, particularly for\nimages containing several identifiable individuals.", "AI": {"tldr": "A probabilistic multi-face framework for dating photos using face recognition/age estimates and career priors, leveraging CSFD-1.6M; outperforms scene-only baselines, especially with many identifiable faces.", "motivation": "Bridge the gap in photo dating by exploiting temporal signals embedded in faces and public-career priors, enabling robust use of multi-face cues beyond scene context.", "method": "Probabilistic integration of face recognition scores, age estimates, and career-based temporal priors across multiple detected faces in an image.", "result": "Evidence aggregation across multiple faces yields consistent performance gains and superior results relative to strong scene-based baselines.", "conclusion": "Demonstrates the usefulness of multi-face aggregation for photo dating and provides a large annotated dataset for future research (CSFD-1.6M)."}}
{"id": "2511.05357", "categories": ["cs.LG", "physics.app-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.05357", "abs": "https://arxiv.org/abs/2511.05357", "authors": ["Mikhail Tsukerman", "Konstantin Grotov", "Pavel Ginzburg"], "title": "Diffusion-Based Electromagnetic Inverse Design of Scattering Structured Media", "comment": "Accepted to Machine Learning and the Physical Sciences Workshop,\n  NeurIPS 2025", "summary": "We present a conditional diffusion model for electromagnetic inverse design\nthat generates structured media geometries directly from target differential\nscattering cross-section profiles, bypassing expensive iterative optimization.\nOur 1D U-Net architecture with Feature-wise Linear Modulation learns to map\ndesired angular scattering patterns to 2x2 dielectric sphere structure,\nnaturally handling the non-uniqueness of inverse problems by sampling diverse\nvalid designs. Trained on 11,000 simulated metasurfaces, the model achieves\nmedian MPE below 19% on unseen targets (best: 1.39%), outperforming CMA-ES\nevolutionary optimization while reducing design time from hours to seconds.\nThese results demonstrate that employing diffusion models is promising for\nadvancing electromagnetic inverse design research, potentially enabling rapid\nexploration of complex metasurface architectures and accelerating the\ndevelopment of next-generation photonic and wireless communication systems. The\ncode is publicly available at\nhttps://github.com/mikzuker/inverse_design_metasurface_generation.", "AI": {"tldr": "Diffusion-based conditional model for EM inverse design producing 2x2 metasurface geometries from target scattering, enabling fast, diverse solutions with competitive accuracy.", "motivation": "Inverse design of metasurfaces is ill-posed and computationally expensive; diffusion models can capture the multi-solution space and enable rapid exploration.", "method": "1D U-Net with Feature-wise Linear Modulation conditioning; conditional diffusion model that maps target differential scattering patterns to a 2x2 dielectric-sphere layout; samples to capture non-uniqueness; trained on 11k simulated metasurfaces.", "result": "Median mean percentage error (MPE) <19% on unseen targets; best case 1.39%; outperforms CMA-ES evolutionary optimization; design time reduced from hours to seconds.", "conclusion": "Diffusion-based approaches show promise for rapid, diverse electromagnetic inverse design, enabling faster exploration of complex metasurface architectures; potential impact on photonics and wireless systems; code available at the provided GitHub repository."}}
{"id": "2511.05467", "categories": ["cs.CV", "76T10, 68T07", "I.2.10; I.4.8; I.4.9"], "pdf": "https://arxiv.org/pdf/2511.05467", "abs": "https://arxiv.org/abs/2511.05467", "authors": ["Sanghyeon Chang", "Srikar Arani", "Nishant Sai Nuthalapati", "Youngjoon Suh", "Nicholas Choi", "Siavash Khodakarami", "Md Rakibul Hasan Roni", "Nenad Miljkovic", "Aparna Chandramowlishwaran", "Yoonjin Won"], "title": "EventFlow: Real-Time Neuromorphic Event-Driven Classification of Two-Phase Boiling Flow Regimes", "comment": "19 pages, 6 figures, Under review in Droplet (Manuscript ID:\n  DRO-2025-0045.R1)", "summary": "Flow boiling is an efficient heat transfer mechanism capable of dissipating\nhigh heat loads with minimal temperature variation, making it an ideal thermal\nmanagement method. However, sudden shifts between flow regimes can disrupt\nthermal performance and system reliability, highlighting the need for accurate\nand low-latency real-time monitoring. Conventional optical imaging methods are\nlimited by high computational demands and insufficient temporal resolution,\nmaking them inadequate for capturing transient flow behavior. To address this,\nwe propose a real-time framework based on signals from neuromorphic sensors for\nflow regime classification. Neuromorphic sensors detect changes in brightness\nat individual pixels, which typically correspond to motion at edges, enabling\nfast and efficient detection without full-frame reconstruction, providing\nevent-based information. We develop five classification models using both\ntraditional image data and event-based data, demonstrating that models\nleveraging event data outperform frame-based approaches due to their\nsensitivity to dynamic flow features. Among these models, the event-based long\nshort-term memory model provides the best balance between accuracy and speed,\nachieving 97.6% classification accuracy with a processing time of 0.28 ms. Our\nasynchronous processing pipeline supports continuous, low-latency predictions\nand delivers stable output through a majority voting mechanisms, enabling\nreliable real-time feedback for experimental control and intelligent thermal\nmanagement.", "AI": {"tldr": "Neuromorphic-event-based sensing enables real-time flow regime classification in flow boiling, outperforming frame-based methods with 97.6% accuracy at 0.28 ms; five models tested, with event-based LSTM offering best efficiency; asynchronous pipeline with majority voting for reliable control.", "motivation": "Need for low-latency, accurate real-time monitoring of flow regime transitions in flow boiling to preserve thermal performance and reliability; traditional imaging suffers from high computational load and limited temporal resolution.", "method": "Develop and compare five classification models using traditional frame data and event-based data from neuromorphic sensors; evaluate performance and latency; implement asynchronous processing with majority voting to provide stable real-time predictions.", "result": "Event-based models outperform frame-based approaches; best performance is an event-based long short-term memory model achieving 97.6% accuracy with 0.28 ms processing; system supports continuous, low-latency predictions with stability through majority voting.", "conclusion": "Neuromorphic, event-based sensing enables reliable, low-latency real-time feedback for experimental control and intelligent thermal management in flow boiling; asynchronous architecture reduces latency and improves robustness."}}
{"id": "2511.05474", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05474", "abs": "https://arxiv.org/abs/2511.05474", "authors": ["Xian-Hong Huang", "Hui-Kai Su", "Chi-Chia Sun", "Jun-Wei Hsieh"], "title": "Semantic-Guided Natural Language and Visual Fusion for Cross-Modal Interaction Based on Tiny Object Detection", "comment": null, "summary": "This paper introduces a cutting-edge approach to cross-modal interaction for\ntiny object detection by combining semantic-guided natural language processing\nwith advanced visual recognition backbones. The proposed method integrates the\nBERT language model with the CNN-based Parallel Residual Bi-Fusion Feature\nPyramid Network (PRB-FPN-Net), incorporating innovative backbone architectures\nsuch as ELAN, MSP, and CSP to optimize feature extraction and fusion. By\nemploying lemmatization and fine-tuning techniques, the system aligns semantic\ncues from textual inputs with visual features, enhancing detection precision\nfor small and complex objects. Experimental validation using the COCO and\nObjects365 datasets demonstrates that the model achieves superior performance.\nOn the COCO2017 validation set, it attains a 52.6% average precision (AP),\noutperforming YOLO-World significantly while maintaining half the parameter\nconsumption of Transformer-based models like GLIP. Several test on different of\nbackbones such ELAN, MSP, and CSP further enable efficient handling of\nmulti-scale objects, ensuring scalability and robustness in\nresource-constrained environments. This study underscores the potential of\nintegrating natural language understanding with advanced backbone\narchitectures, setting new benchmarks in object detection accuracy, efficiency,\nand adaptability to real-world challenges.", "AI": {"tldr": "A cross-modal tiny object detector that fuses BERT-based language cues with a CNN-based PRB-FPN backbone (featuring ELAN, MSP, and CSP variants) to improve small-object detection, achieving 52.6 AP on COCO2017 val and competitive efficiency compared to Transformer-based models.", "motivation": "To enhance tiny object detection by aligning semantic cues from natural language with robust visual features, enabling accurate, scalable detection in resource-constrained settings.", "method": "Integrates BERT with a CNN-based Parallel Residual Bi-Fusion Feature Pyramid Network (PRB-FPN-Net), leveraging backbones such as ELAN, MSP, and CSP; employs lemmatization and fine-tuning to align textual semantics with visual representations.", "result": "On COCO2017 validation, attains 52.6 AP, outperforming YOLO-World while using about half the parameters of Transformer-based models like GLIP; validated on COCO and Objects365, with multi-scale robustness across backbones.", "conclusion": "Demonstrates the viability of integrating natural language understanding with advanced backbone architectures to boost accuracy, efficiency, and adaptability of object detectors in real-world, resource-constrained scenarios."}}
{"id": "2511.05477", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05477", "abs": "https://arxiv.org/abs/2511.05477", "authors": ["Guojie Li", "Anwar P. P. Abdul Majeed", "Muhammad Ateeq", "Anh Nguyen", "Fan Zhang"], "title": "GroupKAN: Rethinking Nonlinearity with Grouped Spline-based KAN Modeling for Efficient Medical Image Segmentation", "comment": null, "summary": "Medical image segmentation requires models that are accurate, lightweight,\nand interpretable. Convolutional architectures lack adaptive nonlinearity and\ntransparent decision-making, whereas Transformer architectures are hindered by\nquadratic complexity and opaque attention mechanisms. U-KAN addresses these\nchallenges using Kolmogorov-Arnold Networks, achieving higher accuracy than\nboth convolutional and attention-based methods, fewer parameters than\nTransformer variants, and improved interpretability compared to conventional\napproaches. However, its O(C^2) complexity due to full-channel transformations\nlimits its scalability as the number of channels increases. To overcome this,\nwe introduce GroupKAN, a lightweight segmentation network that incorporates two\nnovel, structured functional modules: (1) Grouped KAN Transform, which\npartitions channels into G groups for multivariate spline mappings, reducing\ncomplexity to O(C^2/G), and (2) Grouped KAN Activation, which applies shared\nspline-based mappings within each channel group for efficient, token-wise\nnonlinearity. Evaluated on three medical benchmarks (BUSI, GlaS, and CVC),\nGroupKAN achieves an average IoU of 79.80 percent, surpassing U-KAN by +1.11\npercent while requiring only 47.6 percent of the parameters (3.02M vs 6.35M),\nand shows improved interpretability.", "AI": {"tldr": "GroupKAN is a scalable, lightweight, and interpretable medical image segmentation network that improves upon U-KAN by using grouped KAN modules to reduce complexity and parameters, achieving higher IoU.", "motivation": "Convolutional nets lack adaptive nonlinearity and clear decision processes, while Transformers have quadratic complexity and opaque attention. U-KAN improves accuracy and interpretability but suffers from O(C^2) full-channel complexity, limiting scalability. GroupKAN tackles these issues.", "method": "Introduce two structured modules: (1) Grouped KAN Transform, which partitions channels into G groups for multivariate spline mappings, reducing complexity to O(C^2/G); (2) Grouped KAN Activation, which applies shared spline-based mappings within each channel group for efficient, token-wise nonlinearity. Evaluated on BUSI, GlaS, and CVC benchmarks.", "result": "GroupKAN achieves an average IoU of 79.80% across the three medical benchmarks, surpassing U-KAN by +1.11%. It uses 3.02M parameters versus 6.35M for U-KAN, i.e., about 47.6% of the parameters, indicating substantial efficiency gains.", "conclusion": "GroupKAN delivers a scalable, efficient, and more interpretable segmentation solution that outperforms the prior U-KAN while dramatically reducing parameter count."}}
{"id": "2511.05444", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.05444", "abs": "https://arxiv.org/abs/2511.05444", "authors": ["Kasra Fallah", "Leonardo F. Toso", "James Anderson"], "title": "Adversarially Robust Multitask Adaptive Control", "comment": null, "summary": "We study adversarially robust multitask adaptive linear quadratic control; a\nsetting where multiple systems collaboratively learn control policies under\nmodel uncertainty and adversarial corruption. We propose a clustered multitask\napproach that integrates clustering and system identification with resilient\naggregation to mitigate corrupted model updates. Our analysis characterizes how\nclustering accuracy, intra-cluster heterogeneity, and adversarial behavior\naffect the expected regret of certainty-equivalent (CE) control across LQR\ntasks. We establish non-asymptotic bounds demonstrating that the regret\ndecreases inversely with the number of honest systems per cluster and that this\nreduction is preserved under a bounded fraction of adversarial systems within\neach cluster.", "AI": {"tldr": "A clustered multitask robust adaptive LQR framework that uses resilient aggregation to mitigate corrupted updates; regret improves with more honest systems per cluster and remains robust under a bounded fraction of adversarial systems.", "motivation": "Addresses learning control policies for multiple LQR tasks under model uncertainty and adversarial corruption. The goal is to enable cooperative learning that is robust to adversarial updates while maintaining efficiency across tasks.", "method": "Proposes a clustered multitask approach that combines clustering, system identification, and resilient aggregation. Analyzes how clustering accuracy, intra-cluster heterogeneity, and adversarial behavior influence the expected regret of certainty-equivalent control across LQR tasks. Establishes non-asymptotic bounds showing regret decreases inversely with the number of honest systems per cluster, and remains reduced under a bounded adversarial fraction within each cluster.", "result": "Derives non-asymptotic regret bounds demonstrating that increasing the number of honest systems per cluster reduces regret inversely, and that this benefit persists even when a bounded fraction of systems in each cluster are adversarial.", "conclusion": "The proposed clustered robust multitask framework improves CE-LQR learning in the presence of adversaries, with performance governed by cluster quality and the allowed adversarial fraction; practical implications include leveraging cluster structure to enhance robustness and data efficiency in multi-agent LQR tasks."}}
{"id": "2511.05491", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05491", "abs": "https://arxiv.org/abs/2511.05491", "authors": ["Rui Yang", "Ziyu Zhu", "Yanwei Li", "Jingjia Huang", "Shen Yan", "Siyuan Zhou", "Zhe Liu", "Xiangtai Li", "Shuangye Li", "Wenqian Wang", "Yi Lin", "Hengshuang Zhao"], "title": "Visual Spatial Tuning", "comment": null, "summary": "Capturing spatial relationships from visual inputs is a cornerstone of\nhuman-like general intelligence. Several previous studies have tried to enhance\nthe spatial awareness of Vision-Language Models (VLMs) by adding extra expert\nencoders, which brings extra overhead and usually harms general capabilities.\nTo enhance the spatial ability in general architectures, we introduce Visual\nSpatial Tuning (VST), a comprehensive framework to cultivate VLMs with\nhuman-like visuospatial abilities, from spatial perception to reasoning. We\nfirst attempt to enhance spatial perception in VLMs by constructing a\nlarge-scale dataset termed VST-P, which comprises 4.1 million samples spanning\n19 skills across single views, multiple images, and videos. Then, we present\nVST-R, a curated dataset with 135K samples that instruct models to reason in\nspace. In particular, we adopt a progressive training pipeline: supervised\nfine-tuning to build foundational spatial knowledge, followed by reinforcement\nlearning to further improve spatial reasoning abilities. Without the\nside-effect to general capabilities, the proposed VST consistently achieves\nstate-of-the-art results on several spatial benchmarks, including $34.8\\%$ on\nMMSI-Bench and $61.2\\%$ on VSIBench. It turns out that the\nVision-Language-Action models can be significantly enhanced with the proposed\nspatial tuning paradigm, paving the way for more physically grounded AI.", "AI": {"tldr": "Visual Spatial Tuning (VST) enables VLMs to gain visuospatial abilities without extra encoders by using large-scale perception and reasoning datasets and a progressive training pipeline, achieving state-of-the-art on MMSI-Bench and VSIBench and improving Vision-Language-Action models.", "motivation": "To overcome the inefficiency and potential harm to general capabilities caused by adding specialized spatial encoders for VLMs, and to equip general architectures with human-like visuospatial perception and reasoning.", "method": "Construct VST-P (4.1M samples, 19 spatial skills across single views, multi-image, and video) for perception and VST-R (135K samples) for spatial reasoning; employ a progressive training pipeline of supervised fine-tuning to build foundational spatial knowledge, followed by reinforcement learning to enhance spatial reasoning, without degrading general capabilities.", "result": "Achieves state-of-the-art on MMSI-Bench (34.8%) and VSIBench (61.2%); demonstrates that spatial tuning improves Vision-Language-Action models while preserving general abilities.", "conclusion": "VST offers a comprehensive, general-purpose framework to imbue VLMs with visuospatial perception and reasoning, enabling more physically grounded AI without the burden of extra encoders."}}
{"id": "2511.05456", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05456", "abs": "https://arxiv.org/abs/2511.05456", "authors": ["Naveen Raj Manoharan", "Hassan Iqbal", "Krishna Kumar"], "title": "Parameter-Efficient Conditioning for Material Generalization in Graph-Based Simulators", "comment": null, "summary": "Graph network-based simulators (GNS) have demonstrated strong potential for\nlearning particle-based physics (such as fluids, deformable solids, and\ngranular flows) while generalizing to unseen geometries due to their inherent\ninductive biases. However, existing models are typically trained for a single\nmaterial type and fail to generalize across distinct constitutive behaviors,\nlimiting their applicability in real-world engineering settings. Using granular\nflows as a running example, we propose a parameter-efficient conditioning\nmechanism that makes the GNS model adaptive to material parameters. We identify\nthat sensitivity to material properties is concentrated in the early\nmessage-passing (MP) layers, a finding we link to the local nature of\nconstitutive models (e.g., Mohr-Coulomb) and their effects on information\npropagation. We empirically validate this by showing that fine-tuning only the\nfirst few (1-5) of 10 MP layers of a pretrained model achieves comparable test\nperformance as compared to fine-tuning the entire network. Building on this\ninsight, we propose a parameter-efficient Feature-wise Linear Modulation (FiLM)\nconditioning mechanism designed to specifically target these early layers. This\napproach produces accurate long-term rollouts on unseen, interpolated, or\nmoderately extrapolated values (e.g., up to 2.5 degrees for friction angle and\n0.25 kPa for cohesion) when trained exclusively on as few as 12 short\nsimulation trajectories from new materials, representing a 5-fold data\nreduction compared to a baseline multi-task learning method. Finally, we\nvalidate the model's utility by applying it to an inverse problem, successfully\nidentifying unknown cohesion parameters from trajectory data. This approach\nenables the use of GNS in inverse design and closed-loop control tasks where\nmaterial properties are treated as design variables.", "AI": {"tldr": "Parameter-efficient conditioning via FiLM enables graph-network simulators to generalize across material behaviors with data-efficient fine-tuning focusing on early message-passing layers, yielding accurate long-horizon rollouts and enabling inverse-design tasks.", "motivation": "GNS models typically train on a single material type and struggle to generalize across different constitutive behaviors; real-world engineering requires adaptive models that can handle varying material parameters.", "method": "Identify that sensitivity to material properties concentrates in the early message-passing layers. Implement a FiLM-based conditioning mechanism targeted at the first 1-5 MP layers of a pretrained 10-layer MP stack. Fine-tune with as few as 12 short trajectories from new materials, achieving performance comparable to full fine-tuning. Validate on unseen/interpolated/extrapolated material parameters (e.g., friction angle and cohesion) and demonstrate inverse problems by estimating cohesion from trajectory data.", "result": "Fine-tuning only the initial few MP layers matches full fine-tuning performance; FiLM conditioning yields accurate long-term rollouts for unseen/moderately extrapolated materials (up to ~2.5\u00b0 friction angle and 0.25 kPa cohesion). Achieves ~5x data reduction compared to a multi-task baseline and enables successful inverse-design of cohesion from trajectories.", "conclusion": "The proposed parameter-efficient FiLM conditioning enables GNS to adapt to varying material properties, making them viable for inverse design and closed-loop control where material parameters are design variables."}}
{"id": "2511.05460", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.05460", "abs": "https://arxiv.org/abs/2511.05460", "authors": ["Sarkar Snigdha Sarathi Das", "Palash Goyal", "Mihir Parmar", "Yiwen Song", "Long T. Le", "Lesly Miculicich", "Jinsung Yoon", "Rui Zhang", "Hamid Palangi", "Tomas Pfister"], "title": "Synapse: Adaptive Arbitration of Complementary Expertise in Time Series Foundational Models", "comment": "19 pages, 7 figures, 4 tables", "summary": "Pre-trained Time Series Foundational Models (TSFMs) represent a significant\nadvance, capable of forecasting diverse time series with complex\ncharacteristics, including varied seasonalities, trends, and long-range\ndependencies. Despite their primary goal of universal time series forecasting,\ntheir efficacy is far from uniform; divergent training protocols and data\nsources cause individual TSFMs to exhibit highly variable performance across\ndifferent forecasting tasks, domains, and horizons. Leveraging this\ncomplementary expertise by arbitrating existing TSFM outputs presents a\ncompelling strategy, yet this remains a largely unexplored area of research. In\nthis paper, we conduct a thorough examination of how different TSFMs exhibit\nspecialized performance profiles across various forecasting settings, and how\nwe can effectively leverage this behavior in arbitration between different time\nseries models. We specifically analyze how factors such as model selection and\nforecast horizon distribution can influence the efficacy of arbitration\nstrategies. Based on this analysis, we propose Synapse, a novel arbitration\nframework for TSFMs. Synapse is designed to dynamically leverage a pool of\nTSFMs, assign and adjust predictive weights based on their relative,\ncontext-dependent performance, and construct a robust forecast distribution by\nadaptively sampling from the output quantiles of constituent models.\nExperimental results demonstrate that Synapse consistently outperforms other\npopular ensembling techniques as well as individual TSFMs, demonstrating\nSynapse's efficacy in time series forecasting.", "AI": {"tldr": "Synapse is an arbitration framework that dynamically weights a pool of pre-trained time series foundational models (TSFMs) based on context and forecast horizon; it also builds a robust forecast distribution by sampling from models' output quantiles, achieving superior results to standard ensembling and individual TSFMs.", "motivation": "TSFMs exhibit specialized, non-uniform performance due to diverse training data/protocols; leveraging their complementary strengths can improve forecasting across tasks, domains, and horizons.", "method": "Construct a pool of TSFMs; dynamically assign weights according to context-dependent performance; adaptively sample from the output quantiles of constituent models to produce a robust forecast distribution; evaluate arbitration strategies and horizon distribution effects.", "result": "Synapse consistently outperforms popular ensembling techniques and individual TSFMs across forecasting tasks, demonstrating robust gains.", "conclusion": "Arbitration among heterogeneous TSFMs is a promising route for time series forecasting; dynamic weighting and output quantile sampling yield robust, superior forecasts; this approach can generalize across domains and horizon settings."}}
{"id": "2511.05462", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.05462", "abs": "https://arxiv.org/abs/2511.05462", "authors": ["Xiaodong Wang", "Jing Huang", "Kevin J Liang"], "title": "SiamMM: A Mixture Model Perspective on Deep Unsupervised Learning", "comment": null, "summary": "Recent studies have demonstrated the effectiveness of clustering-based\napproaches for self-supervised and unsupervised learning. However, the\napplication of clustering is often heuristic, and the optimal methodology\nremains unclear. In this work, we establish connections between these\nunsupervised clustering methods and classical mixture models from statistics.\nThrough this framework, we demonstrate significant enhancements to these\nclustering methods, leading to the development of a novel model named SiamMM.\nOur method attains state-of-the-art performance across various self-supervised\nlearning benchmarks. Inspection of the learned clusters reveals a strong\nresemblance to unseen ground truth labels, uncovering potential instances of\nmislabeling.", "AI": {"tldr": "Grounds clustering-based self-supervised methods in a probabilistic framework of classical mixture models, introducing SiamMM, which achieves state-of-the-art results and yields interpretable clusters that resemble ground-truth labels.", "motivation": "Clustering-based approaches for self-supervised/unsupervised learning are promising but largely heuristic. A principled, probabilistic formulation\u2014linking clustering to classical mixture models\u2014could improve performance, clarity, and interpretability.", "method": "Establishes formal connections between unsupervised clustering methods and classical mixture models within a unified framework and uses this insight to develop a novel model named SiamMM.", "result": "SiamMM attains state-of-the-art performance across various self-supervised learning benchmarks.", "conclusion": "Learned clusters closely resemble unseen ground-truth labels, revealing potential instances of mislabeling and highlighting the interpretability benefits of the proposed probabilistic clustering framework."}}
{"id": "2511.05471", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05471", "abs": "https://arxiv.org/abs/2511.05471", "authors": ["Ant\u00f4nio Cat\u00e3o", "Melvin Poveda", "Leonardo Voltarelli", "Paulo Orenstein"], "title": "Precipitation nowcasting of satellite data using physically conditioned neural networks", "comment": null, "summary": "Accurate short-term precipitation forecasts predominantly rely on dense\nweather-radar networks, limiting operational value in places most exposed to\nclimate extremes. We present TUPANN (Transferable and Universal Physics-Aligned\nNowcasting Network), a satellite-only model trained on GOES-16 RRQPE. Unlike\nmost deep learning models for nowcasting, TUPANN decomposes the forecast into\nphysically meaningful components: a variational encoder-decoder infers motion\nand intensity fields from recent imagery under optical-flow supervision, a\nlead-time-conditioned MaxViT evolves the latent state, and a differentiable\nadvection operator reconstructs future frames. We evaluate TUPANN on both\nGOES-16 and IMERG data, in up to four distinct climates (Rio de Janeiro,\nManaus, Miami, La Paz) at 10-180min lead times using the CSI and HSS metrics\nover 4-64 mm/h thresholds. Comparisons against optical-flow, deep learning and\nhybrid baselines show that TUPANN achieves the best or second-best skill in\nmost settings, with pronounced gains at higher thresholds. Training on multiple\ncities further improves performance, while cross-city experiments show modest\ndegradation and occasional gains for rare heavy-rain regimes. The model\nproduces smooth, interpretable motion fields aligned with numerical optical\nflow and runs in near real time due to the low latency of GOES-16. These\nresults indicate that physically aligned learning can provide nowcasts that are\nskillful, transferable and global.", "AI": {"tldr": "TUPANN is a satellite-only nowcasting model that decouples forecast into physically meaningful components (motion, intensity) via a variational encoder\u2013decoder with optical-flow supervision, a lead-time-conditioned MaxViT for latent evolution, and a differentiable advection operator, achieving strong, transferable short-term rainfall nowcasts from GOES-16/IMERG data across multiple climates with real-time efficiency.", "motivation": "Dense weather-radar networks limit rainfall nowcasting in regions most exposed to extremes; a global, transferable, satellite-only approach can provide timely forecasts where radars are sparse, supporting operational needs across diverse climates.", "method": "A physics-aligned architecture: (1) a variational encoder\u2013decoder infers motion and intensity fields under optical-flow supervision; (2) a lead-time-conditioned MaxViT evolves the latent state; (3) a differentiable advection operator reconstructs future frames. Trained on GOES-16 RRQPE and evaluated on GOES-16 and IMERG data across four climates (Rio de Janeiro, Manaus, Miami, La Paz) for 10\u2013180 min lead times, using CSI and HSS over 4\u201364 mm/h thresholds; compared against optical-flow, DL, and hybrid baselines.", "result": "TUPANN achieves best or second-best skill in most settings, with pronounced gains at higher rainfall thresholds. Training on multiple cities improves performance; cross-city tests show modest degradation but occasional gains for rare heavy-rain regimes. Outputs smooth, interpretable motion fields aligned with optical flow and runs near real time due to GOES-16 latency.", "conclusion": "Physically aligned learning enables nowcasts that are skillful, transferable, and global, combining satellite data with interpretable dynamics for effective short-term rainfall forecasts."}}
{"id": "2511.05482", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.05482", "abs": "https://arxiv.org/abs/2511.05482", "authors": ["Kang Yang", "Yuanlin Yang", "Yuning Chen", "Sikai Yang", "Xinyu Zhang", "Wan Du"], "title": "SoilX: Calibration-Free Comprehensive Soil Sensing Through Contrastive Cross-Component Learning", "comment": null, "summary": "Precision agriculture demands continuous and accurate monitoring of soil\nmoisture (M) and key macronutrients, including nitrogen (N), phosphorus (P),\nand potassium (K), to optimize yields and conserve resources. Wireless soil\nsensing has been explored to measure these four components; however, current\nsolutions require recalibration (i.e., retraining the data processing model) to\nhandle variations in soil texture, characterized by aluminosilicates (Al) and\norganic carbon (C), limiting their practicality. To address this, we introduce\nSoilX, a calibration-free soil sensing system that jointly measures six key\ncomponents: {M, N, P, K, C, Al}. By explicitly modeling C and Al, SoilX\neliminates texture- and carbon-dependent recalibration. SoilX incorporates\nContrastive Cross-Component Learning (3CL), with two customized terms: the\nOrthogonality Regularizer and the Separation Loss, to effectively disentangle\ncross-component interference. Additionally, we design a novel tetrahedral\nantenna array with an antenna-switching mechanism, which can robustly measure\nsoil dielectric permittivity independent of device placement. Extensive\nexperiments demonstrate that SoilX reduces estimation errors by 23.8% to 31.5%\nover baselines and generalizes well to unseen fields.", "AI": {"tldr": "SoilX offers calibration-free, multi-component soil sensing (M, N, P, K, C, Al) using Contrastive Cross-Component Learning and a tetrahedral antenna array to reduce calibration and improve generalization.", "motivation": "Current wireless soil sensing requires recalibration to cope with soil texture variations (aluminosilicates and organic carbon), limiting practicality. A calibration-free, texture-robust approach is needed.", "method": "Joint measurement of six soil components (M, N, P, K, C, Al) with explicit modeling of C and Al. Introduces Contrastive Cross-Component Learning (3CL) featuring an Orthogonality Regularizer and a Separation Loss to disentangle cross-component interference. Develops a tetrahedral antenna array with switching to measure soil dielectric permittivity independently of device placement.", "result": "Experiments show SoilX reduces estimation errors by 23.8% to 31.5% compared with baselines and generalizes well to unseen fields.", "conclusion": "SoilX delivers calibration-free, texture- and carbon-independent soil sensing by jointly modeling six components and mitigating cross-component interference, aided by a robust tetrahedral antenna design."}}
