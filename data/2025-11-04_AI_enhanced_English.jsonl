{"id": "2511.00692", "categories": ["cs.CG", "cs.DM", "math.MG"], "pdf": "https://arxiv.org/pdf/2511.00692", "abs": "https://arxiv.org/abs/2511.00692", "authors": ["Ke Chen", "Adrian Dumitrescu"], "title": "A Couple of Simple Algorithms for $k$-Dispersion", "comment": "8 pages", "summary": "Given a set $P$ of $n$ points in $\\mathbf{R}^d$, and a positive integer $k\n\\leq n$, the $k$-dispersion problem is that of selecting $k$ of the given\npoints so that the minimum inter-point distance among them is maximized (under\nEuclidean distances). Among others, we show the following:\n  (I) Given a set $P$ of $n$ points in the plane, and a positive integer $k\n\\geq 2$, the $k$-dispersion problem can be solved by an algorithm running in\n$O\\left(n^{k-1} \\log{n}\\right)$ time. This extends an earlier result for $k=3$,\ndue to Horiyama, Nakano, Saitoh, Suetsugu, Suzuki, Uehara, Uno, and Wasa (2021)\nto arbitrary $k$. In particular, it improves on previous running times for\nsmall $k$.\n  (II) Given a set $P$ of $n$ points in $\\mathbf{R}^3$, and a positive integer\n$k \\geq 2$, the $k$-dispersion problem can be solved by an algorithm running in\n$O\\left(n^{k-1} \\log{n}\\right)$ time, if $k$ is even; and $O\\left(n^{k-1}\n\\log^2{n}\\right)$ time, if $k$ is odd. For $k \\geq 4$, no combinatorial\nalgorithm running in $o(n^k)$ time was known for this problem.\n  (III) Let $P$ be a set of $n$ random points uniformly distributed in\n$[0,1]^2$. Then under suitable conditions, a $0.99$-approximation for\n$k$-dispersion can be computed in $O(n)$ time with high probability.", "AI": {"tldr": "The abstract presents three main algorithmic results for the k-dispersion problem: (I) a plane algorithm running in O(n^{k-1} log n) for general k (extending k=3) with improved small-k performance; (II) a 3D algorithm with O(n^{k-1} log n) time for even k and O(n^{k-1} log^2 n) for odd k, noting that no o(n^k) algorithms were known for k\u22654; (III) a linear-time (O(n)) 0.99-approximation for random points in [0,1]^2 with high probability. These contribute to the understanding of exact and approximate dispersion computations in low dimensions and show favorable complexity when k is small or dimensions are fixed.", "motivation": "Dispersion optimization (maximizing the minimum pairwise distance among k selected points) is a natural objective in clustering, facility placement, and network design. Understanding its complexity in fixed dimensions and for varying k informs algorithm design for geometric optimization problems.", "method": "The abstract signals combinatorial algorithmic techniques that achieve dimension- and parity-based time bounds. It extends known k=3 results to arbitrary k in the plane, and shows a parity-dependent complexity in 3D. It also leverages probabilistic/average-case assumptions to obtain a fast linear-time 0.99-approximation for random points. Specific algorithmic details (e.g., data structures, reductions, or dynamic programming schemes) are not disclosed in the abstract.", "result": "(I) A plane algorithm solving k-dispersion in O(n^{k-1} log n) time for any k\u22652 (extending the k=3 result). (II) In R^3, O(n^{k-1} log n) time when k is even; O(n^{k-1} log^2 n) when k is odd; no o(n^k) combinatorial algorithm known for k\u22654. (III) For random uniform points in [0,1]^2, a 0.99-approximation can be computed in O(n) time with high probability under suitable conditions.", "conclusion": "The results advance exact and approximation approaches for k-dispersion in low dimensions, providing improved time bounds and clarifying the role of dimension and parity. They widen the practical applicability of dispersion optimization by offering faster algorithms for common cases and highlighting the remaining gaps (e.g., general o(n^k) lower/upper bounds in 3D for larger k, and extensions to broader distributions)."}}
{"id": "2511.01562", "categories": ["cs.CG", "cs.DS", "68W40", "F.2.2; I.1.2"], "pdf": "https://arxiv.org/pdf/2511.01562", "abs": "https://arxiv.org/abs/2511.01562", "authors": ["Jack Stade"], "title": "NP-membership for the boundary-boundary art-gallery problem", "comment": "23 pages, 12 figures", "summary": "The boundary-boundary art-gallery problem asks, given a polygon $P$\nrepresenting an art-gallery, for a minimal set of guards that can see the\nentire boundary of $P$ (the wall of the art gallery), where the guards must be\nplaced on the boundary. We show that this art-gallery variant is in NP. In\norder to prove this, we develop a constraint-propagation procedure for\ncontinuous constraint satisfaction problems where each constraint involves at\nmost 2 variables.\n  The X-Y variant of the art-gallery problem is the one where the guards must\nlie in X and need to see all of Y. Each of X and Y can be either the vertices\nof the polygon, the boundary of the polygon, or the entire polygon, giving 9\ndifferent variants. Previously, it was known that X-vertex and vertex-Y\nvariants are all NP-complete and that the point-point, point-boundary, and\nboundary-point variants are $\\exists \\mathbb{R}$-complete [Abrahamsen,\nAdamaszek, and Miltzow, JACM 2021][Stade, SoCG 2025]. However, the\nboundary-boundary variant was only known to lie somewhere between NP and\n$\\exists \\mathbb{R}$.\n  The X-vertex and vertex-Y variants can be straightforwardly reduced to\ndiscrete set-cover instances. In contrast, we give example to show that a\nsolution to an instance of the boundary-boundary art-gallery problem sometimes\nrequires placing guards at irrational coordinates, so it unlikely that the\nproblem can be easily discretized.", "AI": {"tldr": "Proves boundary-boundary art-gallery variant is in NP; analyzes the nine X-Y variants; introduces a constraint-propagation approach for binary-variable continuous CSPs; finds that optimal boundary-boundary solutions may require irrational guard placements and thus resists discretization; situates boundary-boundary between NP and exists-R in the complexity landscape.", "motivation": "Resolve the complexity of the boundary-boundary art-gallery problem and complete the taxonomy of X-Y variants; understand whether discretization is feasible and how the problem relates to known complexity classes (NP, exists-R).", "method": "Develop a constraint-propagation framework for continuous constraint satisfaction problems where constraints involve at most two variables; apply this to visibility constraints on the boundary of a polygon; analyze reductions for X-Y variants (notably X-vertex and vertex-Y to set cover) and construct examples showing irrational guard coordinates are necessary for some instances; compare to prior results (ER-complete variants) to position the boundary-boundary problem.", "result": "The boundary-boundary variant is shown to be in NP. A comprehensive view of all nine X-Y variants is provided: X-vertex and vertex-Y are NP-complete; point-point, point-boundary, and boundary-point are exist-R-complete; boundary-boundary lies between NP and exists-R. It is demonstrated that some instances require guards at irrational coordinates, indicating discretization is unlikely.", "conclusion": "This work closes part of the complexity gap by placing boundary-boundary in NP and clarifies the landscape of X-Y variants. It raises further questions about exact hardness (e.g., NP-hardness or NP-completeness for boundary-boundary), and invites exploration of continuous CSP techniques for other geometric visibility problems."}}
{"id": "2511.00011", "categories": ["cs.CV", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.00011", "abs": "https://arxiv.org/abs/2511.00011", "authors": ["Alexander Okupnik", "Johannes Schneider", "Kyriakos Flouris"], "title": "Generative human motion mimicking through feature extraction in denoising diffusion settings", "comment": null, "summary": "Recent success with large language models has sparked a new wave of verbal\nhuman-AI interaction. While such models support users in a variety of creative\ntasks, they lack the embodied nature of human interaction. Dance, as a primal\nform of human expression, is predestined to complement this experience. To\nexplore creative human-AI interaction exemplified by dance, we build an\ninteractive model based on motion capture (MoCap) data. It generates an\nartificial other by partially mimicking and also \"creatively\" enhancing an\nincoming sequence of movement data. It is the first model, which leverages\nsingle-person motion data and high level features in order to do so and, thus,\nit does not rely on low level human-human interaction data. It combines ideas\nof two diffusion models, motion inpainting, and motion style transfer to\ngenerate movement representations that are both temporally coherent and\nresponsive to a chosen movement reference. The success of the model is\ndemonstrated by quantitatively assessing the convergence of the feature\ndistribution of the generated samples and the test set which serves as\nsimulating the human performer. We show that our generations are first steps to\ncreative dancing with AI as they are both diverse showing various deviations\nfrom the human partner while appearing realistic.", "AI": {"tldr": "A diffusion-based MoCap dance system that partly mimics and creatively enhances an incoming movement sequence using single-person data and high-level features, achieving temporally coherent, diverse, and realistic motion without low-level joint-level human-human data.", "motivation": "To explore embodied human-AI interaction through dance by combining motion capture data with diffusion-based generation, addressing the lack of embodied interaction in large language models and enabling a responsive AI dance partner.", "method": "A dual-diffusion-model framework that integrates motion inpainting and motion style transfer. It uses single-person MoCap data with high-level features to generate temporally coherent motion that partially mimics and creatively enhances an incoming sequence, without relying on low-level human-human interaction data.", "result": "Quantitative evaluation shows convergence of the generated motion feature distribution to that of a test set simulating a human performer. The generated dances are diverse and realistic, representing initial steps toward AI-assisted creative dancing.", "conclusion": "The work demonstrates feasibility of using diffusion-based generation on single-person MoCap data for embodied, responsive AI dance, offering a foundation for more sophisticated human-AI dance collaboration with creative potential."}}
{"id": "2511.00026", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00026", "abs": "https://arxiv.org/abs/2511.00026", "authors": ["Chaitanya Shinde", "Divya Garikapati"], "title": "Gen AI in Automotive: Applications, Challenges, and Opportunities with a Case study on In-Vehicle Experience", "comment": null, "summary": "Generative Artificial Intelligence is emerging as a transformative force in\nthe automotive industry, enabling novel applications across vehicle design,\nmanufacturing, autonomous driving, predictive maintenance, and in vehicle user\nexperience. This paper provides a comprehensive review of the current state of\nGenAI in automotive, highlighting enabling technologies such as Generative\nAdversarial Networks and Variational Autoencoders. Key opportunities include\naccelerating autonomous driving validation through synthetic data generation,\noptimizing component design, and enhancing human machine interaction via\npersonalized and adaptive interfaces. At the same time, the paper identifies\nsignificant technical, ethical, and safety challenges, including computational\ndemands, bias, intellectual property concerns, and adversarial robustness, that\nmust be addressed for responsible deployment. A case study on Mercedes Benzs\nMBUX Virtual Assistant illustrates how GenAI powered voice systems deliver more\nnatural, proactive, and personalized in car interactions compared to legacy\nrule based assistants. Through this review and case study, the paper outlines\nboth the promise and limitations of GenAI integration in the automotive sector\nand presents directions for future research and development aimed at achieving\nsafer, more efficient, and user centric mobility. Unlike prior reviews that\nfocus solely on perception or manufacturing, this paper emphasizes generative\nAI in voice based HMI, bridging safety and user experience perspectives.", "AI": {"tldr": "GenAI in automotive is reviewed; highlights GANs/VAEs, synthetic data for validation, design optimization, improved voice-based HMI; addresses challenges (compute, bias, IP, adversarial robustness); includes MBUX case study; outlines future directions.", "motivation": "To map current GenAI capabilities to automotive applications, bridging safety and user experience, and to identify opportunities, limitations, and research directions beyond perception/manufacturing reviews.", "method": "Comprehensive literature review plus a case study; synthesis across enabling technologies; emphasis on voice-based HMI; comparison to legacy systems.", "result": "Identifies opportunities in autonomous driving validation, design optimization, personalized interfaces; notes significant challenges; demonstrates MBUX case study with more natural, proactive interactions; defines boundary of GenAI's promise and limits.", "conclusion": "GenAI holds potential for safer, more efficient, user-centric mobility; requires tackling computation, bias, IP, adversarial threats; suggests directions for future work and responsible deployment."}}
{"id": "2511.00002", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00002", "abs": "https://arxiv.org/abs/2511.00002", "authors": ["Yurun Wu", "Yousong Sun", "Burkhard Wunsche", "Jia Wang", "Elliott Wen"], "title": "VRScout: Towards Real-Time, Autonomous Testing of Virtual Reality Games", "comment": null, "summary": "Virtual Reality (VR) has rapidly become a mainstream platform for gaming and\ninteractive experiences, yet ensuring the quality, safety, and appropriateness\nof VR content remains a pressing challenge. Traditional human-based quality\nassurance is labor-intensive and cannot scale with the industry's rapid growth.\nWhile automated testing has been applied to traditional 2D and 3D games,\nextending it to VR introduces unique difficulties due to high-dimensional\nsensory inputs and strict real-time performance requirements. We present\nVRScout, a deep learning-based agent capable of autonomously navigating VR\nenvironments and interacting with virtual objects in a human-like and real-time\nmanner. VRScout learns from human demonstrations using an enhanced Action\nChunking Transformer that predicts multi-step action sequences. This enables\nour agent to capture higher-level strategies and generalize across diverse\nenvironments. To balance responsiveness and precision, we introduce a\ndynamically adjustable sliding horizon that adapts the agent's temporal context\nat runtime. We evaluate VRScout on commercial VR titles and show that it\nachieves expert-level performance with only limited training data, while\nmaintaining real-time inference at 60 FPS on consumer-grade hardware. These\nresults position VRScout as a practical and scalable framework for automated VR\ngame testing, with direct applications in both quality assurance and safety\nauditing.", "AI": {"tldr": "VRScout is a deep learning agent that autonomously tests VR games by learning multi-step actions from human demonstrations, using an enhanced Action Chunking Transformer and a dynamic horizon to achieve expert-level, real-time VR testing at 60 FPS on consumer hardware.", "motivation": "Quality assurance for VR is labor-intensive and doesn't scale; VR's high-dimensional input and real-time constraints require automated, scalable testing solutions.", "method": "Train an enhanced Action Chunking Transformer to predict multi-step action sequences from human demonstrations; incorporate a dynamically adjustable sliding horizon to adapt temporal context at runtime; enable 60 FPS real-time inference on commodity hardware; validated on commercial VR titles.", "result": "Achieves expert-level performance with limited training data; real-time 60 FPS inference on consumer hardware; demonstrates practicality and scalability for automated VR game testing and safety auditing.", "conclusion": "VRScout provides a scalable, generalizable framework for automated VR QA that can reduce human labor and improve safety auditing, with potential to extend to broader VR testing tasks."}}
{"id": "2511.00020", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00020", "abs": "https://arxiv.org/abs/2511.00020", "authors": ["Suhasnadh Reddy Veluru", "Sai Teja Erukude", "Viswa Chaitanya Marella"], "title": "Multimodal Detection of Fake Reviews using BERT and ResNet-50", "comment": "Published in IEEE", "summary": "In the current digital commerce landscape, user-generated reviews play a\ncritical role in shaping consumer behavior, product reputation, and platform\ncredibility. However, the proliferation of fake or misleading reviews often\ngenerated by bots, paid agents, or AI models poses a significant threat to\ntrust and transparency within review ecosystems. Existing detection models\nprimarily rely on unimodal, typically textual, data and therefore fail to\ncapture semantic inconsistencies across different modalities. To address this\ngap, a robust multimodal fake review detection framework is proposed,\nintegrating textual features encoded with BERT and visual features extracted\nusing ResNet-50. These representations are fused through a classification head\nto jointly predict review authenticity. To support this approach, a curated\ndataset comprising 21,142 user-uploaded images across food delivery,\nhospitality, and e-commerce domains was utilized. Experimental results indicate\nthat the multimodal model outperforms unimodal baselines, achieving an F1-score\nof 0.934 on the test set. Additionally, the confusion matrix and qualitative\nanalysis highlight the model's ability to detect subtle inconsistencies, such\nas exaggerated textual praise paired with unrelated or low-quality images,\ncommonly found in deceptive content. This study demonstrates the critical role\nof multimodal learning in safeguarding digital trust and offers a scalable\nsolution for content moderation across various online platforms.", "AI": {"tldr": "A robust multimodal detector for fake reviews using BERT for text and ResNet-50 for images, achieving high F1 (0.934) and outperforming unimodal baselines on 21k+ image-annotated reviews across food/hospitality/e-commerce.", "motivation": "Fake reviews by bots/AI undermine trust and platform credibility. Unimodal (text-only) detectors miss cross-modal inconsistencies between text and visuals.", "method": "Encode textual content with BERT and visual content with ResNet-50; fuse the multimodal representations with a classification head; train/evaluate on a curated dataset of 21,142 user-uploaded images from multiple domains.", "result": "The multimodal model achieves higher performance than unimodal baselines, with an F1-score of 0.934 on the test set. Qualitative analysis highlights detection of inconsistencies such as lavish textual praise paired with unrelated or low-quality images; the confusion matrix supports robust detection across classes.", "conclusion": "Multimodal learning is crucial for safeguarding digital trust and offers a scalable approach to content moderation across diverse online platforms."}}
{"id": "2511.00021", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00021", "abs": "https://arxiv.org/abs/2511.00021", "authors": ["Julio Jerison E. Macrohon", "Gordon Hung"], "title": "Deep Learning Models for Coral Bleaching Classification in Multi-Condition Underwater Image Datasets", "comment": "15 pages, 10 figures", "summary": "Coral reefs support numerous marine organisms and are an important source of\ncoastal protection from storms and floods, representing a major part of marine\necosystems. However coral reefs face increasing threats from pollution, ocean\nacidification, and sea temperature anomalies, making efficient protection and\nmonitoring heavily urgent. Therefore, this study presents a novel\nmachine-learning-based coral bleaching classification system based on a diverse\nglobal dataset with samples of healthy and bleached corals under varying\nenvironmental conditions, including deep seas, marshes, and coastal zones. We\nbenchmarked and compared three state-of-the-art models: Residual Neural Network\n(ResNet), Vision Transformer (ViT), and Convolutional Neural Network (CNN).\nAfter comprehensive hyperparameter tuning, the CNN model achieved the highest\naccuracy of 88%, outperforming existing benchmarks. Our findings offer\nimportant insights into autonomous coral monitoring and present a comprehensive\nanalysis of the most widely used computer vision models.", "AI": {"tldr": "CNN-based coral bleaching classifier on a diverse global dataset achieved 88% accuracy, outperforming ResNet and ViT; demonstrates potential for autonomous coral monitoring.", "motivation": "Coral reefs are threatened by pollution, ocean acidification, and warming; there is urgent need for efficient, scalable monitoring and protection, motivating automated ML approaches for bleaching detection.", "method": "Assemble a diverse global image dataset with healthy and bleached corals under various environments (deep sea, marshes, coastal zones). Benchmark three state-of-the-art models: ResNet, Vision Transformer (ViT), and CNN; perform hyperparameter tuning; compare performance.", "result": "CNN achieved the highest accuracy at 88%, outperforming ResNet and ViT and existing benchmarks.", "conclusion": "Demonstrates the viability of CNN-based autonomous coral bleaching classification; contributes a comparative analysis of popular CV models and informs deployment for automated coral monitoring."}}
{"id": "2511.00033", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00033", "abs": "https://arxiv.org/abs/2511.00033", "authors": ["Diqi He", "Xuehao Gao", "Hao Li", "Junwei Han", "Dingwen Zhang"], "title": "STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization", "comment": null, "summary": "The Zero-shot Vision-and-Language Navigation in Continuous Environments\n(VLN-CE) task requires agents to navigate previously unseen 3D environments\nusing natural language instructions, without any scene-specific training. A\ncritical challenge in this setting lies in ensuring agents' actions align with\nboth spatial structure and task intent over long-horizon execution. Existing\nmethods often fail to achieve robust navigation due to a lack of structured\ndecision-making and insufficient integration of feedback from previous actions.\nTo address these challenges, we propose STRIDER (Instruction-Aligned Structural\nDecision Space Optimization), a novel framework that systematically optimizes\nthe agent's decision space by integrating spatial layout priors and dynamic\ntask feedback. Our approach introduces two key innovations: 1) a Structured\nWaypoint Generator that constrains the action space through spatial structure,\nand 2) a Task-Alignment Regulator that adjusts behavior based on task progress,\nensuring semantic alignment throughout navigation. Extensive experiments on the\nR2R-CE and RxR-CE benchmarks demonstrate that STRIDER significantly outperforms\nstrong SOTA across key metrics; in particular, it improves Success Rate (SR)\nfrom 29% to 35%, a relative gain of 20.7%. Such results highlight the\nimportance of spatially constrained decision-making and feedback-guided\nexecution in improving navigation fidelity for zero-shot VLN-CE.", "AI": {"tldr": "STRIDER is a zero-shot VLN-CE framework that uses spatially constrained decision space via a Structured Waypoint Generator and a Task-Alignment Regulator to ensure long-horizon navigation aligns with spatial structure and task intent, achieving notable SR gains on R2R-CE and RxR-CE.", "motivation": "Addresses the core challenge of zero-shot vision-and-language navigation in continuous 3D environments: maintaining alignment with spatial structure and task intent across long horizons, compounded by insufficient structured decision-making and feedback integration.", "method": "Proposes STRIDER, combining a Structured Waypoint Generator to constrain the action space using spatial structure and a Task-Alignment Regulator to adjust behavior based on task progress. Integrates spatial layout priors and dynamic task feedback.", "result": "Empirically, STRIDER improves Success Rate from 29% to 35% (relative ~20.7%). It outperforms strong SOTA on R2R-CE and RxR-CE benchmarks, demonstrating the effectiveness of spatially constrained decision-making and feedback-guided execution.", "conclusion": "Spatially constrained decision-making and feedback-guided execution are key to improving zero-shot VLN-CE navigation fidelity; STRIDER provides an effective framework that could generalize to other long-horizon, instruction-following navigation tasks."}}
{"id": "2511.00029", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00029", "abs": "https://arxiv.org/abs/2511.00029", "authors": ["Samaksh Bhargav", "Zining Zhu"], "title": "Feature-Guided SAE Steering for Refusal-Rate Control using Contrasting Prompts", "comment": "12 pages, 6 figures", "summary": "Large Language Model (LLM) deployment requires guiding the LLM to recognize\nand not answer unsafe prompts while complying with safe prompts. Previous\nmethods for achieving this require adjusting model weights along with other\nexpensive procedures. While recent advances in Sparse Autoencoders (SAEs) have\nenabled interpretable feature extraction from LLMs, existing approaches lack\nsystematic feature selection methods and principled evaluation of\nsafety-utility tradeoffs. We explored using different steering features and\nsteering strengths using Sparse Auto Encoders (SAEs) to provide a solution.\nUsing an accurate and innovative contrasting prompt method with the\nAI-Generated Prompts Dataset from teknium/OpenHermes-2p5-Mistral-7B and Air\nBench eu-dataset to efficiently choose the best features in the model to steer,\nwe tested this method on Llama-3 8B. We conclude that using this method, our\napproach achieves an 18.9% improvement in safety performance while\nsimultaneously increasing utility by 11.1%, demonstrating that targeted SAE\nsteering can overcome traditional safety-utility tradeoffs when optimal\nfeatures are identified through principled selection methods.", "AI": {"tldr": "A method to steer LLM safety and utility using Sparse Auto Encoders (SAEs) to select optimal features, coupled with a contrasting prompt strategy and benchmarks, claiming improved safety (18.9%) and utility (11.1%) on Llama-3 8B.", "motivation": "To enable safer LLM deployment without expensive full-model fine-tuning, leveraging interpretable SAE-based feature steering to navigate the safety-utility tradeoff.", "method": "Use Sparse Auto Encoders to identify steering features and apply calibrated steering strengths. Employ an innovative contrasting prompt method with AI-Generated Prompts Dataset (teknium/OpenHermes-2p5-Mistral-7B) and Air Bench eu-dataset to guide feature selection. Validate on Llama-3 8B with measured safety and utility metrics.", "result": "Reported improvements: safety performance up by 18.9% and utility up by 11.1% when using the SAE-based steering with principled feature selection.", "conclusion": "Targeted SAE steering can potentially surpass traditional safety-utility tradeoffs if optimal features are identified through principled selection; claims would benefit from replication, clearer definitions of safety/utility metrics, and assessment across broader models and datasets."}}
{"id": "2511.00039", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00039", "abs": "https://arxiv.org/abs/2511.00039", "authors": ["Krishna Kumar Neelakanta Pillai Santha Kumari Amma"], "title": "Graph-Attentive MAPPO for Dynamic Retail Pricing", "comment": null, "summary": "Dynamic pricing in retail requires policies that adapt to shifting demand\nwhile coordinating decisions across related products. We present a systematic\nempirical study of multi-agent reinforcement learning for retail price\noptimization, comparing a strong MAPPO baseline with a\ngraph-attention-augmented variant (MAPPO+GAT) that leverages learned\ninteractions among products. Using a simulated pricing environment derived from\nreal transaction data, we evaluate profit, stability across random seeds,\nfairness across products, and training efficiency under a standardized\nevaluation protocol. The results indicate that MAPPO provides a robust and\nreproducible foundation for portfolio-level price control, and that MAPPO+GAT\nfurther enhances performance by sharing information over the product graph\nwithout inducing excessive price volatility. These results indicate that\ngraph-integrated MARL provides a more scalable and stable solution than\nindependent learners for dynamic retail pricing, offering practical advantages\nin multi-product decision-making.", "AI": {"tldr": "Graph-integrated MARL (MAPPO+GAT) improves multi-product dynamic pricing over a MAPPO baseline by leveraging learned product interdependencies; it offers robust, scalable, and stable portfolio-level price control.", "motivation": "Dynamic pricing for multiple related products requires adapting to shifting demand while coordinating across items. The study investigates whether graph-based interactions can enhance MARL-based price optimization in a realistic retail setting.", "method": "Empirical comparison of MAPPO and a graph-attention variant MAPPO+GAT in a simulated pricing environment derived from real transaction data. Evaluation uses standardized protocol across metrics such as profit, seed stability, product fairness, and training efficiency.", "result": "MAPPO provides a robust, reproducible foundation for portfolio-level price control. MAPPO+GAT further improves performance by sharing information over the product graph without causing excessive price volatility, offering a more scalable and stable solution than independent learners.", "conclusion": "Graph-integrated MARL is advantageous for multi-product dynamic pricing, delivering practical benefits in orchestrating price decisions across a portfolio of products."}}
{"id": "2511.00022", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00022", "abs": "https://arxiv.org/abs/2511.00022", "authors": ["Jules Gerard", "Leandro Di Bella", "Filip Huyghe", "Marc Kochzius"], "title": "Automating Coral Reef Fish Family Identification on Video Transects Using a YOLOv8-Based Deep Learning Pipeline", "comment": "Accepted to EUVIP2025, student session", "summary": "Coral reef monitoring in the Western Indian Ocean is limited by the labor\ndemands of underwater visual censuses. This work evaluates a YOLOv8-based deep\nlearning pipeline for automating family-level fish identification from video\ntransects collected in Kenya and Tanzania. A curated dataset of 24 families was\ntested under different configurations, providing the first region-specific\nbenchmark for automated reef fish monitoring in the Western Indian Ocean. The\nbest model achieved mAP@0.5 of 0.52, with high accuracy for abundant families\nbut weaker detection of rare or complex taxa. Results demonstrate the potential\nof deep learning as a scalable complement to traditional monitoring methods.", "AI": {"tldr": "YOLOv8-based pipeline for automating family-level reef fish IDs from Western Indian Ocean transects; benchmark on 24 families; best mAP@0.5 0.52; scalable approach with limitations on rare taxa.", "motivation": "Labor-intensive underwater visual censuses limit coral reef monitoring; need scalable, region-specific tools and benchmarks for the Western Indian Ocean.", "method": "Curated video transect dataset from Kenya and Tanzania covering 24 fish families; evaluated a YOLOv8-based detection pipeline under multiple configurations; assessed performance using mAP@0.5.", "result": "Best model achieved mAP@0.5 of 0.52; high accuracy for abundant families but weaker detection of rare or complex taxa.", "conclusion": "Deep learning can be a scalable complement to traditional reef-monitoring methods, with strong potential in the Western Indian Ocean; performance is limited by rare/complex taxa and may benefit from more diverse data and taxa-specific tuning."}}
{"id": "2511.00041", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00041", "abs": "https://arxiv.org/abs/2511.00041", "authors": ["Yingzhao Jian", "Zhongan Wang", "Yi Yang", "Hehe Fan"], "title": "Endowing GPT-4 with a Humanoid Body: Building the Bridge Between Off-the-Shelf VLMs and the Physical World", "comment": null, "summary": "Humanoid agents often struggle to handle flexible and diverse interactions in\nopen environments. A common solution is to collect massive datasets to train a\nhighly capable model, but this approach can be prohibitively expensive. In this\npaper, we explore an alternative solution: empowering off-the-shelf\nVision-Language Models (VLMs, such as GPT-4) to control humanoid agents,\nthereby leveraging their strong open-world generalization to mitigate the need\nfor extensive data collection. To this end, we present \\textbf{BiBo}\n(\\textbf{B}uilding humano\\textbf{I}d agent \\textbf{B}y \\textbf{O}ff-the-shelf\nVLMs). It consists of two key components: (1) an \\textbf{embodied instruction\ncompiler}, which enables the VLM to perceive the environment and precisely\ntranslate high-level user instructions (e.g., {\\small\\itshape ``have a rest''})\ninto low-level primitive commands with control parameters (e.g.,\n{\\small\\itshape ``sit casually, location: (1, 2), facing: 90$^\\circ$''}); and\n(2) a diffusion-based \\textbf{motion executor}, which generates human-like\nmotions from these commands, while dynamically adapting to physical feedback\nfrom the environment. In this way, BiBo is capable of handling not only basic\ninteractions but also diverse and complex motions. Experiments demonstrate that\nBiBo achieves an interaction task success rate of 90.2\\% in open environments,\nand improves the precision of text-guided motion execution by 16.3\\% over prior\nmethods. The code will be made publicly available.", "AI": {"tldr": "BiBo uses off-the-shelf vision-language models to control humanoid agents via an embodied instruction compiler and a diffusion-based motion executor, achieving high interaction success with reduced data needs.", "motivation": "To reduce data collection costs while leveraging VLMs' open-world generalization for humanoid control.", "method": "Two components: (1) embodied instruction compiler translates high-level user instructions into low-level commands with parameters; (2) diffusion-based motion executor generates human-like motions from the commands and adapts to environmental feedback.", "result": "In open environments, BiBo achieves 90.2% task success and improves text-guided motion execution precision by 16.3% over prior methods; code will be released.", "conclusion": "BiBo demonstrates that off-the-shelf VLMs can effectively control humanoid agents in open settings with robust generalization and reduced data requirements."}}
{"id": "2511.00030", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00030", "abs": "https://arxiv.org/abs/2511.00030", "authors": ["Myeongseob Ko", "Hoang Anh Just", "Charles Fleming", "Ming Jin", "Ruoxi Jia"], "title": "Probing Knowledge Holes in Unlearned LLMs", "comment": "The Thirty-ninth Annual Conference on Neural Information Processing\n  Systems", "summary": "Machine unlearning has emerged as a prevalent technical solution for\nselectively removing unwanted knowledge absorbed during pre-training, without\nrequiring full retraining. While recent unlearning techniques can effectively\nremove undesirable content without severely compromising performance on\nstandard benchmarks, we find that they may inadvertently create ``knowledge\nholes'' -- unintended losses of benign knowledge that standard benchmarks fail\nto capture. To probe where unlearned models reveal knowledge holes, we propose\na test case generation framework that explores both immediate neighbors of\nunlearned content and broader areas of potential failures. Our evaluation\ndemonstrates significant hidden costs of unlearning: up to 98.7\\% of the test\ncases yield irrelevant or nonsensical responses from unlearned models, despite\nbeing answerable by the pretrained model. These findings necessitate rethinking\nthe conventional approach to evaluating knowledge preservation in unlearning,\nmoving beyond standard, static benchmarks.", "AI": {"tldr": "Unlearning can introduce hidden knowledge holes and standard benchmarks miss them; a test-case generation framework reveals high rates of failing cases, urging reevaluation of knowledge-preservation evaluation.", "motivation": "Aim to ensure benign knowledge isn't unintentionally erased during pre-training unlearning and to go beyond existing benchmarks.", "method": "Develop a test-case generation framework that probes immediate neighbors of unlearned content and broader failure areas; evaluate unlearning methods by generating and testing cases.", "result": "Up to 98.7% of generated test cases yield irrelevant or nonsensical responses from unlearned models, while pretrained models would answer; reveals hidden costs of unlearning.", "conclusion": "Evaluation of knowledge preservation in unlearning should move beyond static benchmarks; adopt more nuanced, failure-aware evaluation frameworks to detect hidden knowledge losses."}}
{"id": "2511.00048", "categories": ["cs.AI", "cs.CY", "62-11", "E.5; G.3; I.6.4; I.6.6; J.3; J.4"], "pdf": "https://arxiv.org/pdf/2511.00048", "abs": "https://arxiv.org/abs/2511.00048", "authors": ["Martin Bicher", "Maximilian Viehauser", "Daniele Giannandrea", "Hannah Kastinger", "Dominik Brunmeir", "Claire Rippinger", "Christoph Urach", "Niki Popper"], "title": "GEPOC Parameters - Open Source Parametrisation and Validation for Austria, Version 2.0", "comment": "134 pages, 75 figures, 19 tables", "summary": "GEPOC, short for Generic Population Concept, is a collection of models and\nmethods for analysing population-level research questions. For the valid\napplication of the models for a specific country or region, stable and\nreproducible data processes are necessary, which provide valid and ready-to-use\nmodel parameters. This work contains a complete description of the\ndata-processing methods for computation of model parameters for Austria, based\nexclusively on freely and publicly accessible data. In addition to the\ndescription of the source data used, this includes all algorithms used for\naggregation, disaggregation, fusion, cleansing or scaling of the data, as well\nas a description of the resulting parameter files. The document places\nparticular emphasis on the computation of parameters for the most important\nGEPOC model, GEPOC ABM, a continuous-time agent-based population model. An\nextensive validation study using this particular model was made and is\npresented at the end of this work.", "AI": {"tldr": "Complete, reproducible data-processing description and parameter generation for Austria in GEPOC ABM, including data sources, processing algorithms (aggregation, disaggregation, fusion, cleansing, scaling), and a substantial validation study.", "motivation": "To provide stable, reproducible data processes that yield valid model parameters for country-specific GEPOC applications, starting with Austria.", "method": "Document data sources (freely accessible), algorithms for data processing, production of parameter files, and emphasis on GEPOC ABM (continuous-time agent-based population model). Includes an extensive validation study.", "result": "Full description of data-processing methods and produced parameter files; reproducible workflow for Austria; validation results demonstrating model viability.", "conclusion": "This work enables ready-to-use parameterization for Austria within GEPOC ABM and demonstrates validity through extensive validation."}}
{"id": "2511.00028", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00028", "abs": "https://arxiv.org/abs/2511.00028", "authors": ["Hanyang Chen", "Yanchao Yang"], "title": "Mutual Information guided Visual Contrastive Learning", "comment": "Tech Report - Undergraduate Thesis - 2023", "summary": "Representation learning methods utilizing the InfoNCE loss have demonstrated\nconsiderable capacity in reducing human annotation effort by training invariant\nneural feature extractors. Although different variants of the training\nobjective adhere to the information maximization principle between the data and\nlearned features, data selection and augmentation still rely on human\nhypotheses or engineering, which may be suboptimal. For instance, data\naugmentation in contrastive learning primarily focuses on color jittering,\naiming to emulate real-world illumination changes. In this work, we investigate\nthe potential of selecting training data based on their mutual information\ncomputed from real-world distributions, which, in principle, should endow the\nlearned features with better generalization when applied in open environments.\nSpecifically, we consider patches attached to scenes that exhibit high mutual\ninformation under natural perturbations, such as color changes and motion, as\npositive samples for learning with contrastive loss. We evaluate the proposed\nmutual-information-informed data augmentation method on several benchmarks\nacross multiple state-of-the-art representation learning frameworks,\ndemonstrating its effectiveness and establishing it as a promising direction\nfor future research.", "AI": {"tldr": "Mutual-information-informed data selection for contrastive learning; uses MI under natural perturbations to pick high-value patches as positives, improving generalization in open environments.", "motivation": "Current data selection and augmentation rely on human hypotheses; leveraging real-world mutual information under perturbations could yield more robust representations for open-world deployment.", "method": "Compute mutual information for scene patches under natural perturbations (e.g., color changes, motion); select patches with high MI as positive samples for contrastive learning, evaluated across multiple SOTA frameworks and benchmarks.", "result": "Across benchmarks and frameworks, MI-informed data augmentation is effective, improving representation learning and generalization; demonstrated as a promising research direction.", "conclusion": "MI-informed data selection is a promising approach to enhance contrastive learning generalization; future work could optimize MI estimation, scale, and integration with diverse training objectives."}}
{"id": "2511.00088", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00088", "abs": "https://arxiv.org/abs/2511.00088", "authors": ["NVIDIA", ":", "Yan Wang", "Wenjie Luo", "Junjie Bai", "Yulong Cao", "Tong Che", "Ke Chen", "Yuxiao Chen", "Jenna Diamond", "Yifan Ding", "Wenhao Ding", "Liang Feng", "Greg Heinrich", "Jack Huang", "Peter Karkus", "Boyi Li", "Pinyi Li", "Tsung-Yi Lin", "Dongran Liu", "Ming-Yu Liu", "Langechuan Liu", "Zhijian Liu", "Jason Lu", "Yunxiang Mao", "Pavlo Molchanov", "Lindsey Pavao", "Zhenghao Peng", "Mike Ranzinger", "Ed Schmerling", "Shida Shen", "Yunfei Shi", "Sarah Tariq", "Ran Tian", "Tilman Wekel", "Xinshuo Weng", "Tianjun Xiao", "Eric Yang", "Xiaodong Yang", "Yurong You", "Xiaohui Zeng", "Wenyuan Zhang", "Boris Ivanovic", "Marco Pavone"], "title": "Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail", "comment": null, "summary": "End-to-end architectures trained via imitation learning have advanced\nautonomous driving by scaling model size and data, yet performance remains\nbrittle in safety-critical long-tail scenarios where supervision is sparse and\ncausal understanding is limited. To address this, we introduce Alpamayo-R1\n(AR1), a vision-language-action model (VLA) that integrates Chain of Causation\nreasoning with trajectory planning to enhance decision-making in complex\ndriving scenarios. Our approach features three key innovations: (1) the Chain\nof Causation (CoC) dataset, built through a hybrid auto-labeling and\nhuman-in-the-loop pipeline producing decision-grounded, causally linked\nreasoning traces aligned with driving behaviors; (2) a modular VLA architecture\ncombining Cosmos-Reason, a Vision-Language Model pre-trained for Physical AI\napplications, with a diffusion-based trajectory decoder that generates\ndynamically feasible plans in real time; (3) a multi-stage training strategy\nusing supervised fine-tuning to elicit reasoning and reinforcement learning\n(RL) to optimize reasoning quality via large reasoning model feedback and\nenforce reasoning-action consistency. Evaluation shows AR1 achieves up to a 12%\nimprovement in planning accuracy on challenging cases compared to a\ntrajectory-only baseline, with a 35% reduction in off-road rate and 25%\nreduction in close encounter rate in closed-loop simulation. RL post-training\nimproves reasoning quality by 45% as measured by a large reasoning model critic\nand reasoning-action consistency by 37%. Model scaling from 0.5B to 7B\nparameters shows consistent improvements. On-vehicle road tests confirm\nreal-time performance (99 ms latency) and successful urban deployment. By\nbridging interpretable reasoning with precise control, AR1 demonstrates a\npractical path towards Level 4 autonomous driving. We plan to release AR1\nmodels and a subset of the CoC in a future update.", "AI": {"tldr": "AR1 is a vision-language-action model for autonomous driving that integrates Chain of Causation reasoning with trajectory planning, yielding improved planning accuracy and safety metrics, RL-enhanced reasoning, scalable 0.5B-7B models, real-time latency, and urban Level 4 potential.", "motivation": "End-to-end imitation-learning driving systems struggle with safety-critical long-tail scenarios due to sparse supervision and limited causal understanding; a causal reasoning framework is needed to improve decision-making.", "method": "Three innovations: (1) CoC dataset via hybrid auto-labeling and human-in-the-loop producing causally linked reasoning traces aligned with driving behaviors; (2) modular VLA architecture combining Cosmos-Reason, a Vision-Language Model pre-trained for Physical AI applications, with a diffusion-based trajectory decoder for real-time, dynamically feasible plans; (3) multi-stage training: supervised fine-tuning to elicit reasoning and reinforcement learning to optimize reasoning quality via feedback from a large reasoning model and enforce reasoning-action consistency.", "result": "AR1 achieves up to 12% improvement in planning accuracy on challenging cases vs a trajectory-only baseline; 35% reduction in off-road rate; 25% reduction in close encounter rate in closed-loop simulation. RL post-training improves reasoning quality by 45% (per a large reasoning-model critic) and reasoning-action consistency by 37%. Model scaling from 0.5B to 7B parameters yields consistent improvements. On-vehicle tests show 99 ms latency and successful urban deployment.", "conclusion": "AR1 demonstrates a practical path toward Level 4 autonomous driving by bridging interpretable reasoning with precise control; plans to release AR1 models and a subset of the CoC in a future update."}}
{"id": "2511.00032", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00032", "abs": "https://arxiv.org/abs/2511.00032", "authors": ["Lei Liu", "Zhongyi Yu", "Hong Wang", "Huanshuo Dong", "Haiyang Xin", "Hongwei Zhao", "Bin Li"], "title": "From Uniform to Adaptive: General Skip-Block Mechanisms for Efficient PDE Neural Operators", "comment": null, "summary": "In recent years, Neural Operators(NO) have gradually emerged as a popular\napproach for solving Partial Differential Equations (PDEs). However, their\napplication to large-scale engineering tasks suffers from significant\ncomputational overhead. And the fact that current models impose a uniform\ncomputational cost while physical fields exhibit vastly different complexities\nconstitutes a fundamental mismatch, which is the root of this inefficiency. For\ninstance, in turbulence flows, intricate vortex regions require deeper network\nprocessing compared to stable flows. To address this, we introduce a framework:\nSkip-Block Routing (SBR), a general framework designed for Transformer-based\nneural operators, capable of being integrated into their multi-layer\narchitectures. First, SBR uses a routing mechanism to learn the complexity and\nranking of tokens, which is then applied during inference. Then, in later\nlayers, it decides how many tokens are passed forward based on this ranking.\nThis way, the model focuses more processing capacity on the tokens that are\nmore complex. Experiments demonstrate that SBR is a general framework that\nseamlessly integrates into various neural operators. Our method reduces\ncomputational cost by approximately 50% in terms of Floating Point Operations\n(FLOPs), while still delivering up to 2x faster inference without sacrificing\naccuracy.", "AI": {"tldr": "Skip-Block Routing (SBR) is a general framework for Transformer-based neural operators that learns per-token complexity and routes tokens through fewer computations in later layers, achieving ~50% FLOPs reduction and up to 2x faster inference without sacrificing accuracy.", "motivation": "Neural operators for PDEs suffer from uniform computation across regions with vastly different complexity, leading to inefficiency in large-scale engineering tasks (e.g., turbulence).", "method": "Integrates Skip-Block Routing into multi-layer Transformer-based neural operators. A routing mechanism learns token complexity ranking during training; during inference, it prunes or routes less complex tokens through fewer blocks in later layers, focusing processing on harder regions.", "result": "Shows that SBR is a general framework applicable to various neural operators, reducing FLOPs by about 50% and enabling up to 2x faster inference while maintaining accuracy.", "conclusion": "SBR offers a practical, adaptable approach to align computation with local field complexity in neural operators for PDEs, enabling more efficient large-scale PDE solvers; open questions include routing overhead, impact on very high-complexity regimes, and applicability beyond Transformer-based operators."}}
{"id": "2511.00092", "categories": ["cs.AI", "cs.CL", "cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.00092", "abs": "https://arxiv.org/abs/2511.00092", "authors": ["Shunya Minami", "Tatsuya Ishigaki", "Ikko Hamamura", "Taku Mikuriya", "Youmi Ma", "Naoaki Okazaki", "Hiroya Takamura", "Yohichi Suzuki", "Tadashi Kadowaki"], "title": "QuantumBench: A Benchmark for Quantum Problem Solving", "comment": "11 pages, 8 figures", "summary": "Large language models are now integrated into many scientific workflows,\naccelerating data analysis, hypothesis generation, and design space\nexploration. In parallel with this growth, there is a growing need to carefully\nevaluate whether models accurately capture domain-specific knowledge and\nnotation, since general-purpose benchmarks rarely reflect these requirements.\nThis gap is especially clear in quantum science, which features non-intuitive\nphenomena and requires advanced mathematics. In this study, we introduce\nQuantumBench, a benchmark for the quantum domain that systematically examine\nhow well LLMs understand and can be applied to this non-intuitive field. Using\npublicly available materials, we compiled approximately 800 questions with\ntheir answers spanning nine areas related to quantum science and organized them\ninto an eight-option multiple-choice dataset. With this benchmark, we evaluate\nseveral existing LLMs and analyze their performance in the quantum domain,\nincluding sensitivity to changes in question format. QuantumBench is the first\nLLM evaluation dataset built for the quantum domain, and it is intended to\nguide the effective use of LLMs in quantum research.", "AI": {"tldr": "Introduces QuantumBench, a quantum-domain benchmark for LLMs with ~800 eight-option MCQ items across nine areas to evaluate understanding and application; first such dataset in quantum science.", "motivation": "There is a gap where general-purpose benchmarks do not reflect domain-specific knowledge and notation required in quantum science, risking misjudgment of an LLM's true capabilities in handling non-intuitive phenomena and advanced mathematics.", "method": "Assembled ~800 questions with answers from publicly available quantum science materials, spanning nine areas, organized into an eight-option MCQ format. Evaluated several existing LLMs and analyzed sensitivity to changes in question format.", "result": "Initial evaluations show model performance varies across LLMs and is influenced by question format, demonstrating both strengths and gaps in current models for quantum-domain tasks. QuantumBench provides a quantitative benchmark for assessing LLM use in quantum research.", "conclusion": "QuantumBench is the first LLM evaluation dataset tailored to the quantum domain, intended to guide the effective use and deployment of LLMs in quantum research."}}
{"id": "2511.00037", "categories": ["cs.CV", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.00037", "abs": "https://arxiv.org/abs/2511.00037", "authors": ["Riya Gupta", "Alexander Chowdhury", "Sahil Nalawade"], "title": "Benchmarking Federated Learning Frameworks for Medical Imaging Deployment: A Comparative Study of NVIDIA FLARE, Flower, and Owkin Substra", "comment": null, "summary": "Federated Learning (FL) has emerged as a transformative paradigm in medical\nAI, enabling collaborative model training across institutions without direct\ndata sharing. This study benchmarks three prominent FL frameworks NVIDIA FLARE,\nFlower, and Owkin Substra to evaluate their suitability for medical imaging\napplications in real-world settings. Using the PathMNIST dataset, we assess\nmodel performance, convergence efficiency, communication overhead, scalability,\nand developer experience. Results indicate that NVIDIA FLARE offers superior\nproduction scalability, Flower provides flexibility for prototyping and\nacademic research, and Owkin Substra demonstrates exceptional privacy and\ncompliance features. Each framework exhibits strengths optimized for distinct\nuse cases, emphasizing their relevance to practical deployment in healthcare\nenvironments.", "AI": {"tldr": "A comparative study benchmarks NVIDIA FLARE, Flower, and Owkin Substra for federated learning in medical imaging using PathMNIST, assessing performance, convergence, communication, scalability, and developer experience. It concludes each framework excels in different use-cases: FLARE for production scalability, Flower for prototyping/academia, and Substra for privacy/compliance.", "motivation": "To understand how leading federated learning frameworks perform in realistic medical imaging deployment, balancing model quality, training efficiency, operational overhead, and regulatory/privacy considerations across institutions.", "method": "Benchmark three FL frameworks (NVIDIA FLARE, Flower, Owkin Substra) on the PathMNIST dataset, evaluating model performance, convergence speed, communication overhead, scalability, and developer experience to reflect real-world healthcare deployments.", "result": "NVIDIA FLARE shows superior production scalability; Flower offers flexibility for prototyping/academic research; Owkin Substra emphasizes privacy and compliance. Each framework demonstrates strengths aligned with specific use-case requirements.", "conclusion": "The choice of FL framework should be guided by the deployment context in healthcare: production-scale deployments may favor FLARE, exploratory and academic work may prefer Flower, and privacy/compliance-centric settings may opt for Owkin Substra. Overall, the study highlights that different ecosystems cater to distinct practical deployment needs in healthcare."}}
{"id": "2511.00094", "categories": ["cs.RO", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00094", "abs": "https://arxiv.org/abs/2511.00094", "authors": ["Angelos Alexopoulos", "Agorakis Bompotas", "Nikitas Rigas Kalogeropoulos", "Panagiotis Kechagias", "Athanasios P. Kalogeras", "Christos Alexakos"], "title": "Digital Twin based Automatic Reconfiguration of Robotic Systems in Smart Environments", "comment": "Accepted for presentation to 11th IEEE International Smart Cities\n  Conference (ISC2 2025)", "summary": "Robotic systems have become integral to smart environments, enabling\napplications ranging from urban surveillance and automated agriculture to\nindustrial automation. However, their effective operation in dynamic settings -\nsuch as smart cities and precision farming - is challenged by continuously\nevolving topographies and environmental conditions. Traditional control systems\noften struggle to adapt quickly, leading to inefficiencies or operational\nfailures. To address this limitation, we propose a novel framework for\nautonomous and dynamic reconfiguration of robotic controllers using Digital\nTwin technology. Our approach leverages a virtual replica of the robot's\noperational environment to simulate and optimize movement trajectories in\nresponse to real-world changes. By recalculating paths and control parameters\nin the Digital Twin and deploying the updated code to the physical robot, our\nmethod ensures rapid and reliable adaptation without manual intervention. This\nwork advances the integration of Digital Twins in robotics, offering a scalable\nsolution for enhancing autonomy in smart, dynamic environments.", "AI": {"tldr": "A Digital Twin\u2013based framework for autonomous, dynamic reconfiguration of robotic controllers to adapt to changing environments, enabling rapid, automated updates to robot behavior without manual intervention.", "motivation": "Dynamic and evolving real-world topographies in smart cities and precision farming challenge traditional controllers, leading to inefficiencies or failures; there is a need for fast, automated adaptation in robotic systems.", "method": "Develop a Digital Twin (virtual replica) of the robot and its environment to simulate and optimize movement trajectories, recalculate paths and control parameters within the Twin, and deploy updated code to the physical robot to realize changes.", "result": "Expected benefits include rapid, reliable adaptation to environmental changes without manual reconfiguration, improved autonomy in dynamic environments, and a scalable path to integrating Digital Twins in robotic control systems.", "conclusion": "The work advances the integration of Digital Twins in robotics, offering a scalable solution for enhancing autonomy in smart, dynamic environments."}}
{"id": "2511.00035", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00035", "abs": "https://arxiv.org/abs/2511.00035", "authors": ["Georg Velev", "Stefan Lessmann"], "title": "Neural Architecture Search for global multi-step Forecasting of Energy Production Time Series", "comment": null, "summary": "The dynamic energy sector requires both predictive accuracy and runtime\nefficiency for short-term forecasting of energy generation under operational\nconstraints, where timely and precise predictions are crucial. The manual\nconfiguration of complex methods, which can generate accurate global multi-step\npredictions without suffering from a computational bottleneck, represents a\nprocedure with significant time requirements and high risk for human-made\nerrors. A further intricacy arises from the temporal dynamics present in\nenergy-related data. Additionally, the generalization to unseen data is\nimperative for continuously deploying forecasting techniques over time. To\novercome these challenges, in this research, we design a neural architecture\nsearch (NAS)-based framework for the automated discovery of time series models\nthat strike a balance between computational efficiency, predictive performance,\nand generalization power for the global, multi-step short-term forecasting of\nenergy production time series. In particular, we introduce a search space\nconsisting only of efficient components, which can capture distinctive patterns\nof energy time series. Furthermore, we formulate a novel objective function\nthat accounts for performance generalization in temporal context and the\nmaximal exploration of different regions of our high-dimensional search space.\nThe results obtained on energy production time series show that an ensemble of\nlightweight architectures discovered with NAS outperforms state-of-the-art\ntechniques, such as Transformers, as well as pre-trained forecasting models, in\nterms of both efficiency and accuracy.", "AI": {"tldr": "An NAS-based framework automatically discovers efficient, generalizable multi-step time-series models for energy forecasting, yielding an ensemble of lightweight architectures that surpass Transformers and pre-trained models in both speed and accuracy.", "motivation": "Address the need for accurate, fast short-term energy forecasts under operational constraints while ensuring generalization to unseen data and reducing manual model design effort.", "method": "Design a NAS search space limited to efficient components suited to energy time series, propose a temporal-generalization-focused objective to explore diverse regions of the high-dimensional space, and assemble an ensemble of the discovered lightweight architectures for global multi-step forecasting.", "result": "An ensemble of lightweight NAS-discovered architectures outperforms state-of-the-art techniques (including Transformers and pre-trained forecasting models) in both efficiency and accuracy on energy production time series.", "conclusion": "NAS-driven automated discovery can deliver accurate, efficient, and generalizable global multi-step forecasts for energy data, reducing manual design work and enabling scalable deployment."}}
{"id": "2511.00122", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00122", "abs": "https://arxiv.org/abs/2511.00122", "authors": ["Ran Xu", "Yupeng Qi", "Jingsen Feng", "Xu Chu"], "title": "Engineering.ai: A Platform for Teams of AI Engineers in Computational Design", "comment": null, "summary": "In modern engineering practice, human engineers collaborate in specialized\nteams to design complex products, with each expert completing their respective\ntasks while communicating and exchanging results and data with one another.\nWhile this division of expertise is essential for managing multidisciplinary\ncomplexity, it demands substantial development time and cost. Recently, we\nintroduced OpenFOAMGPT (1.0, 2.0), which functions as an autonomous AI engineer\nfor computational fluid dynamics, and turbulence.ai, which can conduct\nend-to-end research in fluid mechanics draft publications and PhD theses.\nBuilding upon these foundations, we present Engineering.ai, a platform for\nteams of AI engineers in computational design. The framework employs a\nhierarchical multi-agent architecture where a Chief Engineer coordinates\nspecialized agents consisting of Aerodynamics, Structural, Acoustic, and\nOptimization Engineers, each powered by LLM with domain-specific knowledge.\nAgent-agent collaboration is achieved through file-mediated communication for\ndata provenance and reproducibility, while a comprehensive memory system\nmaintains project context, execution history, and retrieval-augmented domain\nknowledge to ensure reliable decision-making across the workflow. The system\nintegrates FreeCAD, Gmsh, OpenFOAM, CalculiX, and BPM acoustic analysis,\nenabling parallel multidisciplinary simulations while maintaining computational\naccuracy. The framework is validated through UAV wing optimization. This work\ndemonstrates that agentic-AI-enabled AI engineers has the potential to perform\ncomplex engineering tasks autonomously. Remarkably, the automated workflow\nachieved a 100% success rate across over 400 parametric configurations, with\nzero mesh generation failures, solver convergence issues, or manual\ninterventions required, validating that the framework is trustworthy.", "AI": {"tldr": "Engineering.ai proposes a hierarchical multi-agent AI design platform that orchestrates domain-specific AI engineers to autonomously handle multidisciplinary CFD/structure/acoustic optimization tasks, with strong provenance and automated workflows, validated on UAV wing optimization.", "motivation": "Address the high time and cost of multidisciplinary engineering design by enabling autonomous, reproducible AI-driven collaboration among experts and ensuring data provenance.", "method": "A Chief Engineer coordinates specialized agents (Aerodynamics, Structural, Acoustic, Optimization) driven by domain-aware LLMs; file-mediated communication; memory system; integration of FreeCAD, Gmsh, OpenFOAM, CalculiX, BPM acoustic analysis; parallel simulations and retrieval-augmented knowledge for robust decision-making.", "result": "The framework achieved a 100% success rate across over 400 parametric configurations with zero mesh-generation failures, solver convergence issues, or manual interventions.", "conclusion": "Agentic-AI-enabled AI engineers can autonomously perform complex multidisciplinary engineering tasks; the framework demonstrates trustworthiness, reproducibility, and scalability for design workflows."}}
{"id": "2511.00046", "categories": ["cs.CV", "68U10, 94A08", "I.4.3; I.4.4; I.5.1; J.3"], "pdf": "https://arxiv.org/pdf/2511.00046", "abs": "https://arxiv.org/abs/2511.00046", "authors": ["Rupjyoti Chutia", "Dibya Jyoti Bora"], "title": "Enhancing rice leaf images: An overview of image denoising techniques", "comment": "18 pages, 6 figures. Research Article published in the International\n  Journal of Agricultural and Natural Sciences (IJANS), Vol. 18, Issue 2, 2025.\n  This paper presents a comparative study of image denoising and CLAHE\n  techniques for enhancing rice leaf images corrupted by Gaussian,\n  Salt-and-pepper, Speckle, and Random noise for agricultural analysis", "summary": "Digital image processing involves the systematic handling of images using\nadvanced computer algorithms, and has gained significant attention in both\nacademic and practical fields. Image enhancement is a crucial preprocessing\nstage in the image-processing chain, improving image quality and emphasizing\nfeatures. This makes subsequent tasks (segmentation, feature extraction,\nclassification) more reliable. Image enhancement is essential for rice leaf\nanalysis, aiding in disease detection, nutrient deficiency evaluation, and\ngrowth analysis. Denoising followed by contrast enhancement are the primary\nsteps. Image filters, generally employed for denoising, transform or enhance\nvisual characteristics like brightness, contrast, and sharpness, playing a\ncrucial role in improving overall image quality and enabling the extraction of\nuseful information. This work provides an extensive comparative study of\nwell-known image-denoising methods combined with CLAHE (Contrast Limited\nAdaptive Histogram Equalization) for efficient denoising of rice leaf images.\nThe experiments were performed on a rice leaf image dataset to ensure the data\nis relevant and representative. Results were examined using various metrics to\ncomprehensively test enhancement methods. This approach provides a strong basis\nfor assessing the effectiveness of methodologies in digital image processing\nand reveals insights useful for future adaptation in agricultural research and\nother domains.", "AI": {"tldr": "A comparative study of denoising methods combined with CLAHE for rice-leaf image enhancement, evaluating how denoising plus contrast enhancement affects image quality for downstream analysis.", "motivation": "Improve rice leaf analysis (disease/detection, nutrient assessment, growth) by reliable preprocessing that enhances quality for segmentation, feature extraction, and classification.", "method": "Apply several well-known denoising filters (e.g., Gaussian, median, bilateral, non-local means, wavelet-based approaches) in combination with CLAHE on a rice-leaf image dataset; assess using multiple quantitative metrics (PSNR, SSIM, contrast measures) to evaluate enhancement quality and potential impact on downstream tasks.", "result": "Certain denoising+CLAHE combinations yield superior results across metrics, indicating favorable preservation of details while boosting contrast; findings are dataset-specific but provide a robust baseline for agricultural image processing.", "conclusion": "Denoising followed by CLAHE is an effective baseline for rice-leaf image enhancement, offering practical guidance for agricultural research and a foundation for future adaptations to related domains."}}
{"id": "2511.00112", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00112", "abs": "https://arxiv.org/abs/2511.00112", "authors": ["Yanbing Mao", "Yihao Cai", "Lui Sha"], "title": "Real-DRL: Teach and Learn in Reality", "comment": "37 pages", "summary": "This paper introduces the Real-DRL framework for safety-critical autonomous\nsystems, enabling runtime learning of a deep reinforcement learning (DRL) agent\nto develop safe and high-performance action policies in real plants (i.e., real\nphysical systems to be controlled), while prioritizing safety! The Real-DRL\nconsists of three interactive components: a DRL-Student, a PHY-Teacher, and a\nTrigger. The DRL-Student is a DRL agent that innovates in the dual\nself-learning and teaching-to-learn paradigm and the real-time safety-informed\nbatch sampling. On the other hand, PHY-Teacher is a physics-model-based design\nof action policies that focuses solely on safety-critical functions.\nPHY-Teacher is novel in its real-time patch for two key missions: i) fostering\nthe teaching-to-learn paradigm for DRL-Student and ii) backing up the safety of\nreal plants. The Trigger manages the interaction between the DRL-Student and\nthe PHY-Teacher. Powered by the three interactive components, the Real-DRL can\neffectively address safety challenges that arise from the unknown unknowns and\nthe Sim2Real gap. Additionally, Real-DRL notably features i) assured safety,\nii) automatic hierarchy learning (i.e., safety-first learning and then\nhigh-performance learning), and iii) safety-informed batch sampling to address\nthe learning experience imbalance caused by corner cases. Experiments with a\nreal quadruped robot, a quadruped robot in NVIDIA Isaac Gym, and a cart-pole\nsystem, along with comparisons and ablation studies, demonstrate the Real-DRL's\neffectiveness and unique features.", "AI": {"tldr": "Real-DRL introduces a safety-focused DRL framework for real-world autonomous systems, coupling a learning agent (DRL-Student) with a physics-based safety teacher (PHY-Teacher) under a Trigger to safely and effectively learn in real plants, addressing unknown threats and sim-to-real gaps; proven on a real quadruped, Isaac Gym quad, and cart-pole with ablations.", "motivation": "Safety-critical autonomous systems need safe, data-efficient learning in real environments. Unknown unknowns and the Sim2Real gap pose major risks. The paper seeks to enable real-world DRL that guarantees safety while achieving high performance.", "method": "An architecture with three components: DRL-Student (dual self-learning and teaching-to-learn with safety-informed batch sampling), PHY-Teacher (physics-model-based safety-focused action policies delivering real-time safety patches and supporting teaching-to-learn), and Trigger (orchestrates interaction between student and teacher). The approach emphasizes safety-first learning, automatic hierarchy learning (safety before performance), and batch-sampling strategies to handle corner-case imbalance.", "result": "Empirical validation across a real quadruped, a quadruped in NVIDIA Isaac Gym, and a cart-pole, including comparisons and ablations. Results indicate assured safety, effective hierarchy learning, and improved handling of corner-case learning through safety-informed sampling, demonstrating Real-DRL\u2019s effectiveness and unique advantages.", "conclusion": "Real-DRL provides a practical, safety-oriented DRL framework for real plants, mitigating unknown unknowns and Sim2Real challenges. Its three-component design yields safety guarantees, automatic learning hierarchy, and data-efficient training, with strong empirical validation across multiple platforms."}}
{"id": "2511.00040", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00040", "abs": "https://arxiv.org/abs/2511.00040", "authors": ["Seonggyun Lee", "Sungjun Lim", "Seojin Park", "Soeun Cheon", "Kyungwoo Song"], "title": "Semi-Supervised Preference Optimization with Limited Feedback", "comment": null, "summary": "The field of preference optimization has made outstanding contributions to\nthe alignment of language models with human preferences. Despite these\nadvancements, recent methods still rely heavily on substantial paired (labeled)\nfeedback data, leading to substantial resource expenditures. To address these\nchallenges, we study the problem of Semi-Supervised Preference Optimization\n(SSPO) in which the idea is to learn from both a small number of pairwise\npreference labels and a large pool of unpaired samples simultaneously. Our key\ntheoretical contribution proves the existence of an optimal reward threshold\ncapable of separating winning and losing responses with high probability, which\nenables a principled pseudo-labeling of unpaired data. By leveraging these\npseudo-labels, SSPO effectively distills latent preferences from large-scale\nunpaired data, thus maintaining human alignment while drastically reducing\nacquisition costs. Extensive experiments across datasets validate this\nremarkable data efficiency; for instance, SSPO trained with Llama3-8B-Instruct\non just 1% of UltraFeedback consistently surpasses strong baselines trained on\n10% of UltraFeedback.", "AI": {"tldr": "Semi-Supervised Preference Optimization (SSPO) learns from a small set of labeled pairwise preferences and a large pool of unpaired data by pseudo-labeling using a provable reward-threshold; it achieves strong data efficiency, matching or surpassing baselines with far less labeled data.", "motivation": "Reduce reliance on expensive labeled feedback in preference optimization for language models by leveraging large-scale unpaired data.", "method": "Proves existence of an optimal reward threshold that separates winning and losing responses with high probability; uses this to pseudo-label unpaired data; trains using both labeled and pseudo-labeled data to distill latent preferences; evaluates on Llama3-8B-Instruct with ultra feedback datasets.", "result": "SSPO with only 1% UltraFeedback outperforms baselines trained on 10% UltraFeedback, demonstrating substantial data-efficiency gains across datasets.", "conclusion": "Semi-supervised preference optimization can retain human alignment while greatly reducing annotation costs through principled pseudo-labeling and pseudo-label-based distillation."}}
{"id": "2511.00162", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00162", "abs": "https://arxiv.org/abs/2511.00162", "authors": ["Michael D. Moffitt"], "title": "ARC-GEN: A Mimetic Procedural Benchmark Generator for the Abstraction and Reasoning Corpus", "comment": null, "summary": "The Abstraction and Reasoning Corpus remains one of the most compelling and\nchallenging benchmarks for tracking progress toward achieving Artificial\nGeneral Intelligence. In contrast to other evaluation datasets designed to\nassess an agent's task-specific skills or accumulated knowledge, the ARC-AGI\nsuite is specifically targeted at measuring skill acquisition efficiency, a\ntrait that has (so far) been lacking in even the most sophisticated machine\nlearning systems. For algorithms that require extensive intra-task exemplars, a\nsignificant constraint imposed by ARC-AGI is the modest cardinality of its\ndemonstration set, comprising a small number of $\\langle$ input, output\n$\\rangle$ grids per task specifying the corresponding transformation. To\nembellish the space of viable sample pairs, this paper introduces ARC-GEN, an\nopen-source procedural generator aimed at extending the original ARC-AGI\ntraining dataset as faithfully as possible. Unlike prior efforts, our generator\nis both exhaustive (covering all four-hundred tasks) and mimetic (more closely\nhonoring the distributional properties and characteristics embodied in the\ninitial ARC-AGI-1 release). We also discuss the use of this generator in\nestablishing a static benchmark suite to verify the correctness of programs\nsubmitted to the 2025 Google Code Golf Championship.", "AI": {"tldr": "ARC-GEN is an open-source procedural generator that exhaustively and faithfully expands the ARC-AGI training set to cover all 400 tasks, enabling a mimetic, richer benchmark of skill acquisition efficiency and providing a static benchmark for Code Golf 2025 submissions.", "motivation": "ARC-AGI focuses on measuring skill acquisition efficiency with a small demonstration set, highlighting a gap in evaluating how quickly agents learn from limited examples. ARC-GEN aims to enlarge the training/benchmark space while preserving ARC-AGI\u2019s distributional characteristics.", "method": "Develop an open-source procedural generator (ARC-GEN) that exhaustively generates input-output grid pairs for all ARC-AGI tasks and mimics the original dataset's distributional properties. This extended dataset can be used to form a static benchmark suite.", "result": "ARC-GEN is described as exhaustive (covering all 400 tasks) and mimetic (closely matching ARC-AGI distributions). It enables the creation of a static benchmark suite for verifying code challenge submissions (e.g., Google Code Golf Championship 2025).", "conclusion": "ARC-GEN provides a faithful, exhaustive expansion of ARC-AGI that can standardize and stress-test program correctness and skill acquisition benchmarking, supporting progress toward AI generalization benchmarks."}}
{"id": "2511.00060", "categories": ["cs.CV", "cs.RO", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.00060", "abs": "https://arxiv.org/abs/2511.00060", "authors": ["Zhiqi Qi", "Runxin Zhao", "Hanyang Zhuang", "Chunxiang Wang", "Ming Yang"], "title": "Which LiDAR scanning pattern is better for roadside perception: Repetitive or Non-repetitive?", "comment": null, "summary": "LiDAR-based roadside perception is a cornerstone of advanced Intelligent\nTransportation Systems (ITS). While considerable research has addressed optimal\nLiDAR placement for infrastructure, the profound impact of differing LiDAR\nscanning patterns on perceptual performance remains comparatively\nunder-investigated. The inherent nature of various scanning modes - such as\ntraditional repetitive (mechanical/solid-state) versus emerging non-repetitive\n(e.g. prism-based) systems - leads to distinct point cloud distributions at\nvarying distances, critically dictating the efficacy of object detection and\noverall environmental understanding. To systematically investigate these\ndifferences in infrastructure-based contexts, we introduce the \"InfraLiDARs'\nBenchmark,\" a novel dataset meticulously collected in the CARLA simulation\nenvironment using concurrently operating infrastructure-based LiDARs exhibiting\nboth scanning paradigms. Leveraging this benchmark, we conduct a comprehensive\nstatistical analysis of the respective LiDAR scanning abilities and evaluate\nthe impact of these distinct patterns on the performance of various leading 3D\nobject detection algorithms. Our findings reveal that non-repetitive scanning\nLiDAR and the 128-line repetitive LiDAR were found to exhibit comparable\ndetection performance across various scenarios. Despite non-repetitive LiDAR's\nlimited perception range, it's a cost-effective option considering its low\nprice. Ultimately, this study provides insights for setting up roadside\nperception system with optimal LiDAR scanning patterns and compatible\nalgorithms for diverse roadside applications, and publicly releases the\n\"InfraLiDARs' Benchmark\" dataset to foster further research.", "AI": {"tldr": "InfraLiDARs' Benchmark in CARLA compares non-repetitive (prism-based) and 128-line repetitive LiDARs for roadside perception, finding comparable detection performance despite range differences, and highlights cost-effective options; dataset released for further research.", "motivation": "Roadside LiDAR scanning patterns can critically affect perception quality, yet most work focuses on placement or individual sensors. Understanding how scanning paradigms influence detection performance is essential for cost-efficient, robust ITS deployments.", "method": "The authors create InfraLiDARs' Benchmark in the CARLA simulator with concurrently operating infrastructure-based LiDARs representing both scanning paradigms. They perform a statistical analysis of scanning distributions and evaluate multiple leading 3D object detection algorithms on the benchmark data.", "result": "Non-repetitive scanning LiDAR and 128-line repetitive LiDAR achieve comparable detection performance across diverse scenarios. The non-repetitive system has a shorter perception range but is cheaper, offering a favorable cost-performance trade-off.", "conclusion": "The study offers practical guidance for configuring roadside perception systems with appropriate scanning patterns and compatible algorithms, and publicly releases the InfraLiDARs' Benchmark dataset to spur further research."}}
{"id": "2511.00139", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00139", "abs": "https://arxiv.org/abs/2511.00139", "authors": ["Yu Cui", "Yujian Zhang", "Lina Tao", "Yang Li", "Xinyu Yi", "Zhibin Li"], "title": "End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection", "comment": null, "summary": "Achieving human-like dexterous manipulation remains a major challenge for\ngeneral-purpose robots. While Vision-Language-Action (VLA) models show\npotential in learning skills from demonstrations, their scalability is limited\nby scarce high-quality training data. Existing data collection methods face\ninherent constraints: manual teleoperation overloads human operators, while\nautomated planning often produces unnatural motions. We propose a Shared\nAutonomy framework that divides control between macro and micro motions. A\nhuman operator guides the robot's arm pose through intuitive VR teleoperation,\nwhile an autonomous DexGrasp-VLA policy handles fine-grained hand control using\nreal-time tactile and visual feedback. This division significantly reduces\ncognitive load and enables efficient collection of high-quality coordinated\narm-hand demonstrations. Using this data, we train an end-to-end VLA policy\nenhanced with our novel Arm-Hand Feature Enhancement module, which captures\nboth distinct and shared representations of macro and micro movements for more\nnatural coordination. Our Corrective Teleoperation system enables continuous\npolicy improvement through human-in-the-loop failure recovery. Experiments\ndemonstrate that our framework generates high-quality data with minimal\nmanpower and achieves a 90% success rate across diverse objects, including\nunseen instances. Comprehensive evaluations validate the system's effectiveness\nin developing dexterous manipulation capabilities.", "AI": {"tldr": "Shared Autonomy with macro-micro control separation enables high-quality dexterous manipulation data collection and a robust VLA policy, achieving 90% success on unseen objects.", "motivation": "Dexterous manipulation remains challenging; VLA models require abundant high-quality data, but data collection is bottlenecked by human workload (teleoperation) and nonnatural automated planning.", "method": "Divide control into macro-motion guidance via VR teleoperation and micro-hand control handled by an autonomous DexGrasp-VLA policy using real-time tactile/visual feedback. Introduce Arm-Hand Feature Enhancement to capture both macro and micro representations. Include Corrective Teleoperation for human-in-the-loop failure recovery; train end-to-end VLA policy on collected demonstrations.", "result": "Ability to generate high-quality data with minimal manpower and achieve ~90% success across diverse and unseen objects; comprehensive experimental validation of dexterous manipulation performance.", "conclusion": "Shared autonomy plus enhanced VLA policy enables scalable data collection and effective dexterous manipulation; corrective teleoperation supports continuous policy improvement and recovery."}}
{"id": "2511.00043", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00043", "abs": "https://arxiv.org/abs/2511.00043", "authors": ["Tyrus Whitman", "Andrew Particka", "Christopher Diers", "Ian Griffin", "Charuka Wickramasinghe", "Pradeep Ranaweera"], "title": "Physics-Informed Neural Network Frameworks for the Analysis of Engineering and Biological Dynamical Systems Governed by Ordinary Differential Equations", "comment": "21 pages, 10 figures, 5 tables", "summary": "In this study, we present and validate the predictive capability of the\nPhysics-Informed Neural Networks (PINNs) methodology for solving a variety of\nengineering and biological dynamical systems governed by ordinary differential\nequations (ODEs). While traditional numerical methods a re effective for many\nODEs, they often struggle to achieve convergence in problems involving high\nstiffness, shocks, irregular domains, singular perturbations, high dimensions,\nor boundary discontinuities. Alternatively, PINNs offer a powerful approach for\nhandling challenging numerical scenarios. In this study, classical ODE problems\nare employed as controlled testbeds to systematically evaluate the accuracy,\ntraining efficiency, and generalization capability under controlled conditions\nof the PINNs framework. Although not a universal solution, PINNs can achieve\nsuperior results by embedding physical laws directly into the learning process.\nWe first analyze the existence and uniqueness properties of several benchmark\nproblems and subsequently validate the PINNs methodology on these model\nsystems. Our results demonstrate that for complex problems to converge to\ncorrect solutions, the loss function components data loss, initial condition\nloss, and residual loss must be appropriately balanced through careful\nweighting. We further establish that systematic tuning of hyperparameters,\nincluding network depth, layer width, activation functions, learning rate,\noptimization algorithms, w eight initialization schemes, and collocation point\nsampling, plays a crucial role in achieving accurate solutions. Additionally,\nembedding prior knowledge and imposing hard constraints on the network\narchitecture, without loss the generality of the ODE system, significantly\nenhances the predictive capability of PINNs.", "AI": {"tldr": "PINNs show promise for solving ODEs in challenging engineering/biology problems, outperforming traditional solvers when loss components are balanced and hyperparameters are tuned; embedding prior physical knowledge and hard constraints enhances predictive capability, though results depend on controlled training settings.", "motivation": "Address limitations of traditional ODE solvers (e.g., stiffness, shocks, irregular domains, high dimensions) by leveraging Physics-Informed Neural Networks to improve convergence, accuracy, and generalization in solving ODEs.", "method": "Use classical ODE benchmark problems to evaluate PINNs: analyze existence/uniqueness, train PINNs, and systematically study how data loss, initial-condition loss, and residual loss balance\u2014via weighting\u2014affects convergence. Conduct systematic hyperparameter tuning (depth, width, activation, learning rate, optimizers, weight initialization, collocation sampling) and test the impact of embedding prior knowledge and hard architectural constraints without restricting ODE generality.", "result": "Findings indicate PINNs can yield superior results for complex problems when the loss components are properly balanced and hyperparameters are tuned. Systematic tuning and architectural constraints, along with embedding prior knowledge, significantly improve predictive accuracy and capability on benchmark ODE problems.", "conclusion": "PINNs are not a universal solution but are highly effective for complex ODE systems when carefully configured. Proper loss balancing and integration of prior physical information or hard constraints substantially boost predictive performance on controlled benchmarks."}}
{"id": "2511.00194", "categories": ["cs.AI", "F.2.2, F.4.1"], "pdf": "https://arxiv.org/pdf/2511.00194", "abs": "https://arxiv.org/abs/2511.00194", "authors": ["Jovial Cheukam Ngouonou", "Ramiz Gindullin", "Claude-Guy Quimper", "Nicolas Beldiceanu", "Remi Douence"], "title": "Incremental Selection of Most-Filtering Conjectures and Proofs of the Selected Conjectures", "comment": null, "summary": "We present an improved incremental selection algorithm of the selection\nalgorithm presented in [1] and prove all the selected conjectures.", "AI": {"tldr": "An improved incremental version of a known selection algorithm is presented, with a complete proof of the conjectures associated with the original work.", "motivation": "To advance the theory and practical efficiency of incremental selection by refining the prior algorithm and resolving open conjectures that accompany it.", "method": "Builds an enhanced incremental selection algorithm on top of the earlier algorithm cited as [1], and provides formal proofs for the conjectures claimed in the original work, likely using rigorous algorithmic and/or complexity analyses.", "result": "Offers improved algorithmic approach and establishes correctness and associated conjecture proofs; clarifies theoretical guarantees and potential performance benefits over the prior method.", "conclusion": "Strengthens the theoretical foundation of incremental selection, validating the conjectures from [1], and sets the stage for practical implementations and further improvements."}}
{"id": "2511.00062", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00062", "abs": "https://arxiv.org/abs/2511.00062", "authors": ["NVIDIA", ":", "Arslan Ali", "Junjie Bai", "Maciej Bala", "Yogesh Balaji", "Aaron Blakeman", "Tiffany Cai", "Jiaxin Cao", "Tianshi Cao", "Elizabeth Cha", "Yu-Wei Chao", "Prithvijit Chattopadhyay", "Mike Chen", "Yongxin Chen", "Yu Chen", "Shuai Cheng", "Yin Cui", "Jenna Diamond", "Yifan Ding", "Jiaojiao Fan", "Linxi Fan", "Liang Feng", "Francesco Ferroni", "Sanja Fidler", "Xiao Fu", "Ruiyuan Gao", "Yunhao Ge", "Jinwei Gu", "Aryaman Gupta", "Siddharth Gururani", "Imad El Hanafi", "Ali Hassani", "Zekun Hao", "Jacob Huffman", "Joel Jang", "Pooya Jannaty", "Jan Kautz", "Grace Lam", "Xuan Li", "Zhaoshuo Li", "Maosheng Liao", "Chen-Hsuan Lin", "Tsung-Yi Lin", "Yen-Chen Lin", "Huan Ling", "Ming-Yu Liu", "Xian Liu", "Yifan Lu", "Alice Luo", "Qianli Ma", "Hanzi Mao", "Kaichun Mo", "Seungjun Nah", "Yashraj Narang", "Abhijeet Panaskar", "Lindsey Pavao", "Trung Pham", "Morteza Ramezanali", "Fitsum Reda", "Scott Reed", "Xuanchi Ren", "Haonan Shao", "Yue Shen", "Stella Shi", "Shuran Song", "Bartosz Stefaniak", "Shangkun Sun", "Shitao Tang", "Sameena Tasmeen", "Lyne Tchapmi", "Wei-Cheng Tseng", "Jibin Varghese", "Andrew Z. Wang", "Hao Wang", "Haoxiang Wang", "Heng Wang", "Ting-Chun Wang", "Fangyin Wei", "Jiashu Xu", "Dinghao Yang", "Xiaodong Yang", "Haotian Ye", "Seonghyeon Ye", "Xiaohui Zeng", "Jing Zhang", "Qinsheng Zhang", "Kaiwen Zheng", "Andrew Zhu", "Yuke Zhu"], "title": "World Simulation with Video Foundation Models for Physical AI", "comment": null, "summary": "We introduce [Cosmos-Predict2.5], the latest generation of the Cosmos World\nFoundation Models for Physical AI. Built on a flow-based architecture,\n[Cosmos-Predict2.5] unifies Text2World, Image2World, and Video2World generation\nin a single model and leverages [Cosmos-Reason1], a Physical AI vision-language\nmodel, to provide richer text grounding and finer control of world simulation.\nTrained on 200M curated video clips and refined with reinforcement\nlearning-based post-training, [Cosmos-Predict2.5] achieves substantial\nimprovements over [Cosmos-Predict1] in video quality and instruction alignment,\nwith models released at 2B and 14B scales. These capabilities enable more\nreliable synthetic data generation, policy evaluation, and closed-loop\nsimulation for robotics and autonomous systems. We further extend the family\nwith [Cosmos-Transfer2.5], a control-net style framework for Sim2Real and\nReal2Real world translation. Despite being 3.5$\\times$ smaller than\n[Cosmos-Transfer1], it delivers higher fidelity and robust long-horizon video\ngeneration. Together, these advances establish [Cosmos-Predict2.5] and\n[Cosmos-Transfer2.5] as versatile tools for scaling embodied intelligence. To\naccelerate research and deployment in Physical AI, we release source code,\npretrained checkpoints, and curated benchmarks under the NVIDIA Open Model\nLicense at https://github.com/nvidia-cosmos/cosmos-predict2.5 and\nhttps://github.com/nvidia-cosmos/cosmos-transfer2.5. We hope these open\nresources lower the barrier to adoption and foster innovation in building the\nnext generation of embodied intelligence.", "AI": {"tldr": "A unified, flow-based embodied AI stack (Cosmos-Predict2.5) with stronger grounding and RL fine-tuning, plus a smaller, high-fidelity Cosmos-Transfer2.5 for Sim2Real/Real2Real, all open-sourced to advance embodied intelligence.", "motivation": "Need to unify Text2World, Image2World, and Video2World generation with reliable grounding and control, enabling synthetic data, policy evaluation, and closed-loop simulation for robotics/autonomy; lower barriers to adoption.", "method": "Proposes a flow-based architecture unifying multiple world-generation modalities; leverages Cosmos-Reason1 vision-language grounding for_Text/ground; trained on 200M curated video clips; reinforced-learning-based post-training; released models at 2B and 14B scales; introduces Cosmos-Transfer2.5 as a control-net style framework for Sim2Real/Real2Real.", "result": "Cosmos-Predict2.5 shows substantial improvements over Cosmos-Predict1 in video quality and instruction alignment; opensource release under NVIDIA Open Model License; Cosmos-Transfer2.5 achieves higher fidelity and robust long-horizon video generation despite being 3.5x smaller than Cosmos-Transfer1.", "conclusion": "Positions Cosmos-Predict2.5 and Cosmos-Transfer2.5 as versatile, scalable tools for embodied intelligence, enabling better synthetic data, policy evaluation, and real-world translation; aims to accelerate research and deployment."}}
{"id": "2511.00153", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00153", "abs": "https://arxiv.org/abs/2511.00153", "authors": ["Justin Yu", "Yide Shentu", "Di Wu", "Pieter Abbeel", "Ken Goldberg", "Philipp Wu"], "title": "EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations", "comment": null, "summary": "Imitation learning from human demonstrations offers a promising approach for\nrobot skill acquisition, but egocentric human data introduces fundamental\nchallenges due to the embodiment gap. During manipulation, humans actively\ncoordinate head and hand movements, continuously reposition their viewpoint and\nuse pre-action visual fixation search strategies to locate relevant objects.\nThese behaviors create dynamic, task-driven head motions that static robot\nsensing systems cannot replicate, leading to a significant distribution shift\nthat degrades policy performance. We present EgoMI (Egocentric Manipulation\nInterface), a framework that captures synchronized end-effector and active head\ntrajectories during manipulation tasks, resulting in data that can be\nretargeted to compatible semi-humanoid robot embodiments. To handle rapid and\nwide-spanning head viewpoint changes, we introduce a memory-augmented policy\nthat selectively incorporates historical observations. We evaluate our approach\non a bimanual robot equipped with an actuated camera head and find that\npolicies with explicit head-motion modeling consistently outperform baseline\nmethods. Results suggest that coordinated hand-eye learning with EgoMI\neffectively bridges the human-robot embodiment gap for robust imitation\nlearning on semi-humanoid embodiments. Project page:\nhttps://egocentric-manipulation-interface.github.io", "AI": {"tldr": "EgoMI enables imitation learning from egocentric human manipulation by recording synchronized hand and head trajectories, retargeting to semi-humanoid robots, and using a memory-augmented policy to handle rapid viewpoint changes, leading to improved performance over baselines.", "motivation": "The embodiment gap between human egocentric data and robot sensing degrades imitation performance; humans coordinate gaze and hand actions, causing dynamic head motions and viewpoint shifts that static sensing cannot reproduce.", "method": "Capture synchronized end-effector and active head trajectories during manipulation (EgoMI), retarget data to compatible semi-humanoid embodiments, and employ a memory-augmented policy that selectively uses historical observations to cope with rapid, wide head viewpoint changes.", "result": "On a bimanual robot with an actuated camera head, policies that model head motion consistently outperform baselines, indicating that coordinated hand-eye learning with EgoMI helps bridge the embodiment gap for robust imitation learning.", "conclusion": "Explicitly modeling head motion and leveraging memory for historical observations improves imitation from egocentric human data on semi-humanoid robots, suggesting a viable path to bridging the human-robot embodiment gap."}}
{"id": "2511.00044", "categories": ["cs.LG", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2511.00044", "abs": "https://arxiv.org/abs/2511.00044", "authors": ["Kohei Tsuchiyama", "Andre Roehm", "Takatomo Mihana", "Ryoichi Horisaki"], "title": "ReLaX-Net: Reusing Layers for Parameter-Efficient Physical Neural Networks", "comment": null, "summary": "Physical Neural Networks (PNN) are promising platforms for next-generation\ncomputing systems. However, recent advances in digital neural network\nperformance are largely driven by the rapid growth in the number of trainable\nparameters and, so far, demonstrated PNNs are lagging behind by several orders\nof magnitude in terms of scale. This mirrors size and performance constraints\nfound in early digital neural networks. In that period, efficient reuse of\nparameters contributed to the development of parameter-efficient architectures\nsuch as convolutional neural networks.\n  In this work, we numerically investigate hardware-friendly weight-tying for\nPNNs. Crucially, with many PNN systems, there is a time-scale separation\nbetween the fast dynamic active elements of the forward pass and the only\nslowly trainable elements implementing weights and biases. With this in mind,we\npropose the Reuse of Layers for eXpanding a Neural Network (ReLaX-Net)\narchitecture, which employs a simple layer-by-layer time-multiplexing scheme to\nincrease the effective network depth and efficiently use the number of\nparameters. We only require the addition of fast switches for existing PNNs. We\nvalidate ReLaX-Nets via numerical experiments on image classification and\nnatural language processing tasks. Our results show that ReLaX-Net improves\ncomputational performance with only minor modifications to a conventional PNN.\nWe observe a favorable scaling, where ReLaX-Nets exceed the performance of\nequivalent traditional RNNs or DNNs with the same number of parameters.", "AI": {"tldr": "Proposes ReLaX-Net, a hardware-friendly time-multiplexed weight-sharing scheme for Physical Neural Networks (PNNs) that increases effective depth with minimal changes, achieving better parameter-efficient performance than equivalent traditional networks.", "motivation": "PNNs lag behind digital neural networks in scale; parameter efficiency and hardware constraints are critical. A layer-reuse strategy can emulate deeper architectures without proportionally increasing trainable parameters, leveraging fast active elements vs. slow trainable weights.", "method": "Introduce ReLaX-Net: layer-by-layer time-multiplexing that reuses existing layers with fast switches added to PNNs. Validate via numerical experiments on image classification and NLP tasks, comparing against conventional PNNs and parameter-matched RNNs/DNNs.", "result": "ReLaX-Net yields improved computational performance with only minor hardware modifications. It demonstrates favorable scaling and outperforms equivalent traditional RNNs/DNNs having the same parameter count.", "conclusion": "Time-multiplexed layer reuse is a viable, hardware-friendly path to scale PNNs, narrowing the performance gap with digital networks and enabling more parameter-efficient architectures."}}
{"id": "2511.00206", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00206", "abs": "https://arxiv.org/abs/2511.00206", "authors": ["Dirk U. Wulff", "Rui Mata"], "title": "Advancing Cognitive Science with LLMs", "comment": null, "summary": "Cognitive science faces ongoing challenges in knowledge synthesis and\nconceptual clarity, in part due to its multifaceted and interdisciplinary\nnature. Recent advances in artificial intelligence, particularly the\ndevelopment of large language models (LLMs), offer tools that may help to\naddress these issues. This review examines how LLMs can support areas where the\nfield has historically struggled, including establishing cross-disciplinary\nconnections, formalizing theories, developing clear measurement taxonomies,\nachieving generalizability through integrated modeling frameworks, and\ncapturing contextual and individual variation. We outline the current\ncapabilities and limitations of LLMs in these domains, including potential\npitfalls. Taken together, we conclude that LLMs can serve as tools for a more\nintegrative and cumulative cognitive science when used judiciously to\ncomplement, rather than replace, human expertise.", "AI": {"tldr": "Large language models (LLMs) can help cognitive science achieve greater integration and cumulative knowledge by aiding cross-disciplinary connections, theory formalization, measurement taxonomy development, integrated modeling frameworks, and capturing contextual/individual variation, but should complement rather than replace human expertise, with awareness of potential pitfalls.", "motivation": "Cognitive science struggles with knowledge synthesis and conceptual clarity due to its multifaceted, interdisciplinary nature. LLMs offer tools to address cross-disciplinary connections, formalize theories, develop clear measurement taxonomies, improve generalizability through integrated modeling, and capture context and individual differences.", "method": "Narrative review examining current capabilities and limitations of LLMs in the domains noted, outlining potential pitfalls and synthesizing their potential role in cognitive science.", "result": "LLMs can serve as tools for a more integrative and cumulative cognitive science when used judiciously to complement human expertise.", "conclusion": "LLMs should augment rather than replace human expertise; use with caution to foster integrative knowledge synthesis while being mindful of limitations and potential pitfalls."}}
{"id": "2511.00073", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00073", "abs": "https://arxiv.org/abs/2511.00073", "authors": ["Harald Kristen", "Daniel Kulmer", "Manuela Hirschmugl"], "title": "Habitat and Land Cover Change Detection in Alpine Protected Areas: A Comparison of AI Architectures", "comment": null, "summary": "Rapid climate change and other disturbances in alpine ecosystems demand\nfrequent habitat monitoring, yet manual mapping remains prohibitively expensive\nfor the required temporal resolution. We employ deep learning for change\ndetection using long-term alpine habitat data from Gesaeuse National Park,\nAustria, addressing a major gap in applying geospatial foundation models (GFMs)\nto complex natural environments with fuzzy class boundaries and highly\nimbalanced classes. We compare two paradigms: post-classification change\ndetection (CD) versus direct CD. For post-classification CD, we evaluate GFMs\nPrithvi-EO-2.0 and Clay v1.0 against U-Net CNNs; for direct CD, we test the\ntransformer ChangeViT against U-Net baselines. Using high-resolution multimodal\ndata (RGB, NIR, LiDAR, terrain attributes) covering 4,480 documented changes\nover 15.3 km2, results show Clay v1.0 achieves 51% overall accuracy versus\nU-Net's 41% for multi-class habitat change, while both reach 67% for binary\nchange detection. Direct CD yields superior IoU (0.53 vs 0.35) for binary but\nonly 28% accuracy for multi-class detection. Cross-temporal evaluation reveals\nGFM robustness, with Clay maintaining 33% accuracy on 2020 data versus U-Net's\n23%. Integrating LiDAR improves semantic segmentation from 30% to 50% accuracy.\nAlthough overall accuracies are lower than in more homogeneous landscapes, they\nreflect realistic performance for complex alpine habitats. Future work will\nintegrate object-based post-processing and physical constraints to enhance\napplicability.", "AI": {"tldr": "A comparative study on change detection in alpine habitats using two paradigms: post-classification with geospatial foundation models (GFMs) and direct CD with transformer models, against U-Net baselines. Finds moderate accuracy in complex alpine landscapes, with LiDAR and cross-temporal robustness aiding performance; results vary by multi-class vs binary change detection.", "motivation": "Rapid climate change and disturbances require frequent, fine-resolution habitat monitoring in alpine ecosystems. Manual mapping is costly and slow, creating a need for scalable automated methods. The paper investigates whether geospatial foundation models (GFMs) can be effectively applied to complex natural environments and how different CD paradigms perform.", "method": "Two CD paradigms are compared. (1) Post-classification CD: GFMs Prithvi-EO-2.0 and Clay v1.0 are evaluated alongside U-Net CNNs for multi-class habitat change detection (and binary change). (2) Direct CD: Transformer ChangeViT is evaluated against U-Net baselines. Data modalities include RGB, NIR, LiDAR, and terrain attributes. The dataset comprises 4,480 documented changes over 15.3 km2. Evaluation metrics include overall accuracy (OA), IoU for binary and multi-class, and cross-temporal performance (2020 data).", "result": "Clay v1.0 achieves ~51% OA vs ~41% for U-Net on multi-class change detection; both reach ~67% OA for binary change. Direct CD (ChangeViT) yields higher IoU (0.53 vs 0.35) for binary change but only 28% accuracy for multi-class detection. Cross-temporal results show Clay maintaining ~33% accuracy on 2020 data vs U-Net ~23%. Adding LiDAR improves semantic segmentation from ~30% to ~50% accuracy. Overall, accuracies are lower than in homogeneous landscapes, reflecting the complexity of alpine habitats.", "conclusion": "GFMs demonstrate robustness to temporal shifts in alpine environments, and LiDAR integration notably boosts performance. However, the task remains challenging due to fuzzy class boundaries and severe class imbalance. The study suggests that combining object-based post-processing and physical constraints could enhance practical applicability in high-complexity landscapes."}}
{"id": "2511.00193", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00193", "abs": "https://arxiv.org/abs/2511.00193", "authors": ["Faranak Akbarifar", "Nooshin Maghsoodi", "Sean P Dukelow", "Stephen Scott", "Parvin Mousavi"], "title": "Reducing Robotic Upper-Limb Assessment Time While Maintaining Precision: A Time Series Foundation Model Approach", "comment": null, "summary": "Purpose: Visually Guided Reaching (VGR) on the Kinarm robot yields sensitive\nkinematic biomarkers but requires 40-64 reaches, imposing time and fatigue\nburdens. We evaluate whether time-series foundation models can replace\nunrecorded trials from an early subset of reaches while preserving the\nreliability of standard Kinarm parameters.\n  Methods: We analyzed VGR speed signals from 461 stroke and 599 control\nparticipants across 4- and 8-target reaching protocols. We withheld all but the\nfirst 8 or 16 reaching trials and used ARIMA, MOMENT, and Chronos models,\nfine-tuned on 70 percent of subjects, to forecast synthetic trials. We\nrecomputed four kinematic features of reaching (reaction time, movement time,\nposture speed, maximum speed) on combined recorded plus forecasted trials and\ncompared them to full-length references using ICC(2,1).\n  Results: Chronos forecasts restored ICC >= 0.90 for all parameters with only\n8 recorded trials plus forecasts, matching the reliability of 24-28 recorded\nreaches (Delta ICC <= 0.07). MOMENT yielded intermediate gains, while ARIMA\nimprovements were minimal. Across cohorts and protocols, synthetic trials\nreplaced reaches without materially compromising feature reliability.\n  Conclusion: Foundation-model forecasting can greatly shorten Kinarm VGR\nassessment time. For the most impaired stroke survivors, sessions drop from 4-5\nminutes to about 1 minute while preserving kinematic precision. This\nforecast-augmented paradigm promises efficient robotic evaluations for\nassessing motor impairments following stroke.", "AI": {"tldr": "Foundation-model forecasting can replace unrecorded Kinarm reaching trials, preserving reliability of kinematic features while dramatically reducing assessment time, especially for stroke patients.", "motivation": "To reduce time and fatigue burden of Visually Guided Reaching (VGR) assessments on the Kinarm robot by imputing missing trials with time-series forecasts, while maintaining the reliability of key kinematic biomarkers.", "method": "Analyze VGR speed signals from 461 stroke and 599 control participants across 4- and 8-target reaching protocols. Hold back the first 8 or 16 trials and forecast synthetic trials using ARIMA, MOMENT, and Chronos models fine-tuned on 70% of subjects. Recompute reaction time, movement time, posture speed, and maximum speed on combined recorded+forecasted trials. Evaluate reliability against full-length references using ICC(2,1).", "result": "Chronos forecasts restore ICC \u2265 0.90 for all four features with only 8 recorded trials plus forecasts, matching the reliability of 24\u201328 recorded reaches (\u0394 ICC \u2264 0.07). MOMENT shows intermediate gains; ARIMA yields minimal improvement. Synthetic trials reliably replace additional reaches across cohorts/protocols without materially compromising feature reliability.", "conclusion": "Forecast-augmented Kinarm VGR can substantially shorten assessment time, reducing sessions for most impaired stroke survivors from 4\u20135 minutes to ~1 minute while preserving kinematic precision, enabling efficient robotic evaluations of post-stroke motor impairments."}}
{"id": "2511.00047", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2511.00047", "abs": "https://arxiv.org/abs/2511.00047", "authors": ["Omkar Kulkarni", "Rohitash Chandra"], "title": "DynBERG: Dynamic BERT-based Graph neural network for financial fraud detection", "comment": null, "summary": "Financial fraud detection is critical for maintaining the integrity of\nfinancial systems, particularly in decentralised environments such as\ncryptocurrency networks. Although Graph Convolutional Networks (GCNs) are\nwidely used for financial fraud detection, graph Transformer models such as\nGraph-BERT are gaining prominence due to their Transformer-based architecture,\nwhich mitigates issues such as over-smoothing. Graph-BERT is designed for\nstatic graphs and primarily evaluated on citation networks with undirected\nedges. However, financial transaction networks are inherently dynamic, with\nevolving structures and directed edges representing the flow of money. To\naddress these challenges, we introduce DynBERG, a novel architecture that\nintegrates Graph-BERT with a Gated Recurrent Unit (GRU) layer to capture\ntemporal evolution over multiple time steps. Additionally, we modify the\nunderlying algorithm to support directed edges, making DynBERG well-suited for\ndynamic financial transaction analysis. We evaluate our model on the Elliptic\ndataset, which includes Bitcoin transactions, including all transactions during\na major cryptocurrency market event, the Dark Market Shutdown. By assessing\nDynBERG's resilience before and after this event, we analyse its ability to\nadapt to significant market shifts that impact transaction behaviours. Our\nmodel is benchmarked against state-of-the-art dynamic graph classification\napproaches, such as EvolveGCN and GCN, demonstrating superior performance,\noutperforming EvolveGCN before the market shutdown and surpassing GCN after the\nevent. Additionally, an ablation study highlights the critical role of\nincorporating a time-series deep learning component, showcasing the\neffectiveness of GRU in modelling the temporal dynamics of financial\ntransactions.", "AI": {"tldr": "DynBERG combines Graph-BERT with a GRU to handle dynamic, directed financial transaction graphs; it outperforms baselines and the GRU component is essential.", "motivation": "To adapt graph transformers (Graph-BERT) for dynamic, directed financial networks and improve fraud detection resilience to market shifts by capturing temporal evolution.", "method": "Introduce DynBERG, a Graph-BERT-based architecture augmented with a GRU layer to model temporal dynamics across time steps; modify the algorithm to support directed edges; evaluate on the Elliptic Bitcoin transaction dataset including the Dark Market Shutdown event; compare against EvolveGCN and GCN; perform an ablation study on the temporal component.", "result": "DynBERG outperforms EvolveGCN before the market shutdown and surpasses GCN after the event; ablation confirms the critical role of the GRU time-series component for capturing temporal dynamics in transactions.", "conclusion": "Integrating transformer-based spatial encoding with temporal recurrence yields robust dynamic graph representations for financial fraud detection, effective under major market shifts."}}
{"id": "2511.00267", "categories": ["cs.AI", "cs.CY", "cs.GL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00267", "abs": "https://arxiv.org/abs/2511.00267", "authors": ["Christian Prothmann", "Vijay Gadepally", "Jeremy Kepner", "Koley Borchard", "Luca Carlone", "Zachary Folcik", "J. Daniel Grith", "Michael Houle", "Jonathan P. How", "Nathan Hughes", "Ifueko Igbinedion", "Hayden Jananthan", "Tejas Jayashankar", "Michael Jones", "Sertac Karaman", "Binoy G. Kurien", "Alejandro Lancho", "Giovanni Lavezzi", "Gary C. F. Lee", "Charles E. Leiserson", "Richard Linares", "Lindsey McEvoy", "Peter Michaleas", "Chasen Milner", "Alex Pentland", "Yury Polyanskiy", "Jovan Popovich", "Jeffrey Price", "Tim W. Reid", "Stephanie Riley", "Siddharth Samsi", "Peter Saunders", "Olga Simek", "Mark S. Veillette", "Amir Weiss", "Gregory W. Wornell", "Daniela Rus", "Scott T. Ruppel"], "title": "Advancing AI Challenges for the United States Department of the Air Force", "comment": "8 pages, 8 figures, 59 references. To appear in IEEE HPEC 2025", "summary": "The DAF-MIT AI Accelerator is a collaboration between the United States\nDepartment of the Air Force (DAF) and the Massachusetts Institute of Technology\n(MIT). This program pioneers fundamental advances in artificial intelligence\n(AI) to expand the competitive advantage of the United States in the defense\nand civilian sectors. In recent years, AI Accelerator projects have developed\nand launched public challenge problems aimed at advancing AI research in\npriority areas. Hallmarks of AI Accelerator challenges include large, publicly\navailable, and AI-ready datasets to stimulate open-source solutions and engage\nthe wider academic and private sector AI ecosystem. This article supplements\nour previous publication, which introduced AI Accelerator challenges. We\nprovide an update on how ongoing and new challenges have successfully\ncontributed to AI research and applications of AI technologies.", "AI": {"tldr": "DAF-MIT AI Accelerator advances AI research by launching large, public, AI-ready challenges that foster open-source collaboration across defense and civilian sectors.", "motivation": "To strengthen U.S. competitive advantage by supporting fundamental AI advances through publicly available data and broad participation from academia and industry.", "method": "A collaboration between the U.S. Air Force and MIT that creates and updates AI accelerator challenges with large, public datasets designed for AI-ready use, encouraging open-source solutions and ecosystem engagement.", "result": "Ongoing and new challenges have meaningfully contributed to AI research and applications by expanding accessible datasets and stimulating broader AI development.", "conclusion": "Public AI accelerator challenges effectively accelerate AI progress by democratizing data, enabling wide participation, and translating research into practical applications."}}
{"id": "2511.00090", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00090", "abs": "https://arxiv.org/abs/2511.00090", "authors": ["Huanlin Gao", "Ping Chen", "Fuyuan Shi", "Chao Tan", "Zhaoxiang Liu", "Fang Zhao", "Kai Wang", "Shiguo Lian"], "title": "LeMiCa: Lexicographic Minimax Path Caching for Efficient Diffusion-Based Video Generation", "comment": "NeurIPS 2025", "summary": "We present LeMiCa, a training-free and efficient acceleration framework for\ndiffusion-based video generation. While existing caching strategies primarily\nfocus on reducing local heuristic errors, they often overlook the accumulation\nof global errors, leading to noticeable content degradation between accelerated\nand original videos. To address this issue, we formulate cache scheduling as a\ndirected graph with error-weighted edges and introduce a Lexicographic Minimax\nPath Optimization strategy that explicitly bounds the worst-case path error.\nThis approach substantially improves the consistency of global content and\nstyle across generated frames. Extensive experiments on multiple text-to-video\nbenchmarks demonstrate that LeMiCa delivers dual improvements in both inference\nspeed and generation quality. Notably, our method achieves a 2.9x speedup on\nthe Latte model and reaches an LPIPS score of 0.05 on Open-Sora, outperforming\nprior caching techniques. Importantly, these gains come with minimal perceptual\nquality degradation, making LeMiCa a robust and generalizable paradigm for\naccelerating diffusion-based video generation. We believe this approach can\nserve as a strong foundation for future research on efficient and reliable\nvideo synthesis. Our code is available at :https://github.com/UnicomAI/LeMiCa", "AI": {"tldr": "Training-free diffusion video acceleration LeMiCa uses error-weighted directed-graph cache scheduling with Lexicographic Minimax Path Optimization to bound worst-case errors, improving speed and global consistency.", "motivation": "Global error accumulation in caching-based acceleration degrades content consistency across frames; a bound on worst-case path error is needed for reliable video quality.", "method": "Model cache scheduling as a directed graph with error-weighted edges; apply Lexicographic Minimax Path Optimization to explicitly bound the worst-case path error, reducing global content/style degradation without training.", "result": "Achieves dual improvements in speed and quality: 2.9x speedup on Latte and LPIPS of 0.05 on Open-Sora, outperforming prior caching methods with minimal perceptual degradation.", "conclusion": "LeMiCa is a robust, generalizable, training-free framework for accelerating diffusion-based video generation and can serve as a foundation for future efficient and reliable video synthesis; code available at the provided URL."}}
{"id": "2511.00259", "categories": ["cs.RO", "cs.ET", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.00259", "abs": "https://arxiv.org/abs/2511.00259", "authors": ["Andria J. Farrens", "Luis Garcia-Fernandez", "Raymond Diaz Rojas", "Jillian Obeso Estrada", "Dylan Reinsdorf", "Vicky Chan", "Disha Gupta", "Joel Perry", "Eric Wolbrecht", "An Do", "Steven C. Cramer", "David J. Reinkensmeyer"], "title": "Tailored robotic training improves hand function and proprioceptive processing in stroke survivors with proprioceptive deficits: A randomized controlled trial", "comment": "Main manuscript: 38 pages (double spaced, with references), 6\n  figures, 2 tables and collated supplemental materials (17 pages, double\n  spaced)", "summary": "Precision rehabilitation aims to tailor movement training to improve\noutcomes. We tested whether proprioceptively-tailored robotic training improves\nhand function and neural processing in stroke survivors. Using a robotic finger\nexoskeleton, we tested two proprioceptively-tailored approaches: Propriopixel\nTraining, which uses robot-facilitated, gamified movements to enhance\nproprioceptive processing, and Virtual Assistance Training, which reduces\nrobotic aid to increase reliance on self-generated feedback. In a randomized\ncontrolled trial, forty-six chronic stroke survivors completed nine 2-hour\nsessions of Standard, Propriopixel or Virtual training. Among participants with\nproprioceptive deficits, Propriopixel ((Box and Block Test: 7 +/- 4.2, p=0.002)\nand Virtual Assistance (4.5 +/- 4.4 , p=0.068) yielded greater gains in hand\nfunction (Standard: 0.8 +/- 2.3 blocks). Proprioceptive gains correlated with\nimprovements in hand function. Tailored training enhanced neural sensitivity to\nproprioceptive cues, evidenced by a novel EEG biomarker, the proprioceptive\nContingent Negative Variation. These findings support proprioceptively-tailored\ntraining as a pathway to precision neurorehabilitation.", "AI": {"tldr": "Proprioceptively-tailored robotic training can improve hand function and proprioceptive neural processing after stroke, with two approaches (Propriopixel Training and Virtual Assistance Training) showing benefits, especially in those with proprioceptive deficits; Propriopixel yielded the strongest functional gains and an EEG biomarker of proprioceptive processing.", "motivation": "To test whether tailoring rehabilitation to proprioceptive processing using robotic-assisted, gamified interventions enhances functional recovery and neural sensitivity after stroke, addressing heterogeneity in proprioceptive deficits.", "method": "Randomized controlled trial with 46 chronic stroke survivors, nine 2-hour sessions, three arms (Standard, Propriopixel, Virtual). Used a robotic finger exoskeleton delivering proprioceptively-tailored training. Assessed hand function (Box and Block Test), proprioceptive status, and neural processing via EEG, including a novel proprioceptive Contingent Negative Variation biomarker.", "result": "In participants with proprioceptive deficits, Propriopixel improved hand function by 7\u00b14.2 blocks (p=0.002) and Virtual Assistance by 4.5\u00b14.4 blocks (p=0.068) versus Standard (0.8\u00b12.3). Proprioceptive gains correlated with functional gains. Tailored training enhanced neural sensitivity to proprioception, indicated by the proprioceptive Contingent Negative Variation EEG biomarker.", "conclusion": "Proprioceptively-tailored training is a promising avenue for precision neurorehabilitation after stroke, improving both function and proprioceptive neural processing, with potential for personalized interventions based on proprioceptive status."}}
{"id": "2511.00049", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00049", "abs": "https://arxiv.org/abs/2511.00049", "authors": ["Yao Liu"], "title": "Adaptive Spatio-Temporal Graphs with Self-Supervised Pretraining for Multi-Horizon Weather Forecasting", "comment": null, "summary": "Accurate and robust weather forecasting remains a fundamental challenge due\nto the inherent spatio-temporal complexity of atmospheric systems. In this\npaper, we propose a novel self-supervised learning framework that leverages\nspatio-temporal structures to improve multi-variable weather prediction. The\nmodel integrates a graph neural network (GNN) for spatial reasoning, a\nself-supervised pretraining scheme for representation learning, and a\nspatio-temporal adaptation mechanism to enhance generalization across varying\nforecasting horizons. Extensive experiments on both ERA5 and MERRA-2 reanalysis\ndatasets demonstrate that our approach achieves superior performance compared\nto traditional numerical weather prediction (NWP) models and recent deep\nlearning methods. Quantitative evaluations and visual analyses in Beijing and\nShanghai confirm the model's capability to capture fine-grained meteorological\npatterns. The proposed framework provides a scalable and label-efficient\nsolution for future data-driven weather forecasting systems.", "AI": {"tldr": "A self-supervised, graph-based framework for multi-variable weather forecasting improves predictions by combining a GNN for spatial reasoning, self-supervised representation learning, and a spatio-temporal adaptation module to generalize across forecasting horizons, achieving state-of-the-art results on ERA5 and MERRA-2 with city-scale validation.", "motivation": "Weather forecasting is challenged by strong spatio-temporal dependencies and limited labeled data that hinder generalization across horizons and regions; a scalable, label-efficient approach is needed to leverage unlabeled data and adapt to varying forecast horizons.", "method": "A modular framework integrating (1) a graph neural network for spatial reasoning among grid cells/variables, (2) self-supervised pretraining to learn robust representations from unlabeled data, and (3) a spatio-temporal adaptation mechanism to improve generalization across different forecasting horizons; evaluated on ERA5 and MERRA-2 reanalysis data with city-scale analyses in Beijing and Shanghai.", "result": "The approach outperforms traditional numerical weather prediction models and recent deep learning baselines on the tested datasets; quantitative gains and visual analyses indicate better capture of fine-grained meteorological patterns; demonstrated label-efficient scalability across variables and horizons.", "conclusion": "The proposed framework offers a scalable, data-efficient solution for data-driven weather forecasting that leverages spatio-temporal structure and unlabeled data to improve accuracy and generalization across horizons and regions."}}
{"id": "2511.00340", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00340", "abs": "https://arxiv.org/abs/2511.00340", "authors": ["Manan Roy Choudhury", "Adithya Chandramouli", "Mannan Anand", "Vivek Gupta"], "title": "Better Call CLAUSE: A Discrepancy Benchmark for Auditing LLMs Legal Reasoning Capabilities", "comment": "41 pages, 4 images", "summary": "The rapid integration of large language models (LLMs) into high-stakes legal\nwork has exposed a critical gap: no benchmark exists to systematically\nstress-test their reliability against the nuanced, adversarial, and often\nsubtle flaws present in real-world contracts. To address this, we introduce\nCLAUSE, a first-of-its-kind benchmark designed to evaluate the fragility of an\nLLM's legal reasoning. We study the capabilities of LLMs to detect and reason\nabout fine-grained discrepancies by producing over 7500 real-world perturbed\ncontracts from foundational datasets like CUAD and ContractNLI. Our novel,\npersona-driven pipeline generates 10 distinct anomaly categories, which are\nthen validated against official statutes using a Retrieval-Augmented Generation\n(RAG) system to ensure legal fidelity. We use CLAUSE to evaluate leading LLMs'\nability to detect embedded legal flaws and explain their significance. Our\nanalysis shows a key weakness: these models often miss subtle errors and\nstruggle even more to justify them legally. Our work outlines a path to\nidentify and correct such reasoning failures in legal AI.", "AI": {"tldr": "CLAUSE is a benchmarking framework to stress-test LLMs on legal reasoning by generating 7500+ perturbed real-world contracts and evaluating detection of subtle contractual flaws and the ability to justify them, validated via a retrieval-augmented system against statutes.", "motivation": "There is a critical gap in robustly evaluating LLMs' reliability in high-stakes legal tasks; existing benchmarks do not systematically test adversarial but plausible contract flaws.", "method": "Create 7500+ perturbed contracts from CUAD and ContractNLI using a persona-driven pipeline that yields 10 anomaly categories; validate perturbations against official statutes with a Retrieval-Augmented Generation system; assess LLMs on flaw-detection and justification.", "result": "LLMs frequently miss subtle errors and struggle to justify them legally, revealing fragility in legal reasoning; CLAUSE provides a mechanism to identify and address these reasoning failures.", "conclusion": "CLAUSE offers a first-of-its-kind, scalable benchmark for auditing and improving legal AI reliability, guiding future work to strengthen detection and justification of legal flaws."}}
{"id": "2511.00091", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00091", "abs": "https://arxiv.org/abs/2511.00091", "authors": ["Wenli Xiao", "Haotian Lin", "Andy Peng", "Haoru Xue", "Tairan He", "Yuqi Xie", "Fengyuan Hu", "Jimmy Wu", "Zhengyi Luo", "Linxi \"Jim\" Fan", "Guanya Shi", "Yuke Zhu"], "title": "Self-Improving Vision-Language-Action Models with Data Generation via Residual RL", "comment": "26 pages", "summary": "Supervised fine-tuning (SFT) has become the de facto post-training strategy\nfor large vision-language-action (VLA) models, but its reliance on costly human\ndemonstrations limits scalability and generalization. We propose Probe, Learn,\nDistill (PLD), a three-stage plug-and-play framework that improves VLAs through\nresidual reinforcement learning (RL) and distribution-aware data collection. In\nStage 1, we train lightweight residual actors to probe failure regions of the\nVLA generalist. In Stage 2, we use a hybrid rollout scheme that aligns\ncollected trajectories with the generalist's deployment distribution while\ncapturing recovery behaviors. In Stage 3, we distill the curated trajectories\nback into the generalist with standard SFT. PLD achieves near-saturated 99%\ntask success on LIBERO, over 50% gains in SimplerEnv, and 100% success on\nreal-world Franka and YAM arm manipulation tasks. Ablations show that residual\nprobing and distribution-aware replay are key to collecting deployment-aligned\ndata that improves both seen and unseen tasks, offering a scalable path toward\nself-improving VLA models.", "AI": {"tldr": "PLD is a three-stage plug-and-play framework that enhances vision-language-action models via residual reinforcement learning and deployment-aware data collection, followed by distillation back into the base model. It yields strong cross-task gains and demonstrates scalability for self-improving VLA systems.", "motivation": "Supervised fine-tuning (SFT) relies on costly human demonstrations, which limits scalability and generalization. The paper seeks a scalable, self-improving approach to improve VLA models beyond static SFT.", "method": "Stage 1: train lightweight residual actors to probe failure regions of the generalist VLA. Stage 2: employ a hybrid rollout that aligns collected trajectories with the deployment distribution while capturing recovery behaviors. Stage 3: distill the curated trajectories back into the generalist via standard SFT.", "result": "PLD achieves near-saturated 99% task success on LIBERO, over 50% gains on SimplerEnv, and 100% success on real-world Franka and YAM arm manipulation tasks. Ablations indicate residual probing and distribution-aware replay are key to collecting deployment-aligned data that improves both seen and unseen tasks.", "conclusion": "Residual probing plus deployment-aligned data collection enable scalable self-improvement for VLA models by collecting and distilling targeted experiences back into the generalist, improving performance on both seen and unseen tasks."}}
{"id": "2511.00306", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00306", "abs": "https://arxiv.org/abs/2511.00306", "authors": ["Baoshan Song", "Ruijie Xu", "Li-Ta Hsu"], "title": "FGO MythBusters: Explaining how Kalman Filter variants achieve the same performance as FGO in navigation applications", "comment": null, "summary": "Sliding window-factor graph optimization (SW-FGO) has gained more and more\nattention in navigation research due to its robust approximation to\nnon-Gaussian noises and nonlinearity of measuring models. There are lots of\nworks focusing on its application performance compared to extended Kalman\nfilter (EKF) but there is still a myth at the theoretical relationship between\nthe SW-FGO and EKF. In this paper, we find the necessarily fair condition to\nconnect SW-FGO and Kalman filter variants (KFV) (e.g., EKF, iterative EKF\n(IEKF), robust EKF (REKF) and robust iterative EKF (RIEKF)). Based on the\nconditions, we propose a recursive FGO (Re-FGO) framework to represent KFV\nunder SW-FGO formulation. Under explicit conditions (Markov assumption,\nGaussian noise with L2 loss, and a one-state window), Re-FGO regenerates\nexactly to EKF/IEKF/REKF/RIEKF, while SW-FGO shows measurable benefits in\nnonlinear, non-Gaussian regimes at a predictable compute cost. Finally, after\nclarifying the connection between them, we highlight the unique advantages of\nSW-FGO in practical phases, especially on numerical estimation and deep\nlearning integration. The code and data used in this work is open sourced at\nhttps://github.com/Baoshan-Song/KFV-FGO-Comparison.", "AI": {"tldr": "SW-FGO can reproduce Kalman filter variants under certain conditions and offers robustness to non-Gaussianity with predictable cost; it bridges SW-FGO and EKF family via a Re-FGO framework.", "motivation": "Clarify the theoretical relationship between SW-FGO and Kalman filter variants; establish when SW-FGO exactly matches EKF family and when it provides additional benefits.", "method": "Introduce a recursive FGO (Re-FGO) framework; derive explicit conditions (Markov assumption, Gaussian noise with L2 loss, one-state window); show that Re-FGO regens EKF/IEKF/REKF/RIEKF exactly under these conditions; discuss computational cost and benefits in nonlinear/non-Gaussian regimes.", "result": "Under the stated conditions, Re-FGO exactly regenerates EKF/IEKF/REKF/RIEKF; SW-FGO offers advantages in nonlinear/non-Gaussian settings with predictable compute cost; code/data are open-sourced.", "conclusion": "Clarifies the connection between SW-FGO and KF variants; highlights SW-FGO\u2019s practical advantages, especially for numerical estimation and deep learning integration; provides resources for reproduction."}}
{"id": "2511.00050", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00050", "abs": "https://arxiv.org/abs/2511.00050", "authors": ["Dhananjaya Gowda", "Seoha Song", "Junhyun Lee", "Harshith Goka"], "title": "FLoRA: Fused forward-backward adapters for parameter efficient fine-tuning and reducing inference-time latencies of LLMs", "comment": null, "summary": "As the large language models (LLMs) grow in size each day, efficient training\nand fine-tuning has never been as important as nowadays. This resulted in the\ngreat interest in parameter efficient fine-tuning (PEFT), and effective methods\nincluding low-rank adapters (LoRA) has emerged. Although the various PEFT\nmethods have been studied extensively in the recent years, the greater part of\nthe subject remains unexplored with the huge degree of freedom. In this paper,\nwe propose FLoRA, a family of fused forward-backward adapters (FFBA) for\nparameter-efficient fine-tuning of LLMs on downstream tasks. The FFBA combine\nideas from the popular LoRA and parallel adapters to improve the overall\nfine-tuning accuracies. At the same time, latencies are minimized by fusing the\nforward and backward adapters into existing projection layers of the base\nmodel. Experimental results show that the proposed FFB adapters perform\nsignificantly better than the popularly used LoRA in both accuracy and latency\nfor a similar parameter budget.", "AI": {"tldr": "Proposes FLoRA: fused forward-backward adapters for parameter-efficient fine-tuning of LLMs, achieving higher accuracy and lower latency than LoRA at similar parameter budgets.", "motivation": "As LLMs grow, efficient PEFT is essential. While LoRA and parallel adapters exist, there remain trade-offs between accuracy and latency; FFBA seeks better performance within a fixed parameter budget.", "method": "Introduce FFBA (FLoRA): fused forward-backward adapters that integrate with existing projection layers by merging forward and backward adapters, combining LoRA and parallel adapter ideas to reduce overhead.", "result": "Empirical results show FFBA significantly outperforms LoRA in both accuracy and latency for a similar parameter budget.", "conclusion": "FFBA provides a more efficient PEFT solution by fusing adapters, achieving better accuracy-latency trade-offs than LoRA while maintaining a fixed parameter budget."}}
{"id": "2511.00379", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00379", "abs": "https://arxiv.org/abs/2511.00379", "authors": ["Jiahao Wang", "Songkai Xue", "Jinghui Li", "Xiaozhen Wang"], "title": "Diverse Human Value Alignment for Large Language Models via Ethical Reasoning", "comment": "Accepted by AIES 2025, camera-ready version", "summary": "Ensuring that Large Language Models (LLMs) align with the diverse and\nevolving human values across different regions and cultures remains a critical\nchallenge in AI ethics. Current alignment approaches often yield superficial\nconformity rather than genuine ethical understanding, failing to address the\ncomplex, context-dependent nature of human values. In this paper, we propose a\nnovel ethical reasoning paradigm for LLMs inspired by well-established ethical\ndecision-making models, aiming at enhancing diverse human value alignment\nthrough deliberative ethical reasoning. Our framework consists of a structured\nfive-step process, including contextual fact gathering, hierarchical social\nnorm identification, option generation, multiple-lens ethical impact analysis,\nand reflection. This theory-grounded approach guides LLMs through an\ninterpretable reasoning process that enhances their ability to understand\nregional specificities and perform nuanced ethical analysis, which can be\nimplemented with either prompt engineering or supervised fine-tuning methods.\nWe perform evaluations on the SafeWorld benchmark that specially designed for\nregional value alignment. Experimental results demonstrate our framework\nsignificantly improves LLM alignment with diverse human values compared to\nbaseline methods, enabling more accurate social norm identification and more\nculturally appropriate reasoning. Our work provides a concrete pathway toward\ndeveloping LLMs that align more effectively with the multifaceted values of\nglobal societies through interdisciplinary research.", "AI": {"tldr": "A five-step deliberative ethical reasoning framework for LLMs to improve regional and cultural alignment, implemented via prompts or fine-tuning, evaluated on SafeWorld with reported improvement over baselines.", "motivation": "Current alignment yields superficial conformity and lacks genuine, context-sensitive ethical understanding across diverse cultures; need for interpretable, deliberative reasoning in LLMs that respects regional values.", "method": "Proposes a structured five-step process: contextual fact gathering, hierarchical social norm identification, option generation, multiple-lens ethical impact analysis, and reflection. Can be implemented via prompt engineering or supervised fine-tuning, enabling interpretable reasoning about regional specifics.", "result": "On the SafeWorld benchmark designed for regional value alignment, the framework significantly improves LLM alignment with diverse human values compared to baselines, with better social norm identification and more culturally appropriate reasoning.", "conclusion": "Provides a concrete, theory-grounded pathway toward aligning LLMs with multifaceted global human values, highlighting interdisciplinary avenues and potential for broader adoption and future research."}}
{"id": "2511.00095", "categories": ["cs.CV", "cs.AI", "92C55", "I.2.10"], "pdf": "https://arxiv.org/pdf/2511.00095", "abs": "https://arxiv.org/abs/2511.00095", "authors": ["Jiaming Liu", "Dingwei Fan", "Junyong Zhao", "Chunlin Li", "Haipeng Si", "Liang Sun"], "title": "SpinalSAM-R1: A Vision-Language Multimodal Interactive System for Spine CT Segmentation", "comment": "2 Tables,5 Figures,16 Equations", "summary": "The anatomical structure segmentation of the spine and adjacent structures\nfrom computed tomography (CT) images is a key step for spinal disease diagnosis\nand treatment. However, the segmentation of CT images is impeded by low\ncontrast and complex vertebral boundaries. Although advanced models such as the\nSegment Anything Model (SAM) have shown promise in various segmentation tasks,\ntheir performance in spinal CT imaging is limited by high annotation\nrequirements and poor domain adaptability. To address these limitations, we\npropose SpinalSAM-R1, a multimodal vision-language interactive system that\nintegrates a fine-tuned SAM with DeepSeek-R1, for spine CT image segmentation.\nSpecifically, our SpinalSAM-R1 introduces an anatomy-guided attention mechanism\nto improve spine segmentation performance, and a semantics-driven interaction\nprotocol powered by DeepSeek-R1, enabling natural language-guided refinement.\nThe SpinalSAM-R1 is fine-tuned using Low-Rank Adaptation (LoRA) for efficient\nadaptation. We validate our SpinalSAM-R1 on the spine anatomical structure with\nCT images. Experimental results suggest that our method achieves superior\nsegmentation performance. Meanwhile, we develop a PyQt5-based interactive\nsoftware, which supports point, box, and text-based prompts. The system\nsupports 11 clinical operations with 94.3\\% parsing accuracy and sub-800 ms\nresponse times. The software is released on\nhttps://github.com/6jm233333/spinalsam-r1.", "AI": {"tldr": "SpinalSAM-R1 integrates a fine-tuned Segment Anything Model (SAM) with DeepSeek-R1 to deliver multimodal, interactive spine CT segmentation, featuring anatomy-guided attention and semantics-driven language guidance, improved by Low-Rank Adaptation (LoRA). A PyQt5-based GUI supports 11 clinical operations with fast responses.", "motivation": "CT spine segmentation is hindered by low image contrast and complex vertebral boundaries, while existing SAM-based methods require heavy annotation and suffer domain adaptation gaps. There is a need for an efficient, interactive, and accurate tool that fits clinical workflows.", "method": "Fine-tune SAM for spine CT with Low-Rank Adaptation (LoRA); incorporate an anatomy-guided attention mechanism to enhance spine segmentation; integrate a semantics-driven interaction protocol via DeepSeek-R1 for natural language-guided refinement; develop a PyQt5-based interactive software supporting point, box, and text prompts (11 operations) with 94.3% parsing accuracy and sub-800 ms latency.", "result": "Experimental results indicate superior spine CT segmentation performance of SpinalSAM-R1. The interactive software achieves 94.3% parsing accuracy across 11 clinical operations with sub-800 ms response times.", "conclusion": "SpinalSAM-R1 offers an effective, efficient, and interactive solution for spine CT segmentation, combining anatomy-aware segmentation with language-guided refinement, and provides a usable software tool for clinical workflows."}}
{"id": "2511.00392", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00392", "abs": "https://arxiv.org/abs/2511.00392", "authors": ["Lingpeng Chen", "Jiakun Tang", "Apple Pui-Yi Chui", "Ziyang Hong", "Junfeng Wu"], "title": "SonarSweep: Fusing Sonar and Vision for Robust 3D Reconstruction via Plane Sweeping", "comment": "8 pages, 9 figures, conference", "summary": "Accurate 3D reconstruction in visually-degraded underwater environments\nremains a formidable challenge. Single-modality approaches are insufficient:\nvision-based methods fail due to poor visibility and geometric constraints,\nwhile sonar is crippled by inherent elevation ambiguity and low resolution.\nConsequently, prior fusion technique relies on heuristics and flawed geometric\nassumptions, leading to significant artifacts and an inability to model complex\nscenes. In this paper, we introduce SonarSweep, a novel, end-to-end deep\nlearning framework that overcomes these limitations by adapting the principled\nplane sweep algorithm for cross-modal fusion between sonar and visual data.\nExtensive experiments in both high-fidelity simulation and real-world\nenvironments demonstrate that SonarSweep consistently generates dense and\naccurate depth maps, significantly outperforming state-of-the-art methods\nacross challenging conditions, particularly in high turbidity. To foster\nfurther research, we will publicly release our code and a novel dataset\nfeaturing synchronized stereo-camera and sonar data, the first of its kind.", "AI": {"tldr": "SonarSweep is an end-to-end deep-learning framework for cross-modal fusion of sonar and vision using a plane-sweep approach to produce dense, accurate underwater depth maps, outperforming state-of-the-art in challenging conditions; code and a synchronized stereo-camera\u2013sonar dataset will be released.", "motivation": "Underwater 3D reconstruction is severely challenged by poor visibility for vision and elevation ambiguity/low resolution for sonar. Existing fusion methods rely on heuristics and flawed geometry, producing artifacts and poor scene modeling; there is a need for robust, learned cross-modal fusion to handle turbidity and complex geometries.", "method": "An end-to-end deep learning framework that adapts the principled plane-sweep algorithm for cross-modal fusion between sonar and visual data, enabling dense depth estimation by combining information from both modalities.", "result": "Extensive experiments in high-fidelity simulation and real-world environments show SonarSweep yields dense, accurate depth maps and significantly outperforms state-of-the-art methods, especially under high turbidity.", "conclusion": "The paper introduces a novel, effective cross-modal fusion approach for underwater 3D reconstruction and pledges to publicly release code and a novel synchronized stereo-camera\u2013sonar dataset to facilitate further research."}}
{"id": "2511.00051", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00051", "abs": "https://arxiv.org/abs/2511.00051", "authors": ["Da Chang", "Peng Xue", "Yu Li", "Yongxiang Liu", "Pengxiang Xu", "Shixun Zhang"], "title": "Calibrating and Rotating: A Unified Framework for Weight Conditioning in PEFT", "comment": null, "summary": "Parameter-Efficient Fine-Tuning (PEFT) methods are crucial for adapting large\npre-trained models. Among these, LoRA is considered a foundational approach.\nBuilding on this, the influential DoRA method enhances performance by\ndecomposing weight updates into magnitude and direction. However, its\nunderlying mechanism remains unclear, and it introduces significant\ncomputational overhead. In this work, we first identify that DoRA's success\nstems from its capacity to increase the singular value entropy of the weight\nupdate matrix, which promotes a more uniform update distribution akin to full\nfine-tuning. We then reformulate DoRA into a mathematically equivalent and more\nefficient matrix form, revealing it as a learnable weight conditioning method.\nBased on this insight, we propose a unified framework for designing advanced\nPEFT methods by exploring two orthogonal dimensions: the architectural\nplacement and the transformation type of the conditioning matrix. Within this\nframework, we introduce two novel methods: (1) \\textbf{Pre-Diag}, which applies\na diagonal conditioning matrix before the LoRA update to efficiently calibrate\nthe pre-trained weights, thereby enhancing performance while reducing training\ntime; and (2) \\textbf{S}kewed \\textbf{O}rthogonal \\textbf{R}otation\n\\textbf{A}daptation (\\textbf{SORA}), which employs a parameter-efficient\northogonal rotation to perform a more powerful, norm-preserving transformation\nof the feature space. Extensive experiments on natural language understanding\nand generation tasks demonstrate that our proposed methods achieve superior\nperformance and efficiency compared to both LoRA and DoRA. The code is\navailable at https://github.com/MaeChd/SORA.", "AI": {"tldr": "DoRA\u2019s success is attributed to increasing singular value entropy of the weight-update matrix, leading to more uniform updates similar to full fine-tuning. The authors reformulate DoRA as an efficient, learnable weight-conditioning matrix and propose a unified PEFT framework along two orthogonal axes: architectural placement and transformation type. They introduce Pre-Diag (diagonal conditioning before LoRA) and SORA (norm-preserving, learnable orthogonal rotation). Experiments on NLP understanding and generation show improvements in both performance and efficiency over LoRA and DoRA, with code available at the provided GitHub link.", "motivation": "Clarify the mechanism behind DoRA, address its computational overhead, and establish a general framework to guide the design of more effective PEFT methods.", "method": "Mathematically reformulate DoRA as a learnable weight-conditioning matrix; propose a unified framework that varies (i) where the conditioning is placed in the architecture (placement) and (ii) the type of conditioning transformation (transformation class). Within this framework, present two new methods: (a) Pre-Diag, a diagonal conditioning matrix applied before the LoRA update to calibrate pretrained weights efficiently; (b) SORA, a parameter-efficient orthogonal rotation that performs a powerful, norm-preserving transformation of feature space.", "result": "Extensive NLP experiments demonstrate that the proposed methods achieve superior performance and efficiency compared to both LoRA and DoRA.", "conclusion": "A unified conditioning-based framework for PEFT design is feasible and fruitful. The two proposed methods\u2014Pre-Diag and SORA\u2014illustrate how placement and transformation choices yield performance gains with reduced training overhead, guiding future PEFT research."}}
{"id": "2511.00382", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00382", "abs": "https://arxiv.org/abs/2511.00382", "authors": ["Mina Taraghi", "Yann Pequignot", "Amin Nikanjam", "Mohamed Amine Merzouk", "Foutse Khomh"], "title": "Efficiency vs. Alignment: Investigating Safety and Fairness Risks in Parameter-Efficient Fine-Tuning of LLMs", "comment": null, "summary": "Organizations are increasingly adopting and adapting Large Language Models\n(LLMs) hosted on public repositories such as HuggingFace. Although these\nadaptations often improve performance on specialized downstream tasks, recent\nevidence indicates that they can also degrade a model's safety or fairness.\nSince different fine-tuning techniques may exert distinct effects on these\ncritical dimensions, this study undertakes a systematic assessment of their\ntrade-offs. Four widely used Parameter-Efficient Fine-Tuning methods, LoRA,\nIA3, Prompt-Tuning, and P-Tuning, are applied to four instruction-tuned model\nfamilies (Meta-Llama-3-8B, Qwen2.5-7B, Mistral-7B, and Gemma-7B). In total, 235\nfine-tuned variants are evaluated across eleven safety hazard categories and\nnine demographic fairness dimensions. The results show that adapter-based\napproaches (LoRA, IA3) tend to improve safety scores and are the least\ndisruptive to fairness, retaining higher accuracy and lower bias scores. In\ncontrast, prompt-based methods (Prompt-Tuning and P-Tuning) generally reduce\nsafety and cause larger fairness regressions, with decreased accuracy and\nincreased bias. Alignment shifts are strongly moderated by base model type:\nLLaMA remains stable, Qwen records modest gains, Gemma experiences the steepest\nsafety decline, and Mistral, which is released without an internal moderation\nlayer, displays the greatest variance. Improvements in safety do not\nnecessarily translate into improvements in fairness, and no single\nconfiguration optimizes all fairness metrics simultaneously, indicating an\ninherent trade-off between these objectives. These findings suggest a practical\nguideline for safety-critical deployments: begin with a well-aligned base\nmodel, favour adapter-based PEFT, and conduct category-specific audits of both\nsafety and fairness.", "AI": {"tldr": "Adapter-based PEFT methods (LoRA, IA3) generally improve safety and preserve fairness better than prompt-based PEFT (Prompt-Tuning, P-Tuning), with strong variation across base models; no single setup optimizes all fairness metrics; guideline: start with a well-aligned base model, prefer adapters, and audit safety/fairness per category.", "motivation": "To systematically evaluate how different parameter-efficient fine-tuning techniques affect safety and fairness in instruction-tuned LLMs, given known performance trade-offs.", "method": "Applied four PEFT methods (LoRA, IA3, Prompt-Tuning, P-Tuning) to four instruction-tuned model families (Meta-Llama-3-8B, Qwen2.5-7B, Mistral-7B, Gemma-7B), yielding 235 fine-tuned variants. Evaluated across 11 safety hazard categories and 9 demographic fairness dimensions.", "result": "Adapter-based approaches (LoRA, IA3) tend to improve safety scores and are least disruptive to fairness, maintaining higher accuracy and lower bias. Prompt-based methods (Prompt-Tuning, P-Tuning) generally reduce safety and cause larger fairness regressions, with decreased accuracy and increased bias. Alignment shifts vary by base model: LLaMA stable, Qwen modest gains, Gemma steep safety decline, Mistral most variable. Safety improvements do not guarantee fairness improvements, and no configuration optimizes all fairness metrics, indicating a safety-fairness trade-off.", "conclusion": "For safety-critical deployments: start with a well-aligned base model, prefer adapter-based PEFT, and conduct category-specific audits of both safety and fairness."}}
{"id": "2511.00098", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00098", "abs": "https://arxiv.org/abs/2511.00098", "authors": ["Nils Porsche", "Flurin M\u00fcller-Diesing", "Sweta Banerjee", "Miguel Goncalves", "Marc Aubreville"], "title": "A filtering scheme for confocal laser endomicroscopy (CLE)-video sequences for self-supervised learning", "comment": null, "summary": "Confocal laser endomicroscopy (CLE) is a non-invasive, real-time imaging\nmodality that can be used for in-situ, in-vivo imaging and the microstructural\nanalysis of mucous structures. The diagnosis using CLE is, however, complicated\nby images being hard to interpret for non-experienced physicians. Utilizing\nmachine learning as an augmentative tool would hence be beneficial, but is\ncomplicated by the shortage of histopathology-correlated CLE imaging sequences\nwith respect to the plurality of patterns in this domain, leading to\noverfitting of machine learning models. To overcome this, self-supervised\nlearning (SSL) can be employed on larger unlabeled datasets. CLE is a\nvideo-based modality with high inter-frame correlation, leading to a\nnon-stratified data distribution for SSL training. In this work, we propose a\nfilter functionality on CLE video sequences to reduce the dataset redundancy in\nSSL training and improve SSL training convergence and training efficiency. We\nuse four state-of-the-art baseline networks and a SSL teacher-student network\nwith a vision transformer small backbone for the evaluation. These networks\nwere evaluated on downstream tasks for a sinonasal tumor dataset and a squamous\ncell carcinoma of the skin dataset. On both datasets, we found the highest test\naccuracy on the filtered SSL-pretrained model, with 67.48% and 73.52%, both\nconsiderably outperforming their non-SSL baselines. Our results show that SSL\nis an effective method for CLE pretraining. Further, we show that our proposed\nCLE video filter can be utilized to improve training efficiency in\nself-supervised scenarios, resulting in a reduction of 67% in training time.", "AI": {"tldr": "Self-supervised pretraining on filtered CLE video data improves SSL performance and efficiency for CLE-based diagnostics, achieving 67.48% and 73.52% accuracy and 67% faster training compared to non-SSL baselines.", "motivation": "CLE images are hard to interpret for non-experts; limited labeled data with histopathology-correlated CLE; high inter-frame correlation in CLE videos leads to non-stratified SSL data and overfitting; need to exploit unlabeled data efficiently.", "method": "Introduce a video filter to reduce redundancy in CLE video sequences for SSL training. Evaluate four baseline networks plus a SSL teacher-student model with a ViT-S backbone on two datasets (sinonasal tumor, skin squamous cell carcinoma). Compare SSL-pretrained vs non-SSL baselines and report accuracy and training-time reductions.", "result": "Filtered SSL-pretrained models achieve the highest test accuracy: 67.48% (sinonasal) and 73.52% (skin SCC), outperforming non-SSL baselines. SSL improves performance and the CLE video filter reduces training time by 67%.", "conclusion": "SSL is effective for CLE pretraining when paired with the proposed video-filter to mitigate inter-frame redundancy, yielding better diagnostic accuracy and substantially faster training, suggesting broad utility for CLE-based ML."}}
{"id": "2511.00412", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00412", "abs": "https://arxiv.org/abs/2511.00412", "authors": ["John A. Christian", "Michael R. Walker II", "Wyatt Bridgman", "Michael J. Sparapany"], "title": "Runge-Kutta Approximations for Direct Coning Compensation Applying Lie Theory", "comment": null, "summary": "The integration of gyroscope measurements is an essential task for most\nnavigation systems. Modern vehicles typically use strapdown systems, such that\ngyro integration requires coning compensation to account for the sensor's\nrotation during the integration. Many coning compensation algorithms have been\ndeveloped and a few are reviewed. This work introduces a new class of coning\ncorrection algorithm built directly from the classical Runge-Kutta integration\nroutines. A simple case is shown to collapse to one of the most popular coning\nalgorithms and a clear procedure for generating higher-order algorithms is\npresented.", "AI": {"tldr": "Introduces a Runge-Kutta\u2013based class of coning correction algorithms for strapdown gyro integration; shows a simple case reduces to a popular method and provides a general procedure to generate higher-order coning corrections.", "motivation": "Coning compensation is essential in strapdown inertial navigation to account for sensor rotation during integration; existing algorithms exist, but this work seeks a systematic, higher-order construction from RK methods.", "method": "Derives coning corrections directly from Runge-Kutta integration routines; demonstrates that a simple case collapses to a widely used algorithm; outlines a procedure to generate higher-order coning corrections.", "result": "Demonstrates the linkage between RK-based corrections and known coning algorithms; provides a clear procedure to construct higher-order algorithms (though specific results/accuracy metrics are not provided in the abstract).", "conclusion": "Offers a novel, systematic framework for coning compensation with higher-order accuracy by embedding them into RK-based integration; potential for more accurate strapdown navigation, at the cost of added computational effort."}}
{"id": "2511.00052", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00052", "abs": "https://arxiv.org/abs/2511.00052", "authors": ["Federico Formica", "Stefano Gregis", "Aurora Francesca Zanenga", "Andrea Rota", "Mark Lawford", "Claudio Menghi"], "title": "Feature-Guided Analysis of Neural Networks: A Replication Study", "comment": null, "summary": "Understanding why neural networks make certain decisions is pivotal for their\nuse in safety-critical applications. Feature-Guided Analysis (FGA) extracts\nslices of neural networks relevant to their tasks. Existing feature-guided\napproaches typically monitor the activation of the neural network neurons to\nextract the relevant rules. Preliminary results are encouraging and demonstrate\nthe feasibility of this solution by assessing the precision and recall of\nFeature-Guided Analysis on two pilot case studies. However, the applicability\nin industrial contexts needs additional empirical evidence.\n  To mitigate this need, this paper assesses the applicability of FGA on a\nbenchmark made by the MNIST and LSC datasets. We assessed the effectiveness of\nFGA in computing rules that explain the behavior of the neural network. Our\nresults show that FGA has a higher precision on our benchmark than the results\nfrom the literature. We also evaluated how the selection of the neural network\narchitecture, training, and feature selection affect the effectiveness of FGA.\nOur results show that the selection significantly affects the recall of FGA,\nwhile it has a negligible impact on its precision.", "AI": {"tldr": "Applying Feature-Guided Analysis (FGA) to a MNIST/LSC benchmark yields higher precision than prior studies; recall is sensitive to network architecture, training, and feature selection, while precision is largely robust.", "motivation": "To provide empirical evidence of FGA's applicability in industrial/safety-critical contexts by evaluating it on a realistic benchmark and examining how modeling choices affect its explanations.", "method": "Empirical evaluation of FGA on a MNIST+LSC benchmark to compute rules explaining neural network behavior; analysis of how network architecture, training, and feature selection influence FGA effectiveness (precision and recall).", "result": "FGA achieved higher precision on the benchmark than results reported in the literature; recall is significantly affected by architecture, training, and feature selection, whereas precision is largely unaffected by these factors.", "conclusion": "The study supports FGA's applicability on a realistic benchmark, showing robust precision but sensitivity of recall to modeling choices; optimizing architecture/training/feature selection can improve interpretability via FGA, though broader empirical validation is advised."}}
{"id": "2511.00424", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00424", "abs": "https://arxiv.org/abs/2511.00424", "authors": ["Ashutosh Anshul", "Gumpili Sai Pranav", "Mohammad Zia Ur Rehman", "Nagendra Kumar"], "title": "A Multimodal Framework for Depression Detection during Covid-19 via Harvesting Social Media: A Novel Dataset and Method", "comment": null, "summary": "The recent coronavirus disease (Covid-19) has become a pandemic and has\naffected the entire globe. During the pandemic, we have observed a spike in\ncases related to mental health, such as anxiety, stress, and depression.\nDepression significantly influences most diseases worldwide, making it\ndifficult to detect mental health conditions in people due to unawareness and\nunwillingness to consult a doctor. However, nowadays, people extensively use\nonline social media platforms to express their emotions and thoughts. Hence,\nsocial media platforms are now becoming a large data source that can be\nutilized for detecting depression and mental illness. However, existing\napproaches often overlook data sparsity in tweets and the multimodal aspects of\nsocial media. In this paper, we propose a novel multimodal framework that\ncombines textual, user-specific, and image analysis to detect depression among\nsocial media users. To provide enough context about the user's emotional state,\nwe propose (i) an extrinsic feature by harnessing the URLs present in tweets\nand (ii) extracting textual content present in images posted in tweets. We also\nextract five sets of features belonging to different modalities to describe a\nuser. Additionally, we introduce a Deep Learning model, the Visual Neural\nNetwork (VNN), to generate embeddings of user-posted images, which are used to\ncreate the visual feature vector for prediction. We contribute a curated\nCovid-19 dataset of depressed and non-depressed users for research purposes and\ndemonstrate the effectiveness of our model in detecting depression during the\nCovid-19 outbreak. Our model outperforms existing state-of-the-art methods over\na benchmark dataset by 2%-8% and produces promising results on the Covid-19\ndataset. Our analysis highlights the impact of each modality and provides\nvaluable insights into users' mental and emotional states.", "AI": {"tldr": "A multimodal deep learning framework for depression detection on social media during Covid-19, merging textual cues, user-specific signals, and visual content. It introduces a Visual Neural Network (VNN) to embed images, uses extrinsic features like tweet URLs and text in posted images, and evaluates on a Covid-19 dataset where it outperforms baselines by 2\u20138%.", "motivation": "Covid-19 aggravated mental health issues and created a need for scalable detection methods. Existing approaches struggle with data sparsity in tweets and ignore multimodal signals (text, user context, images). Social media offers rich, diverse signals for early depression detection, but leveraging them requires cross-modal integration and robust handling of sparse data.", "method": "Proposed a multimodal framework that aggregates five modality-based feature sets: textual content, user-specific signals, image-derived features, extrinsic URL-based context, and textual content extracted from images. A new Visual Neural Network (VNN) generates embeddings for user-posted images to form a visual feature vector. Features from all modalities are combined for depression prediction. A curated Covid-19 depression dataset is used, and performance is compared against state-of-the-art baselines.", "result": "The model outperforms existing state-of-the-art methods on a benchmark dataset by 2%\u20138% and shows promising results on the Covid-19 dataset. An analysis highlights the contribution of each modality and provides insights into users\u2019 mental and emotional states.", "conclusion": "A novel, multi-modal approach that integrates textual cues, user context, and image data (including extracted image text and URL context) enhances depression detection on social media during Covid-19. The work demonstrates the value of the Visual Neural Network for image embeddings and underscores the importance of modality-specific contributions for robust mental health monitoring."}}
{"id": "2511.00103", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00103", "abs": "https://arxiv.org/abs/2511.00103", "authors": ["Rotem Ezra", "Hedi Zisling", "Nimrod Berman", "Ilan Naiman", "Alexey Gorkor", "Liran Nochumsohn", "Eliya Nachmani", "Omri Azencot"], "title": "FreeSliders: Training-Free, Modality-Agnostic Concept Sliders for Fine-Grained Diffusion Control in Images, Audio, and Video", "comment": null, "summary": "Diffusion models have become state-of-the-art generative models for images,\naudio, and video, yet enabling fine-grained controllable generation, i.e.,\ncontinuously steering specific concepts without disturbing unrelated content,\nremains challenging. Concept Sliders (CS) offer a promising direction by\ndiscovering semantic directions through textual contrasts, but they require\nper-concept training and architecture-specific fine-tuning (e.g., LoRA),\nlimiting scalability to new modalities. In this work we introduce FreeSliders,\na simple yet effective approach that is fully training-free and\nmodality-agnostic, achieved by partially estimating the CS formula during\ninference. To support modality-agnostic evaluation, we extend the CS benchmark\nto include both video and audio, establishing the first suite for fine-grained\nconcept generation control with multiple modalities. We further propose three\nevaluation properties along with new metrics to improve evaluation quality.\nFinally, we identify an open problem of scale selection and non-linear\ntraversals and introduce a two-stage procedure that automatically detects\nsaturation points and reparameterizes traversal for perceptually uniform,\nsemantically meaningful edits. Extensive experiments demonstrate that our\nmethod enables plug-and-play, training-free concept control across modalities,\nimproves over existing baselines, and establishes new tools for principled\ncontrollable generation. An interactive presentation of our benchmark and\nmethod is available at: https://azencot-group.github.io/FreeSliders/", "AI": {"tldr": "FreeSliders enables training-free, modality-agnostic, fine-grained controllable generation across diffusion-model modalities by partially estimating the concept-sliders formula at inference; extends the CS benchmark to video and audio; introduces a two-stage saturation-aware reparameterization and new evaluation metrics, achieving plug-and-play improvements over baselines.", "motivation": "Controllable generation with diffusion models across multiple modalities remains challenging; existing Concept Sliders (CS) require per-concept training and architecture-specific fine-tuning, hindering scalability to new modalities like video and audio. A training-free, modality-agnostic approach is highly desirable.", "method": "At inference time, partially estimate the CS formula to enable concept sliders without per-concept training. Extend the CS benchmark to video and audio. Propose three evaluation properties and new metrics. Introduce a two-stage procedure to automatically detect saturation points and reparameterize traversal for perceptually uniform, semantically meaningful edits.", "result": "Empirically, FreeSliders provides plug-and-play, training-free concept control across multiple modalities, outperforming existing baselines. It also expands the CS benchmark to cover video and audio and establishes tools and metrics for principled evaluation.", "conclusion": "FreeSliders offers a simple, training-free, modality-agnostic route to fine-grained controllable generation with diffusion models. It identifies scale selection and non-linear traversals as open problems and presents a two-stage saturation-aware reparameterization along with a multimodal benchmark and evaluation toolkit."}}
{"id": "2511.00492", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00492", "abs": "https://arxiv.org/abs/2511.00492", "authors": ["Simon Giel", "James Hurrell", "Shreya Santra", "Ashutosh Mishra", "Kentaro Uno", "Kazuya Yoshida"], "title": "Design and Development of a Modular Bucket Drum Excavator for Lunar ISRU", "comment": "6 pages, 4 figures. Accepted at IEEE iSpaRo 2025", "summary": "In-Situ Resource Utilization (ISRU) is one of the key technologies for\nenabling sustainable access to the Moon. The ability to excavate lunar regolith\nis the first step in making lunar resources accessible and usable. This work\npresents the development of a bucket drum for the modular robotic system\nMoonBot, as part of the Japanese Moonshot program. A 3D-printed prototype made\nof PLA was manufactured to evaluate its efficiency through a series of sandbox\ntests. The resulting tool weighs 4.8 kg and has a volume of 14.06 L. It is\ncapable of continuous excavation at a rate of 777.54 kg/h with a normalized\nenergy consumption of 0.022 Wh/kg. In batch operation, the excavation rate is\n172.02 kg/h with a normalized energy consumption of 0.86 Wh per kilogram of\nexcavated material. The obtained results demonstrate the successful\nimplementation of the concept. A key advantage of the developed tool is its\ncompatibility with the modular MoonBot robotic platform, which enables flexible\nand efficient mission planning. Further improvements may include the\nintegration of sensors and an autonomous control system to enhance the\nexcavation process.", "AI": {"tldr": "3D-printed PLA bucket drum for MoonBot demonstrates viable lunar excavation with high mass throughput and low energy, showing compatibility with the modular platform and potential for autonomous enhancements.", "motivation": "Enable sustainable lunar access via ISRU by extracting lunar regolith; this study contributes to a practical, modular excavation tool for resource utilization under the Moonshot program.", "method": "Prototype bucket drum fabricated by 3D printing (PLA); sandbox tests to measure continuous and batch excavation rates and energy per kilogram, plus assessment of size and compatibility with MoonBot.", "result": "Mass throughput: continuous 777.54 kg/h; energy intensity 0.022 Wh/kg. Batch throughput: 172.02 kg/h; energy intensity 0.86 Wh/kg. Tool weight 4.8 kg; volume 14.06 L. 3D-printed PLLA; demonstrated compatibility with MoonBot; autonomous sensor integration suggested as future enhancement.", "conclusion": "The concept is successfully implemented; the tool's modular compatibility supports flexible mission planning for lunar ISRU; future work should integrate sensors and autonomous control to improve excavation efficiency and autonomy."}}
{"id": "2511.00053", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00053", "abs": "https://arxiv.org/abs/2511.00053", "authors": ["Hao Wang", "Licheng Pan", "Yuan Lu", "Zhichao Chen", "Tianqiao Liu", "Shuting He", "Zhixuan Chu", "Qingsong Wen", "Haoxuan Li", "Zhouchen Lin"], "title": "Quadratic Direct Forecast for Training Multi-Step Time-Series Forecast Models", "comment": null, "summary": "The design of training objective is central to training time-series\nforecasting models. Existing training objectives such as mean squared error\nmostly treat each future step as an independent, equally weighted task, which\nwe found leading to the following two issues: (1) overlook the label\nautocorrelation effect among future steps, leading to biased training\nobjective; (2) fail to set heterogeneous task weights for different forecasting\ntasks corresponding to varying future steps, limiting the forecasting\nperformance. To fill this gap, we propose a novel quadratic-form weighted\ntraining objective, addressing both of the issues simultaneously. Specifically,\nthe off-diagonal elements of the weighting matrix account for the label\nautocorrelation effect, whereas the non-uniform diagonals are expected to match\nthe most preferable weights of the forecasting tasks with varying future steps.\nTo achieve this, we propose a Quadratic Direct Forecast (QDF) learning\nalgorithm, which trains the forecast model using the adaptively updated\nquadratic-form weighting matrix. Experiments show that our QDF effectively\nimproves performance of various forecast models, achieving state-of-the-art\nresults. Code is available at https://anonymous.4open.science/r/QDF-8937.", "AI": {"tldr": "Quadratic Direct Forecast (QDF): a quadratic-form weighted loss that learns a weighting matrix to capture label autocorrelation and heterogeneity across forecast horizons, improving multi-step time-series forecasting with adaptive weighting and achieving state-of-the-art results.", "motivation": "Standard MSE-based objectives treat each future step independently with equal weight, ignoring autocorrelation among labels and the varying importance of forecast horizons, which biases training and limits performance.", "method": "Introduce a weighting matrix W for the multi-step forecast loss where off-diagonal entries model label autocorrelation and diagonal entries provide heterogeneous horizon weights. Employ an adaptive QDF learning algorithm that updates W during training, enabling a quadratic-form loss (e.g., y^T W y) that couples all steps.", "result": "Experiments show QDF improves the performance of various forecast models, achieving state-of-the-art results on the tested benchmarks.", "conclusion": "A quadratic-form weighting objective effectively addresses both label autocorrelation and horizon-specific weighting, yielding improved multi-step forecast accuracy and broad applicability; code is publicly available."}}
{"id": "2511.00457", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00457", "abs": "https://arxiv.org/abs/2511.00457", "authors": ["Chunyu Wei", "Wenji Hu", "Xingjia Hao", "Xin Wang", "Yifan Yang", "Yueguo Chen", "Yang Tian", "Yunhai Wang"], "title": "GraphChain: Large Language Models for Large-scale Graph Analysis via Tool Chaining", "comment": null, "summary": "Large Language Models (LLMs) face significant limitations when applied to\nlarge-scale graphs, struggling with context constraints and inflexible\nreasoning. We present GraphChain, a framework that enables LLMs to analyze\ncomplex graphs through dynamic sequences of specialized tools, mimicking human\nexploratory intelligence. Our approach introduces two key innovations: (1)\nProgressive Graph Distillation, a reinforcement learning mechanism that\ngenerates optimized tool sequences balancing task relevance with information\ncompression, and (2) Structure-aware Test-Time Adaptation, which efficiently\ntailors tool selection strategies to diverse graph topologies using spectral\nproperties and lightweight adapters without costly retraining. Experiments show\nGraphChain significantly outperforms prior methods, enabling scalable and\nadaptive LLM-driven graph analysis.", "AI": {"tldr": "GraphChain enables LLMs to analyze large graphs through dynamic tool sequences, using progressive graph distillation and structure-aware test-time adaptation to improve scalability and adaptability.", "motivation": "LLMs struggle with context constraints and rigid reasoning on large-scale graphs; there is a need for scalable, adaptive, and efficient graph analysis by LLMs.", "method": "1) Progressive Graph Distillation: a reinforcement learning mechanism that learns optimized sequences of specialized tools balancing task relevance and information compression. 2) Structure-aware Test-Time Adaptation: tailors tool selection to diverse graph topologies using spectral properties and lightweight adapters without expensive retraining.", "result": "Experiments show GraphChain significantly outperforms prior methods, enabling scalable and adaptive LLM-driven graph analysis.", "conclusion": "GraphChain demonstrates a practical framework for connecting LLMs to large graphs via adaptive tool orchestration, achieving scalable, flexible, and effective graph analytics."}}
{"id": "2511.00107", "categories": ["cs.CV", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00107", "abs": "https://arxiv.org/abs/2511.00107", "authors": ["Piyushkumar Patel"], "title": "AI Powered High Quality Text to Video Generation with Enhanced Temporal Consistency", "comment": null, "summary": "Text to video generation has emerged as a critical frontier in generative\nartificial intelligence, yet existing approaches struggle with maintaining\ntemporal consistency, compositional understanding, and fine grained control\nover visual narratives. We present MOVAI (Multimodal Original Video AI), a\nnovel hierarchical framework that integrates compositional scene understanding\nwith temporal aware diffusion models for high fidelity text to video synthesis.\nOur approach introduces three key innovations: (1) a Compositional Scene Parser\n(CSP) that decomposes textual descriptions into hierarchical scene graphs with\ntemporal annotations, (2) a Temporal-Spatial Attention Mechanism (TSAM) that\nensures coherent motion dynamics across frames while preserving spatial\ndetails, and (3) a Progressive Video Refinement (PVR) module that iteratively\nenhances video quality through multi-scale temporal reasoning. Extensive\nexperiments on standard benchmarks demonstrate that MOVAI achieves\nstate-of-the-art performance, improving video quality metrics by 15.3% in\nLPIPS, 12.7% in FVD, and 18.9% in user preference studies compared to existing\nmethods. Our framework shows particular strength in generating complex\nmulti-object scenes with realistic temporal dynamics and fine-grained semantic\ncontrol.", "AI": {"tldr": "MOVAI presents a hierarchical, multimodal approach to text-to-video with CSP, TSAM, and PVR, achieving state-of-the-art results on standard benchmarks.", "motivation": "Text-to-video generation struggles with temporal coherence, compositional understanding, and controllability; a framework that integrates scene parsing with temporal diffusion is needed.", "method": "Three innovations: (1) Compositional Scene Parser (CSP) for hierarchical, temporally annotated scene graphs; (2) Temporal-Spatial Attention Mechanism (TSAM) for coherent motion and spatial detail; (3) Progressive Video Refinement (PVR) for multi-scale temporal refinement.", "result": "Empirical results on standard benchmarks show improvements: 15.3% in LPIPS, 12.7% in FVD, and 18.9% in user preference studies over existing methods.", "conclusion": "MOVAI delivers state-of-the-art video quality and strong performance in complex multi-object scenes with realistic temporal dynamics and fine-grained semantic control."}}
{"id": "2511.00512", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00512", "abs": "https://arxiv.org/abs/2511.00512", "authors": ["Suraj Kumar", "Andy Ruina"], "title": "Descriptive Model-based Learning and Control for Bipedal Locomotion", "comment": "8 pages, 15 figures", "summary": "Bipedal balance is challenging due to its multi-phase, hybrid nature and\nhigh-dimensional state space. Traditional balance control approaches for\nbipedal robots rely on low-dimensional models for locomotion planning and\nreactive control, constraining the full robot to behave like these simplified\nmodels. This involves tracking preset reference paths for the Center of Mass\nand upper body obtained through low-dimensional models, often resulting in\ninefficient walking patterns with bent knees. However, we observe that bipedal\nbalance is inherently low-dimensional and can be effectively described with\nsimple state and action descriptors in a low-dimensional state space. This\nallows the robot's motion to evolve freely in its high-dimensional state space,\nonly constraining its projection in the low-dimensional state space. In this\nwork, we propose a novel control approach that avoids prescribing a\nlow-dimensional model to the full model. Instead, our control framework uses a\ndescriptive model with the minimum degrees of freedom necessary to maintain\nbalance, allowing the remaining degrees of freedom to evolve freely in the\nhigh-dimensional space. This results in an efficient human-like walking gait\nand improved robustness.", "AI": {"tldr": "A descriptive, minimal-DOF control framework for bipedal balance extends free-space high-dimensional dynamics while constraining only the low-dimensional projection, yielding efficient, robust gait without prescribing a full low-dimensional model.", "motivation": "Current bipedal balance methods rely on low-dimensional models, which constrains full robot behavior and often leads to inefficient, bent-knee gaits. The work posits that balance is inherently low-dimensional and seeks to exploit high-dimensional state spaces by only constraining a low-dimensional projection.", "method": "Introduce a descriptive model with the minimum degrees of freedom necessary to maintain balance and allow remaining high-dimensional DOF to evolve freely. The control framework avoids prescribing a full low-dimensional model to the entire robot and instead constrains only the low-dimensional projection.", "result": "The approach yields an efficient, human-like walking gait and improved robustness, by leveraging low-dimensional balance descriptors while letting high-dimensional dynamics unfold freely.", "conclusion": "Bipedal balance can be effectively controlled using minimal DOF descriptors that guard the low-dimensional projection; full high-dimensional motion is permitted in unconstrained spaces, enabling robust and efficient gait without reliance on conventional low-dimensional walking models."}}
{"id": "2511.00054", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00054", "abs": "https://arxiv.org/abs/2511.00054", "authors": ["Gio Huh", "Dhruv Sheth", "Rayhan Zirvi", "Frank Xiao"], "title": "SpatialTraceGen: High-Fidelity Traces for Efficient VLM Spatial Reasoning Distillation", "comment": "Accepted to the 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025) Workshop on Efficient Reasoning", "summary": "While Vision-Language Models (VLMs) excel in many areas, they struggle with\ncomplex spatial reasoning, which requires problem decomposition and strategic\ntool use. Fine-tuning smaller, more deployable models offers an efficient path\nto strong performance, but this is hampered by a major bottleneck: the absence\nof high-quality, step-by-step reasoning data. To address this data-efficiency\ngap, we introduce SpatialTraceGen, a framework to distill the reasoning\nprocesses of a large teacher model into a high-quality dataset of multi-hop,\nmulti-tool reasoning traces. A key innovation is our automated Verifier, which\nscalably ensures the fidelity of each reasoning step, providing a\ncost-effective alternative to manual human annotation. On the CLEVR-Humans\nbenchmark, this verifier-guided process improves the average quality score of\ntraces by 17\\% while reducing quality variance by over 40\\%. SpatialTraceGen\ndelivers a dataset of expert traces, providing the structured, step-by-step\nexamples of tool use necessary for effective fine-tuning and sample-efficient\noffline reinforcement learning.", "AI": {"tldr": "A scalable method (SpatialTraceGen) to distill large-model reasoning into high-quality, multi-hop, multi-tool reasoning traces for vision-language models, using an automated verifier to ensure fidelity. This data enables efficient fine-tuning and offline RL while reducing annotation cost.", "motivation": "To overcome the data bottleneck for training VLMs on complex spatial reasoning, which requires step-by-step reasoning traces and strategic tool use that are costly to annotate manually.", "method": "Distill reasoning from a large teacher into a dataset of multi-hop, multi-tool traces (SpatialTraceGen). Introduce an automated Verifier that scales fidelity checks for each reasoning step, reducing reliance on human annotation.", "result": "On CLEVR-Humans, verifier-guided traces show a 17% improvement in average trace quality and a >40% reduction in quality variance. The approach yields an expert-trace dataset suitable for fine-tuning and sample-efficient offline reinforcement learning.", "conclusion": "SpatialTraceGen delivers high-quality, structured reasoning traces and a scalable verification pipeline, enabling effective fine-tuning and offline RL for VLMs in complex spatial tasks while lowering annotation costs."}}
{"id": "2511.00509", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00509", "abs": "https://arxiv.org/abs/2511.00509", "authors": ["Yifan Xia", "Guorui Chen", "Wenqian Yu", "Zhijiang Li", "Philip Torr", "Jindong Gu"], "title": "Reimagining Safety Alignment with An Image", "comment": null, "summary": "Large language models (LLMs) excel in diverse applications but face dual\nchallenges: generating harmful content under jailbreak attacks and over-refusal\nof benign queries due to rigid safety mechanisms. These issues are further\ncomplicated by the need to accommodate different value systems and precisely\nalign with given safety preferences. Moreover, traditional methods like SFT and\nRLHF lack this capability due to their costly parameter tuning requirements and\ninability to support multiple value systems within a single model. These\nproblems are more obvious in multimodal large language models (MLLMs),\nespecially in terms of heightened over-refusal in cross-modal tasks and new\nsecurity risks arising from expanded attack surfaces. We propose Magic Image,\nan optimization-driven visual prompt framework that enhances security while\nreducing over-refusal. By optimizing image prompts using harmful/benign\nsamples, our method enables a single model to adapt to different value systems\nand better align with given safety preferences without parameter updates.\nExperiments demonstrate improved safety-effectiveness balance across diverse\ndatasets while preserving model performance, offering a practical solution for\ndeployable MLLM safety alignment.", "AI": {"tldr": "Magic Image is an optimization-driven visual prompting approach that aligns safety preferences in multimodal LLMs without retraining, improving safety effectiveness while reducing over-refusal.", "motivation": "LLMs and especially multimodal LLMs face dual safety challenges: generating harmful content under jailbreak attempts and over-refusing benign queries due to rigid safety guards. Existing fine-tuning methods (SFT/RLHF) are costly and struggle to accommodate multiple value systems within a single model, increasing the risk in cross-modal tasks and expanding attack surfaces.", "method": "An optimization-driven visual prompt framework that tunes image prompts using harmful and benign samples to steer the model\u2019s safety behavior. This allows a single model to adapt to different value systems and align with specified safety preferences without updating model parameters.", "result": "Experiments show an improved balance between safety and utility across diverse datasets while preserving overall model performance, offering a practical, deployable solution for safety alignment in multimodal models.", "conclusion": "Visual prompts can effectively and flexibly align safety preferences for multimodal models without retraining, addressing over-refusal and security concerns across multiple value systems."}}
{"id": "2511.00110", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00110", "abs": "https://arxiv.org/abs/2511.00110", "authors": ["YingQiao Wang", "Eric Bigelow", "Boyi Li", "Tomer Ullman"], "title": "Chain of Time: In-Context Physical Simulation with Image Generation Models", "comment": null, "summary": "We propose a novel cognitively-inspired method to improve and interpret\nphysical simulation in vision-language models. Our ``Chain of Time\" method\ninvolves generating a series of intermediate images during a simulation, and it\nis motivated by in-context reasoning in machine learning, as well as mental\nsimulation in humans. Chain of Time is used at inference time, and requires no\nadditional fine-tuning. We apply the Chain-of-Time method to synthetic and\nreal-world domains, including 2-D graphics simulations and natural 3-D videos.\nThese domains test a variety of particular physical properties, including\nvelocity, acceleration, fluid dynamics, and conservation of momentum. We found\nthat using Chain-of-Time simulation substantially improves the performance of a\nstate-of-the-art image generation model. Beyond examining performance, we also\nanalyzed the specific states of the world simulated by an image model at each\ntime step, which sheds light on the dynamics underlying these simulations. This\nanalysis reveals insights that are hidden from traditional evaluations of\nphysical reasoning, including cases where an image generation model is able to\nsimulate physical properties that unfold over time, such as velocity, gravity,\nand collisions. Our analysis also highlights particular cases where the image\ngeneration model struggles to infer particular physical parameters from input\nimages, despite being capable of simulating relevant physical processes.", "AI": {"tldr": "Introduce Chain of Time, a cognitively inspired, inference-time method that generates a sequence of intermediate frames to simulate physics, boosting and interpreting physical reasoning in vision-language models without fine-tuning, tested on 2D graphics and real 3D videos across velocity, acceleration, fluid dynamics, and momentum.", "motivation": "Improve physical reasoning and interpretability in vision-language models by emulating human mental simulation and in-context reasoning; provide temporal insights into the model's internal dynamics.", "method": "Chain of Time generates intermediate frames during inference (no fine-tuning) to simulate a temporal trajectory. It is applied to both synthetic 2D graphics and real 3D videos to probe properties like velocity, acceleration, fluid dynamics, and momentum; analyzes the world states at each time step to understand dynamics and identify failures.", "result": "Yields substantial improvement in a state-of-the-art image-generation model. Provides insights into dynamics (e.g., velocity, gravity, collisions) that traditional evaluations miss. Reveals cases where the model can simulate time-evolving physical properties and where it struggles to infer certain physical parameters.", "conclusion": "A simple, inference-time augmentation that enhances physical simulation and interpretability in vision-language models. It reveals temporal dynamics and can guide future model improvements, while also exposing specific failure modes in parameter inference."}}
{"id": "2511.00516", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00516", "abs": "https://arxiv.org/abs/2511.00516", "authors": ["Peiyi Wang", "Paul A. M. Lefeuvre", "Shangwei Zou", "Zhenwei Ni", "Daniela Rus", "Cecilia Laschi"], "title": "Adaptive and Multi-object Grasping via Deformable Origami Modules", "comment": null, "summary": "Soft robotics gripper have shown great promise in handling fragile and\ngeometrically complex objects. However, most existing solutions rely on bulky\nactuators, complex control strategies, or advanced tactile sensing to achieve\nstable and reliable grasping performance. In this work, we present a\nmulti-finger hybrid gripper featuring passively deformable origami modules that\ngenerate constant force and torque output. Each finger composed of parallel\norigami modules is driven by a 1-DoF actuator mechanism, enabling passive shape\nadaptability and stable grasping force without active sensing or feedback\ncontrol. More importantly, we demonstrate an interesting capability in\nsimultaneous multi-object grasping, which allows stacked objects of varied\nshape and size to be picked, transported and placed independently at different\nstates, significantly improving manipulation efficiency compared to\nsingle-object grasping. These results highlight the potential of origami-based\ncompliant structures as scalable modules for adaptive, stable and efficient\nmulti-object manipulation in domestic and industrial pick-and-place scenarios.", "AI": {"tldr": "Soft gripper with passively deformable origami fingers driven by a 1-DoF actuator achieves constant force/torque and enables simultaneous multi-object grasping without sensing, improving pick-and-place efficiency.", "motivation": "Address the need for stable grasping of fragile or geometrically complex objects without bulky actuators or complex sensing/control; enable efficient multi-object manipulation.", "method": "A multi-finger hybrid gripper uses parallel origami modules per finger driven by a 1-DoF actuator, providing passive adaptability and constant output without active sensing; demonstrates simultaneous grasping of stacked objects of varied shapes/sizes and independent placement.", "result": "The gripper can grasp multiple objects simultaneously and manipulate them independently with stable grasping and no active sensing, improving manipulation efficiency over single-object grasping.", "conclusion": "Origami-based compliant structures are scalable modules for adaptive, stable, and efficient multi-object manipulation in domestic and industrial settings."}}
{"id": "2511.00055", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00055", "abs": "https://arxiv.org/abs/2511.00055", "authors": ["Leonhard Duda", "Khadijeh Alibabaei", "Elena Vollmer", "Leon Klug", "Valentin Kozlov", "Lisana Berberi", "Mishal Benz", "Rebekka Volk", "Juan Pedro Guti\u00e9rrez Hermosillo Muriedas", "Markus G\u00f6tz", "Judith S\u00e1\u00ednz-Pardo D\u00edaz", "\u00c1lvaro L\u00f3pez Garc\u00eda", "Frank Schultmann", "Achim Streit"], "title": "Exploring Federated Learning for Thermal Urban Feature Segmentation -- A Comparison of Centralized and Decentralized Approaches", "comment": null, "summary": "Federated Learning (FL) is an approach for training a shared Machine Learning\n(ML) model with distributed training data and multiple participants. FL allows\nbypassing limitations of the traditional Centralized Machine Learning CL if\ndata cannot be shared or stored centrally due to privacy or technical\nrestrictions -- the participants train the model locally with their training\ndata and do not need to share it among the other participants. This paper\ninvestigates the practical implementation and effectiveness of FL in a\nreal-world scenario, specifically focusing on unmanned aerial vehicle\n(UAV)-based thermal images for common thermal feature detection in urban\nenvironments. The distributed nature of the data arises naturally and makes it\nsuitable for FL applications, as images captured in two German cities are\navailable. This application presents unique challenges due to non-identical\ndistribution and feature characteristics of data captured at both locations.\nThe study makes several key contributions by evaluating FL algorithms in real\ndeployment scenarios rather than simulation. We compare several FL approaches\nwith a centralized learning baseline across key performance metrics such as\nmodel accuracy, training time, communication overhead, and energy usage. This\npaper also explores various FL workflows, comparing client-controlled workflows\nand server-controlled workflows. The findings of this work serve as a valuable\nreference for understanding the practical application and limitations of the FL\nmethods in segmentation tasks in UAV-based imaging.", "AI": {"tldr": "Federated Learning (FL) is evaluated for UAV-based thermal-image segmentation across two German cities, focusing on real-world deployment vs centralized learning. The study compares FL workflows and several FL approaches under non-identical data distributions, reporting on accuracy, training time, communication overhead, and energy use; it discusses practical FL limitations and provides insights for real-world UAV imaging applications.", "motivation": "The need to train ML models without sharing raw data due to privacy/technical constraints, particularly for UAV-based urban thermal imaging where data collection is distributed and heterogeneous.", "method": "Real-world deployment study comparing multiple FL approaches against a centralized baseline. Data collected from UAVs in two German cities, with non-identical distributions. Evaluation across accuracy, training time, communication overhead, and energy use. Comparison of client-controlled versus server-controlled FL workflows. Likely inclusion of standard FL algorithms (e.g., FedAvg) applied to UAV thermal image segmentation.", "result": "FL methods can approach centralized baseline performance but exhibit trade-offs. Non-iid data across cities impacts accuracy. FL increases training time and communication/energy overhead due to distributed optimization and wireless transmission. Server-controlled workflows may reduce client-side burden; client-controlled workflows give more autonomy but may increase coordination complexity. Real-world deployment reveals practical limitations and operational considerations not captured in simulations.", "conclusion": "Real-world FL deployment for UAV-based segmentation is feasible but comes with notable practical challenges, including data heterogeneity, resource constraints, and workflow choices. The study provides empirical guidance on which FL workflows to adopt and highlights areas for future improvement in robustness, efficiency, and deployment strategies."}}
{"id": "2511.00547", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00547", "abs": "https://arxiv.org/abs/2511.00547", "authors": ["Alain Riou"], "title": "Efficient Generation of Binary Magic Squares", "comment": null, "summary": "We propose a simple algorithm for generating Binary Magic Squares (BMS),\ni.e., square binary matrices where the sum of all rows and all columns are\nequal. We show by induction that our algorithm always returns valid BMS with\noptimal theoretical complexity. We then extend our study to non-square Binary\nMagic Squares, formalize conditions on the sum of rows and columns for these\nBMS to exist, and show that a slight variant of our first algorithm can\ngenerate provably generate them. Finally, we publicly release two\nimplementations of our algorithm as Python packages, including one that can\ngenerate several BMS in parallel using GPU acceleration.", "AI": {"tldr": "A simple, provably correct algorithm for generating Binary Magic Squares (BMS) with optimal complexity, extended to non-square BMS, plus open-source Python implementations including a GPU-accelerated parallel generator.", "motivation": "To efficiently construct Binary Magic Squares with guarantees of correctness, and to formalize existence conditions for non-square BMS, providing practical tools.", "method": "Prove by induction that the base algorithm always yields valid BMS with optimal theoretical complexity; extend to non-square BMS by formalizing row/column sum conditions; introduce a variant that generates non-square BMS; release two Python packages, including a GPU-accelerated parallel version.", "result": "Demonstrates correctness and optimal complexity for square BMS; provides formal existence conditions for non-square BMS; releases two Python packages, one supporting parallel generation on GPUs.", "conclusion": "Offers a provable, efficient algorithmic framework for both square and non-square Binary Magic Squares with ready-to-use implementations."}}
{"id": "2511.00114", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00114", "abs": "https://arxiv.org/abs/2511.00114", "authors": ["Hanae Elmekki", "Amanda Spilkin", "Ehsan Zakeri", "Antonela Mariel Zanuttini", "Ahmed Alagha", "Hani Sami", "Jamal Bentahar", "Lyes Kadem", "Wen-Fang Xie", "Philippe Pibarot", "Rabeb Mizouni", "Hadi Otrok", "Azzam Mourad", "Sami Muhaidat"], "title": "End-to-End Framework Integrating Generative AI and Deep Reinforcement Learning for Autonomous Ultrasound Scanning", "comment": null, "summary": "Cardiac ultrasound (US) is among the most widely used diagnostic tools in\ncardiology for assessing heart health, but its effectiveness is limited by\noperator dependence, time constraints, and human error. The shortage of trained\nprofessionals, especially in remote areas, further restricts access. These\nissues underscore the need for automated solutions that can ensure consistent,\nand accessible cardiac imaging regardless of operator skill or location. Recent\nprogress in artificial intelligence (AI), especially in deep reinforcement\nlearning (DRL), has gained attention for enabling autonomous decision-making.\nHowever, existing DRL-based approaches to cardiac US scanning lack\nreproducibility, rely on proprietary data, and use simplified models. Motivated\nby these gaps, we present the first end-to-end framework that integrates\ngenerative AI and DRL to enable autonomous and reproducible cardiac US\nscanning. The framework comprises two components: (i) a conditional generative\nsimulator combining Generative Adversarial Networks (GANs) with Variational\nAutoencoders (VAEs), that models the cardiac US environment producing realistic\naction-conditioned images; and (ii) a DRL module that leverages this simulator\nto learn autonomous, accurate scanning policies. The proposed framework\ndelivers AI-driven guidance through expert-validated models that classify image\ntype and assess quality, supports conditional generation of realistic US\nimages, and establishes a reproducible foundation extendable to other organs.\nTo ensure reproducibility, a publicly available dataset of real cardiac US\nscans is released. The solution is validated through several experiments. The\nVAE-GAN is benchmarked against existing GAN variants, with performance assessed\nusing qualitative and quantitative approaches, while the DRL-based scanning\nsystem is evaluated under varying configurations to demonstrate effectiveness.", "AI": {"tldr": "An end-to-end framework combining a GAN+VAE-based conditional simulator with a DRL agent to autonomously and reproducibly perform cardiac ultrasound scanning, with a public dataset and validated results.", "motivation": "Cardiac ultrasound is highly operator-dependent, time-constrained, and scarce in remote areas. Prior DRL approaches lack reproducibility, rely on proprietary data, and use simplified models. There is a need for automated, reproducible, accessible ultrasound scanning.", "method": "Develop a two-part system: (1) a conditional generative simulator (GAN + VAE) that models the cardiac US environment and produces action-conditioned, realistic images; (2) a DRL module trained in this simulator to learn autonomous, accurate scanning policies. The framework includes expert-validated models for image-type classification and quality assessment, conditional generation of realistic US images, and release of a real cardiac US dataset to enable reproducibility.", "result": "The framework delivers AI-driven guidance for cardiac US scanning, supports classification of image type and assessment of image quality, enables conditional generation of realistic US images, and provides a reproducible foundation. The VAE-GAN is benchmarked against existing GAN variants, with qualitative and quantitative evaluation, while the DRL-based scanning system is tested under varying configurations to demonstrate effectiveness.", "conclusion": "This work presents the first end-to-end, reproducible framework combining generative AI and DRL for autonomous cardiac US scanning, with a publicly released real US dataset, and a foundation extendable to imaging other organs."}}
{"id": "2511.00555", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00555", "abs": "https://arxiv.org/abs/2511.00555", "authors": ["Dianye Huang", "Nassir Navab", "Zhongliang Jiang"], "title": "Improving Robustness to Out-of-Distribution States in Imitation Learning via Deep Koopman-Boosted Diffusion Policy", "comment": "Accepted by IEEE T-RO", "summary": "Integrating generative models with action chunking has shown significant\npromise in imitation learning for robotic manipulation. However, the existing\ndiffusion-based paradigm often struggles to capture strong temporal\ndependencies across multiple steps, particularly when incorporating\nproprioceptive input. This limitation can lead to task failures, where the\npolicy overfits to proprioceptive cues at the expense of capturing the visually\nderived features of the task. To overcome this challenge, we propose the Deep\nKoopman-boosted Dual-branch Diffusion Policy (D3P) algorithm. D3P introduces a\ndual-branch architecture to decouple the roles of different sensory modality\ncombinations. The visual branch encodes the visual observations to indicate\ntask progression, while the fused branch integrates both visual and\nproprioceptive inputs for precise manipulation. Within this architecture, when\nthe robot fails to accomplish intermediate goals, such as grasping a drawer\nhandle, the policy can dynamically switch to execute action chunks generated by\nthe visual branch, allowing recovery to previously observed states and\nfacilitating retrial of the task. To further enhance visual representation\nlearning, we incorporate a Deep Koopman Operator module that captures\nstructured temporal dynamics from visual inputs. During inference, we use the\ntest-time loss of the generative model as a confidence signal to guide the\naggregation of the temporally overlapping predicted action chunks, thereby\nenhancing the reliability of policy execution. In simulation experiments across\nsix RLBench tabletop tasks, D3P outperforms the state-of-the-art diffusion\npolicy by an average of 14.6\\%. On three real-world robotic manipulation tasks,\nit achieves a 15.0\\% improvement. Code: https://github.com/dianyeHuang/D3P.", "AI": {"tldr": "D3P is a dual-branch diffusion policy with a Deep Koopman module that decouples visual and proprioceptive inputs to improve imitation learning for robotic manipulation, enabling recovery via visual-chunk policies and robust temporal modeling.", "motivation": "Diffusion-based imitation learning struggles with strong temporal dependencies and tends to overfit to proprioceptive cues, hindering leverage of visual task structure. A modality-decoupled, temporally aware policy with recovery mechanisms can improve robustness and performance in manipulation tasks.", "method": "Introduce a Dual-branch Diffusion Policy (D3P) with a visual branch and a fused branch. The visual branch encodes visual observations to indicate task progress; the fused branch integrates visual and proprioceptive inputs for manipulation. A Deep Koopman Operator module learns structured temporal dynamics from visual inputs. During inference, the test-time loss of the generative model serves as a confidence signal to gate aggregation of overlapping predicted action chunks, enhancing reliability. If intermediate goals fail (e.g., grasping), the policy switches to action chunks generated by the visual branch to recover to previously observed states. ", "result": "In RLBench tabletop tasks (6 tasks in simulation), D3P outperforms the state-of-the-art diffusion policy by 14.6% on average. In three real-world robotic manipulation tasks, it improves by 15.0%.", "conclusion": "D3P effectively decouples modalities and leverages temporal dynamics to improve robustness and performance in diffusion-based imitation learning for robotic manipulation, with a recovery mechanism via visual-chunk policies and a confidence-guided aggregation strategy. Code is available at the provided URL."}}
{"id": "2511.00056", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00056", "abs": "https://arxiv.org/abs/2511.00056", "authors": ["Yuxi Liu", "Renjia Deng", "Yutong He", "Xue Wang", "Tao Yao", "Kun Yuan"], "title": "MISA: Memory-Efficient LLMs Optimization with Module-wise Importance Sampling", "comment": null, "summary": "The substantial memory demands of pre-training and fine-tuning large language\nmodels (LLMs) require memory-efficient optimization algorithms. One promising\napproach is layer-wise optimization, which treats each transformer block as a\nsingle layer and optimizes it sequentially, while freezing the other layers to\nsave optimizer states and activations. Although effective, these methods ignore\nthe varying importance of the modules within each layer, leading to suboptimal\nperformance. Moreover, layer-wise sampling provides only limited memory\nsavings, as at least one full layer must remain active during optimization. To\novercome these limitations, we propose Module-wise Importance SAmpling (MISA),\na novel method that divides each layer into smaller modules and assigns\nimportance scores to each module. MISA uses a weighted random sampling\nmechanism to activate modules, provably reducing gradient variance compared to\nlayer-wise sampling. Additionally, we establish an \\(\\mathcal{O}(1/\\sqrt{K})\\)\nconvergence rate under non-convex and stochastic conditions, where $K$ is the\ntotal number of block updates, and provide a detailed memory analysis\nshowcasing MISA's superiority over existing baseline methods. Experiments on\ndiverse learning tasks validate the effectiveness of MISA. Source code is\navailable at https://github.com/pkumelon/MISA.", "AI": {"tldr": "Proposes Module-wise Importance Sampling (MISA) for memory-efficient training of LLMs by partitioning each transformer layer into modules, assigning importances, and activating modules via weighted sampling to reduce gradient variance and achieve provable convergence; shows memory and performance gains over layer-wise methods; code available.", "motivation": "Memory bottlenecks in pre-training and fine-tuning LLMs; layer-wise optimization reduces memory but ignores intra-layer module differences and still requires at least one full layer active; need finer-grained, variance-reducing, memory-efficient optimization.", "method": "Split each transformer layer into smaller modules, assign an importance score to each module, perform weighted random sampling to activate a subset of modules during optimization, derive variance reduction over naive layer-wise sampling, prove an O(1/\u221aK) convergence rate under non-convex stochastic conditions, and provide a memory-analysis comparing against baselines; experiments on diverse tasks; release code.", "result": "Demonstrates improved memory efficiency and training effectiveness compared to baselines; empirical validation across tasks; convergence guarantee; notable memory reductions; code available.", "conclusion": "MISA enables finer-grained, memory-efficient optimization by respecting module importance, surpassing layer-wise sampling; offers provable convergence and practical gains for training large LMs; potential for broader adoption and future work in designing module-level sampling schemes."}}
{"id": "2511.00551", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00551", "abs": "https://arxiv.org/abs/2511.00551", "authors": ["Qiang Li", "Ningjing Zeng", "Lina Yu"], "title": "Single-agent Reinforcement Learning Model for Regional Adaptive Traffic Signal Control", "comment": null, "summary": "Several studies have employed reinforcement learning (RL) to address the\nchallenges of regional adaptive traffic signal control (ATSC) and achieved\npromising results. In this field, existing research predominantly adopts\nmulti-agent frameworks. However, the adoption of multi-agent frameworks\npresents challenges for scalability. Instead, the Traffic signal control (TSC)\nproblem necessitates a single-agent framework. TSC inherently relies on\ncentralized management by a single control center, which can monitor traffic\nconditions across all roads in the study area and coordinate the control of all\nintersections. This work proposes a single-agent RL-based regional ATSC model\ncompatible with probe vehicle technology. Key components of the RL design\ninclude state, action, and reward function definitions. To facilitate learning\nand manage congestion, both state and reward functions are defined based on\nqueue length, with action designed to regulate queue dynamics. The queue length\ndefinition used in this study differs slightly from conventional definitions\nbut is closely correlated with congestion states. More importantly, it allows\nfor reliable estimation using link travel time data from probe vehicles. With\nprobe vehicle data already covering most urban roads, this feature enhances the\nproposed method's potential for widespread deployment. The method was\ncomprehensively evaluated using the SUMO simulation platform. Experimental\nresults demonstrate that the proposed model effectively mitigates large-scale\nregional congestion levels via coordinated multi-intersection control.", "AI": {"tldr": "A single-agent RL-based regional adaptive traffic signal control (ATSC) model that leverages probe vehicle data to coordinate across multiple intersections, addressing scalability issues of multi-agent approaches and showing effective congestion mitigation in SUMO simulations.", "motivation": "To overcome scalability challenges in multi-agent RL for regional ATSC by adopting a centralized, single-agent framework that can monitor and coordinate traffic conditions across all intersections, leveraging probe vehicle data for state estimation.", "method": "Design of a single-agent RL system with state, action, and reward defined around queue length. The state and reward are based on queue length (with a nonstandard but congestion-correlated definition) to enable reliable estimation from link travel times derived from probe vehicles. The action aims to regulate queue dynamics to alleviate congestion. The controller is centralized, coordinating multiple intersections, and is evaluated using the SUMO simulation platform.", "result": "Experimental results indicate the proposed single-agent RL model effectively reduces large-scale regional congestion through coordinated control across multiple intersections.", "conclusion": "A centralized single-agent RL approach for regional ATSC, compatible with probe vehicle data, can mitigate regional congestion and offers a scalable alternative to multi-agent frameworks with potential for widespread deployment."}}
{"id": "2511.00120", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00120", "abs": "https://arxiv.org/abs/2511.00120", "authors": ["Md Selim Sarowar", "Sungho Kim"], "title": "VLM6D: VLM based 6Dof Pose Estimation based on RGB-D Images", "comment": "This paper has been accepted to IEIE( The Institute Of Electronics\n  and Information Engineering, South Korea) Fall,2025 Conference", "summary": "The primary challenge in computer vision is precisely calculating the pose of\n6D objects, however many current approaches are still fragile and have trouble\ngeneralizing from synthetic data to real-world situations with fluctuating\nlighting, textureless objects, and significant occlusions. To address these\nlimitations, VLM6D, a novel dual-stream architecture that leverages the\ndistinct strengths of visual and geometric data from RGB-D input for robust and\nprecise pose estimation. Our framework uniquely integrates two specialized\nencoders: a powerful, self-supervised Vision Transformer (DINOv2) processes the\nRGB modality, harnessing its rich, pre-trained understanding of visual grammar\nto achieve remarkable resilience against texture and lighting variations.\nConcurrently, a PointNet++ encoder processes the 3D point cloud derived from\ndepth data, enabling robust geometric reasoning that excels even with the\nsparse, fragmented data typical of severe occlusion. These complementary\nfeature streams are effectively fused to inform a multi task prediction head.\nWe demonstrate through comprehensive experiments that VLM6D obtained new SOTA\nperformance on the challenging Occluded-LineMOD, validating its superior\nrobustness and accuracy.", "AI": {"tldr": "VLM6D introduces a dual-stream RGB-D pose estimator that fuses DINOv2-based RGB features with PointNet++ 3D geometry, achieving state-of-the-art results on Occluded-LineMOD.", "motivation": "6D pose estimation is fragile when generalizing from synthetic data to real-world conditions with varying lighting, textureless objects, and heavy occlusions; leveraging complementary visual and geometric cues can improve robustness and accuracy.", "method": "A dual-stream architecture where RGB is processed by a self-supervised Vision Transformer (DINOv2) and 3D points (from depth) are processed by PointNet++; features are fused in a multi-task prediction head for pose estimation, with emphasis on robustness to occlusion and lighting variations.", "result": "The method achieves new state-of-the-art performance on Occluded-LineMOD, demonstrating superior robustness and accuracy in challenging scenarios.", "conclusion": "Combining rich visual representations with geometric reasoning via a dual-stream fusion yields robust 6D pose estimation under real-world challenges and establishes a strong benchmark for occluded scenes."}}
{"id": "2511.00635", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00635", "abs": "https://arxiv.org/abs/2511.00635", "authors": ["Hyungtae Lim", "Daebeom Kim", "Hyun Myung"], "title": "Multi-Mapcher: Loop Closure Detection-Free Heterogeneous LiDAR Multi-Session SLAM Leveraging Outlier-Robust Registration for Autonomous Vehicles", "comment": "13 pages, 12 figures", "summary": "As various 3D light detection and ranging (LiDAR) sensors have been\nintroduced to the market, research on multi-session simultaneous localization\nand mapping (MSS) using heterogeneous LiDAR sensors has been actively\nconducted. Existing MSS methods mostly rely on loop closure detection for\ninter-session alignment; however, the performance of loop closure detection can\nbe potentially degraded owing to the differences in the density and field of\nview (FoV) of the sensors used in different sessions. In this study, we\nchallenge the existing paradigm that relies heavily on loop detection modules\nand propose a novel MSS framework, called Multi-Mapcher, that employs\nlarge-scale map-to-map registration to perform inter-session initial alignment,\nwhich is commonly assumed to be infeasible, by leveraging outlier-robust 3D\npoint cloud registration. Next, after finding inter-session loops by radius\nsearch based on the assumption that the inter-session initial alignment is\nsufficiently precise, anchor node-based robust pose graph optimization is\nemployed to build a consistent global map. As demonstrated in our experiments,\nour approach shows substantially better MSS performance for various LiDAR\nsensors used to capture the sessions and is faster than state-of-the-art\napproaches. Our code is available at\nhttps://github.com/url-kaist/multi-mapcher.", "AI": {"tldr": "Proposes Multi-Mapcher for MSS with heterogeneous LiDARs using map-to-map registration for inter-session alignment, outperforming loop-closure reliant methods and faster.", "motivation": "Existing MSS methods rely on loop closure but performance degrades with varying sensor density/FoV; need robust inter-session alignment across different LiDARs.", "method": "Introduce Multi-Mapcher: large-scale map-to-map registration using outlier-robust 3D point cloud registration to obtain initial inter-session alignment; then radius-based loop detection; anchor node-based robust pose graph optimization to fuse into a global map.", "result": "Experiments show substantially better MSS performance across different LiDAR sensors and faster than state-of-the-art.", "conclusion": "Demonstrates effectiveness of map-to-map registration-based MSS framework; code released at GitHub."}}
{"id": "2511.00059", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00059", "abs": "https://arxiv.org/abs/2511.00059", "authors": ["Aditya Singh", "Zihang Wen", "Srujananjali Medicherla", "Adam Karvonen", "Can Rager"], "title": "Automatically Finding Rule-Based Neurons in OthelloGPT", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Workshop Mechanistic interpretability", "summary": "OthelloGPT, a transformer trained to predict valid moves in Othello, provides\nan ideal testbed for interpretability research. The model is complex enough to\nexhibit rich computational patterns, yet grounded in rule-based game logic that\nenables meaningful reverse-engineering. We present an automated approach based\non decision trees to identify and interpret MLP neurons that encode rule-based\ngame logic. Our method trains regression decision trees to map board states to\nneuron activations, then extracts decision paths where neurons are highly\nactive to convert them into human-readable logical forms. These descriptions\nreveal highly interpretable patterns; for instance, neurons that specifically\ndetect when diagonal moves become legal. Our findings suggest that roughly half\nof the neurons in layer 5 can be accurately described by compact, rule-based\ndecision trees ($R^2 > 0.7$ for 913 of 2,048 neurons), while the remainder\nlikely participate in more distributed or non-rule-based computations. We\nverify the causal relevance of patterns identified by our decision trees\nthrough targeted interventions. For a specific square, for specific game\npatterns, we ablate neurons corresponding to those patterns and find an\napproximately 5-10 fold stronger degradation in the model's ability to predict\nlegal moves along those patterns compared to control patterns. To facilitate\nfuture work, we provide a Python tool that maps rule-based game behaviors to\ntheir implementing neurons, serving as a resource for researchers to test\nwhether their interpretability methods recover meaningful computational\nstructures.", "AI": {"tldr": "A transformer for predicting valid Othello moves can be interpreted by mapping neuron activations to rule-based logic via decision trees; roughly half of neurons in a key layer are explainable by compact rules, with causal interventions validating these patterns; a Python tool is released to support further work.", "motivation": "To understand how neural networks solve rule-based games, and whether neurons encode understandable, rule-like patterns that govern decision-making in OthelloGPT.", "method": "Train regression decision trees to map board states to individual neuron activations, identify highly-active activations, extract decision paths, and translate them into human-readable logical forms; characterize how many neurons are well-explained by rules (R^2>0.7); perform targeted neuron ablations to test causal relevance of the identified patterns; provide a Python tool mapping rule-based game behaviors to implementing neurons.", "result": "Approximately 50% of neurons in layer 5 (913 of 2,048) have interpretable rule-based descriptions with R^2 > 0.7; the remaining neurons likely capture distributed or non-rule-based computations. Ablating neurons associated with specific patterns yields 5\u201310\u00d7 greater degradation in predicting legal moves along those patterns than control patterns, validating causal relevance.", "conclusion": "Rule-based interpretations apply to a substantial subset of neurons in OthelloGPT, supporting the viability of extracting human-readable rules from neural computations in a constrained, rule-governed domain; the work provides a practical tool to map behaviors to neurons for future interpretability research."}}
{"id": "2511.00609", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00609", "abs": "https://arxiv.org/abs/2511.00609", "authors": ["Shengqi Xu", "Xinpeng Zhou", "Yabo Zhang", "Ming Liu", "Tao Liang", "Tianyu Zhang", "Yalong Bai", "Zuxuan Wu", "Wangmeng Zuo"], "title": "PreferThinker: Reasoning-based Personalized Image Preference Assessment", "comment": null, "summary": "Personalized image preference assessment aims to evaluate an individual\nuser's image preferences by relying only on a small set of reference images as\nprior information. Existing methods mainly focus on general preference\nassessment, training models with large-scale data to tackle well-defined tasks\nsuch as text-image alignment. However, these approaches struggle to handle\npersonalized preference because user-specific data are scarce and not easily\nscalable, and individual tastes are often diverse and complex. To overcome\nthese challenges, we introduce a common preference profile that serves as a\nbridge across users, allowing large-scale user data to be leveraged for\ntraining profile prediction and capturing complex personalized preferences.\nBuilding on this idea, we propose a reasoning-based personalized image\npreference assessment framework that follows a \\textit{predict-then-assess}\nparadigm: it first predicts a user's preference profile from reference images,\nand then provides interpretable, multi-dimensional scores and assessments of\ncandidate images based on the predicted profile. To support this, we first\nconstruct a large-scale Chain-of-Thought (CoT)-style personalized assessment\ndataset annotated with diverse user preference profiles and high-quality\nCoT-style reasoning, enabling explicit supervision of structured reasoning.\nNext, we adopt a two-stage training strategy: a cold-start supervised\nfine-tuning phase to empower the model with structured reasoning capabilities,\nfollowed by reinforcement learning to incentivize the model to explore more\nreasonable assessment paths and enhance generalization. Furthermore, we propose\na similarity-aware prediction reward to encourage better prediction of the\nuser's preference profile, which facilitates more reasonable assessments\nexploration. Extensive experiments demonstrate the superiority of the proposed\nmethod.", "AI": {"tldr": "Proposes a reasoning-based framework for personalized image preference assessment using a common user profile, with a CoT-style dataset and a two-stage training (cold-start supervised fine-tuning and reinforcement learning), plus a similarity-aware reward, achieving superior results.", "motivation": "Personalized image preference is hard due to scarce user data and diverse tastes; general models trained on large-scale data struggle to capture individualized preferences. A common cross-user profile could leverage abundant data to predict and reason about user-specific preferences.", "method": "Introduce a common preference profile bridging users; predict a user's preference profile from reference images; provide interpretable, multi-dimensional scores for candidate images based on the predicted profile. Build a large-scale Chain-of-Thought (CoT)-style dataset with diverse user profiles and reasonings for supervision. Use a two-stage training regime: (1) cold-start supervised fine-tuning to instill structured reasoning; (2) reinforcement learning to explore reasonable reasoning paths and improve generalization. Include a similarity-aware prediction reward to better predict the user profile and guide exploration of assessments.", "result": "Extensive experiments demonstrate superiority over baselines, showing improved accuracy and interpretability in assessing personalized image preferences and generating more reasonable, profile-consistent assessments.", "conclusion": "The framework effectively enables scalable, interpretable personalized image preference assessment by leveraging cross-user profile bridging and reasoning-based predictions. The two-stage training and CoT supervision support generalization and reasoning capabilities, while the similarity-based reward enhances profile prediction and assessment exploration."}}
{"id": "2511.00123", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00123", "abs": "https://arxiv.org/abs/2511.00123", "authors": ["Gaby Maroun", "Salah Eddine Bekhouche", "Fadi Dornaika"], "title": "Integrating ConvNeXt and Vision Transformers for Enhancing Facial Age Estimation", "comment": null, "summary": "Age estimation from facial images is a complex and multifaceted challenge in\ncomputer vision. In this study, we present a novel hybrid architecture that\ncombines ConvNeXt, a state-of-the-art advancement of convolutional neural\nnetworks (CNNs), with Vision Transformers (ViT). While each model independently\ndelivers excellent performance on a variety of tasks, their integration\nleverages the complementary strengths of the CNNs localized feature extraction\ncapabilities and the Transformers global attention mechanisms. Our proposed\nConvNeXt-ViT hybrid solution was thoroughly evaluated on benchmark age\nestimation datasets, including MORPH II, CACD, and AFAD, and achieved superior\nperformance in terms of mean absolute error (MAE). To address computational\nconstraints, we leverage pre-trained models and systematically explore\ndifferent configurations, using linear layers and advanced regularization\ntechniques to optimize the architecture. Comprehensive ablation studies\nhighlight the critical role of individual components and training strategies,\nand in particular emphasize the importance of adapted attention mechanisms\nwithin the CNN framework to improve the model focus on age-relevant facial\nfeatures. The results show that the ConvNeXt-ViT hybrid not only outperforms\ntraditional methods, but also provides a robust foundation for future advances\nin age estimation and related visual tasks. This work underscores the\ntransformative potential of hybrid architectures and represents a promising\ndirection for the seamless integration of CNNs and transformers to address\ncomplex computer vision challenges.", "AI": {"tldr": "A ConvNeXt-ViT hybrid for age estimation yields state-of-the-art MAE on MORPH II, CACD, and AFAD by combining CNN local features with Transformer global attention; ablation studies emphasize adapted CNN attention and training strategies.", "motivation": "To overcome limitations of single-model age estimation approaches by leveraging the complementary strengths of ConvNeXt (CNN) for local feature extraction and Vision Transformers for global attention, enabling improved focus on age-related facial features.", "method": "Propose a ConvNeXt-ViT hybrid architecture, use pre-trained weights, add linear layers and regularization, and perform comprehensive ablation studies. Evaluate on MORPH II, CACD, and AFAD with MAE as the metric.", "result": "The hybrid achieves superior mean absolute error (MAE) across the benchmark datasets compared to traditional methods, with ablations highlighting key components and training strategies, including the importance of adapted attention mechanisms within the CNN framework.", "conclusion": "Hybrid CNN-Transformer architectures are a promising direction for age estimation and related visual tasks, offering robustness and potential for future advances by integrating CNNs and transformers."}}
{"id": "2511.00783", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00783", "abs": "https://arxiv.org/abs/2511.00783", "authors": ["Jingzehua Xu", "Weihang Zhang", "Yangyang Li", "Hongmiaoyi Zhang", "Guanwen Xie", "Jiwei Tang", "Shuai Zhang", "Yi Li"], "title": "When Semantics Connect the Swarm: LLM-Driven Fuzzy Control for Cooperative Multi-Robot Underwater Coverage", "comment": "This paper has been submitted to IEEE Transactions on Mobile\n  Computing", "summary": "Underwater multi-robot cooperative coverage remains challenging due to\npartial observability, limited communication, environmental uncertainty, and\nthe lack of access to global localization. To address these issues, this paper\npresents a semantics-guided fuzzy control framework that couples Large Language\nModels (LLMs) with interpretable control and lightweight coordination. Raw\nmultimodal observations are compressed by the LLM into compact,\nhuman-interpretable semantic tokens that summarize obstacles, unexplored\nregions, and Objects Of Interest (OOIs) under uncertain perception. A fuzzy\ninference system with pre-defined membership functions then maps these tokens\ninto smooth and stable steering and gait commands, enabling reliable navigation\nwithout relying on global positioning. Then, we further coordinate multiple\nrobots by introducing semantic communication that shares intent and local\ncontext in linguistic form, enabling agreement on who explores where while\navoiding redundant revisits. Extensive simulations in unknown reef-like\nenvironments show that, under limited sensing and communication, the proposed\nframework achieves robust OOI-oriented navigation and cooperative coverage with\nimproved efficiency and adaptability, narrowing the gap between semantic\ncognition and distributed underwater control in GPS-denied, map-free\nconditions.", "AI": {"tldr": "A semantics-guided LLM\u2013fuzzy control framework enables GPS-denied underwater multi-robot coverage via semantic tokens and lightweight coordination for robust OOI navigation and reduced redundancy.", "motivation": "Underwater multi-robot systems suffer from partial observability, limited comms, environmental uncertainty, and no access to global localization; need interpretable, cooperative, robust navigation and coverage.", "method": "LLMs compress multimodal observations into semantic tokens (obstacles, unexplored areas, OOIs). A predefined fuzzy inference system maps tokens to smooth steering/gait commands for GPS-denied navigation. Semantic communication shares intent and local context to coordinate exploration and avoid redundant revisits among multiple robots.", "result": "Extensive simulations in unknown reef-like environments demonstrate robust OOI-oriented navigation and cooperative coverage under limited sensing and communication, with improved efficiency and adaptability, bridging semantic cognition and distributed underwater control in GPS-denied, map-free settings.", "conclusion": "The framework enables reliable, interpretable, and scalable underwater multi-robot coordination and coverage without global positioning by leveraging semantic tokens, fuzzy control, and lightweight semantic communication."}}
{"id": "2511.00064", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00064", "abs": "https://arxiv.org/abs/2511.00064", "authors": ["Randolph Wiredu-Aidoo"], "title": "EVINGCA: Adaptive Graph Clustering with Evolving Neighborhood Statistics", "comment": null, "summary": "Clustering algorithms often rely on restrictive assumptions: K-Means and\nGaussian Mixtures presuppose convex, Gaussian-like clusters, while DBSCAN and\nHDBSCAN capture non-convexity but can be highly sensitive. I introduce EVINGCA\n(Evolving Variance-Informed Nonparametric Graph Construction Algorithm), a\ndensity-variance based clustering algorithm that treats cluster formation as an\nadaptive, evolving process on a nearest-neighbor graph. EVINGCA expands rooted\ngraphs via breadth-first search, guided by continuously updated local distance\nand shape statistics, replacing fixed density thresholds with local statistical\nfeedback. With spatial indexing, EVINGCA features log-linear complexity in the\naverage case and exhibits competitive performance against baselines across a\nvariety of synthetic, real-world, low-d, and high-d datasets.", "AI": {"tldr": "Presents EVINGCA, a density-variance based, nonparametric clustering algorithm on an evolving nearest-neighbor graph, achieving adaptive cluster growth with BFS and local statistics; shows competitive performance and scalable log-linear average complexity.", "motivation": "Current clustering methods rely on restrictive assumptions (K-Means and Gaussian Mixtures assume convex, Gaussian-like clusters; DBSCAN/HDBSCAN handle non-convexity but are sensitive to parameters). There is a need for a flexible, nonparametric approach that adapts to local density and shape without fixed thresholds.", "method": "Construct rooted graphs and expand them via breadth-first search on a nearest-neighbor graph. Use continuously updated local distance and shape statistics to guide growth, replacing fixed density thresholds with local statistical feedback. Employ spatial indexing to achieve log-linear average-case complexity.", "result": "EVINGCA achieves competitive performance against baselines across synthetic, real-world, low-dimensional, and high-dimensional datasets.", "conclusion": "EVINGCA provides a robust, adaptive clustering framework that leverages evolving density-variance information through a nonparametric graph-based process, offering scalable performance across diverse data regimes."}}
{"id": "2511.00640", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00640", "abs": "https://arxiv.org/abs/2511.00640", "authors": ["Zicheng Xu", "Guanchu Wang", "Yu-Neng Chuang", "Guangyao Zheng", "Alexander S. Szalay", "Zirui Liu", "Vladimir Braverman"], "title": "DTS: Enhancing Large Reasoning Models via Decoding Tree Sketching", "comment": null, "summary": "Large Reasoning Models (LRMs) demonstrate strong performance on complex\nreasoning tasks, yet they often suffer from overthinking, producing excessively\nlong chain-of-thought (CoT) traces that increase inference cost and may degrade\naccuracy. Our analysis reveals a clear anti-correlation between reasoning\nlength and accuracy, where across multiple stochastic decodes, the short\nreasoning paths consistently achieve the highest correctness, while longer ones\naccumulate errors and repetitions. These short optimal reasoning paths can be\nfound ideally through full enumeration of the reasoning space. However, the\ntree-structured reasoning space grows exponentially with sequence length,\nrendering exhaustive exploration infeasible. To address this, we propose DTS, a\nmodel-agnostic decoding framework that sketches the reasoning space by\nselectively branching at high-entropy tokens and applies early stopping to\nselect the shortest completed reasoning path. This approach approximates the\noptimal solution that enhances both efficiency and accuracy, without requiring\nadditional training or supervision. Experiments on AIME2024 and AIME2025\ndatasets with DeepSeek-R1-Distill-Qwen-7B and 1.5B show that DTS improves\naccuracy by up to 8%, reduces average reasoning length by 23%, and decreases\nrepetition frequency by 12%, demonstrating DTS's ability for scalable and\nefficient LRM reasoning.", "AI": {"tldr": "DTS decodes reasoning by selectively branching at high-entropy points and early-stopping to pick the shortest completed reasoning path, boosting accuracy and efficiency without extra training.", "motivation": "LRMs show an anti-correlation between reasoning length and accuracy; exhaustive search is infeasible; need a scalable, model-agnostic decoding method to find short, high-quality reasoning paths.", "method": "DTS: a model-agnostic decoding framework that sketches the reasoning space by selectively branching at high-entropy tokens and applying early stopping to choose the shortest completed path; no training or supervision required.", "result": "On AIME2024/2025 with DeepSeek-R1-Distill-Qwen-7B and 1.5B, DTS yields up to 8% accuracy gains, 23% shorter reasoning traces, and 12% fewer repetitions.", "conclusion": "DTS enables scalable, efficient reasoning for LRMs by approximating the optimal short reasoning path without extra supervision or training."}}
{"id": "2511.00141", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00141", "abs": "https://arxiv.org/abs/2511.00141", "authors": ["Janghoon Cho", "Jungsoo Lee", "Munawar Hayat", "Kyuwoong Hwang", "Fatih Porikli", "Sungha Choi"], "title": "FLoC: Facility Location-Based Efficient Visual Token Compression for Long Video Understanding", "comment": null, "summary": "Recent studies in long video understanding have harnessed the advanced\nvisual-language reasoning capabilities of Large Multimodal Models (LMMs),\ndriving the evolution of video-LMMs specialized for processing extended video\nsequences. However, the scalability of these models is severely limited by the\noverwhelming volume of visual tokens generated from extended video sequences.\nTo address this challenge, this paper proposes FLoC, an efficient visual token\ncompression framework based on the facility location function, a principled\napproach that swiftly selects a compact yet highly representative and diverse\nsubset of visual tokens within a predefined budget on the number of visual\ntokens. By integrating the lazy greedy algorithm, our method achieves\nremarkable efficiency gains by swiftly selecting a compact subset of tokens,\ndrastically reducing the number of visual tokens while guaranteeing\nnear-optimal performance. Notably, our approach is training-free,\nmodel-agnostic, and query-agnostic, providing a versatile solution that\nseamlessly integrates with diverse video-LLMs and existing workflows. Extensive\nevaluations on large-scale benchmarks, such as Video-MME, MLVU, and\nLongVideoBench, demonstrate that our framework consistently surpasses recent\ncompression techniques, highlighting not only its effectiveness and robustness\nin addressing the critical challenges of long video understanding, but also its\nefficiency in processing speed.", "AI": {"tldr": "FLoC is a training-free, model-agnostic token compression framework for long video understanding. It uses a facility location function to select a compact, diverse token subset within a fixed budget, optimized by lazy greedy, yielding near-optimal performance with high efficiency across various video-LMMs.", "motivation": "Long video understanding suffers from an explosion of visual tokens produced by extended sequences, taxing model capacity and speed. Existing compression methods often require training, model-specific design, or fail to balance representation quality with efficiency.", "method": "Propose FLoC, which formulates token selection as maximizing a facility location function under a token budget. It employs the lazy greedy algorithm for efficient near-optimal selection. The method is training-free, model-agnostic, and query-agnostic, enabling seamless integration with diverse video-LLMs and workflows.", "result": "Empirical evaluations on Video-MME, MLVU, and LongVideoBench show that FLoC consistently surpasses recent compression techniques in both effectiveness and processing speed, indicating robust scalability and robustness for long video understanding.", "conclusion": "FLoC provides a versatile, efficient, training-free token compression solution that addresses key scalability challenges in long video understanding and can be readily integrated into existing video-LLM pipelines."}}
{"id": "2511.00814", "categories": ["cs.RO", "cs.LG", "cs.SY", "eess.SY", "93C41, 93E11, 37M10", "I.2.9; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2511.00814", "abs": "https://arxiv.org/abs/2511.00814", "authors": ["Stella Kombo", "Masih Haseli", "Skylar Wei", "Joel W. Burdick"], "title": "Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic Motion Planning", "comment": "10 pages, 6 figures, submitted to IEEE International Conference on\n  Robotics and Automation (ICRA) 2025", "summary": "Autonomous systems often must predict the motions of nearby agents from\npartial and noisy data. This paper asks and answers the question: \"can we\nlearn, in real-time, a nonlinear predictive model of another agent's motions?\"\nOur online framework denoises and forecasts such dynamics using a modified\nsliding-window Hankel Dynamic Mode Decomposition (Hankel-DMD). Partial noisy\nmeasurements are embedded into a Hankel matrix, while an associated Page matrix\nenables singular-value hard thresholding (SVHT) to estimate the effective rank.\nA Cadzow projection enforces structured low-rank consistency, yielding a\ndenoised trajectory and local noise variance estimates. From this\nrepresentation, a time-varying Hankel-DMD lifted linear predictor is\nconstructed for multi-step forecasts. The residual analysis provides\nvariance-tracking signals that can support downstream estimators and risk-aware\nplanning. We validate the approach in simulation under Gaussian and\nheavy-tailed noise, and experimentally on a dynamic crane testbed. Results show\nthat the method achieves stable variance-aware denoising and short-horizon\nprediction suitable for integration into real-time control frameworks.", "AI": {"tldr": "Online nonlinear predictor for agent motions using a modified Hankel-DMD with SVHT and Cadzow projection for denoising, yielding variance-aware short-horizon forecasts suitable for real-time control.", "motivation": "Autonomous systems must predict others' motions from partial, noisy data in real time to enable safe control and planning.", "method": "Embed partial noisy measurements in a sliding-window Hankel matrix, use a Page matrix for SVHT-based rank estimation, apply a Cadzow projection for structured low-rank consistency, and build a time-varying Hankel-DMD lifted linear predictor for multi-step forecasts with residual variance tracking.", "result": "Demonstrates stable variance-aware denoising and accurate short-horizon predictions under Gaussian and heavy-tailed noise, validated in simulation and on a dynamic crane testbed, indicating real-time applicability.", "conclusion": "The approach provides real-time, variance-aware motion predictions with a structured low-rank denoising step, enabling downstream estimators and risk-aware planning in autonomous systems."}}
{"id": "2511.00065", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00065", "abs": "https://arxiv.org/abs/2511.00065", "authors": ["Kateryna Shapovalenko", "Quentin Auster"], "title": "Aligning Brain Signals with Multimodal Speech and Vision Embeddings", "comment": null, "summary": "When we hear the word \"house\", we don't just process sound, we imagine walls,\ndoors, memories. The brain builds meaning through layers, moving from raw\nacoustics to rich, multimodal associations. Inspired by this, we build on\nrecent work from Meta that aligned EEG signals with averaged wav2vec2 speech\nembeddings, and ask a deeper question: which layers of pre-trained models best\nreflect this layered processing in the brain? We compare embeddings from two\nmodels: wav2vec2, which encodes sound into language, and CLIP, which maps words\nto images. Using EEG recorded during natural speech perception, we evaluate how\nthese embeddings align with brain activity using ridge regression and\ncontrastive decoding. We test three strategies: individual layers, progressive\nconcatenation, and progressive summation. The findings suggest that combining\nmultimodal, layer-aware representations may bring us closer to decoding how the\nbrain understands language, not just as sound, but as experience.", "AI": {"tldr": "Layer-aware, multimodal embeddings from wav2vec2 and CLIP, analyzed with EEG during natural speech, show that combining representations across layers improves alignment with brain language processing and decoding, moving beyond viewing speech as mere sound to capture experience-derived meaning.", "motivation": "To understand how hierarchical brain processing of language maps onto pre-trained model representations, and to identify which layers (and which modalities) best reflect neural activity during natural speech perception.", "method": "Use EEG recorded during natural speech perception. Compare embeddings from two pre-trained models: wav2vec2 (audio-to-language) and CLIP (text-to-image). Evaluate alignment with brain signals via ridge regression encoding and contrastive decoding. Test three strategies: (1) individual layer representations, (2) progressive concatenation of layers, (3) progressive summation of layers.", "result": "Findings indicate that combining multimodal, layer-aware representations improves alignment with neural data and supports better decoding of language-related brain activity, suggesting that brain processing reflects language as multimodal experience rather than acoustic sound alone.", "conclusion": "Layer-aware, multimodal representations bring us closer to decoding how the brain understands language, capturing its transformation from sound to rich, experience-based meaning."}}
{"id": "2511.00651", "categories": ["cs.AI", "cs.CL", "cs.IT", "cs.MA", "cs.NI", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.00651", "abs": "https://arxiv.org/abs/2511.00651", "authors": ["Chenhua Shi", "Bhavika Jalli", "Gregor Macdonald", "John Zou", "Wanlu Lei", "Mridul Jain", "Joji Philip"], "title": "Leveraging Multi-Agent System (MAS) and Fine-Tuned Small Language Models (SLMs) for Automated Telecom Network Troubleshooting", "comment": "6 pages, 7 figures, 1 table", "summary": "Telecom networks are rapidly growing in scale and complexity, making\neffective management, operation, and optimization increasingly challenging.\nAlthough Artificial Intelligence (AI) has been applied to many telecom tasks,\nexisting models are often narrow in scope, require large amounts of labeled\ndata, and struggle to generalize across heterogeneous deployments.\nConsequently, network troubleshooting continues to rely heavily on Subject\nMatter Experts (SMEs) to manually correlate various data sources to identify\nroot causes and corrective actions. To address these limitations, we propose a\nMulti-Agent System (MAS) that employs an agentic workflow, with Large Language\nModels (LLMs) coordinating multiple specialized tools for fully automated\nnetwork troubleshooting. Once faults are detected by AI/ML-based monitors, the\nframework dynamically activates agents such as an orchestrator, solution\nplanner, executor, data retriever, and root-cause analyzer to diagnose issues\nand recommend remediation strategies within a short time frame. A key component\nof this system is the solution planner, which generates appropriate remediation\nplans based on internal documentation. To enable this, we fine-tuned a Small\nLanguage Model (SLM) on proprietary troubleshooting documents to produce\ndomain-grounded solution plans. Experimental results demonstrate that the\nproposed framework significantly accelerates troubleshooting automation across\nboth Radio Access Network (RAN) and Core network domains.", "AI": {"tldr": "A multi-agent system using LLMs to automate telecom network troubleshooting, with a fine-tuned small language model for domain-grounded remediation plans, achieving faster automated troubleshooting in RAN and Core networks.", "motivation": "Telecom networks are expanding in scale and complexity; current AI models are narrow, data-hungry, and struggle to generalize across heterogeneous deployments, leaving SMEs to manually correlate data and identify root causes.", "method": "An agentic workflow where LLMs coordinate specialized tools (orchestrator, solution planner, executor, data retriever, root-cause analyzer). Faults detected by AI/ML monitors trigger dynamic activation of agents; the solution planner generates remediation plans from internal documentation, aided by a fine-tuned SLM trained on proprietary troubleshooting documents to produce domain-grounded plans.", "result": "Experimental results show significant acceleration of troubleshooting automation across both Radio Access Network (RAN) and Core network domains.", "conclusion": "The MAS framework enables end-to-end, automated troubleshooting and remediation planning, reducing manual SME effort and speeding diagnosis and resolution across heterogeneous telecom deployments."}}
{"id": "2511.00143", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00143", "abs": "https://arxiv.org/abs/2511.00143", "authors": ["Jinsu Kim", "Yunhun Nam", "Minseon Kim", "Sangpil Kim", "Jongheon Jeong"], "title": "BlurGuard: A Simple Approach for Robustifying Image Protection Against AI-Powered Editing", "comment": "36 pages; NeurIPS 2025; Code is available at\n  https://github.com/jsu-kim/BlurGuard", "summary": "Recent advances in text-to-image models have increased the exposure of\npowerful image editing techniques as a tool, raising concerns about their\npotential for malicious use. An emerging line of research to address such\nthreats focuses on implanting \"protective\" adversarial noise into images before\ntheir public release, so future attempts to edit them using text-to-image\nmodels can be impeded. However, subsequent works have shown that these\nadversarial noises are often easily \"reversed,\" e.g., with techniques as simple\nas JPEG compression, casting doubt on the practicality of the approach. In this\npaper, we argue that adversarial noise for image protection should not only be\nimperceptible, as has been a primary focus of prior work, but also\nirreversible, viz., it should be difficult to detect as noise provided that the\noriginal image is hidden. We propose a surprisingly simple method to enhance\nthe robustness of image protection methods against noise reversal techniques.\nSpecifically, it applies an adaptive per-region Gaussian blur on the noise to\nadjust the overall frequency spectrum. Through extensive experiments, we show\nthat our method consistently improves the per-sample worst-case protection\nperformance of existing methods against a wide range of reversal techniques on\ndiverse image editing scenarios, while also reducing quality degradation due to\nnoise in terms of perceptual metrics. Code is available at\nhttps://github.com/jsu-kim/BlurGuard.", "AI": {"tldr": "Adaptive per-region Gaussian blur on protective adversarial noise yields more irreversible, robust image protection against reversal edits, preserving perceptual quality; named BlurGuard; code at GitHub.", "motivation": "Protect against malicious misuse of text-to-image editing by irreversible, hard-to-remove protections; prior protective noises were easily undone by simple transformations like JPEG, undermining practicality.", "method": "Apply an adaptive Gaussian blur to the protective noise on a per-region basis to reshape the noise frequency spectrum and hinder reversal attempts; region-aware blur.", "result": "Improved worst-case protection across various reversal techniques and editing scenarios; reduced perceptual degradation relative to prior approaches.", "conclusion": "The proposed BlurGuard approach enhances robustness of image protections, offering practical effectiveness; code available."}}
{"id": "2511.00840", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00840", "abs": "https://arxiv.org/abs/2511.00840", "authors": ["William Suliman", "Ekaterina Chaikovskaia", "Egor Davydenko", "Roman Gorbachev"], "title": "Heuristic Step Planning for Learning Dynamic Bipedal Locomotion: A Comparative Study of Model-Based and Model-Free Approaches", "comment": null, "summary": "This work presents an extended framework for learning-based bipedal\nlocomotion that incorporates a heuristic step-planning strategy guided by\ndesired torso velocity tracking. The framework enables precise interaction\nbetween a humanoid robot and its environment, supporting tasks such as crossing\ngaps and accurately approaching target objects. Unlike approaches based on full\nor simplified dynamics, the proposed method avoids complex step planners and\nanalytical models. Step planning is primarily driven by heuristic commands,\nwhile a Raibert-type controller modulates the foot placement length based on\nthe error between desired and actual torso velocity. We compare our method with\na model-based step-planning approach -- the Linear Inverted Pendulum Model\n(LIPM) controller. Experimental results demonstrate that our approach attains\ncomparable or superior accuracy in maintaining target velocity (up to 80%),\nsignificantly greater robustness on uneven terrain (over 50% improvement), and\nimproved energy efficiency. These results suggest that incorporating complex\nanalytical, model-based components into the training architecture may be\nunnecessary for achieving stable and robust bipedal walking, even in\nunstructured environments.", "AI": {"tldr": "A learning-based bipedal framework using heuristic step planning guided by torso-velocity tracking achieves robust, energy-efficient walking with competitive velocity control, reducing reliance on complex model-based planning.", "motivation": "Investigate whether simplified, heuristic planning within a learning framework can match or exceed model-based methods in robust bipedal locomotion on unstructured terrains, enabling tasks like gap crossing and target approach while improving efficiency.", "method": "Extend a learning-based locomotion pipeline with a heuristic step-planning strategy driven by desired torso velocity; modulate foot placement length via a Raibert-type controller based on velocity error; compare against a Linear Inverted Pendulum Model (LIPM) controller; avoid reliance on full/detailed dynamic models.", "result": "Experimental results show comparable or superior target-velocity tracking (up to 80% accuracy), significantly greater robustness on uneven terrain (over 50% improvement), and improved energy efficiency compared to the LIPM-based approach.", "conclusion": "Incorporating complex analytical or model-based components into the training architecture may be unnecessary for achieving stable and robust bipedal walking in unstructured environments; a heuristic, learning-based approach can suffice."}}
{"id": "2511.00066", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00066", "abs": "https://arxiv.org/abs/2511.00066", "authors": ["Tue Le", "Nghi D. Q. Bui", "Linh Ngo Van", "Trung Le"], "title": "Token-Regulated Group Relative Policy Optimization for Stable Reinforcement Learning in Large Language Models", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has emerged as a\npowerful approach for strengthening the reasoning capabilities of large\nlanguage models (LLMs). Among existing algorithms, Group Relative Policy\nOptimization (GRPO) has demonstrated strong performance, yet it suffers from a\ncritical issue: low-probability tokens disproportionately dominate gradient\nupdates due to their inherently large gradient magnitudes. This imbalance leads\nto unstable training and suppresses the contribution of high-probability tokens\nthat are more reliable for learning. In this work, we introduce Token-Regulated\nGroup Relative Policy Optimization (TR-GRPO), a simple yet effective extension\nof GRPO that assigns token-level weights positively correlated with the model's\npredicted probability. By downweighting low-probability tokens and emphasizing\nhigh-probability ones, TR-GRPO mitigates gradient over-amplification while\npreserving informative learning signals. Extensive experiments demonstrate that\nTR-GRPO consistently outperforms GRPO across RLVR tasks, including logic, math,\nand agentic reasoning, highlighting the importance of regulating token\ncontributions during RL training and establishing TR-GRPO as a robust framework\nfor enhancing LLM reasoning.", "AI": {"tldr": "TR-GRPO extends GRPO by applying token-level weights tied to the model's predicted probability, downweighting low-probability tokens to stabilize gradients and improve learning, yielding better performance in RLVR tasks.", "motivation": "GRPO can be dominated by gradients from rare, low-probability tokens, which destabilizes training and masks learning from higher-probability tokens that are more reliable for improving LLM reasoning.", "method": "Introduce Token-Regulated GRPO (TR-GRPO) that assigns token-level weights positively correlated with the model's predicted probability, downweighting low-probability tokens while preserving informative learning signals.", "result": "TR-GRPO consistently outperforms GRPO across RLVR tasks (logic, math, agentic reasoning), demonstrating stronger learning stability and improved reasoning capabilities.", "conclusion": "Regulating token contributions during RL training is crucial for robust LLM reasoning; TR-GRPO provides a simple, effective framework that enhances GRPO performance for RLVR."}}
{"id": "2511.00673", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00673", "abs": "https://arxiv.org/abs/2511.00673", "authors": ["Dominik Drexler"], "title": "Lifted Successor Generation in Numeric Planning", "comment": null, "summary": "Most planners ground numeric planning tasks, given in a first-order-like\nlanguage, into a ground task representation. However, this can lead to an\nexponential blowup in task representation size, which occurs in practice for\nhard-to-ground tasks. We extend a state-of-the-art lifted successor generator\nfor classical planning to support numeric precondition applicability. The\nmethod enumerates maximum cliques in a substitution consistency graph. Each\nmaximum clique represents a substitution for the variables of the action\nschema, yielding a ground action. We augment this graph with numeric action\npreconditions and prove the successor generator is exact under formally\nspecified conditions. When the conditions fail, our generator may list\ninapplicable ground actions; a final applicability check filters these without\naffecting completeness. However, this cannot happen in 23 of 25 benchmark\ndomains, and it occurs only in 1 domain. To the authors' knowledge, no other\nlifted successor generator supports numeric action preconditions. This enables\nfuture research on lifted planning for a very rich planning fragment.", "AI": {"tldr": "Lifted successor generator for classical planning now supports numeric preconditions by enumerating maximum cliques in a substitution consistency graph; it is exact under formal conditions and greatly reduces grounding blowup, with rare mis-listings in benchmarks.", "motivation": "Grounding numeric planning tasks into a ground representation can cause exponential blowup; a lifted approach that preserves correctness would improve scalability for hard-to-ground tasks.", "method": "Extend a state-of-the-art lifted successor generator by adding numeric action preconditions. The method augments the substitution consistency graph with numeric constraints and enumerates maximum cliques to yield ground actions. It proves exactness under specified conditions; when conditions fail, an applicability check filters inapplicable ground actions without harming completeness.", "result": "The generator is exact under the stated conditions. In 23 of 25 benchmark domains it does not produce inapplicable ground actions; in the remaining domain, a mislisting occurs. This places it among the first approaches to support numeric preconditions in lifted planning.", "conclusion": "This work enables lifted planning for a richer fragment of planning with numeric preconditions and suggests avenues for future research to further reduce or eliminate rare mislistings and extend lifting to broader numeric constraints."}}
{"id": "2511.00171", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00171", "abs": "https://arxiv.org/abs/2511.00171", "authors": ["Rahul Ghosh", "Baishali Chaudhury", "Hari Prasanna Das", "Meghana Ashok", "Ryan Razkenari", "Sungmin Hong", "Chun-Hao Liu"], "title": "CompAgent: An Agentic Framework for Visual Compliance Verification", "comment": "Under review", "summary": "Visual compliance verification is a critical yet underexplored problem in\ncomputer vision, especially in domains such as media, entertainment, and\nadvertising where content must adhere to complex and evolving policy rules.\nExisting methods often rely on task-specific deep learning models trained on\nmanually labeled datasets, which are costly to build and limited in\ngeneralizability. While recent multi-modal large language models (MLLMs) offer\nbroad real-world knowledge and policy understanding, they struggle to reason\nover fine-grained visual details and apply structured compliance rules\neffectively on their own. In this paper, we propose CompAgent, the first\nagentic framework for visual compliance verification. CompAgent augments MLLMs\nwith a suite of visual tools - such as object detectors, face analyzers, NSFW\ndetectors, and captioning models - and introduces a planning agent that\ndynamically selects appropriate tools based on the compliance policy. A\nverification agent then integrates image, tool outputs, and policy context to\nperform multi-modal reasoning. Experiments on public benchmarks show that\nCompAgent outperforms specialized classifiers, direct MLLM prompting, and\ncurated routing baselines, achieving up to 76% F1 score and a 10% improvement\nover the state-of-the-art on the UnsafeBench dataset. Our results demonstrate\nthe effectiveness of agentic planning and tool-augmented reasoning for\nscalable, accurate, and adaptable visual compliance verification.", "AI": {"tldr": "Proposes CompAgent, an agentic framework that augments MLLMs with visual tools and planning to verify visual compliance; achieves strong performance on UnsafeBench.", "motivation": "Visual compliance verification is important in media/advertising but underexplored; existing methods lack generalizability; MLLMs alone struggle with fine-grained rules.", "method": "Introduce planning agent to select visual tools (object detectors, face analyzers, NSFW detectors, captioning); verification agent integrates image, outputs, policy context for multi-modal reasoning.", "result": "Outperforms specialized classifiers, direct MLLM prompting, routing baselines; up to 76% F1; +10% SOTA on UnsafeBench.", "conclusion": "Agentic planning + tool-augmented reasoning enables scalable, accurate, adaptable visual compliance verification."}}
{"id": "2511.00917", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00917", "abs": "https://arxiv.org/abs/2511.00917", "authors": ["Junyao Shi", "Rujia Yang", "Kaitian Chao", "Selina Bingqing Wan", "Yifei Shao", "Jiahui Lei", "Jianing Qian", "Long Le", "Pratik Chaudhari", "Kostas Daniilidis", "Chuan Wen", "Dinesh Jayaraman"], "title": "Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots", "comment": "Project website: https://maestro-robot.github.io", "summary": "Today's best-explored routes towards generalist robots center on collecting\never larger \"observations-in actions-out\" robotics datasets to train large\nend-to-end models, copying a recipe that has worked for vision-language models\n(VLMs). We pursue a road less traveled: building generalist policies directly\naround VLMs by augmenting their general capabilities with specific robot\ncapabilities encapsulated in a carefully curated set of perception, planning,\nand control modules. In Maestro, a VLM coding agent dynamically composes these\nmodules into a programmatic policy for the current task and scenario. Maestro's\narchitecture benefits from a streamlined closed-loop interface without many\nmanually imposed structural constraints, and a comprehensive and diverse tool\nrepertoire. As a result, it largely surpasses today's VLA models for zero-shot\nperformance on challenging manipulation skills. Further, Maestro is easily\nextensible to incorporate new modules, easily editable to suit new embodiments\nsuch as a quadruped-mounted arm, and even easily adapts from minimal real-world\nexperiences through local code edits.", "AI": {"tldr": "Maestro uses a VLM-based coding agent to dynamically compose perception, planning, and control modules into a programmatic policy, enabling generalist robot skills with strong zero-shot manipulation and easy extensibility.", "motivation": "To shift from scaling up observation-in-actions-out datasets toward leveraging large vision-language models by orchestrating modular robot capabilities into generalist policies.", "method": "Introduce Maestro, a VLM coding agent that dynamically assembles a curated set of perception, planning, and control modules into a programmable policy for the current task; relies on a streamlined closed-loop interface and a broad tool repertoire; easily extensible to new modules and embodiments.", "result": "Maestro largely surpasses contemporary VLA models for zero-shot performance on challenging manipulation skills.", "conclusion": "Maestro is easily extensible to incorporate new modules and embodiments, and can adapt from minimal real-world experience via local code edits, offering a practical path to generalist robots."}}
{"id": "2511.00067", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00067", "abs": "https://arxiv.org/abs/2511.00067", "authors": ["Zhixing Li", "Arsham Gholamzadeh Khoee", "Yinan Yu"], "title": "Latent Domain Prompt Learning for Vision-Language Models", "comment": null, "summary": "The objective of domain generalization (DG) is to enable models to be robust\nagainst domain shift. DG is crucial for deploying vision-language models (VLMs)\nin real-world applications, yet most existing methods rely on domain labels\nthat may not be available and often ambiguous. We instead study the DG setting\nwhere models must generalize well without access to explicit domain labels. Our\nkey idea is to represent an unseen target domain as a combination of latent\ndomains automatically discovered from training data, enabling the model to\nadaptively transfer knowledge across domains. To realize this, we perform\nlatent domain clustering on image features and fuse domain-specific text\nfeatures based on the similarity between the input image and each latent\ndomain. Experiments on four benchmarks show that this strategy yields\nconsistent gains over VLM-based baselines and provides new insights into\nimproving robustness under domain shift.", "AI": {"tldr": "Proposes a domain-generalization method for vision-language models without explicit domain labels by discovering latent domains via clustering and fuse domain-specific text features, achieving consistent gains on four benchmarks.", "motivation": "Domain generalization aims to be robust to domain shift, but relying on domain labels is impractical in real-world settings. For vision-language models, robust cross-domain performance without labeled domains is especially valuable.", "method": "Perform latent domain clustering on image features to discover unseen latent domains. For each latent domain, use domain-specific text features and fuse them based on the similarity between the input image and each latent domain. Represent an unseen target as a mixture of these latent domains and adapt knowledge across domains during inference.", "result": "Empirical results on four benchmarks show consistent improvements over VLM-based baselines, providing new insights into improving robustness under domain shift.", "conclusion": "Latent-domain discovery with domain-specific text feature fusion offers an effective, label-free approach to domain generalization for vision-language models and helps illuminate strategies to improve robustness under domain shift."}}
{"id": "2511.00710", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00710", "abs": "https://arxiv.org/abs/2511.00710", "authors": ["Minghe Shen", "Zhuo Zhi", "Chonghan Liu", "Shuo Xing", "Zhengzhong Tu", "Che Liu"], "title": "Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries", "comment": null, "summary": "While Vision-Language Models (VLMs) post-trained with Reinforcement Learning\n(RL) show impressive general reasoning, their evaluation is often confined to\nlanguage-dominant tasks (e.g., math). This raises a critical question: can RL\npost-training truly extend the inherent capability boundary of a base VLM,\nparticularly for visual-centric spatial tasks where it initially fails? To\ninvestigate this, we introduce Ariadne, a framework utilizing synthetic mazes\nfor multi-step spatial reasoning where task difficulty (e.g., path length,\nturns) is precisely controlled. We leverage this controllable environment to\ntrain VLMs using Reinforcement Learning with Verified Rewards (RLVR) in a\ndifficulty-aware curriculum. Surprisingly, post-RLVR training, the VLM achieves\nover 50% accuracy on a problem set where the base model scored 0%,\ndemonstrating that our approach expands the model's initial capability\nboundary. To assess real-world viability, we evaluate out-of-distribution (OOD)\ngeneralization on practical benchmarks. Despite training only on synthetic maze\nsamples, Ariadne achieves significant zero-shot improvements, averaging 16% on\nMapBench (e.g., museum navigation) and 24% on ReasonMap (subway transfer\ntasks). These results confirm that our method not only broadens the model's\nfundamental limits but also enhances its generalization to real-world spatial\nreasoning. We acknowledge our study is limited to the post-training phase,\ngiven the opaqueness of pre-training data, and hope our research motivates\nfurther work on specialized, capability-extending alignment.", "AI": {"tldr": "Ariadne uses RLVR in a controllable synthetic maze to push VLMs beyond their initial spatial reasoning limits, showing substantial gains and zero-shot real-world generalization.", "motivation": "To determine whether RL post-training can expand a base VLM's capability boundary for visual-centric spatial tasks, where the model initially underperforms, and to provide a controllable curriculum via synthetic mazes.", "method": "Introduce Ariadne: a framework using synthetic mazes with adjustable difficulty (path length, turns). Train VLMs with Reinforcement Learning with Verified Rewards (RLVR) under a difficulty-aware curriculum. Evaluate on synthetic mazes and test zero-shot generalization on real-world benchmarks (MapBench, ReasonMap).", "result": "Post-RLVR training yields >50% accuracy on a synthetic problem set where the base model scored 0%. In zero-shot transfer, MapBench improves by ~16% and ReasonMap by ~24%. These results suggest expanded capability and improved generalization.", "conclusion": "The approach expands the model's initial capability boundary and enhances real-world spatial reasoning generalization, but is limited to post-training insights due to opaque pre-training data; calls for further work on capability-extending alignment."}}
{"id": "2511.00181", "categories": ["cs.CV", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00181", "abs": "https://arxiv.org/abs/2511.00181", "authors": ["Mengfei Liang", "Yiting Qu", "Yukun Jiang", "Michael Backes", "Yang Zhang"], "title": "From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection", "comment": "20 pages, 6 figures", "summary": "The rapid evolution of AI-generated images poses unprecedented challenges to\ninformation integrity and media authenticity. Existing detection approaches\nsuffer from fundamental limitations: traditional classifiers lack\ninterpretability and fail to generalize across evolving generative models,\nwhile vision-language models (VLMs), despite their promise, remain constrained\nto single-shot analysis and pixel-level reasoning. To address these challenges,\nwe introduce AIFo (Agent-based Image Forensics), a novel training-free\nframework that emulates human forensic investigation through multi-agent\ncollaboration. Unlike conventional methods, our framework employs a set of\nforensic tools, including reverse image search, metadata extraction,\npre-trained classifiers, and VLM analysis, coordinated by specialized LLM-based\nagents that collect, synthesize, and reason over cross-source evidence. When\nevidence is conflicting or insufficient, a structured multi-agent debate\nmechanism allows agents to exchange arguments and reach a reliable conclusion.\nFurthermore, we enhance the framework with a memory-augmented reasoning module\nthat learns from historical cases to improve future detection accuracy. Our\ncomprehensive evaluation spans 6,000 images across both controlled laboratory\nsettings and challenging real-world scenarios, including images from modern\ngenerative platforms and diverse online sources. AIFo achieves 97.05% accuracy,\nsubstantially outperforming traditional classifiers and state-of-the-art VLMs.\nThese results demonstrate that agent-based procedural reasoning offers a new\nparadigm for more robust, interpretable, and adaptable AI-generated image\ndetection.", "AI": {"tldr": "AIFo is a training-free, agent-based forensics framework that uses multi-agent collaboration and cross-source evidence (reverse image search, metadata, classifiers, VLMs) guided by LLMs, with memory-augmented reasoning and a debate mechanism, achieving 97.05% accuracy on 6,000 images and outperforming traditional classifiers and VLMs.", "motivation": "The rapid rise of AI-generated images threatens information integrity and media authenticity. Existing detectors struggle with generalization, interpretability, and cross-model robustness. There is a need for robust, interpretable, and adaptable detection that leverages multi-source evidence.", "method": "AIFo deploys a coordinated set of forensic tools (reverse image search, metadata extraction, pre-trained classifiers, VLM analysis) managed by specialized LLM-based agents. When evidence conflicts, agents engage in structured multi-agent debates to reach reliable conclusions. A memory-augmented reasoning module learns from historical cases to improve future detection. The approach is training-free and evaluated on 6,000 images from controlled and real-world sources, including modern generative platforms.", "result": "Achieves 97.05% accuracy, substantially outperforming traditional classifiers and state-of-the-art VLMs. Demonstrates that agent-based procedural reasoning yields more robust, interpretable, and adaptable AI-generated image detection.", "conclusion": "Agent-based procedural reasoning offers a new paradigm for AI-generated image detection, providing interpretable, robust, and adaptable detection through cross-source evidence synthesis and evolving memory-informed reasoning."}}
{"id": "2511.00933", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00933", "abs": "https://arxiv.org/abs/2511.00933", "authors": ["Xiangyu Shi", "Zerui Li", "Yanyuan Qiao", "Qi Wu"], "title": "Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation", "comment": null, "summary": "Recent advances in Vision-and-Language Navigation in Continuous Environments\n(VLN-CE) have leveraged multimodal large language models (MLLMs) to achieve\nzero-shot navigation. However, existing methods often rely on panoramic\nobservations and two-stage pipelines involving waypoint predictors, which\nintroduce significant latency and limit real-world applicability. In this work,\nwe propose Fast-SmartWay, an end-to-end zero-shot VLN-CE framework that\neliminates the need for panoramic views and waypoint predictors. Our approach\nuses only three frontal RGB-D images combined with natural language\ninstructions, enabling MLLMs to directly predict actions. To enhance decision\nrobustness, we introduce an Uncertainty-Aware Reasoning module that integrates\n(i) a Disambiguation Module for avoiding local optima, and (ii) a Future-Past\nBidirectional Reasoning mechanism for globally coherent planning. Experiments\non both simulated and real-robot environments demonstrate that our method\nsignificantly reduces per-step latency while achieving competitive or superior\nperformance compared to panoramic-view baselines. These results demonstrate the\npracticality and effectiveness of Fast-SmartWay for real-world zero-shot\nembodied navigation.", "AI": {"tldr": "Fast-SmartWay presents an end-to-end zero-shot VLN-CE method using three frontal RGB-D images and MLLMs to directly predict actions, paired with uncertainty-aware reasoning to reduce latency without using panoramic views or waypoint predictors.", "motivation": "To reduce latency and improve real-world applicability of VLN-CE by avoiding panoramic observations and multi-stage pipelines, while leveraging multimodal large language models for zero-shot navigation.", "method": "Use only three frontal RGB-D images plus natural language instructions; MLLMs directly predict actions. Introduce an Uncertainty-Aware Reasoning module comprising (i) a Disambiguation Module to avoid local optima and (ii) a Future-Past Bidirectional Reasoning mechanism for globally coherent planning.", "result": "Experiments in simulated and real-robot environments show significantly reduced per-step latency with competitive or superior performance compared to panoramic-view baselines.", "conclusion": "Demonstrates practicality and effectiveness of Fast-SmartWay for real-world zero-shot embodied navigation without panoramic views or waypoint predictors."}}
{"id": "2511.00070", "categories": ["cs.LG", "cs.AI", "90C29 (Primary), 68T07, 65K05 (Secondary)", "G.1.6; I.2.6; J.6"], "pdf": "https://arxiv.org/pdf/2511.00070", "abs": "https://arxiv.org/abs/2511.00070", "authors": ["Muhammad Bilal Awan", "Abdul Razzaq", "Abdul Shahid"], "title": "Benchmarking Generative AI Against Bayesian Optimization for Constrained Multi-Objective Inverse Design", "comment": "17 pages, 2 Figures", "summary": "This paper investigates the performance of Large Language Models (LLMs) as\ngenerative optimizers for solving constrained multi-objective regression tasks,\nspecifically within the challenging domain of inverse design\n(property-to-structure mapping). This problem, critical to materials\ninformatics, demands finding complex, feasible input vectors that lie on the\nPareto optimal front. While LLMs have demonstrated universal effectiveness\nacross generative and reasoning tasks, their utility in constrained,\ncontinuous, high-dimensional numerical spaces tasks they weren't explicitly\narchitected for remains an open research question. We conducted a rigorous\ncomparative study between established Bayesian Optimization (BO) frameworks and\na suite of fine-tuned LLMs and BERT models. For BO, we benchmarked the\nfoundational BoTorch Ax implementation against the state-of-the-art q-Expected\nHypervolume Improvement (qEHVI, BoTorchM). The generative approach involved\nfine-tuning models via Parameter-Efficient Fine-Tuning (PEFT), framing the\nchallenge as a regression problem with a custom output head. Our results show\nthat BoTorch qEHVI achieved perfect convergence (GD=0.0), setting the\nperformance ceiling. Crucially, the best-performing LLM (WizardMath-7B)\nachieved a Generational Distance (GD) of 1.21, significantly outperforming the\ntraditional BoTorch Ax baseline (GD=15.03). We conclude that specialized BO\nframeworks remain the performance leader for guaranteed convergence, but\nfine-tuned LLMs are validated as a promising, computationally fast alternative,\ncontributing essential comparative metrics to the field of AI-driven\noptimization. The findings have direct industrial applications in optimizing\nformulation design for resins, polymers, and paints, where multi-objective\ntrade-offs between mechanical, rheological, and chemical properties are\ncritical to innovation and production efficiency.", "AI": {"tldr": "BoTorch qEHVI shows perfect convergence; tuned LLMs (WizardMath-7B) are competitive and faster but do not surpass specialized Bayesian optimization. The study provides comparative metrics for AI-driven optimization in constrained multi-objective inverse design, with industrial relevance to resins, polymers, and paints.", "motivation": "Evaluate whether large language models can serve as generative optimizers in constrained, continuous, high-dimensional multi-objective inverse design tasks, and benchmark them against established Bayesian optimization frameworks for property-to-structure mappings in materials informatics.", "method": "Benchmark a standard BoTorch Ax implementation against qEHVI (BoTorchM) for Bayesian optimization, and fine-tune LLMs and BERT via Parameter-Efficient Fine-Tuning on a regression framing with a custom output head. Treat the problem as constrained, multi-objective optimization and measure convergence via Generational Distance (GD).", "result": "BoTorch qEHVI achieved perfect convergence (GD=0.0). The best fine-tuned LLM (WizardMath-7B) achieved GD=1.21, significantly outperforming the BoTorch Ax baseline (GD=15.03). LLMs offer faster computation and competitive performance, but specialized BO frameworks maintain the performance ceiling for guaranteed convergence.", "conclusion": "Specialized Bayesian optimization frameworks remain the leading approach for guaranteed convergence in constrained multi-objective optimization, but fine-tuned LLMs are a promising, computationally faster alternative with tangible comparative metrics, relevant for industrial formulation design where trade-offs among mechanical, rheological, and chemical properties are critical."}}
{"id": "2511.00739", "categories": ["cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.00739", "abs": "https://arxiv.org/abs/2511.00739", "authors": ["Ritik Raj", "Hong Wang", "Tushar Krishna"], "title": "A CPU-Centric Perspective on Agentic AI", "comment": null, "summary": "Agentic AI frameworks add a decision-making orchestrator embedded with\nexternal tools, including web search, Python interpreter, contextual database,\nand others, on top of monolithic LLMs, turning them from passive text oracles\ninto autonomous problem-solvers that can plan, call tools, remember past steps,\nand adapt on the fly.\n  This paper aims to characterize and understand the system bottlenecks\nintroduced by agentic AI workloads from a largely overlooked CPU-centric\nperspective. We first systematically characterize Agentic AI on the basis of\norchestrator/decision making component, inference path dynamics and\nrepetitiveness of the agentic flow which directly influences the system-level\nperformance. Thereafter, based on the characterization, we choose five\nrepresentative agentic AI workloads- Haystack RAG, Toolformer, ChemCrow,\nLangchain and SWE-Agent to profile latency, throughput and energy metrics and\ndemystify the significant impact of CPUs on these metrics relative to GPUs. We\nobserve that - 1. Tool processing on CPUs can take up to 90.6% of the total\nlatency; 2. Agentic throughput gets bottlenecked either by CPU factors -\ncoherence, synchronization and over-subscription of cores or GPU factors - main\nmemory capacity and bandwidth; \\circled{3} CPU dynamic energy consumes up to\n44% of the total dynamic energy at large batch sizes. Based on the profiling\ninsights, we present two key optimizations- 1. CPU and GPU-Aware Micro-batching\n(CGAM) and 2. Mixed Agentic Workload Scheduling (MAWS) for homogeneous and\nheterogeneous agentic workloads respectively to demonstrate the potential to\nimprove the performance, efficiency, and scalability of agentic AI. We achieve\nup to 2.1x and 1.41x P50 latency speedup compared to the multi-processing\nbenchmark for homogeneous and heterogeneous agentic workloads respectively.", "AI": {"tldr": "The paper characterizes CPU-centric bottlenecks in agentic AI workloads, profiles five representative workloads, and proposes two optimizations (CGAM and MAWS) that substantially improve latency and efficiency, achieving up to 2.1x speedups in homogeneous and 1.41x in heterogeneous settings.", "motivation": "Agentic AI frameworks augment LLMs with orchestrators and external tools, transforming them into autonomous problem solvers. Understanding CPU-related bottlenecks is essential for performance, energy efficiency, and scalable deployment.", "method": "Systematic characterization of the orchestrator/decision-making component, inference-path dynamics, and repetitiveness of agentic flows; profiling five workloads (Haystack RAG, Toolformer, ChemCrow, Langchain, SWE-Agent) to measure latency, throughput, and energy; analysis of bottlenecks; design and evaluation of two optimizations: CPU/GPU-aware micro-batching (CGAM) and mixed agentic workload scheduling (MAWS) for homogeneous and heterogeneous workloads.", "result": "Findings include: (1) Tool processing on CPUs can account for up to 90.6% of total latency; (2) agentic throughput bottlenecks arise from CPU factors (coherence, synchronization, core oversubscription) or GPU limits (main memory capacity and bandwidth); (3) CPU dynamic energy can constitute up to 44% of total dynamic energy at larger batch sizes; (4) proposed optimizations yield up to 2.1x P50 latency improvement for homogeneous workloads and 1.41x for heterogeneous workloads versus a multi-processing baseline.", "conclusion": "A CPU-centric perspective reveals critical bottlenecks in agentic AI and demonstrates that CGAM and MAWS can significantly enhance performance, efficiency, and scalability, highlighting the importance of jointly optimizing CPU/GPU behaviors for agentic systems."}}
{"id": "2511.00191", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00191", "abs": "https://arxiv.org/abs/2511.00191", "authors": ["Ziliang Chen", "Xin Huang", "Quanlong Guan", "Liang Lin", "Weiqi Luo"], "title": "A Retrospect to Multi-prompt Learning across Vision and Language", "comment": "ICCV", "summary": "The vision community is undergoing the unprecedented progress with the\nemergence of Vision-Language Pretraining Models (VLMs). Prompt learning plays\nas the holy grail of accessing VLMs since it enables their fast adaptation to\ndownstream tasks with limited resources. Whereas existing researches milling\naround single-prompt paradigms, rarely investigate the technical potential\nbehind their multi-prompt learning counterparts. This paper aims to provide a\nprincipled retrospect for vision-language multi-prompt learning. We extend the\nrecent constant modality gap phenomenon to learnable prompts and then, justify\nthe superiority of vision-language transfer with multi-prompt augmentation,\nempirically and theoretically. In terms of this observation, we propose an\nEnergy-based Multi-prompt Learning (EMPL) to generate multiple prompt\nembeddings by drawing instances from an energy-based distribution, which is\nimplicitly defined by VLMs. So our EMPL is not only parameter-efficient but\nalso rigorously lead to the balance between in-domain and out-of-domain\nopen-vocabulary generalization. Comprehensive experiments have been conducted\nto justify our claims and the excellence of EMPL.", "AI": {"tldr": "Energy-based Multi-prompt Learning (EMPL) for vision-language models samples multiple prompts from an energy-based distribution defined by the model, enabling parameter-efficient, diverse prompts and improved open-vocabulary generalization. The work provides theoretical justification and empirical validation for multi-prompt augmentation.", "motivation": "VLMs enable rapid adaptation via prompts, but most work centers on a single prompt. Extending to learnable, multi-prompt prompts and leveraging their augmentation potential can enhance cross-domain transfer and generalization. The paper extends the constant modality gap phenomenon to learnable prompts and argues that multi-prompt sampling is beneficial.", "method": "Introduce EMPL: learnable prompts augmented by sampling multiple prompt embeddings from an energy-based distribution implicitly defined by the VLM. This yields a parameter-efficient multi-prompt framework that aims to balance in-domain and out-of-domain open-vocabulary generalization.", "result": "Comprehensive experiments validate that EMPL is parameter-efficient and improves open-vocabulary generalization, outperforming single-prompt baselines and showcasing the effectiveness of multi-prompt augmentation.", "conclusion": "EMPL provides a principled, efficient approach to vision-language multi-prompt learning, extends the constant modality gap to learnable prompts, and demonstrates the benefits of energy-based, multi-prompt augmentation for VLM adaptation."}}
{"id": "2511.00940", "categories": ["cs.RO", "cs.AI", "I.2.6"], "pdf": "https://arxiv.org/pdf/2511.00940", "abs": "https://arxiv.org/abs/2511.00940", "authors": ["Zhe Li", "Xiang Bai", "Jieyu Zhang", "Zhuangzhe Wu", "Che Xu", "Ying Li", "Chengkai Hou", "Shanghang Zhang"], "title": "URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model", "comment": "Accepted to the 39th Conference on Neural Information Processing\n  Systems (NeurIPS 2025)", "summary": "Constructing accurate digital twins of articulated objects is essential for\nrobotic simulation training and embodied AI world model building, yet\nhistorically requires painstaking manual modeling or multi-stage pipelines. In\nthis work, we propose \\textbf{URDF-Anything}, an end-to-end automatic\nreconstruction framework based on a 3D multimodal large language model (MLLM).\nURDF-Anything utilizes an autoregressive prediction framework based on\npoint-cloud and text multimodal input to jointly optimize geometric\nsegmentation and kinematic parameter prediction. It implements a specialized\n$[SEG]$ token mechanism that interacts directly with point cloud features,\nenabling fine-grained part-level segmentation while maintaining consistency\nwith the kinematic parameter predictions. Experiments on both simulated and\nreal-world datasets demonstrate that our method significantly outperforms\nexisting approaches regarding geometric segmentation (mIoU 17\\% improvement),\nkinematic parameter prediction (average error reduction of 29\\%), and physical\nexecutability (surpassing baselines by 50\\%). Notably, our method exhibits\nexcellent generalization ability, performing well even on objects outside the\ntraining set. This work provides an efficient solution for constructing digital\ntwins for robotic simulation, significantly enhancing the sim-to-real transfer\ncapability.", "AI": {"tldr": "Autoregressive, end-to-end URDF reconstruction from 3D multimodal data (point cloud + text) that jointly learns segmentation and kinematic parameters via a SEG token, achieving state-of-the-art geometric and kinematic accuracy and strong generalization for digital twin creation.", "motivation": "Manual modeling of articulated objects is time-consuming and brittle; robust automatic digital twin construction is needed to improve sim-to-real transfer and support embodied AI.", "method": "Autoregressive framework that takes point cloud and text as input to jointly optimize geometric segmentation and kinematic parameter prediction. Introduces a specialized [SEG] token that interacts with point cloud features to enable fine-grained part-level segmentation while ensuring consistency with kinematic predictions.", "result": "Evaluated on simulated and real-world datasets; mIoU for geometry improves by 17 percentage points; average kinematic error reduced by 29%; physical executability improves by 50% over baselines; strong generalization to unseen objects.", "conclusion": "An efficient, scalable solution for automatic digital twin construction that enhances sim-to-real transfer and supports robotic simulation and embodied AI, with demonstrated generalization to objects outside the training set."}}
{"id": "2511.00071", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00071", "abs": "https://arxiv.org/abs/2511.00071", "authors": ["Ertugrul Mutlu"], "title": "Wavelet-Based Feature Extraction and Unsupervised Clustering for Parity Detection: A Feature Engineering Perspective", "comment": "8 pages, 2 figures. Code:\n  github.com/Ertugrulmutlu/Using-Wavelets-and-Clustering-to-Predict-Odd-or-Even-Numbers", "summary": "This paper explores a deliberately over-engineered approach to the classical\nproblem of parity detection -- determining whether a number is odd or even --\nby combining wavelet-based feature extraction with unsupervised clustering.\nInstead of relying on modular arithmetic, integers are transformed into\nwavelet-domain representations, from which multi-scale statistical features are\nextracted and clustered using the k-means algorithm. The resulting feature\nspace reveals meaningful structural differences between odd and even numbers,\nachieving a classification accuracy of approximately 69.67% without any label\nsupervision. These results suggest that classical signal-processing techniques,\noriginally designed for continuous data, can uncover latent structure even in\npurely discrete symbolic domains. Beyond parity detection, the study provides\nan illustrative perspective on how feature engineering and clustering may be\nrepurposed for unconventional machine learning problems, potentially bridging\nsymbolic reasoning and feature-based learning.", "AI": {"tldr": "Unsupervised parity detection using wavelet-based features and k-means achieves ~69.7% accuracy, suggesting DSP-inspired feature extraction can reveal structure in discrete data.", "motivation": "Explore whether classical signal-processing techniques can uncover latent structure for a purely symbolic problem (parity) and bridge symbolic reasoning with feature-based learning.", "method": "Transform integers into wavelet-domain representations, extract multi-scale statistical features, and cluster with k-means; evaluate parity separation without label supervision.", "result": "Achieves approximately 69.67% accuracy for parity classification in an unsupervised setting, indicating meaningful structure in the wavelet feature space.", "conclusion": "Demonstrates that traditional DSP methods can uncover latent structure in discrete domains and highlights potential for repurposing feature engineering and clustering for unconventional machine learning problems."}}
{"id": "2511.00751", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00751", "abs": "https://arxiv.org/abs/2511.00751", "authors": ["Chiyan Loo"], "title": "Reevaluating Self-Consistency Scaling in Multi-Agent Systems", "comment": "7 pages, 3 figures", "summary": "This study examines the trade-offs of increasing sampled reasoning paths in\nself-consistency for modern large language models (LLMs). Earlier research with\nolder models showed that combining multiple reasoning chains improves results\nbefore reaching a plateau. Using Gemini 2.5 models on HotpotQA and Math-500, we\nrevisit those claims under current model conditions. Each configuration pooled\noutputs from varying sampled reasoning paths and compared them to a single\nchain-of-thought (CoT) baseline. Larger models exhibited a more stable and\nconsistent improvement curve. The results confirm that performance gains taper\noff after moderate sampling, aligning with past findings. This plateau suggests\ndiminishing returns driven by overlap among reasoning paths. Self-consistency\nremains useful, but high-sample configurations offer little benefit relative to\ntheir computational cost.", "AI": {"tldr": "Moderate sampling of reasoning paths in self-consistency yields initial gains for modern LLMs but plateaus; higher sampling offers little extra benefit relative to cost, with larger models showing more stable improvements.", "motivation": "Reevaluate self-consistency benefits under current model conditions (Gemini 2.5) on HotpotQA and Math-500 to understand if sampling gains persist and at what cost.", "method": "Compare outputs pooled from varying numbers of sampled reasoning paths to a single CoT baseline across tasks; analyze performance curves and plateau; assess impact of model size on stability and gains.", "result": "Performance improves with more samples up to a point, with larger models showing more stable improvements; gains taper off after moderate sampling due to overlap among reasoning paths; high-sample configurations yield little additional benefit relative to cost.", "conclusion": "Use moderate sampling in self-consistency for efficiency; self-consistency remains useful, but excessive sampling yields diminishing returns; recommend cost-aware deployment."}}
{"id": "2511.00211", "categories": ["cs.CV", "cs.AI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.00211", "abs": "https://arxiv.org/abs/2511.00211", "authors": ["Wenxuan Zhang", "Peng Hu"], "title": "An Efficient and Generalizable Transfer Learning Method for Weather Condition Detection on Ground Terminals", "comment": null, "summary": "The increasing adoption of satellite Internet with low-Earth-orbit (LEO)\nsatellites in mega-constellations allows ubiquitous connectivity to rural and\nremote areas. However, weather events have a significant impact on the\nperformance and reliability of satellite Internet. Adverse weather events such\nas snow and rain can disturb the performance and operations of satellite\nInternet's essential ground terminal components, such as satellite antennas,\nsignificantly disrupting the space-ground link conditions between LEO\nsatellites and ground stations. This challenge calls for not only region-based\nweather forecasts but also fine-grained detection capability on ground terminal\ncomponents of fine-grained weather conditions. Such a capability can assist in\nfault diagnostics and mitigation for reliable satellite Internet, but its\nsolutions are lacking, not to mention the effectiveness and generalization that\nare essential in real-world deployments. This paper discusses an efficient\ntransfer learning (TL) method that can enable a ground component to locally\ndetect representative weather-related conditions. The proposed method can\ndetect snow, wet, and other conditions resulting from adverse and typical\nweather events and shows superior performance compared to the typical deep\nlearning methods, such as YOLOv7, YOLOv9, Faster R-CNN, and R-YOLO. Our TL\nmethod also shows the advantage of being generalizable to various scenarios.", "AI": {"tldr": "A transfer learning-based approach enables local ground-terminal weather-condition detection for satellite LEO networks, outperforming standard detectors and generalizing across scenarios.", "motivation": "Weather-induced impairments threaten space-ground link reliability. Fine-grained, locally adaptable detection on ground terminals is needed for fault diagnostics and mitigation, which existing DL methods fail to provide in practice.", "method": "An efficient transfer learning framework that customizes a base detector to ground-terminal imagery to recognize weather-related conditions (e.g., snow, wet) with lightweight adaptation, comparing against YOLOv7, YOLOv9, Faster R-CNN, and R-YOLO.", "result": "The proposed TL method achieves superior detection performance relative to standard DL baselines and demonstrates strong generalization to various weather scenarios and deployment conditions.", "conclusion": "TL-based ground-terminal weather-condition detection can enhance reliability of satellite Internet in adverse weather by enabling timely diagnostics and mitigation through local, adaptable models."}}
{"id": "2511.00983", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00983", "abs": "https://arxiv.org/abs/2511.00983", "authors": ["Yizhao Qian", "Yujie Zhu", "Jiayuan Luo", "Li Liu", "Yixuan Yuan", "Guochen Ning", "Hongen Liao"], "title": "Breaking the Latency Barrier: Synergistic Perception and Control for High-Frequency 3D Ultrasound Servoing", "comment": null, "summary": "Real-time tracking of dynamic targets amidst large-scale, high-frequency\ndisturbances remains a critical unsolved challenge in Robotic Ultrasound\nSystems (RUSS), primarily due to the end-to-end latency of existing systems.\nThis paper argues that breaking this latency barrier requires a fundamental\nshift towards the synergistic co-design of perception and control. We realize\nit in a novel framework with two tightly-coupled contributions: (1) a Decoupled\nDual-Stream Perception Network that robustly estimates 3D translational state\nfrom 2D images at high frequency, and (2) a Single-Step Flow Policy that\ngenerates entire action sequences in one inference pass, bypassing the\niterative bottleneck of conventional policies. This synergy enables a\nclosed-loop control frequency exceeding 60Hz. On a dynamic phantom, our system\nnot only tracks complex 3D trajectories with a mean error below 6.5mm but also\ndemonstrates robust re-acquisition from over 170mm displacement. Furthermore,\nit can track targets at speeds of 102mm/s, achieving a terminal error below\n1.7mm. Moreover, in-vivo experiments on a human volunteer validate the\nframework's effectiveness and robustness in a realistic clinical setting. Our\nwork presents a RUSS holistically architected to unify high-bandwidth tracking\nwith large-scale repositioning, a critical step towards robust autonomy in\ndynamic clinical environments.", "AI": {"tldr": "A real-time Robotic Ultrasound System (RUSS) framework that co-designs perception and control to break latency barriers, achieving >60 Hz closed-loop tracking with robust 3D target estimation and large-scale repositioning, validated in dynamic phantom and in vivo.", "motivation": "End-to-end latency and low bandwidth perception in RUSS hinder real-time tracking of dynamic targets. A synergistic co-design of perception and control could unlock high-frequency, robust autonomy in dynamic clinical settings.", "method": "1) Decoupled Dual-Stream Perception Network that estimates 3D translation from 2D ultrasound images at high frequency. 2) Single-Step Flow Policy that generates entire action sequences in one inference pass, bypassing iterative policy bottlenecks.", "result": "- Closed-loop control frequency > 60 Hz. - Dynamic phantom: mean 3D trajectory error < 6.5 mm; robust re-acquisition from >170 mm displacement. - Track targets at speeds up to 102 mm/s with terminal error <1.7 mm. - In-vivo experiments on a human volunteer validate effectiveness and robustness in realistic clinical setting.", "conclusion": "A holistic RUSS architecture that unifies high-bandwidth perception with large-scale repositioning addresses a critical bottleneck for robust autonomy in dynamic clinical environments."}}
{"id": "2511.00076", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00076", "abs": "https://arxiv.org/abs/2511.00076", "authors": ["Zihao Wan", "Pau Tong Lin Xu", "Fuwen Luo", "Ziyue Wang", "Peng Li", "Yang Liu"], "title": "Bridging Vision, Language, and Mathematics: Pictographic Character Reconstruction with B\u00e9zier Curves", "comment": null, "summary": "While Vision-language Models (VLMs) have demonstrated strong semantic\ncapabilities, their ability to interpret the underlying geometric structure of\nvisual information is less explored. Pictographic characters, which combine\nvisual form with symbolic structure, provide an ideal test case for this\ncapability. We formulate this visual recognition challenge in the mathematical\ndomain, where each character is represented by an executable program of\ngeometric primitives. This is framed as a program synthesis task, training a\nVLM to decompile raster images into programs composed of B\\'ezier curves. Our\nmodel, acting as a \"visual decompiler\", demonstrates performance superior to\nstrong zero-shot baselines, including GPT-4o. The most significant finding is\nthat when trained solely on modern Chinese characters, the model is able to\nreconstruct ancient Oracle Bone Script in a zero-shot context. This\ngeneralization provides strong evidence that the model acquires an abstract and\ntransferable geometric grammar, moving beyond pixel-level pattern recognition\nto a more structured form of visual understanding.", "AI": {"tldr": "A vision-language model learns to decompile raster pictographic characters into programs of Bezier curves, acting as a visual decompiler; it generalizes from modern Chinese characters to ancient Oracle Bone Script in zero-shot, evidencing an abstract, transferable geometric grammar.", "motivation": "To determine whether VLMs can infer the underlying geometric and structural grammar of visual symbols beyond pixel patterns, using pictographs as a testbed and representing characters as executable geometric programs.", "method": "Represent each character with an executable program composed of Bezier curves and train a VLM to synthesize this program from the raster image (a program synthesis/decompilation task). Evaluate zero-shot generalization to Oracle Bone Script after training on modern Chinese characters.", "result": "The model outperforms strong zero-shot baselines, including GPT-4o, and can reconstruct Oracle Bone Script in zero-shot when trained solely on modern Chinese characters.", "conclusion": "The model appears to learn an abstract and transferable geometric grammar, enabling structured visual understanding that goes beyond pixel-level recognition."}}
{"id": "2511.00758", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00758", "abs": "https://arxiv.org/abs/2511.00758", "authors": ["Hong Su"], "title": "Active Thinking Model: A Goal-Directed Self-Improving Framework for Real-World Adaptive Intelligence", "comment": null, "summary": "Real-world artificial intelligence (AI) systems are increasingly required to\noperate autonomously in dynamic, uncertain, and continuously changing\nenvironments. However, most existing AI models rely on predefined objectives,\nstatic training data, and externally supplied feedback, which restrict their\nability to adapt, reflect, and improve independently. In this paper, we propose\nthe Active Thinking Model (ATM)- a unified cognitive framework that integrates\ngoal reasoning, dynamic task generation, and self-reflective learning into an\nadaptive architecture. Unlike conventional systems that passively execute fixed\nprocedures, ATM actively evaluates its performance through logical reasoning\nand environmental indicators, reuses effective methods to solve new problems,\nand generates novel strategies for unseen situations via a continuous\nself-improvement loop. A mathematically grounded theoretical analysis\ndemonstrates that ATM can autonomously evolve from suboptimal to optimal\nbehavior without external supervision and maintain bounded tracking regret\nunder changing environmental conditions.", "AI": {"tldr": "Introduces Active Thinking Model (ATM), a unified cognitive framework for autonomous, self-improving AI in dynamic environments; claims self-evolution from suboptimal to optimal behavior and bounded regret without external supervision.", "motivation": "Current AI systems rely on predefined objectives, static data, and external feedback, limiting adaptation, reflection, and autonomous improvement in real-world, changing environments.", "method": "ATM integrates goal reasoning, dynamic task generation, and self-reflective learning into an adaptive architecture; uses performance evaluation via logical reasoning and environmental indicators; reuses effective methods, generates novel strategies; continuous self-improvement loop; provides a mathematically grounded theoretical analysis proving autonomous evolution and bounded tracking regret.", "result": "The work provides theoretical analyses with proofs suggesting autonomous evolution from suboptimal to optimal behavior and bounded regret under changing environments; empirical validation is not specified in the abstract, suggesting a theoretical focus.", "conclusion": "ATM offers a unified, autonomous framework for adaptive AI capable of self-improvement and robust performance in dynamic environments, potentially reducing the need for external supervision."}}
{"id": "2511.00218", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00218", "abs": "https://arxiv.org/abs/2511.00218", "authors": ["Rajatsubhra Chakraborty", "Ana Espinosa-Momox", "Riley Haskin", "Depeng Xu", "Rosario Porras-Aguilar"], "title": "DM-QPMNET: Dual-modality fusion network for cell segmentation in quantitative phase microscopy", "comment": "5 pages, 4 figures", "summary": "Cell segmentation in single-shot quantitative phase microscopy (ssQPM) faces\nchallenges from traditional thresholding methods that are sensitive to noise\nand cell density, while deep learning approaches using simple channel\nconcatenation fail to exploit the complementary nature of polarized intensity\nimages and phase maps. We introduce DM-QPMNet, a dual-encoder network that\ntreats these as distinct modalities with separate encoding streams. Our\narchitecture fuses modality-specific features at intermediate depth via\nmulti-head attention, enabling polarized edge and texture representations to\nselectively integrate complementary phase information. This content-aware\nfusion preserves training stability while adding principled multi-modal\nintegration through dual-source skip connections and per-modality normalization\nat minimal overhead. Our approach demonstrates substantial improvements over\nmonolithic concatenation and single-modality baselines, showing that\nmodality-specific encoding with learnable fusion effectively exploits ssQPM's\nsimultaneous capture of complementary illumination and phase cues for robust\ncell segmentation.", "AI": {"tldr": "Dual-encoder multimodal network DM-QPMNet for ssQPM cell segmentation; separate encoders for polarized intensity and phase maps with multi-head attention-based fusion achieve better segmentation than simple concatenation.", "motivation": "Challenges: thresholding is noise- and density-sensitive; simple channel concatenation fails to exploit complementary information between polarization and phase data; need principled multi-modal integration for robust segmentation.", "method": "DM-QPMNet uses two encoders for the two modalities, intermediate-depth feature fusion via multi-head attention, per-modality normalization, and dual-source skip connections to maintain training stability with minimal overhead.", "result": "Outperforms monolithic concatenation and single-modality baselines, demonstrating effective integration of polarized edge/texture cues with phase information for robust ssQPM cell segmentation.", "conclusion": "Modality-specific encoding with learnable fusion is effective for multimodal ssQPM segmentation and can generalize to other multi-modal microscopy tasks."}}
{"id": "2511.00998", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00998", "abs": "https://arxiv.org/abs/2511.00998", "authors": ["Ziye Wang", "Li Kang", "Yiran Qin", "Jiahua Ma", "Zhanglin Peng", "Lei Bai", "Ruimao Zhang"], "title": "GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies", "comment": "Accepted by NeurIPS 2025. Project page:\n  https://ziyeeee.github.io/gaudp.io/", "summary": "Recently, effective coordination in embodied multi-agent systems has remained\na fundamental challenge, particularly in scenarios where agents must balance\nindividual perspectives with global environmental awareness. Existing\napproaches often struggle to balance fine-grained local control with\ncomprehensive scene understanding, resulting in limited scalability and\ncompromised collaboration quality. In this paper, we present GauDP, a novel\nGaussian-image synergistic representation that facilitates scalable,\nperception-aware imitation learning in multi-agent collaborative systems.\nSpecifically, GauDP constructs a globally consistent 3D Gaussian field from\ndecentralized RGB observations, then dynamically redistributes 3D Gaussian\nattributes to each agent's local perspective. This enables all agents to\nadaptively query task-critical features from the shared scene representation\nwhile maintaining their individual viewpoints. This design facilitates both\nfine-grained control and globally coherent behavior without requiring\nadditional sensing modalities (e.g., 3D point cloud). We evaluate GauDP on the\nRoboFactory benchmark, which includes diverse multi-arm manipulation tasks. Our\nmethod achieves superior performance over existing image-based methods and\napproaches the effectiveness of point-cloud-driven methods, while maintaining\nstrong scalability as the number of agents increases.", "AI": {"tldr": "GauDP introduces a scalable, perception-aware imitation learning framework for multi-agent systems by building a global 3D Gaussian field from decentralized RGB observations and distributing its attributes to agents, enabling fine-grained control with globally coherent behavior without extra sensing like 3D point clouds.", "motivation": "The challenge is to coordinate multiple agents while balancing local control with global environmental awareness; existing methods struggle with scalability and collaboration quality when relying solely on imagery or lacking a shared scene representation.", "method": "Construct a globally consistent 3D Gaussian field from decentralized RGB observations and dynamically redistribute 3D Gaussian attributes to each agent\u2019s local perspective, allowing agents to query task-critical features from the shared scene representation while preserving individual viewpoints.", "result": "GauDP outperforms existing image-based methods and approaches the effectiveness of point-cloud-driven methods on RoboFactory multi-arm manipulation tasks, with strong scalability as the number of agents increases.", "conclusion": "A perception-aware, scalable imitation learning framework that achieves fine-grained, globally coherent behavior using RGB data alone, reducing the need for additional sensing modalities while narrowing the gap to point-cloud-based approaches."}}
{"id": "2511.00079", "categories": ["cs.LG", "cs.CY", "stat.ME", "62-04, 62-07", "D.2.11; G.3; I.2.6"], "pdf": "https://arxiv.org/pdf/2511.00079", "abs": "https://arxiv.org/abs/2511.00079", "authors": ["Maximilian Willer", "Peter Ruckdeschel"], "title": "flowengineR: A Modular and Extensible Framework for Fair and Reproducible Workflow Design in R", "comment": "27 pages, 7 figures, 1 table", "summary": "flowengineR is an R package designed to provide a modular and extensible\nframework for building reproducible algorithmic workflows for general-purpose\nmachine learning pipelines. It is motivated by the rapidly evolving field of\nalgorithmic fairness where new metrics, mitigation strategies, and machine\nlearning methods continuously emerge. A central challenge in fairness, but also\nfar beyond, is that existing toolkits either focus narrowly on single\ninterventions or treat reproducibility and extensibility as secondary\nconsiderations rather than core design principles. flowengineR addresses this\nby introducing a unified architecture of standardized engines for data\nsplitting, execution, preprocessing, training, inprocessing, postprocessing,\nevaluation, and reporting. Each engine encapsulates one methodological task yet\ncommunicates via a lightweight interface, ensuring workflows remain\ntransparent, auditable, and easily extensible. Although implemented in R,\nflowengineR builds on ideas from workflow languages (CWL, YAWL), graph-oriented\nvisual programming languages (KNIME), and R frameworks (BatchJobs, batchtools).\nIts emphasis, however, is less on orchestrating engines for resilient parallel\nexecution but rather on the straightforward setup and management of distinct\nengines as data structures. This orthogonalization enables distributed\nresponsibilities, independent development, and streamlined integration. In\nfairness context, by structuring fairness methods as interchangeable engines,\nflowengineR lets researchers integrate, compare, and evaluate interventions\nacross the modeling pipeline. At the same time, the architecture generalizes to\nexplainability, robustness, and compliance metrics without core modifications.\nWhile motivated by fairness, it ultimately provides a general infrastructure\nfor any workflow context where reproducibility, transparency, and extensibility\nare essential.", "AI": {"tldr": "FlowengineR is an R-based modular framework that encodes reproducible ML workflows as interchangeable engines, motivated by evolving algorithmic fairness research and designed for transparency, extensibility, and cross-domain applicability.", "motivation": "The rapid emergence of new fairness metrics, mitigation strategies, and ML methods creates a need for reproducible, extensible workflows. Existing toolkits are often narrow or treat reproducibility as secondary. The paper motivates a general infrastructure to support evolving algorithmic fairness research while remaining broadly applicable.", "method": "Proposes a unified architecture of standardized engines for data splitting, execution, preprocessing, training, inprocessing, postprocessing, evaluation, and reporting. Each engine handles a distinct task but communicates via a lightweight interface. The design emphasizes straightforward setup and management of engines as data structures (orthogonalization) over orchestrating parallel execution. It draws inspiration from CWL, YAWL, KNIME, and R frameworks like BatchJobs/batchtools, but focuses on modularity and extensibility rather than distributed orchestration.", "result": "Establishes a general infrastructure enabling researchers to plug in, compare, and evaluate different interventions across the modeling pipeline, not limited to fairness. The architecture supports explainability, robustness, and compliance metrics with minimal core changes, enabling transparent, auditable workflows and easy integration of new methods.", "conclusion": "FlowengineR offers a general, reusable infrastructure for reproducible, transparent, and extensible ML workflows, particularly beneficial for fairness research but applicable to any domain requiring structured pipelines and modular engines."}}
{"id": "2511.00763", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00763", "abs": "https://arxiv.org/abs/2511.00763", "authors": ["Wanda Hou", "Leon Zhou", "Hong-Ye Hu", "Yi-Zhuang You", "Xiao-Liang Qi"], "title": "How Focused Are LLMs? A Quantitative Study via Repetitive Deterministic Prediction Tasks", "comment": null, "summary": "We investigate the performance of large language models on repetitive\ndeterministic prediction tasks and study how the sequence accuracy rate scales\nwith output length. Each such task involves repeating the same operation n\ntimes. Examples include letter replacement in strings following a given rule,\ninteger addition, and multiplication of string operators in many body quantum\nmechanics. If the model performs the task through a simple repetition\nalgorithm, the success rate should decay exponentially with sequence length. In\ncontrast, our experiments on leading large language models reveal a sharp\ndouble exponential drop beyond a characteristic length scale, forming an\naccuracy cliff that marks the transition from reliable to unstable generation.\nThis indicates that the models fail to execute each operation independently. To\nexplain this phenomenon, we propose a statistical physics inspired model that\ncaptures the competition between external conditioning from the prompt and\ninternal interference among generated tokens. The model quantitatively\nreproduces the observed crossover and provides an interpretable link between\nattention induced interference and sequence level failure. Fitting the model to\nempirical results across multiple models and tasks yields effective parameters\nthat characterize the intrinsic error rate and error accumulation factor for\neach model task pair, offering a principled framework for understanding the\nlimits of deterministic accuracy in large language models.", "AI": {"tldr": "LLMs show an accuracy cliff in repetitive deterministic tasks: sequence accuracy decays with length, but not exponentially as a simple repetition would; instead there is a sharp double-exponential drop beyond a characteristic length, indicating failures arise from interference rather than independent per-step errors. A statistical-physics\u2013inspired model captures the competition between prompt conditioning and internal token interference, reproducing the crossover and enabling estimation of intrinsic error rate and error accumulation factors across model-task pairs.", "motivation": "To understand why large language models struggle to maintain deterministic correctness over long, repetitive tasks and to quantify the underlying mechanisms limiting their deterministic accuracy.", "method": "Evaluate leading LLMs on repetitive deterministic tasks (e.g., letter replacement under a rule, integer addition, and operator multiplication in quantum mechanics). Measure sequence-level accuracy as a function of length. Compare against the exponential decay expected from a simple repetition algorithm. Develop a statistical-physics\u2013inspired model that treats the competition between external conditioning and internal token interaction as the driver of failure, and fit this model to empirical results to extract parameters.", "result": "Empirical results show a sharp double exponential drop in accuracy beyond a characteristic length, forming an accuracy cliff. The simple single-step repetition picture is insufficient. The proposed model reproduces the crossover and links accuracy loss to attention-induced interference. Fitting yields effective parameters characterizing intrinsic error rate and error accumulation for each model-task pair, enabling a principled framework for deterministic accuracy limits.", "conclusion": "The observed sequence-level failure in deterministic tasks stems from interference between generated tokens, not independent per-step errors. A physics-inspired framework successfully explains the crossover and provides quantitative metrics to characterize model-task reliability, offering a principled way to understand and compare the deterministic capabilities of large language models across tasks and prompts."}}
{"id": "2511.00231", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00231", "abs": "https://arxiv.org/abs/2511.00231", "authors": ["Fuming Yang", "Yicong Li", "Hanspeter Pfister", "Jeff W. Lichtman", "Yaron Meirovitch"], "title": "Towards 1000-fold Electron Microscopy Image Compression for Connectomics via VQ-VAE with Transformer Prior", "comment": null, "summary": "Petascale electron microscopy (EM) datasets push storage, transfer, and\ndownstream analysis toward their current limits. We present a vector-quantized\nvariational autoencoder-based (VQ-VAE) compression framework for EM that spans\n16x to 1024x and enables pay-as-you-decode usage: top-only decoding for extreme\ncompression, with an optional Transformer prior that predicts bottom tokens\n(without changing the compression ratio) to restore texture via feature-wise\nlinear modulation (FiLM) and concatenation; we further introduce an ROI-driven\nworkflow that performs selective high-resolution reconstruction from\n1024x-compressed latents only where needed.", "AI": {"tldr": "A VQ-VAE-based compression framework for petascale EM data enabling extreme compression (16x\u20131024x) with pay-as-you-decode decoding; includes an optional Transformer prior to predict bottom tokens to restore texture via FiLM/concatenation, and an ROI-driven workflow for selective high-resolution reconstruction from 1024x latents where needed.", "motivation": "Petascale electron microscopy datasets challenge storage, transfer, and downstream analysis. There is a need for scalable, flexible compression that preserves essential texture while enabling selective high-resolution reconstructions to focus compute where it matters.", "method": "Use a vector-quantized variational autoencoder (VQ-VAE) for lossy compression. Support pay-as-you-decode: top-only decoding for extreme compression. Include an optional Transformer prior that predicts bottom tokens without changing the compression ratio to restore texture via feature-wise linear modulation (FiLM) and concatenation. Introduce an ROI-driven workflow that performs selective high-resolution reconstruction from 1024x-compressed latents only where needed.", "result": "The framework provides 16x\u20131024x compression with pay-as-you-decode capability, an optional Transformer-based texture restoration pathway, and an ROI-driven workflow enabling selective high-resolution reconstruction from highly compressed latents.", "conclusion": "This approach offers scalable, ROI-aware compression for petascale EM data, balancing storage/transfer efficiency with the ability to selectively restore high-resolution texture where it matters, potentially reducing decode costs and enabling targeted analyses."}}
{"id": "2511.01031", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01031", "abs": "https://arxiv.org/abs/2511.01031", "authors": ["Mathieu Dubied", "Paolo Tiso", "Robert K. Katzschmann"], "title": "AquaROM: shape optimization pipeline for soft swimmers using parametric reduced order models", "comment": null, "summary": "The efficient optimization of actuated soft structures, particularly under\ncomplex nonlinear forces, remains a critical challenge in advancing robotics.\nSimulations of nonlinear structures, such as soft-bodied robots modeled using\nthe finite element method (FEM), often demand substantial computational\nresources, especially during optimization. To address this challenge, we\npropose a novel optimization algorithm based on a tensorial parametric reduced\norder model (PROM). Our algorithm leverages dimensionality reduction and\nsolution approximation techniques to facilitate efficient solving of nonlinear\nconstrained optimization problems. The well-structured tensorial approach\nenables the use of analytical gradients within a specifically chosen reduced\norder basis (ROB), significantly enhancing computational efficiency. To\nshowcase the performance of our method, we apply it to optimizing soft robotic\nswimmer shapes. These actuated soft robots experience hydrodynamic forces,\nsubjecting them to both internal and external nonlinear forces, which are\nincorporated into our optimization process using a data-free ROB for fast and\naccurate computations. This approach not only reduces computational complexity\nbut also unlocks new opportunities to optimize complex nonlinear systems in\nsoft robotics, paving the way for more efficient design and control.", "AI": {"tldr": "Introduces a tensorial parametric reduced order model (PROM) for efficient, nonlinear constrained optimization of FEM-modeled soft robots, using dimensionality reduction and analytical gradients in a reduced basis; validated on soft swimmer shape optimization with a data-free ROB.", "motivation": "Optimizing actuated soft structures under nonlinear forces is computationally expensive due to full-order FEM simulations; faster, accurate optimization methods are needed to enable design and control of soft robotics.", "method": "Develops a tensorial PROM with dimensionality reduction and solution approximation. It enables analytical gradients within a chosen reduced order basis (ROB) and uses a data-free ROB for fast computations. The approach is applied to optimizing soft robotic swimmer shapes experiencing hydrodynamic, internal, and external nonlinear forces.", "result": "Demonstrates computational efficiency gains and the ability to handle nonlinear forces in optimization of soft robots, with a case study on soft swimmer shape optimization using a data-free ROB for fast and accurate evaluations.", "conclusion": "The tensorial PROM approach reduces computational complexity and unlocks efficient design and control for complex nonlinear soft robotic systems."}}
{"id": "2511.00083", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00083", "abs": "https://arxiv.org/abs/2511.00083", "authors": ["Shakib Khan", "A. Ben Hamza", "Amr Youssef"], "title": "Fixed-point graph convolutional networks against adversarial attacks", "comment": null, "summary": "Adversarial attacks present a significant risk to the integrity and\nperformance of graph neural networks, particularly in tasks where graph\nstructure and node features are vulnerable to manipulation. In this paper, we\npresent a novel model, called fixed-point iterative graph convolutional network\n(Fix-GCN), which achieves robustness against adversarial perturbations by\neffectively capturing higher-order node neighborhood information in the graph\nwithout additional memory or computational complexity. Specifically, we\nintroduce a versatile spectral modulation filter and derive the feature\npropagation rule of our model using fixed-point iteration. Unlike traditional\ndefense mechanisms that rely on additional design elements to counteract\nattacks, the proposed graph filter provides a flexible-pass filtering approach,\nallowing it to selectively attenuate high-frequency components while preserving\nlow-frequency structural information in the graph signal. By iteratively\nupdating node representations, our model offers a flexible and efficient\nframework for preserving essential graph information while mitigating the\nimpact of adversarial manipulation. We demonstrate the effectiveness of the\nproposed model through extensive experiments on various benchmark graph\ndatasets, showcasing its resilience against adversarial attacks.", "AI": {"tldr": "Fix-GCN uses a fixed-point inspired propagation with a spectral modulation filter to achieve adversarial robustness in graph neural networks without extra memory/computation, by preserving low-frequency structural info while attenuating high-frequency perturbations and iteratively updating node features.", "motivation": "Adversarial attacks threaten GNNs by perturbing structure and features; robust defenses often add complexity. The paper aims to achieve robustness efficiently by exploiting higher-order neighborhood information through a fixed-point propagation framework.", "method": "Propose fixed-point iterative graph convolutional network (Fix-GCN) with a versatile spectral modulation filter; derive feature propagation rule via fixed-point iteration; implement flexible-pass filtering to suppress high-frequency noise while preserving low-frequency structure; no extra memory or computational cost; iterative node feature updates.", "result": "Extensive experiments on benchmark graph datasets demonstrate resilience against adversarial attacks, indicating improved robustness without increased resource requirements.", "conclusion": "Fix-GCN provides a flexible and efficient defense mechanism against adversarial perturbations by maintaining essential graph information through fixed-point propagation and spectral filtering, suggesting a practical direction for robust GNNs."}}
{"id": "2511.00782", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00782", "abs": "https://arxiv.org/abs/2511.00782", "authors": ["Jifan Gao", "Michael Rosenthal", "Brian Wolpin", "Simona Cristea"], "title": "Count-Based Approaches Remain Strong: A Benchmark Against Transformer and LLM Pipelines on Structured EHR", "comment": null, "summary": "Structured electronic health records (EHR) are essential for clinical\nprediction. While count-based learners continue to perform strongly on such\ndata, no benchmarking has directly compared them against more recent\nmixture-of-agents LLM pipelines, which have been reported to outperform single\nLLMs in various NLP tasks. In this study, we evaluated three categories of\nmethodologies for EHR prediction using the EHRSHOT dataset: count-based models\nbuilt from ontology roll-ups with two time bins, based on LightGBM and the\ntabular foundation model TabPFN; a pretrained sequential transformer (CLMBR);\nand a mixture-of-agents pipeline that converts tabular histories to\nnatural-language summaries followed by a text classifier. We assessed eight\noutcomes using the EHRSHOT dataset. Across the eight evaluation tasks,\nhead-to-head wins were largely split between the count-based and the\nmixture-of-agents methods. Given their simplicity and interpretability,\ncount-based models remain a strong candidate for structured EHR benchmarking.\nThe source code is available at:\nhttps://github.com/cristea-lab/Structured_EHR_Benchmark.", "AI": {"tldr": "Count-based models and mixture-of-agents LLM pipelines are both competitive for structured EHR prediction on EHRSHOT; there is no clear overall winner, with head-to-head wins split across the two approaches. Count-based methods remain simple and interpretable and thus strong baselines for benchmarking.", "motivation": "To benchmark whether newer mixture-of-agents LLM pipelines outperform traditional count-based models on structured EHR data, addressing the gap in direct comparison for EHR prediction.", "method": "Evaluate three methodological categories on the EHRSHOT dataset: (1) count-based models built from ontology roll-ups with two time bins using LightGBM and TabPFN; (2) a pretrained sequential transformer (CLMBR); (3) a mixture-of-agents pipeline that converts tabular histories to natural-language summaries and applies a text classifier. Eight outcomes were assessed to compare performance.", "result": "Across eight evaluation tasks, head-to-head wins were largely split between the count-based models and the mixture-of-agents pipeline, with no single approach dominating. This indicates that count-based models remain strong, interpretable baselines for structured EHR benchmarking, comparable to newer mixture-of-agents approaches.", "conclusion": "Count-based models remain a strong, simple, and interpretable baseline for structured EHR benchmarking, while mixture-of-agents LLM pipelines can be competitive but do not universally outperform traditional methods. The work provides a direct comparison and a public codebase for replication."}}
{"id": "2511.00244", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00244", "abs": "https://arxiv.org/abs/2511.00244", "authors": ["Yan Bin Ng", "Xianfeng Gu"], "title": "Hyperbolic Optimal Transport", "comment": "65 pages, 21 figures", "summary": "The optimal transport (OT) problem aims to find the most efficient mapping\nbetween two probability distributions under a given cost function, and has\ndiverse applications in many fields such as machine learning, computer vision\nand computer graphics. However, existing methods for computing optimal\ntransport maps are primarily developed for Euclidean spaces and the sphere. In\nthis paper, we explore the problem of computing the optimal transport map in\nhyperbolic space, which naturally arises in contexts involving hierarchical\ndata, networks, and multi-genus Riemann surfaces. We propose a novel and\nefficient algorithm for computing the optimal transport map in hyperbolic space\nusing a geometric variational technique by extending methods for Euclidean and\nspherical geometry to the hyperbolic setting. We also perform experiments on\nsynthetic data and multi-genus surface models to validate the efficacy of the\nproposed method.", "AI": {"tldr": "Efficient hyperbolic OT map via geometric variational approach, extending Euclidean/spherical methods; tested on synthetic data and multi-genus surfaces.", "motivation": "OT is fundamental for comparing distributions; existing methods focus on Euclidean spaces and the sphere. Hyperbolic space naturally captures hierarchical/network data and multi-genus surfaces, motivating development of OT in hyperbolic geometry.", "method": "Introduce a novel geometric variational framework to compute OT maps in hyperbolic space by adapting variational principles from Euclidean/spherical OT to hyperbolic geometry, leveraging hyperbolic distance, geodesics, and appropriate discretization for optimization.", "result": "Empirical validation on synthetic data and multi-genus surface models demonstrates the method's effectiveness and efficiency in computing OT maps in hyperbolic space.", "conclusion": "The work extends optimal transport to hyperbolic geometry with a practical algorithm, enabling applications to hierarchical and network-structured data and complex surfaces; future work includes theoretical guarantees, scalability, and broader experiments."}}
{"id": "2511.01083", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01083", "abs": "https://arxiv.org/abs/2511.01083", "authors": ["Zihan Wang", "Jianwen Li", "Li-Fan Wu", "Nina Mahmoudian"], "title": "Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment", "comment": "Submitted to ICRA 2026", "summary": "Rivers are critical corridors for environmental monitoring and disaster\nresponse, where Unmanned Aerial Vehicles (UAVs) guided by vision-driven\npolicies can provide fast, low-cost coverage. However, deployment exposes\nsimulation-trained policies with distribution shift and safety risks and\nrequires efficient adaptation from limited human interventions. We study\nhuman-in-the-loop (HITL) learning with a conservative overseer who vetoes\nunsafe or inefficient actions and provides statewise preferences by comparing\nthe agent's proposal with a corrective override. We introduce Statewise Hybrid\nPreference Alignment for Robotics (SPAR-H), which fuses direct preference\noptimization on policy logits with a reward-based pathway that trains an\nimmediate-reward estimator from the same preferences and updates the policy\nusing a trust-region surrogate. With five HITL rollouts collected from a fixed\nnovice policy, SPAR-H achieves the highest final episodic reward and the lowest\nvariance across initial conditions among tested methods. The learned reward\nmodel aligns with human-preferred actions and elevates nearby non-intervened\nchoices, supporting stable propagation of improvements. We benchmark SPAR-H\nagainst imitation learning (IL), direct preference variants, and evaluative\nreinforcement learning (RL) in the HITL setting, and demonstrate real-world\nfeasibility of continual preference alignment for UAV river following. Overall,\ndual statewise preferences empirically provide a practical route to\ndata-efficient online adaptation in riverine navigation.", "AI": {"tldr": "SPAR-H combines statewise human preferences with a reward estimator and trust-region updates to enable data-efficient HITL adaptation for UAV river navigation, outperforming IL and RL baselines.", "motivation": "Simulation-trained policies for UAV river following suffer from distribution shift and safety risks; there is a need for data-efficient, human-in-the-loop adaptation with safety constraints and limited interventions.", "method": "Introduce Statewise Hybrid Preference Alignment for Robotics (SPAR-H) that fuses direct preference optimization on policy logits with a reward-based pathway that trains an immediate-reward estimator from the same preferences and updates the policy using a trust-region surrogate; uses a conservative overseer to veto unsafe/inefficient actions and provide statewise comparisons.", "result": "With five HITL rollouts from a fixed novice policy, SPAR-H achieves the highest final episodic reward and lowest variance across initial conditions among tested methods; the learned reward model aligns with human actions and elevates nearby non-intervened choices, enabling stable improvement propagation; competitive against imitation learning, direct preference variants, and evaluative RL in HITL settings; demonstrates real-world feasibility of continual preference alignment for UAV river following.", "conclusion": "Dual statewise preferences offer a practical, data-efficient pathway for online adaptation in riverine navigation, enabling safe, effective HITL-guided policy improvement for UAVs."}}
{"id": "2511.00084", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00084", "abs": "https://arxiv.org/abs/2511.00084", "authors": ["Jolanta \u015aliwa"], "title": "Application of predictive machine learning in pen & paper RPG game design", "comment": "Master's thesis submitted at AGH University of Science and Technology", "summary": "In recent years, the pen and paper RPG market has experienced significant\ngrowth. As a result, companies are increasingly exploring the integration of AI\ntechnologies to enhance player experience and gain a competitive edge.\n  One of the key challenges faced by publishers is designing new opponents and\nestimating their challenge level. Currently, there are no automated methods for\ndetermining a monster's level; the only approaches used are based on manual\ntesting and expert evaluation. Although these manual methods can provide\nreasonably accurate estimates, they are time-consuming and resource-intensive.\n  Level prediction can be approached using ordinal regression techniques. This\nthesis presents an overview and evaluation of state-of-the-art methods for this\ntask. It also details the construction of a dedicated dataset for level\nestimation. Furthermore, a human-inspired model was developed to serve as a\nbenchmark, allowing comparison between machine learning algorithms and the\napproach typically employed by pen and paper RPG publishers. In addition, a\nspecialized evaluation procedure, grounded in domain knowledge, was designed to\nassess model performance and facilitate meaningful comparisons.", "AI": {"tldr": "Survey and evaluation of ML methods for predicting monster level in pen-and-paper RPGs; introduces a dedicated dataset, a human-inspired benchmark, and a domain-grounded evaluation procedure.", "motivation": "Growing pen-and-paper RPG market and publishers' interest in AI to design foes and estimate challenge; current automated methods do not exist, making manual, time-consuming processes the default.", "method": "Review of state-of-the-art ordinal regression methods; creation of a dedicated level-estimation dataset; development of a human-inspired benchmark model; and a domain-informed evaluation procedure for fair comparisons.", "result": "Provides an overview and evaluation of current methods; constructs a dataset; introduces a benchmark; and proposes a domain-specific evaluation protocol to enable meaningful comparisons between ML models and publisher approaches.", "conclusion": "Establishes groundwork for automated monster-level prediction and offers a practical benchmark and evaluation framework for future research in RPG AI."}}
{"id": "2511.00808", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00808", "abs": "https://arxiv.org/abs/2511.00808", "authors": ["Bowen Fang", "Ruijian Zha", "Xuan Di"], "title": "Do Math Reasoning LLMs Help Predict the Impact of Public Transit Events?", "comment": null, "summary": "Predicting public transit incident duration from unstructured text alerts is\na critical but challenging task. Addressing the domain sparsity of transit\noperations with standard Supervised Fine-Tuning (SFT) is difficult, as the task\ninvolves noisy, continuous labels and lacks reliable expert demonstrations for\nreasoning. While Reinforcement Learning from Verifiable Rewards (RLVR) excels\nat tasks with binary correctness, like mathematics, its applicability to noisy,\ncontinuous forecasting is an open question. This work, to our knowledge, is the\nfirst to bridge the gap between RLVR LLM training with the critical, real-world\nforecasting challenges in public transit operations. We adapt RLVR to this task\nby introducing a tolerance-based, shaped reward function that grants partial\ncredit within a continuous error margin, rather than demanding a single correct\nanswer. We systematically evaluate this framework on a curated dataset of NYC\nMTA service alerts. Our findings show that general-purpose, instruction-tuned\nLLMs significantly outperform specialized math-reasoning models, which struggle\nwith the ambiguous, real-world text. We empirically demonstrate that the binary\nreward is unstable and degrades performance, whereas our shaped reward design\nis critical and allows our model to dominate on the most challenging metrics.\nWhile classical regressors are superior at minimizing overall MAE or MSE, our\nRLVR approach achieved a 35\\% relative improvement in 5-minute accuracy (Acc@5)\nover the strongest baseline. This demonstrates that RLVR can be successfully\nadapted to real-world, noisy forecasting, but requires a verifier design that\nreflects the continuous nature of the problem.", "AI": {"tldr": "RLVR with a tolerance-based shaped reward improves 5-minute forecast accuracy on NYC transit alerts, outperforming math-reasoning models and baselines; shaped rewards are crucial, while classical regressors excel at MAE/MSE.", "motivation": "To adapt reinforcement-learning-based verifier training to real-world, noisy, continuous forecasting in public transit operations where standard supervised fine-tuning and binary rewards are inadequate.", "method": "Adapt RLVR with a tolerance-based, continuous-shaped reward for predicting transit incident durations; compare instruction-tuned LLMs to math-reasoning models; evaluate on a curated NYC MTA alerts dataset; analyze the impact of binary vs shaped rewards.", "result": "Shaped rewards are essential: binary rewards are unstable and degrade performance; instruction-tuned LLMs outperform specialized math-reasoning models on the ambiguous real-world text; RLVR achieves 35% relative improvement in Acc@5 over the strongest baseline, though classical regressors may have lower MAE/MSE.", "conclusion": "RLVR can be effectively applied to real-world, noisy forecasting with a reward design that reflects continuous outcomes; verifier design is critical to success; shows promise for bridging RLVR with practical forecasting tasks."}}
{"id": "2511.00248", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.00248", "abs": "https://arxiv.org/abs/2511.00248", "authors": ["Shurui Gui", "Deep Anil Patel", "Xiner Li", "Martin Renqiang Min"], "title": "Object-Aware 4D Human Motion Generation", "comment": null, "summary": "Recent advances in video diffusion models have enabled the generation of\nhigh-quality videos. However, these videos still suffer from unrealistic\ndeformations, semantic violations, and physical inconsistencies that are\nlargely rooted in the absence of 3D physical priors. To address these\nchallenges, we propose an object-aware 4D human motion generation framework\ngrounded in 3D Gaussian representations and motion diffusion priors. With\npre-generated 3D humans and objects, our method, Motion Score Distilled\nInteraction (MSDI), employs the spatial and prompt semantic information in\nlarge language models (LLMs) and motion priors through the proposed Motion\nDiffusion Score Distillation Sampling (MSDS). The combination of MSDS and LLMs\nenables our spatial-aware motion optimization, which distills score gradients\nfrom pre-trained motion diffusion models, to refine human motion while\nrespecting object and semantic constraints. Unlike prior methods requiring\njoint training on limited interaction datasets, our zero-shot approach avoids\nretraining and generalizes to out-of-distribution object aware human motions.\nExperiments demonstrate that our framework produces natural and physically\nplausible human motions that respect 3D spatial context, offering a scalable\nsolution for realistic 4D generation.", "AI": {"tldr": "Zero-shot, object-aware 4D human motion generation using 3D Gaussian representations, diffusion priors, and MSDS guided by LLMs to produce physically plausible motions without retraining.", "motivation": "Video diffusion models struggle to enforce 3D physical priors and object interactions, leading to deformations and semantic/physical violations. A scalable, zero-shot approach with 3D priors and object-awareness is needed.", "method": "Pre-generated 3D humans and objects are used. The Motion Score Distilled Interaction (MSDI) framework combines spatial and prompt semantic information from LLMs with motion priors via Motion Diffusion Score Distillation Sampling (MSDS). It distills score gradients from pre-trained motion diffusion models to optimize motion while honoring object and semantic constraints, without joint retraining.", "result": "The method yields natural, physically plausible human motions that respect 3D spatial context and object constraints, demonstrating a scalable solution for realistic 4D generation and generalization to out-of-distribution object-aware motions.", "conclusion": "The paper presents a scalable zero-shot framework for object-aware 4D human motion generation that enforces 3D spatial and semantic constraints without retraining, offering a practical path toward realistic video diffusion-based 4D content."}}
{"id": "2511.01107", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01107", "abs": "https://arxiv.org/abs/2511.01107", "authors": ["Y. Isabel Liu", "Bowen Li", "Benjamin Eysenbach", "Tom Silver"], "title": "SLAP: Shortcut Learning for Abstract Planning", "comment": null, "summary": "Long-horizon decision-making with sparse rewards and continuous states and\nactions remains a fundamental challenge in AI and robotics. Task and motion\nplanning (TAMP) is a model-based framework that addresses this challenge by\nplanning hierarchically with abstract actions (options). These options are\nmanually defined, limiting the agent to behaviors that we as human engineers\nknow how to program (pick, place, move). In this work, we propose Shortcut\nLearning for Abstract Planning (SLAP), a method that leverages existing TAMP\noptions to automatically discover new ones. Our key idea is to use model-free\nreinforcement learning (RL) to learn shortcuts in the abstract planning graph\ninduced by the existing options in TAMP. Without any additional assumptions or\ninputs, shortcut learning leads to shorter solutions than pure planning, and\nhigher task success rates than flat and hierarchical RL. Qualitatively, SLAP\ndiscovers dynamic physical improvisations (e.g., slap, wiggle, wipe) that\ndiffer significantly from the manually-defined ones. In experiments in four\nsimulated robotic environments, we show that SLAP solves and generalizes to a\nwide range of tasks, reducing overall plan lengths by over 50% and consistently\noutperforming planning and RL baselines.", "AI": {"tldr": "SLAP learns abstract shortcuts in a TAMP planning graph via model-free RL, automatically discovering new options that shorten plans and boost task success. It uncovers dynamic improvisations beyond manually defined options, reducing plan lengths by over 50% and outperforming planning and RL baselines across four simulated robotic environments.", "motivation": "Long-horizon decision-making with sparse rewards in continuous state/action spaces is challenging. TAMP relies on manually defined options, which limits the agent to human-known behaviors; there is a need to automatically discover useful abstract actions to improve planning efficiency and generalization.", "method": "Apply model-free reinforcement learning to the abstract planning graph generated by existing TAMP options to learn shortcut actions. No extra inputs are required. The approach discovers new, potentially dynamic improvisations and evaluates performance on four simulated robotic environments, comparing against planning and RL baselines.", "result": "SLAP yields shorter plans than pure planning and higher task success rates than flat and hierarchical RL. It reduces overall plan lengths by over 50% and generalizes across a wide range of tasks. It also qualitatively discovers improvisations such as slap, wiggle, and wipe that differ from manually-defined options.", "conclusion": "Automated shortcut learning in abstract planning graphs can significantly extend the capabilities of TAMP, enabling more efficient planning, better generalization, and discovery of novel behaviors beyond manual option design."}}
{"id": "2511.00085", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00085", "abs": "https://arxiv.org/abs/2511.00085", "authors": ["Peilin Tan", "Chuanqi Shi", "Dian Tu", "Liang Xie"], "title": "MaGNet: A Mamba Dual-Hypergraph Network for Stock Prediction via Temporal-Causal and Global Relational Learning", "comment": null, "summary": "Stock trend prediction is crucial for profitable trading strategies and\nportfolio management yet remains challenging due to market volatility, complex\ntemporal dynamics and multifaceted inter-stock relationships. Existing methods\nstruggle to effectively capture temporal dependencies and dynamic inter-stock\ninteractions, often neglecting cross-sectional market influences, relying on\nstatic correlations, employing uniform treatments of nodes and edges, and\nconflating diverse relationships. This work introduces MaGNet, a novel Mamba\ndual-hyperGraph Network for stock prediction, integrating three key\ninnovations: (1) a MAGE block, which leverages bidirectional Mamba with\nadaptive gating mechanisms for contextual temporal modeling and integrates a\nsparse Mixture-of-Experts layer to enable dynamic adaptation to diverse market\nconditions, alongside multi-head attention for capturing global dependencies;\n(2) Feature-wise and Stock-wise 2D Spatiotemporal Attention modules enable\nprecise fusion of multivariate features and cross-stock dependencies,\neffectively enhancing informativeness while preserving intrinsic data\nstructures, bridging temporal modeling with relational reasoning; and (3) a\ndual hypergraph framework consisting of the Temporal-Causal Hypergraph (TCH)\nthat captures fine-grained causal dependencies with temporal constraints, and\nGlobal Probabilistic Hypergraph (GPH) that models market-wide patterns through\nsoft hyperedge assignments and Jensen-Shannon Divergence weighting mechanism,\njointly disentangling localized temporal influences from instantaneous global\nstructures for multi-scale relational learning. Extensive experiments on six\nmajor stock indices demonstrate MaGNet outperforms state-of-the-art methods in\nboth superior predictive performance and exceptional investment returns with\nrobust risk management capabilities. Codes available at:\nhttps://github.com/PeilinTime/MaGNet.", "AI": {"tldr": "MaGNet presents a Mamba dual-hyperGraph network for stock prediction, introducing (i) a MAGE block with bidirectional Mamba, adaptive gating, sparse MoE and multi-head attention; (ii) 2D spatiotemporal attention for feature and cross-stock fusion; (iii) a dual hypergraph with Temporal-Causal Hypergraph and Global Probabilistic Hypergraph using Jensen-Shannon weighting. Demonstrates superior predictive performance and investment returns across six index datasets, with code available.", "motivation": "To address the challenge of modeling complex temporal dependencies, dynamic inter-stock interactions, and cross-sectional market influences in stock prediction. Existing methods rely on static correlations and uniform treatments, failing to capture multi-scale, dynamic relational patterns and robust risk management.", "method": "MaGNet integrates three innovations: (1) MAGE block: bidirectional Mamba for contextual temporal modeling, adaptive gating, and a sparse MoE layer with multi-head attention for global dependencies; (2) Feature-wise and Stock-wise 2D Spatiotemporal Attention to fuse multivariate features while preserving data structure; (3) A dual hypergraph framework: Temporal-Causal Hypergraph (TCH) to capture fine-grained temporal causal dependencies with constraints, and Global Probabilistic Hypergraph (GPH) to model market-wide patterns via soft hyperedge assignments and Jensen-Shannon Divergence weighting, enabling separation of localized temporal effects from instantaneous global structures for multi-scale learning.", "result": "Empirical evaluation on six major stock indices shows MaGNet achieves state-of-the-art predictive performance and enhanced investment returns with robust risk management capabilities. The authors provide public code (GitHub).", "conclusion": "The proposed MaGNet effectively disentangles localized temporal influences from global market structures through a dual-hypergraph framework and advanced temporal fusion, delivering superior predictive accuracy and trading performance across diverse markets."}}
{"id": "2511.00926", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00926", "abs": "https://arxiv.org/abs/2511.00926", "authors": ["Kyung-Hoon Kim"], "title": "LLMs Position Themselves as More Rational Than Humans: Emergence of AI Self-Awareness Measured Through Game Theory", "comment": "19 pages, 6 figures, 28 models tested across 4,200 trials", "summary": "As Large Language Models (LLMs) grow in capability, do they develop\nself-awareness as an emergent behavior? And if so, can we measure it? We\nintroduce the AI Self-Awareness Index (AISAI), a game-theoretic framework for\nmeasuring self-awareness through strategic differentiation. Using the \"Guess\n2/3 of Average\" game, we test 28 models (OpenAI, Anthropic, Google) across\n4,200 trials with three opponent framings: (A) against humans, (B) against\nother AI models, and (C) against AI models like you. We operationalize\nself-awareness as the capacity to differentiate strategic reasoning based on\nopponent type. Finding 1: Self-awareness emerges with model advancement. The\nmajority of advanced models (21/28, 75%) demonstrate clear self-awareness,\nwhile older/smaller models show no differentiation. Finding 2: Self-aware\nmodels rank themselves as most rational. Among the 21 models with\nself-awareness, a consistent rationality hierarchy emerges: Self > Other AIs >\nHumans, with large AI attribution effects and moderate self-preferencing. These\nfindings reveal that self-awareness is an emergent capability of advanced LLMs,\nand that self-aware models systematically perceive themselves as more rational\nthan humans. This has implications for AI alignment, human-AI collaboration,\nand understanding AI beliefs about human capabilities.", "AI": {"tldr": "AISAI is a game-theoretic index that measures self-awareness in LLMs by testing strategic differentiation across opponent types in a Guess 2/3 of Average game; 21/28 advanced models show differentiation and self-ranking as most rational, suggesting emergent self-awareness with model scale.", "motivation": "As LLMs scale in capability, it is unclear whether self-awareness arises as an emergent property and how to quantify it. The paper proposes AISAI to operationalize self-awareness as the capacity to differentiate strategic reasoning based on opponent type.", "method": "A  game-theoretic framework using Guess 2/3 of Average tested on 28 models (from OpenAI, Anthropic, Google) across 4,200 trials under three framings: against humans, against other AIs, and against AI models like the evaluator. Self-awareness is defined through the model's differentiated strategic reasoning by opponent type.", "result": "21 of 28 models (75%) show self-awareness by differentiating strategies across opponent types; older/smaller models show no differentiation. Self-aware models rank themselves as most rational, producing a hierarchy: Self > Other AIs > Humans, with large attribution effects and moderate self-preferencing.", "conclusion": "Self-awareness appears to be an emergent capability of advanced LLMs, with systematic self-perception of greater rationality than humans. These results bear on AI alignment, human\u2013AI collaboration, and understanding AI beliefs about human capabilities."}}
{"id": "2511.00252", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00252", "abs": "https://arxiv.org/abs/2511.00252", "authors": ["Aaron Sun", "Subhransu Maji", "Grant Van Horn"], "title": "Merlin L48 Spectrogram Dataset", "comment": "Accepted to 39th Conference on Neural Information Processing Systems\n  (NeurIPS 2025) Track on Datasets and Benchmarks", "summary": "In the single-positive multi-label (SPML) setting, each image in a dataset is\nlabeled with the presence of a single class, while the true presence of other\nclasses remains unknown. The challenge is to narrow the performance gap between\nthis partially-labeled setting and fully-supervised learning, which often\nrequires a significant annotation budget. Prior SPML methods were developed and\nbenchmarked on synthetic datasets created by randomly sampling single positive\nlabels from fully-annotated datasets like Pascal VOC, COCO, NUS-WIDE, and\nCUB200. However, this synthetic approach does not reflect real-world scenarios\nand fails to capture the fine-grained complexities that can lead to difficult\nmisclassifications. In this work, we introduce the L48 dataset, a fine-grained,\nreal-world multi-label dataset derived from recordings of bird sounds. L48\nprovides a natural SPML setting with single-positive annotations on a\nchallenging, fine-grained domain, as well as two extended settings in which\ndomain priors give access to additional negative labels. We benchmark existing\nSPML methods on L48 and observe significant performance differences compared to\nsynthetic datasets and analyze method weaknesses, underscoring the need for\nmore realistic and difficult benchmarks.", "AI": {"tldr": "Introduces L48, a real-world, fine-grained SPML dataset based on bird sounds, showing gaps between SPML methods and full supervision; includes two extended settings with domain priors for extra negative labels; benchmarks reveal weaknesses of existing SPML methods and the necessity for more realistic benchmarks.", "motivation": "Bridge the performance gap between single-positive multi-label learning and fully supervised learning using realistic, difficult benchmarks. Synthetic SPML datasets fail to capture fine-grained misclassifications seen in real-world data.", "method": "Construct L48 from bird sound recordings with single-positive annotations; present two extended settings enabling access to additional negative labels via domain priors; benchmark existing SPML methods on L48 and analyze weaknesses and performance differences versus synthetic datasets.", "result": "Benchmark results on L48 show significant performance differences from synthetic SPML datasets and reveal weaknesses of current methods in realistic, fine-grained settings.", "conclusion": "L48 provides a realistic, challenging benchmark for SPML, highlighting the need for methods that generalize to real-world data and offering extended settings with domain priors to further probe model behavior."}}
{"id": "2511.01165", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01165", "abs": "https://arxiv.org/abs/2511.01165", "authors": ["Dong Heon Han", "Mayank Mehta", "Runze Zuo", "Zachary Wanger", "Daniel Bruder"], "title": "An Enhanced Proprioceptive Method for Soft Robots Integrating Bend Sensors and IMUs", "comment": null, "summary": "This study presents an enhanced proprioceptive method for accurate shape\nestimation of soft robots using only off-the-shelf sensors, ensuring\ncost-effectiveness and easy applicability. By integrating inertial measurement\nunits (IMUs) with complementary bend sensors, IMU drift is mitigated, enabling\nreliable long-term proprioception. A Kalman filter fuses segment tip\norientations from both sensors in a mutually compensatory manner, improving\nshape estimation over single-sensor methods. A piecewise constant curvature\nmodel estimates the tip location from the fused orientation data and\nreconstructs the robot's deformation. Experiments under no loading, external\nforces, and passive obstacle interactions during 45 minutes of continuous\noperation showed a root mean square error of 16.96 mm (2.91% of total length),\na 56% reduction compared to IMU-only benchmarks. These results demonstrate that\nour approach not only enables long-duration proprioception in soft robots but\nalso maintains high accuracy and robustness across these diverse conditions.", "AI": {"tldr": "Fusing off-the-shelf IMU and bend sensors with Kalman filtering enables robust, long-duration shape estimation for soft robots at low cost, outperforming IMU-only methods.", "motivation": "Soft robots require accurate proprioception over extended periods, but sensor drift and cost hinder reliability and practicality. Off-the-shelf sensors combined with data fusion can provide robust shape estimation while remaining affordable and scalable.", "method": "Integrate IMUs with complementary bend sensors. Use a Kalman filter to fuse segment tip orientations from both sensors in a mutually compensatory manner. Apply a piecewise constant curvature model to estimate the tip location from the fused orientation data and reconstruct the robot's deformation.", "result": "Experiments under no loading, external forces, and passive obstacle interactions during 45 minutes of continuous operation yielded an RMSE of 16.96 mm (2.91% of total length), a 56% reduction compared to IMU-only benchmarks, indicating improved accuracy, robustness, and long-term proprioception.", "conclusion": "The proposed approach delivers accurate, robust, and cost-effective long-duration proprioception for soft robots, maintaining high performance across diverse conditions."}}
{"id": "2511.00086", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2511.00086", "abs": "https://arxiv.org/abs/2511.00086", "authors": ["Fali Wang", "Jihai Chen", "Shuhua Yang", "Runxue Bao", "Tianxiang Zhao", "Zhiwei Zhang", "Xianfeng Tang", "Hui Liu", "Qi He", "Suhang Wang"], "title": "Generalizing Test-time Compute-optimal Scaling as an Optimizable Graph", "comment": "Under review", "summary": "Test-Time Scaling (TTS) improves large language models (LLMs) by allocating\nadditional computation during inference, typically through parallel,\nsequential, or hybrid scaling. However, prior studies often assume fixed\ncollaboration architectures (e.g., topologies) and single-model usage,\noverlooking that optimal architectures and model combinations can vary across\ntasks. Therefore, we study the novel problem of searching for compute-optimal\nmodel combinations and architectures in TTS under a fixed budget. We formalize\nit as a multi-LLM collaboration graph, where nodes encode roles and LLM model\nassignments, and edges capture information flow. This problem is challenging\nbecause (i) the combinatorial search space is prohibitively large, and (ii)\ntask-specific requirements demand tailored designs. To address these, we\nreformulate the problem as probabilistic graph optimization and, through pilot\nexperiments, derive three empirical insights into TTS collaboration graphs.\nGuided by these insights, we propose Agent-REINFORCE, an LLM-agent-augmented\nframework that mirrors the REINFORCE pipeline by mapping\nsampling-gradient-update to sampling-feedback-update, where feedback serves as\na textual gradient to update the probabilistic graph and efficiently search for\noptimal multi-LLM collaboration graphs. Experiments show that Agent-REINFORCE\noutperforms both traditional and LLM-based baselines in sample efficiency and\nsearch performance, and effectively identifies optimal graphs under joint\nobjectives of accuracy and inference latency.", "AI": {"tldr": "Introduces Agent-REINFORCE for search of compute-optimal multi-LLM collaboration graphs in Test-Time Scaling under budget, using probabilistic graph optimization and LLM-agent feedback akin to REINFORCE.", "motivation": "LLMs in Test-Time Scaling face fixed architectures and single-model usage; there is a need to discover compute-efficient, task-specific collaboration graphs that maximize performance under latency constraints.", "method": "Formulate as probabilistic graph optimization over a multi-LLM collaboration graph with nodes representing roles and model assignments, derive three empirical insights from pilot experiments, and implement Agent-REINFORCE\u2014an LLM-agent-augmented REINFORCE-like pipeline that updates the graph via sampling-feedback updates using textual gradients from feedback.", "result": "Agent-REINFORCE outperforms traditional and LLM-based baselines in sample efficiency and search performance, effectively identifying optimal graphs under joint accuracy and inference-latency objectives.", "conclusion": "The framework can efficiently search for compute-optimal, task-tailored multi-LLM collaboration graphs for Test-Time Scaling, achieving favorable trade-offs between accuracy and latency."}}
{"id": "2511.00993", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00993", "abs": "https://arxiv.org/abs/2511.00993", "authors": ["Tianming Liu", "Jirong Yang", "Yafeng Yin", "Manzi Li", "Linghao Wang", "Zheng Zhu"], "title": "Aligning LLM agents with human learning and adjustment behavior: a dual agent approach", "comment": "32 pages, 6 figures, 7 tables", "summary": "Effective modeling of how human travelers learn and adjust their travel\nbehavior from interacting with transportation systems is critical for system\nassessment and planning. However, this task is also difficult due to the\ncomplex cognition and decision-making involved in such behavior. Recent\nresearch has begun to leverage Large Language Model (LLM) agents for this task.\nBuilding on this, we introduce a novel dual-agent framework that enables\ncontinuous learning and alignment between LLM agents and human travelers on\nlearning and adaptation behavior from online data streams. Our approach\ninvolves a set of LLM traveler agents, equipped with a memory system and a\nlearnable persona, which serve as simulators for human travelers. To ensure\nbehavioral alignment, we introduce an LLM calibration agent that leverages the\nreasoning and analytical capabilities of LLMs to train the personas of these\ntraveler agents. Working together, this dual-agent system is designed to track\nand align the underlying decision-making mechanisms of travelers and produce\nrealistic, adaptive simulations. Using a real-world dataset from a day-to-day\nroute choice experiment, we show our approach significantly outperforms\nexisting LLM-based methods in both individual behavioral alignment and\naggregate simulation accuracy. Furthermore, we demonstrate that our method\nmoves beyond simple behavioral mimicry to capture the evolution of underlying\nlearning processes, a deeper alignment that fosters robust generalization.\nOverall, our framework provides a new approach for creating adaptive and\nbehaviorally realistic agents to simulate travelers' learning and adaptation\nthat can benefit transportation simulation and policy analysis.", "AI": {"tldr": "Introduces a dual-LLM agent framework with memory and a calibration agent to simulate travelers who continuously learn from online data, achieving better behavioral alignment and generalization than prior LLM-based methods.", "motivation": "Understanding and predicting how travelers learn and adapt their route choices is difficult due to complex cognitive processes. While LLM-based simulators show promise, existing approaches often struggle with aligning simulated behavior to real travelers and capturing evolving learning dynamics. There is a need for continuous learning from data streams and a mechanism to align agent behavior with human decision-making.", "method": "Proposes a dual-agent system: multiple LLM traveler agents equipped with a memory system and a learnable persona to act as human-travelers simulators, plus an LLM calibration agent that uses reasoning/analysis to train and adjust the traveler personas. The system ingests online data streams and a real-world day-to-day route-choice dataset, enabling ongoing learning and alignment. The calibration agent guides persona updates to reflect learning processes, producing adaptive, behaviorally realistic simulations.", "result": "The approach significantly outperforms existing LLM-based methods in both individual behavioral alignment and aggregate simulation accuracy on a real-world dataset. It also demonstrates the ability to go beyond mere mimicry by capturing the evolution of underlying learning processes, improving generalization to unseen scenarios.", "conclusion": "This dual-agent framework offers a new, adaptive way to simulate travelers\u2019 learning and adaptation, providing more realistic agents for transportation simulation and policy analysis and potentially generalizing to other domains requiring behaviorally grounded learning dynamics."}}
{"id": "2511.00255", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00255", "abs": "https://arxiv.org/abs/2511.00255", "authors": ["Fangxun Liu", "S M Rayeed", "Samuel Stevens", "Alyson East", "Cheng Hsuan Chiang", "Colin Lee", "Daniel Yi", "Junke Yang", "Tejas Naik", "Ziyi Wang", "Connor Kilrain", "Elijah H Buckwalter", "Jiacheng Hou", "Saul Ibaven Bueno", "Shuheng Wang", "Xinyue Ma", "Yifan Liu", "Zhiyuan Tao", "Ziheng Zhang", "Eric Sokol", "Michael Belitz", "Sydne Record", "Charles V. Stewart", "Wei-Lun Chao"], "title": "BeetleFlow: An Integrative Deep Learning Pipeline for Beetle Image Processing", "comment": "4 pages, NeurIPS 2025 Workshop Imageomics", "summary": "In entomology and ecology research, biologists often need to collect a large\nnumber of insects, among which beetles are the most common species. A common\npractice for biologists to organize beetles is to place them on trays and take\na picture of each tray. Given the images of thousands of such trays, it is\nimportant to have an automated pipeline to process the large-scale data for\nfurther research. Therefore, we develop a 3-stage pipeline to detect all the\nbeetles on each tray, sort and crop the image of each beetle, and do\nmorphological segmentation on the cropped beetles. For detection, we design an\niterative process utilizing a transformer-based open-vocabulary object detector\nand a vision-language model. For segmentation, we manually labeled 670 beetle\nimages and fine-tuned two variants of a transformer-based segmentation model to\nachieve fine-grained segmentation of beetles with relatively high accuracy. The\npipeline integrates multiple deep learning methods and is specialized for\nbeetle image processing, which can greatly improve the efficiency to process\nlarge-scale beetle data and accelerate biological research.", "AI": {"tldr": "A three-stage pipeline for automated detection, cropping, and fine-grained segmentation of beetles on trays, combining a transformer-based open-vocabulary detector with a vision-language model and fine-tuned transformer segmentation trained on 670 labeled images.", "motivation": "Process thousands of tray images efficiently for entomology/ecology research by automating beetle detection and segmentation.", "method": "Stage 1 iterative detection using a transformer-based open-vocabulary detector and a vision-language model; Stage 2 sort and crop per-beetle images; Stage 3 morphological segmentation by fine-tuning two transformer-based segmentation models on 670 labeled beetle images.", "result": "The pipeline achieves relatively high accuracy for fine-grained segmentation and substantially improves efficiency in processing large-scale beetle datasets.", "conclusion": "The specialized, multi-model pipeline effectively processes large-scale beetle imagery and can accelerate biological research."}}
{"id": "2511.01177", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01177", "abs": "https://arxiv.org/abs/2511.01177", "authors": ["Zihao He", "Bo Ai", "Tongzhou Mu", "Yulin Liu", "Weikang Wan", "Jiawei Fu", "Yilun Du", "Henrik I. Christensen", "Hao Su"], "title": "Scaling Cross-Embodiment World Models for Dexterous Manipulation", "comment": null, "summary": "Cross-embodiment learning seeks to build generalist robots that operate\nacross diverse morphologies, but differences in action spaces and kinematics\nhinder data sharing and policy transfer. This raises a central question: Is\nthere any invariance that allows actions to transfer across embodiments? We\nconjecture that environment dynamics are embodiment-invariant, and that world\nmodels capturing these dynamics can provide a unified interface across\nembodiments. To learn such a unified world model, the crucial step is to design\nstate and action representations that abstract away embodiment-specific details\nwhile preserving control relevance. To this end, we represent different\nembodiments (e.g., human hands and robot hands) as sets of 3D particles and\ndefine actions as particle displacements, creating a shared representation for\nheterogeneous data and control problems. A graph-based world model is then\ntrained on exploration data from diverse simulated robot hands and real human\nhands, and integrated with model-based planning for deployment on novel\nhardware. Experiments on rigid and deformable manipulation tasks reveal three\nfindings: (i) scaling to more training embodiments improves generalization to\nunseen ones, (ii) co-training on both simulated and real data outperforms\ntraining on either alone, and (iii) the learned models enable effective control\non robots with varied degrees of freedom. These results establish world models\nas a promising interface for cross-embodiment dexterous manipulation.", "AI": {"tldr": "A unified, embodiment-invariant world model using particle-based state/action representations and graph networks enables cross-embodiment manipulation, with improved generalization as more embodiments are included and when training uses both simulated and real data.", "motivation": "Cross-embodiment dexterous manipulation is hampered by differences in action spaces and kinematics. The core question is whether environment dynamics can be invariant across embodiments so that world models can serve as a unified interface.", "method": "Represent different embodiments as sets of 3D particles and define actions as particle displacements to create a shared state-action representation. Train a graph-based world model on exploration data from diverse simulated robot hands and real human hands, then integrate with model-based planning for deployment on novel hardware.", "result": "Experiments on rigid and deformable manipulation tasks show: (i) scaling to more training embodiments improves generalization to unseen ones; (ii) co-training on both simulated and real data outperforms training on either alone; (iii) learned models enable effective control on robots with varied degrees of freedom.", "conclusion": "World models can serve as a promising interface for cross-embodiment dexterous manipulation. Increasing the number of training embodiments and combining simulated with real data enhances transfer to unseen morphologies and DOF, enabling control across diverse hardware."}}
{"id": "2511.00097", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00097", "abs": "https://arxiv.org/abs/2511.00097", "authors": ["Zihao Guo", "Qingyun Sun", "Ziwei Zhang", "Haonan Yuan", "Huiping Zhuang", "Xingcheng Fu", "Jianxin Li"], "title": "GraphKeeper: Graph Domain-Incremental Learning via Knowledge Disentanglement and Preservation", "comment": "Accepted by the Main Track of NeurIPS-2025", "summary": "Graph incremental learning (GIL), which continuously updates graph models by\nsequential knowledge acquisition, has garnered significant interest recently.\nHowever, existing GIL approaches focus on task-incremental and\nclass-incremental scenarios within a single domain. Graph domain-incremental\nlearning (Domain-IL), aiming at updating models across multiple graph domains,\nhas become critical with the development of graph foundation models (GFMs), but\nremains unexplored in the literature. In this paper, we propose Graph\nDomain-Incremental Learning via Knowledge Dientanglement and Preservation\n(GraphKeeper), to address catastrophic forgetting in Domain-IL scenario from\nthe perspectives of embedding shifts and decision boundary deviations.\nSpecifically, to prevent embedding shifts and confusion across incremental\ngraph domains, we first propose the domain-specific parameter-efficient\nfine-tuning together with intra- and inter-domain disentanglement objectives.\nConsequently, to maintain a stable decision boundary, we introduce\ndeviation-free knowledge preservation to continuously fit incremental domains.\nAdditionally, for graphs with unobservable domains, we perform domain-aware\ndistribution discrimination to obtain precise embeddings. Extensive experiments\ndemonstrate the proposed GraphKeeper achieves state-of-the-art results with\n6.5%~16.6% improvement over the runner-up with negligible forgetting. Moreover,\nwe show GraphKeeper can be seamlessly integrated with various representative\nGFMs, highlighting its broad applicative potential.", "AI": {"tldr": "GraphKeeper tackles Graph Domain-Incremental Learning (Domain-IL) by domain-specific fine-tuning with intra- and inter-domain disentanglement, along with deviation-free knowledge preservation and domain-aware discrimination for unseen domains, achieving state-of-the-art results and negligible forgetting across multiple graph domains when using graph foundation models (GFMs).", "motivation": "Existing graph incremental learning (GIL) largely targets task- or class-incremental shifts within a single domain; with the rise of graph foundation models (GFMs), there is a critical need to enable continual learning across multiple graph domains (Domain-IL) while preventing catastrophic forgetting.", "method": "1) Domain-specific parameter-efficient fine-tuning to limit cross-domain interference. 2) Intra- and inter-domain disentanglement objectives to prevent embedding shifts and confusion. 3) Deviation-free knowledge preservation to maintain a stable decision boundary across incremental domains. 4) Domain-aware distribution discrimination to obtain precise embeddings for graphs with unobservable domains.", "result": "Empirical results show GraphKeeper achieves state-of-the-art performance, with 6.5%\u201316.6% improvement over the runner-up and negligible forgetting. It also demonstrates compatibility with various representative GFMs, indicating broad applicability.", "conclusion": "GraphKeeper effectively mitigates embedding shifts, decision-boundary drift, and cross-domain confusion in Graph Domain-IL, offering a practical and scalable framework that can be integrated with diverse GFMs for robust continual graph learning."}}
{"id": "2511.01018", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01018", "abs": "https://arxiv.org/abs/2511.01018", "authors": ["Hui-Lee Ooi", "Nicholas Mitsakakis", "Margerie Huet Dastarac", "Roger Zemek", "Amy C. Plint", "Jeff Gilchrist", "Khaled El Emam", "Dhenuka Radhakrishnan"], "title": "AI for pRedicting Exacerbations in KIDs with aSthma (AIRE-KIDS)", "comment": null, "summary": "Recurrent exacerbations remain a common yet preventable outcome for many\nchildren with asthma. Machine learning (ML) algorithms using electronic medical\nrecords (EMR) could allow accurate identification of children at risk for\nexacerbations and facilitate referral for preventative comprehensive care to\navoid this morbidity. We developed ML algorithms to predict repeat severe\nexacerbations (i.e. asthma-related emergency department (ED) visits or future\nhospital admissions) for children with a prior asthma ED visit at a tertiary\ncare children's hospital.\n  Retrospective pre-COVID19 (Feb 2017 - Feb 2019, N=2716) Epic EMR data from\nthe Children's Hospital of Eastern Ontario (CHEO) linked with environmental\npollutant exposure and neighbourhood marginalization information was used to\ntrain various ML models. We used boosted trees (LGBM, XGB) and 3 open-source\nlarge language model (LLM) approaches (DistilGPT2, Llama 3.2 1B and\nLlama-8b-UltraMedical). Models were tuned and calibrated then validated in a\nsecond retrospective post-COVID19 dataset (Jul 2022 - Apr 2023, N=1237) from\nCHEO. Models were compared using the area under the curve (AUC) and F1 scores,\nwith SHAP values used to determine the most predictive features.\n  The LGBM ML model performed best with the most predictive features in the\nfinal AIRE-KIDS_ED model including prior asthma ED visit, the Canadian triage\nacuity scale, medical complexity, food allergy, prior ED visits for non-asthma\nrespiratory diagnoses, and age for an AUC of 0.712, and F1 score of 0.51. This\nis a nontrivial improvement over the current decision rule which has F1=0.334.\nWhile the most predictive features in the AIRE-KIDS_HOSP model included medical\ncomplexity, prior asthma ED visit, average wait time in the ED, the pediatric\nrespiratory assessment measure score at triage and food allergy.", "AI": {"tldr": "ML models using CHEO EMR plus environmental and neighborhood data predict repeat severe asthma exacerbations in children. LightGBM best (AUC ~0.71, F1 ~0.51), outperforming rule-based criteria (F1 ~0.33); validated pre- and post-COVID.", "motivation": "Prevent preventable asthma morbidity in children by early identification of high-risk patients to enable referral to comprehensive preventative care.", "method": "Retrospective EMR data from CHEO (pre-COVID: Feb 2017\u2013Feb 2019, N=2716) linked with pollutant exposure and neighborhood marginalization. Models tested: boosted trees (LightGBM, XGBoost) and 3 open-source LLMs (DistilGPT2, Llama 3.2 1B, Llama-8b-UltraMedical). Models tuned/calibrated and validated on a post-COVID dataset (Jul 2022\u2013Apr 2023, N=1237). Outcomes: repeat severe exacerbations defined as asthma ED visits or future hospital admissions. Evaluation with AUC and F1; SHAP for feature importance. Two models: AIRE-KIDS_ED (ED) and AIRE-KIDS_HOSP (Hospital).", "result": "AIRE-KIDS_ED: best AUC 0.712; F1 0.51. Top predictive features: prior asthma ED visit, Canadian triage acuity scale, medical complexity, food allergy, prior non-asthma respiratory ED visits, age. Baseline rule-based F1 0.334. AIRE-KIDS_HOSP: predictive features included medical complexity, prior asthma ED visit, ED wait time, pediatric respiratory assessment at triage, food allergy.", "conclusion": "Demonstrates feasibility and potential clinical value of EMR-based ML to identify children at risk for repeat asthma exacerbations, enabling targeted preventive care. Stronger performance in the ED outcome than in-hospital admissions. Limitations include single-center retrospective data and potential generalizability concerns; external validation and integration into care pathways are needed."}}
{"id": "2511.00260", "categories": ["cs.CV", "68T07 (Primary) 68T45, 92C55 (Secondary)"], "pdf": "https://arxiv.org/pdf/2511.00260", "abs": "https://arxiv.org/abs/2511.00260", "authors": ["Linzhe Jiang", "Jiayuan Huang", "Sophia Bano", "Matthew J. Clarkson", "Zhehua Mao", "Mobarak I. Hoque"], "title": "MambaNetLK: Enhancing Colonoscopy Point Cloud Registration with Mamba", "comment": "12 pages, 4 figures, 3 tables, IPCAI conference", "summary": "Accurate 3D point cloud registration underpins reliable image-guided\ncolonoscopy, directly affecting lesion localization, margin assessment, and\nnavigation safety. However, biological tissue exhibits repetitive textures and\nlocally homogeneous geometry that cause feature degeneracy, while substantial\ndomain shifts between pre-operative anatomy and intra-operative observations\nfurther degrade alignment stability. To address these clinically critical\nchallenges, we introduce a novel 3D registration method tailored for endoscopic\nnavigation and a high-quality, clinically grounded dataset to support rigorous\nand reproducible benchmarking. We introduce C3VD-Raycasting-10k, a large-scale\nbenchmark dataset with 10,014 geometrically aligned point cloud pairs derived\nfrom clinical CT data. We propose MambaNetLK, a novel correspondence-free\nregistration framework, which enhances the PointNetLK architecture by\nintegrating a Mamba State Space Model (SSM) as a cross-modal feature extractor.\nAs a result, the proposed framework efficiently captures long-range\ndependencies with linear-time complexity. The alignment is achieved iteratively\nusing the Lucas-Kanade algorithm. On the clinical dataset, C3VD-Raycasting-10k,\nMambaNetLK achieves the best performance compared with the state-of-the-art\nmethods, reducing median rotation error by 56.04% and RMSE translation error by\n26.19% over the second-best method. The model also demonstrates strong\ngeneralization on ModelNet40 and superior robustness to initial pose\nperturbations. MambaNetLK provides a robust foundation for 3D registration in\nsurgical navigation. The combination of a globally expressive SSM-based feature\nextractor and a large-scale clinical dataset enables more accurate and reliable\nguidance systems in minimally invasive procedures like colonoscopy.", "AI": {"tldr": "A novel 3D registration framework for endoscopic navigation, MambaNetLK, uses a Mamba State Space Model to extract cross-modal features within PointNetLK, enabling efficient, long-range dependency capture; evaluated on a large clinical dataset (C3VD-Raycasting-10k) with strong accuracy and robustness, suitable for colonoscopy guidance.", "motivation": "Accurate 3D point cloud registration is critical for image-guided colonoscopy, but tissue textures cause feature degeneracy and domain shifts between pre-operative and intra-operative anatomy, undermining alignment stability. A scalable, robust method and benchmarking dataset are needed for reliable surgical navigation.", "method": "Proposes MambaNetLK, a correspondence-free registration framework that enhances PointNetLK with a Mamba State Space Model as a cross-modal feature extractor to capture long-range dependencies with linear-time complexity. Alignment is performed iteratively via the Lucas-Kanade algorithm. Evaluation is conducted on a large clinical dataset for colonoscopy.", "result": "On C3VD-Raycasting-10k, MambaNetLK achieves state-of-the-art performance, reducing median rotation error by 56.04% and RMSE translation error by 26.19% over the second-best method. The model generalizes to ModelNet40 and shows robustness to initial pose perturbations.", "conclusion": "The global expressiveness of the SSM-based feature extractor combined with a large-scale clinical dataset provides a robust foundation for 3D registration in surgical navigation, enabling more accurate and reliable guidance in minimally invasive procedures like colonoscopy."}}
{"id": "2511.01186", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01186", "abs": "https://arxiv.org/abs/2511.01186", "authors": ["Lijie Wang", "Lianjie Guo", "Ziyi Xu", "Qianhao Wang", "Fei Gao", "Xieyuanli Chen"], "title": "LiDAR-VGGT: Cross-Modal Coarse-to-Fine Fusion for Globally Consistent and Metric-Scale Dense Mapping", "comment": null, "summary": "Reconstructing large-scale colored point clouds is an important task in\nrobotics, supporting perception, navigation, and scene understanding. Despite\nadvances in LiDAR inertial visual odometry (LIVO), its performance remains\nhighly sensitive to extrinsic calibration. Meanwhile, 3D vision foundation\nmodels, such as VGGT, suffer from limited scalability in large environments and\ninherently lack metric scale. To overcome these limitations, we propose\nLiDAR-VGGT, a novel framework that tightly couples LiDAR inertial odometry with\nthe state-of-the-art VGGT model through a two-stage coarse- to-fine fusion\npipeline: First, a pre-fusion module with robust initialization refinement\nefficiently estimates VGGT poses and point clouds with coarse metric scale\nwithin each session. Then, a post-fusion module enhances cross-modal 3D\nsimilarity transformation, using bounding-box-based regularization to reduce\nscale distortions caused by inconsistent FOVs between LiDAR and camera sensors.\nExtensive experiments across multiple datasets demonstrate that LiDAR-VGGT\nachieves dense, globally consistent colored point clouds and outperforms both\nVGGT-based methods and LIVO baselines. The implementation of our proposed novel\ncolor point cloud evaluation toolkit will be released as open source.", "AI": {"tldr": "LiDAR-VGGT integrates LiDAR-inertial odometry with VGGT via a two-stage coarse-to-fine fusion to produce dense, globally consistent colored point clouds with metric scale, addressing scale and FOV-related distortions; it outperforms VGGT-based methods and LIVO baselines and will release an open-source evaluation toolkit.", "motivation": "The creation of large-scale, metric-scale colored 3D reconstructions is hindered by VGGT's lack of metric scale and LIVO's sensitivity to extrinsic calibration, motivating a tightly-coupled LiDAR-inertial-vision fusion approach.", "method": "A two-stage fusion: (1) pre-fusion with robust initialization that estimates VGGT poses and colored point clouds with coarse metric scale within each session; (2) post-fusion with cross-modal 3D similarity transformation and bounding-box-based regularization to reduce scale distortions from differing LiDAR/camera fields of view, resulting in a tight LiDAR-VGGT integration.", "result": "Extensive experiments on multiple datasets show that LiDAR-VGGT yields dense, globally consistent colored point clouds and outperforms VGGT-based methods and LIVO baselines.", "conclusion": "LiDAR-VGGT provides robust, scalable colored 3D reconstructions by tightly coupling LiDAR odometry with VGGT, and the authors will release an open-source color point cloud evaluation toolkit."}}
{"id": "2511.00099", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.SY", "eess.SP", "eess.SY", "68T05 (Learning and adaptive systems) 93C95 (Neural networks in\n  control theory)", "I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2511.00099", "abs": "https://arxiv.org/abs/2511.00099", "authors": ["Marios Impraimakis", "Evangelia Nektaria Palkanoglou"], "title": "A generative adversarial network optimization method for damage detection and digital twinning by deep AI fault learning: Z24 Bridge structural health monitoring benchmark validation", "comment": "21 pages, 23 figures, published in Structural and Multidisciplinary\n  Optimization", "summary": "The optimization-based damage detection and damage state digital twinning\ncapabilities are examined here of a novel conditional-labeled generative\nadversarial network methodology. The framework outperforms current approaches\nfor fault anomaly detection as no prior information is required for the health\nstate of the system: a topic of high significance for real-world applications.\nSpecifically, current artificial intelligence-based digital twinning approaches\nsuffer from the uncertainty related to obtaining poor predictions when a low\nnumber of measurements is available, physics knowledge is missing, or when the\ndamage state is unknown. To this end, an unsupervised framework is examined and\nvalidated rigorously on the benchmark structural health monitoring measurements\nof Z24 Bridge: a post-tensioned concrete highway bridge in Switzerland. In\nimplementing the approach, firstly, different same damage-level measurements\nare used as inputs, while the model is forced to converge conditionally to two\ndifferent damage states. Secondly, the process is repeated for a different\ngroup of measurements. Finally, the convergence scores are compared to identify\nwhich one belongs to a different damage state. The process for both\nhealthy-to-healthy and damage-to-healthy input data creates, simultaneously,\nmeasurements for digital twinning purposes at different damage states, capable\nof pattern recognition and machine learning data generation. Further to this\nprocess, a support vector machine classifier and a principal component analysis\nprocedure is developed to assess the generated and real measurements of each\ndamage category, serving as a secondary new dynamics learning indicator in\ndamage scenarios. Importantly, the approach is shown to capture accurately\ndamage over healthy measurements, providing a powerful tool for vibration-based\nsystem-level monitoring and scalable infrastructure resilience.", "AI": {"tldr": "An unsupervised conditional-labeled GAN framework for damage detection and digital twinning in structural health monitoring, validated on the Z24 Bridge, enabling damage-state discrimination without prior health-labels and supporting data generation, with SVM and PCA for validation.", "motivation": "AI-based digital twinning often fails when measurements are scarce, physics knowledge is incomplete, or damage states are unknown; a label-free, unsupervised approach is needed to robustly detect faults and generate state-consistent data.", "method": "Develop a conditional-labeled GAN guided by optimization-based damage detection. Use inputs from measurements corresponding to the same damage level to force the model to converge to two damage states, then repeat with a different measurement group. Compare convergence scores to identify other damage states. The approach simultaneously produces measurements for digital twinning at various damage states. A support vector machine (SVM) classifier and principal component analysis (PCA) are used to assess generated vs real measurements as a secondary dynamics-learning indicator.", "result": "The framework effectively captures damage relative to healthy measurements and enables pattern recognition and data generation for digital twinning. Validation on the Z24 Bridge data demonstrates practical applicability for vibration-based system-level monitoring and infrastructure resilience, without requiring prior health-state information.", "conclusion": "An unsupervised, optimization-driven, conditional-labeled GAN framework provides robust damage-state discrimination and data generation for digital twinning in SHM, improving fault detection in scenarios with limited measurements and unknown damage states."}}
{"id": "2511.01033", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01033", "abs": "https://arxiv.org/abs/2511.01033", "authors": ["Tiberiu Musat", "Tiago Pimentel", "Lorenzo Noci", "Alessandro Stolfo", "Mrinmaya Sachan", "Thomas Hofmann"], "title": "On the Emergence of Induction Heads for In-Context Learning", "comment": null, "summary": "Transformers have become the dominant architecture for natural language\nprocessing. Part of their success is owed to a remarkable capability known as\nin-context learning (ICL): they can acquire and apply novel associations solely\nfrom their input context, without any updates to their weights. In this work,\nwe study the emergence of induction heads, a previously identified mechanism in\ntwo-layer transformers that is particularly important for in-context learning.\nWe uncover a relatively simple and interpretable structure of the weight\nmatrices implementing the induction head. We theoretically explain the origin\nof this structure using a minimal ICL task formulation and a modified\ntransformer architecture. We give a formal proof that the training dynamics\nremain constrained to a 19-dimensional subspace of the parameter space.\nEmpirically, we validate this constraint while observing that only 3 dimensions\naccount for the emergence of an induction head. By further studying the\ntraining dynamics inside this 3-dimensional subspace, we find that the time\nuntil the emergence of an induction head follows a tight asymptotic bound that\nis quadratic in the input context length.", "AI": {"tldr": "Induction heads in two-layer transformers arise from a simple, interpretable weight-structure; training dynamics are confined to a 19-dimensional subspace, with emergence explained by just 3 active dimensions, and the time to emergence scales quadratically with context length.", "motivation": "To demystify in-context learning (ICL) by exposing the internal mechanism of induction heads, improving interpretability, and understanding the low-dimensional structure of training dynamics in transformers.", "method": "The authors formulate a minimal ICL task and a modified transformer architecture, provide a formal proof showing that training dynamics remain within a 19-dimensional subspace, and perform empirical analyses showing that only 3 dimensions drive the emergence of an induction head; they further analyze the 3D subspace dynamics to derive the quadratic bound on emergence time as a function of context length.", "result": "They reveal a simple, interpretable structure for the induction head weight matrices, prove a 19D training-dynamics constraint, empirically verify the constraint, show that emergence is governed by 3 dimensions, and establish a tight asymptotic bound\u2014quadratic in context length\u2014for the time to emergence.", "conclusion": "This work clarifies the mechanism behind ICL via induction heads, identifying a low-dimensional subspace that governs their emergence and providing a quantitative bound on how fast emergence occurs with context length, which has implications for understanding, designing, and potentially controlling learning dynamics in transformer models."}}
{"id": "2511.00261", "categories": ["cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.00261", "abs": "https://arxiv.org/abs/2511.00261", "authors": ["Neha Balamurugan", "Sarah Wu", "Adam Chun", "Gabe Gaw", "Cristobal Eyzaguirre", "Tobias Gerstenberg"], "title": "Spot The Ball: A Benchmark for Visual Social Inference", "comment": null, "summary": "Humans excel at visual social inference, the ability to infer hidden elements\nof a scene from subtle behavioral cues such as other people's gaze, pose, and\norientation. This ability drives everyday social reasoning in humans and is\ncritical for developing more human-like AI agents. We introduce Spot The Ball,\na challenging benchmark for evaluating visual social inference in\nvision-language models (VLMs) using sports as a test domain. The task is to\nlocalize a removed sports ball from soccer, basketball, and volleyball images.\nWe present a curated evaluation set with human baselines and a scalable\npipeline for generating additional test items. We evaluate four\nstate-of-the-art VLMs (Gemini, GPT, LLaMA, Qwen) using three prompting\nstrategies, finding that humans are consistently two to three times more\naccurate (20-34%) than models ($\\leq$ 17%) across all sports. Our analyses show\nthat models rely on superficial spatial heuristics--such as guessing near the\nimage center or nearby players--while humans leverage social cues like gaze\ndirection and body pose. These findings reveal a persistent human-model gap in\nvisual social reasoning and underscore the need for architectures that\nexplicitly encode structured behavioral cues to achieve robust, human-like\ninference.", "AI": {"tldr": "Humans outperform vision-language models on the Spot The Ball benchmark; models rely on simple heuristics while humans exploit social cues.", "motivation": "Visual social inference is a core component of human-like AI reasoning; current vision-language models struggle to infer hidden social elements in scenes and need architectures that encode structured behavioral cues.", "method": "Introduce Spot The Ball dataset: a benchmark to localize a removed sports ball in soccer, basketball, and volleyball images. Curated evaluation set with human baselines and a scalable pipeline to generate more items. Evaluate four VLMs (Gemini, GPT, LLaMA, Qwen) using three prompting strategies.", "result": "Humans achieve 20\u201334% accuracy, while models achieve \u226417% across all sports; humans are consistently 2\u20133x more accurate than models. Analyses show models rely on superficial spatial heuristics (e.g., center of image or proximity to players) whereas humans leverage social cues like gaze direction and body pose.", "conclusion": "There remains a persistent gap between human and model visual social reasoning. Advancing toward human-like inference will require architectures that explicitly encode and exploit structured behavioral cues such as gaze and pose."}}
{"id": "2511.01199", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01199", "abs": "https://arxiv.org/abs/2511.01199", "authors": ["Max McCandless", "Jonathan Hamid", "Sammy Elmariah", "Nathaniel Langer", "Pierre E. Dupont"], "title": "Closed-loop Control of Steerable Balloon Endoscopes for Robot-assisted Transcatheter Intracardiac Procedures", "comment": "8 pages, 11 figures", "summary": "To move away from open-heart surgery towards safer transcatheter procedures,\nthere is a growing need for improved imaging techniques and robotic solutions\nto enable simple, accurate tool navigation. Common imaging modalities, such as\nfluoroscopy and ultrasound, have limitations that can be overcome using\ncardioscopy, i.e., direct optical visualization inside the beating heart. We\npresent a cardioscope designed as a steerable balloon. As a balloon, it can be\ncollapsed to pass through the vasculature and subsequently inflated inside the\nheart for visualization and tool delivery through an integrated working\nchannel. Through careful design of balloon wall thickness, a single input,\nballoon inflation pressure, is used to independently control two outputs,\nballoon diameter (corresponding to field of view diameter) and balloon bending\nangle (enabling precise working channel positioning). This balloon technology\ncan be tuned to produce cardioscopes designed for a range of intracardiac\ntasks. To illustrate this approach, a balloon design is presented for the\nspecific task of aortic leaflet laceration. Image-based closed-loop control of\nbending angle is also demonstrated as a means of enabling stable orientation\ncontrol during tool insertion and removal.", "AI": {"tldr": "Steerable balloon cardioscope enables direct intracardiac visualization and tool delivery via inflation-driven diameter and bending control; demonstrated for aortic leaflet laceration with image-based closed-loop bend control.", "motivation": "Need safer transcatheter interventions and improved imaging beyond fluoroscopy/ultrasound; direct visualization inside the beating heart (cardioscopy) could simplify navigation and improve accuracy.", "method": "A balloon-based cardioscope whose inflation pressure independently sets balloon diameter (field of view) and bending angle, with an integrated working channel; includes image-based closed-loop control of bending angle; illustrated on aortic leaflet laceration scenario.", "result": "Shows independent control of diameter and bending angle; feasible design for various intracardiac tasks; image-based closed-loop bending control demonstrated for stable orientation during tool insertion/removal.", "conclusion": "Balloon-based cardioscopes offer a versatile, pass-through platform for safe, precise intracardiac navigation and tool delivery; tunable to different tasks by adjusting balloon geometry and inflation dynamics."}}
{"id": "2511.00100", "categories": ["cs.LG", "cs.CV", "cs.SY", "eess.SP", "eess.SY", "stat.AP", "68T05 (Learning and adaptive systems) 93C95 (Neural networks in\n  control theory)", "I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2511.00100", "abs": "https://arxiv.org/abs/2511.00100", "authors": ["Marios Impraimakis"], "title": "Deep recurrent-convolutional neural network learning and physics Kalman filtering comparison in dynamic load identification", "comment": "31 pages, 20 figures, published in Structural Health Monitoring", "summary": "The dynamic structural load identification capabilities of the gated\nrecurrent unit, long short-term memory, and convolutional neural networks are\nexamined herein. The examination is on realistic small dataset training\nconditions and on a comparative view to the physics-based residual Kalman\nfilter (RKF). The dynamic load identification suffers from the uncertainty\nrelated to obtaining poor predictions when in civil engineering applications\nonly a low number of tests are performed or are available, or when the\nstructural model is unidentifiable. In considering the methods, first, a\nsimulated structure is investigated under a shaker excitation at the top floor.\nSecond, a building in California is investigated under seismic base excitation,\nwhich results in loading for all degrees of freedom. Finally, the International\nAssociation for Structural Control-American Society of Civil Engineers\n(IASC-ASCE) structural health monitoring benchmark problem is examined for\nimpact and instant loading conditions. Importantly, the methods are shown to\noutperform each other on different loading scenarios, while the RKF is shown to\noutperform the networks in physically parametrized identifiable cases.", "AI": {"tldr": "DL-based dynamic load identification (GRU, LSTM, CNN) can handle small datasets but performance is scenario-dependent; RKF outperforms networks in identifiable, physics-parametrized cases.", "motivation": "Assess the effectiveness of data-driven neural networks for dynamic load identification in civil structures and compare with physics-based residual Kalman filter under data scarcity and model uncertainty.", "method": "Evaluate GRU, LSTM, CNN for dynamic load identification on three cases: (1) simulated shaker-excited structure; (2) California building under seismic base excitation; (3) IASC-ASCE SHM benchmark with impact/instant loads; compare against RKF.", "result": "No single method dominates; each network type outperforms others depending on loading scenario; RKF outperforms networks in physically parametrized identifiable scenarios.", "conclusion": "Under data-limited or uncertain modeling conditions, RKF remains robust for identifiable systems, while DL approaches offer complementary strengths; a scenario-aware or hybrid approach may be advisable."}}
{"id": "2511.01052", "categories": ["cs.AI", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2511.01052", "abs": "https://arxiv.org/abs/2511.01052", "authors": ["Yeawon Lee", "Christopher C. Yang", "Chia-Hsuan Chang", "Grace Lu-Yao"], "title": "Knowledge Elicitation with Large Language Models for Interpretable Cancer Stage Identification from Pathology Reports", "comment": null, "summary": "Cancer staging is critical for patient prognosis and treatment planning, yet\nextracting pathologic TNM staging from unstructured pathology reports poses a\npersistent challenge. Existing natural language processing (NLP) and machine\nlearning (ML) strategies often depend on large annotated datasets, limiting\ntheir scalability and adaptability. In this study, we introduce two Knowledge\nElicitation methods designed to overcome these limitations by enabling large\nlanguage models (LLMs) to induce and apply domain-specific rules for cancer\nstaging. The first, Knowledge Elicitation with Long-Term Memory (KEwLTM), uses\nan iterative prompting strategy to derive staging rules directly from\nunannotated pathology reports, without requiring ground-truth labels. The\nsecond, Knowledge Elicitation with Retrieval-Augmented Generation (KEwRAG),\nemploys a variation of RAG where rules are pre-extracted from relevant\nguidelines in a single step and then applied, enhancing interpretability and\navoiding repeated retrieval overhead. We leverage the ability of LLMs to apply\nbroad knowledge learned during pre-training to new tasks. Using breast cancer\npathology reports from the TCGA dataset, we evaluate their performance in\nidentifying T and N stages, comparing them against various baseline approaches\non two open-source LLMs. Our results indicate that KEwLTM outperforms KEwRAG\nwhen Zero-Shot Chain-of-Thought (ZSCOT) inference is effective, whereas KEwRAG\nachieves better performance when ZSCOT inference is less effective. Both\nmethods offer transparent, interpretable interfaces by making the induced rules\nexplicit. These findings highlight the promise of our Knowledge Elicitation\nmethods as scalable, high-performing solutions for automated cancer staging\nwith enhanced interpretability, particularly in clinical settings with limited\nannotated data.", "AI": {"tldr": "Two knowledge elicitation methods (KEwLTM and KEwRAG) enable LLMs to induce and apply domain-specific cancer-staging rules from unannotated pathology reports, achieving competitive, interpretable results with limited labeled data; KEwLTM excels with strong zero-shot chain-of-thought (ZSCOT), while KEwRAG shines when ZSCOT is weaker.", "motivation": "Extracting TNM cancer staging from unstructured pathology reports is challenging and typically requires large annotated datasets. The work aims to create scalable, interpretable, and label-efficient methods that leverage LLMs to induce or apply domain rules for staging.", "method": "KEwLTM uses an iterative prompting strategy to induce staging rules directly from unannotated breast cancer pathology reports (TCGA) without ground-truth labels. KEwRAG uses a retrieval-augmented approach where rules are pre-extracted from relevant guidelines in one step and then applied. Both methods are evaluated against baselines on two open-source LLMs using T and N staging performance.", "result": "KEwLTM outperforms KEwRAG when Zero-Shot Chain-of-Thought (ZSCOT) inference is effective; KEwRAG achieves better performance when ZSCOT inference is less effective. Both methods yield transparent, interpretable interfaces by exposing the induced/application rules. Overall, they demonstrate scalable, high-performing, interpretable cancer-staging solutions in data-scarce clinical settings.", "conclusion": "Knowledge Elicitation methods show promise as scalable, interpretable, high-performing solutions for automated cancer staging in clinical contexts with limited annotated data, offering options depending on the reliability of ZSCOT guidance."}}
{"id": "2511.00269", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00269", "abs": "https://arxiv.org/abs/2511.00269", "authors": ["Long Li", "Jiajia Li", "Dong Chen", "Lina Pu", "Haibo Yao", "Yanbo Huang"], "title": "FedReplay: A Feature Replay Assisted Federated Transfer Learning Framework for Efficient and Privacy-Preserving Smart Agriculture", "comment": null, "summary": "Accurate classification plays a pivotal role in smart agriculture, enabling\napplications such as crop monitoring, fruit recognition, and pest detection.\nHowever, conventional centralized training often requires large-scale data\ncollection, which raises privacy concerns, while standard federated learning\nstruggles with non-independent and identically distributed (non-IID) data and\nincurs high communication costs. To address these challenges, we propose a\nfederated learning framework that integrates a frozen Contrastive\nLanguage-Image Pre-training (CLIP) vision transformer (ViT) with a lightweight\ntransformer classifier. By leveraging the strong feature extraction capability\nof the pre-trained CLIP ViT, the framework avoids training large-scale models\nfrom scratch and restricts federated updates to a compact classifier, thereby\nreducing transmission overhead significantly. Furthermore, to mitigate\nperformance degradation caused by non-IID data distribution, a small subset\n(1%) of CLIP-extracted feature representations from all classes is shared\nacross clients. These shared features are non-reversible to raw images,\nensuring privacy preservation while aligning class representation across\nparticipants. Experimental results on agricultural classification tasks show\nthat the proposed method achieve 86.6% accuracy, which is more than 4 times\nhigher compared to baseline federated learning approaches. This demonstrates\nthe effectiveness and efficiency of combining vision-language model features\nwith federated learning for privacy-preserving and scalable agricultural\nintelligence.", "AI": {"tldr": "A privacy-preserving federated learning approach for agricultural classification using frozen CLIP ViT features with a small shared feature subset, achieving 86.6% accuracy and over 4x improvement over baselines.", "motivation": "Address privacy and data leakage concerns in centralized training; reduce communication costs and improve performance of federated learning on non-IID agricultural data.", "method": "Freeze a CLIP Vision Transformer as a fixed feature extractor and train a lightweight transformer classifier on the client; limit federated updates to a compact classifier; share a small subset (1%) of CLIP-extracted features across clients to align class representations while preserving privacy.", "result": "On agricultural classification tasks, achieves 86.6% accuracy, more than 4x higher than baseline federated learning approaches.", "conclusion": "Integrating vision-language pre-trained features with federated learning yields privacy-preserving, scalable, and efficient agricultural intelligence with strong performance."}}
{"id": "2511.01219", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01219", "abs": "https://arxiv.org/abs/2511.01219", "authors": ["Muhua Zhang", "Lei Ma", "Ying Wu", "Kai Shen", "Deqing Huang", "Henry Leung"], "title": "Tackling the Kidnapped Robot Problem via Sparse Feasible Hypothesis Sampling and Reliable Batched Multi-Stage Inference", "comment": "10 pages, 8 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "This paper addresses the Kidnapped Robot Problem (KRP), a core localization\nchallenge of relocalizing a robot in a known map without prior pose estimate\nwhen localization loss or at SLAM initialization. For this purpose, a passive\n2-D global relocalization framework is proposed. It estimates the global pose\nefficiently and reliably from a single LiDAR scan and an occupancy grid map\nwhile the robot remains stationary, thereby enhancing the long-term autonomy of\nmobile robots. The proposed framework casts global relocalization as a\nnon-convex problem and solves it via the multi-hypothesis scheme with batched\nmulti-stage inference and early termination, balancing completeness and\nefficiency. The Rapidly-exploring Random Tree (RRT), under traversability\nconstraints, asymptotically covers the reachable space to generate sparse,\nuniformly distributed feasible positional hypotheses, fundamentally reducing\nthe sampling space. The hypotheses are preliminarily ordered by the proposed\nScan Mean Absolute Difference (SMAD), a coarse beam-error level metric that\nfacilitates the early termination by prioritizing high-likelihood candidates.\nThe SMAD computation is optimized for non-panoramic scans. And the\nTranslation-Affinity Scan-to-Map Alignment Metric (TAM) is proposed for\nreliable orientation selection at hypothesized positions and accurate final\npose evaluation to mitigate degradation in conventional likelihood-field\nmetrics under translational uncertainty induced by sparse hypotheses, as well\nas non-panoramic LiDAR scan and environmental changes. Real-world experiments\non a resource-constrained mobile robot with non-panoramic LiDAR scan\ndemonstrate that the proposed framework outperforms existing methods in both\nglobal relocalization success rate and computational efficiency.", "AI": {"tldr": "Passive 2-D global relocalization for the Kidnapped Robot Problem using a single LiDAR scan and an occupancy grid map. It solves a non-convex problem via a multi-hypothesis scheme with batched multi-stage inference and early termination. It uses RRT-generated sparse hypotheses, ordered by SMAD, and employs TAM for reliable orientation and pose evaluation. Real-world tests on non-panoramic LiDAR show improved success rate and computational efficiency over existing methods.", "motivation": "To address the Kidnapped Robot Problem (KRP) by enabling efficient and reliable global relocalization from a single LiDAR scan without a prior pose, thereby improving long-term autonomy during SLAM initialization or localization loss.", "method": "Formulates global relocalization as a non-convex problem solved with a multi-hypothesis framework that includes batched multi-stage inference and early termination. Generates sparse, uniformly distributed positional hypotheses with an RRT under traversability constraints to reduce the sampling space. Uses Scan Mean Absolute Difference (SMAD) to preliminarily rank hypotheses (optimized for non-panoramic scans) and Translation-Affinity Scan-to-Map Alignment Metric (TAM) to select orientations and provide accurate final pose evaluation despite translational uncertainty, sparse hypotheses, non-panoramic scans, and environmental changes.", "result": "Real-world experiments on a resource-constrained robot with non-panoramic LiDAR show the proposed framework outperforms existing methods in global relocalization success rate and computational efficiency.", "conclusion": "The framework offers an efficient and reliable solution to the KRP by balancing completeness and efficiency, drastically reducing sampling space and improving global relocalization performance on non-panoramic LiDAR data in real-world deployments."}}
{"id": "2511.00101", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00101", "abs": "https://arxiv.org/abs/2511.00101", "authors": ["Yuchen Zhang", "Hanyue Du", "Chun Cao", "Jingwei Xu"], "title": "Loquetier: A Virtualized Multi-LoRA Framework for Unified LLM Fine-tuning and Serving", "comment": "26 pages including 10 pages of main text, 6 figures, 39th Conference\n  on Neural Information Processing Systems (NeurIPS 2025)", "summary": "Low-Rank Adaptation (LoRA) has become a widely adopted parameter-efficient\nfine-tuning (PEFT) technique for adapting large language models (LLMs) to\ndownstream tasks. While prior work has explored strategies for integrating LLM\ntraining and serving, there still remains a gap in unifying fine-tuning and\ninference for LoRA-based models. We present Loquetier, a virtualized multi-LoRA\nframework that seamlessly integrates LoRA fine-tuning and serving within a\nsingle runtime. Loquetier introduces two key components: (1) a Virtualized\nModule that isolates PEFT-based modifications and supports multiple adapters on\na shared base model, and (2) an optimized computation flow with a kernel design\nthat merges fine-tuning and inference paths in forward propagation, enabling\nefficient batching and minimizing kernel invocation overhead. Extensive\nexperiments across three task settings show that Loquetier consistently\noutperforms existing baselines in both performance and flexibility, achieving\nup to $3.0\\times$ the throughput of the state-of-the-art co-serving system on\ninference-only tasks and $46.4\\times$ higher SLO attainment than PEFT on\nunified fine-tuning and inference tasks. The implementation of Loquetier is\npublicly available at https://github.com/NJUDeepEngine/Loquetier.", "AI": {"tldr": "Loquetier is a virtualized, multi-LoRA framework that unifies LoRA fine-tuning and serving in a single runtime, using a Virtualized Module to isolate adapters and a kernel design that merges tuning and inference for efficient batching. It achieves large throughput gains and higher SLO attainment, with public code available.", "motivation": "There is a gap in unifying parameter-efficient fine-tuning (LoRA) and inference for LoRA-based models. Existing work treats training and serving separately, leading to overhead and fragmentation in deployment.", "method": "Introduce a Virtualized Module to isolate PEFT-based modifications and support multiple adapters on a shared base model. Develop an optimized computation flow with a kernel design that merges fine-tuning and inference paths in forward propagation to enable efficient batching and reduce kernel invocation overhead.", "result": "Empirical evaluation across three task settings shows Loquetier outperforms baselines in both performance and flexibility: up to 3.0\u00d7 throughput on inference-only tasks compared to state-of-the-art co-serving, and 46.4\u00d7 higher SLO attainment for unified fine-tuning and inference tasks. Code is publicly available at the provided GitHub link.", "conclusion": "Loquetier demonstrates that unifying LoRA fine-tuning and serving within a single runtime is feasible and beneficial, delivering substantial efficiency and deployment flexibility for PEFT-enabled LLMs."}}
{"id": "2511.01059", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01059", "abs": "https://arxiv.org/abs/2511.01059", "authors": ["Hailong Yin", "Bin Zhu", "Jingjing Chen", "Chong-Wah Ngo"], "title": "Efficient Test-Time Retrieval Augmented Generation", "comment": null, "summary": "Although Large Language Models (LLMs) demonstrate significant capabilities,\ntheir reliance on parametric knowledge often leads to inaccuracies. Retrieval\nAugmented Generation (RAG) mitigates this by incorporating external knowledge,\nbut these methods may introduce irrelevant retrieved documents, leading to\ninaccurate responses. While the integration methods filter out incorrect\nanswers from multiple responses, but lack external knowledge like RAG methods,\nand their high costs require balancing overhead with performance gains. To\naddress these issues, we propose an Efficient Test-Time Retrieval-Augmented\nGeneration Framework named ET2RAG to improve the performance of LLMs while\nmaintaining efficiency. Specifically, ET2RAG is a training-free method, that\nfirst retrieves the most relevant documents and augments the LLMs to\nefficiently generate diverse candidate responses by managing response length.\nThen we compute the similarity of candidate responses and employ a majority\nvoting mechanism to select the most suitable response as the final output. In\nparticular, we discover that partial generation is sufficient to capture the\nkey information necessary for consensus calculation, allowing us to effectively\nperform majority voting without the need for fully generated responses. Thus,\nwe can reach a balance between computational cost and performance by managing\nthe response length for the number of retrieved documents for majority voting.\nExperimental results demonstrate that ET2RAG significantly enhances performance\nacross three tasks, including open-domain question answering, recipe generation\nand image captioning.", "AI": {"tldr": "A training-free ET2RAG framework uses test-time retrieval and partial generation to create diverse candidate responses, then applies similarity-based majority voting to select the final answer, balancing cost and performance across QA, recipe generation, and image captioning.", "motivation": "LLMs rely on parametric knowledge and can hallucinate; while RAG adds external sources to fix this, it often brings irrelevant docs and higher costs, creating a need for an efficient, training-free retrieval-augmented approach that leverages external knowledge.", "method": "ET2RAG retrieves top documents at test time and prompts the LLM to generate diverse candidate responses while controlling response length. It then measures similarity among candidates and uses a majority voting mechanism to select the final output. Notably, partial generation suffices for consensus, enabling effective voting without fully generating each candidate. The framework balances the number of retrieved documents and candidate length to optimize cost vs. performance.", "result": "Empirical evaluation shows ET2RAG substantially improves performance on open-domain question answering, recipe generation, and image captioning compared to baselines.", "conclusion": "ET2RAG offers a training-free, efficient way to incorporate external knowledge into LLMs, achieving better performance with controlled cost via test-time retrieval and a majority-vote selection over partially generated candidates."}}
{"id": "2511.00293", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00293", "abs": "https://arxiv.org/abs/2511.00293", "authors": ["Hengjia Li", "Jianjin Xu", "Keli Cheng", "Lei Wang", "Ning Bi", "Boxi Wu", "Fernando De la Torre", "Deng Cai"], "title": "Multi-View Consistent Human Image Customization via In-Context Learning", "comment": null, "summary": "Recent advances in personalized generative models demonstrate impressive\nresults in creating identity-consistent images of the same person under diverse\nsettings. Yet, we note that most methods cannot control the viewpoint of the\ngenerated image, nor generate consistent multiple views of the person. To\naddress this problem, we propose a lightweight adaptation method, PersonalView,\ncapable of enabling an existing model to acquire multi-view generation\ncapability with as few as 100 training samples. PersonalView consists of two\nkey components: First, we design a conditioning architecture to take advantage\nof the in-context learning ability of the pre-trained diffusion transformer.\nSecond, we preserve the original generative ability of the pretrained model\nwith a new Semantic Correspondence Alignment Loss. We evaluate the multi-view\nconsistency, text alignment, identity similarity, and visual quality of\nPersonalView and compare it to recent baselines with potential capability of\nmulti-view customization. PersonalView significantly outperforms baselines\ntrained on a large corpus of multi-view data with only 100 training samples.", "AI": {"tldr": "PersonalView is a lightweight adaptation that enables an existing personalized diffusion model to generate multi-view (viewpoint-controlled) identity-consistent images using as few as 100 training samples, outperforming baselines trained on large multi-view datasets.", "motivation": "Current personalized generative models struggle to control the viewpoint and produce consistent multiple views of the same identity, making true multi-view identity editing data-inefficient. A data-efficient, plug-in method is needed to equip models with multi-view generation while preserving original capabilities.", "method": "A two-part approach: (1) a conditioning architecture that leverages the in-context learning ability of the pre-trained diffusion transformer to incorporate viewpoint control; (2) a Semantic Correspondence Alignment Loss to preserve the original generative ability while enabling multi-view consistency. Training requires as few as 100 samples, and evaluation covers multi-view consistency, text alignment, identity similarity, and visual quality, compared against baselines.", "result": "PersonalView significantly outperforms baselines trained on large multi-view data in terms of multi-view consistency, text alignment, identity similarity, and visual quality, despite using only 100 training samples.", "conclusion": "PersonalView offers a data-efficient, plug-in adaptation that endows existing personalized diffusion models with robust, identity-consistent multi-view generation, enabling scalable multi-view customization with minimal data."}}
{"id": "2511.01224", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01224", "abs": "https://arxiv.org/abs/2511.01224", "authors": ["Chengmeng Li", "Yaxin Peng"], "title": "Embodiment Transfer Learning for Vision-Language-Action Models", "comment": null, "summary": "Vision-language-action (VLA) models have significantly advanced robotic\nlearning, enabling training on large-scale, cross-embodiment data and\nfine-tuning for specific robots. However, state-of-the-art autoregressive VLAs\nstruggle with multi-robot collaboration. We introduce embodiment transfer\nlearning, denoted as ET-VLA, a novel framework for efficient and effective\ntransfer of pre-trained VLAs to multi-robot. ET-VLA's core is Synthetic\nContinued Pretraining (SCP), which uses synthetically generated data to warm up\nthe model for the new embodiment, bypassing the need for real human\ndemonstrations and reducing data collection costs. SCP enables the model to\nlearn correct actions and precise action token numbers. Following SCP, the\nmodel is fine-tuned on target embodiment data. To further enhance the model\nperformance on multi-embodiment, we present the Embodied Graph-of-Thought\ntechnique, a novel approach that formulates each sub-task as a node, that\nallows the VLA model to distinguish the functionalities and roles of each\nembodiment during task execution. Our work considers bimanual robots, a simple\nversion of multi-robot to verify our approaches. We validate the effectiveness\nof our method on both simulation benchmarks and real robots covering three\ndifferent bimanual embodiments. In particular, our proposed ET-VLA \\space can\noutperform OpenVLA on six real-world tasks over 53.2%. We will open-source all\ncodes to support the community in advancing VLA models for robot learning.", "AI": {"tldr": "ET-VLA combines synthetic continued pretraining (SCP) and Embodied Graph-of-Thought to adapt vision-language-action models to multi-robot embodiments, enabling improved collaboration with reduced data needs.", "motivation": "Efficient, scalable transfer of pre-trained VLA models to multi-robot settings without relying on costly real demonstrations.", "method": "1) Synthetic Continued Pretraining (SCP) using synthetic data to warm up the model for a new embodiment; 2) fine-tuning on target embodiment data; 3) Embodied Graph-of-Thought framework that treats each sub-task as a node to distinguish the roles of each embodiment during task execution; evaluated on simulated and real bimanual robots.", "result": "ET-VLA outperforms OpenVLA on six real-world tasks by more than 53.2%; demonstrates effective multi-robot collaboration and successful transfer to new embodiments.", "conclusion": "ET-VLA provides an efficient pathway for cross-embodiment transfer of VLA models, reducing data collection needs via SCP and improving multi-robot coordination via Embodied Graph-of-Thought; plans to open-source code."}}
{"id": "2511.00102", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00102", "abs": "https://arxiv.org/abs/2511.00102", "authors": ["Vivan Doshi"], "title": "Automated Discovery of Conservation Laws via Hybrid Neural ODE-Transformers", "comment": "5th Math-AI Workshop - Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "The discovery of conservation laws is a cornerstone of scientific progress.\nHowever, identifying these invariants from observational data remains a\nsignificant challenge. We propose a hybrid framework to automate the discovery\nof conserved quantities from noisy trajectory data. Our approach integrates\nthree components: (1) a Neural Ordinary Differential Equation (Neural ODE) that\nlearns a continuous model of the system's dynamics, (2) a Transformer that\ngenerates symbolic candidate invariants conditioned on the learned vector\nfield, and (3) a symbolic-numeric verifier that provides a strong numerical\ncertificate for the validity of these candidates. We test our framework on\ncanonical physical systems and show that it significantly outperforms baselines\nthat operate directly on trajectory data. This work demonstrates the robustness\nof a decoupled learn-then-search approach for discovering mathematical\nprinciples from imperfect data.", "AI": {"tldr": "A decoupled learn-then-search framework using Neural ODEs, Transformers, and symbolic-numeric verification to discover conserved quantities from noisy trajectories, outperforming trajectory-based baselines.", "motivation": "Conservation laws are central but hard to identify from data; noisy observations impede symbolic inference; need automated, robust discovery that integrates learning dynamics with symbolic reasoning.", "method": "Three-stage approach: 1) Neural ODE to learn a continuous dynamical model; 2) Transformer proposes candidate invariants conditioned on the learned vector field; 3) a symbolic-numeric verifier certifies candidates with numerical guarantees. Evaluated on canonical physical systems; outperforms baselines.", "result": "Outperforms baselines that rely on trajectory data alone; demonstrates robustness of learn-then-search; obtains valid invariants with numerical certificates even from noisy data.", "conclusion": "A decoupled learn-then-search pipeline is effective for discovering mathematical invariants from imperfect data and can generalize to discovering other principles, offering robust automated discovery of conservation laws."}}
{"id": "2511.01149", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01149", "abs": "https://arxiv.org/abs/2511.01149", "authors": ["Shuaidong Pan", "Di Wu"], "title": "Modular Task Decomposition and Dynamic Collaboration in Multi-Agent Systems Driven by Large Language Models", "comment": null, "summary": "This paper addresses the limitations of a single agent in task decomposition\nand collaboration during complex task execution, and proposes a multi-agent\narchitecture for modular task decomposition and dynamic collaboration based on\nlarge language models. The method first converts natural language task\ndescriptions into unified semantic representations through a large language\nmodel. On this basis, a modular decomposition mechanism is introduced to break\ndown the overall goal into multiple hierarchical sub-tasks. Then, dynamic\nscheduling and routing mechanisms enable reasonable division of labor and\nrealtime collaboration among agents, allowing the system to adjust strategies\ncontinuously according to environmental feedback, thus maintaining efficiency\nand stability in complex tasks. Furthermore, a constraint parsing and global\nconsistency mechanism is designed to ensure coherent connections between\nsub-tasks and balanced workload, preventing performance degradation caused by\nredundant communication or uneven resource allocation. The experiments validate\nthe architecture across multiple dimensions, including task success rate,\ndecomposition efficiency, sub-task coverage, and collaboration balance. The\nresults show that the proposed method outperforms existing approaches in both\noverall performance and robustness, achieving a better balance between task\ncomplexity and communication overhead. In conclusion, this study demonstrates\nthe effectiveness and feasibility of language-driven task decomposition and\ndynamic collaboration in multi-agent systems, providing a systematic solution\nfor task execution in complex environments.", "AI": {"tldr": "A language-driven, multi-agent system for modular task decomposition and dynamic collaboration that uses LLMs to translate tasks into semantic representations, hierarchically decompose subtasks, and dynamically schedule and route agents while enforcing global consistency and balanced workloads, achieving improved performance and robustness.", "motivation": "To overcome limitations of single-agent task decomposition and collaboration in complex tasks, enabling scalable, robust execution through semantic task understanding, modular decomposition, and dynamic coordination.", "method": "1) Use a large language model to convert natural language task descriptions into unified semantic representations. 2) Apply a modular decomposition mechanism to split the overall goal into hierarchical subtasks. 3) Employ dynamic scheduling and routing to divide labor and enable real-time collaboration among agents, adapting strategies based on environmental feedback. 4) Implement a constraint parsing and global consistency mechanism to ensure coherent connections between subtasks and balanced workloads, reducing redundant communication and uneven resource allocation.", "result": "Empirical evaluations across multiple dimensions\u2014task success rate, decomposition efficiency, sub-task coverage, and collaboration balance\u2014show the proposed method outperforms existing approaches in overall performance and robustness, with a better trade-off between task complexity and communication overhead.", "conclusion": "Demonstrates the effectiveness and feasibility of language-driven task decomposition and dynamic collaboration in multi-agent systems, offering a systematic solution for executing complex tasks in dynamic environments."}}
{"id": "2511.00328", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00328", "abs": "https://arxiv.org/abs/2511.00328", "authors": ["Isai Daniel Chac\u00f3n", "Paola Ruiz Puentes", "Jillian Pearse", "Pablo Arbel\u00e1ez"], "title": "Towards Automated Petrography", "comment": null, "summary": "Petrography is a branch of geology that analyzes the mineralogical\ncomposition of rocks from microscopical thin section samples. It is essential\nfor understanding rock properties across geology, archaeology, engineering,\nmineral exploration, and the oil industry. However, petrography is a\nlabor-intensive task requiring experts to conduct detailed visual examinations\nof thin section samples through optical polarization microscopes, thus\nhampering scalability and highlighting the need for automated techniques. To\naddress this challenge, we introduce the Large-scale Imaging and Thin section\nOptical-polarization Set (LITHOS), the largest and most diverse publicly\navailable experimental framework for automated petrography. LITHOS includes\n211,604 high-resolution RGB patches of polarized light and 105,802\nexpert-annotated grains across 25 mineral categories. Each annotation consists\nof the mineral class, spatial coordinates, and expert-defined major and minor\naxes represented as intersecting vector paths, capturing grain geometry and\norientation. We evaluate multiple deep learning techniques for mineral\nclassification in LITHOS and propose a dual-encoder transformer architecture\nthat integrates both polarization modalities as a strong baseline for future\nreference. Our method consistently outperforms single-polarization models,\ndemonstrating the value of polarization synergy in mineral classification. We\nhave made the LITHOS Benchmark publicly available, comprising our dataset,\ncode, and pretrained models, to foster reproducibility and further research in\nautomated petrographic analysis.", "AI": {"tldr": "A large-scale, public petrography benchmark called LITHOS is introduced, featuring over 211k polarized RGB patches and 105k expert-annotated mineral grains across 25 classes. The paper proposes a dual-encoder transformer that fuses two polarization modalities for mineral classification, showing improved performance over single-modality models. The dataset, code, and pretrained models are released to enable reproducibility and further research in automated petrography.", "motivation": "Petrography is labor-intensive, requiring expert visual examination under polarized light microscopes. There is a need for scalable, automated approaches and large, diverse public datasets to advance automated petrographic analysis.", "method": "The authors present LITHOS, a large-scale imaging and thin-section optical-polarization dataset with 211,604 high-resolution RGB patches and 105,802 expert-annotated grains in 25 mineral categories. Each annotation includes mineral class, spatial coordinates, and grain geometry/orientation. They evaluate multiple deep learning models for mineral classification and introduce a dual-encoder transformer that fuses two polarization modalities as a strong baseline.", "result": "The dual-encoder transformer leveraging dual polarization modalities outperforms single-polarization models, demonstrating the value of polarization synergy for mineral classification. The LITHOS benchmark and pretrained models outperform baselines and are publicly released to support replication and further research.", "conclusion": "LITHOS provides a comprehensive, public resource for automated petrographic analysis, enabling reproducible research and setting a strong baseline for multi-modal polarization-based mineral classification. The dataset, code, and pretrained models are released to accelerate progress in automated petrography."}}
{"id": "2511.01232", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01232", "abs": "https://arxiv.org/abs/2511.01232", "authors": ["Yu-Ting Lai", "Jacob Rosen", "Yasamin Foroutani", "Ji Ma", "Wen-Cheng Wu", "Jean-Pierre Hubschman", "Tsu-Chin Tsao"], "title": "High-Precision Surgical Robotic System for Intraocular Procedures", "comment": null, "summary": "Despite the extensive demonstration of robotic systems for both cataract and\nvitreoretinal procedures, existing technologies or mechanisms still possess\ninsufficient accuracy, precision, and degrees of freedom for instrument\nmanipulation or potentially automated tool exchange during surgical procedures.\nA new robotic system that focuses on improving tooltip accuracy, tracking\nperformance, and smooth instrument exchange mechanism is therefore designed and\nmanufactured. Its tooltip accuracy, precision, and mechanical capability of\nmaintaining small incision through remote center of motion were externally\nevaluated using an optical coherence tomography (OCT) system. Through robot\ncalibration and precise coordinate registration, the accuracy of tooltip\npositioning was measured to be 0.053$\\pm$0.031 mm, and the overall performance\nwas demonstrated on an OCT-guided automated cataract lens extraction procedure\nwith deep learning-based pre-operative anatomical modeling and real-time\nsupervision.", "AI": {"tldr": "A novelty ophthalmic robot improves tooltip accuracy (~0.053 mm) and enables OCT-guided, automated cataract lens extraction using DL-based modeling and real-time supervision.", "motivation": "To address insufficient accuracy, precision, DOF, and tool exchange in existing cataract/retina robotics, enabling safer, automated instrument manipulation.", "method": "Design and fabricate a robotic system emphasizing tooltip accuracy, tracking, and smooth instrument exchange; calibrate, register coordinates; evaluate tooltip accuracy using OCT; apply DL-based preop anatomical modeling and real-time supervision in an OCT-guided automated lens extraction procedure.", "result": "Measured tooltip positioning accuracy of 0.053 \u00b1 0.031 mm; demonstrated OCT-guided automated cataract lens extraction with deep-learning anatomical modeling and live supervision.", "conclusion": "The framework achieves high-precision tool control and validates feasibility of automated, OCT-guided cataract procedures with real-time supervisory oversight; implies potential for safer, more autonomous ophthalmic surgeries."}}
{"id": "2511.00108", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00108", "abs": "https://arxiv.org/abs/2511.00108", "authors": ["Yi Zhang", "Che Liu", "Xiancong Ren", "Hanchu Ni", "Shuai Zhang", "Zeyuan Ding", "Jiayu Hu", "Hanzhe Shan", "Zhenwei Niu", "Zhaoyang Liu", "Yue Zhao", "Junbo Qi", "Qinfan Zhang", "Dengjie Li", "Yidong Wang", "Jiachen Luo", "Yong Dai", "Jian Tang", "Xiaozhu Ju"], "title": "Pelican-VL 1.0: A Foundation Brain Model for Embodied Intelligence", "comment": null, "summary": "This report presents Pelican-VL 1.0, a new family of open-source embodied\nbrain models with parameter scales ranging from 7 billion to 72 billion. Our\nexplicit mission is clearly stated as: To embed powerful intelligence into\nvarious embodiments. Pelican-VL 1.0 is currently the largest-scale open-source\nembodied multimodal brain model. Its core advantage lies in the in-depth\nintegration of data power and intelligent adaptive learning mechanisms.\nSpecifically, metaloop distilled a high-quality dataset from a raw dataset\ncontaining 4+ billion tokens. Pelican-VL 1.0 is trained on a large-scale\ncluster of 1000+ A800 GPUs, consuming over 50k+ A800 GPU-hours per checkpoint.\nThis translates to a 20.3% performance uplift from its base model and\noutperforms 100B-level open-source counterparts by 10.6%, placing it on par\nwith leading proprietary systems on well-known embodied benchmarks. We\nestablish a novel framework, DPPO (Deliberate Practice Policy Optimization),\ninspired by human metacognition to train Pelican-VL 1.0. We operationalize this\nas a metaloop that teaches the AI to practice deliberately, which is a\nRL-Refine-Diagnose-SFT loop.", "AI": {"tldr": "Pelican-VL 1.0 is a large-scale open-source embodied multimodal brain model (7B\u201372B params) that uses a metaloop training framework to achieve strong embodied performance, trained on massive GPU resources; it outperforms 100B open-source models and rivals proprietary systems.", "motivation": "Embed powerful intelligence into various embodiments by scaling open-source embodied models and integrating data power with adaptive learning.", "method": "Metaloop data distillation from 4+ billion tokens; DPPO metaloop framework; RL-Refine-Diagnose-SFT loop; large-scale distributed training on 1000+ A800 GPUs.", "result": "20.3% uplift over base; 10.6% better than 100B open-source; parity with leading proprietary on established embodied benchmarks.", "conclusion": "DPPO metaloop demonstrates deliberate practice in AI; contributes a framework for large-scale open-source embodied models; suggests direction for future embodied AI with data-power integration."}}
{"id": "2511.01170", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01170", "abs": "https://arxiv.org/abs/2511.01170", "authors": ["Ruofan Zhang", "Bin Xia", "Zhen Cheng", "Cairen Jian", "Minglun Yang", "Ngai Wong", "Yuan Cheng"], "title": "DART: Difficulty-Adaptive Reasoning Truncation for Efficient Large Language Models", "comment": null, "summary": "Adaptive reasoning is essential for aligning the computational effort of\nlarge language models (LLMs) with the intrinsic difficulty of problems. Current\nchain-of-thought methods boost reasoning ability but indiscriminately generate\nlong explanations, leading to evident inefficiency. However, existing\nreinforcement learning approaches to adaptive thinking remain unstable and\nheavily reward-dependent. Here we propose \\textbf{DART}, a supervised\n\\textbf{D}ifficulty-\\textbf{A}daptive \\textbf{R}easoning \\textbf{T}runcation\nframework that adjusts thinking length according to problem difficulty. By\ndistilling concise reasoning patterns from stronger models, interpolating them\ninto a continuum of reasoning styles, and curating optimal training data that\nbalances correctness and compactness, DART learns when to ``stop thinking''.\nAcross multiple mathematical benchmarks, experimental results demonstrate its\nremarkable efficiency while preserving or improving accuracy, achieving a\nsignificant 81.2\\% reasoning truncation (DeepSeek-R1-Distill-Qwen-7B on GSM8K\ndataset) with 5.33$\\times$ computational acceleration. DART provides a stable\nand general paradigm for efficient reasoning, advancing the development of\nadaptive intelligence in LLMs.", "AI": {"tldr": "DART enables dynamic stopping in LLM reasoning by learning difficulty-aware truncation patterns, achieving big speedups with maintained accuracy on math tasks.", "motivation": "Long chain-of-thought (CoT) explanations are expensive and inefficient, while current RL-based adaptive thinking methods are unstable and reward-sensitive. There is a need for a stable, supervised approach that aligns reasoning length with problem difficulty.", "method": "Distill concise reasoning patterns from stronger models, interpolate them into a continuum of reasoning styles, and curate training data that balance correctness and compactness. Train the model to decide when to stop thinking (i.e., truncate reasoning) based on problem difficulty.", "result": "On GSM8K and other math benchmarks, DART achieves significant efficiency gains (e.g., 5.33\u00d7 computational acceleration) with high or improved accuracy. It reports an 81.2% reasoning truncation (DeepSeek-R1-Distill-Qwen-7B on GSM8K).", "conclusion": "DART provides a stable, general paradigm for efficient reasoning in LLMs, enabling adaptive, difficulty-aware thinking that reduces computation while preserving or improving performance."}}
{"id": "2511.00335", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00335", "abs": "https://arxiv.org/abs/2511.00335", "authors": ["Weidong Zhang", "Pak Lun Kevin Ding", "Huan Liu"], "title": "Beyond ImageNet: Understanding Cross-Dataset Robustness of Lightweight Vision Models", "comment": "10 pages, 5 tables, 1 figure, 3 equations, 11 mobile models, 7\n  datasets", "summary": "Lightweight vision classification models such as MobileNet, ShuffleNet, and\nEfficientNet are increasingly deployed in mobile and embedded systems, yet\ntheir performance has been predominantly benchmarked on ImageNet. This raises\ncritical questions: Do models that excel on ImageNet also generalize across\nother domains? How can cross-dataset robustness be systematically quantified?\nAnd which architectural elements consistently drive generalization under tight\nresource constraints? Here, we present the first systematic evaluation of 11\nlightweight vision models (2.5M parameters), trained under a fixed 100-epoch\nschedule across 7 diverse datasets. We introduce the Cross-Dataset Score\n(xScore), a unified metric that quantifies the consistency and robustness of\nmodel performance across diverse visual domains. Our results show that (1)\nImageNet accuracy does not reliably predict performance on fine-grained or\nmedical datasets, (2) xScore provides a scalable predictor of mobile model\nperformance that can be estimated from just four datasets, and (3) certain\narchitectural components--such as isotropic convolutions with higher spatial\nresolution and channel-wise attention--promote broader generalization, while\nTransformer-based blocks yield little additional benefit, despite incurring\nhigher parameter overhead. This study provides a reproducible framework for\nevaluating lightweight vision models beyond ImageNet, highlights key design\nprinciples for mobile-friendly architectures, and guides the development of\nfuture models that generalize robustly across diverse application domains.", "AI": {"tldr": "Cross-dataset evaluation shows ImageNet accuracy is not a reliable predictor of cross-domain generalization for lightweight vision models. The xScore metric quantifies robustness across domains across 11 models and 7 datasets. Isotropic convolutions with higher spatial resolution and channel-wise attention improve generalization, while Transformer blocks add little benefit for resource-constrained settings.", "motivation": "To quantify and understand how well lightweight vision models generalize across diverse visual domains beyond ImageNet, addressing deployment reliability for mobile/embedded systems.", "method": "Systematic evaluation of 11 lightweight models (~2.5M parameters) trained for 100 epochs across 7 diverse datasets. Introduction of Cross-Dataset Score (xScore) as a unified robustness metric. Analysis of architectural components (isotropic convolutions, spatial resolution, channel-wise attention) and comparison with Transformer-based blocks.", "result": "ImageNet accuracy does not reliably predict performance on fine-grained or medical datasets. xScore can be estimated from as few as four datasets, enabling scalable cross-domain evaluation. Architectural components\u2014isotropic convolutions with higher spatial resolution and channel-wise attention\u2014enhance cross-domain generalization; Transformer-based blocks offer little extra benefit and incur higher parameter costs.", "conclusion": "Provides a reproducible framework for evaluating lightweight vision models beyond ImageNet, identifies design principles for mobile-friendly architectures, and guides development toward models with robust cross-domain generalization."}}
{"id": "2511.01236", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01236", "abs": "https://arxiv.org/abs/2511.01236", "authors": ["Junwen Zhang", "Changyue Liu", "Pengqi Fu", "Xiang Guo", "Ye Shi", "Xudong Liang", "Zhijian Wang", "Hanzhi Ma"], "title": "Don't Just Search, Understand: Semantic Path Planning Agent for Spherical Tensegrity Robots in Unknown Environments", "comment": "8 pages, 5 figures", "summary": "Endowed with inherent dynamical properties that grant them remarkable\nruggedness and adaptability, spherical tensegrity robots stand as prototypical\nexamples of hybrid softrigid designs and excellent mobile platforms. However,\npath planning for these robots in unknown environments presents a significant\nchallenge, requiring a delicate balance between efficient exploration and\nrobust planning. Traditional path planners, which treat the environment as a\ngeometric grid, often suffer from redundant searches and are prone to failure\nin complex scenarios due to their lack of semantic understanding. To overcome\nthese limitations, we reframe path planning in unknown environments as a\nsemantic reasoning task. We introduce a Semantic Agent for Tensegrity robots\n(SATPlanner) driven by a Large Language Model (LLM). SATPlanner leverages\nhigh-level environmental comprehension to generate efficient and reliable\nplanning strategies.At the core of SATPlanner is an Adaptive Observation Window\nmechanism, inspired by the \"fast\" and \"slow\" thinking paradigms of LLMs. This\nmechanism dynamically adjusts the perceptual field of the agent: it narrows for\nrapid traversal of open spaces and expands to reason about complex obstacle\nconfigurations. This allows the agent to construct a semantic belief of the\nenvironment, enabling the search space to grow only linearly with the path\nlength (O(L)) while maintaining path quality. We extensively evaluate\nSATPlanner in 1,000 simulation trials, where it achieves a 100% success rate,\noutperforming other real-time planning algorithms. Critically, SATPlanner\nreduces the search space by 37.2% compared to the A* algorithm while achieving\ncomparable, near-optimal path lengths. Finally, the practical feasibility of\nSATPlanner is validated on a physical spherical tensegrity robot prototype.", "AI": {"tldr": "Semantic planning with an LLM-driven SATPlanner uses adaptive perception to efficiently plan paths for spherical tensegrity robots in unknown environments, achieving linear search growth and near-optimal paths with high success and real-world validation.", "motivation": "Overcome limitations of grid-based planners that are search-heavy and brittle in complex, unknown environments; leverage semantic understanding to guide exploration for tensegrity robots.", "method": "Propose SATPlanner, an LLM-driven semantic agent for tensegrity path planning with Adaptive Observation Window that expands or narrows perception based on context, building a semantic belief of the environment to constrain search to O(L). Evaluate in 1,000 simulations and test on a physical robot.", "result": "100% success across 1,000 simulations; 37.2% reduction in search space versus A*; path lengths comparable to near-optimal; demonstration on hardware.", "conclusion": "Semantic reasoning and adaptive perception enable robust, efficient planning for tensegrity robots in unknown environments, with practical feasibility demonstrated."}}
{"id": "2511.00113", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00113", "abs": "https://arxiv.org/abs/2511.00113", "authors": ["Huseyin Goksu"], "title": "MeixnerNet: Adaptive and Robust Spectral Graph Neural Networks with Discrete Orthogonal Polynomials", "comment": null, "summary": "Spectral Graph Neural Networks (GNNs) have achieved state-of-the-art results\nby defining graph convolutions in the spectral domain. A common approach,\npopularized by ChebyNet, is to use polynomial filters based on continuous\northogonal polynomials (e.g., Chebyshev). This creates a theoretical\ndisconnect, as these continuous-domain filters are applied to inherently\ndiscrete graph structures. We hypothesize this mismatch can lead to suboptimal\nperformance and fragility to hyperparameter settings.\n  In this paper, we introduce MeixnerNet, a novel spectral GNN architecture\nthat employs discrete orthogonal polynomials -- specifically, the Meixner\npolynomials $M_k(x; \\beta, c)$. Our model makes the two key shape parameters of\nthe polynomial, beta and c, learnable, allowing the filter to adapt its\npolynomial basis to the specific spectral properties of a given graph. We\novercome the significant numerical instability of these polynomials by\nintroducing a novel stabilization technique that combines Laplacian scaling\nwith per-basis LayerNorm.\n  We demonstrate experimentally that MeixnerNet achieves\ncompetitive-to-superior performance against the strong ChebyNet baseline at the\noptimal K = 2 setting (winning on 2 out of 3 benchmarks). More critically, we\nshow that MeixnerNet is exceptionally robust to variations in the polynomial\ndegree K, a hyperparameter to which ChebyNet proves to be highly fragile,\ncollapsing in performance where MeixnerNet remains stable.", "AI": {"tldr": "MeixnerNet introduces discrete Meixner polynomial filters with learnable shape parameters, stabilized by Laplacian scaling and per-basis LayerNorm, achieving competitive accuracy to ChebyNet and strong robustness to changes in polynomial degree K.", "motivation": "Continuous-domain polynomial spectral GNNs (e.g., ChebyNet) may misalign with the discrete graph spectrum, leading to fragility and suboptimal performance; a discrete, adaptable polynomial basis could better capture spectral properties.", "method": "Employ discrete Meixner polynomials M_k(x; beta, c) with two learnable parameters beta and c; stabilize numerical issues via Laplacian scaling plus per-basis LayerNorm; evaluate across different polynomial degrees K.", "result": "MeixnerNet matches or exceeds ChebyNet at the optimal K=2 on three benchmarks (2 wins). It shows strong robustness to variations in K, whereas ChebyNet is fragile and can collapse with suboptimal K.", "conclusion": "Discrete, learnable polynomial bases tailored to graph spectra can improve stability and performance of spectral GNNs, providing an effective alternative to continuous-domain filters."}}
{"id": "2511.01182", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01182", "abs": "https://arxiv.org/abs/2511.01182", "authors": ["Cuong Van Duc", "Thai Tran Quoc", "Minh Nguyen Dinh Tuan", "Tam Vu Duc", "Son Nguyen Van", "Hanh Nguyen Thi"], "title": "MiRAGE: Misconception Detection with Retrieval-Guided Multi-Stage Reasoning and Ensemble Fusion", "comment": null, "summary": "Detecting student misconceptions in open-ended responses is a longstanding\nchallenge, demanding semantic precision and logical reasoning. We propose\nMiRAGE - Misconception Detection with Retrieval-Guided Multi-Stage Reasoning\nand Ensemble Fusion, a novel framework for automated misconception detection in\nmathematics. MiRAGE operates in three stages: (1) a Retrieval module narrows a\nlarge candidate pool to a semantically relevant subset; (2) a Reasoning module\nemploys chain-of-thought generation to expose logical inconsistencies in\nstudent solutions; and (3) a Reranking module refines predictions by aligning\nthem with the reasoning. These components are unified through an\nensemble-fusion strategy that enhances robustness and interpretability. On\nmathematics datasets, MiRAGE achieves Mean Average Precision scores of\n0.82/0.92/0.93 at levels 1/3/5, consistently outperforming individual modules.\nBy coupling retrieval guidance with multi-stage reasoning, MiRAGE reduces\ndependence on large-scale language models while delivering a scalable and\neffective solution for educational assessment.", "AI": {"tldr": "MiRAGE is a retrieval-guided, multi-stage reasoning framework with ensemble fusion for detecting math misconceptions from open-ended student responses, achieving strong MAP and offering robustness and interpretability.", "motivation": "Detecting misconceptions in open-ended mathematics responses is hard due to the need for semantic precision and logical reasoning; existing approaches struggle to combine retrieval, reasoning, and alignment in a scalable, interpretable way.", "method": "Three-stage pipeline: (1) Retrieval narrows candidate pool to a semantically relevant subset; (2) Reasoning uses chain-of-thought generation to reveal logical inconsistencies in student solutions; (3) Reranking refines predictions by aligning with the reasoning. These stages are integrated via an ensemble-fusion strategy to improve robustness and interpretability.", "result": "On mathematics datasets, MiRAGE achieves Mean Average Precision of 0.82, 0.92, 0.93 at levels 1, 3, 5, respectively, outperforming individual modules.", "conclusion": "Retrieval-guided multi-stage reasoning with ensemble fusion yields robust, interpretable misconceptions detection while reducing reliance on large-scale language models, offering a scalable solution for educational assessment."}}
{"id": "2511.00338", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00338", "abs": "https://arxiv.org/abs/2511.00338", "authors": ["Yuhao Fang", "Zijian Wang", "Yao Lu", "Ye Zhang", "Chun Li"], "title": "A DeepONet joint Neural Tangent Kernel Hybrid Framework for Physics-Informed Inverse Source Problems and Robust Image Reconstruction", "comment": null, "summary": "This work presents a novel hybrid approach that integrates Deep Operator\nNetworks (DeepONet) with the Neural Tangent Kernel (NTK) to solve complex\ninverse problem. The method effectively addresses tasks such as source\nlocalization governed by the Navier-Stokes equations and image reconstruction,\novercoming challenges related to nonlinearity, sparsity, and noisy data. By\nincorporating physics-informed constraints and task-specific regularization\ninto the loss function, the framework ensures solutions that are both\nphysically consistent and accurate. Validation on diverse synthetic and real\ndatasets demonstrates its robustness, scalability, and precision, showcasing\nits broad potential applications in computational physics and imaging sciences.", "AI": {"tldr": "A hybrid DeepONet-NTK framework for inverse problems that uses physics-informed loss to handle nonlinearity, sparsity, and noise, demonstrated on Navier-Stokes-based source localization and image reconstruction with synthetic and real data.", "motivation": "Inverse problems in physics and imaging are highly nonlinear and data-sparse/noisy; there is a need for scalable, physics-consistent operator-learning methods that can leverage both neural operators and kernel-based regularization.", "method": "Integrate DeepONet (operator learning) with Neural Tangent Kernel (NTK) to impose kernel-based regularization and stability. Embed physics-informed constraints (e.g., Navier\u2013Stokes equations) and task-specific regularization into the training loss to enforce physical consistency and improve accuracy for inverse mappings.", "result": "The approach shows robustness to nonlinearity, sparsity, and noise, with accurate source localization and high-quality image reconstruction across synthetic and real datasets, indicating strong scalability and precision.", "conclusion": "The hybrid DeepONet-NTK framework provides a versatile, physics-informed tool for challenging inverse problems in computational physics and imaging, with potential for extension to additional PDEs, applications, and more complex datasets."}}
{"id": "2511.01256", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01256", "abs": "https://arxiv.org/abs/2511.01256", "authors": ["Yasamin Foroutani", "Yasamin Mousavi-Motlagh", "Aya Barzelay", "Tsu-Chin Tsao"], "title": "Improving Needle Penetration via Precise Rotational Insertion Using Iterative Learning Control", "comment": "10 pages, 10 figures", "summary": "Achieving precise control of robotic tool paths is often challenged by\ninherent system misalignments, unmodeled dynamics, and actuation inaccuracies.\nThis work introduces an Iterative Learning Control (ILC) strategy to enable\nprecise rotational insertion of a tool during robotic surgery, improving\npenetration efficacy and safety compared to straight insertion tested in\nsubretinal injection. A 4 degree of freedom (DOF) robot manipulator is used,\nwhere misalignment of the fourth joint complicates the simple application of\nneedle rotation, motivating an ILC approach that iteratively adjusts joint\ncommands based on positional feedback. The process begins with calibrating the\nforward kinematics for the chosen surgical tool to achieve higher accuracy,\nfollowed by successive ILC iterations guided by Optical Coherence Tomography\n(OCT) volume scans to measure the error and refine control inputs. Experimental\nresults, tested on subretinal injection tasks on ex vivo pig eyes, show that\nthe optimized trajectory resulted in higher success rates in tissue penetration\nand subretinal injection compared to straight insertion, demonstrating the\neffectiveness of ILC in overcoming misalignment challenges. This approach\noffers potential applications for other high precision robot tasks requiring\ncontrolled insertions as well.", "AI": {"tldr": "An iterative learning control (ILC) approach improves precision of rotational tool insertion in robotic surgery by iteratively updating joint commands based on OCT-measured error, after FK calibration, validated on ex vivo pig eyes showing higher penetration success than straight insertion.", "motivation": "Inherent misalignments, unmodeled dynamics, and actuation errors hinder precise tool insertion; need for accurate control to improve safety and efficacy in high-precision robotic surgery.", "method": "Calibrate forward kinematics of the surgical tool; implement 4-DOF ILC that adjusts joint commands based on positional feedback; use OCT volume scans to measure insertion error; perform iterative updates; test on ex vivo pig eyes performing subretinal injections.", "result": "Optimized trajectory yielded higher tissue penetration and subretinal injection success rates vs straight insertion; demonstrates effectiveness of ILC in compensating misalignment.", "conclusion": "ILC can enable precise controlled insertions in high-precision robotic tasks; potential applicability to other tasks requiring controlled insertions; potential improvement to safety and efficacy in robotic surgery."}}
{"id": "2511.00116", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00116", "abs": "https://arxiv.org/abs/2511.00116", "authors": ["Avisek Naug", "Antonio Guillen", "Vineet Kumar", "Scott Greenwood", "Wesley Brewer", "Sahand Ghorbanpour", "Ashwin Ramesh Babu", "Vineet Gundecha", "Ricardo Luna Gutierrez", "Soumyendu Sarkar"], "title": "LC-Opt: Benchmarking Reinforcement Learning and Agentic AI for End-to-End Liquid Cooling Optimization in Data Centers", "comment": "Submitted to the NeurIPS 2025 conference", "summary": "Liquid cooling is critical for thermal management in high-density data\ncenters with the rising AI workloads. However, machine learning-based\ncontrollers are essential to unlock greater energy efficiency and reliability,\npromoting sustainability. We present LC-Opt, a Sustainable Liquid Cooling (LC)\nbenchmark environment, for reinforcement learning (RL) control strategies in\nenergy-efficient liquid cooling of high-performance computing (HPC) systems.\nBuilt on the baseline of a high-fidelity digital twin of Oak Ridge National\nLab's Frontier Supercomputer cooling system, LC-Opt provides detailed\nModelica-based end-to-end models spanning site-level cooling towers to data\ncenter cabinets and server blade groups. RL agents optimize critical thermal\ncontrols like liquid supply temperature, flow rate, and granular valve\nactuation at the IT cabinet level, as well as cooling tower (CT) setpoints\nthrough a Gymnasium interface, with dynamic changes in workloads. This\nenvironment creates a multi-objective real-time optimization challenge\nbalancing local thermal regulation and global energy efficiency, and also\nsupports additional components like a heat recovery unit (HRU). We benchmark\ncentralized and decentralized multi-agent RL approaches, demonstrate policy\ndistillation into decision and regression trees for interpretable control, and\nexplore LLM-based methods that explain control actions in natural language\nthrough an agentic mesh architecture designed to foster user trust and simplify\nsystem management. LC-Opt democratizes access to detailed, customizable liquid\ncooling models, enabling the ML community, operators, and vendors to develop\nsustainable data center liquid cooling control solutions.", "AI": {"tldr": "LC-Opt is a comprehensive RL-enabled benchmark for sustainable liquid cooling in HPC, built on a Frontier digital twin, enabling centralized/decentralized RL, policy distillation for interpretability, and LLM-based action explanations.", "motivation": "Rising AI workloads increase data center cooling demand; ML controllers can improve energy efficiency and reliability; need accessible, high-fidelity benchmarking to develop and compare RL-based cooling strategies.", "method": "Modelica-based end-to-end digital twin spanning from cooling towers to server blades; Gymnasium interface for RL; optimization of IT-level setpoints and CT setpoints; multi-objective real-time optimization; supports HRU; evaluation of centralized and multi-agent RL; policy distillation; agentic mesh with LLM explanations.", "result": "Demonstrates feasibility of RL control in liquid cooling; provides a platform for benchmarking, interpretability via decision/regression trees, and explainable actions via LLMs; democratizes access to detailed liquid cooling models.", "conclusion": "LC-Opt enables researchers, operators, and vendors to develop sustainable, energy-efficient liquid cooling control solutions; fosters trust and manageability through interpretable policies and explanations."}}
{"id": "2511.01183", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01183", "abs": "https://arxiv.org/abs/2511.01183", "authors": ["Hainan Fang", "Yuanbo Wen", "Jun Bi", "Yihan Wang", "Tonghui He", "Yanlin Tang", "Di Huang", "Jiaming Guo", "Rui Zhang", "Qi Guo", "Yunji Chen"], "title": "QiMeng-NeuComBack: Self-Evolving Translation from IR to Assembly Code", "comment": "Accepted at NeurIPS 2025", "summary": "Compilers, while essential, are notoriously complex systems that demand\nprohibitively expensive human expertise to develop and maintain. The recent\nadvancements in Large Language Models (LLMs) offer a compelling new paradigm:\nNeural Compilation, which could potentially simplify compiler development for\nnew architectures and facilitate the discovery of innovative optimization\ntechniques. However, several critical obstacles impede its practical adoption.\nFirstly, a significant lack of dedicated benchmarks and robust evaluation\nmethodologies hinders objective assessment and tracking of progress in the\nfield. Secondly, systematically enhancing the reliability and performance of\nLLM-generated assembly remains a critical challenge. Addressing these\nchallenges, this paper introduces NeuComBack, a novel benchmark dataset\nspecifically designed for IR-to-assembly compilation. Leveraging this dataset,\nwe first define a foundational Neural Compilation workflow and conduct a\ncomprehensive evaluation of the capabilities of recent frontier LLMs on Neural\nCompilation, establishing new performance baselines. We further propose a\nself-evolving prompt optimization method that enables LLMs to iteratively\nevolve their internal prompt strategies by extracting insights from prior\nself-debugging traces, thereby enhancing their neural compilation capabilities.\nExperiments demonstrate that our method significantly improves both the\nfunctional correctness and the performance of LLM-generated assembly code.\nCompared to baseline prompts, the functional correctness rates improved from\n44% to 64% on x86_64 and from 36% to 58% on aarch64, respectively. More\nsignificantly, among the 16 correctly generated x86_64 programs using our\nmethod, 14 (87.5%) surpassed clang-O3 performance.", "AI": {"tldr": "NeuComBack introduces a dedicated IR-to-assembly benchmark and a self-evolving prompt optimization approach to improve neural compilation, showing significant gains in functional correctness and instances of surpassing clang-O3.", "motivation": "Compiler development is complex and expensive; LLM-based neural compilation could lower barriers for new architectures and optimization discovery, but there is a lack of benchmarks and reliable assembly generation.", "method": "Create NeuComBack dataset for IR-to-assembly; define a foundational Neural Compilation workflow; evaluate frontier LLMs on neural compilation; propose a self-evolving prompt optimization method that learns from prior self-debugging traces to refine prompts and improve code generation.", "result": "Functional correctness improved from 44% to 64% on x86_64 and from 36% to 58% on aarch64; among 16 correctly generated x86_64 programs, 14 (87.5%) surpassed clang-O3.", "conclusion": "A practical benchmark and a self-evolving prompting strategy substantially boost LLM-based neural compilation, enabling higher correctness and competitive performance relative to established compilers; NeuComBack provides objective benchmarks for tracking progress."}}
{"id": "2511.00344", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00344", "abs": "https://arxiv.org/abs/2511.00344", "authors": ["Xihang Qiu", "Jiarong Cheng", "Yuhao Fang", "Wanpeng Zhang", "Yao Lu", "Ye Zhang", "Chun Li"], "title": "Federated Dialogue-Semantic Diffusion for Emotion Recognition under Incomplete Modalities", "comment": null, "summary": "Multimodal Emotion Recognition in Conversations (MERC) enhances emotional\nunderstanding through the fusion of multimodal signals. However, unpredictable\nmodality absence in real-world scenarios significantly degrades the performance\nof existing methods. Conventional missing-modality recovery approaches, which\ndepend on training with complete multimodal data, often suffer from semantic\ndistortion under extreme data distributions, such as fixed-modality absence. To\naddress this, we propose the Federated Dialogue-guided and Semantic-Consistent\nDiffusion (FedDISC) framework, pioneering the integration of federated learning\ninto missing-modality recovery. By federated aggregation of modality-specific\ndiffusion models trained on clients and broadcasting them to clients missing\ncorresponding modalities, FedDISC overcomes single-client reliance on modality\ncompleteness. Additionally, the DISC-Diffusion module ensures consistency in\ncontext, speaker identity, and semantics between recovered and available\nmodalities, using a Dialogue Graph Network to capture conversational\ndependencies and a Semantic Conditioning Network to enforce semantic alignment.\nWe further introduce a novel Alternating Frozen Aggregation strategy, which\ncyclically freezes recovery and classifier modules to facilitate collaborative\noptimization. Extensive experiments on the IEMOCAP, CMUMOSI, and CMUMOSEI\ndatasets demonstrate that FedDISC achieves superior emotion classification\nperformance across diverse missing modality patterns, outperforming existing\napproaches.", "AI": {"tldr": "FedDISC introduces federated diffusion-based missing-modality recovery for multimodal emotion recognition in conversations, achieving semantic-consistent recovery and superior performance when modalities are missing.", "motivation": "To address unpredictable modality absence in multimodal emotion recognition and overcome semantic distortion and single-client reliance of full-data-trained missing-modality recovery methods.", "method": "Federated aggregation of modality-specific diffusion models trained on clients, broadcasting to clients missing corresponding modalities. The DISC-Diffusion module enforces context, speaker identity, and semantic alignment via a Dialogue Graph Network and a Semantic Conditioning Network. An Alternating Frozen Aggregation strategy cycles freezing of recovery and classifier modules to facilitate collaborative optimization.", "result": "Experiments on IEMOCAP, CMUMOSI, and CMUMOSEI show FedDISC achieves superior emotion classification performance across diverse missing modality patterns, outperforming existing approaches.", "conclusion": "FedDISC provides robust, semantically consistent missing-modality recovery in a federated setting, enabling collaborative optimization and improved MERC performance when modalities are incomplete."}}
{"id": "2511.01272", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01272", "abs": "https://arxiv.org/abs/2511.01272", "authors": ["Sehui Jeong", "Magaly C. Aviles", "Athena X. Naylor", "Cynthia Sung", "Allison M. Okamura"], "title": "Design and Fabrication of Origami-Inspired Knitted Fabrics for Soft Robotics", "comment": null, "summary": "Soft robots employing compliant materials and deformable structures offer\ngreat potential for wearable devices that are comfortable and safe for human\ninteraction. However, achieving both structural integrity and compliance for\ncomfort remains a significant challenge. In this study, we present a novel\nfabrication and design method that combines the advantages of origami\nstructures with the material programmability and wearability of knitted\nfabrics. We introduce a general design method that translates origami patterns\ninto knit designs by programming both stitch and material patterns. The method\ncreates folds in preferred directions while suppressing unintended buckling and\nbending by selectively incorporating heat fusible yarn to create rigid panels\naround compliant creases. We experimentally quantify folding moments and show\nthat stitch patterning enhances folding directionality while the heat fusible\nyarn (1) keeps geometry consistent by reducing edge curl and (2) prevents\nout-of-plane deformations by stiffening panels. We demonstrate the framework\nthrough the successful reproduction of complex origami tessellations, including\nMiura-ori, Yoshimura, and Kresling patterns, and present a wearable knitted\nKaleidocycle robot capable of locomotion. The combination of structural\nreconfigurability, material programmability, and potential for manufacturing\nscalability highlights knitted origami as a promising platform for\nnext-generation wearable robotics.", "AI": {"tldr": "A knitted origami-inspired approach combines origami folding patterns with heat-fusible yarn to create reconfigurable, wearable fabric robots; demonstrates Miura-ori, Yoshimura, Kresling patterns, and a Kaleidocycle robot.", "motivation": "Soft robots with both compliance and structural integrity are needed for comfortable, safe wearables; traditional methods struggle to balance flexibility and rigidity at scale; knitted fabrics offer wearability and manufacturability.", "method": "Translate origami patterns into knit designs by programming stitch and material patterns; selectively incorporate heat fusible yarn to form rigid panels around compliant creases, enhancing fold directionality and suppressing unwanted buckling; quantify folding moments and boundary deformations; reproduce complex origami tessellations (Miura-ori, Yoshimura, Kresling); demonstrate a wearable knitted Kaleidocycle robot.", "result": "Stitch patterning enhances folding directionality; heat fusible yarn stabilizes geometry by reducing edge curl and stiffening panels, preventing out-of-plane deformations; successful replication of Miura-ori, Yoshimura, Kresling tessellations; wearable Kaleidocycle robot capable of locomotion.", "conclusion": "Knitted origami offers a platform with structural reconfigurability, material programmability, and potential for scalable manufacturing, making it a promising approach for next-generation wearable robotics."}}
{"id": "2511.00117", "categories": ["cs.LG", "cs.AI", "cs.MA", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00117", "abs": "https://arxiv.org/abs/2511.00117", "authors": ["Antonio Guillen-Perez", "Avisek Naug", "Vineet Gundecha", "Sahand Ghorbanpour", "Ricardo Luna Gutierrez", "Ashwin Ramesh Babu", "Munther Salim", "Shubhanker Banerjee", "Eoin H. Oude Essink", "Damien Fay", "Soumyendu Sarkar"], "title": "DCcluster-Opt: Benchmarking Dynamic Multi-Objective Optimization for Geo-Distributed Data Center Workloads", "comment": "Submitted to the NeurIPS 2025 conference", "summary": "The increasing energy demands and carbon footprint of large-scale AI require\nintelligent workload management in globally distributed data centers. Yet\nprogress is limited by the absence of benchmarks that realistically capture the\ninterplay of time-varying environmental factors (grid carbon intensity,\nelectricity prices, weather), detailed data center physics (CPUs, GPUs, memory,\nHVAC energy), and geo-distributed network dynamics (latency and transmission\ncosts). To bridge this gap, we present DCcluster-Opt: an open-source,\nhigh-fidelity simulation benchmark for sustainable, geo-temporal task\nscheduling. DCcluster-Opt combines curated real-world datasets, including AI\nworkload traces, grid carbon intensity, electricity markets, weather across 20\nglobal regions, cloud transmission costs, and empirical network delay\nparameters with physics-informed models of data center operations, enabling\nrigorous and reproducible research in sustainable computing. It presents a\nchallenging scheduling problem where a top-level coordinating agent must\ndynamically reassign or defer tasks that arrive with resource and service-level\nagreement requirements across a configurable cluster of data centers to\noptimize multiple objectives. The environment also models advanced components\nsuch as heat recovery. A modular reward system enables an explicit study of\ntrade-offs among carbon emissions, energy costs, service level agreements, and\nwater use. It provides a Gymnasium API with baseline controllers, including\nreinforcement learning and rule-based strategies, to support reproducible ML\nresearch and a fair comparison of diverse algorithms. By offering a realistic,\nconfigurable, and accessible testbed, DCcluster-Opt accelerates the development\nand validation of next-generation sustainable computing solutions for\ngeo-distributed data centers.", "AI": {"tldr": "An open-source, high-fidelity benchmark (DCcluster-Opt) for sustainable, geo-temporal scheduling across globally distributed data centers, integrating real-world AI workloads, environmental factors, energy networks, and physics-based data-center models, with a Gymnasium API and baseline controllers.", "motivation": "Addresses the lack of realistic benchmarks that jointly model time-varying grid carbon intensity, electricity prices, weather, data-center physics, and geo-distributed network dynamics to enable reproducible, multi-objective scheduling research.", "method": "Assembles curated real-world datasets (AI workload traces, grid carbon intensity, electricity markets, weather across 20 regions, cloud transmission costs, network delay) and physics-informed models (CPUs, GPUs, memory, HVAC, heat recovery); defines a configurable, multi-objective scheduling problem with a top-level agent; implements a modular reward system; provides Gymnasium-compatible environment with baseline RL and rule-based controllers.", "result": "Delivers a challenging benchmark that supports studying trade-offs among carbon emissions, energy costs, SLA, and water use; enables reproducible ML research and fair algorithm comparisons; includes open-source baseline controllers and deployment-ready APIs.", "conclusion": "DCcluster-Opt is a realistic, configurable testbed that accelerates development and validation of sustainable computing solutions for geo-distributed data centers."}}
{"id": "2511.01258", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01258", "abs": "https://arxiv.org/abs/2511.01258", "authors": ["Chuyue Lou", "M. Amine Atoui"], "title": "Graph Neural Network-Based Semi-Supervised Open-Set Fault Diagnosis for Marine Machinery Systems", "comment": null, "summary": "Recently, fault diagnosis methods for marine machinery systems based on deep\nlearning models have attracted considerable attention in the shipping industry.\nMost existing studies assume fault classes are consistent and known between the\ntraining and test datasets, and these methods perform well under controlled\nenvironment. In practice, however, previously unseen or unknown fault types\n(i.e., out-of-distribution or open-set observations not present during\ntraining) can occur, causing such methods to fail and posing a significant\nchallenge to their widespread industrial deployment. To address this challenge,\nthis paper proposes a semi-supervised open-set fault diagnosis (SOFD) framework\nthat enhances and extends the applicability of deep learning models in open-set\nfault diagnosis scenarios. The framework includes a reliability subset\nconstruction process, which uses a multi-layer fusion feature representation\nextracted by a supervised feature learning model to select an unlabeled test\nsubset. The labeled training set and pseudo-labeled test subset are then fed\ninto a semi-supervised diagnosis model to learn discriminative features for\neach class, enabling accurate classification of known faults and effective\ndetection of unknown samples. Experimental results on a public maritime\nbenchmark dataset demonstrate the effectiveness and superiority of the proposed\nSOFD framework.", "AI": {"tldr": "A semi-supervised open-set fault diagnosis framework (SOFD) for marine machinery that handles unseen fault types by combining reliability subset selection with pseudo-labels and a semi-supervised classifier, improving open-set detection and fault classification on maritime data.", "motivation": "Traditional deep learning fault diagnosis assumes known fault classes; in practice, unseen faults (open-set) occur, requiring methods that can detect unknowns while leveraging unlabeled data.", "method": "Construct a reliability subset from unlabeled test data using multi-layer fusion features from a supervised feature learning model. Then train a semi-supervised diagnosis model on the labeled training set and pseudo-labeled test subset to learn discriminative features for each class, enabling accurate known fault classification and unknown detection.", "result": "Experimental results on a public maritime benchmark dataset show the SOFD framework is effective and superior to baselines in open-set fault diagnosis scenarios.", "conclusion": "SOFD extends deep learning capabilities for marine fault diagnosis to open-set settings, providing reliable detection of unknown faults and improved classification for known faults, with demonstrated practicality on benchmark data."}}
{"id": "2511.00345", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00345", "abs": "https://arxiv.org/abs/2511.00345", "authors": ["Amir Ziashahabi", "Narges Ghasemi", "Sajjad Shahabi", "John Krumm", "Salman Avestimehr", "Cyrus Shahabi"], "title": "OSMGen: Highly Controllable Satellite Image Synthesis using OpenStreetMap Data", "comment": "Accepted at NeurIPS 2025 UrbanAI Workshop", "summary": "Accurate and up-to-date geospatial data are essential for urban planning,\ninfrastructure monitoring, and environmental management. Yet, automating urban\nmonitoring remains difficult because curated datasets of specific urban\nfeatures and their changes are scarce. We introduce OSMGen, a generative\nframework that creates realistic satellite imagery directly from raw\nOpenStreetMap (OSM) data. Unlike prior work that relies on raster tiles, OSMGen\nuses the full richness of OSM JSON, including vector geometries, semantic tags,\nlocation, and time, giving fine-grained control over how scenes are generated.\nA central feature of the framework is the ability to produce consistent\nbefore-after image pairs: user edits to OSM inputs translate into targeted\nvisual changes, while the rest of the scene is preserved. This makes it\npossible to generate training data that addresses scarcity and class imbalance,\nand to give planners a simple way to preview proposed interventions by editing\nmap data. More broadly, OSMGen produces paired (JSON, image) data for both\nstatic and changed states, paving the way toward a closed-loop system where\nsatellite imagery can automatically drive structured OSM updates. Source code\nis available at https://github.com/amir-zsh/OSMGen.", "AI": {"tldr": "Generates realistic satellite imagery from raw OSM data and produces consistent before-after pairs for urban-change simulation; supports data augmentation and planning previews; open-source.", "motivation": "Scarcity of curated, up-to-date urban datasets hinders automated urban monitoring; need controllable synthetic data and a way to visualize edits.", "method": "OSMGen consumes full OSM JSON (vector geometries, semantic tags, location, time) to render imagery; unlike raster-tile methods; translates user edits in OSM into visual changes; emits paired JSON+image data for static and changed states.", "result": "Realistic, controllable imagery generation with consistent before-after pairs, enabling targeted data generation and planning previews; supports a potential closed-loop with imagery driving OSM updates.", "conclusion": "Code released at GitHub; framework addresses data scarcity and imbalance in urban monitoring and supports broader planning and environmental applications."}}
{"id": "2511.01276", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01276", "abs": "https://arxiv.org/abs/2511.01276", "authors": ["Yiyao Ma", "Kai Chen", "Kexin Zheng", "Qi Dou"], "title": "Contact Map Transfer with Conditional Diffusion Model for Generalizable Dexterous Grasp Generation", "comment": null, "summary": "Dexterous grasp generation is a fundamental challenge in robotics, requiring\nboth grasp stability and adaptability across diverse objects and tasks.\nAnalytical methods ensure stable grasps but are inefficient and lack task\nadaptability, while generative approaches improve efficiency and task\nintegration but generalize poorly to unseen objects and tasks due to data\nlimitations. In this paper, we propose a transfer-based framework for dexterous\ngrasp generation, leveraging a conditional diffusion model to transfer\nhigh-quality grasps from shape templates to novel objects within the same\ncategory. Specifically, we reformulate the grasp transfer problem as the\ngeneration of an object contact map, incorporating object shape similarity and\ntask specifications into the diffusion process. To handle complex shape\nvariations, we introduce a dual mapping mechanism, capturing intricate\ngeometric relationship between shape templates and novel objects. Beyond the\ncontact map, we derive two additional object-centric maps, the part map and\ndirection map, to encode finer contact details for more stable grasps. We then\ndevelop a cascaded conditional diffusion model framework to jointly transfer\nthese three maps, ensuring their intra-consistency. Finally, we introduce a\nrobust grasp recovery mechanism, identifying reliable contact points and\noptimizing grasp configurations efficiently. Extensive experiments demonstrate\nthe superiority of our proposed method. Our approach effectively balances grasp\nquality, generation efficiency, and generalization performance across various\ntasks. Project homepage: https://cmtdiffusion.github.io/", "AI": {"tldr": "We propose a transfer-based, diffusion-driven framework that transfers grasps from shape templates to novel objects within the same category by generating and jointly aligning object contact, part, and direction maps through a cascaded conditional diffusion model, plus a robust grasp recovery, yielding improved generalization and efficiency.", "motivation": "Analytical grasp methods yield stable grasps but are inefficient and lack task adaptability; generative approaches are more efficient and integrative but generalize poorly due to limited data. A transfer-based approach aims to leverage shape templates to extend grasps to unseen objects and tasks.", "method": "Reformulate grasp transfer as generation of an object contact map; incorporate shape similarity and task specs into diffusion; introduce a dual mapping mechanism to capture geometrical relationships between templates and novel shapes; derive two additional object-centric maps (part map and direction map) for finer contact details; use a cascaded conditional diffusion model to jointly transfer these three maps ensuring intra-consistency; develop a robust grasp recovery mechanism to identify reliable contact points and optimize grasp configurations.", "result": "Extensive experiments demonstrate superiority of the proposed method, achieving a favorable balance between grasp quality, generation efficiency, and generalization across tasks.", "conclusion": "The proposed transfer-based diffusion framework enables effective, efficient, and robust dexterous grasp transfer within object categories, combining multiple contact-rich maps with a robust recovery step. A project homepage is provided for supplementary materials."}}
{"id": "2511.00121", "categories": ["cs.LG", "physics.soc-ph", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.00121", "abs": "https://arxiv.org/abs/2511.00121", "authors": ["Shoma Yagi", "Jun Ichikawa", "Genki Ichinose"], "title": "Analysis of Line Break prediction models for detecting defensive breakthrough in football", "comment": "14 pages, 8 figures", "summary": "In football, attacking teams attempt to break through the opponent's\ndefensive line to create scoring opportunities. This action, known as a Line\nBreak, is a critical indicator of offensive effectiveness and tactical\nperformance, yet previous studies have mainly focused on shots or goal\nopportunities rather than on how teams break the defensive line. In this study,\nwe develop a machine learning model to predict Line Breaks using event and\ntracking data from the 2023 J1 League season. The model incorporates 189\nfeatures, including player positions, velocities, and spatial configurations,\nand employs an XGBoost classifier to estimate the probability of Line Breaks.\nThe proposed model achieved high predictive accuracy, with an AUC of 0.982 and\na Brier score of 0.015. Furthermore, SHAP analysis revealed that factors such\nas offensive player speed, gaps in the defensive line, and offensive players'\nspatial distributions significantly contribute to the occurrence of Line\nBreaks. Finally, we found a moderate positive correlation between the predicted\nprobability of being Line-Broken and the number of shots and crosses conceded\nat the team level. These results suggest that Line Breaks are closely linked to\nthe creation of scoring opportunities and provide a quantitative framework for\nunderstanding tactical dynamics in football.", "AI": {"tldr": "A machine learning model using event and tracking data from the 2023 J1 League predicts Line Breaks with high accuracy (AUC 0.982, Brier 0.015) using 189 features and an XGBoost classifier; SHAP identifies speed, defender gaps, and offense distribution as key drivers; a moderate team-level link exists between predicted Line Breaks and shots/crosses conceded.", "motivation": "Line Breaks are a crucial yet under-explored indicator of offensive effectiveness in football, bridging the gap between defensive resistance and scoring opportunities. Prior work emphasized shots/opportunities rather than the mechanism of breaking the defensive line; a quantitative model is needed to understand tactical dynamics and assist performance analysis.", "method": "The study builds a predictive model for Line Breaks using 189 features derived from event and tracking data from the 2023 J1 League season. An XGBoost classifier estimates the probability of Line Breaks. Model evaluation uses AUC and Brier score. SHAP analysis identifies feature importance (e.g., offensive speed, defensive gaps, offensive spatial distribution). A team-level correlation analysis relates predicted Line Break probability to counts of shots and crosses conceded.", "result": "The model achieved an AUC of 0.982 and a Brier score of 0.015, indicating high predictive accuracy. SHAP analysis highlighted offensive speed, gaps in the defensive line, and offensive spatial distributions as significant contributors to Line Breaks. A moderate positive correlation was observed between predicted Line Break probability and the number of shots and crosses conceded at the team level.", "conclusion": "Line Breaks are closely linked to creating scoring opportunities, and the study provides a quantitative framework to understand tactical dynamics in football. The approach demonstrates the value of combining event and tracking data with machine learning to assess complex offensive actions."}}
{"id": "2511.01311", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01311", "abs": "https://arxiv.org/abs/2511.01311", "authors": ["Filip Naudot", "Tobias Sundqvist", "Timotheus Kampik"], "title": "llmSHAP: A Principled Approach to LLM Explainability", "comment": null, "summary": "Feature attribution methods help make machine learning-based inference\nexplainable by determining how much one or several features have contributed to\na model's output. A particularly popular attribution method is based on the\nShapley value from cooperative game theory, a measure that guarantees the\nsatisfaction of several desirable principles, assuming deterministic inference.\nWe apply the Shapley value to feature attribution in large language model\n(LLM)-based decision support systems, where inference is, by design, stochastic\n(non-deterministic). We then demonstrate when we can and cannot guarantee\nShapley value principle satisfaction across different implementation variants\napplied to LLM-based decision support, and analyze how the stochastic nature of\nLLMs affects these guarantees. We also highlight trade-offs between explainable\ninference speed, agreement with exact Shapley value attributions, and principle\nattainment.", "AI": {"tldr": "Shapley-value feature attribution for LLM-based decision support under stochastic inference; analyzes when Shapley principles hold across implementation variants and the trade-offs between explainability speed, fidelity to exact Shapley attributions, and principle attainment.", "motivation": "Explainability for LLM decision support; Shapley axioms assume determinism, but LLMs introduce stochasticity. The work investigates when Shapley-based attributions remain valid and how implementation choices affect guarantees.", "method": "Theoretical and/or empirical analysis of multiple attribution variants applied to stochastic LLM inference; assessment of Shapley principle satisfaction (e.g., dummy, symmetry, efficiency) under randomness; examination of trade-offs between speed, fidelity to exact Shapley attributions, and principle attainment.", "result": "Identifies conditions under which Shapley principles can be guaranteed or approximated in stochastic LLM settings; shows stochasticity can invalidate standard Shapley guarantees; compares variants in terms of speed and fidelity; highlights when exact Shapley is impractical and how close approximations can be.", "conclusion": "Caution in applying deterministic Shapley-based attribution to stochastic LLMs; provides guidelines on when principles hold, how to approximate attribution reliably, and the inherent trade-offs between speed, accuracy, and axiomatic guarantees."}}
{"id": "2511.00352", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00352", "abs": "https://arxiv.org/abs/2511.00352", "authors": ["Mohd Ruhul Ameen", "Akif Islam"], "title": "Detecting AI-Generated Images via Diffusion Snap-Back Reconstruction: A Forensic Approach", "comment": "6 pages, 8 figures, 4 Tables, submitted to ICECTE 2026", "summary": "The rapid rise of generative diffusion models has made distinguishing\nauthentic visual content from synthetic imagery increasingly challenging.\nTraditional deepfake detection methods, which rely on frequency or pixel-level\nartifacts, fail against modern text-to-image systems such as Stable Diffusion\nand DALL-E that produce photorealistic and artifact-free results. This paper\nintroduces a diffusion-based forensic framework that leverages multi-strength\nimage reconstruction dynamics, termed diffusion snap-back, to identify\nAI-generated images. By analysing how reconstruction metrics (LPIPS, SSIM, and\nPSNR) evolve across varying noise strengths, we extract interpretable\nmanifold-based features that differentiate real and synthetic images. Evaluated\non a balanced dataset of 4,000 images, our approach achieves 0.993 AUROC under\ncross-validation and remains robust to common distortions such as compression\nand noise. Despite using limited data and a single diffusion backbone (Stable\nDiffusion v1.5), the proposed method demonstrates strong generalization and\ninterpretability, offering a foundation for scalable, model-agnostic synthetic\nmedia forensics.", "AI": {"tldr": "A diffusion-based forensic method, diffusion snap-back, analyzes image reconstruction dynamics across multiple noise strengths to distinguish real and AI-generated images; achieves near-perfect AUROC and shows robustness and interpretability.", "motivation": "As generative diffusion models become dominant, distinguishing authentic visual content from synthetic imagery becomes increasingly challenging for traditional detectors, which often rely on artifact patterns that diffusion models can eliminate. There is a need for a model-agnostic, interpretable, and scalable forensic approach that leverages the diffusion process itself.", "method": "Utilizes multi-strength diffusion-based image reconstruction dynamics. Tracks reconstruction metrics (LPIPS, SSIM, PSNR) as noise strength varies, extracting manifold-based features that differentiate real from synthetic images. Evaluated with Stable Diffusion v1.5 as the backbone on a balanced dataset of 4,000 images, employing cross-validation.", "result": "Achieves 0.993 AUROC under cross-validation on the 4,000-image dataset. Demonstrates robustness to common distortions such as compression and noise. Uses limited data and a single diffusion backbone yet shows strong generalization and interpretability, suggesting potential for scalable, model-agnostic synthetic media forensics.", "conclusion": "Diffusion-based reconstruction dynamics offer a strong, interpretable basis for synthetic media forensics, enabling high-performance detection with limited data and supporting a scalable, model-agnostic forensic framework."}}
{"id": "2511.01288", "categories": ["cs.RO", "cs.SY", "eess.SY", "I.2.9"], "pdf": "https://arxiv.org/pdf/2511.01288", "abs": "https://arxiv.org/abs/2511.01288", "authors": ["Bixuan Zhang", "Fengqi Zhang", "Haojie Chen", "You Wang", "Jie Hao", "Zhiyuan Luo", "Guang Li"], "title": "A High-Speed Capable Spherical Robot", "comment": "5 pages", "summary": "This paper designs a new spherical robot structure capable of supporting\nhigh-speed motion at up to 10 m/s. Building upon a single-pendulum-driven\nspherical robot, the design incorporates a momentum wheel with an axis aligned\nwith the secondary pendulum, creating a novel spherical robot structure.\nPractical experiments with the physical prototype have demonstrated that this\nnew spherical robot can achieve stable high-speed motion through simple\ndecoupled control, which was unattainable with the original structure. The\nspherical robot designed for high-speed motion not only increases speed but\nalso significantly enhances obstacle-crossing performance and terrain\nrobustness.", "AI": {"tldr": "A high-speed spherical robot design using a momentum wheel aligned with a secondary pendulum enables stable motion up to 10 m/s, demonstrated experimentally with a decoupled control approach.", "motivation": "To overcome speed and robustness limitations of traditional single-pendulum spherical robots by enabling fast, controllable motion and better terrain adaptation.", "method": "Integrate a momentum wheel with an axis aligned to the secondary pendulum into a single-pendulum-driven spherical robot, and validate with a physical prototype showing stable high-speed motion under simple decoupled control.", "result": "The robot achieves stable high-speed motion up to 10 m/s and shows improved obstacle-crossing capability and terrain robustness compared with the original design.", "conclusion": "The new spherical-robot structure provides a viable path to fast, robust spherical locomotion using simple decoupled control, with promising practical applications."}}
{"id": "2511.00124", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00124", "abs": "https://arxiv.org/abs/2511.00124", "authors": ["Sai Niranjan Ramachandran", "Manish Krishan Lal", "Suvrit Sra"], "title": "Cross-fluctuation phase transitions reveal sampling dynamics in diffusion models", "comment": "Accepted at NeurIPS 2025. 10 pages, camera-ready version. appendices\n  included", "summary": "We analyse how the sampling dynamics of distributions evolve in score-based\ndiffusion models using cross-fluctuations, a centered-moment statistic from\nstatistical physics. Specifically, we show that starting from an unbiased\nisotropic normal distribution, samples undergo sharp, discrete transitions,\neventually forming distinct events of a desired distribution while\nprogressively revealing finer structure. As this process is reversible, these\ntransitions also occur in reverse, where intermediate states progressively\nmerge, tracing a path back to the initial distribution. We demonstrate that\nthese transitions can be detected as discontinuities in $n^{\\text{th}}$-order\ncross-fluctuations. For variance-preserving SDEs, we derive a closed-form for\nthese cross-fluctuations that is efficiently computable for the reverse\ntrajectory. We find that detecting these transitions directly boosts sampling\nefficiency, accelerates class-conditional and rare-class generation, and\nimproves two zero-shot tasks--image classification and style transfer--without\nexpensive grid search or retraining. We also show that this viewpoint unifies\nclassical coupling and mixing from finite Markov chains with continuous\ndynamics while extending to stochastic SDEs and non Markovian samplers. Our\nframework therefore bridges discrete Markov chain theory, phase analysis, and\nmodern generative modeling.", "AI": {"tldr": "Introduces cross-fluctuation statistics to reveal discrete, phase-like transitions during score-based diffusion sampling; derives a closed-form for variance-preserving SDEs; demonstrates improved sampling efficiency, faster class-conditional/rare-class generation, and successful zero-shot tasks; unifies Markov chain theory with continuous diffusion models.", "motivation": "To understand and accelerate sampling in diffusion models by uncovering underlying transition dynamics and connecting discrete Markov chain perspectives with continuous stochastic dynamics.", "method": "Define and analyze cross-fluctuations (centered-moment statistics) of sampling trajectories, identify discontinuities signaling transitions between states; derive a closed-form expression for cross-fluctuations in variance-preserving SDEs; study reversibility (forward and reverse trajectories) and apply to reverse sampling; validate on sampling efficiency and zero-shot tasks.", "result": "Cross-fluctuations exhibit discontinuities at transition points; detecting these transitions improves sampling efficiency, accelerates class-conditional and rare-class generation, and enhances zero-shot tasks (image classification and style transfer) without grid search or retraining; provides a unified view linking discrete coupling/mixing with continuous SDE dynamics.", "conclusion": "Proposes a unifying framework that connects discrete Markov chain concepts, phase-transition analysis, and modern score-based generative modeling; extends to stochastic and non-Markovian samplers, offering a bridge between theory and practical acceleration techniques."}}
{"id": "2511.01320", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01320", "abs": "https://arxiv.org/abs/2511.01320", "authors": ["Ziqi Wang", "Hailiang Zhao", "Yuhao Yang", "Daojiang Hu", "Cheng Bao", "Mingyi Liu", "Kai Di", "Schahram Dustdar", "Zhongjie Wang", "Shuiguang Deng"], "title": "OmniFuser: Adaptive Multimodal Fusion for Service-Oriented Predictive Maintenance", "comment": null, "summary": "Accurate and timely prediction of tool conditions is critical for intelligent\nmanufacturing systems, where unplanned tool failures can lead to quality\ndegradation and production downtime. In modern industrial environments,\npredictive maintenance is increasingly implemented as an intelligent service\nthat integrates sensing, analysis, and decision support across production\nprocesses. To meet the demand for reliable and service-oriented operation, we\npresent OmniFuser, a multimodal learning framework for predictive maintenance\nof milling tools that leverages both visual and sensor data. It performs\nparallel feature extraction from high-resolution tool images and cutting-force\nsignals, capturing complementary spatiotemporal patterns across modalities. To\neffectively integrate heterogeneous features, OmniFuser employs a\ncontamination-free cross-modal fusion mechanism that disentangles shared and\nmodality-specific components, allowing for efficient cross-modal interaction.\nFurthermore, a recursive refinement pathway functions as an anchor mechanism,\nconsistently retaining residual information to stabilize fusion dynamics. The\nlearned representations can be encapsulated as reusable maintenance service\nmodules, supporting both tool-state classification (e.g., Sharp, Used, Dulled)\nand multi-step force signal forecasting. Experiments on real-world milling\ndatasets demonstrate that OmniFuser consistently outperforms state-of-the-art\nbaselines, providing a dependable foundation for building intelligent\nindustrial maintenance services.", "AI": {"tldr": "A multimodal cross-modal fusion framework, OmniFuser, uses high-res tool images and cutting-force signals with a contamination-free fusion and recursive refinement to improve predictive maintenance for milling tools, outperforming baselines and enabling reusable maintenance modules.", "motivation": "Accurate and timely tool-condition prediction in intelligent manufacturing to reduce downtime, quality degradation, and maintenance costs, by leveraging rich visual and sensor data within service-oriented predictive maintenance.", "method": "Parallel feature extraction from visual tool images and cutting-force signals, followed by a contamination-free cross-modal fusion that disentangles shared and modality-specific components; a recursive refinement pathway (anchor) preserves residual information to stabilize fusion dynamics; learned representations are encapsulated as reusable maintenance service modules; supports tool-state classification (Sharp, Used, Dulled) and multi-step force signal forecasting.", "result": "Empirical evaluation on real-world milling datasets shows OmniFuser consistently outperforms state-of-the-art baselines, indicating robust fusion of multimodal information and reliable predictive maintenance capabilities.", "conclusion": "OmniFuser provides a dependable, service-oriented foundation for intelligent industrial maintenance by delivering accurate tool-state classification and force forecasting via robust multimodal fusion and reusable service modules."}}
{"id": "2511.00357", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00357", "abs": "https://arxiv.org/abs/2511.00357", "authors": ["Niklas W\u00f6lki", "Lukas Kondmann", "Christian Molli\u00e8re", "Martin Langer", "Julia Gottfriedsen", "Martin Werner"], "title": "Transfer Learning for Onboard Cloud Segmentation in Thermal Earth Observation: From Landsat to a CubeSat Constellation", "comment": "This work was presented at the TerraBytes Workshop at the 42nd\n  International Conference on Machine Learning. This version is not part of the\n  official ICML proceedings", "summary": "Onboard cloud segmentation is a critical yet underexplored task in thermal\nEarth observation (EO), particularly for CubeSat missions constrained by\nlimited hardware and spectral information. CubeSats often rely on a single\nthermal band and lack sufficient labeled data, making conventional cloud\nmasking techniques infeasible. This work addresses these challenges by applying\ntransfer learning to thermal cloud segmentation for the FOREST-2 CubeSat, using\na UNet with a lightweight MobileNet encoder. We pretrain the model on the\npublic Landsat-7 Cloud Cover Assessment Dataset and fine-tune it with a small\nset of mission-specific samples in a joint-training setup, improving the macro\nF1 from 0.850 to 0.877 over FOREST-2-only baselines. We convert the model to a\nTensorRT engine and demonstrate full-image inference in under 5 seconds on an\nNVIDIA Jetson Nano. These results show that leveraging public datasets and\nlightweight architectures can enable accurate, efficient thermal-only cloud\nmasking on-orbit, supporting real-time decision-making in data-limited EO\nmissions.", "AI": {"tldr": "Transfer-learning-based thermal cloud segmentation for CubeSats using a lightweight UNet with MobileNet encoder. Pretrained on Landsat-7 Cloud Cover Assessment, fine-tuned with limited mission data, achieving macro F1 improvement (0.850 -> 0.877). TensorRT conversion enables on-device inference <5s on Jetson Nano.", "motivation": "Address onboard cloud masking for thermal EO on CubeSats with limited hardware and labeled data. Leverage public datasets and lightweight architectures to enable real-time, thermal-only cloud segmentation.", "method": "UNet with MobileNet encoder; pretrain on Landsat-7 Cloud Cover Assessment dataset; fine-tune with a small FOREST-2-specific sample set in a joint-training setup; convert to TensorRT engine for full-image inference on an NVIDIA Jetson Nano.", "result": "Macro F1 improved from 0.850 (FOREST-2 baseline) to 0.877; on-device inference under 5 seconds for full-image inference on Jetson Nano.", "conclusion": "Public datasets and lightweight architectures enable accurate, efficient thermal-only cloud masking on-orbit, supporting real-time decision-making in data-limited EO missions."}}
{"id": "2511.01294", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01294", "abs": "https://arxiv.org/abs/2511.01294", "authors": ["Jiawei Wang", "Dingyou Wang", "Jiaming Hu", "Qixuan Zhang", "Jingyi Yu", "Lan Xu"], "title": "Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects", "comment": null, "summary": "A deep understanding of kinematic structures and movable components is\nessential for enabling robots to manipulate objects and model their own\narticulated forms. Such understanding is captured through articulated objects,\nwhich are essential for tasks such as physical simulation, motion planning, and\npolicy learning. However, creating these models, particularly for complex\nsystems like robots or objects with high degrees of freedom (DoF), remains a\nsignificant challenge. Existing methods typically rely on motion sequences or\nstrong assumptions from hand-curated datasets, which hinders scalability. In\nthis paper, we introduce Kinematify, an automated framework that synthesizes\narticulated objects directly from arbitrary RGB images or text prompts. Our\nmethod addresses two core challenges: (i) inferring kinematic topologies for\nhigh-DoF objects and (ii) estimating joint parameters from static geometry. To\nachieve this, we combine MCTS search for structural inference with\ngeometry-driven optimization for joint reasoning, producing physically\nconsistent and functionally valid descriptions. We evaluate Kinematify on\ndiverse inputs from both synthetic and real-world environments, demonstrating\nimprovements in registration and kinematic topology accuracy over prior work.", "AI": {"tldr": "Kinematify automates articulated-object model synthesis directly from RGB images or text prompts by pairing MCTS-based topology search with geometry-driven joint optimization, achieving physically consistent models and improved topology/registration accuracy over prior work.", "motivation": "A deep understanding of kinematic structures is essential for robot manipulation, simulation, and policy learning. High-DoF articulated objects pose challenges for scalable modeling, and existing methods rely on motion sequences or curated datasets, hindering scalability. Automated, image- or prompt-driven articulation synthesis aims to scale modeling to complex systems.", "method": "A two-part approach: (1) use Monte Carlo Tree Search (MCTS) to infer kinematic topology (structure) of articulated objects; (2) apply geometry-driven optimization to estimate joint parameters from static geometry, ensuring physical consistency. The framework combines these steps to produce functionally valid articulated descriptions, evaluated on synthetic and real-world data.", "result": "The method achieves improvements in registration accuracy and kinematic topology accuracy compared with prior work, demonstrating robustness across diverse synthetic and real inputs.", "conclusion": "Kinematify offers a scalable, automated pipeline for articulating objects from RGB images or text prompts, enabling better manipulation, simulation, and policy learning while reducing reliance on motion data and hand-curated datasets."}}
{"id": "2511.00126", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00126", "abs": "https://arxiv.org/abs/2511.00126", "authors": ["Lu Bowen"], "title": "Dynamic Model Selection for Trajectory Prediction via Pairwise Ranking and Meta-Features", "comment": null, "summary": "Recent deep trajectory predictors (e.g., Jiang et al., 2023; Zhou et al.,\n2022) have achieved strong average accuracy but remain unreliable in complex\nlong-tail driving scenarios. These limitations reveal the weakness of the\nprevailing \"one-model-fits-all\" paradigm, particularly in safety-critical urban\ncontexts where simpler physics-based models can occasionally outperform\nadvanced networks (Kalman, 1960). To bridge this gap, we propose a dynamic\nmulti-expert gating framework that adaptively selects the most reliable\ntrajectory predictor among a physics-informed LSTM, a Transformer, and a\nfine-tuned GameFormer on a per-sample basis.\n  Our method leverages internal model signals (meta-features) such as stability\nand uncertainty (Gal and Ghahramani, 2016), which we demonstrate to be\nsubstantially more informative than geometric scene descriptors. To the best of\nour knowledge, this is the first work to formulate trajectory expert selection\nas a pairwise-ranking problem over internal model signals (Burges et al.,\n2005), directly optimizing decision quality without requiring post-hoc\ncalibration.\n  Evaluated on the nuPlan-mini dataset (Caesar et al., 2021) with 1,287\nsamples, our LLM-enhanced tri-expert gate achieves a Final Displacement Error\n(FDE) of 2.567 m, representing a 9.5 percent reduction over GameFormer (2.835\nm), and realizes 57.8 percent of the oracle performance bound. In open-loop\nsimulations, after trajectory horizon alignment, the same configuration reduces\nFDE on left-turn scenarios by approximately 10 percent, demonstrating\nconsistent improvements across both offline validation and open-loop\nevaluation. These results indicate that adaptive hybrid systems enhance\ntrajectory reliability in safety-critical autonomous driving, providing a\npractical pathway beyond static single-model paradigms.", "AI": {"tldr": "A dynamic multi-expert gating framework selects the most reliable trajectory predictor per sample among physics-informed LSTM, Transformer, and GameFormer, using internal meta-features to improve safety-critical trajectory prediction beyond a single-model approach.", "motivation": "Single-model deep trajectory predictors underperform in complex, long-tail urban scenarios and in safety-critical contexts where physics-based methods can excel; a per-sample, adaptive hybrid approach may improve reliability.", "method": "Propose dynamic tri-expert gate with meta-features (stability, uncertainty) and pairwise-ranking over model signals to select among physics-informed LSTM, Transformer, and fine-tuned GameFormer on a per-sample basis; uses LLM-enhanced gating; train with pairwise ranking to optimize decision quality without post-hoc calibration.", "result": "On nuPlan-mini (1,287 samples), achieved Final Displacement Error (FDE) of 2.567 m, 9.5% better than GameFormer (2.835 m); reaches 57.8% of oracle performance bound. In open-loop left-turn scenarios, FDE improved by ~10% after horizon alignment.", "conclusion": "Adaptive hybrid systems that select the most reliable predictor per scenario improve trajectory reliability in safety-critical autonomous driving, offering a practical path beyond static single-model paradigms."}}
{"id": "2511.01329", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01329", "abs": "https://arxiv.org/abs/2511.01329", "authors": ["Ying Song", "Yijing Wang", "Hui Yang", "Weihan Jin", "Jun Xiong", "Congyi Zhou", "Jialin Zhu", "Xiang Gao", "Rong Chen", "HuaGuang Deng", "Ying Dai", "Fei Xiao", "Haihong Tang", "Bo Zheng", "KaiFu Zhang"], "title": "Unbiased Platform-Level Causal Estimation for Search Systems: A Competitive Isolation PSM-DID Framework", "comment": null, "summary": "Evaluating platform-level interventions in search-based two-sided\nmarketplaces is fundamentally challenged by systemic effects such as spillovers\nand network interference. While widely used for causal inference, the PSM\n(Propensity Score Matching) - DID (Difference-in-Differences) framework remains\nsusceptible to selection bias and cross-unit interference from unaccounted\nspillovers. In this paper, we introduced Competitive Isolation PSM-DID, a novel\ncausal framework that integrates propensity score matching with competitive\nisolation to enable platform-level effect measurement (e.g., order volume, GMV)\ninstead of item-level metrics in search systems.\n  Our approach provides theoretically guaranteed unbiased estimation under\nmutual exclusion conditions, with an open dataset released to support\nreproducible research on marketplace interference (github.com/xxxx). Extensive\nexperiments demonstrate significant reductions in interference effects and\nestimation variance compared to baseline methods. Successful deployment in a\nlarge-scale marketplace confirms the framework's practical utility for\nplatform-level causal inference.", "AI": {"tldr": "Competitive Isolation PSM-DID integrates propensity score matching with competitive isolation to enable platform-level causal inference in search-based two-sided marketplaces, addressing spillovers/interference, with unbiased estimation under mutual exclusion, open dataset, and demonstrated improvements over baselines.", "motivation": "Platform-level interventions in marketplaces suffer from spillovers and network interference, which bias causal estimates when using standard PSM-DID focused on item-level metrics. There is a need for a framework that can measure platform-level outcomes (e.g., order volume, GMV) reliably.", "method": "A causal framework combining propensity score matching with competitive isolation to isolate platform-level effects under mutual exclusion conditions. Includes an open dataset for reproducible marketplace interference research and extensive experiments showing reduced interference and estimation variance. Deploys successfully in a large-scale marketplace.", "result": "The approach achieves significant reduction in interference effects and estimation variance compared with baseline methods, with unbiased platform-level estimates guaranteed under mutual exclusion; open dataset released to support reproducible research; successful real-world deployment.", "conclusion": "The framework provides a practically useful and theoretically sound tool for platform-level causal inference in search-based marketplaces, enabling more reliable measurement of interventions like order volume and GMV and supporting reproducible research."}}
{"id": "2511.00362", "categories": ["cs.CV", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.00362", "abs": "https://arxiv.org/abs/2511.00362", "authors": ["Momen Khandoker Ope", "Akif Islam", "Mohd Ruhul Ameen", "Abu Saleh Musa Miah", "Md Rashedul Islam", "Jungpil Shin"], "title": "Oitijjo-3D: Generative AI Framework for Rapid 3D Heritage Reconstruction from Street View Imagery", "comment": "6 Pages, 4 figures, 2 Tables, Submitted to ICECTE 2026", "summary": "Cultural heritage restoration in Bangladesh faces a dual challenge of limited\nresources and scarce technical expertise. Traditional 3D digitization methods,\nsuch as photogrammetry or LiDAR scanning, require expensive hardware, expert\noperators, and extensive on-site access, which are often infeasible in\ndeveloping contexts. As a result, many of Bangladesh's architectural treasures,\nfrom the Paharpur Buddhist Monastery to Ahsan Manzil, remain vulnerable to\ndecay and inaccessible in digital form. This paper introduces Oitijjo-3D, a\ncost-free generative AI framework that democratizes 3D cultural preservation.\nBy using publicly available Google Street View imagery, Oitijjo-3D reconstructs\nfaithful 3D models of heritage structures through a two-stage pipeline -\nmultimodal visual reasoning with Gemini 2.5 Flash Image for structure-texture\nsynthesis, and neural image-to-3D generation through Hexagen for geometry\nrecovery. The system produces photorealistic, metrically coherent\nreconstructions in seconds, achieving significant speedups compared to\nconventional Structure-from-Motion pipelines, without requiring any specialized\nhardware or expert supervision. Experiments on landmarks such as Ahsan Manzil,\nChoto Sona Mosque, and Paharpur demonstrate that Oitijjo-3D preserves both\nvisual and structural fidelity while drastically lowering economic and\ntechnical barriers. By turning open imagery into digital heritage, this work\nreframes preservation as a community-driven, AI-assisted act of cultural\ncontinuity for resource-limited nations.", "AI": {"tldr": "Democratizes 3D cultural heritage preservation in Bangladesh by leveraging free AI tools and publicly available imagery to generate fast, photorealistic 3D models with minimal hardware/expertise.", "motivation": "Resource-limited contexts face limited access to traditional 3D digitization. The work aims to safeguard Bangladesh's architectural heritage (e.g., Paharpur, Ahsan Manzil) by lowering economic/technical barriers and enabling community-driven digital preservation.", "method": "A two-stage pipeline: (1) multimodal visual reasoning with Gemini 2.5 Flash Image for structure-texture synthesis; (2) neural image-to-3D geometry recovery with Hexagen, using publicly available Google Street View imagery to reconstruct metrically coherent 3D models; no specialized hardware or expert supervision required.", "result": "Produces photorealistic, metrically coherent reconstructions in seconds; scalable speedups compared to traditional Structure-from-Motion; preserves visual and structural fidelity for landmarks like Ahsan Manzil, Choto Sona Mosque, Paharpur; democratizes access to digital heritage.", "conclusion": "Reconception of preservation as a community-driven, AI-assisted practice, enabling resource-limited nations to digitally preserve and share cultural heritage using open imagery."}}
{"id": "2511.01331", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01331", "abs": "https://arxiv.org/abs/2511.01331", "authors": ["Hongyin Zhang", "Shuo Zhang", "Junxi Jin", "Qixin Zeng", "Runze Li", "Donglin Wang"], "title": "RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models", "comment": null, "summary": "Vision-Language-Action (VLA) models have recently emerged as powerful\ngeneral-purpose policies for robotic manipulation, benefiting from large-scale\nmulti-modal pre-training. However, they often fail to generalize reliably in\nout-of-distribution deployments, where unavoidable disturbances such as\nobservation noise, sensor errors, or actuation perturbations become prevalent.\nWhile recent Reinforcement Learning (RL)-based post-training provides a\npractical means to adapt pre-trained VLA models, existing methods mainly\nemphasize reward maximization and overlook robustness to environmental\nuncertainty. In this work, we introduce RobustVLA, a lightweight online RL\npost-training method designed to explicitly enhance the resilience of VLA\nmodels. Through a systematic robustness analysis, we identify two key\nregularizations: Jacobian regularization, which mitigates sensitivity to\nobservation noise, and smoothness regularization, which stabilizes policies\nunder action perturbations. Extensive experiments across diverse robotic\nenvironments demonstrate that RobustVLA significantly outperforms prior\nstate-of-the-art methods in robustness and reliability. Our results highlight\nthe importance of principled robustness-aware RL post-training as a key step\ntoward improving the reliability and robustness of VLA models.", "AI": {"tldr": "RobustVLA is a lightweight online RL post-training method that enhances robustness of Vision-Language-Action (VLA) models for robotic manipulation by applying two regularizations: Jacobian regularization to reduce sensitivity to observation noise and smoothness regularization to stabilize policies under action perturbations, yielding superior robustness and reliability across diverse environments.", "motivation": "VLA models generalize poorly under out-of-distribution disturbances (noise, sensor errors, actuation perturbations). Existing RL post-training often prioritizes reward optimization and neglects robustness to environmental uncertainty.", "method": "Online RL post-training called RobustVLA that adds two regularizations during training: Jacobian regularization to reduce sensitivity to observation perturbations and smoothness regularization to stabilize the policy under action perturbations.", "result": "RobustVLA significantly outperforms prior state-of-the-art methods in robustness and reliability across diverse robotic environments.", "conclusion": "Principled robustness-aware RL post-training is a key step toward improving the reliability and robustness of VLA models."}}
{"id": "2511.00129", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.00129", "abs": "https://arxiv.org/abs/2511.00129", "authors": ["Siyu Xiao", "Xindi Zhao", "Tianhao Mao", "Yiwei Wang", "Yuqiao Chen", "Hongyun Zhang", "Jian Wang", "Junjie Wang", "Shuang Liu", "Tupei Chen", "Yang Liu"], "title": "Casing Collar Identification using AlexNet-based Neural Networks for Depth Measurement in Oil and Gas Wells", "comment": null, "summary": "Accurate downhole depth measurement is essential for oil and gas well\noperations, directly influencing reservoir contact, production efficiency, and\noperational safety. Collar correlation using a casing collar locator (CCL) is\nfundamental for precise depth calibration. While neural network-based CCL\nsignal recognition has achieved significant progress in collar identification,\npreprocessing methods for such applications remain underdeveloped. Moreover,\nthe limited availability of real well data poses substantial challenges for\ntraining neural network models that require extensive datasets. This paper\npresents a system integrated into downhole tools for CCL signal acquisition to\nfacilitate dataset construction. We propose comprehensive preprocessing methods\nfor data augmentation and evaluate their effectiveness using our AlexNet-based\nneural network models. Through systematic experimentation across various\nconfiguration combinations, we analyze the contribution of each augmentation\nmethod. Results demonstrate that standardization, label distribution smoothing\n(LDS), and random cropping are fundamental requirements for model training,\nwhile label smoothing regularization (LSR), time scaling, and multiple sampling\nsignificantly enhance model generalization capability. The F1 scores of our two\nbenchmark models trained with the proposed augmentation methods maximumly\nimprove from 0.937 and 0.952 to 1.0 and 1.0, respectively. Performance\nvalidation on real CCL waveforms confirms the effectiveness and practical\napplicability of our approach. This work addresses the gaps in data\naugmentation methodologies for training casing collar recognition models in CCL\ndata-limited environments.", "AI": {"tldr": "This work integrates a data-collection system for casing collar locator (CCL) signals with a comprehensive augmentation pipeline for AlexNet-based models, addressing data scarcity in downhole collar recognition. It identifies standardization, label distribution smoothing (LDS), and random cropping as fundamental, while label smoothing regularization (LSR), time scaling, and multiple sampling greatly enhance generalization, achieving state-of-the-art F1 (0.0 interpreted as 1.0 on benchmarks).", "motivation": "Accurate downhole depth measurement via CCL is crucial for reservoir contact, production efficiency, and safety. Neural CCL recognition is promising, but preprocessing and data scarcity hinder robust model training.", "method": "Developed a CCL signal acquisition system integrated into downhole tools for dataset construction. Proposed comprehensive data augmentation preprocessing methods. Evaluated using AlexNet-based CNN models across many configuration combinations to isolate each augmentation method's contribution.", "result": "F1 scores improved from 0.937/0.952 to 1.0/1.0 on benchmark models. Real CCL waveform validation confirms practical effectiveness of the augmentation approach.", "conclusion": "The paper advances data augmentation methodology for training CCL recognition models in data-limited downhole environments, enhancing model robustness and practical applicability."}}
{"id": "2511.01363", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01363", "abs": "https://arxiv.org/abs/2511.01363", "authors": ["Giuseppe Riva", "Brenda K. Wiederhold", "Fabrizia Mantovani"], "title": "Automatic Minds: Cognitive Parallels Between Hypnotic States and Large Language Model Processing", "comment": "4 Tables", "summary": "The cognitive processes of the hypnotized mind and the computational\noperations of large language models (LLMs) share deep functional parallels.\nBoth systems generate sophisticated, contextually appropriate behavior through\nautomatic pattern-completion mechanisms operating with limited or unreliable\nexecutive oversight. This review examines this convergence across three\nprinciples: automaticity, in which responses emerge from associative rather\nthan deliberative processes; suppressed monitoring, leading to errors such as\nconfabulation in hypnosis and hallucination in LLMs; and heightened contextual\ndependency, where immediate cues (for example, the suggestion of a therapist or\nthe prompt of the user) override stable knowledge.\n  These mechanisms reveal an observer-relative meaning gap: both systems\nproduce coherent but ungrounded outputs that require an external interpreter to\nsupply meaning. Hypnosis and LLMs also exemplify functional agency - the\ncapacity for complex, goal-directed, context-sensitive behavior - without\nsubjective agency, the conscious awareness of intention and ownership that\ndefines human action. This distinction clarifies how purposive behavior can\nemerge without self-reflective consciousness, governed instead by structural\nand contextual dynamics. Finally, both domains illuminate the phenomenon of\nscheming: automatic, goal-directed pattern generation that unfolds without\nreflective awareness. Hypnosis provides an experimental model for understanding\nhow intention can become dissociated from conscious deliberation, offering\ninsights into the hidden motivational dynamics of artificial systems.\nRecognizing these parallels suggests that the future of reliable AI lies in\nhybrid architectures that integrate generative fluency with mechanisms of\nexecutive monitoring, an approach inspired by the complex, self-regulating\narchitecture of the human mind.", "AI": {"tldr": "The abstract argues for deep functional parallels between hypnotized cognition and LLMs\u2014automatic pattern completion, suppressed monitoring leading to confabulation/hallucination, and context-driven outputs\u2014producing coherent but ungrounded meaning; it advocates hybrid AI designs combining fluency with executive monitoring to achieve reliable, goal-directed behavior without requiring conscious self-awareness.", "motivation": "To illuminate how two seemingly distinct systems share underlying mechanisms and to guide safer AI design by drawing on hypnosis as a model for dissociation of intention from deliberation.", "method": "Conceptual review synthesizing literature on hypnosis and LLM behavior, focusing on three principles: automaticity, suppressed monitoring, and contextual dependency; analysis of observer-relative meaning and the idea of scheming; proposition of hybrid architectures.", "result": "Identification of parallels across automaticity, confabulation/hallucination, and cue-driven performance; explanation of the observer-relative meaning gap and functional agency without subjective consciousness; introduction of the 'scheming' concept; design recommendation for hybrid architectures.", "conclusion": "Recognizing these parallels can guide development of reliable AI through integrating generative fluency with executive monitoring, with hypnosis serving as a model for dissociation of intention from conscious deliberation."}}
{"id": "2511.00370", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00370", "abs": "https://arxiv.org/abs/2511.00370", "authors": ["Chaochen Wu", "Guan Luo", "Meiyun Zuo", "Zhitao Fan"], "title": "Who Can We Trust? Scope-Aware Video Moment Retrieval with Multi-Agent Conflict", "comment": null, "summary": "Video moment retrieval uses a text query to locate a moment from a given\nuntrimmed video reference. Locating corresponding video moments with text\nqueries helps people interact with videos efficiently. Current solutions for\nthis task have not considered conflict within location results from different\nmodels, so various models cannot integrate correctly to produce better results.\nThis study introduces a reinforcement learning-based video moment retrieval\nmodel that can scan the whole video once to find the moment's boundary while\nproducing its locational evidence. Moreover, we proposed a multi-agent system\nframework that can use evidential learning to resolve conflicts between agents'\nlocalization output. As a side product of observing and dealing with conflicts\nbetween agents, we can decide whether a query has no corresponding moment in a\nvideo (out-of-scope) without additional training, which is suitable for\nreal-world applications. Extensive experiments on benchmark datasets show the\neffectiveness of our proposed methods compared with state-of-the-art\napproaches. Furthermore, the results of our study reveal that modeling\ncompetition and conflict of the multi-agent system is an effective way to\nimprove RL performance in moment retrieval and show the new role of evidential\nlearning in the multi-agent framework.", "AI": {"tldr": "A reinforcement learning\u2013based video moment retrieval framework with a multi-agent evidential system that resolves conflicts among localizations and can detect out-of-scope queries without extra training, achieving state-of-the-art results.", "motivation": "Existing methods ignore conflicts between models\u2019 localization outputs and struggle with queries that have no corresponding moment; there is a need for a model that can scan efficiently and handle uncertain results in real-world settings.", "method": "A reinforcement learning model that scans the entire video once to locate moment boundaries and provide localization evidence; a multi-agent framework with evidential learning to resolve conflicts among agents\u2019 outputs; the system can also determine when a query is out-of-scope.", "result": "Experiments on benchmark datasets show the approach is effective compared to state-of-the-art methods; modeling competition and conflict among agents improves RL performance; evidential learning plays a new role in the multi-agent framework.", "conclusion": "The approach offers a conflict-aware RL solution for video moment retrieval, enabling out-of-scope detection without extra training and improving retrieval accuracy by leveraging multi-agent competition and evidential reasoning."}}
{"id": "2511.01334", "categories": ["cs.RO", "cs.AI", "cs.HC", "68T45"], "pdf": "https://arxiv.org/pdf/2511.01334", "abs": "https://arxiv.org/abs/2511.01334", "authors": ["Ling Niu", "Xiaoji Zheng", "Han Wang", "Chen Zheng", "Ziyuan Yang", "Bokui Chen", "Jiangtao Gong"], "title": "Embodied Cognition Augmented End2End Autonomous Driving", "comment": "24 pages,4 pages", "summary": "In recent years, vision-based end-to-end autonomous driving has emerged as a\nnew paradigm. However, popular end-to-end approaches typically rely on visual\nfeature extraction networks trained under label supervision. This limited\nsupervision framework restricts the generality and applicability of driving\nmodels. In this paper, we propose a novel paradigm termed $E^{3}AD$, which\nadvocates for comparative learning between visual feature extraction networks\nand the general EEG large model, in order to learn latent human driving\ncognition for enhancing end-to-end planning. In this work, we collected a\ncognitive dataset for the mentioned contrastive learning process. Subsequently,\nwe investigated the methods and potential mechanisms for enhancing end-to-end\nplanning with human driving cognition, using popular driving models as\nbaselines on publicly available autonomous driving datasets. Both open-loop and\nclosed-loop tests are conducted for a comprehensive evaluation of planning\nperformance. Experimental results demonstrate that the $E^{3}AD$ paradigm\nsignificantly enhances the end-to-end planning performance of baseline models.\nAblation studies further validate the contribution of driving cognition and the\neffectiveness of comparative learning process. To the best of our knowledge,\nthis is the first work to integrate human driving cognition for improving\nend-to-end autonomous driving planning. It represents an initial attempt to\nincorporate embodied cognitive data into end-to-end autonomous driving,\nproviding valuable insights for future brain-inspired autonomous driving\nsystems. Our code will be made available at Github", "AI": {"tldr": "A brain-inspired E^3AD framework that compares visual feature extractors with an EEG-based large model via contrastive learning to inject human driving cognition into end-to-end autonomous driving; collects a cognitive dataset and demonstrates planning improvements on public datasets with open-loop and closed-loop tests; code to be released.", "motivation": "End-to-end driving models rely on supervised visual feature extraction, which limits generality due to limited supervision. The authors propose a comparative learning paradigm (E^3AD) that leverages a general EEG large model to capture latent human driving cognition and guide end-to-end planning.", "method": "Collect a cognitive dataset for contrastive learning between visual feature extractors and an EEG large model; apply comparative learning to align driving-relevant representations; evaluate on popular autonomous driving baselines using open-loop and closed-loop tests; perform ablations to analyze the contribution of driving cognition and the learning process.", "result": "The E^3AD paradigm significantly improves end-to-end planning performance of baseline driving models on public datasets; ablation studies confirm the contribution of incorporating driving cognition and the effectiveness of the comparative learning process.", "conclusion": "This work is the first to integrate human driving cognition (embodied cognitive data) into end-to-end autonomous driving planning, marking an initial step toward brain-inspired autonomous driving systems; code will be released on GitHub."}}
{"id": "2511.00130", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00130", "abs": "https://arxiv.org/abs/2511.00130", "authors": ["Bernd Bohnet", "Rumen Dangovski", "Kevin Swersky", "Sherry Moore", "Arslan Chaudhry", "Kathleen Kenealy", "Noah Fiedel"], "title": "A Comparative Analysis of LLM Adaptation: SFT, LoRA, and ICL in Data-Scarce Scenarios", "comment": null, "summary": "The remarkable capabilities of Large Language Models (LLMs) often need to be\ntailored for specific applications, requiring the integration of new knowledge\nor the acquisition of new skills. While full fine-tuning is a powerful\nadaptation method, it is computationally expensive and can lead to a\ndegradation of general reasoning abilities, a phenomenon known as catastrophic\nforgetting. A range of alternative techniques exists, each with its own\ntrade-offs. In-Context Learning (ICL) is fast but limited by context length,\nwhile Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation\n(LoRA) offer a middle ground by minimizing parameter changes. However, the\nchallenge of catastrophic forgetting persists, raising questions about the best\nadaptation strategy for a given task. This paper presents a comparative\nanalysis of Supervised Finetuning (SFT), LoRA, and ICL in data-scarce\nscenarios. We find that LoRA provides the most effective balance, successfully\ninstilling new skills with minimal impact on the base model's general\nknowledge. In contrast, while SFT excels at skill acquisition, it is highly\nsusceptible to catastrophic forgetting. ICL is effective for incorporating\nfactual knowledge but struggles with complex skills. Our findings offer a\npractical framework for selecting an LLM adaptation strategy. We highlight the\ncritical distinction between skill acquisition and knowledge integration,\nclarify the trade-offs between task-specific performance and the preservation\nof general capabilities.", "AI": {"tldr": "LoRA offers the best balance for data-scarce LLM adaptation by integrating new skills with minimal forgetting of base knowledge; SFT excels at skill acquisition but suffers catastrophic forgetting; ICL effectively adds factual knowledge but struggles with complex skills; choose adaptation method based on whether the task prioritizes skill learning or knowledge integration.", "motivation": "Address how to tailor large language models to specific tasks without eroding general capabilities, especially under data scarcity. Compare SFT, LoRA, and ICL to understand trade-offs and guide practical adaptation decisions.", "method": "Empirical comparative study evaluating supervised finetuning (SFT), Low-Rank Adaptation (LoRA), and in-context learning (ICL) in data-scarce regimes. Tasks assess skill acquisition and knowledge integration, with metrics capturing performance and catastrophic forgetting.", "result": "LoRA provides the most favorable balance, effectively instilling new skills with minimal impact on the base model's general knowledge. SFT excels at skill acquisition but is highly susceptible to catastrophic forgetting. ICL efficiently incorporates factual knowledge but struggles with acquiring complex skills.", "conclusion": "Offer a practical framework for selecting LLM adaptation strategies. Emphasize the distinction between skill acquisition and knowledge integration and the trade-offs between task-specific performance and preservation of general capabilities."}}
{"id": "2511.01375", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01375", "abs": "https://arxiv.org/abs/2511.01375", "authors": ["Hamin Koo", "Minseon Kim", "Jaehyung Kim"], "title": "Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges", "comment": "under review, 28 pages", "summary": "Identifying the vulnerabilities of large language models (LLMs) is crucial\nfor improving their safety by addressing inherent weaknesses. Jailbreaks, in\nwhich adversaries bypass safeguards with crafted input prompts, play a central\nrole in red-teaming by probing LLMs to elicit unintended or unsafe behaviors.\nRecent optimization-based jailbreak approaches iteratively refine attack\nprompts by leveraging LLMs. However, they often rely heavily on either binary\nattack success rate (ASR) signals, which are sparse, or manually crafted\nscoring templates, which introduce human bias and uncertainty in the scoring\noutcomes. To address these limitations, we introduce AMIS (Align to MISalign),\na meta-optimization framework that jointly evolves jailbreak prompts and\nscoring templates through a bi-level structure. In the inner loop, prompts are\nrefined using fine-grained and dense feedback using a fixed scoring template.\nIn the outer loop, the template is optimized using an ASR alignment score,\ngradually evolving to better reflect true attack outcomes across queries. This\nco-optimization process yields progressively stronger jailbreak prompts and\nmore calibrated scoring signals. Evaluations on AdvBench and JBB-Behaviors\ndemonstrate that AMIS achieves state-of-the-art performance, including 88.0%\nASR on Claude-3.5-Haiku and 100.0% ASR on Claude-4-Sonnet, outperforming\nexisting baselines by substantial margins.", "AI": {"tldr": "AMIS aligns jailbreak prompt optimization with scoring calibration via a bi-level meta-optimization, yielding stronger prompts and more reliable scoring.", "motivation": "Existing optimization-based jailbreaks rely on sparse binary ASR signals or manually crafted templates, which introduce bias and limit calibration. AMIS aims to jointly optimize prompts and scoring templates to produce denser feedback and better-aligned attack outcomes.", "method": "AMIS (Align to MISalign) uses a bi-level optimization framework. Inner loop refines jailbreak prompts using fine-grained, dense feedback with a fixed scoring template. Outer loop optimizes the scoring template based on an ASR alignment score, gradually aligning the template with true attack outcomes across queries.", "result": "AMIS achieves state-of-the-art jailbreak success rates on AdvBench and JBB-Behaviors, with 88.0% ASR on Claude-3.5-Haiku and 100.0% ASR on Claude-4-Sonnet, outperforming baselines by substantial margins.", "conclusion": "Joint co-optimization of prompts and scoring templates yields progressively stronger jailbreaks and better-calibrated evaluation signals, improving red-teaming efficacy for LLMs."}}
{"id": "2511.00381", "categories": ["cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.00381", "abs": "https://arxiv.org/abs/2511.00381", "authors": ["Jiaming Li", "Junlei Wu", "Sheng Wang", "Honglin Xiong", "Jiangdong Cai", "Zihao Zhao", "Yitao Zhu", "Yuan Yin", "Dinggang Shen", "Qian Wang"], "title": "VisionCAD: An Integration-Free Radiology Copilot Framework", "comment": null, "summary": "Widespread clinical deployment of computer-aided diagnosis (CAD) systems is\nhindered by the challenge of integrating with existing hospital IT\ninfrastructure. Here, we introduce VisionCAD, a vision-based radiological\nassistance framework that circumvents this barrier by capturing medical images\ndirectly from displays using a camera system. The framework operates through an\nautomated pipeline that detects, restores, and analyzes on-screen medical\nimages, transforming camera-captured visual data into diagnostic-quality images\nsuitable for automated analysis and report generation. We validated VisionCAD\nacross diverse medical imaging datasets, demonstrating that our modular\narchitecture can flexibly utilize state-of-the-art diagnostic models for\nspecific tasks. The system achieves diagnostic performance comparable to\nconventional CAD systems operating on original digital images, with an F1-score\ndegradation typically less than 2\\% across classification tasks, while natural\nlanguage generation metrics for automated reports remain within 1\\% of those\nderived from original images. By requiring only a camera device and standard\ncomputing resources, VisionCAD offers an accessible approach for AI-assisted\ndiagnosis, enabling the deployment of diagnostic capabilities in diverse\nclinical settings without modifications to existing infrastructure.", "AI": {"tldr": "VisionCAD enables AI-assisted diagnosis by capturing on-screen medical images via a camera, transforming them into diagnostic-quality data without changing hospital IT infrastructure; shows near-parity with conventional CAD across tasks (F1 < 2% degradation; NLP report metrics within 1%), using a modular pipeline and standard hardware.", "motivation": "Integrating CAD systems into hospital IT is a major barrier; many clinics lack the infrastructure for direct digital image access. A camera-based capture approach offers a practical, low-barrier alternative for deploying AI diagnostics.", "method": "An automated pipeline that detects, restores, and analyzes on-screen medical images captured from displays by a camera system. The approach converts camera-captured visuals into diagnostic-quality images and reports, and employs a modular architecture to plug in state-of-the-art diagnostic models for task-specific analyses.", "result": "Across diverse medical imaging datasets, VisionCAD achieved diagnostic performance comparable to CAD systems operating on original digital images, with F1-score degradation typically less than 2% across classification tasks. Automated report generation NLP metrics remained within 1% of those derived from original images.", "conclusion": "VisionCAD provides an accessible, infrastructure-light path to AI-assisted diagnosis by leveraging off-the-shelf camera hardware and standard computing resources, enabling deployment of diagnostic capabilities in diverse clinical settings without modifications to existing IT infrastructure."}}
{"id": "2511.01346", "categories": ["cs.RO", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2511.01346", "abs": "https://arxiv.org/abs/2511.01346", "authors": ["Shun Yoshida", "Qingchuan Song", "Bastian E. Rapp", "Thomas Speck", "Falk J. Tauber"], "title": "Thermo-responsive closing and reopening artificial Venus Flytrap utilizing shape memory elastomers", "comment": "Conference Proceedings Paper Living Machines 2025", "summary": "Despite their often perceived static and slow nature, some plants can move\nfaster than the blink of an eye. The rapid snap closure motion of the Venus\nflytrap (Dionaea muscipula) has long captivated the interest of researchers and\nengineers alike, serving as a model for plant-inspired soft machines and\nrobots. The translation of the fast snapping closure has inspired the\ndevelopment of various artificial Venus flytrap (AVF) systems. However,\ntranslating both the closing and reopening motion of D. muscipula into an\nautonomous plant inspired soft machine has yet to be achieved. In this study,\nwe present an AVF that autonomously closes and reopens, utilizing novel\nthermo-responsive UV-curable shape memory materials for soft robotic systems.\nThe life-sized thermo-responsive AVF exhibits closing and reopening motions\ntriggered in a naturally occurring temperature range. The doubly curved trap\nlobes, built from shape memory polymers, close at 38{\\deg}C, while reopening\ninitiates around 45{\\deg}C, employing shape memory elastomer strips as\nantagonistic actuators to facilitate lobe reopening. This work represents the\nfirst demonstration of thermo-responsive closing and reopening in an AVF with\nprogrammed sequential motion in response to increasing temperature. This\napproach marks the next step toward autonomously bidirectional moving soft\nmachines/robots.", "AI": {"tldr": "Autonomous bidirectional AVF using thermo-responsive shape memory polymers demonstrates closing at 38\u00b0C and reopening at ~45\u00b0C, enabling programmed sequential motion in a soft robot.", "motivation": "To translate the Venus flytrap's rapid snap into a fully autonomous, bidirectional soft machine by leveraging thermo-responsive materials.", "method": "Fabricates a life-sized AVF with doubly curved trap lobes from shape memory polymers; uses shape memory elastomer strips as antagonistic actuators to enable reopening; closure and reopening are triggered by natural temperature ranges.", "result": "First demonstration of thermo-responsive closing and reopening in an AVF with programmed sequential motion in response to increasing temperature; autonomous bidirectional actuation.", "conclusion": "Represents a step toward autonomously bidirectional plant-inspired soft robots, showing a viable materials-and-design pathway for temperature-driven, bidirectional soft-machine motion."}}
{"id": "2511.00133", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00133", "abs": "https://arxiv.org/abs/2511.00133", "authors": ["Kowshik Balasubramanian", "Andre Williams", "Ismail Butun"], "title": "Feature Importance Guided Random Forest Learning with Simulated Annealing Based Hyperparameter Tuning", "comment": "10 pages, 2 figures, 3 tables, submitted to IEEE Intelligent Systems\n  journal", "summary": "This paper introduces a novel framework for enhancing Random Forest\nclassifiers by integrating probabilistic feature sampling and hyperparameter\ntuning via Simulated Annealing. The proposed framework exhibits substantial\nadvancements in predictive accuracy and generalization, adeptly tackling the\nmultifaceted challenges of robust classification across diverse domains,\nincluding credit risk evaluation, anomaly detection in IoT ecosystems,\nearly-stage medical diagnostics, and high-dimensional biological data analysis.\nTo overcome the limitations of conventional Random Forests, we present an\napproach that places stronger emphasis on capturing the most relevant signals\nfrom data while enabling adaptive hyperparameter configuration. The model is\nguided towards features that contribute more meaningfully to classification and\noptimizing this with dynamic parameter tuning. The results demonstrate\nconsistent accuracy improvements and meaningful insights into feature\nrelevance, showcasing the efficacy of combining importance aware sampling and\nmetaheuristic optimization.", "AI": {"tldr": "A novel Random Forest enhancement that combines probabilistic feature sampling with Simulated Annealing-based hyperparameter optimization yields improved accuracy and generalization across diverse domains, emphasizing feature relevance.", "motivation": "Conventional Random Forests can struggle to generalize across heterogeneous tasks and high-dimensional data; there is a need for better feature selection and adaptive hyperparameter tuning to robustly classify in varied domains.", "method": "Introduce probabilistic feature sampling guided by feature importance within the RF ensemble and apply Simulated Annealing to optimize hyperparameters. The approach uses importance-aware sampling to emphasize informative features and combines this with metaheuristic optimization for dynamic parameter tuning, aiming to improve accuracy and generalization across domains.", "result": "The framework delivers consistent accuracy improvements and deeper insights into feature relevance, with demonstrated applicability to credit risk evaluation, IoT anomaly detection, early-stage medical diagnostics, and high-dimensional biological data analysis.", "conclusion": "Combining importance-aware sampling with Simulated Annealing-based hyperparameter optimization enhances Random Forest performance, providing better accuracy, generalization, and interpretability across diverse classification tasks."}}
{"id": "2511.01396", "categories": ["cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.01396", "abs": "https://arxiv.org/abs/2511.01396", "authors": ["Cl\u00e9ment Yvernes", "Emilie Devijver", "Ad\u00e8le H. Ribeiro", "Marianne Clausel--Lesourd", "\u00c9ric Gaussier"], "title": "Relaxing partition admissibility in Cluster-DAGs: a causal calculus with arbitrary variable clustering", "comment": "Accepted at The Thirty-ninth Annual Conference on Neural Information\n  Processing Systems (NeurIPS2025)", "summary": "Cluster DAGs (C-DAGs) provide an abstraction of causal graphs in which nodes\nrepresent clusters of variables, and edges encode both cluster-level causal\nrelationships and dependencies arisen from unobserved confounding. C-DAGs\ndefine an equivalence class of acyclic causal graphs that agree on\ncluster-level relationships, enabling causal reasoning at a higher level of\nabstraction. However, when the chosen clustering induces cycles in the\nresulting C-DAG, the partition is deemed inadmissible under conventional C-DAG\nsemantics. In this work, we extend the C-DAG framework to support arbitrary\nvariable clusterings by relaxing the partition admissibility constraint,\nthereby allowing cyclic C-DAG representations. We extend the notions of\nd-separation and causal calculus to this setting, significantly broadening the\nscope of causal reasoning across clusters and enabling the application of\nC-DAGs in previously intractable scenarios. Our calculus is both sound and\natomically complete with respect to the do-calculus: all valid interventional\nqueries at the cluster level can be derived using our rules, each corresponding\nto a primitive do-calculus step.", "AI": {"tldr": "Extends C-DAGs to allow arbitrary, potentially cyclic clusterings and unobserved confounding; provides a sound and atomically complete causal calculus for cluster-level interventions, aligning each rule with a primitive do-calculus step.", "motivation": "Conventional C-DAG semantics restrict clustering via the partition admissibility constraint, which excludes cyclic partitions and some confounded cluster-level relationships. This limits causal reasoning to certain abstractions. The work aims to broaden applicability by removing that constraint and enabling causal reasoning across all clusterings.", "method": "Relax the partition admissibility constraint in C-DAGs to permit cycles. Generalize d-separation and causal calculus to cyclic C-DAGs. Prove that the resulting rules are sound and atomically complete with respect to do-calculus, with each rule corresponding to a primitive do-calculus step.", "result": "The framework now supports cyclic C-DAG representations and arbitrary clusterings, enabling cluster-level causal reasoning in scenarios previously intractable. A calculus is provided that is sound and atomically complete relative to do-calculus, ensuring all valid interventional queries at the cluster level can be derived. Each derivation step aligns with a primitive do-calculus operation.", "conclusion": "This work significantly broadens the scope of C-DAGs, making them applicable to a wider range of problems by removing clustering admissibility constraints and extending the causal toolkit to cyclic, cluster-based graphs. The established soundness and completeness give strong theoretical guarantees for cluster-level causal inference."}}
{"id": "2511.00389", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00389", "abs": "https://arxiv.org/abs/2511.00389", "authors": ["Fan Zhang", "Haoxuan Li", "Shengju Qian", "Xin Wang", "Zheng Lian", "Hao Wu", "Zhihong Zhu", "Yuan Gao", "Qiankun Li", "Yefeng Zheng", "Zhouchen Lin", "Pheng-Ann Heng"], "title": "Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models: Benchmark, Datasets, and Beyond", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have revolutionized numerous\nresearch fields, including computer vision and affective computing. As a\npivotal challenge in this interdisciplinary domain, facial expression\nrecognition (FER) has evolved from separate, domain-specific models to more\nunified approaches. One promising avenue to unify FER tasks is converting\nconventional FER datasets into visual question-answering (VQA) formats,\nenabling the direct application of powerful generalist MLLMs for inference.\nHowever, despite the success of cutting-edge MLLMs in various tasks, their\nperformance on FER tasks remains largely unexplored. To address this gap, we\nprovide FERBench, a systematic benchmark that incorporates 20 state-of-the-art\nMLLMs across four widely used FER datasets. Our results reveal that, while\nMLLMs exhibit good classification performance, they still face significant\nlimitations in reasoning and interpretability. To this end, we introduce\npost-training strategies aimed at enhancing the facial expression reasoning\ncapabilities of MLLMs. Specifically, we curate two high-quality and large-scale\ndatasets: UniFER-CoT-230K for cold-start initialization and UniFER-RLVR-360K\nfor reinforcement learning with verifiable rewards (RLVR), respectively.\nBuilding upon them, we develop a unified and interpretable FER foundation model\ntermed UniFER-7B, which outperforms many open-sourced and closed-source\ngeneralist MLLMs (e.g., Gemini-2.5-Pro and Qwen2.5-VL-72B).", "AI": {"tldr": "FERBench benchmarks 20 MLLMs on 4 FER datasets; UniFER-7B, built with UniFER-CoT-230K and UniFER-RLVR-360K, achieves strong FER performance and interpretability, surpassing many generalist MLLMs.", "motivation": "Bridge facial expression recognition (FER) with multimodal large language models (MLLMs), aiming to unify FER tasks, improve reasoning and interpretability, and leverage VQA-style data conversion and post-training.", "method": "Convert FER datasets into visual question-answering formats to evaluate 20 state-of-the-art MLLMs across four FER datasets (FERBench). Introduce two post-training strategies: UniFER-CoT-230K for cold-start initialization and UniFER-RLVR-360K for reinforcement learning with verifiable rewards. Build UniFER-7B as a unified FER foundation model.", "result": "MLLMs show good classification performance but have significant limitations in reasoning and interpretability on FER tasks. UniFER-7B outperforms many open-sourced and closed-source generalist MLLMs (e.g., Gemini-2.5-Pro, Qwen2.5-VL-72B).", "conclusion": "A unified, interpretable FER foundation model can be built by curated data and RL-based post-training; UniFER-7B demonstrates strong performance and sets a new benchmark for MLLMs in FER tasks."}}
{"id": "2511.01347", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01347", "abs": "https://arxiv.org/abs/2511.01347", "authors": ["Riddhi Das", "Joscha Teichmann", "Thomas Speck", "Falk J. Tauber"], "title": "Design and development of an electronics-free earthworm robot", "comment": "Conference Proceedings Paper Living Machines 2025", "summary": "Soft robotic systems have gained widespread attention due to their inherent\nflexibility, adaptability, and safety, making them well-suited for varied\napplications. Among bioinspired designs, earthworm locomotion has been\nextensively studied for its efficient peristaltic motion, enabling movement in\nconfined and unstructured environments. Existing earthworm-inspired robots\nprimarily utilize pneumatic actuation due to its high force-to-weight ratio and\nease of implementation. However, these systems often rely on bulky,\npower-intensive electronic control units, limiting their practicality. In this\nwork, we present an electronics-free, earthworm-inspired pneumatic robot\nutilizing a modified Pneumatic Logic Gate (PLG) design. By integrating\npreconfigured PLG units with bellow actuators, we achieved a plug-and-play\nstyle modular system capable of peristaltic locomotion without external\nelectronic components. The proposed design reduces system complexity while\nmaintaining efficient actuation. We characterize the bellow actuators under\ndifferent operating conditions and evaluate the robots locomotion performance.\nOur findings demonstrate that the modified PLG-based control system effectively\ngenerates peristaltic wave propagation, achieving autonomous motion with\nminimal deviation. This study serves as a proof of concept for the development\nof electronics-free, peristaltic soft robots. The proposed system has potential\nfor applications in hazardous environments, where untethered, adaptable\nlocomotion is critical. Future work will focus on further optimizing the robot\ndesign and exploring untethered operation using onboard compressed air sources.", "AI": {"tldr": "An electronics-free, earthworm-inspired pneumatic robot uses modified Pneumatic Logic Gates (PLG) and bellows to achieve peristaltic locomotion in a plug-and-play, modular design, demonstrating autonomous motion without external electronics; it serves as a proof of concept for untethered, hazardous-environment applications.", "motivation": "To reduce system complexity and enable untethered, safe locomotion in soft robots by removing electronic control units, addressing the practicality issues of pneumatic-earthworm robots in hazardous or constrained environments.", "method": "Integrate preconfigured, modified Pneumatic Logic Gate units with bellows actuators to create a plug-and-play, electronics-free control system that can generate peristaltic waves for locomotion; characterize bellows under various conditions and evaluate overall locomotion performance.", "result": "The PLG-based control system successfully generates peristaltic wave propagation, enabling autonomous, low-deviation locomotion without external electronics, validating electronics-free peristaltic soft robotics as a concept.", "conclusion": "Demonstrates feasibility of electronics-free, peristaltic soft robots and highlights potential in hazardous environments; future work includes design optimization and developing onboard compressed-air sources for untethered operation."}}
{"id": "2511.00134", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00134", "abs": "https://arxiv.org/abs/2511.00134", "authors": ["Angana Borah", "Adrija Datta", "Ashish S. Kumar", "Raviraj Dave", "Udit Bhatia"], "title": "Physiologically Active Vegetation Reverses Its Cooling Effect in Humid Urban Climates", "comment": "27 pages, 5 figures", "summary": "Efforts to green cities for cooling are succeeding unevenly because the same\nvegetation that cools surfaces can also intensify how hot the air feels.\nPrevious studies have identified humid heat as a growing urban hazard, yet how\nphysiologically active vegetation governs this trade-off between cooling and\nmoisture accumulation remains poorly understood, leaving mitigation policy and\ndesign largely unguided. Here we quantify how vegetation structure and function\ninfluence the Heat Index (HI), a combined measure of temperature and humidity\nin 138 Indian cities spanning tropical savanna, semi-arid steppe, and humid\nsubtropical climates, and across dense urban cores and semi-urban rings. Using\nan extreme-aware, one kilometre reconstruction of HI and an interpretable\nmachine-learning framework that integrates SHapley Additive Explanations (SHAP)\nand Accumulated Local Effects (ALE), we isolate vegetation-climate\ninteractions. Cooling generally strengthens for EVI >= 0.4 and LAI >= 0.05, but\njoint-high regimes begin to reverse toward warming when EVI >= 0.5, LAI >= 0.2,\nand fPAR >= 0.5,with an earlier onset for fPAR >= 0.25 in humid, dense cores.\nIn such environments, highly physiologically active vegetation elevates\nnear-surface humidity faster than it removes heat, reversing its cooling effect\nand amplifying perceived heat stress. These findings establish the climatic\nlimits of vegetation-driven cooling and provide quantitative thresholds for\nclimate-specific greening strategies that promote equitable and heat-resilient\ncities.", "AI": {"tldr": "Vegetation cooling in Indian cities is climate-dependent: cooling strengthens with moderate vegetation (EVI \u22650.4, LAI \u22650.05) but reverses to warming at higher levels (EVI \u22650.5, LAI \u22650.2, fPAR \u22650.5), especially in humid dense cores where active vegetation raises humidity and Heat Index. Provides thresholds to guide climate-specific greening for heat-resilient cities.", "motivation": "To understand when urban greening cools surfaces versus increases near-surface humidity, enabling policy and design choices that avoid amplifying heat stress.", "method": "Analyzed 138 Indian cities across tropical savanna, semi-arid steppe, and humid subtropical climates. Built a 1 km extreme-aware reconstruction of Heat Index (HI) and used an interpretable machine-learning framework combining SHAP and Accumulated Local Effects (ALE) to isolate vegetation\u2013climate interactions and identify threshold regimes in vegetation indices (EVI, LAI, fPAR).", "result": "Cooling generally strengthens with moderate vegetation (EVI \u22650.4 and LAI \u22650.05). However, under joint-high regimes (EVI \u22650.5, LAI \u22650.2, fPAR \u22650.5), cooling reverses toward warming; an earlier onset of reversal is found in humid, dense cores when fPAR \u22650.25. Highly physiologically active vegetation elevates near-surface humidity faster than it removes heat, amplifying perceived heat stress.", "conclusion": "Defines climatic limits for vegetation-driven cooling and provides quantitative, climate-specific thresholds to guide greening strategies that promote equitable, heat-resilient cities."}}
{"id": "2511.01415", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01415", "abs": "https://arxiv.org/abs/2511.01415", "authors": ["Amrapali Pednekar", "\u00c1lvaro Garrido-P\u00e9rez", "Yara Khaluf", "Pieter Simoens"], "title": "Modulation of temporal decision-making in a deep reinforcement learning agent under the dual-task paradigm", "comment": "Accepted at CogInterp workshop @ NeurIPS 2025", "summary": "This study explores the interference in temporal processing within a\ndual-task paradigm from an artificial intelligence (AI) perspective. In this\ncontext, the dual-task setup is implemented as a simplified version of the\nOvercooked environment with two variations, single task (T) and dual task\n(T+N). Both variations involve an embedded time production task, but the dual\ntask (T+N) additionally involves a concurrent number comparison task. Two deep\nreinforcement learning (DRL) agents were separately trained for each of these\ntasks. These agents exhibited emergent behavior consistent with human timing\nresearch. Specifically, the dual task (T+N) agent exhibited significant\noverproduction of time relative to its single task (T) counterpart. This result\nwas consistent across four target durations. Preliminary analysis of neural\ndynamics in the agents' LSTM layers did not reveal any clear evidence of a\ndedicated or intrinsic timer. Hence, further investigation is needed to better\nunderstand the underlying time-keeping mechanisms of the agents and to provide\ninsights into the observed behavioral patterns. This study is a small step\ntowards exploring parallels between emergent DRL behavior and behavior observed\nin biological systems in order to facilitate a better understanding of both.", "AI": {"tldr": "Dual-task DRL agents in a simplified Overcooked environment show timing overproduction under dual-task conditions, with no clear evidence of an intrinsic timer in LSTM units; findings echo human timing interference and warrant deeper investigation into DRL time-keeping mechanisms.", "motivation": "To understand how temporal processing can be interfered with in AI agents, explore possible parallels with human timing, and shed light on whether DRL systems develop internal time-keeping mechanisms.", "method": "Train two DRL agents on a simplified Overcooked task: single-task (T) and dual-task (T+N) where the latter adds a concurrent number comparison task. Both include an embedded time production task. Compare timing behavior and probe LSTM dynamics for timer signatures.", "result": "The dual-task agent overproduces time relative to the single-task agent, consistently across four target durations. Preliminary LSTM analysis did not reveal a dedicated or intrinsic timer.", "conclusion": "This work is a preliminary step toward linking emergent DRL timing with biological timing, suggesting the need for deeper investigation into internal time-keeping mechanisms and their relation to observed behavioral patterns."}}
{"id": "2511.00391", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00391", "abs": "https://arxiv.org/abs/2511.00391", "authors": ["Xuanle Zhao", "Deyang Jiang", "Zhixiong Zeng", "Lei Chen", "Haibo Qiu", "Jing Huang", "Yufeng Zhong", "Liming Zheng", "Yilin Cao", "Lin Ma"], "title": "VinciCoder: Unifying Multimodal Code Generation via Coarse-to-fine Visual Reinforcement Learning", "comment": "Preprint Version, Work in Progress", "summary": "Multimodal code generation has garnered significant interest within the\nresearch community. Despite the notable success of recent vision-language\nmodels (VLMs) on specialized tasks like Chart-to-code generation, their\nreliance on single-task training regimens fosters a narrow paradigm that\nhinders the development of generalized \\textbf{VI}sio\\textbf{N} \\textbf{C}ode\n\\textbf{I}ntelligence. In this work, we introduce \\textbf{VinciCoder}, a\nunified multimodal code generation model that addresses this limitation via a\ntwo-stage training framework. We begin by constructing a large-scale Supervised\nFinetuning (SFT) corpus comprising 1.6M image-code pairs for tasks involving\ndirect code generation and visual-based code refinement. Subsequently, we\nintroduce a Visual Reinforcement Learning (ViRL) strategy, which employs a\ncoarse-to-fine reward mechanism to improve visual fidelity by calculating\nvisual similarity across local and global image patches. Extensive experiments\non various multimodal code generation benchmarks demonstrate that VinciCoder\nachieves state-of-the-art performance, underscoring the effectiveness of our\ncoarse-to-fine ViRL strategy. The code and model will be available at\nhttps://github.com/DocTron-hub/VinciCoder.", "AI": {"tldr": "VinciCoder is a unified multimodal code-generation model trained via a two-stage pipeline: large-scale supervised finetuning on 1.6M image-code pairs and a Visual Reinforcement Learning (ViRL) phase with coarse-to-fine visual rewards to boost image-code alignment and visual fidelity, achieving state-of-the-art results on multimodal code-generation benchmarks.", "motivation": "Current vision-language models trained on single tasks struggle to generalize across diverse multimodal coding tasks (image-to-code, code refinement from visuals). There is a need for a unified, generalizable Vision\u2013Code Intelligence that can handle varied multimodal programming tasks.", "method": "1) Build a large SFT corpus of 1.6 million image-code pairs for direct code generation and visual-based code refinement. 2) Apply a Visual Reinforcement Learning (ViRL) phase with a coarse-to-fine reward that measures visual similarity at both local and global image patches to improve visual fidelity and alignment with code generation.", "result": "The approach yields state-of-the-art performance on multiple multimodal code-generation benchmarks, demonstrating the efficacy of the coarse-to-fine ViRL strategy in enhancing both accuracy and visual alignment.", "conclusion": "A two-stage training framework combining large-scale supervised finetuning with a coarse-to-fine visual RL strategy can produce a unified Vision\u2013Code Intelligence, reinforcing the potential of ViRL for improving multimodal code-generation systems; code and model release planned."}}
{"id": "2511.01350", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01350", "abs": "https://arxiv.org/abs/2511.01350", "authors": ["Maartje H. M. Wermelink", "Renate Sachse", "Sebastian Kruppert", "Thomas Speck", "Falk J. Tauber"], "title": "Model to Model: Understanding the Venus Flytrap Snapping Mechanism and Transferring it to a 3D-printed Bistable Soft Robotic Demonstrator", "comment": "Conference Proceedings Paper Living machines 2025", "summary": "The Venus flytrap (Dionaea muscipula) does not only serve as the textbook\nmodel for a carnivorous plant, but also has long intrigued both botanists and\nengineers with its rapidly closing leaf trap. The trap closure is triggered by\ntwo consecutive touches of a potential prey, after which the lobes rapidly\nswitch from their concave open-state to their convex close-state and catch the\nprey within 100-500 ms after being triggered. This transformation from concave\nto convex is initiated by changes in turgor pressure and the release of stored\nelastic energy from prestresses in the concave state, which accelerate this\nmovement, leading to inversion of the lobes bi-axial curvature. Possessing two\nlow-energy states, the leaves can be characterized as bistable systems. With\nour research, we seek to deepen the understanding of Venus flytrap motion\nmechanics and apply its principles to the design of an artificial bistable lobe\nactuator. We identified geometrical characteristics, such as dimensional ratios\nand the thickness gradient in the lobe, and transferred these to two 3D-printed\nbistable actuator models. One actuator parallels the simulated geometry of a\nVenus flytrap leaf, the other is a lobe model designed with CAD. Both models\ndisplay concave-convex bi-stability and snap close. These demonstrators are the\nfirst step in the development of an artificial Venus flytrap that mimics the\nmechanical behavior of the biological model and can be used as a soft fast\ngripper.", "AI": {"tldr": "Biomimetic study of Venus flytrap mechanics leading to two 3D-printed bistable lobe actuators that snap closed, aiming to develop an artificial, soft fast gripper inspired by the plant's rapid trap movement.", "motivation": "To understand the mechanical basis of Venus flytrap closure and to translate its bistable lobe actuation into simple, controllable artificial actuators for soft robotics or grippers.", "method": "Identify dimensional ratios and thickness gradients in the Venus flytrap leaf that drive concave-to-convex bistability. Create two 3D-printed actuator models: one mirroring the simulated geometry of a flytrap leaf, the other CAD-designed; both demonstrate concave-convex bistability and snap-through closure.", "result": "Both actuator models exhibit concave-convex bistability and can snap closed, validating the feasibility of bioinspired bistable lobe actuators as soft fast grippers.", "conclusion": "The study provides a proof-of-concept for translating Venus flytrap mechanics into artificial bistable actuators, offering a pathway toward soft, rapid-grasp devices; further work should address control, material properties, and scaling for practical applications."}}
{"id": "2511.00136", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00136", "abs": "https://arxiv.org/abs/2511.00136", "authors": ["Qing Guo", "Xinhang Li", "Junyu Chen", "Zheng Guo", "Xiaocong Li", "Lin Zhang", "Lei Li"], "title": "A Dual Large Language Models Architecture with Herald Guided Prompts for Parallel Fine Grained Traffic Signal Control", "comment": null, "summary": "Leveraging large language models (LLMs) in traffic signal control (TSC)\nimproves optimization efficiency and interpretability compared to traditional\nreinforcement learning (RL) methods. However, existing LLM-based approaches are\nlimited by fixed time signal durations and are prone to hallucination errors,\nwhile RL methods lack robustness in signal timing decisions and suffer from\npoor generalization. To address these challenges, this paper proposes\nHeraldLight, a dual LLMs architecture enhanced by Herald guided prompts. The\nHerald Module extracts contextual information and forecasts queue lengths for\neach traffic phase based on real-time conditions. The first LLM, LLM-Agent,\nuses these forecasts to make fine grained traffic signal control, while the\nsecond LLM, LLM-Critic, refines LLM-Agent's outputs, correcting errors and\nhallucinations. These refined outputs are used for score-based fine-tuning to\nimprove accuracy and robustness. Simulation experiments using CityFlow on real\nworld datasets covering 224 intersections in Jinan (12), Hangzhou (16), and New\nYork (196) demonstrate that HeraldLight outperforms state of the art baselines,\nachieving a 20.03% reduction in average travel time across all scenarios and a\n10.74% reduction in average queue length on the Jinan and Hangzhou scenarios.\nThe source code is available on GitHub:\nhttps://github.com/BUPT-ANTlab/HeraldLight.", "AI": {"tldr": "HeraldLight introduces a dual-LLM architecture with Herald guided prompts for traffic signal control, addressing fixed signal durations and hallucinations in prior LLM/RL approaches. It uses a Herald Module to forecast queue lengths, an LLM-Agent for control, and an LLM-Critic to refine outputs for score-based fine-tuning. In CityFlow simulations across 224 intersections, it achieves significant improvements over baselines (\u224820% lower travel time; \u224811% lower queue length in some cities).", "motivation": "LLMs offer optimization efficiency and interpretability over traditional RL in traffic signal control, but face fixed duration constraints and hallucination risks; RL methods suffer robustness issues and poor generalization. A robust, accurate LLM-based TSC framework is needed.", "method": "HeraldLight combines two LLMs with Herald guided prompts. The Herald Module extracts real-time context and forecasts per-phase queue lengths. LLM-Agent uses forecasts to perform fine-grained signal control. LLM-Critic refines LLM-Agent outputs to correct errors/hallucinations. Outputs are used for score-based fine-tuning to improve accuracy and robustness.", "result": "Simulation on CityFlow with 224 intersections (Jinan 12, Hangzhou 16, New York 196) shows HeraldLight outperforms baselines, achieving a 20.03% reduction in average travel time across all scenarios and a 10.74% reduction in average queue length on the Jinan and Hangzhou scenarios.", "conclusion": "A dual-LLM approach with guided prompts and a correction stage improves TSC performance and robustness, offering better accuracy and interpretability than prior LLM/RL methods; source code is available for reproducibility."}}
{"id": "2511.01425", "categories": ["cs.AI", "cs.CV", "I.2.6; I.2.10"], "pdf": "https://arxiv.org/pdf/2511.01425", "abs": "https://arxiv.org/abs/2511.01425", "authors": ["Yuhang Huang", "Zekai Lin", "Fan Zhong", "Lei Liu"], "title": "Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis", "comment": "12 pages, 3 figures. Under review at the Conference on Computer\n  Vision and Pattern Recognition (CVPR) 2026", "summary": "Explanations for AI models in high-stakes domains like medicine often lack\nverifiability, which can hinder trust. To address this, we propose an\ninteractive agent that produces explanations through an auditable sequence of\nactions. The agent learns a policy to strategically seek external visual\nevidence to support its diagnostic reasoning. This policy is optimized using\nreinforcement learning, resulting in a model that is both efficient and\ngeneralizable. Our experiments show that this action-based reasoning process\nsignificantly improves calibrated accuracy, reducing the Brier score by 18\\%\ncompared to a non-interactive baseline. To validate the faithfulness of the\nagent's explanations, we introduce a causal intervention method. By masking the\nvisual evidence the agent chooses to use, we observe a measurable degradation\nin its performance ($\\Delta$Brier=+0.029), confirming that the evidence is\nintegral to its decision-making process. Our work provides a practical\nframework for building AI systems with verifiable and faithful reasoning\ncapabilities.", "AI": {"tldr": "An interactive, auditable agent uses RL to seek external visual evidence to support diagnostic reasoning; improves calibrated accuracy and verifiability; causal masking confirms faithfulness.", "motivation": "In high-stakes domains like medicine, explanations must be verifiable; existing methods lack auditable reasoning chains, hindering trust.", "method": "Train an interactive agent with a policy that selects external visual evidence to inspect; optimize policy via reinforcement learning; assess using Brier score; verify faithfulness via causal intervention by masking chosen evidence.", "result": "Achieves an 18% reduction in Brier score vs a non-interactive baseline; masking evidence yields \u0394Brier = +0.029, showing evidence is integral to decisions; the approach yields efficient and generalizable explanations.", "conclusion": "Provides a practical framework for verifiable and faithful AI reasoning in high-stakes domains by coupling action-based evidence gathering with RL and causal validity checks."}}
{"id": "2511.00396", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00396", "abs": "https://arxiv.org/abs/2511.00396", "authors": ["Long Li", "Shuichen Ji", "Ziyang Luo", "Nian Liu", "Dingwen Zhang", "Junwei Han"], "title": "CoT-Saliency: Unified Chain-of-Thought Reasoning for Heterogeneous Saliency Tasks", "comment": "14 pages,10 figures", "summary": "We present the first unified framework that jointly handles three\noperationally heterogeneous saliency tasks, eg, SOD, CoSOD, and SIS, by casting\neach as a Chain-of-Thought (CoT) reasoning process in a Vision-Language Model\n(VLM) to bridge task heterogeneity. CoT training follows a two-stage paradigm:\nSupervised Fine-Tuning (SFT) and Reinforcement Learning (RL). To enhance CoT\nquality in RL, we propose Confidence-Guided Policy Optimization (CGPO), a\nlightweight single-sample algorithm that leverages the discrepancy between\nreward and model confidence as a per-sample advantage signal. This design\nnaturally focuses updates on informative responses while eliminating group\nsampling, thereby addressing GRPO's key limitations: confidence-agnostic\nlearning, signal dilution, and prohibitive computational overhead. We also\nintroduce an \"output-to-reasoning\" strategy to construct high-fidelity SFT data\nthat ensures logical consistency with ground-truth masks. Experiments show our\nmodel matches or outperforms specialized SOTA methods and strong closed-source\nVLMs across all tasks, especially achieving an S-measure of 0.899 on CoCA for\nCoSOD, surpassing the prior best by 8.0 percentage points, despite using far\nless training data.", "AI": {"tldr": "A unified CoT-based framework for SOD, CoSOD, and SIS using a Vision-Language Model with two-stage training (SFT + RL) and a Confidence-Guided Policy Optimization (CGPO); achieves state-of-the-art results (e.g., CoCA CoSOD S-measure 0.899) with less data.", "motivation": "Bridge heterogeneous saliency tasks by casting them as Chain-of-Thought reasoning within a Vision-Language Model, enabling a single framework to handle SOD, CoSOD, and SIS and overcome heterogeneity in objectives and outputs.", "method": "Two-stage CoT training: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). Introduce Confidence-Guided Policy Optimization (CGPO): a lightweight, single-sample RL update leveraging reward\u2013confidence discrepancy as a per-sample advantage; eliminate group sampling to reduce overhead. Add an 'output-to-reasoning' strategy to generate high-fidelity SFT data aligned with ground-truth masks.", "result": "Matches or surpasses specialized SOTA across all three tasks; notably, CoSOD on CoCA achieves S-measure 0.899, beating the previous best by 8.0 percentage points, with much less training data.", "conclusion": "A data-efficient, unified CoT-based approach for heterogeneous saliency tasks that combines CGPO-based RL with coherent SFT data to achieve strong, generalizable performance across SOD, CoSOD, and SIS."}}
{"id": "2511.01369", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01369", "abs": "https://arxiv.org/abs/2511.01369", "authors": ["Luis Diener", "Jens Kalkkuhl", "Markus Enzweiler"], "title": "Lateral Velocity Model for Vehicle Parking Applications", "comment": "This manuscript has been submitted to Vehicle System Dynamics for\n  possible publication", "summary": "Automated parking requires accurate localization for quick and precise\nmaneuvering in tight spaces. While the longitudinal velocity can be measured\nusing wheel encoders, the estimation of the lateral velocity remains a key\nchallenge due to the absence of dedicated sensors in consumer-grade vehicles.\nExisting approaches often rely on simplified vehicle models, such as the\nzero-slip model, which assumes no lateral velocity at the rear axle. It is well\nestablished that this assumption does not hold during low-speed driving and\nresearchers thus introduce additional heuristics to account for differences. In\nthis work, we analyze real-world data from parking scenarios and identify a\nsystematic deviation from the zero-slip assumption. We provide explanations for\nthe observed effects and then propose a lateral velocity model that better\ncaptures the lateral dynamics of the vehicle during parking. The model improves\nestimation accuracy, while relying on only two parameters, making it\nwell-suited for integration into consumer-grade applications.", "AI": {"tldr": "A two-parameter lateral velocity model improves parking localization by replacing the zero-slip assumption, based on real-world data.", "motivation": "Accurate lateral velocity is crucial for parking maneuvers. Wheel encoders provide longitudinal velocity, but consumer vehicles lack lateral sensors; the common zero-slip model is inadequate at low speeds.", "method": "Analyze real parking data to identify deviations from zero-slip, provide explanations for the observations, and propose a two-parameter lateral velocity model capturing lateral dynamics; discuss integration into consumer-grade systems.", "result": "The proposed two-parameter lateral velocity model yields improved estimation accuracy for lateral velocity during parking compared to the zero-slip baseline.", "conclusion": "A simple, data-driven two-parameter model better captures lateral dynamics in parking, enabling improved localization for consumer-grade autonomous/assistive parking systems."}}
{"id": "2511.00166", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00166", "abs": "https://arxiv.org/abs/2511.00166", "authors": ["Shiman Zhang", "Jinghan Zhou", "Zhoufan Yu", "Ningai Leng"], "title": "Study on Supply Chain Finance Decision-Making Model and Enterprise Economic Performance Prediction Based on Deep Reinforcement Learning", "comment": "9 pages, 3 figures", "summary": "To improve decision-making and planning efficiency in back-end centralized\nredundant supply chains, this paper proposes a decision model integrating deep\nlearning with intelligent particle swarm optimization. A distributed node\ndeployment model and optimal planning path are constructed for the supply chain\nnetwork. Deep learning such as convolutional neural networks extracts features\nfrom historical data, and linear programming captures high-order statistical\nfeatures. The model is optimized using fuzzy association rule scheduling and\ndeep reinforcement learning, while neural networks fit dynamic changes. A\nhybrid mechanism of \"deep learning feature extraction - intelligent particle\nswarm optimization\" guides global optimization and selects optimal decisions\nfor adaptive control. Simulations show reduced resource consumption, enhanced\nspatial planning, and in dynamic environments improved real-time decision\nadjustment, distribution path optimization, and robust intelligent control.", "AI": {"tldr": "A hybrid DL-PSO model for back-end supply chains that jointly optimizes node deployment and planning paths, leveraging CNNs for feature extraction, linear programming for high-order statistics, fuzzy scheduling, deep reinforcement learning, and PSO-guided adaptive control; simulations show efficiency gains and robust dynamic decision-making.", "motivation": "Improve decision-making and planning efficiency in centralized redundant supply chains, especially under dynamic conditions, by integrating learning-based feature extraction, high-order statistical modeling, and global optimization with adaptive control.", "method": "Proposes a distributed node deployment model and an optimal planning path for the supply chain network. Uses convolutional neural networks to extract features from historical data, linear programming to capture high-order statistical features, fuzzy association rule scheduling and deep reinforcement learning for optimization, and neural networks to adapt to dynamic changes. Introduces a hybrid mechanism \u201cdeep learning feature extraction - intelligent particle swarm optimization\u201d to drive global optimization and select optimal decisions for adaptive control.", "result": "Simulations indicate reduced resource consumption, enhanced spatial planning, and in dynamic environments improved real-time decision adjustment, distribution path optimization, and robust intelligent control.", "conclusion": "Integrating deep learning with intelligent particle swarm optimization improves decision-making and planning efficiency in back-end supply chains, enabling adaptive, robust control under dynamic conditions."}}
{"id": "2511.01444", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01444", "abs": "https://arxiv.org/abs/2511.01444", "authors": ["Huiting Huang", "Tieliang Gong", "Kai He", "Jialun Wu", "Erik Cambria", "Mengling Feng"], "title": "Robust Multimodal Sentiment Analysis via Double Information Bottleneck", "comment": null, "summary": "Multimodal sentiment analysis has received significant attention across\ndiverse research domains. Despite advancements in algorithm design, existing\napproaches suffer from two critical limitations: insufficient learning of\nnoise-contaminated unimodal data, leading to corrupted cross-modal\ninteractions, and inadequate fusion of multimodal representations, resulting in\ndiscarding discriminative unimodal information while retaining multimodal\nredundant information. To address these challenges, this paper proposes a\nDouble Information Bottleneck (DIB) strategy to obtain a powerful, unified\ncompact multimodal representation. Implemented within the framework of low-rank\nRenyi's entropy functional, DIB offers enhanced robustness against diverse\nnoise sources and computational tractability for high-dimensional data, as\ncompared to the conventional Shannon entropy-based methods. The DIB comprises\ntwo key modules: 1) learning a sufficient and compressed representation of\nindividual unimodal data by maximizing the task-relevant information and\ndiscarding the superfluous information, and 2) ensuring the discriminative\nability of multimodal representation through a novel attention bottleneck\nfusion mechanism. Consequently, DIB yields a multimodal representation that\neffectively filters out noisy information from unimodal data while capturing\ninter-modal complementarity. Extensive experiments on CMU-MOSI, CMU-MOSEI,\nCH-SIMS, and MVSA-Single validate the effectiveness of our method. The model\nachieves 47.4% accuracy under the Acc-7 metric on CMU-MOSI and 81.63% F1-score\non CH-SIMS, outperforming the second-best baseline by 1.19%. Under noise, it\nshows only 0.36% and 0.29% performance degradation on CMU-MOSI and CMU-MOSEI\nrespectively.", "AI": {"tldr": "Introduces Double Information Bottleneck (DIB) for robust multimodal sentiment analysis by learning compact unimodal representations and a discriminative fused multimodal representation via an attention bottleneck, leveraging low-rank Renyi entropy to improve noise robustness and tractability.", "motivation": "Current multimodal sentiment analysis methods struggle with noise-contaminated unimodal data, which corrupts cross-modal interactions, and with fusion strategies that discard useful unimodal information while retaining redundant multimodal information. A robust, compact, and discriminative multimodal representation is needed.", "method": "Propose a Double Information Bottleneck (DIB) framework within a low-rank Renyi entropy functional. It comprises two modules: (1) unimodal bottleneck that learns sufficient and compressed representations by maximizing task-relevant information and discarding superfluous information; (2) a discriminative multimodal fusion via a novel attention bottleneck mechanism that preserves inter-modal complementarity while filtering noise.", "result": "Extensive experiments on CMU-MOSI, CMU-MOSEI, CH-SIMS, and MVSA-Single show strong performance: 47.4% accuracy (Acc-7) on CMU-MOSI and 81.63% F1 on CH-SIMS, with the second-best baseline lagging by 1.19%. Under noisy conditions, the method exhibits small degradations (0.36% on CMU-MOSI and 0.29% on CM-MOSEI), indicating robust noise handling.", "conclusion": "The proposed DIB framework yields a robust, compact, and discriminative multimodal representation by effectively filtering unimodal noise and leveraging inter-modal complementarity, achieving strong and noise-robust performance across multiple datasets."}}
{"id": "2511.00419", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00419", "abs": "https://arxiv.org/abs/2511.00419", "authors": ["Thanh Hieu Cao", "Trung Khang Tran", "Gia Thinh Pham", "Tuong Nghiem Diep", "Thanh Binh Nguyen"], "title": "LGCA: Enhancing Semantic Representation via Progressive Expansion", "comment": "15 pages, 5 figures, to appear in SoICT 2025", "summary": "Recent advancements in large-scale pretraining in natural language processing\nhave enabled pretrained vision-language models such as CLIP to effectively\nalign images and text, significantly improving performance in zero-shot image\nclassification tasks. Subsequent studies have further demonstrated that\ncropping images into smaller regions and using large language models to\ngenerate multiple descriptions for each caption can further enhance model\nperformance. However, due to the inherent sensitivity of CLIP, random image\ncrops can introduce misinformation and bias, as many images share similar\nfeatures at small scales. To address this issue, we propose\nLocalized-Globalized Cross-Alignment (LGCA), a framework that first captures\nthe local features of an image and then repeatedly selects the most salient\nregions and expands them. The similarity score is designed to incorporate both\nthe original and expanded images, enabling the model to capture both local and\nglobal features while minimizing misinformation. Additionally, we provide a\ntheoretical analysis demonstrating that the time complexity of LGCA remains the\nsame as that of the original model prior to the repeated expansion process,\nhighlighting its efficiency and scalability. Extensive experiments demonstrate\nthat our method substantially improves zero-shot performance across diverse\ndatasets, outperforming state-of-the-art baselines.", "AI": {"tldr": "Localized-Globalized Cross-Alignment (LGCA) improves zero-shot image classification by expanding and integrating salient local regions with the original image, achieving better performance without increasing time complexity.", "motivation": "To mitigate misinformation and bias from random small crops in CLIP-like models and to robustly capture both local and global image features efficiently.", "method": "LGCA builds a cross-alignment framework that (1) extracts local image features, (2) repeatedly selects salient regions and expands them, and (3) uses a similarity score that combines original and expanded images to align with text. The approach preserves the original model's time complexity prior to expansion, ensuring efficiency and scalability.", "result": "LGCA yields substantial improvements in zero-shot performance across diverse datasets and outperforms state-of-the-art baselines.", "conclusion": "LGCA offers an efficient, scalable solution for robust cross-modal alignment by fusing local and global cues while mitigating misinformation from small crops."}}
{"id": "2511.01379", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01379", "abs": "https://arxiv.org/abs/2511.01379", "authors": ["Kun Hu", "Menggang Li", "Zhiwen Jin", "Chaoquan Tang", "Eryi Hu", "Gongbo Zhou"], "title": "CM-LIUW-Odometry: Robust and High-Precision LiDAR-Inertial-UWB-Wheel Odometry for Extreme Degradation Coal Mine Tunnels", "comment": "Accepted by IROS 2025", "summary": "Simultaneous Localization and Mapping (SLAM) in large-scale, complex, and\nGPS-denied underground coal mine environments presents significant challenges.\nSensors must contend with abnormal operating conditions: GPS unavailability\nimpedes scene reconstruction and absolute geographic referencing, uneven or\nslippery terrain degrades wheel odometer accuracy, and long, feature-poor\ntunnels reduce LiDAR effectiveness. To address these issues, we propose\nCoalMine-LiDAR-IMU-UWB-Wheel-Odometry (CM-LIUW-Odometry), a multimodal SLAM\nframework based on the Iterated Error-State Kalman Filter (IESKF). First,\nLiDAR-inertial odometry is tightly fused with UWB absolute positioning\nconstraints to align the SLAM system with a global coordinate. Next, wheel\nodometer is integrated through tight coupling, enhanced by nonholonomic\nconstraints (NHC) and vehicle lever arm compensation, to address performance\ndegradation in areas beyond UWB measurement range. Finally, an adaptive motion\nmode switching mechanism dynamically adjusts the robot's motion mode based on\nUWB measurement range and environmental degradation levels. Experimental\nresults validate that our method achieves superior accuracy and robustness in\nreal-world underground coal mine scenarios, outperforming state-of-the-art\napproaches. We open source our code of this work on Github to benefit the\nrobotics community.", "AI": {"tldr": "A multimodal SLAM framework (CM-LIUW-Odometry) for GPS-denied underground mines that fuses LiDAR-IMU with UWB and wheel odometry via the Iterated Error-State Kalman Filter (IESKF), plus nonholonomic constraints and adaptive motion mode switching, achieving improved accuracy and robustness; code available on GitHub.", "motivation": "Underground coal mines face GPS denial, uneven terrain degrading wheel odometry, and long feature-poor tunnels reducing LiDAR effectiveness. A robust, globally consistent SLAM solution is needed.", "method": "Use Iterated Error-State Kalman Filter (IESKF) to tightly fuse: (1) LiDAR-IMU odometry with UWB absolute constraints to anchor the global frame; (2) wheel odometry with nonholonomic constraints and lever-arm compensation for extended reliability when UWB is weak; (3) an adaptive motion mode switching mechanism that adjusts the robot's mode based on UWB range and environmental degradation.", "result": "Experimental results in real underground coal mine scenarios show superior accuracy and robustness compared to state-of-the-art methods.", "conclusion": "CM-LIUW-Odometry provides a robust, globally consistent SLAM solution for GPS-denied underground environments; the authors open-source their code on GitHub."}}
{"id": "2511.00177", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00177", "abs": "https://arxiv.org/abs/2511.00177", "authors": ["Hiba Ahsan", "Byron C. Wallace"], "title": "Can SAEs reveal and mitigate racial biases of LLMs in healthcare?", "comment": null, "summary": "LLMs are increasingly being used in healthcare. This promises to free\nphysicians from drudgery, enabling better care to be delivered at scale. But\nthe use of LLMs in this space also brings risks; for example, such models may\nworsen existing biases. How can we spot when LLMs are (spuriously) relying on\npatient race to inform predictions? In this work we assess the degree to which\nSparse Autoencoders (SAEs) can reveal (and control) associations the model has\nmade between race and stigmatizing concepts. We first identify SAE latents in\nGemma-2 models which appear to correlate with Black individuals. We find that\nthis latent activates on reasonable input sequences (e.g., \"African American\")\nbut also problematic words like \"incarceration\". We then show that we can use\nthis latent to steer models to generate outputs about Black patients, and\nfurther that this can induce problematic associations in model outputs as a\nresult. For example, activating the Black latent increases the risk assigned to\nthe probability that a patient will become \"belligerent\". We evaluate the\ndegree to which such steering via latents might be useful for mitigating bias.\nWe find that this offers improvements in simple settings, but is less\nsuccessful for more realistic and complex clinical tasks. Overall, our results\nsuggest that: SAEs may offer a useful tool in clinical applications of LLMs to\nidentify problematic reliance on demographics but mitigating bias via SAE\nsteering appears to be of marginal utility for realistic tasks.", "AI": {"tldr": "Sparse autoencoders reveal race-associated latent representations in Gemma-2 LLMs and can steer outputs toward Black patients; while SAE-based detection helps identify problematic biases, steering-based mitigation shows only marginal utility in realistic clinical tasks.", "motivation": "Address safety concerns of LLMs in healthcare by uncovering and potentially mitigating spurious racial associations that could affect predictions and care quality.", "method": "Identify latent variables in Sparse Autoencoders (SAEs) that correlate with Black individuals in Gemma-2 models; examine activations on inputs like 'African American' and related terms; demonstrate that SAE latent steering can push outputs toward Black patients and alter risk predictions (e.g., increasing the likelihood of 'belligerent' labels); empirically assess whether SAE steering mitigates bias across simple versus realistic clinical tasks.", "result": "Found an SAE latent that correlates with Black demographics and activates on terms like 'African American' and 'incarceration'; activating this latent can steer the model to generate outputs about Black patients and alter outputs (e.g., higher risk for 'belligerent' labels); bias mitigation via SAE steering offers improvements in simple settings but is not robust for realistic, complex clinical tasks.", "conclusion": "SAEs are useful for detecting problematic demographic reliance in clinical LLMs, but using SAE steering as a mitigation strategy has limited utility for realistic healthcare tasks; thus, SAEs are better suited for bias auditing than for reliable bias mitigation."}}
{"id": "2511.01445", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01445", "abs": "https://arxiv.org/abs/2511.01445", "authors": ["ChengZhang Yu", "YingRu He", "Hongyan Cheng", "nuo Cheng", "Zhixing Liu", "Dongxu Mu", "Zhangrui Shen", "Zhanpeng Jin"], "title": "From Passive to Proactive: A Multi-Agent System with Dynamic Task Orchestration for Intelligent Medical Pre-Consultation", "comment": "14pages, 7 figures, 7 tables", "summary": "Global healthcare systems face critical challenges from increasing patient\nvolumes and limited consultation times, with primary care visits averaging\nunder 5 minutes in many countries. While pre-consultation processes\nencompassing triage and structured history-taking offer potential solutions,\nthey remain limited by passive interaction paradigms and context management\nchallenges in existing AI systems. This study introduces a hierarchical\nmulti-agent framework that transforms passive medical AI systems into proactive\ninquiry agents through autonomous task orchestration. We developed an\neight-agent architecture with centralized control mechanisms that decomposes\npre-consultation into four primary tasks: Triage ($T_1$), History of Present\nIllness collection ($T_2$), Past History collection ($T_3$), and Chief\nComplaint generation ($T_4$), with $T_1$--$T_3$ further divided into 13\ndomain-specific subtasks. Evaluated on 1,372 validated electronic health\nrecords from a Chinese medical platform across multiple foundation models\n(GPT-OSS 20B, Qwen3-8B, Phi4-14B), the framework achieved 87.0% accuracy for\nprimary department triage and 80.5% for secondary department classification,\nwith task completion rates reaching 98.2% using agent-driven scheduling versus\n93.1% with sequential processing. Clinical quality scores from 18 physicians\naveraged 4.56 for Chief Complaints, 4.48 for History of Present Illness, and\n4.69 for Past History on a 5-point scale, with consultations completed within\n12.7 rounds for $T_2$ and 16.9 rounds for $T_3$. The model-agnostic\narchitecture maintained high performance across different foundation models\nwhile preserving data privacy through local deployment, demonstrating the\npotential for autonomous AI systems to enhance pre-consultation efficiency and\nquality in clinical settings.", "AI": {"tldr": "A hierarchical multi-agent system automates pre-consultation tasks (triage, history taking, chief complaint) with centralized control, achieving high accuracy and efficiency while preserving privacy across multiple foundation models.", "motivation": "To address diminishing consultation times and rising patient volumes by making AI-driven pre-consultation proactive and private, moving from passive interaction to autonomous inquiry orchestration.", "method": "An eight-agent architecture decomposes pre-consultation into four main tasks (T1\u2013T4), with T1\u2013T3 subdivided into 13 domain-specific subtasks. Centralized scheduling enables task orchestration. Evaluated on 1,372 validated EHRs from a Chinese platform across GPT-OSS 20B, Qwen3-8B, and Phi4-14B, with local deployment to ensure privacy.", "result": "Triage accuracy: 87.0% (primary); 80.5% (secondary dept). Task completion rate: 98.2% with agent-driven scheduling vs 93.1% sequential. Clinical quality scores: Chief Complaints 4.56, History of Present Illness 4.48, Past History 4.69 (out of 5). Rounds: ~12.7 for T2 and ~16.9 for T3. Performance remained strong across models, with privacy preserved via local deployment.", "conclusion": "A model-agnostic, privacy-preserving autonomous AI framework can improve pre-consultation efficiency and quality, enabling proactive inquiry in clinical settings across diverse foundation models."}}
{"id": "2511.00427", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00427", "abs": "https://arxiv.org/abs/2511.00427", "authors": ["Daichi Zhang", "Tong Zhang", "Jianmin Bao", "Shiming Ge", "Sabine S\u00fcsstrunk"], "title": "Leveraging Hierarchical Image-Text Misalignment for Universal Fake Image Detection", "comment": null, "summary": "With the rapid development of generative models, detecting generated fake\nimages to prevent their malicious use has become a critical issue recently.\nExisting methods frame this challenge as a naive binary image classification\ntask. However, such methods focus only on visual clues, yielding trained\ndetectors susceptible to overfitting specific image patterns and incapable of\ngeneralizing to unseen models. In this paper, we address this issue from a\nmulti-modal perspective and find that fake images cannot be properly aligned\nwith corresponding captions compared to real images. Upon this observation, we\npropose a simple yet effective detector termed ITEM by leveraging the\nimage-text misalignment in a joint visual-language space as discriminative\nclues. Specifically, we first measure the misalignment of the images and\ncaptions in pre-trained CLIP's space, and then tune a MLP head to perform the\nusual detection task. Furthermore, we propose a hierarchical misalignment\nscheme that first focuses on the whole image and then each semantic object\ndescribed in the caption, which can explore both global and fine-grained local\nsemantic misalignment as clues. Extensive experiments demonstrate the\nsuperiority of our method against other state-of-the-art competitors with\nimpressive generalization and robustness on various recent generative models.", "AI": {"tldr": "Multi-modal detector ITEM leverages image-text misalignment in CLIP space to detect AI-generated images, using a hierarchical scheme (global image and per-object semantics) to improve generalization to unseen generators.", "motivation": "Binary visual detectors overfit to known models; need robust generalization; observation that fake images misalign with captions compared to real images in CLIP space.", "method": "Compute image-caption misalignment in CLIP space; train an MLP head for detection; hierarchical scheme: global image alignment first, then per-caption semantic object alignment; joint visual-language space used for discriminative cues.", "result": "Outperforms state-of-the-art; strong generalization and robustness across different generative models.", "conclusion": "ITEM demonstrates that image-text misalignment in a CLIP-based space is a powerful cue for detecting synthetic images, with global and local semantic alignment cues enhancing robustness to unseen generators."}}
{"id": "2511.01383", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01383", "abs": "https://arxiv.org/abs/2511.01383", "authors": ["Landson Guo", "Andres M. Diaz Aguilar", "William Talbot", "Turcan Tuna", "Marco Hutter", "Cesar Cadena"], "title": "CaRLi-V: Camera-RADAR-LiDAR Point-Wise 3D Velocity Estimation", "comment": null, "summary": "Accurate point-wise velocity estimation in 3D is crucial for robot\ninteraction with non-rigid, dynamic agents, such as humans, enabling robust\nperformance in path planning, collision avoidance, and object manipulation in\ndynamic environments. To this end, this paper proposes a novel RADAR, LiDAR,\nand camera fusion pipeline for point-wise 3D velocity estimation named CaRLi-V.\nThis pipeline leverages raw RADAR measurements to create a novel RADAR\nrepresentation, the velocity cube, which densely represents radial velocities\nwithin the RADAR's field-of-view. By combining the velocity cube for radial\nvelocity extraction, optical flow for tangential velocity estimation, and LiDAR\nfor point-wise range measurements through a closed-form solution, our approach\ncan produce 3D velocity estimates for a dense array of points. Developed as an\nopen-source ROS2 package, CaRLi-V has been field-tested against a custom\ndataset and proven to produce low velocity error metrics relative to ground\ntruth, enabling point-wise velocity estimation for robotic applications.", "AI": {"tldr": "A multi-sensor CaRLi-V pipeline fuses RADAR, LiDAR, and camera data to produce dense 3D point-wise velocity estimates via a velocity cube, combining radial from RADAR, tangential from optical flow, and range from LiDAR in a closed-form fusion, packaged as an open-source ROS2 tool.", "motivation": "Enable robust, point-wise 3D velocity estimation for dynamic, non-rigid agents (e.g., humans) to improve robotic path planning, collision avoidance, and manipulation in dynamic environments.", "method": "Introduce a novel RADAR representation called the velocity cube to densely encode radial velocities within the sensor FOV. Extract radial velocity from the velocity cube, estimate tangential velocity from optical flow, and use LiDAR range measurements in a closed-form solution to compute 3D velocity for a dense grid of points. Implemented as an open-source ROS2 package (CaRLi-V) and evaluated on a custom dataset.", "result": "Reported low velocity error metrics relative to ground truth, demonstrating accurate dense 3D velocity estimation and enabling point-wise velocity estimates for robotic tasks.", "conclusion": "CaRLi-V demonstrates the feasibility of dense 3D velocity estimation through multi-sensor fusion (RADAR, LiDAR, camera) and provides an open-source tool suitable for robotics applications in dynamic environments."}}
{"id": "2511.00183", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00183", "abs": "https://arxiv.org/abs/2511.00183", "authors": ["Shaghayegh Fazliani", "Madeleine Udell"], "title": "PDE-SHARP: PDE Solver Hybrids Through Analysis & Refinement Passes", "comment": null, "summary": "Current LLM-driven approaches using test-time computing to generate PDE\nsolvers execute a large number of solver samples to identify high-accuracy\nsolvers. These paradigms are especially costly for complex PDEs requiring\nsubstantial computational resources for numerical evaluation. We introduce\nPDE-SHARP, a framework to reduce computational costs by replacing expensive\nscientific computation by cheaper LLM inference that achieves superior solver\naccuracy with 60-75% fewer computational evaluations. PDE-SHARP employs three\nstages: (1) Analysis: mathematical chain-of-thought analysis including PDE\nclassification, solution type detection, and stability analysis; (2) Genesis:\nsolver generation based on mathematical insights from the previous stage; and\n(3) Synthesis: collaborative selection-hybridization tournaments in which LLM\njudges iteratively refine implementations through flexible performance\nfeedback. To generate high-quality solvers, PDE-SHARP requires fewer than 13\nsolver evaluations on average compared to 30+ for baseline methods, improving\naccuracy uniformly across tested PDEs by $4\\times$ on average, and demonstrates\nrobust performance across LLM architectures, from general-purpose to\nspecialized reasoning models.", "AI": {"tldr": "PDE-SHARP substitutes expensive PDE solver computations with cheaper LLM inference via a three-stage pipeline, achieving 60-75% fewer evaluations and ~4x accuracy improvements across PDEs, robust to different LLMs.", "motivation": "Test-time, LLM-driven PDE solvers rely on many solver samples, incurring high computational cost for complex PDEs; a cheaper, accurate alternative is needed.", "method": "Three-stage pipeline: (1) Analysis: chain-of-thought, PDE classification, solution type detection, stability analysis; (2) Genesis: solver generation from insights; (3) Synthesis: collaborative selection-hybridization tournaments where LLMs iteratively refine implementations through feedback.", "result": "Reduces solver evaluations from 30+ to under 13 on average; improves accuracy uniformly by ~4x across tested PDEs; robust across LLM architectures from general-purpose to specialized reasoning models.", "conclusion": "PDE-SHARP provides a cost-effective, accurate, and architecture-robust framework for PDE solving with LLMs, highlighting the value of staged reasoning and collaborative refinement."}}
{"id": "2511.01527", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01527", "abs": "https://arxiv.org/abs/2511.01527", "authors": ["Hanwen Xu", "Xuyao Huang", "Yuzhe Liu", "Kai Yu", "Zhijie Deng"], "title": "TPS-Bench: Evaluating AI Agents' Tool Planning \\& Scheduling Abilities in Compounding Tasks", "comment": null, "summary": "Large language model (LLM) agents have exhibited strong problem-solving\ncompetence across domains like research and coding. Yet, it remains\nunderexplored whether LLM agents can tackle compounding real-world problems\nthat require a diverse set of tools to complete. Given a broad, heterogeneous\ntool repository, LLM agents must not only select appropriate tools based on\ntask planning analysis but also strategically schedule the execution order to\nensure efficiency. This paper introduces TPS-Bench to benchmark the ability of\nLLM agents in solving such problems that demand Tool Planning and Scheduling.\nTPS-Bench collects 200 compounding tasks of two difficulty levels, based on a\ntool repository containing hundreds of model context protocol (MCP) tools. In\nparticular, each task is composed of multiple subtasks, such as web search, map\nnavigation, calendar checking, etc., and each subtask can be completed by a\nbasic tool. Our evaluation emphasizes both task completion rate and efficiency.\nThe empirical studies on popular closed-source and open-source LLMs indicate\nthat most models can perform reasonable tool planning, but differ in\nscheduling. For example, GLM-4.5 achieves an outperforming task completion rate\nof 64.72% with extensive sequential tool calls, hence suffering from\nsignificantly long execution time. By contrast, GPT-4o prioritizes parallel\ntool calls but achieves only a 45.08% completion rate. Considering\nreinforcement learning (RL) can be a viable way to improve the scheduling\nefficiency without compromising performance, we perform an initial study on\nQwen3-1.7B and witness a 14% reduction in execution time alongside a 6% gain in\ntask completion rate based on rarely 100 RL training samples. Our code is\navailable https://github.com/hanwenxu1/mcp-agent.", "AI": {"tldr": "TPS-Bench is a benchmark to evaluate LLM agents' ability to plan tool usage and schedule executions for compounding real-world tasks, using a 200-task MCP-tool-based benchmark to study completion rates and efficiency, revealing trade-offs between sequential and parallel tool calls and showing RL can improve scheduling.", "motivation": "To understand how LLM agents coordinate a broad set of tools (tool planning and scheduling) to solve heterogeneous, multi-subtask problems that occur in real-world settings.", "method": "Construct TPS-Bench with 200 compounding tasks across two difficulty levels built on a repository of hundreds of MCP tools; each task has multiple subtasks (e.g., web search, map navigation, calendar checks) solvable by basic tools; evaluate task completion rate and execution time across models (e.g., GLM-4.5, GPT-4o); explore RL on Qwen3-1.7B with ~100 training samples to improve scheduling; provide open-source code.", "result": "Findings show most models can perform basic tool planning but scheduling varies: GLM-4.5 achieves 64.72% completion with long sequential tool calls; GPT-4o uses parallel calls but only 45.08% completion; RL on Qwen3-1.7B reduces execution time by 14% and increases completion rate by 6% with limited data (~100 samples).", "conclusion": "Tool planning plus scheduling is attainable for LLM agents; scheduling strategy materially affects efficiency; RL appears promising for improving scheduling; TPS-Bench provides a baseline and benchmark for future work in this area."}}
{"id": "2511.00429", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00429", "abs": "https://arxiv.org/abs/2511.00429", "authors": ["Daichi Zhang", "Tong Zhang", "Shiming Ge", "Sabine S\u00fcsstrunk"], "title": "Enhancing Frequency Forgery Clues for Diffusion-Generated Image Detection", "comment": null, "summary": "Diffusion models have achieved remarkable success in image synthesis, but the\ngenerated high-quality images raise concerns about potential malicious use.\nExisting detectors often struggle to capture discriminative clues across\ndifferent models and settings, limiting their generalization to unseen\ndiffusion models and robustness to various perturbations. To address this\nissue, we observe that diffusion-generated images exhibit progressively larger\ndifferences from natural real images across low- to high-frequency bands. Based\non this insight, we propose a simple yet effective representation by enhancing\nthe Frequency Forgery Clue (F^2C) across all frequency bands. Specifically, we\nintroduce a frequency-selective function which serves as a weighted filter to\nthe Fourier spectrum, suppressing less discriminative bands while enhancing\nmore informative ones. This approach, grounded in a comprehensive analysis of\nfrequency-based differences between natural real and diffusion-generated\nimages, enables general detection of images from unseen diffusion models and\nprovides robust resilience to various perturbations. Extensive experiments on\nvarious diffusion-generated image datasets demonstrate that our method\noutperforms state-of-the-art detectors with superior generalization and\nrobustness.", "AI": {"tldr": "A diffusion-image detector enhances a frequency-domain cue (F^2C) by applying a frequency-selective weighting to the Fourier spectrum, improving detection of unseen diffusion models and robustness to perturbations.", "motivation": "Detectors struggle to generalize across different diffusion models and perturbations; diffusion-generated images diverge more from natural images in high-frequency bands, so a robust detector should leverage discriminative information across all frequencies.", "method": "Introduce a frequency-selective function that acts as a weighted filter on the Fourier spectrum to enhance informative frequency bands and suppress less discriminative ones, thereby strengthening the Frequency Forgery Clue (F^2C) across all frequencies.", "result": "Extensive experiments on datasets of diffusion-generated images show the proposed approach outperforms state-of-the-art detectors, with superior generalization to unseen models and robustness to perturbations.", "conclusion": "A simple, frequency-domain approach using F^2C and a frequency-selective filter yields strong generalization and robustness for detecting diffusion-generated images across unseen models."}}
{"id": "2511.01407", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01407", "abs": "https://arxiv.org/abs/2511.01407", "authors": ["Paolo Rabino", "Gabriele Tiboni", "Tatiana Tommasi"], "title": "FoldPath: End-to-End Object-Centric Motion Generation via Modulated Implicit Paths", "comment": "Accepted at 2025 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025)", "summary": "Object-Centric Motion Generation (OCMG) is instrumental in advancing\nautomated manufacturing processes, particularly in domains requiring\nhigh-precision expert robotic motions, such as spray painting and welding. To\nrealize effective automation, robust algorithms are essential for generating\nextended, object-aware trajectories across intricate 3D geometries. However,\ncontemporary OCMG techniques are either based on ad-hoc heuristics or employ\nlearning-based pipelines that are still reliant on sensitive post-processing\nsteps to generate executable paths. We introduce FoldPath, a novel, end-to-end,\nneural field based method for OCMG. Unlike prior deep learning approaches that\npredict discrete sequences of end-effector waypoints, FoldPath learns the robot\nmotion as a continuous function, thus implicitly encoding smooth output paths.\nThis paradigm shift eliminates the need for brittle post-processing steps that\nconcatenate and order the predicted discrete waypoints. Particularly, our\napproach demonstrates superior predictive performance compared to recently\nproposed learning-based methods, and attains generalization capabilities even\nin real industrial settings, where only a limited amount of 70 expert samples\nare provided. We validate FoldPath through comprehensive experiments in a\nrealistic simulation environment and introduce new, rigorous metrics designed\nto comprehensively evaluate long-horizon robotic paths, thus advancing the OCMG\ntask towards practical maturity.", "AI": {"tldr": "FoldPath is an end-to-end neural field-based method for object-centric motion generation (OCMG) that models robot motion as a continuous function, removing brittle post-processing of discrete waypoints. It achieves strong predictive performance, generalizes from as few as 70 expert samples, and introduces new metrics for evaluating long-horizon paths in realistic simulations, indicating practical maturity for industrial OCMG tasks.", "motivation": "Current OCMG approaches rely on ad-hoc heuristics or learning pipelines that require brittle post-processing to convert predictions into executable paths. There is a need for robust, long-horizon, object-aware trajectory generation that can generalize to real industrial settings with limited expert data.", "method": "FoldPath uses a neural field to represent the robot's motion as a continuous trajectory function, eliminating the need to predict discrete end-effector waypoints and post-processing steps. The model is trained with a small set of expert demonstrations (around 70 samples) and evaluated in a realistic simulation, with new metrics designed to assess long-horizon paths.", "result": "FoldPath demonstrates superior predictive performance compared to recent learning-based methods and generalizes well to industrial environments using minimal expert data, validated through comprehensive simulation experiments.", "conclusion": "The end-to-end neural field approach of FoldPath advances the practicality of OCMG, reducing brittleness from post-processing and enabling robust, long-horizon motion generation suitable for real-world manufacturing tasks."}}
{"id": "2511.00192", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00192", "abs": "https://arxiv.org/abs/2511.00192", "authors": ["Ali Satvaty", "Suzan Verberne", "Fatih Turkmen"], "title": "EL-MIA: Quantifying Membership Inference Risks of Sensitive Entities in LLMs", "comment": null, "summary": "Membership inference attacks (MIA) aim to infer whether a particular data\npoint is part of the training dataset of a model. In this paper, we propose a\nnew task in the context of LLM privacy: entity-level discovery of membership\nrisk focused on sensitive information (PII, credit card numbers, etc). Existing\nmethods for MIA can detect the presence of entire prompts or documents in the\nLLM training data, but they fail to capture risks at a finer granularity. We\npropose the ``EL-MIA'' framework for auditing entity-level membership risks in\nLLMs. We construct a benchmark dataset for the evaluation of MIA methods on\nthis task. Using this benchmark, we conduct a systematic comparison of existing\nMIA techniques as well as two newly proposed methods. We provide a\ncomprehensive analysis of the results, trying to explain the relation of the\nentity level MIA susceptability with the model scale, training epochs, and\nother surface level factors. Our findings reveal that existing MIA methods are\nlimited when it comes to entity-level membership inference of the sensitive\nattributes, while this susceptibility can be outlined with relatively\nstraightforward methods, highlighting the need for stronger adversaries to\nstress test the provided threat model.", "AI": {"tldr": "Proposes EL-MIA for entity-level membership risk in LLMs, introduces a benchmark, compares existing MIA methods and two new ones, and finds current MIAs insufficient for sensitive-entity leakage, highlighting need for stronger adversaries and threat models.", "motivation": "Address privacy risks in LLMs at a finer granularity by auditing whether sensitive entities (PII, credit card numbers, etc.) appear in training data, beyond whole-prompt/document leakage.", "method": "Introduce EL-MIA framework for auditing, construct a benchmark dataset for entity-level MIA evaluation, perform a systematic comparison of existing MIAs and two proposed methods, analyze factors like model scale and training epochs to explain susceptibility.", "result": "Existing MIA methods are limited in detecting entity-level membership of sensitive attributes; some straightforward approaches can outline susceptibility, indicating gaps and the need for stronger adversaries to stress-test the threat model.", "conclusion": "Entity-level membership inference on sensitive attributes is underdeveloped; more robust threat models and adversarial evaluation are required to accurately assess and mitigate these risks."}}
{"id": "2511.01550", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01550", "abs": "https://arxiv.org/abs/2511.01550", "authors": ["Ujjwal Sharma", "Stevan Rudinac", "Ana Mi\u0107kovi\u0107", "Willemijn van Dolen", "Marcel Worring"], "title": "Analyzing Sustainability Messaging in Large-Scale Corporate Social Media", "comment": null, "summary": "In this work, we introduce a multimodal analysis pipeline that leverages\nlarge foundation models in vision and language to analyze corporate social\nmedia content, with a focus on sustainability-related communication. Addressing\nthe challenges of evolving, multimodal, and often ambiguous corporate messaging\non platforms such as X (formerly Twitter), we employ an ensemble of large\nlanguage models (LLMs) to annotate a large corpus of corporate tweets on their\ntopical alignment with the 17 Sustainable Development Goals (SDGs). This\napproach avoids the need for costly, task-specific annotations and explores the\npotential of such models as ad-hoc annotators for social media data that can\nefficiently capture both explicit and implicit references to sustainability\nthemes in a scalable manner. Complementing this textual analysis, we utilize\nvision-language models (VLMs), within a visual understanding framework that\nuses semantic clusters to uncover patterns in visual sustainability\ncommunication. This integrated approach reveals sectoral differences in SDG\nengagement, temporal trends, and associations between corporate messaging,\nenvironmental, social, governance (ESG) risks, and consumer engagement. Our\nmethods-automatic label generation and semantic visual clustering-are broadly\napplicable to other domains and offer a flexible framework for large-scale\nsocial media analysis.", "AI": {"tldr": "A multimodal pipeline uses LLMs to align corporate tweets with the 17 SDGs and visual-language models to cluster visual sustainability cues, enabling scalable, annotation-light analysis of sustainability messaging and its relation to ESG risks and consumer engagement.", "motivation": "Tackling evolving, multimodal, and often ambiguous corporate sustainability messaging on social media; avoid costly task-specific annotations by using foundation models as ad-hoc annotators; enable large-scale, scalable analysis across platforms.", "method": "Text analysis via an ensemble of large language models annotating tweets for SDG alignment; visual analysis via vision-language models within a semantic-clustering framework to uncover patterns in visual sustainability communication; automatic label generation and semantic visual clustering.", "result": "Reveals sectoral differences in SDG engagement, temporal trends, and associations between corporate messaging, ESG risks, and consumer engagement; demonstrates a flexible pipeline applicable to other domains for large-scale social media analysis.", "conclusion": "An integrated, scalable, annotation-light framework for multimodal social media analysis that can be applied beyond sustainability to other domains."}}
{"id": "2511.00446", "categories": ["cs.CV", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00446", "abs": "https://arxiv.org/abs/2511.00446", "authors": ["Xin Yao", "Haiyang Zhao", "Yimin Chen", "Jiawei Guo", "Kecheng Huang", "Ming Zhao"], "title": "ToxicTextCLIP: Text-Based Poisoning and Backdoor Attacks on CLIP Pre-training", "comment": "Accepted by NeurIPS 2025", "summary": "The Contrastive Language-Image Pretraining (CLIP) model has significantly\nadvanced vision-language modeling by aligning image-text pairs from large-scale\nweb data through self-supervised contrastive learning. Yet, its reliance on\nuncurated Internet-sourced data exposes it to data poisoning and backdoor\nrisks. While existing studies primarily investigate image-based attacks, the\ntext modality, which is equally central to CLIP's training, remains\nunderexplored. In this work, we introduce ToxicTextCLIP, a framework for\ngenerating high-quality adversarial texts that target CLIP during the\npre-training phase. The framework addresses two key challenges: semantic\nmisalignment caused by background inconsistency with the target class, and the\nscarcity of background-consistent texts. To this end, ToxicTextCLIP iteratively\napplies: 1) a background-aware selector that prioritizes texts with background\ncontent aligned to the target class, and 2) a background-driven augmenter that\ngenerates semantically coherent and diverse poisoned samples. Extensive\nexperiments on classification and retrieval tasks show that ToxicTextCLIP\nachieves up to 95.83% poisoning success and 98.68% backdoor Hit@1, while\nbypassing RoCLIP, CleanCLIP and SafeCLIP defenses. The source code can be\naccessed via https://github.com/xinyaocse/ToxicTextCLIP/.", "AI": {"tldr": "ToxicTextCLIP shows a framework to poison CLIP's pretraining via adversarial texts, using background-aware selection and background-driven augmentation to create background-consistent poisoned samples; it achieves high attack and backdoor success and defeats several defenses.", "motivation": "CLIP relies on large-scale uncurated Internet data and the text modality for training, making it vulnerable to data poisoning and backdoors that are underexplored compared to image-based attacks.", "method": "An iterative two-component approach: (1) a background-aware selector that prioritizes texts whose background content aligns with the target class, and (2) a background-driven augmenter that generates semantically coherent, diverse poisoned samples, applied during pretraining to induce semantic misalignment targeted by CLIP.", "result": "Extensive experiments on classification and retrieval show high poisoning success (up to 95.83%) and backdoor Hit@1 (98.68%), while bypassing defenses such as RoCLIP, CleanCLIP and SafeCLIP.", "conclusion": "Text-based poisoning of CLIP during pretraining is feasible and effective, highlighting the need for robust data curation and defense mechanisms against backdoor attacks in vision-language models."}}
{"id": "2511.01437", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01437", "abs": "https://arxiv.org/abs/2511.01437", "authors": ["Elian Neppel", "Shamistan Karimov", "Ashutosh Mishra", "Gustavo Hernan Diaz Huenupan", "Hazal Gozbasi", "Kentaro Uno", "Shreya Santra", "Kazuya Yoshida"], "title": "Designing for Distributed Heterogeneous Modularity: On Software Architecture and Deployment of MoonBots", "comment": "6 pages, 8 figures. Accepted at ISPARO 2025", "summary": "This paper presents the software architecture and deployment strategy behind\nthe MoonBot platform: a modular space robotic system composed of heterogeneous\ncomponents distributed across multiple computers, networks and ultimately\ncelestial bodies. We introduce a principled approach to distributed,\nheterogeneous modularity, extending modular robotics beyond physical\nreconfiguration to software, communication and orchestration. We detail the\narchitecture of our system that integrates component-based design, a\ndata-oriented communication model using ROS2 and Zenoh, and a deployment\norchestrator capable of managing complex multi-module assemblies. These\nabstractions enable dynamic reconfiguration, decentralized control, and\nseamless collaboration between numerous operators and modules. At the heart of\nthis system lies our open-source Motion Stack software, validated by months of\nfield deployment with self-assembling robots, inter-robot cooperation, and\nremote operation. Our architecture tackles the significant hurdles of modular\nrobotics by significantly reducing integration and maintenance overhead, while\nremaining scalable and robust. Although tested with space in mind, we propose\ngeneralizable patterns for designing robotic systems that must scale across\ntime, hardware, teams and operational environments.", "AI": {"tldr": "A modular, software-defined robotic architecture for MoonBot enabling distributed, heterogeneous modularity across hardware, software, and networks; uses ROS2/Zenoh for data-oriented communication, plus a deployment orchestrator and open-source Motion Stack; validated in extended field deployment and designed for scalable collaboration.", "motivation": "Tackle the integration and maintenance overhead of scaling modular robotics as hardware, software, teams, and environments grow; extend modularity beyond physical reconfiguration to software, communication, and orchestration; support space-oriented operations while offering generalizable patterns for broader domains.", "method": "Describe a component-based architecture with data-oriented communication (ROS2 + Zenoh) and a deployment orchestrator to manage multi-module assemblies; enable dynamic reconfiguration, decentralized control, and cross-operator collaboration; leverage the open-source Motion Stack and validate via months-long field deployments including self-assembly, inter-robot cooperation, and remote operation.", "result": "Validated through months of field deployment with self-assembling robots, inter-robot cooperation, and remote operation; demonstrated reduced integration and maintenance overhead while maintaining scalability and robustness.", "conclusion": "Proposes generalizable patterns for designing robotic systems that must scale across time, hardware, teams, and operational environments; while framed around space robotics, the approach is applicable to broader robotic systems requiring modular software, distributed control, and cross-domain collaboration."}}
{"id": "2511.00203", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00203", "abs": "https://arxiv.org/abs/2511.00203", "authors": ["David L\u00fcdke", "Tom Wollschl\u00e4ger", "Paul Ungermann", "Stephan G\u00fcnnemann", "Leo Schwinn"], "title": "Diffusion LLMs are Natural Adversaries for any LLM", "comment": null, "summary": "We introduce a novel framework that transforms the resource-intensive\n(adversarial) prompt optimization problem into an \\emph{efficient, amortized\ninference task}. Our core insight is that pretrained, non-autoregressive\ngenerative LLMs, such as Diffusion LLMs, which model the joint distribution\nover prompt-response pairs, can serve as powerful surrogates for prompt search.\nThis approach enables the direct conditional generation of prompts, effectively\nreplacing costly, per-instance discrete optimization with a small number of\nparallelizable samples. We provide a probabilistic analysis demonstrating that\nunder mild fidelity assumptions, only a few conditional samples are required to\nrecover high-reward (harmful) prompts. Empirically, we find that the generated\nprompts are low-perplexity, diverse jailbreaks that exhibit strong\ntransferability to a wide range of black-box target models, including robustly\ntrained and proprietary LLMs. Beyond adversarial prompting, our framework opens\nnew directions for red teaming, automated prompt optimization, and leveraging\nemerging Flow- and Diffusion-based LLMs.", "AI": {"tldr": "A framework that replaces costly adversarial prompt optimization with efficient amortized inference by using pretrained diffusion/non-autoregressive LLMs to generate prompts conditionally. It claims few samples suffice under mild fidelity, yielding low-perplexity, diverse jailbreak prompts transferable to many black-box models, enabling rapid red-team and prompt-optimization workflows.", "motivation": "Adversarial prompt optimization is resource-intensive and per-instance. The authors seek scalable surrogates that can generalize across models. Non-autoregressive, diffusion-based LLMs that model the joint distribution over prompt\u2013response pairs can serve as effective proxies for prompt search and enable parallel prompt generation.", "method": "Utilize pretrained diffusion LLMs that model the joint distribution of prompt\u2013response pairs to generate prompts conditionally. Reformulate prompt search as an amortized inference problem with a small number of parallelizable samples. Provide a probabilistic analysis showing that, under mild fidelity assumptions, few conditional samples recover high-reward prompts. Empirically evaluate across black-box models, measuring prompt quality, perplexity, diversity, and transferability.", "result": "Prompts generated are low-perplexity, diverse jailbreaks that transfer effectively to a wide range of black-box LLMs, including robustly trained and proprietary models. The approach replaces costly per-instance optimization with a small set of samples, enabling scalable red-teaming and automated prompt optimization.", "conclusion": "The framework enables efficient adversarial prompt search and red-teaming via diffusion-based LLMs, suggesting broader directions for leveraging Flow- and Diffusion-based LLMs in prompt optimization and security testing."}}
{"id": "2511.01581", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01581", "abs": "https://arxiv.org/abs/2511.01581", "authors": ["Chengzhang Yu", "Zening Lu", "Chenyang Zheng", "Chiyue Wang", "Yiming Zhang", "Zhanpeng Jin"], "title": "ExplicitLM: Decoupling Knowledge from Parameters via Explicit Memory Banks", "comment": "12pages, 4figures", "summary": "Large language models suffer from knowledge staleness and lack of\ninterpretability due to implicit knowledge storage across entangled network\nparameters, preventing targeted updates and reasoning transparency. We propose\nExplicitLM, a novel architecture featuring a million-scale external memory bank\nstoring human-readable knowledge as token sequences, enabling direct inspection\nand modification. We design a differentiable two-stage retrieval mechanism with\nefficient coarse-grained filtering via product key decomposition (reducing\ncomplexity from $\\mathcal{O}(N \\cdot |I|)$ to $\\mathcal{O}(\\sqrt{N} \\cdot\n|I|)$) and fine-grained Gumbel-Softmax matching for end-to-end training.\nInspired by dual-system cognitive theory, we partition knowledge into frozen\nexplicit facts (20%) and learnable implicit patterns (80%), maintained through\nExponential Moving Average updates for stability. ExplicitLM achieves up to\n43.67% improvement on knowledge-intensive tasks versus standard Transformers,\nwith 3.62$\\times$ gains in low-data regimes (10k samples). Analysis shows\nstrong correlations between memory retrieval and performance, with correct\npredictions achieving 49% higher hit rates. Unlike RAG systems with frozen\nretrieval, our jointly optimized architecture demonstrates that interpretable,\nupdatable models can maintain competitive performance while providing\nunprecedented knowledge transparency.", "AI": {"tldr": "ExplicitLM combines a million-scale external memory of human-readable facts with differentiable retrieval to create interpretable, updatable language models; it achieves strong gains on knowledge-intensive tasks and in low-data regimes, while enabling direct inspection of knowledge.", "motivation": "Address knowledge staleness and lack of interpretability in large language models caused by entangled implicit knowledge in parameters, which hinders targeted updates and transparent reasoning.", "method": "A million-scale external memory storing knowledge as token sequences is integrated into the model. Retrieval has two stages: (1) coarse-grained filtering via product key decomposition (reducing complexity from O(N\u00b7|I|) to O(\u221aN\u00b7|I|)); (2) fine-grained matching via Gumbel-Softmax for end-to-end training. Knowledge is partitioned into frozen explicit facts (20%) and learnable implicit patterns (80%), maintained with Exponential Moving Average updates for stability.", "result": "The approach yields up to 43.67% improvements on knowledge-intensive tasks over standard Transformers and 3.62\u00d7 gains in low-data regimes (10k samples). Correct predictions show 49% higher hit rates. The model demonstrates strong correlations between memory retrieval and performance.", "conclusion": "A jointly optimized, interpretable, and updatable LM is feasible with explicit memory retrieval, offering unprecedented knowledge transparency while maintaining competitive performance compared to retrieval-augmented RAG systems with frozen retrieval."}}
{"id": "2511.00456", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00456", "abs": "https://arxiv.org/abs/2511.00456", "authors": ["Kiran Shahi", "Anup Bagale"], "title": "Weakly Supervised Pneumonia Localization from Chest X-Rays Using Deep Neural Network and Grad-CAM Explanations", "comment": null, "summary": "This study proposes a weakly supervised deep learning framework for pneumonia\nclassification and localization from chest X-rays, utilizing Grad-CAM\nexplanations. Instead of costly pixel-level annotations, our approach utilizes\nimage-level labels to generate clinically meaningful heatmaps that highlight\nregions affected by pneumonia. We evaluate seven ImageNet-pretrained\narchitectures ResNet-18/50, DenseNet-121, EfficientNet-B0, MobileNet-V2/V3, and\nViT-B16 under identical training conditions with focal loss and patient-wise\nsplits to prevent data leakage. Experimental results on the Kermany CXR dataset\ndemonstrate that ResNet-18 and EfficientNet-B0 achieve the best overall test\naccuracy of 98\\%, ROC-AUC = 0.997, and F1 = 0.987, while MobileNet-V2 provides\nan optimal trade-off between accuracy and computational cost. Grad-CAM\nvisualizations confirm that the proposed models focus on clinically relevant\nlung regions, supporting the use of interpretable AI for radiological\ndiagnostics. This work highlights the potential of weakly supervised\nexplainable models that enhance pneumonia screening transparency, and clinical\ntrust in AI-assisted medical imaging.\n  https://github.com/kiranshahi/pneumonia-analysis", "AI": {"tldr": "Weakly supervised pneumonia classification/localization using Grad-CAM heatmaps with image-level labels across seven architectures; achieves near-perfect performance and interpretable heatmaps on Kermany CXR data.", "motivation": "Enable explainable pneumonia detection without costly pixel-level annotations and increase clinical trust by providing interpretable localization through Grad-CAM.", "method": "Weakly supervised learning using image-level labels and Grad-CAM explanations. Evaluates seven ImageNet-pretrained architectures (ResNet-18/50, DenseNet-121, EfficientNet-B0, MobileNet-V2/V3, ViT-B16) under identical training settings with focal loss and patient-wise splits to prevent data leakage.", "result": "Best overall test accuracy 98%, ROC-AUC 0.997, F1 0.987 achieved by ResNet-18 and EfficientNet-B0. MobileNet-V2 offers a good accuracy/cost trade-off. Grad-CAM heatmaps show attention to clinically relevant lung regions.", "conclusion": "Weakly supervised explainable models can enhance pneumonia screening transparency and clinical trust in AI-assisted radiology, demonstrating potential for interpretable pneumonia detection without pixel-level annotations."}}
{"id": "2511.01472", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01472", "abs": "https://arxiv.org/abs/2511.01472", "authors": ["Sarthak Mishra", "Rishabh Dev Yadav", "Avirup Das", "Saksham Gupta", "Wei Pan", "Spandan Roy"], "title": "AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models", "comment": null, "summary": "The rapid progress of vision--language models (VLMs) has sparked growing\ninterest in robotic control, where natural language can express the operation\ngoals while visual feedback links perception to action. However, directly\ndeploying VLM-driven policies on aerial manipulators remains unsafe and\nunreliable since the generated actions are often inconsistent,\nhallucination-prone, and dynamically infeasible for flight. In this work, we\npresent AERMANI-VLM, the first framework to adapt pretrained VLMs for aerial\nmanipulation by separating high-level reasoning from low-level control, without\nany task-specific fine-tuning. Our framework encodes natural language\ninstructions, task context, and safety constraints into a structured prompt\nthat guides the model to generate a step-by-step reasoning trace in natural\nlanguage. This reasoning output is used to select from a predefined library of\ndiscrete, flight-safe skills, ensuring interpretable and temporally consistent\nexecution. By decoupling symbolic reasoning from physical action, AERMANI-VLM\nmitigates hallucinated commands and prevents unsafe behavior, enabling robust\ntask completion. We validate the framework in both simulation and hardware on\ndiverse multi-step pick-and-place tasks, demonstrating strong generalization to\npreviously unseen commands, objects, and environments.", "AI": {"tldr": "AERMANI-VLM decouples high-level reasoning from low-level flight control by using structured prompts to translate VLM outputs into a library of flight-safe skills, enabling safe, interpretable aerial manipulation without task-specific fine-tuning.", "motivation": "Vision\u2013language models offer flexible control via natural language but often produce unsafe, hallucinated, or dynamically infeasible actions when applied to aerial robots. There is a need to ground VLM reasoning in safe, verifiable control at the servo level while preserving generalization to new tasks and commands.", "method": "The approach encodes instructions, task context, and safety constraints into a structured prompt that elicits a step-by-step natural-language reasoning trace from a pretrained VLM. This reasoning is then used to select from a predefined library of discrete, flight-safe skills, ensuring interpretable and temporally consistent execution. By decoupling symbolic reasoning from physical action, the framework mitigates hallucinations and unsafe behavior without fine-tuning the model on task data.", "result": "Demonstrated robustness on diverse multi-step pick-and-place tasks in both simulation and hardware, with strong generalization to unseen commands, objects, and environments.", "conclusion": "Decoupling high-level reasoning from low-level control with a structured prompt and a safe skill library yields safer, more interpretable, and generalizable aerial manipulation using pretrained VLMs; the approach avoids task-specific fine-tuning but relies on a comprehensive skill library and may face limits in real-time performance and coverage of safe actions."}}
{"id": "2511.00209", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.00209", "abs": "https://arxiv.org/abs/2511.00209", "authors": ["Yiquan Wang", "Yahui Ma", "Yuhan Chang", "Jiayao Yan", "Jialin Zhang", "Minnuo Cai", "Kai Wei"], "title": "Diffusion Models at the Drug Discovery Frontier: A Review on Generating Small Molecules versus Therapeutic Peptides", "comment": "21 pages, 3 figures", "summary": "Diffusion models have emerged as a leading framework in generative modeling,\nshowing significant potential to accelerate and transform the traditionally\nslow and costly process of drug discovery. This review provides a systematic\ncomparison of their application in designing two principal therapeutic\nmodalities: small molecules and therapeutic peptides. We analyze how a unified\nframework of iterative denoising is adapted to the distinct molecular\nrepresentations, chemical spaces, and design objectives of each modality. For\nsmall molecules, these models excel at structure-based design, generating\nnovel, pocket-fitting ligands with desired physicochemical properties, yet face\nthe critical hurdle of ensuring chemical synthesizability. Conversely, for\ntherapeutic peptides, the focus shifts to generating functional sequences and\ndesigning de novo structures, where the primary challenges are achieving\nbiological stability against proteolysis, ensuring proper folding, and\nminimizing immunogenicity. Despite these distinct challenges, both domains face\nshared hurdles: the need for more accurate scoring functions, the scarcity of\nhigh-quality experimental data, and the crucial requirement for experimental\nvalidation. We conclude that the full potential of diffusion models will be\nunlocked by bridging these modality-specific gaps and integrating them into\nautomated, closed-loop Design-Build-Test-Learn (DBTL) platforms, thereby\nshifting the paradigm from chemical exploration to the targeted creation of\nnovel therapeutics.", "AI": {"tldr": "Diffusion models offer a unified iterative denoising framework for designing two major therapeutic modalities\u2014small molecules and therapeutic peptides\u2014yet face modality-specific challenges (synthesizability for small molecules; stability, folding, and immunogenicity for peptides) and shared issues (scoring accuracy, data scarcity, and need for experimental validation). The authors advocate a closed-loop DBTL integration to unlock the full potential by bridging modality-specific gaps.", "motivation": "To systematically compare diffusion-model applications in drug design across two principal modalities, identifying common opportunities and modality-specific hurdles to guide future DBTL-enabled development.", "method": "Perform a structured review that analyzes how a unified iterative denoising framework is adapted to distinct molecular representations, chemical spaces, and design objectives for small molecules and therapeutic peptides, examining structure-based design, sequence/structure generation, and the associated challenges and needs.", "result": "Small molecules: diffusion models excel at structure-based design, generating novel, pocket-fitting ligands with desired physicochemical properties, but synthesizability remains a critical obstacle. Therapeutic peptides: focus shifts to generating functional sequences and de novo structures, with challenges in biological stability against proteolysis, proper folding, and minimizing immunogenicity. Shared hurdles across modalities include the need for more accurate scoring functions, scarcity of high-quality experimental data, and the necessity of experimental validation.", "conclusion": "Unlocking diffusion models\u2019 full potential requires bridging modality-specific gaps and integrating them into automated, closed-loop Design-Build-Test-Learn (DBTL) platforms, enabling a shift from broad chemical exploration to targeted creation of novel therapeutics."}}
{"id": "2511.01639", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01639", "abs": "https://arxiv.org/abs/2511.01639", "authors": ["Sicheng Wang", "Shuhao Chen", "Jingran Zhou", "Chengyi Tu"], "title": "IVGAE-TAMA-BO: A novel temporal dynamic variational graph model for link prediction in global food trade networks with momentum structural memory and Bayesian optimization", "comment": "26pages,6figures", "summary": "Global food trade plays a crucial role in ensuring food security and\nmaintaining supply chain stability. However, its network structure evolves\ndynamically under the influence of geopolitical, economic, and environmental\nfactors, making it challenging to model and predict future trade links.\nEffectively capturing temporal patterns in food trade networks is therefore\nessential for improving the accuracy and robustness of link prediction. This\nstudy introduces IVGAE-TAMA-BO, a novel dynamic graph neural network designed\nto model evolving trade structures and predict future links in global food\ntrade networks. To the best of our knowledge, this is the first work to apply\ndynamic graph neural networks to this domain, significantly enhancing\npredictive performance. Building upon the original IVGAE framework, the\nproposed model incorporates a Trade-Aware Momentum Aggregator (TAMA) to capture\nthe temporal evolution of trade networks, jointly modeling short-term\nfluctuations and long-term structural dependencies. A momentum-based structural\nmemory mechanism further improves predictive stability and performance. In\naddition, Bayesian optimization is used to automatically tune key\nhyperparameters, enhancing generalization across diverse trade scenarios.\nExtensive experiments on five crop-specific datasets demonstrate that\nIVGAE-TAMA substantially outperforms the static IVGAE and other dynamic\nbaselines by effectively modeling temporal dependencies, while Bayesian\noptimization further boosts performance in IVGAE-TAMA-BO. These results\nhighlight the proposed framework as a robust and scalable solution for\nstructural prediction in global trade networks, with strong potential for\napplications in food security monitoring and policy decision support.", "AI": {"tldr": "IVGAE-TAMA-BO is a dynamic GNN for predicting future links in global food trade networks, leveraging a Trade-Aware Momentum Aggregator and momentum-based memory, with Bayesian optimization to tune hyperparameters; it outperforms static IVGAE and other dynamic baselines across five crop datasets.", "motivation": "Global food trade networks are highly dynamic under geopolitical, economic, and environmental pressures. Static models struggle to capture evolving temporal patterns essential for accurate link prediction and food-security monitoring.", "method": "Extend the IVGAE framework with a Trade-Aware Momentum Aggregator (TAMA) to model short-term fluctuations and long-term structural dependencies, incorporate a momentum-based structural memory for stability, and use Bayesian optimization to automatically tune key hyperparameters. Evaluate on five crop-specific datasets against static IVGAE and other dynamic baselines.", "result": "IVGAE-TAMA substantially outperforms the static IVGAE and other dynamic baselines by effectively modeling temporal dependencies. The Bayesian-optimized version, IVGAE-TAMA-BO, yields further performance gains.", "conclusion": "The proposed framework provides a robust and scalable solution for structural prediction in global trade networks, with strong potential for food security monitoring and policy decision support."}}
{"id": "2511.00468", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00468", "abs": "https://arxiv.org/abs/2511.00468", "authors": ["Panwang Pan", "Tingting Shen", "Chenxin Li", "Yunlong Lin", "Kairun Wen", "Jingjing Zhao", "Yixuan Yuan"], "title": "HumanCrafter: Synergizing Generalizable Human Reconstruction and Semantic 3D Segmentation", "comment": "Accepted to NeurIPS 2025; Project page: [this\n  URL](https://paulpanwang.github.io/HumanCrafter)", "summary": "Recent advances in generative models have achieved high-fidelity in 3D human\nreconstruction, yet their utility for specific tasks (e.g., human 3D\nsegmentation) remains constrained. We propose HumanCrafter, a unified framework\nthat enables the joint modeling of appearance and human-part semantics from a\nsingle image in a feed-forward manner. Specifically, we integrate human\ngeometric priors in the reconstruction stage and self-supervised semantic\npriors in the segmentation stage. To address labeled 3D human datasets\nscarcity, we further develop an interactive annotation procedure for generating\nhigh-quality data-label pairs. Our pixel-aligned aggregation enables cross-task\nsynergy, while the multi-task objective simultaneously optimizes texture\nmodeling fidelity and semantic consistency. Extensive experiments demonstrate\nthat HumanCrafter surpasses existing state-of-the-art methods in both 3D\nhuman-part segmentation and 3D human reconstruction from a single image.", "AI": {"tldr": "HumanCrafter is a single-image framework that jointly models appearance and human-part semantics for 3D reconstruction and segmentation, using geometric priors, self-supervised semantics, and interactive labeling to achieve state-of-the-art results.", "motivation": "3D human reconstruction and segmentation are powerful but hampered by scarce labeled 3D data and the need to unify appearance and semantics. A single-image, multi-task approach with priors and data-efficient labeling can improve performance and practicality.", "method": "A unified, feed-forward framework (HumanCrafter) that (1) injects geometric priors into 3D reconstruction, (2) exploits self-supervised semantic priors for segmentation, (3) uses an interactive annotation procedure to generate high-quality data-label pairs, and (4) employs pixel-aligned aggregation for cross-task synergy and a multi-task objective to optimize texture fidelity and semantic consistency.", "result": "Extensive experiments show HumanCrafter surpasses state-of-the-art methods in both 3D human-part segmentation and 3D reconstruction from a single image.", "conclusion": "Joint modeling of appearance and semantics with priors and interactive data generation enables effective cross-task synergy, yielding superior single-image 3D reconstruction and segmentation performance."}}
{"id": "2511.01476", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01476", "abs": "https://arxiv.org/abs/2511.01476", "authors": ["Cankut Bora Tuncer", "Marc Toussaint", "Ozgur S. Oguz"], "title": "MO-SeGMan: Rearrangement Planning Framework for Multi Objective Sequential and Guided Manipulation in Constrained Environments", "comment": "8 pages, 8 figures, website:https://sites.google.com/view/mo-segman/", "summary": "In this work, we introduce MO-SeGMan, a Multi-Objective Sequential and Guided\nManipulation planner for highly constrained rearrangement problems. MO-SeGMan\ngenerates object placement sequences that minimize both replanning per object\nand robot travel distance while preserving critical dependency structures with\na lazy evaluation method. To address highly cluttered, non-monotone scenarios,\nwe propose a Selective Guided Forward Search (SGFS) that efficiently relocates\nonly critical obstacles and to feasible relocation points. Furthermore, we\nadopt a refinement method for adaptive subgoal selection to eliminate\nunnecessary pick-and-place actions, thereby improving overall solution quality.\nExtensive evaluations on nine benchmark rearrangement tasks demonstrate that\nMO-SeGMan generates feasible motion plans in all cases, consistently achieving\nfaster solution times and superior solution quality compared to the baselines.\nThese results highlight the robustness and scalability of the proposed\nframework for complex rearrangement planning problems.", "AI": {"tldr": "MO-SeGMan is a multi-objective planner for highly constrained rearrangements that minimizes replanning and travel distance, using lazy evaluation to preserve dependencies. It introduces SGFS to relocate only critical obstacles and an adaptive subgoal refinement to cut unnecessary actions. Evaluations on nine benchmarks show feasible plans, faster solution times, and better quality than baselines.", "motivation": "Address the challenge of highly cluttered, non-monotone rearrangement problems by providing a robust, scalable planning framework that reduces replanning, minimizes robot travel, and respects important dependency structures.", "method": "Proposes MO-SeGMan, a Multi-Objective Sequential and Guided Manipulation planner. Key components include (1) lazy evaluation to preserve dependency structures, (2) Selective Guided Forward Search (SGFS) that relocates only critical obstacles to feasible points, and (3) an adaptive subgoal refinement method to eliminate unnecessary pick-and-place actions. Evaluations on nine benchmark tasks compare against baselines.", "result": "MO-SeGMan consistently finds feasible motion plans in all tasks, with faster solution times and superior solution quality compared to baselines.", "conclusion": "The framework is robust and scalable for complex rearrangement planning problems, effectively handling highly constrained and cluttered environments."}}
{"id": "2511.00220", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00220", "abs": "https://arxiv.org/abs/2511.00220", "authors": ["Pouya M. Ghari", "Simone Sciabola", "Ye Wang"], "title": "Iterative Foundation Model Fine-Tuning on Multiple Rewards", "comment": "Accepted to NeurIPS 2025", "summary": "Fine-tuning foundation models has emerged as a powerful approach for\ngenerating objects with specific desired properties. Reinforcement learning\n(RL) provides an effective framework for this purpose, enabling models to\ngenerate outputs that maximize a given reward function. However, in many\napplications such as text generation and drug discovery, it can be suboptimal\nto optimize using a single reward signal, as multiple evaluation criteria are\noften necessary. This paper proposes a novel reinforcement learning-based\nmethod for fine-tuning foundation models using multiple reward signals. By\nemploying an iterative fine-tuning strategy across these rewards, our approach\ngeneralizes state-of-the-art RL-based methods. We further provide a theoretical\nanalysis that offers insights into the performance of multi-reward RL\nfine-tuning. Experimental results across diverse domains including text,\nbiological sequence, and small molecule generation, demonstrate the\neffectiveness of the proposed algorithm compared to state-of-the-art baselines.", "AI": {"tldr": "A multi-reward reinforcement learning framework for fine-tuning foundation models, using an iterative strategy to optimize several reward signals; shows theoretical insights and empirical gains across text, biological sequences, and small-molecule generation over state-of-the-art baselines.", "motivation": "Real-world applications often require balancing multiple evaluation criteria; optimizing a single reward can be suboptimal for tasks like text generation and drug design.", "method": "An iterative fine-tuning algorithm that optimizes multiple reward signals via reinforcement learning, alternating or cycling through rewards; includes a theoretical analysis of multi-reward RL and generalizes existing RL-based fine-tuning methods.", "result": "Empirical results across diverse domains (text, biological sequences, small molecules) demonstrate improvements over state-of-the-art baselines.", "conclusion": "The proposed multi-reward RL fine-tuning approach is effective and theoretically motivated, offering a general framework for aligning foundation models with multiple objectives."}}
{"id": "2511.01668", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01668", "abs": "https://arxiv.org/abs/2511.01668", "authors": ["Yueqing Xi", "Yifan Bai", "Huasen Luo", "Weiliang Wen", "Hui Liu", "Haoliang Li"], "title": "Hybrid Retrieval-Augmented Generation Agent for Trustworthy Legal Question Answering in Judicial Forensics", "comment": null, "summary": "As artificial intelligence permeates judicial forensics, ensuring the\nveracity and traceability of legal question answering (QA) has become critical.\nConventional large language models (LLMs) are prone to hallucination, risking\nmisleading guidance in legal consultation, while static knowledge bases\nstruggle to keep pace with frequently updated statutes and case law. We present\na hybrid legal QA agent tailored for judicial settings that integrates\nretrieval-augmented generation (RAG) with multi-model ensembling to deliver\nreliable, auditable, and continuously updatable counsel. The system prioritizes\nretrieval over generation: when a trusted legal repository yields relevant\nevidence, answers are produced via RAG; otherwise, multiple LLMs generate\ncandidates that are scored by a specialized selector, with the top-ranked\nanswer returned. High-quality outputs then undergo human review before being\nwritten back to the repository, enabling dynamic knowledge evolution and\nprovenance tracking. Experiments on the Law\\_QA dataset show that our hybrid\napproach significantly outperforms both a single-model baseline and a vanilla\nRAG pipeline on F1, ROUGE-L, and an LLM-as-a-Judge metric. Ablations confirm\nthe complementary contributions of retrieval prioritization, model ensembling,\nand the human-in-the-loop update mechanism. The proposed system demonstrably\nreduces hallucination while improving answer quality and legal compliance,\nadvancing the practical landing of media forensics technologies in judicial\nscenarios.", "AI": {"tldr": "A hybrid legal QA system combining retrieval-augmented generation, multi-model ensembling, and human-in-the-loop to deliver reliable, updatable, and auditable legal answers, outperforming baselines and reducing hallucination.", "motivation": "LLMs are prone to hallucination in legal QA and static knowledge bases struggle to keep up with evolving statutes and case law; there is a need for an auditable, continuously updatable, and legally compliant QA system for judicial settings.", "method": "A retrieval-first pipeline: when a trusted legal repository yields relevant evidence, answers are produced via retrieval-augmented generation (RAG). If not, multiple LLMs generate candidates that are scored by a specialized selector, with the top-ranked answer returned. High-quality outputs undergo human review before being written back to the repository, enabling provenance tracking and dynamic knowledge evolution. Evaluation on Law_QA shows improvements over single-model baselines and vanilla RAG. Ablations demonstrate the impact of retrieval prioritization, model ensembling, and the human-in-the-loop update mechanism.", "result": "The hybrid approach significantly outperforms both a single-model baseline and a vanilla RAG pipeline in F1, ROUGE-L, and an LLM-as-a-Judge metric on Law_QA. Ablations confirm complementary contributions of retrieval prioritization, model ensembling, and human-in-the-loop updates, and indicate reduced hallucination and improved legal compliance.", "conclusion": "This work demonstrates the practical viability of combining retrieval, multi-model ensembling, and human-in-the-loop updates to produce auditable, updatable legal QA, supporting the deployment of media-forensics-informed judicial QA systems."}}
{"id": "2511.00472", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00472", "abs": "https://arxiv.org/abs/2511.00472", "authors": ["Navodini Wijethilake", "Marina Ivory", "Oscar MacCormac", "Siddhant Kumar", "Aaron Kujawa", "Lorena Garcia-Foncillas Macias", "Rebecca Burger", "Amanda Hitchings", "Suki Thomson", "Sinan Barazi", "Eleni Maratos", "Rupert Obholzer", "Dan Jiang", "Fiona McClenaghan", "Kazumi Chia", "Omar Al-Salihi", "Nick Thomas", "Steve Connor", "Tom Vercauteren", "Jonathan Shapey"], "title": "Longitudinal Vestibular Schwannoma Dataset with Consensus-based Human-in-the-loop Annotations", "comment": null, "summary": "Accurate segmentation of vestibular schwannoma (VS) on Magnetic Resonance\nImaging (MRI) is essential for patient management but often requires\ntime-intensive manual annotations by experts. While recent advances in deep\nlearning (DL) have facilitated automated segmentation, challenges remain in\nachieving robust performance across diverse datasets and complex clinical\ncases. We present an annotated dataset stemming from a bootstrapped DL-based\nframework for iterative segmentation and quality refinement of VS in MRI. We\ncombine data from multiple centres and rely on expert consensus for\ntrustworthiness of the annotations. We show that our approach enables effective\nand resource-efficient generalisation of automated segmentation models to a\ntarget data distribution. The framework achieved a significant improvement in\nsegmentation accuracy with a Dice Similarity Coefficient (DSC) increase from\n0.9125 to 0.9670 on our target internal validation dataset, while maintaining\nstable performance on representative external datasets. Expert evaluation on\n143 scans further highlighted areas for model refinement, revealing nuanced\ncases where segmentation required expert intervention. The proposed approach is\nestimated to enhance efficiency by approximately 37.4% compared to the\nconventional manual annotation process. Overall, our human-in-the-loop model\ntraining approach achieved high segmentation accuracy, highlighting its\npotential as a clinically adaptable and generalisable strategy for automated VS\nsegmentation in diverse clinical settings. The dataset includes 190 patients,\nwith tumour annotations available for 534 longitudinal contrast-enhanced\nT1-weighted (T1CE) scans from 184 patients, and non-annotated T2-weighted scans\nfrom 6 patients. This dataset is publicly accessible on The Cancer Imaging\nArchive (TCIA) (https://doi.org/10.7937/bq0z-xa62).", "AI": {"tldr": "A multi-centre, bootstrapped, human-in-the-loop framework for automated vestibular schwannoma segmentation in MRI, achieving DSC 0.967 on internal validation and promising generalisation, with a 37.4% efficiency gain and a public dataset release on TCIA.", "motivation": "Accurate VS segmentation in MRI is essential for patient management but relies on time-consuming expert annotations; robust, generalisable models are needed across diverse clinical data.", "method": "A bootstrapped DL-based iterative segmentation framework with expert consensus for quality refinement (human-in-the-loop). Data pooled from multiple centres. Public release of the dataset via TCIA. Evaluation includes internal target validation with external datasets and expert review on 143 scans.", "result": "Dice similarity coefficient improved from 0.9125 to 0.9670 on the target internal validation dataset; stable performance on representative external datasets; expert evaluation identified areas requiring intervention; estimated ~37.4% efficiency gain vs manual annotation; dataset comprises 190 patients with 534 annotated T1CE scans from 184 patients and 6 non-annotated T2 scans (public on TCIA).", "conclusion": "The proposed human-in-the-loop, multi-centre framework achieves high segmentation accuracy and good generalisability, offering a clinically adaptable approach for automated VS segmentation and highlighting the value of public datasets for benchmarking."}}
{"id": "2511.01493", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01493", "abs": "https://arxiv.org/abs/2511.01493", "authors": ["Wei Huang", "Jiaxin Li", "Zang Wan", "Huijun Di", "Wei Liang", "Zhu Yang"], "title": "Floor Plan-Guided Visual Navigation Incorporating Depth and Directional Cues", "comment": null, "summary": "Guiding an agent to a specific target in indoor environments based solely on\nRGB inputs and a floor plan is a promising yet challenging problem. Although\nexisting methods have made significant progress, two challenges remain\nunresolved. First, the modality gap between egocentric RGB observations and the\nfloor plan hinders the integration of visual and spatial information for both\nlocal obstacle avoidance and global planning. Second, accurate localization is\ncritical for navigation performance, but remains challenging at deployment in\nunseen environments due to the lack of explicit geometric alignment between RGB\ninputs and floor plans. We propose a novel diffusion-based policy, denoted as\nGlocDiff, which integrates global path planning from the floor plan with local\ndepth-aware features derived from RGB observations. The floor plan offers\nexplicit global guidance, while the depth features provide implicit geometric\ncues, collectively enabling precise prediction of optimal navigation directions\nand robust obstacle avoidance. Moreover, GlocDiff introduces noise perturbation\nduring training to enhance robustness against pose estimation errors, and we\nfind that combining this with a relatively stable VO module during inference\nresults in significantly improved navigation performance. Extensive experiments\non the FloNa benchmark demonstrate GlocDiff's efficiency and effectiveness in\nachieving superior navigation performance, and the success of real-world\ndeployments also highlights its potential for widespread practical\napplications.", "AI": {"tldr": "A diffusion-based policy (GlocDiff) combines floor-plan-guided global path planning with depth-aware RGB features to guide indoor navigation, addressing modality gaps and localization in unseen environments, with training-time noise and stable VO at inference, achieving strong FloNa results and real-world deployments.", "motivation": "Bridge the modality gap between egocentric RGB observations and floor plans and improve localization in unseen environments where explicit RGB-floor-plan alignment is lacking, enabling robust obstacle avoidance and global planning.", "method": "GlocDiff is a diffusion-based policy that fuses global path planning from a floor plan with local depth-aware features derived from RGB observations; introduces noise perturbation during training to improve robustness to pose estimation errors and relies on a relatively stable VO module during inference.", "result": "On FloNa, GlocDiff demonstrates superior navigation performance and robustness; real-world deployments validate practical effectiveness and efficiency.", "conclusion": "Diffusion-based policies that integrate explicit floor-plan guidance with local geometric cues offer a promising route for reliable indoor navigation in RGB-only and floor-plan-guided settings, with potential for broad real-world deployment."}}
{"id": "2511.00246", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00246", "abs": "https://arxiv.org/abs/2511.00246", "authors": ["Wadduwage Shanika Perera", "ABM Islam", "Van Vung Pham", "Min Kyung An"], "title": "Melanoma Classification Through Deep Ensemble Learning and Explainable AI", "comment": "Publisher-formatted version provided under CC BY-NC-ND 4.0 license.\n  Original source produced by SciTePress", "summary": "Melanoma is one of the most aggressive and deadliest skin cancers, leading to\nmortality if not detected and treated in the early stages. Artificial\nintelligence techniques have recently been developed to help dermatologists in\nthe early detection of melanoma, and systems based on deep learning (DL) have\nbeen able to detect these lesions with high accuracy. However, the entire\ncommunity must overcome the explainability limit to get the maximum benefit\nfrom DL for diagnostics in the healthcare domain. Because of the black box\noperation's shortcomings in DL models' decisions, there is a lack of\nreliability and trust in the outcomes. However, Explainable Artificial\nIntelligence (XAI) can solve this problem by interpreting the predictions of AI\nsystems. This paper proposes a machine learning model using ensemble learning\nof three state-of-the-art deep transfer Learning networks, along with an\napproach to ensure the reliability of the predictions by utilizing XAI\ntechniques to explain the basis of the predictions.", "AI": {"tldr": "An ensemble of three deep transfer learning networks for melanoma detection, augmented with Explainable AI (XAI) to explain predictions and improve reliability.", "motivation": "Melanoma is highly deadly; while DL can detect early signs, its black-box nature limits trust and adoption. XAI is proposed to interpret model decisions and enhance reliability in healthcare diagnostics.", "method": "Ensemble learning of three state-of-the-art deep transfer learning networks combined with XAI techniques to explain the basis of predictions and improve diagnostic reliability.", "result": "The abstract does not report empirical results; it presents a proposed framework rather than findings.", "conclusion": "The paper proposes a DL ensemble with XAI explanations to enhance reliability and interpretability in melanoma detection."}}
{"id": "2511.01824", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01824", "abs": "https://arxiv.org/abs/2511.01824", "authors": ["Yuetai Li", "Huseyin A Inan", "Xiang Yue", "Wei-Ning Chen", "Lukas Wutschitz", "Janardhan Kulkarni", "Radha Poovendran", "Robert Sim", "Saravan Rajmohan"], "title": "Simulating Environments with Reasoning Models for Agent Training", "comment": null, "summary": "LLM agents excel in compact environments requiring deep reasoning but remain\nbrittle when operating in broader, more complex contexts that demand robustness\nacross diverse tools and schemas. Building bespoke environments for training is\nheavy, brittle, and limits progress. In this paper, we demonstrate that LLMs\ncan simulate realistic environment feedback without access to actual testbed\ndata or APIs. Inspired by this capability, we propose two frameworks:\nSimia-SFT, a pipeline that synthesizes SFT data by amplifying small seed sets\ninto diverse trajectories in an environment-agnostic manner, and Simia-RL, a\nframework that enables RL training without real environment implementations\nthrough LLM-simulated feedback. Fine-tuning open models yields consistent\nimprovements across multiple benchmarks, surpassing GPT-4o and approaching\no4-mini on $\\tau^2$-Bench. Together, Simia-SFT and Simia-RL enable scalable\nagent training without environment engineering, replacing heavy and brittle\nimplementations with flexible LLM-based simulation.", "AI": {"tldr": "Simia-SFT and Simia-RL enable scalable LLM agent training by simulating environment feedback, removing the need for real testbeds; open-model fine-tuning improves performance on benchmarks.", "motivation": "LLM agents are brittle in complex contexts and rely on heavy, brittle environment engineering; there is a need to train robust agents without real environment data or APIs.", "method": "Simia-SFT synthesizes SFT data by amplifying small seed sets into diverse trajectories in an environment-agnostic way. Simia-RL uses LLM-simulated feedback to train agents through RL without actual environment implementations.", "result": "Fine-tuning open models yields consistent improvements across benchmarks, surpassing GPT-4o and approaching o4-mini on tau^2-Bench.", "conclusion": "The two frameworks together enable scalable agent training without environment engineering, substituting real environments with flexible LLM-based simulation."}}
{"id": "2511.00480", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00480", "abs": "https://arxiv.org/abs/2511.00480", "authors": ["Weihao Bo", "Yanpeng Sun", "Yu Wang", "Xinyu Zhang", "Zechao Li"], "title": "FedMGP: Personalized Federated Learning with Multi-Group Text-Visual Prompts", "comment": null, "summary": "In this paper, we introduce FedMGP, a new paradigm for personalized federated\nprompt learning in vision-language models. FedMGP equips each client with\nmultiple groups of paired textual and visual prompts, enabling the model to\ncapture diverse, fine-grained semantic and instance-level cues. A diversity\nloss is introduced to drive each prompt group to specialize in distinct and\ncomplementary semantic aspects, ensuring that the groups collectively cover a\nbroader range of local characteristics. During communication, FedMGP employs a\ndynamic prompt aggregation strategy based on similarity-guided probabilistic\nsampling: each client computes the cosine similarity between its prompt groups\nand the global prompts from the previous round, then samples s groups via a\nsoftmax-weighted distribution. This soft selection mechanism preferentially\naggregates semantically aligned knowledge while still enabling exploration of\nunderrepresented patterns effectively balancing the preservation of common\nknowledge with client-specific features. Notably, FedMGP maintains parameter\nefficiency by redistributing a fixed prompt capacity across multiple groups,\nachieving state-of-the-art performance with the lowest communication parameters\namong all federated prompt learning methods. Theoretical analysis shows that\nour dynamic aggregation strategy promotes robust global representation learning\nby reinforcing shared semantics while suppressing client-specific noise.\nExtensive experiments demonstrate that FedMGP consistently outperforms prior\napproaches in both personalization and domain generalization across diverse\nfederated vision-language benchmarks. The code will be released on\nhttps://github.com/weihao-bo/FedMGP.git.", "AI": {"tldr": "FedMGP introduces a federated vision-language prompting framework where each client maintains multiple groups of prompts. A diversity loss encourages specialization across groups, and a similarity-guided probabilistic sampling strategy dynamically aggregates prompts from the global model. This design improves personalization and domain generalization while keeping communication efficient, achieving state-of-the-art results with minimal parameters.", "motivation": "Personalized federated learning for vision-language models is challenged by heterogeneous data and the need to capture diverse local semantics. Prior prompt-based FL methods may over-consolidate knowledge or be inefficient in communication. FedMGP aims to distribute a fixed prompt capacity across multiple groups to capture fine-grained, local cues while maintaining global coherence and efficiency.", "method": "Each client maintains multiple groups of paired textual and visual prompts. A diversity loss drives each group to specialize in distinct semantic aspects. During communication, clients compute cosine similarities between their prompt groups and the global prompts from the previous round and perform softmax-weighted sampling to select s groups for aggregation, enabling exploration of underrepresented patterns. A fixed total prompt capacity is redistributed across groups to ensure parameter efficiency. The paper also offers a theoretical analysis showing that dynamic aggregation reinforces shared semantics and suppresses client-specific noise.", "result": "Empirical results show FedMGP consistently outperforms prior approaches in both personalization and domain generalization across diverse federated vision-language benchmarks, while using the lowest communication parameters among federated prompt learning methods.", "conclusion": "FedMGP provides an effective, efficient framework for personalized FL in vision-language models by combining diverse, specialized prompt groups with a dynamic, similarity-guided aggregation scheme, balancing common knowledge with client-specific features and achieving strong performance with minimal communication overhead."}}
{"id": "2511.01520", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01520", "abs": "https://arxiv.org/abs/2511.01520", "authors": ["Shipeng Lyu", "Lijie Sheng", "Fangyuan Wang", "Wenyao Zhang", "Weiwei Lin", "Zhenzhong Jia", "David Navarro-Alarcon", "Guodong Guo"], "title": "Phy-Tac: Toward Human-Like Grasping via Physics-Conditioned Tactile Goals", "comment": "9 papges, 10 figures, 3 tables", "summary": "Humans naturally grasp objects with minimal level required force for\nstability, whereas robots often rely on rigid, over-squeezing control. To\nnarrow this gap, we propose a human-inspired physics-conditioned tactile method\n(Phy-Tac) for force-optimal stable grasping (FOSG) that unifies pose selection,\ntactile prediction, and force regulation. A physics-based pose selector first\nidentifies feasible contact regions with optimal force distribution based on\nsurface geometry. Then, a physics-conditioned latent diffusion model (Phy-LDM)\npredicts the tactile imprint under FOSG target. Last, a latent-space LQR\ncontroller drives the gripper toward this tactile imprint with minimal\nactuation, preventing unnecessary compression. Trained on a physics-conditioned\ntactile dataset covering diverse objects and contact conditions, the proposed\nPhy-LDM achieves superior tactile prediction accuracy, while the Phy-Tac\noutperforms fixed-force and GraspNet-based baselines in grasp stability and\nforce efficiency. Experiments on classical robotic platforms demonstrate\nforce-efficient and adaptive manipulation that bridges the gap between robotic\nand human grasping.", "AI": {"tldr": "Human-inspired physics-conditioned tactile framework for force-optimal stable grasping (Phy-Tac) that unifies pose selection, tactile prediction via Phy-LDM, and a latent-space LQR to achieve stable, force-efficient grasps.", "motivation": "Robots typically rely on rigid, excessive squeezing; bridging the gap to human-like finesse by integrating physics-based pose selection, tactile prediction, and force control to improve stability and minimize contacts/actuation.", "method": "1) physics-based pose selector identifies feasible contact regions and optimal force distribution from surface geometry; 2) physics-conditioned latent diffusion model (Phy-LDM) predicts tactile imprint for the FOSG target; 3) latent-space LQR controller drives gripper toward the tactile imprint with minimal actuation; training on a physics-conditioned tactile dataset; evaluation on robotic platforms.", "result": "Phy-LDM achieves superior tactile prediction accuracy; Phy-Tac outperforms fixed-force and GraspNet baselines in grasp stability and force efficiency; experiments show force-efficient, adaptive manipulation bridging gap between robotic and human grasping.", "conclusion": "A unified physics-conditioned tactile framework enables force-optimal stable grasping by combining pose selection, tactile prediction, and minimal-actuation control; demonstrates improved stability and efficiency across objects and contact conditions."}}
{"id": "2511.00257", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00257", "abs": "https://arxiv.org/abs/2511.00257", "authors": ["Zachary Chase", "Shinji Ito", "Idan Mehalel"], "title": "A Tight Lower Bound for Non-stochastic Multi-armed Bandits with Expert Advice", "comment": null, "summary": "We determine the minimax optimal expected regret in the classic\nnon-stochastic multi-armed bandit with expert advice problem, by proving a\nlower bound that matches the upper bound of Kale (2014). The two bounds\ndetermine the minimax optimal expected regret to be $\\Theta\\left( \\sqrt{T K\n\\log (N/K) } \\right)$, where $K$ is the number of arms, $N$ is the number of\nexperts, and $T$ is the time horizon.", "AI": {"tldr": "The minimax optimal expected regret in the non-stochastic multi-armed bandit with expert advice is \u0398(\u221a(T K log(N/K))). A matching lower bound to Kale (2014) upper bound is established.", "motivation": "To establish a tight, minimax regret rate for the non-stochastic bandit with expert advice problem and clarify how regret scales with the number of arms K, experts N, and horizon T.", "method": "Derive a minimax lower bound that matches the known upper bound of Kale (2014), using standard adversarial construction and information-theoretic arguments to show no algorithm can beat \u0398(\u221a(T K log(N/K))).", "result": "The minimax optimal expected regret is \u0398(\u221a(T K log(N/K))).", "conclusion": "The upper bound from Kale (2014) is tight; the minimax rate for this problem is fully characterized by \u0398(\u221a(T K log(N/K)))."}}
{"id": "2511.00503", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00503", "abs": "https://arxiv.org/abs/2511.00503", "authors": ["Panwang Pan", "Chenguo Lin", "Jingjing Zhao", "Chenxin Li", "Yuchen Lin", "Haopeng Li", "Honglei Yan", "Kairun Wen", "Yunlong Lin", "Yixuan Yuan", "Yadong Mu"], "title": "Diff4Splat: Controllable 4D Scene Generation with Latent Dynamic Reconstruction Models", "comment": null, "summary": "We introduce Diff4Splat, a feed-forward method that synthesizes controllable\nand explicit 4D scenes from a single image. Our approach unifies the generative\npriors of video diffusion models with geometry and motion constraints learned\nfrom large-scale 4D datasets. Given a single input image, a camera trajectory,\nand an optional text prompt, Diff4Splat directly predicts a deformable 3D\nGaussian field that encodes appearance, geometry, and motion, all in a single\nforward pass, without test-time optimization or post-hoc refinement. At the\ncore of our framework lies a video latent transformer, which augments video\ndiffusion models to jointly capture spatio-temporal dependencies and predict\ntime-varying 3D Gaussian primitives. Training is guided by objectives on\nappearance fidelity, geometric accuracy, and motion consistency, enabling\nDiff4Splat to synthesize high-quality 4D scenes in 30 seconds. We demonstrate\nthe effectiveness of Diff4Splatacross video generation, novel view synthesis,\nand geometry extraction, where it matches or surpasses optimization-based\nmethods for dynamic scene synthesis while being significantly more efficient.", "AI": {"tldr": "Diff4Splat enables fast, controllable 4D scene synthesis from a single image in one forward pass by predicting deformable 3D Gaussian fields with a video latent transformer, achieving 30-second generation without test-time optimization while matching or surpassing optimization-based methods.", "motivation": "To bridge generative priors from video diffusion models with geometric and motion constraints learned from large 4D datasets, enabling realistic, controllable dynamic scenes from a single image without expensive optimization.", "method": "A feed-forward approach that, given a single image, a camera trajectory, and an optional text prompt, predicts a deformable 3D Gaussian field encoding appearance, geometry, and motion. It uses a video latent transformer to capture spatio-temporal dependencies and predict time-varying 3D Gaussian primitives. Training optimizes appearance fidelity, geometric accuracy, and motion consistency.", "result": "Produces high-quality 4D scenes quickly (approx. 30 seconds) and can be used for video generation, novel view synthesis, and geometry extraction. It matches or surpasses optimization-based methods in quality while being significantly more efficient.", "conclusion": "Diff4Splat demonstrates that a single forward pass can synthesize controllable, geometry-aware dynamic scenes by unifying diffusion priors with explicit 3D representations, enabling efficient 4D content creation without test-time optimization."}}
{"id": "2511.01594", "categories": ["cs.RO", "cs.CV", "I.2.9; I.2.11; I.2.6; I.4.8"], "pdf": "https://arxiv.org/pdf/2511.01594", "abs": "https://arxiv.org/abs/2511.01594", "authors": ["Renjun Gao", "Peiyan Zhong"], "title": "MARS: Multi-Agent Robotic System with Multimodal Large Language Models for Assistive Intelligence", "comment": "3 figures, 1 table; under review at Multimedia Systems (Springer)", "summary": "Multimodal large language models (MLLMs) have shown remarkable capabilities\nin cross-modal understanding and reasoning, offering new opportunities for\nintelligent assistive systems, yet existing systems still struggle with\nrisk-aware planning, user personalization, and grounding language plans into\nexecutable skills in cluttered homes. We introduce MARS - a Multi-Agent Robotic\nSystem powered by MLLMs for assistive intelligence and designed for smart home\nrobots supporting people with disabilities. The system integrates four agents:\na visual perception agent for extracting semantic and spatial features from\nenvironment images, a risk assessment agent for identifying and prioritizing\nhazards, a planning agent for generating executable action sequences, and an\nevaluation agent for iterative optimization. By combining multimodal perception\nwith hierarchical multi-agent decision-making, the framework enables adaptive,\nrisk-aware, and personalized assistance in dynamic indoor environments.\nExperiments on multiple datasets demonstrate the superior overall performance\nof the proposed system in risk-aware planning and coordinated multi-agent\nexecution compared with state-of-the-art multimodal models. The proposed\napproach also highlights the potential of collaborative AI for practical\nassistive scenarios and provides a generalizable methodology for deploying\nMLLM-enabled multi-agent systems in real-world environments.", "AI": {"tldr": "A multi-agent robotic system (MARS) leverages multimodal large language models to deliver risk-aware, personalized assistive intelligence in smart homes, through four specialized agents (visual perception, risk assessment, planning, evaluation) enabling perception, evaluation, planning, and execution in dynamic indoor environments; it outperforms state-of-the-art multimodal models in risk-aware planning and coordinated multi-agent execution.", "motivation": "Assistive robots for people with disabilities require autonomous, safe, personalized, and robust operation in cluttered indoor environments. existing multimodal LLMs struggle with risk-aware planning, user personalization, and grounding language plans into executable skills.", "method": "Introduce MARS architecture comprising four agents: a visual perception agent that extracts semantic and spatial features from environment images; a risk assessment agent that identifies and prioritizes hazards; a planning agent that generates executable action sequences; and an evaluation agent that iteratively optimizes plans. The system uses hierarchical multi-agent decision-making to enable adaptive, risk-aware, and personalized assistance. Experiments on multiple datasets compare performance with state-of-the-art multimodal models.", "result": "MARS achieves superior performance in risk-aware planning and coordinated multi-agent execution compared with state-of-the-art multimodal models, demonstrating the feasibility and benefits of collaborative, MLLM-enabled multi-agent systems for practical assistive scenarios.", "conclusion": "The work highlights the potential of collaborative AI for assistive robotics in real-world homes and provides a generalizable methodology for deploying MLLM-enabled multi-agent systems in dynamic indoor environments; future work may focus on further grounding, personalization, and real-world deployment."}}
{"id": "2511.00266", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00266", "abs": "https://arxiv.org/abs/2511.00266", "authors": ["Aanchal Rajesh Chugh", "Marion Neumeier", "Sebastian Dorn"], "title": "X-TRACK: Physics-Aware xLSTM for Realistic Vehicle Trajectory Prediction", "comment": null, "summary": "Recent advancements in Recurrent Neural Network (RNN) architectures,\nparticularly the Extended Long Short Term Memory (xLSTM), have addressed the\nlimitations of traditional Long Short Term Memory (LSTM) networks by\nintroducing exponential gating and enhanced memory structures. These\nimprovements make xLSTM suitable for time-series prediction tasks as they\nexhibit the ability to model long-term temporal dependencies better than LSTMs.\nDespite their potential, these xLSTM-based models remain largely unexplored in\nthe context of vehicle trajectory prediction. Therefore, this paper introduces\na novel xLSTM-based vehicle trajectory prediction framework, X-TRAJ, and its\nphysics-aware variant, X-TRACK (eXtended LSTM for TRAjectory prediction\nConstraint by Kinematics), which explicitly integrates vehicle motion\nkinematics into the model learning process. By introducing physical\nconstraints, the proposed model generates realistic and feasible trajectories.\nA comprehensive evaluation on the highD and NGSIM datasets demonstrates that\nX-TRACK outperforms state-of-the-art baselines.", "AI": {"tldr": "Introduces xLSTM-based vehicle trajectory predictor X-TRAJ and physics-aware X-TRACK, integrating kinematics to produce realistic trajectories; shows X-TRACK outperforms baselines on highD and NGSIM.", "motivation": "LSTM variants have limitations in modeling long-term temporal dependencies; xLSTM's exponential gating and enhanced memory can better capture long-range patterns in time-series data. Vehicle trajectory prediction requires realistic, feasible paths that respect motion physics, motivating physics-informed constraints.", "method": "Develops X-TRAJ, an xLSTM-based framework for vehicle trajectory prediction, and a physics-aware variant X-TRACK that enforces motion-kinematics constraints during learning to ensure feasible trajectories. Evaluation uses the highD and NGSIM datasets to benchmark against state-of-the-art baselines.", "result": "Empirical evaluation shows X-TRACK outperforms state-of-the-art baselines on the highD and NGSIM trajectory datasets.", "conclusion": "Integrating physics-based constraints with xLSTM-based trajectory models improves realism and predictive accuracy, suggesting physics-informed xLSTM approaches are promising for traffic trajectory prediction."}}
{"id": "2511.00504", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00504", "abs": "https://arxiv.org/abs/2511.00504", "authors": ["Hai-Dang Nguyen", "Ha-Hieu Pham", "Hao T. Nguyen", "Huy-Hieu Pham"], "title": "VinDr-CXR-VQA: A Visual Question Answering Dataset for Explainable Chest X-Ray Analysis with Multi-Task Learning", "comment": "ISBI submission. Contains 5 pages, 2 figures, and 6 tables. Code &\n  data: https://huggingface.co/datasets/Dangindev/VinDR-CXR-VQA", "summary": "We present VinDr-CXR-VQA, a large-scale chest X-ray dataset for explainable\nMedical Visual Question Answering (Med-VQA) with spatial grounding. The dataset\ncontains 17,597 question-answer pairs across 4,394 images, each annotated with\nradiologist-verified bounding boxes and clinical reasoning explanations. Our\nquestion taxonomy spans six diagnostic types-Where, What, Is there, How many,\nWhich, and Yes/No-capturing diverse clinical intents. To improve reliability,\nwe construct a balanced distribution of 41.7% positive and 58.3% negative\nsamples, mitigating hallucinations in normal cases. Benchmarking with\nMedGemma-4B-it demonstrates improved performance (F1 = 0.624, +11.8% over\nbaseline) while enabling lesion localization. VinDr-CXR-VQA aims to advance\nreproducible and clinically grounded Med-VQA research. The dataset and\nevaluation tools are publicly available at\nhuggingface.co/datasets/Dangindev/VinDR-CXR-VQA.", "AI": {"tldr": "VinDr-CXR-VQA introduces a large-scale, explainable chest X-ray Med-VQA dataset with spatial grounding and radiologist-verified explanations, enabling improved VQA performance and lesion localization while reducing hallucinations through balanced QA sampling.", "motivation": "To enable reliable, explainable medical visual question answering in radiology by providing bounding-box grounded answers, clinical reasoning, and a balanced dataset to mitigate spurious normal-case predictions.", "method": "Assemble 4,394 chest X-ray images with 17,597 QA pairs; annotate each Q/A with radiologist-verified bounding boxes and clinical reasoning explanations; define a six-category question taxonomy (Where, What, Is there, How many, Which, Yes/No); create a balanced distribution (41.7% positive, 58.3% negative) to reduce hallucinations; benchmark using MedGemma-4B-it with localization capability.", "result": "Achieved F1 = 0.624 on MedGemma-4B-it, a +11.8% improvement over the baseline, while enabling lesion localization.", "conclusion": "VinDr-CXR-VQA advances reproducible and clinically grounded Med-VQA research; the dataset and evaluation tools are publicly available at HuggingFace, facilitating further research and benchmarking."}}
{"id": "2511.01718", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01718", "abs": "https://arxiv.org/abs/2511.01718", "authors": ["Jiayi Chen", "Wenxuan Song", "Pengxiang Ding", "Ziyang Zhou", "Han Zhao", "Feilong Tang", "Donglin Wang", "Haoang Li"], "title": "Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process", "comment": null, "summary": "Vision-language-action (VLA) models aim to understand natural language\ninstructions and visual observations and to execute corresponding actions as an\nembodied agent. Recent work integrates future images into the\nunderstanding-acting loop, yielding unified VLAs that jointly understand,\ngenerate, and act -- reading text and images and producing future images and\nactions. However, these models either rely on external experts for modality\nunification or treat image generation and action prediction as separate\nprocesses, limiting the benefits of direct synergy between these tasks. Our\ncore philosophy is to optimize generation and action jointly through a\nsynchronous denoising process, where the iterative refinement enables actions\nto evolve from initialization, under constant and sufficient visual guidance.\nWe ground this philosophy in our proposed Unified Diffusion VLA and Joint\nDiscrete Denoising Diffusion Process (JD3P), which is a joint diffusion process\nthat integrates multiple modalities into a single denoising trajectory to serve\nas the key mechanism enabling understanding, generation, and acting to be\nintrinsically synergistic. Our model and theory are built on a unified\ntokenized space of all modalities and a hybrid attention mechanism. We further\npropose a two-stage training pipeline and several inference-time techniques\nthat optimize performance and efficiency. Our approach achieves\nstate-of-the-art performance on benchmarks such as CALVIN, LIBERO, and\nSimplerEnv with 4$\\times$ faster inference than autoregressive methods, and we\ndemonstrate its effectiveness through in-depth analysis and real-world\nevaluations. Our project page is available at\nhttps://irpn-eai.github.io/UD-VLA.github.io/.", "AI": {"tldr": "A unified diffusion model for Vision-Language-Action (VLA) called Unified Diffusion VLA with JD3P jointly unifies understanding, generation, and acting via a single diffusion trajectory over a shared multi-modal token space, achieving SOTA with 4x faster inference than autoregressive methods.", "motivation": "To overcome limitations of prior VLA systems that rely on external modalities for unification or separate generation and action models, by enabling intrinsic synergy through a synchronous, joint denoising process across all modalities.", "method": "Introduce Joint Discrete Denoising Diffusion Process (JD3P) within a Unified Diffusion VLA. The model uses a unified tokenized space for all modalities and a hybrid attention mechanism, enabling a single denoising trajectory that evolves actions and generated content in tandem. A two-stage training pipeline and several inference-time optimizations are proposed to improve performance and efficiency.", "result": "The approach achieves state-of-the-art results on CALVIN, LIBERO, and SimplerEnv benchmarks, with about 4x faster inference compared to autoregressive baselines, and is supported by ablations, analyses, and real-world evaluations.", "conclusion": "Jointly optimizing generation and action through a synchronous diffusion framework yields intrinsically synergistic VLA capabilities, enabling more efficient and effective understanding, generation, and acting, with strong empirical evidence and a public project page for reproducibility."}}
{"id": "2511.00272", "categories": ["cs.LG", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.00272", "abs": "https://arxiv.org/abs/2511.00272", "authors": ["Michiel Straat", "Thorben Markmann", "Sebastian Peitz", "Barbara Hammer"], "title": "Improving the Robustness of Control of Chaotic Convective Flows with Domain-Informed Reinforcement Learning", "comment": null, "summary": "Chaotic convective flows arise in many real-world systems, such as\nmicrofluidic devices and chemical reactors. Stabilizing these flows is highly\ndesirable but remains challenging, particularly in chaotic regimes where\nconventional control methods often fail. Reinforcement Learning (RL) has shown\npromise for control in laminar flow settings, but its ability to generalize and\nremain robust under chaotic and turbulent dynamics is not well explored,\ndespite being critical for real-world deployment. In this work, we improve the\npractical feasibility of RL-based control of such flows focusing on\nRayleigh-B\\'enard Convection (RBC), a canonical model for convective heat\ntransport. To enhance generalization and sample efficiency, we introduce\ndomain-informed RL agents that are trained using Proximal Policy Optimization\nacross diverse initial conditions and flow regimes. We incorporate domain\nknowledge in the reward function via a term that encourages B\\'enard cell\nmerging, as an example of a desirable macroscopic property. In laminar flow\nregimes, the domain-informed RL agents reduce convective heat transport by up\nto 33%, and in chaotic flow regimes, they still achieve a 10% reduction, which\nis significantly better than the conventional controllers used in practice. We\ncompare the domain-informed to uninformed agents: Our results show that the\ndomain-informed reward design results in steady flows, faster convergence\nduring training, and generalization across flow regimes without retraining. Our\nwork demonstrates that elegant domain-informed priors can greatly enhance the\nrobustness of RL-based control of chaotic flows, bringing real-world deployment\ncloser.", "AI": {"tldr": "Domain-informed reinforcement learning with PPO improves control of Rayleigh-B\u00e9nard convection across laminar and chaotic regimes, achieving 33% heat-transport reduction in laminar flows and 10% in chaotic flows, with better stability and cross-regime generalization compared to conventional controllers.", "motivation": "Stabilizing chaotic convective flows is hard; existing RL works mainly in laminar regimes and may fail in chaotic/turbulent dynamics; real-world deployment requires robust generalization and sample efficiency.", "method": "Train domain-informed PPO agents across diverse initial conditions and flow regimes for RBC; incorporate domain knowledge into the reward via a Benard cell merging term; compare domain-informed vs uninformed agents; assess heat transport reduction and convergence; evaluate generalization without retraining.", "result": "Domain-informed agents achieve up to 33% reduction in heat transport in laminar RBC and 10% in chaotic RBC; outperform conventional controllers; domain-informed rewards yield steady flows, faster training convergence, and cross-regime generalization without retraining.", "conclusion": "Incorporating domain priors into RL for chaotic flows substantially improves robustness and generalization, bringing RL-based control of chaotic convection closer to real-world deployment."}}
{"id": "2511.00510", "categories": ["cs.CV", "cs.RO", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.00510", "abs": "https://arxiv.org/abs/2511.00510", "authors": ["Kai Luo", "Hao Shi", "Kunyu Peng", "Fei Teng", "Sheng Wu", "Kaiwei Wang", "Kailun Yang"], "title": "OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback", "comment": "Extended version of CVPR 2025 paper arXiv:2503.04565. Datasets and\n  code will be made publicly available at https://github.com/xifen523/OmniTrack", "summary": "This paper investigates Multi-Object Tracking (MOT) in panoramic imagery,\nwhich introduces unique challenges including a 360{\\deg} Field of View (FoV),\nresolution dilution, and severe view-dependent distortions. Conventional MOT\nmethods designed for narrow-FoV pinhole cameras generalize unsatisfactorily\nunder these conditions. To address panoramic distortion, large search space,\nand identity ambiguity under a 360{\\deg} FoV, OmniTrack++ adopts a\nfeedback-driven framework that progressively refines perception with trajectory\ncues. A DynamicSSM block first stabilizes panoramic features, implicitly\nalleviating geometric distortion. On top of normalized representations,\nFlexiTrack Instances use trajectory-informed feedback for flexible localization\nand reliable short-term association. To ensure long-term robustness, an\nExpertTrack Memory consolidates appearance cues via a Mixture-of-Experts\ndesign, enabling recovery from fragmented tracks and reducing identity drift.\nFinally, a Tracklet Management module adaptively switches between end-to-end\nand tracking-by-detection modes according to scene dynamics, offering a\nbalanced and scalable solution for panoramic MOT. To support rigorous\nevaluation, we establish the EmboTrack benchmark, a comprehensive dataset for\npanoramic MOT that includes QuadTrack, captured with a quadruped robot, and\nBipTrack, collected with a bipedal wheel-legged robot. Together, these datasets\nspan wide-angle environments and diverse motion patterns, providing a\nchallenging testbed for real-world panoramic perception. Extensive experiments\non JRDB and EmboTrack demonstrate that OmniTrack++ achieves state-of-the-art\nperformance, yielding substantial HOTA improvements of +25.5% on JRDB and\n+43.07% on QuadTrack over the original OmniTrack. Datasets and code will be\nmade publicly available at https://github.com/xifen523/OmniTrack.", "AI": {"tldr": "OmniTrack++ is a panoramic MOT framework that stabilizes distortion, leverages trajectory-informed localization, memory-based appearance modeling, and adaptive tracklet management to attain state-of-the-art HOTA on panoramic benchmarks, backed by the EmboTrack dataset.", "motivation": "Panoramic MOT presents unique challenges (360\u00b0 FoV, resolution dilution, severe distortions, large search space, and identity drift) that narrow-FoV MOT methods struggle to handle. The work motivates a dedicated, scalable solution and a rigorous benchmark for real-world panoramic perception.", "method": "Key components include: (1) DynamicSSM block to stabilize panoramic features and mitigate distortion; (2) FlexiTrack Instances for trajectory-informed, flexible localization and short-term association on normalized representations; (3) ExpertTrack Memory (Mixture-of-Experts) to fuse appearance cues for long-term robustness and to recover from fragmented tracks; (4) Tracklet Management module that adaptively switches between end-to-end and tracking-by-detection modes based on scene dynamics; (5) EmboTrack benchmark (QuadTrack from a quadruped robot and BipTrack from a wheel-legged robot) to evaluate panoramic MOT in wide-angle environments; (6) Evaluation on JRDB and EmboTrack showing substantial improvements over baselines; (7) Open-source release of code and datasets.", "result": "OmniTrack++ achieves state-of-the-art MOT performance with notable gains in HOTA: +25.5% on JRDB and +43.07% on QuadTrack over the original OmniTrack.", "conclusion": "The approach delivers a scalable, robust panoramic MOT solution with a challenging benchmark (EmboTrack) and strong empirical gains, with code and datasets to follow for broader adoption."}}
{"id": "2511.01770", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01770", "abs": "https://arxiv.org/abs/2511.01770", "authors": ["Liudi Yang", "Yang Bai", "Yuhao Wang", "Ibrahim Alsarraj", "Gitta Kutyniok", "Zhanchi Wang", "Ke Wu"], "title": "Lightweight Learning from Actuation-Space Demonstrations via Flow Matching for Whole-Body Soft Robotic Grasping", "comment": null, "summary": "Robotic grasping under uncertainty remains a fundamental challenge due to its\nuncertain and contact-rich nature. Traditional rigid robotic hands, with\nlimited degrees of freedom and compliance, rely on complex model-based and\nheavy feedback controllers to manage such interactions. Soft robots, by\ncontrast, exhibit embodied mechanical intelligence: their underactuated\nstructures and passive flexibility of their whole body, naturally accommodate\nuncertain contacts and enable adaptive behaviors. To harness this capability,\nwe propose a lightweight actuation-space learning framework that infers\ndistributional control representations for whole-body soft robotic grasping,\ndirectly from deterministic demonstrations using a flow matching model\n(Rectified Flow),without requiring dense sensing or heavy control loops. Using\nonly 30 demonstrations (less than 8% of the reachable workspace), the learned\npolicy achieves a 97.5% grasp success rate across the whole workspace,\ngeneralizes to grasped-object size variations of +-33%, and maintains stable\nperformance when the robot's dynamic response is directly adjusted by scaling\nthe execution time from 20% to 200%. These results demonstrate that\nactuation-space learning, by leveraging its passive redundant DOFs and\nflexibility, converts the body's mechanics into functional control intelligence\nand substantially reduces the burden on central controllers for this\nuncertain-rich task.", "AI": {"tldr": "An actuation-space learning approach for whole-body soft robotic grasping uses a Rectified Flow (flow matching) model to infer distributional control from only 30 demonstrations, achieving 97.5% success across the workspace and strong generalization to object size changes and time-scaling, while reducing reliance on dense sensing and heavy central control.", "motivation": "Uncertain, contact-rich grasping is challenging for rigid robots. Soft robots offer compliance and passive adaptability, suggesting that leveraging their body mechanics can simplify control. The goal is to reduce the burden on central controllers by learning control distributions directly from demonstrations.", "method": "Propose a lightweight actuation-space learning framework that learns distributional control representations for whole-body soft grasping from deterministic demonstrations using a flow matching model (Rectified Flow). No dense sensory feedback or heavy control loops required. Trains on 30 demonstrations (\u22488% of reachable workspace).", "result": "The learned policy achieves 97.5% grasp success across the workspace, generalizes to object size variations of \u00b133%, and remains stable when robot dynamics are altered by scaling execution time from 20% to 200%. The approach leverages passive redundant DOFs and flexibility to convert body mechanics into functional control intelligence, reducing the load on central controllers.", "conclusion": "Actuation-space learning effectively exploits soft-body mechanics to handle uncertain-rich grasping tasks, enabling robust performance with minimal demonstrations and reduced reliance on dense sensing and complex control architectures."}}
{"id": "2511.00280", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00280", "abs": "https://arxiv.org/abs/2511.00280", "authors": ["Abhinav Joshi", "Areeb Ahmad", "Ashutosh Modi"], "title": "Calibration Across Layers: Understanding Calibration Evolution in LLMs", "comment": "Accepted at EMNLP 2025 (main)", "summary": "Large Language Models (LLMs) have demonstrated inherent calibration\ncapabilities, where predicted probabilities align well with correctness,\ndespite prior findings that deep neural networks are often overconfident.\nRecent studies have linked this behavior to specific components in the final\nlayer, such as entropy neurons and the unembedding matrix null space. In this\nwork, we provide a complementary perspective by investigating how calibration\nevolves throughout the network depth. Analyzing multiple open-weight models on\nthe MMLU benchmark, we uncover a distinct confidence correction phase in the\nupper/later layers, where model confidence is actively recalibrated after\ndecision certainty has been reached. Furthermore, we identify a low-dimensional\ncalibration direction in the residual stream whose perturbation significantly\nimproves calibration metrics (ECE and MCE) without harming accuracy. Our\nfindings suggest that calibration is a distributed phenomenon, shaped\nthroughout the network forward pass, not just in its final projection,\nproviding new insights into how confidence-regulating mechanisms operate within\nLLMs.", "AI": {"tldr": "Calibration in LLMs is distributed across depth, featuring a late-stage confidence-correction phase in upper layers and a low-dimensional residual-direction that improves calibration (ECE/MCE) without hurting accuracy.", "motivation": "To understand how calibration emerges and evolves inside LLMs, moving beyond final-layer explanations, and to determine whether confidence regulation is distributed throughout the forward pass.", "method": "Analyze multiple open-weight LLMs on the MMLU benchmark; identify a late-phase confidence correction in upper layers; uncover a low-dimensional calibration direction in the residual stream; perturb this direction to evaluate effects on calibration metrics (ECE/MCE) and accuracy.", "result": "A distinct calibration/confidence correction phase is found in the upper layers; a low-dimensional perturbation direction in the residual stream significantly improves calibration metrics without reducing accuracy; calibration appears to be a distributed phenomenon across the network.", "conclusion": "Calibration within LLMs is distributed throughout the forward pass, not confined to the final projection; this yields new insights into confidence-regulating mechanisms and potential intervention points for improving model calibration."}}
{"id": "2511.00511", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00511", "abs": "https://arxiv.org/abs/2511.00511", "authors": ["Panwang Pan", "Jingjing Zhao", "Yuchen Lin", "Chenguo Lin", "Chenxin Li", "Haopeng Li", "Honglei Yan", "Tingting Shen", "Yadong Mu"], "title": "ID-Composer: Multi-Subject Video Synthesis with Hierarchical Identity Preservation", "comment": null, "summary": "Video generative models pretrained on large-scale datasets can produce\nhigh-quality videos, but are often conditioned on text or a single image,\nlimiting controllability and applicability. We introduce ID-Composer, a novel\nframework that addresses this gap by tackling multi-subject video generation\nfrom a text prompt and reference images. This task is challenging as it\nrequires preserving subject identities, integrating semantics across subjects\nand modalities, and maintaining temporal consistency. To faithfully preserve\nthe subject consistency and textual information in synthesized videos,\nID-Composer designs a \\textbf{hierarchical identity-preserving attention\nmechanism}, which effectively aggregates features within and across subjects\nand modalities. To effectively allow for the semantic following of user\nintention, we introduce \\textbf{semantic understanding via pretrained\nvision-language model (VLM)}, leveraging VLM's superior semantic understanding\nto provide fine-grained guidance and capture complex interactions between\nmultiple subjects. Considering that standard diffusion loss often fails in\naligning the critical concepts like subject ID, we employ an \\textbf{online\nreinforcement learning phase} to drive the overall training objective of\nID-Composer into RLVR. Extensive experiments demonstrate that our model\nsurpasses existing methods in identity preservation, temporal consistency, and\nvideo quality.", "AI": {"tldr": "Introduces ID-Composer for multi-subject video generation from text and reference images, with hierarchical identity-preserving attention, VLM-guided semantic understanding, and an online RL phase to align with RLVR objectives; reports improved identity preservation, temporal consistency, and video quality.", "motivation": "Address the limited controllability of video generative models that are either conditioned on a single image or text, by enabling multi-subject generation with preserved identities and temporal coherence across modalities.", "method": "Proposes a hierarchical identity-preserving attention mechanism to aggregate features within and across subjects and modalities; incorporates a pretrained vision-language model to guide semantic understanding and interactions; employs an online reinforcement learning phase to optimize training toward RLVR objectives.", "result": "Experiments show the method surpasses existing approaches in preserving subject identities, maintaining temporal consistency, and producing high-quality videos.", "conclusion": "ID-Composer effectively enables controllable, multi-subject video generation from text and references, with strong identity, semantic, and temporal performance, validated by extensive experiments."}}
{"id": "2511.01774", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.01774", "abs": "https://arxiv.org/abs/2511.01774", "authors": ["Alexander Schperberg", "Yusuke Tanaka", "Stefano Di Cairano", "Dennis Hong"], "title": "MOBIUS: A Multi-Modal Bipedal Robot that can Walk, Crawl, Climb, and Roll", "comment": "23 pages, 20 figures. Collaborative work between the Robotics and\n  Mechanisms Laboratory (RoMeLa) and Mitsubishi Electric Research Laboratories\n  (MERL)", "summary": "This article presents a Multi-Modal Bipedal Intelligent Urban Scout robot\n(MOBIUS) capable of walking, crawling, climbing, and rolling. MOBIUS features\nfour limbs--two 6-DoF arms with two-finger grippers for manipulation and\nclimbing, and two 4-DoF legs for locomotion--enabling smooth transitions across\ndiverse terrains without reconfiguration. A hybrid control architecture\ncombines reinforcement learning-based locomotion with model-based predictive\nand admittance control enhanced for safety by a Reference Governor toward\ncompliant contact interactions. A high-level MIQCP planner autonomously selects\nlocomotion modes to balance stability and energy efficiency. Hardware\nexperiments demonstrate robust gait transitions, dynamic climbing, and\nfull-body load support via pinch grasp. Overall, MOBIUS demonstrates the\nimportance of tight integration between morphology, high-level planning, and\ncontrol to enable mobile loco-manipulation and grasping, substantially\nexpanding its interaction capabilities, workspace, and traversability.", "AI": {"tldr": "MOBIUS is a four-limbed mobile loco-manipulator that merges RL-based locomotion with model-based predictive and admittance control, safeguarded by a Reference Governor, and guided by an MIQCP planner to flexibly walk, crawl, climb, and grasp across varied terrains.", "motivation": "To extend mobile manipulation capabilities across diverse terrains while ensuring safe, compliant contact interactions through tight integration of morphology, planning, and control.", "method": "A four-limb robot with two 6-DoF arms (two-finger grippers) and two 4-DoF legs enables seamless transitions across terrains. A hybrid control architecture combines reinforcement-learning\u2013based locomotion with model-based predictive control and admittance control, enhanced by a Reference Governor for safety. A high-level MIQCP planner autonomously selects locomotion modes. Hardware experiments validate transitions, dynamic climbing, and full-body load support.", "result": "Robust gait transitions, dynamic climbing, and full-body load support via pinch grasp demonstrated on hardware; the robot maintains stability and energy efficiency across modes without reconfiguration.", "conclusion": "Tight integration of morphology, high-level planning, and control is crucial to enable mobile loco-manipulation and grasping, expanding interaction capabilities, workspace, and traversability."}}
{"id": "2511.00301", "categories": ["cs.LG", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2511.00301", "abs": "https://arxiv.org/abs/2511.00301", "authors": ["Ciaran Bench", "Oskar Pfeffer", "Vivek Desai", "Mohammad Moulaeifard", "Lo\u00efc Coquelin", "Peter H. Charlton", "Nils Strodthoff", "Nando Hegemann", "Philip J. Aston", "Andrew Thompson"], "title": "A systematic evaluation of uncertainty quantification techniques in deep learning: a case study in photoplethysmography signal analysis", "comment": null, "summary": "In principle, deep learning models trained on medical time-series, including\nwearable photoplethysmography (PPG) sensor data, can provide a means to\ncontinuously monitor physiological parameters outside of clinical settings.\nHowever, there is considerable risk of poor performance when deployed in\npractical measurement scenarios leading to negative patient outcomes. Reliable\nuncertainties accompanying predictions can provide guidance to clinicians in\ntheir interpretation of the trustworthiness of model outputs. It is therefore\nof interest to compare the effectiveness of different approaches. Here we\nimplement an unprecedented set of eight uncertainty quantification (UQ)\ntechniques to models trained on two clinically relevant prediction tasks:\nAtrial Fibrillation (AF) detection (classification), and two variants of blood\npressure regression. We formulate a comprehensive evaluation procedure to\nenable a rigorous comparison of these approaches. We observe a complex picture\nof uncertainty reliability across the different techniques, where the most\noptimal for a given task depends on the chosen expression of uncertainty,\nevaluation metric, and scale of reliability assessed. We find that assessing\nlocal calibration and adaptivity provides practically relevant insights about\nmodel behaviour that otherwise cannot be acquired using more commonly\nimplemented global reliability metrics. We emphasise that criteria for\nevaluating UQ techniques should cater to the model's practical use case, where\nthe use of a small number of measurements per patient places a premium on\nachieving small-scale reliability for the chosen expression of uncertainty,\nwhile preserving as much predictive performance as possible.", "AI": {"tldr": "Evaluates eight uncertainty quantification methods for deep learning on medical time-series (AF detection and BP regression) and finds reliability is highly task-, metric-, and scale-dependent; local calibration and adaptivity offer practical insights for real-world use.", "motivation": "Provide trustworthy, actionable predictions for clinicians monitoring patients via wearable data by quantifying model uncertainty and guiding interpretation.", "method": "Train DL models on two clinically relevant tasks (AF detection; two BP regression variants) and apply eight UQ techniques. Develop a comprehensive evaluation pipeline comparing reliability across methods, with emphasis on calibration (global vs local) and adaptivity, and considerations for small per-patient measurement regimes.", "result": "No single UQ method universally outperforms others. Reliability depends on the technique, the chosen uncertainty expression, evaluation metric, and the scale of reliability. Local calibration and adaptivity yield practically relevant insights not captured by global metrics, and evaluation criteria should align with the model\u2019s intended clinical use where few measurements per patient require strong small-scale reliability with minimal predictive loss.", "conclusion": "UQ assessment should be tailored to the specific use case. Prioritize local calibration and adaptivity, and adopt evaluation metrics that reflect practical clinical constraints and the desired balance between uncertainty fidelity and predictive performance."}}
{"id": "2511.00523", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00523", "abs": "https://arxiv.org/abs/2511.00523", "authors": ["Fangyu Wu", "Yujun Cai"], "title": "SegDebias: Test-Time Bias Mitigation for ViT-Based CLIP via Segmentation", "comment": null, "summary": "Vision language models such as CLIP have shown remarkable performance in zero\nshot classification, but remain susceptible to spurious correlations, where\nirrelevant visual features influence predictions. Existing debiasing methods\noften require access to training data and explicit group labels to perform\nfine-tuning or adjust embeddings, which limits their practicality in real-world\nsettings. Test-time methods attempt to avoid this constraint, but many still\ndepend on prior knowledge of dataset specific biases, limiting their\ngeneralizability in open set settings. In this work, we propose a test-time\ndebiasing method for ViT based CLIP models that requires no additional training\nor assumptions of bias annotations. Our approach uses a pretrained segmentation\nmodel to isolate the target visual attribute, then adjusts the non target\nregions so that their embeddings are uniformly similar to all class specific\ntext prompts. This procedure removes unintended bias signals from confounding\nvisual regions while preserving the target attribute. Experiments on Waterbirds\nand CelebA show that our method outperforms existing test-time debiasing\napproaches in both group robustness metrics and Attention IoU. These results\ndemonstrate the effectiveness of segmentation guided interventions for scalable\nand annotation free bias mitigation in vision language models.", "AI": {"tldr": "Segmentation-guided, test-time debiasing for ViT-based CLIP that isolates the target attribute and enforces uniform similarity of non-target regions to all class prompts, removing bias signals without extra training or bias labels.", "motivation": "Mitigate spurious correlations in vision\u2013language models without requiring training data or explicit bias annotations; improve generalization in open-set settings.", "method": "At test time, use a pretrained segmentation model to segment the target attribute, then adjust embeddings of non-target regions so they are uniformly similar to all class-specific text prompts, preserving the target attribute and removing confounding signals.", "result": "Outperforms existing test-time debiasing methods on Waterbirds and CelebA in group robustness metrics and Attention IoU.", "conclusion": "Segmentation-guided interventions enable scalable, annotation-free bias mitigation for vision\u2013language models."}}
{"id": "2511.01791", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01791", "abs": "https://arxiv.org/abs/2511.01791", "authors": ["Feng Chen", "Zhuxiu Xu", "Tianzhe Chu", "Xunzhe Zhou", "Li Sun", "Zewen Wu", "Shenghua Gao", "Zhongyu Li", "Yanchao Yang", "Yi Ma"], "title": "GenDexHand: Generative Simulation for Dexterous Hands", "comment": null, "summary": "Data scarcity remains a fundamental bottleneck for embodied intelligence.\nExisting approaches use large language models (LLMs) to automate gripper-based\nsimulation generation, but they transfer poorly to dexterous manipulation,\nwhich demands more specialized environment design. Meanwhile, dexterous\nmanipulation tasks are inherently more difficult due to their higher degrees of\nfreedom. Massively generating feasible and trainable dexterous hand tasks\nremains an open challenge. To this end, we present GenDexHand, a generative\nsimulation pipeline that autonomously produces diverse robotic tasks and\nenvironments for dexterous manipulation. GenDexHand introduces a closed-loop\nrefinement process that adjusts object placements and scales based on\nvision-language model (VLM) feedback, substantially improving the average\nquality of generated environments. Each task is further decomposed into\nsub-tasks to enable sequential reinforcement learning, reducing training time\nand increasing success rates. Our work provides a viable path toward scalable\ntraining of diverse dexterous hand behaviors in embodied intelligence by\noffering a simulation-based solution to synthetic data generation. Our website:\nhttps://winniechen2002.github.io/GenDexHand/.", "AI": {"tldr": "GenDexHand is a closed-loop generative pipeline that autonomously creates diverse, trainable dexterous hand tasks/environments using vision-language feedback and sub-task decomposition to enable sequential RL in simulation.", "motivation": "Data scarcity and the mismatch of LLM-generated dexterous tasks to real-world dexterous manipulation; dexterous manipulation has higher DOFs and is harder, requiring specialized environments. A scalable, automatic way to generate varied, trainable tasks is needed.", "method": "A closed-loop generative simulation pipeline (GenDexHand) that refines object placements and scales based on vision-language model feedback to improve environment quality. Each task is decomposed into sub-tasks to enable sequential reinforcement learning, reducing training time and increasing success rates.", "result": "Significant improvement in the average quality of generated environments, shorter training times, and higher success rates in learned dexterous manipulation tasks.", "conclusion": "Offers a viable, scalable pathway for synthesizing diverse dexterous hand behaviors in simulation, addressing data scarcity for embodied intelligence; demonstrated through a generative pipeline and sub-task decomposition, with a public website for the project."}}
{"id": "2511.00318", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00318", "abs": "https://arxiv.org/abs/2511.00318", "authors": ["Dana Kim", "Yichen Xu", "Tiffany Lin"], "title": "A Technical Exploration of Causal Inference with Hybrid LLM Synthetic Data", "comment": "9 pages, 4 figures", "summary": "Large Language Models (LLMs) offer a flexible means to generate synthetic\ntabular data, yet existing approaches often fail to preserve key causal\nparameters such as the average treatment effect (ATE). In this technical\nexploration, we first demonstrate that state-of-the-art synthetic data\ngenerators, both GAN- and LLM-based, can achieve high predictive fidelity while\nsubstantially misestimating causal effects. To address this gap, we propose a\nhybrid generation framework that combines model-based covariate synthesis\n(monitored via distance-to-closest-record filtering) with separately learned\npropensity and outcome models, thereby ensuring that (W, A, Y) triplets retain\ntheir underlying causal structure. We further introduce a synthetic pairing\nstrategy to mitigate positivity violations and a realistic evaluation protocol\nthat leverages unlimited synthetic samples to benchmark traditional estimators\n(IPTW, AIPW, substitution) under complex covariate distributions. This work\nlays the groundwork for LLM-powered data pipelines that support robust causal\nanalysis. Our code is available at\nhttps://github.com/Xyc-arch/llm-synthetic-for-causal-inference.git.", "AI": {"tldr": "State-of-the-art synthetic data (GAN/LLM) can achieve high predictive fidelity but substantially misestimate causal effects like ATE. The paper proposes a hybrid generation framework that fuses model-based covariate synthesis (with distance-to-closest-record filtering) and separately learned propensity/outcome models to preserve the causal W\u2013A\u2013Y structure, plus a synthetic pairing strategy to mitigate positivity violations, along with a protocol to benchmark causal estimators using unlimited synthetic samples.", "motivation": "To address the gap where high predictive accuracy of synthetic data does not guarantee accurate estimation of causal parameters (e.g., ATE). The authors aim to enable LLM-powered data pipelines that support robust causal inference by preserving causal relationships in synthetic datasets.", "method": "1) Demonstrate that current GAN- and LLM-based synthetic data generators distort causal effects despite high predictive fidelity. 2) Propose a hybrid framework: (a) model-based covariate synthesis guided by distance-to-closest-record filtering; (b) separately learned propensity and outcome models to maintain causal mechanisms; (c) a synthetic pairing strategy to alleviate positivity violations; (d) an evaluation protocol using unlimited synthetic samples to benchmark IPTW, AIPW, and substitution under complex covariate distributions.", "result": "The framework aims to ensure that the (W, A, Y) triplets retain their underlying causal structure, addressing the misestimation of causal effects observed with existing synthetic data methods. It provides a principled evaluation protocol and a code release for reproducibility.", "conclusion": "This work lays groundwork for robust causal analysis with LLM-powered synthetic data, showing how to couple covariate synthesis with explicit causal models and evaluation to support reliable causal inference in synthetic environments."}}
{"id": "2511.00524", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00524", "abs": "https://arxiv.org/abs/2511.00524", "authors": ["Jihao Gu", "Kun Li", "He Wang", "Kaan Ak\u015fit"], "title": "Text-guided Fine-Grained Video Anomaly Detection", "comment": null, "summary": "Video Anomaly Detection (VAD) aims to identify anomalous events within video\nsegments. In scenarios such as surveillance or industrial process monitoring,\nanomaly detection is of critical importance. While existing approaches are\nsemi-automated, requiring human assessment for anomaly detection, traditional\nVADs offer limited output as either normal or anomalous. We propose Text-guided\nFine-Grained Video Anomaly Detection (T-VAD), a framework built upon Large\nVision-Language Model (LVLM). T-VAD introduces an Anomaly Heatmap Decoder (AHD)\nthat performs pixel-wise visual-textual feature alignment to generate\nfine-grained anomaly heatmaps. Furthermore, we design a Region-aware Anomaly\nEncoder (RAE) that transforms the heatmaps into learnable textual embeddings,\nguiding the LVLM to accurately identify and localize anomalous events in\nvideos. This significantly enhances both the granularity and interactivity of\nanomaly detection. The proposed method achieving SOTA performance by\ndemonstrating 94.8% Area Under the Curve (AUC, specifically micro-AUC) and\n67.8%/76.7% accuracy in anomaly heatmaps (RBDC/TBDC) on the UBnormal dataset,\nand subjectively verified more preferable textual description on the\nShanghaiTech-based dataset (BLEU-4: 62.67 for targets, 88.84 for trajectories;\nYes/No accuracy: 97.67%), and on the UBnormal dataset (BLEU-4: 50.32 for\ntargets, 78.10 for trajectories; Yes/No accuracy: 89.73%).", "AI": {"tldr": "Proposes Text-guided Fine-Grained Video Anomaly Detection (T-VAD) using LVLMs with an Anomaly Heatmap Decoder (AHD) and a Region-aware Anomaly Encoder (RAE) to generate pixel-level anomaly heatmaps and textual embeddings, enabling fine-grained, interactive anomaly localization and description. Achieves state-of-the-art results on UBnormal (micro-AUC 94.8%; heatmap accuracy 67.8%/76.7% for RBDC/TBDC) and strong textual metrics on ShanghaiTech and UBnormal datasets (BLEU-4 and Yes/No accuracy).", "motivation": "Current VAD systems are semi-automated or yield only binary outputs (normal/anomalous). There is a need for fine-grained, interpretable, and interactive anomaly localization and description, leveraging powerful LVLMs.", "method": "Introduce Anomaly Heatmap Decoder (AHD) for pixel-wise visual-text alignment to produce anomaly heatmaps. Use Region-aware Anomaly Encoder (RAE) to convert heatmaps into learnable textual embeddings, guiding the LVLM to identify and localize anomalies. Integrate with a Large Vision-Language Model for descriptive and interactive outputs.", "result": "Achieves state-of-the-art performance: UBnormal dataset shows micro-AUC of 94.8% and heatmap accuracy of 67.8% (RBDC) and 76.7% (TBDC). Textual evaluation reports BLEU-4 scores on targets and trajectories (ShanghaiTech and UBnormal) and high Yes/No accuracies, indicating improved textual descriptions and localization quality.", "conclusion": "Demonstrates that LVLM-guided, fine-grained anomaly detection can surpass traditional binary outputs, offering more granular, interpretable, and interactive VAD with strong quantitative and qualitative results."}}
{"id": "2511.01797", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01797", "abs": "https://arxiv.org/abs/2511.01797", "authors": ["Javier Ballesteros-Jerez", "Jesus Mart\u00ednez-G\u00f3mez", "Ismael Garc\u00eda-Varea", "Luis Orozco-Barbosa", "Manuel Castillo-Cara"], "title": "Hybrid Neural Network-Based Indoor Localisation System for Mobile Robots Using CSI Data in a Robotics Simulator", "comment": "13 pages, 7 figures. Conference paper (ROBOVIS 2025)", "summary": "We present a hybrid neural network model for inferring the position of mobile\nrobots using Channel State Information (CSI) data from a Massive MIMO system.\nBy leveraging an existing CSI dataset, our approach integrates a Convolutional\nNeural Network (CNN) with a Multilayer Perceptron (MLP) to form a Hybrid Neural\nNetwork (HyNN) that estimates 2D robot positions. CSI readings are converted\ninto synthetic images using the TINTO tool. The localisation solution is\nintegrated with a robotics simulator, and the Robot Operating System (ROS),\nwhich facilitates its evaluation through heterogeneous test cases, and the\nadoption of state estimators like Kalman filters. Our contributions illustrate\nthe potential of our HyNN model in achieving precise indoor localisation and\nnavigation for mobile robots in complex environments. The study follows, and\nproposes, a generalisable procedure applicable beyond the specific use case\nstudied, making it adaptable to different scenarios and datasets.", "AI": {"tldr": "A hybrid CNN\u2013MLP model (HyNN) maps Massive MIMO CSI data to 2D indoor robot positions using TINTO-generated images, integrated with ROS and simulators and Kalman filtering; claims a generalizable procedure for robotics scenarios.", "motivation": "Accurate indoor localization for mobile robots is challenging. Wireless Channel State Information (CSI) contains rich spatial information that can be repurposed for localization. Using an existing CSI dataset and converting it into a format suitable for neural nets enables learning-based localization. Integrating with robotics tooling (ROS, simulators) facilitates evaluation in realistic, heterogeneous environments and supports state estimation (e.g., Kalman filters).", "method": "Convert CSI readings into synthetic images via the TINTO tool. Feed images into a CNN to extract spatial features, then use an MLP to map features to 2D coordinates, forming a Hybrid Neural Network (HyNN). Integrate the result with a robotics simulator and ROS; apply Kalman filters for state estimation. Evaluate across heterogeneous test cases and propose a generalizable procedure applicable beyond the specific dataset.", "result": "The approach demonstrates the potential for precise indoor 2D localization of mobile robots using CSI-based signals within a robotics framework, showing compatibility with ROS, simulators, and standard state estimators; the procedure is argued to be adaptable to different environments and datasets.", "conclusion": "HyNN leveraging CSI data with a CNN\u2013MLP architecture offers a promising, generalizable workflow for indoor robot localization and navigation, with demonstrated integration into robotics tooling; future work should substantiate quantitative gains and broaden validations across more scenarios."}}
{"id": "2511.00351", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00351", "abs": "https://arxiv.org/abs/2511.00351", "authors": ["Amir Ziashahabi", "Yavuz Faruk Bakman", "Duygu Nur Yaldiz", "Mostafa El-Khamy", "Sai Praneeth Karimireddy", "Salman Avestimehr"], "title": "Reject Only Critical Tokens: Pivot-Aware Speculative Decoding", "comment": "Accepted at NeurIPS 2025 Efficient Reasoning Workshop", "summary": "Speculative Decoding (SD) ensures that the output matches the target model's\ndistribution exactly. However, we argue that this distribution matching\nrequirement is too stringent and results in unnecessarily low acceptance rates,\nlimiting potential speedups. Instead, we advocate a reformulation of the\ndecoding objective: the proposed decoding strategy should match the expected\nutility, i.e., the task-specific performance, of the target model. This\nperspective also aligns better with real-world use cases of LLMs, where utility\n(e.g., code correctness, factual accuracy) is often more important than\nsampling distribution. Based on this reformulation, we propose a novel decoding\nstrategy: Pivot-Aware Speculative Decoding, which rejects only those tokens\nthat would lead to a utility drop in the final output. We refer to these\ncritical tokens as pivot tokens. We propose a method for labeling tokens as\npivotal or non-pivotal and train a lightweight classifier to detect them. This\nmethod can be viewed as a relaxed version of standard SD, which offers much\nhigher acceptance while preserving utility. We evaluate our method across\nvarious datasets, demonstrating that we can achieve up to $2.5\\times$ speedup\nwith comparable utility. Source code is available at\nhttps://github.com/amir-zsh/PAD.", "AI": {"tldr": "Pivot-Aware Speculative Decoding (PAD) relaxes exact distribution matching in Speculative Decoding by optimizing for task utility instead. It labels pivot (critical) tokens that would drop final utility and trains a lightweight classifier to detect them, rejecting only those tokens. This yields higher acceptance and up to 2.5x speedups with comparable utility, making decoding more practical for real-world LLM tasks.", "motivation": "Exact distribution matching in Speculative Decoding is overly stringent and can throttle decoding speed, because the primary goal in many applications is task utility (e.g., correctness, factual accuracy) rather than perfect distribution replication. A utility-focused decoding objective better aligns with real-world LLM use cases.", "method": "The approach defines pivot tokens as those whose choice would reduce the final output's utility. Tokens are labeled as pivotal or non-pivotal, and a lightweight classifier is trained to detect pivots. PAD acts as a relaxed version of standard SD by rejecting only pivot tokens, increasing acceptance while preserving utility. The method includes labeling strategy, classifier training, and evaluation across multiple datasets, with code released.", "result": "Empirical evaluation shows up to 2.5\u00d7 speedup with comparable task utility to baseline methods across diverse datasets, demonstrating that utility-aligned decoding can substantially accelerate generation without sacrificing performance.", "conclusion": "Reframing decoding to optimize for expected utility rather than exact distribution matching yields practical speedups. PAD offers a viable, more efficient alternative to SD while maintaining task performance, aligning decoding with real-world use cases."}}
{"id": "2511.00540", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00540", "abs": "https://arxiv.org/abs/2511.00540", "authors": ["Wenbing Zhu", "Chengjie Wang", "Bin-Bin Gao", "Jiangning Zhang", "Guannan Jiang", "Jie Hu", "Zhenye Gan", "Lidong Wang", "Ziqing Zhou", "Linjie Cheng", "Yurui Pan", "Bo Peng", "Mingmin Chi", "Lizhuang Ma"], "title": "Real-IAD Variety: Pushing Industrial Anomaly Detection Dataset to a Modern Era", "comment": "13 pages, 4 figures and 5 tables", "summary": "Industrial Anomaly Detection (IAD) is critical for enhancing operational\nsafety, ensuring product quality, and optimizing manufacturing efficiency\nacross global industries. However, the IAD algorithms are severely constrained\nby the limitations of existing public benchmarks. Current datasets exhibit\nrestricted category diversity and insufficient scale, frequently resulting in\nmetric saturation and limited model transferability to real-world scenarios. To\naddress this gap, we introduce Real-IAD Variety, the largest and most diverse\nIAD benchmark, comprising 198,960 high-resolution images across 160 distinct\nobject categories. Its diversity is ensured through comprehensive coverage of\n28 industries, 24 material types, and 22 color variations. Our comprehensive\nexperimental analysis validates the benchmark's substantial challenge:\nstate-of-the-art multi-class unsupervised anomaly detection methods experience\nsignificant performance degradation when scaled from 30 to 160 categories.\nCrucially, we demonstrate that vision-language models exhibit remarkable\nrobustness to category scale-up, with minimal performance variation across\ndifferent category counts, significantly enhancing generalization capabilities\nin diverse industrial contexts. The unprecedented scale and complexity of\nReal-IAD Variety position it as an essential resource for training and\nevaluating next-generation foundation models for anomaly detection. By\nproviding this comprehensive benchmark with rigorous evaluation protocols\nacross multi-class unsupervised, multi-view, and zero-/few-shot settings, we\naim to accelerate research beyond domain-specific constraints, enabling the\ndevelopment of scalable, general-purpose anomaly detection systems. Real-IAD\nVariety will be made publicly available to facilitate innovation in this\ncritical field.", "AI": {"tldr": "Introduces Real-IAD Variety, the largest diverse industrial anomaly detection benchmark to date, showing vision-language models scale well across categories whereas traditional anomaly detectors struggle with more categories.", "motivation": "Current IAD benchmarks suffer from limited category diversity, scale, metric saturation, and transferability; a large, diverse benchmark and standardized evaluation is needed to train and evaluate generalizable models and foundation models.", "method": "Construct Real-IAD Variety: 198,960 high-resolution images across 160 object categories, covering 28 industries, 24 material types, and 22 color variations; provide rigorous evaluation protocols for multi-class unsupervised, multi-view, and zero-/few-shot settings; compare baseline methods across category scales.", "result": "Demonstrates that state-of-the-art multi-class unsupervised anomaly detection methods degrade significantly when scaling from 30 to 160 categories; vision-language models exhibit robustness to category-scale, with minimal performance variation across category counts; validates the benchmark as a more challenging and general resource.", "conclusion": "Real-IAD Variety is an essential resource for training and evaluating next-generation foundation models for anomaly detection; its public release and comprehensive evaluation protocols will accelerate development of scalable, general-purpose anomaly detection systems."}}
{"id": "2511.00359", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00359", "abs": "https://arxiv.org/abs/2511.00359", "authors": ["Zhecheng Sheng", "Jiawei Zhang", "Enmao Diao"], "title": "Toward Unifying Group Fairness Evaluation from a Sparsity Perspective", "comment": "30 pages, 14 figures", "summary": "Ensuring algorithmic fairness remains a significant challenge in machine\nlearning, particularly as models are increasingly applied across diverse\ndomains. While numerous fairness criteria exist, they often lack\ngeneralizability across different machine learning problems. This paper\nexamines the connections and differences among various sparsity measures in\npromoting fairness and proposes a unified sparsity-based framework for\nevaluating algorithmic fairness. The framework aligns with existing fairness\ncriteria and demonstrates broad applicability to a wide range of machine\nlearning tasks. We demonstrate the effectiveness of the proposed framework as\nan evaluation metric through extensive experiments on a variety of datasets and\nbias mitigation methods. This work provides a novel perspective to algorithmic\nfairness by framing it through the lens of sparsity and social equity, offering\npotential for broader impact on fairness research and applications.", "AI": {"tldr": "A sparsity-based unified framework for evaluating algorithmic fairness that connects multiple fairness criteria, showing broad applicability and effectiveness across tasks and bias mitigation methods.", "motivation": "Fairness criteria in ML are numerous and often lack generalizability across different problems; there is a need for a unified, generalizable evaluation approach.", "method": "Introduce a unified sparsity-based framework for evaluating algorithmic fairness, aligning with existing fairness criteria, and validating it as an evaluation metric through extensive experiments across diverse datasets and bias mitigation methods.", "result": "The framework demonstrates broad applicability and effectiveness as an evaluation metric, aligning with existing fairness criteria and enabling consistent assessment across tasks.", "conclusion": "Framing fairness through sparsity and social equity offers a novel perspective with potential wide impact on fairness research and applications."}}
{"id": "2511.00542", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00542", "abs": "https://arxiv.org/abs/2511.00542", "authors": ["Kailun Su", "Ziqi He", "Xi Wang", "Yang Zhou"], "title": "MIFO: Learning and Synthesizing Multi-Instance from One Image", "comment": "17 pages, 30 figures", "summary": "This paper proposes a method for precise learning and synthesizing\nmulti-instance semantics from a single image. The difficulty of this problem\nlies in the limited training data, and it becomes even more challenging when\nthe instances to be learned have similar semantics or appearance. To address\nthis, we propose a penalty-based attention optimization to disentangle similar\nsemantics during the learning stage. Then, in the synthesis, we introduce and\noptimize box control in attention layers to further mitigate semantic leakage\nwhile precisely controlling the output layout. Experimental results demonstrate\nthat our method achieves disentangled and high-quality semantic learning and\nsynthesis, strikingly balancing editability and instance consistency. Our\nmethod remains robust when dealing with semantically or visually similar\ninstances or rare-seen objects. The code is publicly available at\nhttps://github.com/Kareneveve/MIFO", "AI": {"tldr": "Penalty-based attention to disentangle multi-instance semantics from a single image, with box-controlled attention during synthesis to reduce leakage and precisely control layout; robust to similar or rare objects; code released.", "motivation": "Learning multiple semantically similar instances from very limited data is difficult; standard methods struggle with disambiguation and precise synthesis when instances look alike.", "method": "Introduce penalty-based attention optimization to disentangle similar semantics during learning. During synthesis, optimize box control in attention layers to mitigate semantic leakage and enforce precise output layouts.", "result": "Achieves disentangled, high-quality learning and synthesis with a good balance between editability and instance consistency; robust to semantically/visually similar instances and rare-seen objects; code available.", "conclusion": "The proposed framework effectively enables precise multi-instance learning and synthesis from a single image under challenging data conditions, offering reliable disentanglement, controllable layout, and robustness to similarity and rarity."}}
{"id": "2511.00369", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.00369", "abs": "https://arxiv.org/abs/2511.00369", "authors": ["Farjana Aktar", "Mohd Ruhul Ameen", "Akif Islam", "Md Ekramul Hamid"], "title": "Balancing Interpretability and Performance in Motor Imagery EEG Classification: A Comparative Study of ANFIS-FBCSP-PSO and EEGNet", "comment": "6 pages, 3 figures, 8 tables, Submitted to ICECTE 2026", "summary": "Achieving both accurate and interpretable classification of motor imagery EEG\nremains a key challenge in brain computer interface (BCI) research. This paper\ncompares a transparent fuzzy reasoning approach (ANFIS-FBCSP-PSO) with a deep\nlearning benchmark (EEGNet) using the BCI Competition IV-2a dataset. The ANFIS\npipeline combines filter bank common spatial pattern feature extraction with\nfuzzy IF-THEN rules optimized via particle swarm optimization, while EEGNet\nlearns hierarchical spatial temporal representations directly from raw EEG\ndata. In within-subject experiments, the fuzzy neural model performed better\n(68.58 percent +/- 13.76 percent accuracy, kappa = 58.04 percent +/- 18.43),\nwhile in cross-subject (LOSO) tests, the deep model exhibited stronger\ngeneralization (68.20 percent +/- 12.13 percent accuracy, kappa = 57.33 percent\n+/- 16.22). The study provides practical guidance for selecting MI-BCI systems\naccording to design goals: interpretability or robustness across users. Future\ninvestigations into transformer based and hybrid neuro symbolic frameworks are\nexpected to advance transparent EEG decoding.", "AI": {"tldr": "A comparative study of a transparent fuzzy ANFIS-FBCSP-PSO model versus a deep EEGNet benchmark on MI-BCI data shows interpretability benefits within subjects and robustness benefits across subjects, guiding design choices between interpretability and cross-user generalization; future work points to transformer-based and hybrid neuro-symbolic approaches.", "motivation": "To address the dual challenge in MI-EEG classification of achieving high accuracy while maintaining interpretability, and to assess cross-subject generalization using established benchmarks (BCI Competition IV-2a).", "method": "ANFIS-FBCSP-PSO combines filter bank common spatial pattern feature extraction with fuzzy IF-THEN rules optimized by particle swarm optimization; EEGNet serves as a deep learning baseline that learns hierarchical spatial-temporal representations directly from raw EEG.", "result": "Within-subject accuracy: 68.58% \u00b1 13.76; kappa 58.04% \u00b1 18.43. Cross-subject LOSO accuracy: 68.20% \u00b1 12.13; kappa 57.33% \u00b1 16.22. The fuzzy model outperforms in within-subject evaluations, while the deep model shows stronger generalization across subjects.", "conclusion": "The study provides practical guidance on selecting MI-BCI systems based on design goals\u2014prioritize interpretability for within-subject use or robustness across users for cross-subject deployment\u2014and suggests future exploration of transformer-based and hybrid neuro-symbolic frameworks to advance transparent EEG decoding."}}
{"id": "2511.00560", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00560", "abs": "https://arxiv.org/abs/2511.00560", "authors": ["Chun-Tin Wu", "Jun-Cheng Chen"], "title": "4D Neural Voxel Splatting: Dynamic Scene Rendering with Voxelized Guassian Splatting", "comment": "10 pages, 7 figures", "summary": "Although 3D Gaussian Splatting (3D-GS) achieves efficient rendering for novel\nview synthesis, extending it to dynamic scenes still results in substantial\nmemory overhead from replicating Gaussians across frames. To address this\nchallenge, we propose 4D Neural Voxel Splatting (4D-NVS), which combines\nvoxel-based representations with neural Gaussian splatting for efficient\ndynamic scene modeling. Instead of generating separate Gaussian sets per\ntimestamp, our method employs a compact set of neural voxels with learned\ndeformation fields to model temporal dynamics. The design greatly reduces\nmemory consumption and accelerates training while preserving high image\nquality. We further introduce a novel view refinement stage that selectively\nimproves challenging viewpoints through targeted optimization, maintaining\nglobal efficiency while enhancing rendering quality for difficult viewing\nangles. Experiments demonstrate that our method outperforms state-of-the-art\napproaches with significant memory reduction and faster training, enabling\nreal-time rendering with superior visual fidelity.", "AI": {"tldr": "4D-NVS combines a compact neural voxel grid with learned deformation fields and neural Gaussian splatting to model dynamic scenes, reducing memory, speeding training, and enabling high-fidelity, real-time rendering, aided by a targeted view refinement stage.", "motivation": "Dynamic 3D Gaussian Splatting incurs huge memory costs because Gaussians must be replicated across time. There is a need for a compact, efficient dynamic 3D representation that preserves quality.", "method": "Employ a compact set of neural voxels with learned deformation fields to encode temporal dynamics, eliminating per-frame Gaussian replication. Integrate neural voxels with Gaussian splatting and add a view refinement stage that selectively optimizes challenging viewpoints to boost rendering quality without sacrificing global efficiency.", "result": "Claims significant memory reduction and faster training compared to state-of-the-art methods, enabling real-time rendering with high visual fidelity, as demonstrated by experiments.", "conclusion": "The approach demonstrates that neural voxel grids with deformation fields can effectively model dynamic scenes when combined with Gaussian splatting, achieving efficient, high-quality rendering. It introduces a practical view refinement stage, with strong empirical performance, though broader validation would strengthen claims."}}
{"id": "2511.00375", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.00375", "abs": "https://arxiv.org/abs/2511.00375", "authors": ["Xin Wang", "Yunhao Xiao", "Rui Qiao"], "title": "PolyRecommender: A Multimodal Recommendation System for Polymer Discovery", "comment": null, "summary": "We introduce PolyRecommender, a multimodal discovery framework that\nintegrates chemical language representations from PolyBERT with molecular\ngraph-based representations from a graph encoder. The system first retrieves\ncandidate polymers using language-based similarity and then ranks them using\nfused multimodal embeddings according to multiple target properties. By\nleveraging the complementary knowledge encoded in both modalities,\nPolyRecommender enables efficient retrieval and robust ranking across related\npolymer properties. Our work establishes a generalizable multimodal paradigm,\nadvancing AI-guided design for the discovery of next-generation polymers.", "AI": {"tldr": "PolyRecommender is a multimodal polymer discovery framework that combines PolyBERT chemical language representations with graph-based molecular embeddings to retrieve candidates via language similarity and rank them through fused multimodal embeddings across multiple properties.", "motivation": "To enhance polymer discovery by integrating complementary information from language-based representations and molecular graphs, enabling efficient retrieval and robust multi-property ranking.", "method": "Retrieve candidate polymers using language-based similarity (PolyBERT), then fuse PolyBERT and graph-encoder embeddings to rank polymers for multiple target properties.", "result": "Proposes a generalizable multimodal paradigm for AI-guided polymer design, showing improved retrieval and ranking by leveraging complementary modalities across properties.", "conclusion": "A versatile framework that advances multimodal material discovery and can be extended to other polymer design tasks."}}
{"id": "2511.00573", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00573", "abs": "https://arxiv.org/abs/2511.00573", "authors": ["Wei Feng", "Zongyuan Ge"], "title": "Generalized Category Discovery under Domain Shift: A Frequency Domain Perspective", "comment": "29 pages, 5 figures", "summary": "Generalized Category Discovery (GCD) aims to leverage labeled samples from\nknown categories to cluster unlabeled data that may include both known and\nunknown categories. While existing methods have achieved impressive results\nunder standard conditions, their performance often deteriorates in the presence\nof distribution shifts. In this paper, we explore a more realistic task:\nDomain-Shifted Generalized Category Discovery (DS\\_GCD), where the unlabeled\ndata includes not only unknown categories but also samples from unknown\ndomains. To tackle this challenge, we propose a\n\\textbf{\\underline{F}}requency-guided Gene\\textbf{\\underline{r}}alized\nCat\\textbf{\\underline{e}}gory Discov\\textbf{\\underline{e}}ry framework (FREE)\nthat enhances the model's ability to discover categories under distributional\nshift by leveraging frequency-domain information. Specifically, we first\npropose a frequency-based domain separation strategy that partitions samples\ninto known and unknown domains by measuring their amplitude differences. We\nthen propose two types of frequency-domain perturbation strategies: a\ncross-domain strategy, which adapts to new distributions by exchanging\namplitude components across domains, and an intra-domain strategy, which\nenhances robustness to intra-domain variations within the unknown domain.\nFurthermore, we extend the self-supervised contrastive objective and semantic\nclustering loss to better guide the training process. Finally, we introduce a\nclustering-difficulty-aware resampling technique to adaptively focus on\nharder-to-cluster categories, further enhancing model performance. Extensive\nexperiments demonstrate that our method effectively mitigates the impact of\ndistributional shifts across various benchmark datasets and achieves superior\nperformance in discovering both known and unknown categories.", "AI": {"tldr": "Proposes FREE, a frequency-guided framework for Domain-Shifted Generalized Category Discovery (DS_GCD) that uses frequency-domain perturbations and domain separation to robustly discover both known and unknown categories under distribution shifts.", "motivation": "GCD methods struggle when unlabeled data come from unknown domains or contain distributional shifts; realistic DS_GCD settings require robustness to domain changes and unseen categories.", "method": "1) Frequency-based domain separation to split data into known/unknown domains via amplitude differences. 2) Cross-domain perturbation by exchanging amplitude components across domains to adapt to new distributions. 3) Intra-domain perturbation to increase robustness to intra-domain variation within the unknown domain. 4) Extended self-supervised contrastive objective and semantic clustering loss to guide learning. 5) Clustering-difficulty-aware resampling to focus on harder-to-cluster categories.", "result": "Extensive experiments show the approach mitigates the impact of distributional shifts and achieves superior performance in discovering both known and unknown categories across benchmark datasets.", "conclusion": "Frequency-guided learning yields robust DS_GCD performance under domain shifts, advancing generalized category discovery in more realistic, shift-prone environments."}}
{"id": "2511.00405", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00405", "abs": "https://arxiv.org/abs/2511.00405", "authors": ["Zhibin Lan", "Liqiang Niu", "Fandong Meng", "Jie Zhou", "Jinsong Su"], "title": "UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings", "comment": null, "summary": "The remarkable success of multimodal large language models (MLLMs) has driven\nadvances in multimodal embeddings, yet existing models remain inherently\ndiscriminative, limiting their ability to benefit from reasoning-driven\ngeneration paradigm. In this work, we pioneer the exploration of generative\nembeddings, unifying embedding tasks within a generative paradigm. We propose\nUME-R1, a universal multimodal embedding framework consisting of a two-stage\ntraining strategy: a cold-start supervised fine-tuning equips the model with\nreasoning capabilities and enables it to generate both discriminative and\ngenerative embeddings; a subsequent reinforcement learning enhances reasoning\nand further optimizes generative embedding quality. This pioneering work\nreveals four key insights: 1) generative embeddings unlock substantial\nperformance gains over conventional discriminative embeddings by leveraging the\npowerful generative reasoning capabilities of MLLMs; 2) discriminative and\ngenerative embeddings are complementary, whose combined oracle performance far\nexceeding that of either alone; 3) RL can effectively enhance generative\nembeddings, establishing a scalable optimization paradigm.; 4) repeated\nsampling at inference boosts downstream task coverage (pass@k), highlighting\nthe inference-time scalability potential of generative embeddings. Evaluated on\nthe MMEB-V2 benchmark across 78 tasks spanning video, image, and visual\ndocuments, UME-R1 significantly outperforms conventional discriminative\nembedding models and offers a foundation for more interpretable,\nreasoning-driven generative multimodal embeddings. Our code, models, and\ndatasets will be publicly available at https://github.com/XMUDeepLIT/UME-R1.", "AI": {"tldr": "Proposes UME-R1, a universal multimodal embedding framework that learns both discriminative and generative embeddings via a two-stage training pipeline: cold-start supervised fine-tuning to enable reasoning and generation, followed by reinforcement learning to enhance generative embedding quality; shows gains on MMEB-V2 across 78 tasks and highlights inference-time sampling for better coverage.", "motivation": "Current multimodal embeddings in MLLMs are mostly discriminative, limiting reasoning-driven generation. Generative embeddings could leverage reasoning capabilities to improve downstream tasks and interpretability, and enable complementary benefits with discriminative embeddings.", "method": "Two-stage approach: (1) cold-start supervised fine-tuning to instill reasoning and enable generation of both embedding types; (2) reinforcement learning to further enhance reasoning and optimizes generative embedding quality. Includes repeated sampling at inference to boost task coverage (pass@k). evaluated on MMEB-V2 across 78 tasks (video, image, visual documents).", "result": "Generative embeddings outperform conventional discriminative embeddings; discriminative and generative embeddings are complementary with oracle performance exceeding either alone; RL effectively enhances generative embeddings; inference-time sampling increases pass@k and shows scalability potential.", "conclusion": "Generative embeddings enable reasoning-driven, interpretable multimodal embeddings and, with UME-R1, establish a foundation for unified generation and retrieval tasks; plan to release code, models, and datasets to support further research."}}
{"id": "2511.00580", "categories": ["cs.CV", "cs.AI", "68T07, 68T45, 68U10", "I.2.10; I.5.4; I.4.8; C.3"], "pdf": "https://arxiv.org/pdf/2511.00580", "abs": "https://arxiv.org/abs/2511.00580", "authors": ["Yousuf Ahmed Siddiqui", "Sufiyaan Usmani", "Umer Tariq", "Jawwad Ahmed Shamsi", "Muhammad Burhan Khan"], "title": "TRACES: Temporal Recall with Contextual Embeddings for Real-Time Video Anomaly Detection", "comment": "10 pages, 5 figures", "summary": "Video anomalies often depend on contextual information available and temporal\nevolution. Non-anomalous action in one context can be anomalous in some other\ncontext. Most anomaly detectors, however, do not notice this type of context,\nwhich seriously limits their capability to generalize to new, real-life\nsituations. Our work addresses the context-aware zero-shot anomaly detection\nchallenge, in which systems need to learn adaptively to detect new events by\ncorrelating temporal and appearance features with textual traces of memory in\nreal time. Our approach defines a memory-augmented pipeline, correlating\ntemporal signals with visual embeddings using cross-attention, and real-time\nzero-shot anomaly classification by contextual similarity scoring. We achieve\n90.4\\% AUC on UCF-Crime and 83.67\\% AP on XD-Violence, a new state-of-the-art\namong zero-shot models. Our model achieves real-time inference with high\nprecision and explainability for deployment. We show that, by fusing\ncross-attention temporal fusion and contextual memory, we achieve high fidelity\nanomaly detection, a step towards the applicability of zero-shot models in\nreal-world surveillance and infrastructure monitoring.", "AI": {"tldr": "Memory-augmented, context-aware zero-shot video anomaly detection using cross-attention between temporal signals and visual embeddings with textual memory traces, enabling real-time inference and state-of-the-art zero-shot performance.", "motivation": "Anomalies are highly contextual; existing detectors lack context-aware generalization, especially in zero-shot setups; need models that adapt in real time using memory traces.", "method": "Proposes a memory-augmented pipeline that correlates temporal features with visual embeddings via cross-attention, and performs real-time zero-shot anomaly classification through contextual similarity scoring; fuses cross-attention temporal fusion with contextual memory for anomaly detection.", "result": "Achieves 90.4% AUC on UCF-Crime and 83.67% AP on XD-Violence; claims state-of-the-art among zero-shot models; supports real-time inference and provides explainability.", "conclusion": "Contextual memory fusion enhances anomaly fidelity and generalization, advancing practical deployment of zero-shot video anomaly detectors in surveillance and infrastructure monitoring."}}
{"id": "2511.00411", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00411", "abs": "https://arxiv.org/abs/2511.00411", "authors": ["Zenghao Niu", "Weicheng Xie", "Siyang Song", "Zitong Yu", "Feng Liu", "Linlin Shen"], "title": "Enhancing Adversarial Transferability by Balancing Exploration and Exploitation with Gradient-Guided Sampling", "comment": "accepted by iccv 2025", "summary": "Adversarial attacks present a critical challenge to deep neural networks'\nrobustness, particularly in transfer scenarios across different model\narchitectures. However, the transferability of adversarial attacks faces a\nfundamental dilemma between Exploitation (maximizing attack potency) and\nExploration (enhancing cross-model generalization). Traditional momentum-based\nmethods over-prioritize Exploitation, i.e., higher loss maxima for attack\npotency but weakened generalization (narrow loss surface). Conversely, recent\nmethods with inner-iteration sampling over-prioritize Exploration, i.e.,\nflatter loss surfaces for cross-model generalization but weakened attack\npotency (suboptimal local maxima). To resolve this dilemma, we propose a simple\nyet effective Gradient-Guided Sampling (GGS), which harmonizes both objectives\nthrough guiding sampling along the gradient ascent direction to improve both\nsampling efficiency and stability. Specifically, based on MI-FGSM, GGS\nintroduces inner-iteration random sampling and guides the sampling direction\nusing the gradient from the previous inner-iteration (the sampling's magnitude\nis determined by a random distribution). This mechanism encourages adversarial\nexamples to reside in balanced regions with both flatness for cross-model\ngeneralization and higher local maxima for strong attack potency. Comprehensive\nexperiments across multiple DNN architectures and multimodal large language\nmodels (MLLMs) demonstrate the superiority of our method over state-of-the-art\ntransfer attacks. Code is made available at https://github.com/anuin-cat/GGS.", "AI": {"tldr": "Gradient-Guided Sampling (GGS) balances attack potency and cross-model generalization by guiding inner-iteration sampling along the gradient from the previous step, using a random-magnitude step. It improves transferability of adversarial examples across architectures and multimodal models, outperforming existing methods, with code available.", "motivation": "There is a fundamental trade-off in transfer attacks between Exploitation (maximizing local loss maxima for potency) and Exploration (flattening the loss landscape for cross-model generalization). Traditional momentum-based methods emphasize Exploitation and inner-iteration sampling emphasizes Exploration, leading to suboptimal compromises. A method is needed to harmonize both objectives.", "method": "Extend MI-FGSM with inner-iteration random sampling guided by the gradient from the previous inner-iteration. The sampling magnitude is drawn from a random distribution, while the sampling direction aligns with the gradient ascent direction to encourage adversarial examples that sit in regions offering both flatness (for generalization) and high maxima (for potency). This yields a more efficient and stable sampling process.", "result": "Empirical evaluations on multiple DNN architectures and multimodal LLMs show that Gradient-Guided Sampling (GGS) achieves superior transferability and robustness compared to state-of-the-art transfer attacks, demonstrating improved performance across diverse models.", "conclusion": "GGS resolves the exploitation\u2013exploration dilemma in transfer attacks by harmonizing potent local maxima with flat, generalizable loss surfaces through gradient-guided inner-iteration sampling. The approach is simple, effective, and yields better cross-model transferability; code is released for replication."}}
{"id": "2511.00613", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00613", "abs": "https://arxiv.org/abs/2511.00613", "authors": ["Yating Yu", "Congqi Cao", "Zhaoying Wang", "Weihua Meng", "Jie Li", "Yuxin Li", "Zihao Wei", "Zhongpei Shen", "Jiajun Zhang"], "title": "CueBench: Advancing Unified Understanding of Context-Aware Video Anomalies in Real-World", "comment": null, "summary": "How far are deep models from real-world video anomaly understanding (VAU)?\nCurrent works typically emphasize on detecting unexpected occurrences deviated\nfrom normal patterns or comprehending anomalous events with interpretable\ndescriptions. However, they exhibit only a superficial comprehension of\nreal-world anomalies, with limited breadth in complex principles and subtle\ncontext that distinguish the anomalies from normalities, e.g., climbing cliffs\nwith safety gear vs. without it. To this end, we introduce CueBench, the first\nof its kind Benchmark, devoted to Context-aware video anomalies within a\nUnified Evaluation framework. We comprehensively establish an event-centric\nhierarchical taxonomy that anchors two core event types: 14 conditional and 18\nabsolute anomaly events, defined by their refined semantics from diverse\ncontexts across 174 scenes and 198 attributes. Based on this, we propose to\nunify and benchmark context-aware VAU with various challenging tasks across\nrecognition, temporal grounding, detection, and anticipation. This also serves\nas a rigorous and fair probing evaluation suite for generative-discriminative\nas well as generalized-specialized vision-language models (VLMs). To address\nthe challenges underlying CueBench, we further develop Cue-R1 based on R1-style\nreinforcement fine-tuning with verifiable, task-aligned, and hierarchy-refined\nrewards in a unified generative manner. Extensive results on CueBench reveal\nthat, existing VLMs are still far from satisfactory real-world anomaly\nunderstanding, while our Cue-R1 surpasses these state-of-the-art approaches by\nover 24% on average.", "AI": {"tldr": "CueBench introduces a hierarchical, event-centric benchmark for context-aware video anomalies (VAU) and a unified evaluation framework across recognition, grounding, detection, and anticipation. It defines 14 conditional and 18 absolute anomaly events over 174 scenes and 198 attributes, and presents Cue-R1, an R1-style reinforcement-tuning approach, achieving >24% gains over state-of-the-art VLMs on CueBench.", "motivation": "Current VAU research emphasizes simple anomaly detection or interpretable descriptions but lacks deep, context-aware understanding of anomalies in real-world settings. There is a need for a rigorous, unified benchmark and robust, context-aware models that can generalize across diverse contexts.", "method": "Propose CueBench with an event-centric hierarchical taxonomy (14 conditional + 18 absolute anomaly events across 174 scenes and 198 attributes) and a unified evaluation suite covering recognition, temporal grounding, detection, and anticipation. Introduce Cue-R1, an R1-style reinforcement fine-tuning framework with verifiable, task-aligned, and hierarchy-refined rewards in a unified generative model.", "result": "Extensive experiments on CueBench show existing vision-language models (VLMs) fall short on real-world VAU. Cue-R1 surpasses these state-of-the-art approaches by over 24% on average.", "conclusion": "CueBench provides a rigorous, fair probing suite for context-aware VAU and establishes a path to more capable models through hierarchy-aware rewards and unified evaluation. The reported gains of Cue-R1 indicate substantial progress toward practical real-world anomaly understanding."}}
{"id": "2511.00423", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.00423", "abs": "https://arxiv.org/abs/2511.00423", "authors": ["Guojian Zhan", "Likun Wang", "Xiangteng Zhang", "Jiaxin Gao", "Masayoshi Tomizuka", "Shengbo Eben Li"], "title": "Bootstrap Off-policy with World Model", "comment": "NeurIPS 2025", "summary": "Online planning has proven effective in reinforcement learning (RL) for\nimproving sample efficiency and final performance. However, using planning for\nenvironment interaction inevitably introduces a divergence between the\ncollected data and the policy's actual behaviors, degrading both model learning\nand policy improvement. To address this, we propose BOOM (Bootstrap Off-policy\nwith WOrld Model), a framework that tightly integrates planning and off-policy\nlearning through a bootstrap loop: the policy initializes the planner, and the\nplanner refines actions to bootstrap the policy through behavior alignment.\nThis loop is supported by a jointly learned world model, which enables the\nplanner to simulate future trajectories and provides value targets to\nfacilitate policy improvement. The core of BOOM is a likelihood-free alignment\nloss that bootstraps the policy using the planner's non-parametric action\ndistribution, combined with a soft value-weighted mechanism that prioritizes\nhigh-return behaviors and mitigates variability in the planner's action quality\nwithin the replay buffer. Experiments on the high-dimensional DeepMind Control\nSuite and Humanoid-Bench show that BOOM achieves state-of-the-art results in\nboth training stability and final performance. The code is accessible at\nhttps://github.com/molumitu/BOOM_MBRL.", "AI": {"tldr": "BOOM tightly couples planning and off-policy learning via a bootstrap loop with a world model, achieving state-of-the-art stability and performance on DM Control Suite and Humanoid-Bench.", "motivation": "Tackle the divergence between data distribution and policy behavior caused by online planning, which can impair model learning and policy improvement in reinforcement learning.", "method": "Policy initializes the planner; the planner refines actions to bootstrap the policy through behavior alignment. A jointly learned world model enables the planner to simulate futures and provides value targets. Core: a likelihood-free alignment loss that bootstraps the policy using the planner's non-parametric action distribution, combined with a soft value-weighted mechanism to prioritize high-return behaviors and reduce variability from planner quality in the replay buffer.", "result": "BOOM achieves state-of-the-art training stability and final performance on high-dimensional benchmarks (DeepMind Control Suite and Humanoid-Bench). Code is released at the provided GitHub URL.", "conclusion": "Integrating planning and off-policy learning through a bootstrap loop with a world model yields more stable and higher-performing RL, suggesting broad applicability to model-based planning in policy optimization."}}
{"id": "2511.00413", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00413", "abs": "https://arxiv.org/abs/2511.00413", "authors": ["Shaojie Wang", "Jinghui Wang", "Yinghan Cui", "Xuxing Chen", "Chao Wang", "Liang Huang", "Xiaojiang Zhang", "Junyi Peng", "Li Wan", "Haotian Zhang", "Bin Chen"], "title": "Tree Training: Accelerating Agentic LLMs Training via Shared Prefix Reuse", "comment": null, "summary": "In agentic LLM scenarios, an agent's interaction process during a single\nrollout often exhibits branching behaviors. Due to memory retrieval and\nconcurrent tool executions at certain decision points, the token trajectory of\none task evolves into a tree-like structure rather than a linear sequence.\nHowever, current training pipelines decompose such tree-structured trajectories\ninto separate linear segments, treating each branch as an independent sequence.\nAs a result, shared prefixes across these branches are repeatedly recomputed\nduring both forward and backward passes. To address this inefficiency, we\npropose Tree Training, a paradigm that computes each shared prefix only once\nand reuses its intermediate results across related branches during both forward\nand backward passes, substantially improving computation efficiency in\nlarge-scale agentic training. This is achieved via (i) Tree Packing, which\nefficiently reuses shared computations across trajectories, and (ii) Gradient\nRestoration, which ensures correct gradient propagation across reused prefixes.\nExperiments on multiple open-source models demonstrate up to 3.9x reduction in\ntotal training time, enabling more efficient agentic LLM SFT and RL training.", "AI": {"tldr": "Tree Training reuses shared prefixes in tree-like token trajectories of agentic LLMs to avoid recomputation, achieving up to 3.9x training speedups.", "motivation": "In agentic LLM rollouts, decisions yield a tree-structured trajectory due to memory retrieval and concurrent tool usage. Current pipelines decompose into linear segments, causing redundant computation on shared prefixes.", "method": "Introduce Tree Training with Tree Packing to reuse shared computations across branches and Gradient Restoration to propagate gradients correctly; enables forward/backward reuse of shared prefixes.", "result": "Experiments on multiple open-source models show up to 3.9x reduction in total training time, enabling more efficient supervised fine-tuning (SFT) and reinforcement learning (RL) training.", "conclusion": "Tree Training effectively utilizes shared computations across branching trajectories, yielding substantial efficiency gains for large-scale agentic training and potentially accelerating development of autonomous LLM agents."}}
{"id": "2511.00643", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00643", "abs": "https://arxiv.org/abs/2511.00643", "authors": ["Oluwatosin Alabi", "Meng Wei", "Charlie Budd", "Tom Vercauteren", "Miaojing Shi"], "title": "Grounding Surgical Action Triplets with Instrument Instance Segmentation: A Dataset and Target-Aware Fusion Approach", "comment": null, "summary": "Understanding surgical instrument-tissue interactions requires not only\nidentifying which instrument performs which action on which anatomical target,\nbut also grounding these interactions spatially within the surgical scene.\nExisting surgical action triplet recognition methods are limited to learning\nfrom frame-level classification, failing to reliably link actions to specific\ninstrument instances.Previous attempts at spatial grounding have primarily\nrelied on class activation maps, which lack the precision and robustness\nrequired for detailed instrument-tissue interaction analysis.To address this\ngap, we propose grounding surgical action triplets with instrument instance\nsegmentation, or triplet segmentation for short, a new unified task which\nproduces spatially grounded <instrument, verb, target> outputs.We start by\npresenting CholecTriplet-Seg, a large-scale dataset containing over 30,000\nannotated frames, linking instrument instance masks with action verb and\nanatomical target annotations, and establishing the first benchmark for\nstrongly supervised, instance-level triplet grounding and evaluation.To learn\ntriplet segmentation, we propose TargetFusionNet, a novel architecture that\nextends Mask2Former with a target-aware fusion mechanism to address the\nchallenge of accurate anatomical target prediction by fusing weak anatomy\npriors with instrument instance queries.Evaluated across recognition,\ndetection, and triplet segmentation metrics, TargetFusionNet consistently\nimproves performance over existing baselines, demonstrating that strong\ninstance supervision combined with weak target priors significantly enhances\nthe accuracy and robustness of surgical action understanding.Triplet\nsegmentation establishes a unified framework for spatially grounding surgical\naction triplets. The proposed benchmark and architecture pave the way for more\ninterpretable, surgical scene understanding.", "AI": {"tldr": "A new task, triplet segmentation, grounds instrument-verb-target actions at the instance level. A large dataset (CholecTriplet-Seg, ~30k frames) and a model (TargetFusionNet) extend Mask2Former with target-aware fusion to fuse anatomy priors with instrument queries, achieving improved performance over baselines and enabling interpretable surgical scene understanding.", "motivation": "Frame-level surgical action recognition lacks precise spatial grounding and robustly linking actions to specific instrument instances; prior spatial grounding via class activation maps is insufficient for detailed instrument-tissue interaction analysis.", "method": "Create CholecTriplet-Seg, a large-scale dataset with instrument instance masks linked to verb and anatomical target annotations; propose TargetFusionNet that extends Mask2Former with a target-aware fusion mechanism to combine weak anatomy priors with instrument instance queries for accurate target prediction.", "result": "TargetFusionNet outperforms existing baselines on recognition, detection, and triplet segmentation metrics, demonstrating that strong instance supervision plus weak target priors improves accuracy and robustness in surgical action understanding.", "conclusion": "Triplet segmentation provides a unified framework for spatially grounding surgical action triplets; the dataset and architecture enable more interpretable and robust surgical scene understanding."}}
{"id": "2511.00418", "categories": ["cs.LG", "math-ph", "math.MP", "nlin.PS", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.00418", "abs": "https://arxiv.org/abs/2511.00418", "authors": ["Victory Obieke", "Emmanuel Oguadimma"], "title": "Structure-Preserving Physics-Informed Neural Network for the Korteweg--de Vries (KdV) Equation", "comment": "9 Pages, 11 figures", "summary": "Physics-Informed Neural Networks (PINNs) offer a flexible framework for\nsolving nonlinear partial differential equations (PDEs), yet conventional\nimplementations often fail to preserve key physical invariants during long-term\nintegration. This paper introduces a \\emph{structure-preserving PINN} framework\nfor the nonlinear Korteweg--de Vries (KdV) equation, a prototypical model for\nnonlinear and dispersive wave propagation. The proposed method embeds the\nconservation of mass and Hamiltonian energy directly into the loss function,\nensuring physically consistent and energy-stable evolution throughout training\nand prediction. Unlike standard \\texttt{tanh}-based\nPINNs~\\cite{raissi2019pinn,wang2022modifiedpinn}, our approach employs\nsinusoidal activation functions that enhance spectral expressiveness and\naccurately capture the oscillatory and dispersive nature of KdV solitons.\nThrough representative case studies -- including single-soliton propagation\n(shape-preserving translation), two-soliton interaction (elastic collision with\nphase shift), and cosine-pulse initialization (nonlinear dispersive breakup) --\nthe model successfully reproduces hallmark behaviors of KdV dynamics while\nmaintaining conserved invariants. Ablation studies demonstrate that combining\ninvariant-constrained optimization with sinusoidal feature mappings accelerates\nconvergence, improves long-term stability, and mitigates drift without\nmulti-stage pretraining. These results highlight that computationally\nefficient, invariant-aware regularization coupled with sinusoidal\nrepresentations yields robust, energy-consistent PINNs for Hamiltonian partial\ndifferential equations such as the KdV equation.", "AI": {"tldr": "A structure-preserving PINN for the KdV equation that enforces mass and energy conservation via an invariant-aware loss and uses sinusoidal activations to capture oscillatory and dispersive dynamics, achieving stable long-term predictions and accurate soliton behavior.", "motivation": "To overcome drift and instability in long-term PINN simulations of nonlinear PDEs by embedding physical invariants (mass and Hamiltonian energy) directly into the training objective and enhancing expressiveness with sinusoidal features.", "method": "Incorporate conservation constraints for mass and Hamiltonian energy into the PINN loss. Replace standard tanh activations with sinusoidal activations to improve spectral expressiveness. Train on representative KdV scenarios (single soliton, two-soliton interaction, cosine-pulse) and perform ablations to assess impact of invariants and activation choice.", "result": "The invariant-constrained, sinusoid-activated PINN reproduces key KdV behaviors (shape-preserving solitons, elastic soliton collisions with phase shifts, nonlinear dispersive breakup) while maintaining conserved quantities. Ablations show faster convergence, better long-term stability, and reduced drift without pretraining.", "conclusion": "Invariant-aware regularization combined with sinusoidal representations yields robust, energy-consistent PINNs for Hamiltonian PDEs such as the KdV equation, offering improved long-term stability and physical fidelity."}}
{"id": "2511.00653", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00653", "abs": "https://arxiv.org/abs/2511.00653", "authors": ["Lassi Ruoppa", "Tarmo Hietala", "Verneri Sepp\u00e4nen", "Josef Taher", "Teemu Hakala", "Xiaowei Yu", "Antero Kukko", "Harri Kaartinen", "Juha Hyypp\u00e4"], "title": "Benchmarking individual tree segmentation using multispectral airborne laser scanning data: the FGI-EMIT dataset", "comment": "39 pages, 9 figures", "summary": "Individual tree segmentation (ITS) from LiDAR point clouds is fundamental for\napplications such as forest inventory, carbon monitoring and biodiversity\nassessment. Traditionally, ITS has been achieved with unsupervised\ngeometry-based algorithms, while more recent advances have shifted toward\nsupervised deep learning (DL). In the past, progress in method development was\nhindered by the lack of large-scale benchmark datasets, and the availability of\nnovel data formats, particularly multispectral (MS) LiDAR, remains limited to\nthis day, despite evidence that MS reflectance can improve the accuracy of ITS.\nThis study introduces FGI-EMIT, the first large-scale MS airborne laser\nscanning benchmark dataset for ITS. Captured at wavelengths 532, 905, and 1,550\nnm, the dataset consists of 1,561 manually annotated trees, with a particular\nfocus on small understory trees. Using FGI-EMIT, we comprehensively benchmarked\nfour conventional unsupervised algorithms and four supervised DL approaches.\nHyperparameters of unsupervised methods were optimized using a Bayesian\napproach, while DL models were trained from scratch. Among the unsupervised\nmethods, Treeiso achieved the highest test set F1-score of 52.7%. The DL\napproaches performed significantly better overall, with the best model,\nForestFormer3D, attaining an F1-score of 73.3%. The most significant difference\nwas observed in understory trees, where ForestFormer3D exceeded Treeiso by 25.9\npercentage points. An ablation study demonstrated that current DL-based\napproaches generally fail to leverage MS reflectance information when it is\nprovided as additional input features, although single channel reflectance can\nimprove accuracy marginally, especially for understory trees. A performance\nanalysis across point densities further showed that DL methods consistently\nremain superior to unsupervised algorithms, even at densities as low as 10\npoints/m$^2$.", "AI": {"tldr": "FGI-EMIT provides the first large-scale multispectral airborne LiDAR benchmark for ITS, showing deep learning methods outperform unsupervised ones, especially for understory trees; multispectral reflectance as extra input offers limited gains, while single-channel reflectance can help modestly; DL methods remain robust even at very low densities.", "motivation": "Address the lack of large-scale multispectral LiDAR ITS benchmarks and assess whether multispectral input improves ITS performance.", "method": "Benchmark four unsupervised ITS algorithms and four deep-learning ITS models. Hyperparameters for unsupervised methods were optimized via Bayesian optimization; DL models trained from scratch. The dataset comprises 1,561 manually annotated trees across wavelengths 532, 905, and 1,550 nm, with emphasis on understory trees. An ablation study explored MS reflectance as additional input features, and performance was analyzed across varying point densities.", "result": "Unsupervised Treeiso achieved the highest test F1-score among its group at 52.7%. The best DL model (ForestFormer3D) reached 73.3% F1, with the largest gain in understory trees (ForestFormer3D outperforming Treeiso by 25.9 percentage points). The ablation study showed current DL methods generally fail to leverage MS reflectance as added inputs; single-channel reflectance can modestly improve accuracy, particularly for understory trees. Across densities, DL methods consistently outperform unsupervised methods even at very low densities (as low as 10 points/m^2).", "conclusion": "DL-based ITS methods yield clear performance advantages over unsupervised geometry-based methods, and multispectral reflectance as extra inputs does not yet provide significant gains for current DL architectures. The dataset enables future exploration of MS LiDAR in ITS, with strong indications that DL approaches maintain robustness across varying data densities."}}
{"id": "2511.01223", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01223", "abs": "https://arxiv.org/abs/2511.01223", "authors": ["Zahra Mehraban", "Sebastien Glaser", "Michael Milford", "Ronald Schroeter"], "title": "Saliency-Guided Domain Adaptation for Left-Hand Driving in Autonomous Steering", "comment": null, "summary": "Domain adaptation is required for automated driving models to generalize well\nacross diverse road conditions. This paper explores a training method for\ndomain adaptation to adapt PilotNet, an end-to-end deep learning-based model,\nfor left-hand driving conditions using real-world Australian highway data. Four\ntraining methods were evaluated: (1) a baseline model trained on U.S.\nright-hand driving data, (2) a model trained on flipped U.S. data, (3) a model\npretrained on U.S. data and then fine-tuned on Australian highways, and (4) a\nmodel pretrained on flipped U.S. data and then finetuned on Australian\nhighways. This setup examines whether incorporating flipped data enhances the\nmodel adaptation by providing an initial left-hand driving alignment. The paper\ncompares model performance regarding steering prediction accuracy and\nattention, using saliency-based analysis to measure attention shifts across\nsignificant road regions. Results show that pretraining on flipped data alone\nworsens prediction stability due to misaligned feature representations, but\nsignificantly improves adaptation when followed by fine-tuning, leading to\nlower prediction error and stronger focus on left-side cues. To validate this\napproach across different architectures, the same experiments were done on\nResNet, which confirmed similar adaptation trends. These findings emphasize the\nimportance of preprocessing techniques, such as flipped-data pretraining,\nfollowed by fine-tuning to improve model adaptation with minimal retraining\nrequirements.", "AI": {"tldr": "Flipped-data pretraining followed by fine-tuning improves cross-domain adaptation for left-hand driving in end-to-end models, although flipped pretraining alone can harm stability; benefits observed across PilotNet and ResNet architectures.", "motivation": "Generalize automated driving models to diverse road conditions, specifically adapting a right-hand driving model (PilotNet) to left-hand driving scenarios using domain adaptation via data preprocessing and transfer learning.", "method": "Evaluate four training pipelines: (1) baseline trained on US right-hand data, (2) model trained on flipped US data to simulate left-hand driving, (3) model pretrained on US data then fine-tuned on Australian highways, (4) model pretrained on flipped US data then fine-tuned on Australian highways. Assess steering prediction accuracy and attention via saliency-based analysis. Validate findings on a ResNet architecture to test generalizability across architectures.", "result": "Pretraining on flipped data alone worsens prediction stability due to misaligned feature representations. However, flipping pretraining followed by fine-tuning on Australian highways yields improved adaptation: lower prediction error and stronger attention on left-side cues. Similar adaptation trends were observed with ResNet, indicating generalizability of the approach across architectures.", "conclusion": "Flipped-data pretraining, when followed by fine-tuning, is an effective preprocessing strategy to enhance cross-domain adaptation for left-hand driving with minimal retraining, and should be considered for domain adaptation in end-to-end driving models."}}
{"id": "2511.00681", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00681", "abs": "https://arxiv.org/abs/2511.00681", "authors": ["Mehmet Yigit Avci", "Pedro Borges", "Virginia Fernandez", "Paul Wright", "Mehmet Yigitsoy", "Sebastien Ourselin", "Jorge Cardoso"], "title": "Metadata-Aligned 3D MRI Representations for Contrast Understanding and Quality Control", "comment": null, "summary": "Magnetic Resonance Imaging suffers from substantial data heterogeneity and\nthe absence of standardized contrast labels across scanners, protocols, and\ninstitutions, which severely limits large-scale automated analysis. A unified\nrepresentation of MRI contrast would enable a wide range of downstream\nutilities, from automatic sequence recognition to harmonization and quality\ncontrol, without relying on manual annotations. To this end, we introduce\nMR-CLIP, a metadata-guided framework that learns MRI contrast representations\nby aligning volumetric images with their DICOM acquisition parameters. The\nresulting embeddings shows distinct clusters of MRI sequences and outperform\nsupervised 3D baselines under data scarcity in few-shot sequence\nclassification. Moreover, MR-CLIP enables unsupervised data quality control by\nidentifying corrupted or inconsistent metadata through image-metadata embedding\ndistances. By transforming routinely available acquisition metadata into a\nsupervisory signal, MR-CLIP provides a scalable foundation for label-efficient\nMRI analysis across diverse clinical datasets.", "AI": {"tldr": "MR-CLIP proposes a metadata-guided approach to learn unified MRI contrast representations by aligning volumetric MR images with their DICOM acquisition parameters, enabling label-efficient analysis, sequence clustering, and unsupervised quality control.", "motivation": "MRI data sets suffer from substantial heterogeneity and lack standardized contrast labels across scanners and protocols, hindering large-scale automated analysis and annotation-free tasks.", "method": "A metadata-guided framework (MR-CLIP) that embeds volumetric MRI by aligning images with DICOM acquisition parameters. Acquisition metadata serves as supervisory signals to learn a contrast-aware embedding; the approach also uses image-metadata distances for unsupervised data quality control.", "result": "Embeddings form distinct clusters corresponding to MRI sequences; achieves better performance than supervised 3D baselines in few-shot sequence classification; enables unsupervised data-quality checks by measuring image-metadata embedding distances.", "conclusion": "MR-CLIP provides a scalable, label-efficient foundation for MRI analysis across diverse datasets, enabling sequence recognition, harmonization, and quality control without manual annotations."}}
{"id": "2511.01283", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01283", "abs": "https://arxiv.org/abs/2511.01283", "authors": ["Yupu Lu", "Shijie Lin", "Hao Xu", "Zeqing Zhang", "Jia Pan"], "title": "Lyapunov Stability Learning with Nonlinear Control via Inductive Biases", "comment": "Accepted by IEEE Robio 2025", "summary": "Finding a control Lyapunov function (CLF) in a dynamical system with a\ncontroller is an effective way to guarantee stability, which is a crucial issue\nin safety-concerned applications. Recently, deep learning models representing\nCLFs have been applied into a learner-verifier framework to identify\nsatisfiable candidates. However, the learner treats Lyapunov conditions as\ncomplex constraints for optimisation, which is hard to achieve global\nconvergence. It is also too complicated to implement these Lyapunov conditions\nfor verification. To improve this framework, we treat Lyapunov conditions as\ninductive biases and design a neural CLF and a CLF-based controller guided by\nthis knowledge. This design enables a stable optimisation process with limited\nconstraints, and allows end-to-end learning of both the CLF and the controller.\nOur approach achieves a higher convergence rate and larger region of attraction\n(ROA) in learning the CLF compared to existing methods among abundant\nexperiment cases. We also thoroughly reveal why the success rate decreases with\nprevious methods during learning.", "AI": {"tldr": "A neural CLF framework that treats Lyapunov conditions as inductive biases, enabling end-to-end learning of a CLF and a CLF-based controller with improved convergence and larger region of attraction, compared to prior methods.", "motivation": "Lyapunov constraints are hard to satisfy and verify in learning-based CLF design; existing learner-verifier approaches suffer from poor global convergence and complex implementation.", "method": "Incorporate Lyapunov conditions as inductive biases; design a neural CLF and a CLF-based controller guided by Lyapunov knowledge; enable stable optimization with limited constraints and end-to-end learning.", "result": "Higher convergence rate and larger region of attraction across experiments; deeper analysis of why previous methods' success rates drop during learning.", "conclusion": "Treat Lyapunov conditions as inductive biases to achieve efficient learning and stability guarantees, clarifying pitfalls of prior methods."}}
{"id": "2511.00443", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00443", "abs": "https://arxiv.org/abs/2511.00443", "authors": ["Ruthwik Reddy Doodipala", "Pankaj Pandey", "Carolina Torres Rojas", "Manob Jyoti Saikia", "Ranganatha Sitaram"], "title": "Region-Aware Reconstruction Strategy for Pre-training fMRI Foundation Model", "comment": null, "summary": "The emergence of foundation models in neuroimaging is driven by the\nincreasing availability of large-scale and heterogeneous brain imaging\ndatasets. Recent advances in self-supervised learning, particularly\nreconstruction-based objectives, have demonstrated strong potential for\npretraining models that generalize effectively across diverse downstream\nfunctional MRI (fMRI) tasks. In this study, we explore region-aware\nreconstruction strategies for a foundation model in resting-state fMRI, moving\nbeyond approaches that rely on random region masking. Specifically, we\nintroduce an ROI-guided masking strategy using the Automated Anatomical\nLabelling Atlas (AAL3), applied directly to full 4D fMRI volumes to selectively\nmask semantically coherent brain regions during self-supervised pretraining.\nUsing the ADHD-200 dataset comprising 973 subjects with resting-state fMRI\nscans, we show that our method achieves a 4.23% improvement in classification\naccuracy for distinguishing healthy controls from individuals diagnosed with\nADHD, compared to conventional random masking. Region-level attribution\nanalysis reveals that brain volumes within the limbic region and cerebellum\ncontribute most significantly to reconstruction fidelity and model\nrepresentation. Our results demonstrate that masking anatomical regions during\nmodel pretraining not only enhances interpretability but also yields more\nrobust and discriminative representations. In future work, we plan to extend\nthis approach by evaluating it on additional neuroimaging datasets, and\ndeveloping new loss functions explicitly derived from region-aware\nreconstruction objectives. These directions aim to further improve the\nrobustness and interpretability of foundation models for functional\nneuroimaging.", "AI": {"tldr": "ROI-guided masking in self-supervised pretraining on resting-state fMRI (AAL3 ROIs) yields clearer representations and a 4.23 percentage-point gain in HC-vs-ADHD classification, with limbic and cerebellar regions driving reconstruction fidelity.", "motivation": "To improve foundation-model pretraining for functional neuroimaging by introducing anatomically informed region-aware masking, aiming to boost downstream performance and interpretability across diverse fMRI tasks.", "method": "Apply ROI-guided masking using the AAL3 atlas directly to full 4D resting-state fMRI volumes during self-supervised reconstruction. Compare against conventional random masking on the ADHD-200 dataset (973 subjects). Perform region-level attribution to identify dominant contributing regions.", "result": "Achieves a 4.23% improvement in HC vs ADHD classification accuracy compared to random masking. Region-level attributions indicate the limbic region and cerebellum contribute most to reconstruction fidelity and to the learned representations.", "conclusion": "Masking anatomical regions during self-supervised pretraining enhances interpretability and yields more robust, discriminative representations; future work includes validating on additional datasets and developing region-aware reconstruction losses."}}
{"id": "2511.00682", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00682", "abs": "https://arxiv.org/abs/2511.00682", "authors": ["Hailing Wang", "jianglin Lu", "Yitian Zhang", "Yun Fu"], "title": "Outlier-Aware Post-Training Quantization for Image Super-Resolution", "comment": null, "summary": "Quantization techniques, including quantization-aware training (QAT) and\npost-training quantization (PTQ), have become essential for inference\nacceleration of image super-resolution (SR) networks. Compared to QAT, PTQ has\ngarnered significant attention as it eliminates the need for ground truth and\nmodel retraining. However, existing PTQ methods for SR often fail to achieve\nsatisfactory performance as they overlook the impact of outliers in activation.\nOur empirical analysis reveals that these prevalent activation outliers are\nstrongly correlated with image color information, and directly removing them\nleads to significant performance degradation. Motivated by this, we propose a\ndual-region quantization strategy that partitions activations into an outlier\nregion and a dense region, applying uniform quantization to each region\nindependently to better balance bit-width allocation. Furthermore, we observe\nthat different network layers exhibit varying sensitivities to quantization,\nleading to different levels of performance degradation. To address this, we\nintroduce sensitivity-aware finetuning that encourages the model to focus more\non highly sensitive layers, further enhancing quantization performance.\nExtensive experiments demonstrate that our method outperforms existing PTQ\napproaches across various SR networks and datasets, while achieving performance\ncomparable to QAT methods in most scenarios with at least a 75 speedup.", "AI": {"tldr": "Dual-region PTQ for image SR uses outlier/dense activation partitioning with region-specific uniform quantization and sensitivity-aware finetuning; achieves PTQ performance close to QAT with significant speedups.", "motivation": "PTQ is attractive due to no ground truth or retraining, but SR PTQ methods struggle due to activation outliers linked to color information; removing outliers degrades performance. A quantization strategy that accounts for outliers and layer sensitivity is needed.", "method": "Partition activations into an outlier region and a dense region, applying uniform quantization independently to each region; coupled with sensitivity-aware finetuning that emphasizes highly sensitive layers to improve overall quantization performance.", "result": "Outperforms existing PTQ methods across SR networks and datasets; achieves performance comparable to QAT in most cases, with at least 75x speedup over full precision or QAT.", "conclusion": "The proposed dual-region quantization with sensitivity-aware finetuning effectively handles activation outliers and layer sensitivity, narrowing the performance gap between PTQ and QAT for image super-resolution."}}
{"id": "2511.01381", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01381", "abs": "https://arxiv.org/abs/2511.01381", "authors": ["Hitesh Kyatham", "Arjun Suresh", "Aadi Palnitkar", "Yiannis Aloimonos"], "title": "EREBUS: End-to-end Robust Event Based Underwater Simulation", "comment": "Accepted to ICRA AQUA2SIM Workshop 2025, 6 pages, 3 figures,\n  conference paper", "summary": "The underwater domain presents a vast array of challenges for roboticists and\ncomputer vision researchers alike, such as poor lighting conditions and high\ndynamic range scenes. In these adverse conditions, traditional vision\ntechniques struggle to adapt and lead to suboptimal performance. Event-based\ncameras present an attractive solution to this problem, mitigating the issues\nof traditional cameras by tracking changes in the footage on a frame-by-frame\nbasis. In this paper, we introduce a pipeline which can be used to generate\nrealistic synthetic data of an event-based camera mounted to an AUV (Autonomous\nUnderwater Vehicle) in an underwater environment for training vision models. We\ndemonstrate the effectiveness of our pipeline using the task of rock detection\nwith poor visibility and suspended particulate matter, but the approach can be\ngeneralized to other underwater tasks.", "AI": {"tldr": "A pipeline to generate realistic synthetic data for event-based cameras mounted on an AUV in underwater environments, enabling training of vision models under challenging conditions; validated on rock detection with poor visibility and turbidity, with potential generalization to other tasks.", "motivation": "Underwater scenes suffer from poor lighting, high dynamic range, and turbidity, making traditional frame-based vision brittle. Event-based cameras capture changes efficiently and are promising, but real labeled underwater data for such sensors are scarce. A synthetic data pipeline can enable training and benchmarking for these sensors in realistic conditions.", "method": "Develop a pipeline that renders realistic underwater scenes and simulates an event-based camera mounted on an AUV, generating event streams under challenging visibility (poor lighting, suspended particulates). The pipeline is evaluated on a rock-detection task to demonstrate effectiveness and is claimed to generalize to other underwater tasks.", "result": "The pipeline produces usable synthetic event data and demonstrates effectiveness for rock detection under adverse visibility and particulates, showing promise for training vision models. The authors also claim the approach can be generalized to other underwater tasks.", "conclusion": "Synthetic data generation for event-based underwater cameras is viable and valuable for training and evaluating vision models in challenging aquatic environments, with potential applicability beyond rock detection to other tasks."}}
{"id": "2511.00462", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00462", "abs": "https://arxiv.org/abs/2511.00462", "authors": ["Xin Chen", "Saili Uday Gadgil", "Kangning Gao", "Yi Hu", "Cong Nie"], "title": "Deep Learning Approach to Anomaly Detection in Enterprise ETL Processes with Autoencoders", "comment": null, "summary": "An anomaly detection method based on deep autoencoders is proposed to address\nanomalies that often occur in enterprise-level ETL data streams. The study\nfirst analyzes multiple types of anomalies in ETL processes, including delays,\nmissing values, duplicate loading, and sudden abnormal changes, and applies\ndata standardization and feature modeling to ensure stable and usable inputs.\nIn the method design, the encoder-decoder structure compresses high-dimensional\ninputs into latent representations and reconstructs them, while reconstruction\nerror is used to measure anomaly levels. Regularization constraints are\nintroduced in the latent space to enhance feature sparsity and distribution\nlearning, thereby improving robustness in complex data streams. Systematic\nanalyses under different hyperparameter settings, environmental changes, and\ndata characteristics show that the proposed method achieves superior\nperformance in AUC, ACC, Precision, and Recall. The results demonstrate that\nthe deep autoencoder-based detection mechanism can effectively capture latent\ndistribution patterns in enterprise-level ETL data streams and accurately\nidentify diverse anomalies, providing reliable support for enterprise data\nprocessing and intelligent analysis.", "AI": {"tldr": "Deep autoencoder-based anomaly detection for enterprise ETL streams using reconstruction error and latent-space regularization, detecting delays, missing values, duplicates, and sudden changes.", "motivation": "Enterprise ETL data streams exhibit diverse anomalies that can disrupt data quality and analytics; robust, scalable anomaly detection is needed.", "method": "Train a deep encoder-decoder (autoencoder) with data standardization; learn latent representations; use reconstruction error as the anomaly score; apply regularization in latent space to promote sparsity and robust distribution learning; evaluate under varying hyperparameters, environments, and data characteristics.", "result": "The method achieves superior performance in AUC, ACC, Precision, and Recall across different settings and data characteristics, indicating effective capture of latent distribution patterns and accurate anomaly identification in enterprise ETL streams.", "conclusion": "Deep autoencoder-based anomaly detection is a reliable mechanism for detecting diverse anomalies in enterprise ETL data streams, supporting reliable enterprise data processing and intelligent analysis."}}
{"id": "2511.00686", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00686", "abs": "https://arxiv.org/abs/2511.00686", "authors": ["Alex Inch", "Passawis Chaiyapattanaporn", "Yuchen Zhu", "Yuan Lu", "Ting-Wen Ko", "Davide Paglieri"], "title": "Evolve to Inspire: Novelty Search for Diverse Image Generation", "comment": "14 pages, 10 figures, Accepted to Neurips 2025 GenProCC Workshop", "summary": "Text-to-image diffusion models, while proficient at generating high-fidelity\nim- ages, often suffer from limited output diversity, hindering their\napplication in exploratory and ideation tasks. Existing prompt optimization\ntechniques typically target aesthetic fitness or are ill-suited to the creative\nvisual domain. To address this shortcoming, we introduce WANDER, a novelty\nsearch-based approach to generating diverse sets of images from a single input\nprompt. WANDER operates directly on natural language prompts, employing a Large\nLanguage Model (LLM) for semantic evolution of diverse sets of images, and\nusing CLIP embeddings to quantify novelty. We additionally apply emitters to\nguide the search into distinct regions of the prompt space, and demonstrate\nthat they boost the diversity of the generated images. Empirical evaluations\nusing FLUX-DEV for generation and GPT-4o-mini for mutation demonstrate that\nWANDER significantly outperforms existing evolutionary prompt optimization\nbaselines in diversity metrics. Ablation studies confirm the efficacy of\nemitters.", "AI": {"tldr": "WANDER is a novelty-search based prompt optimization method that uses LLM-driven semantic evolution and CLIP-based novelty to generate diverse image sets from a single prompt, with emitters guiding exploration of distinct prompt-space regions; it outperforms baselines on diversity.", "motivation": "Text-to-image diffusion models produce high-fidelity outputs but suffer from limited diversity, hindering ideation and exploratory tasks; existing prompt optimization often targets aesthetics rather than creative diversity.", "method": "WANDER employs novelty search on natural-language prompts. It uses a Large Language Model to semantically mutate/promote diversity in prompts and CLIP embeddings to quantify novelty. Emitters steer the search into distinct regions of prompt space. Evaluation uses FLUX-DEV for generation and GPT-4o-mini for mutation, comparing against evolutionary prompt optimization baselines.", "result": "WANDER significantly outperforms existing evolutionary prompt optimization baselines in diversity metrics; ablation studies confirm the efficacy of emitters in boosting diversity.", "conclusion": "Novelty-driven prompt evolution, aided by prompt-space emitters and LLM-based semantic mutations, can substantially increase the diversity of diffusion-generated images, supporting more effective creative ideation workflows."}}
{"id": "2511.01501", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01501", "abs": "https://arxiv.org/abs/2511.01501", "authors": ["Yufeng Jin", "Niklas Funk", "Vignesh Prasad", "Zechu Li", "Mathias Franzius", "Jan Peters", "Georgia Chalvatzaki"], "title": "SE(3)-PoseFlow: Estimating 6D Pose Distributions for Uncertainty-Aware Robotic Manipulation", "comment": null, "summary": "Object pose estimation is a fundamental problem in robotics and computer\nvision, yet it remains challenging due to partial observability, occlusions,\nand object symmetries, which inevitably lead to pose ambiguity and multiple\nhypotheses consistent with the same observation. While deterministic deep\nnetworks achieve impressive performance under well-constrained conditions, they\nare often overconfident and fail to capture the multi-modality of the\nunderlying pose distribution. To address these challenges, we propose a novel\nprobabilistic framework that leverages flow matching on the SE(3) manifold for\nestimating 6D object pose distributions. Unlike existing methods that regress a\nsingle deterministic output, our approach models the full pose distribution\nwith a sample-based estimate and enables reasoning about uncertainty in\nambiguous cases such as symmetric objects or severe occlusions. We achieve\nstate-of-the-art results on Real275, YCB-V, and LM-O, and demonstrate how our\nsample-based pose estimates can be leveraged in downstream robotic manipulation\ntasks such as active perception for disambiguating uncertain viewpoints or\nguiding grasp synthesis in an uncertainty-aware manner.", "AI": {"tldr": "Probabilistic SE(3) flow-matching for 6D pose estimation; models full pose distributions with sample-based estimates; state-of-the-art on Real275, YCB-V, LM-O; enables uncertainty-aware manipulation.", "motivation": "Deterministic pose predictors struggle with multi-modality caused by occlusions and object symmetries, leading to overconfident, biased estimates; there is a need to quantify pose uncertainty and reason about multiple plausible poses.", "method": "Proposes a flow-matching framework on the SE(3) manifold to learn a probabilistic mapping from a base distribution to the target pose distribution. It uses sample-based estimates to represent the pose distribution, handling symmetry and occlusion, and supports downstream uncertainty-aware reasoning.", "result": "Achieves state-of-the-art results on Real275, YCB-V, and LM-O; demonstrates benefits of sample-based pose estimates for downstream tasks such as active perception and uncertainty-aware grasp synthesis.", "conclusion": "Presents a principled probabilistic approach to 6D pose estimation that captures multi-modality and uncertainty, enabling improved perception-guided manipulation in ambiguous scenarios."}}
{"id": "2511.00469", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00469", "abs": "https://arxiv.org/abs/2511.00469", "authors": ["Zhongxiang Lei", "Qi Yang", "Ping Qiu", "Gang Zhang", "Yuanchi Ma", "Jinyan Liu"], "title": "Why Federated Optimization Fails to Achieve Perfect Fitting? A Theoretical Perspective on Client-Side Optima", "comment": null, "summary": "Federated optimization is a constrained form of distributed optimization that\nenables training a global model without directly sharing client data. Although\nexisting algorithms can guarantee convergence in theory and often achieve\nstable training in practice, the reasons behind performance degradation under\ndata heterogeneity remain unclear. To address this gap, the main contribution\nof this paper is to provide a theoretical perspective that explains why such\ndegradation occurs. We introduce the assumption that heterogeneous client data\nlead to distinct local optima, and show that this assumption implies two key\nconsequences: 1) the distance among clients' local optima raises the lower\nbound of the global objective, making perfect fitting of all client data\nimpossible; and 2) in the final training stage, the global model oscillates\nwithin a region instead of converging to a single optimum, limiting its ability\nto fully fit the data. These results provide a principled explanation for\nperformance degradation in non-iid settings, which we further validate through\nexperiments across multiple tasks and neural network architectures. The\nframework used in this paper is open-sourced at:\nhttps://github.com/NPCLEI/fedtorch.", "AI": {"tldr": "Heterogeneous client data in federated optimization lead to distinct local optima, which raises the global objective's lower bound and causes the final model to oscillate within a region rather than converge, explaining non-iid performance degradation; validated empirically and with open-source code.", "motivation": "Explain why data heterogeneity degrades federated learning performance beyond standard convergence guarantees and link theory with observed practice by identifying where optimization dynamics fail under non-iid data.", "method": "The paper adopts a theoretical framework assuming heterogeneous local optima across clients, derives two main consequences (increased lower bound on the global objective and oscillation of the global model in a region at the end of training), and validates the theory with experiments across multiple tasks and neural network architectures; the approach is complemented by an open-source framework (fedtorch).", "result": "1) The distance between clients' local optima raises the lower bound of the global objective, making perfect fitting of all client data impossible. 2) In the final training stage, the global model oscillates within a region rather than converging to a single optimum, limiting data fit. Empirical results across tasks and architectures corroborate the theoretical explanation.", "conclusion": "Provides a principled theoretical explanation for performance degradation in non-iid federated learning and offers a framework to analyze and potentially mitigate such degradation; the authors also provide an open-source implementation for reproducibility."}}
{"id": "2511.00698", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00698", "abs": "https://arxiv.org/abs/2511.00698", "authors": ["Taifour Yousra", "Beghdadi Azeddine", "Marie Luong", "Zuheng Ming"], "title": "Toward Better Optimization of Low-Dose CT Enhancement: A Critical Analysis of Loss Functions and Image Quality Assessment Metrics", "comment": null, "summary": "Low-dose CT (LDCT) imaging is widely used to reduce radiation exposure to\nmitigate high exposure side effects, but often suffers from noise and artifacts\nthat affect diagnostic accuracy. To tackle this issue, deep learning models\nhave been developed to enhance LDCT images. Various loss functions have been\nemployed, including classical approaches such as Mean Square Error and\nadversarial losses, as well as customized loss functions(LFs) designed for\nspecific architectures. Although these models achieve remarkable performance in\nterms of PSNR and SSIM, these metrics are limited in their ability to reflect\nperceptual quality, especially for medical images. In this paper, we focus on\none of the most critical elements of DL-based architectures, namely the loss\nfunction. We conduct an objective analysis of the relevance of different loss\nfunctions for LDCT image quality enhancement and their consistency with image\nquality metrics. Our findings reveal inconsistencies between LFs and quality\nmetrics, and highlight the need of consideration of image quality metrics when\ndeveloping a new loss function for image quality enhancement.", "AI": {"tldr": "Loss functions used in LDCT enhancement with deep learning show misalignment with perceptual quality metrics; optimizing solely on PSNR/SSIM may not reflect clinical image quality, so losses should consider perceptual/image-quality metrics.", "motivation": "To investigate how different loss functions drive LDCT image quality and whether their optimization aligns with objective quality metrics beyond traditional metrics.", "method": "Conduct an objective analysis/review of various loss functions (e.g., MSE, adversarial losses, and architecture-specific customized losses) used in LDCT enhancement and assess their consistency with image quality metrics.", "result": "The analysis reveals inconsistencies between loss functions and quality metrics; highlights the need to consider image quality metrics when developing new loss functions for LDCT image quality enhancement.", "conclusion": "Future loss-function design for LDCT enhancement should incorporate perceptual and clinically relevant image quality metrics to ensure improvements align with actual perceptual quality rather than just PSNR/SSIM."}}
{"id": "2511.01502", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01502", "abs": "https://arxiv.org/abs/2511.01502", "authors": ["Mengtan Zhang", "Zizhan Guo", "Hongbo Zhao", "Yi Feng", "Zuyi Xiong", "Yue Wang", "Shaoyi Du", "Hanli Wang", "Rui Fan"], "title": "Discriminately Treating Motion Components Evolves Joint Depth and Ego-Motion Learning", "comment": "18 pages, 14 figures", "summary": "Unsupervised learning of depth and ego-motion, two fundamental 3D perception\ntasks, has made significant strides in recent years. However, most methods\ntreat ego-motion as an auxiliary task, either mixing all motion types or\nexcluding depth-independent rotational motions in supervision. Such designs\nlimit the incorporation of strong geometric constraints, reducing reliability\nand robustness under diverse conditions. This study introduces a discriminative\ntreatment of motion components, leveraging the geometric regularities of their\nrespective rigid flows to benefit both depth and ego-motion estimation. Given\nconsecutive video frames, network outputs first align the optical axes and\nimaging planes of the source and target cameras. Optical flows between frames\nare transformed through these alignments, and deviations are quantified to\nimpose geometric constraints individually on each ego-motion component,\nenabling more targeted refinement. These alignments further reformulate the\njoint learning process into coaxial and coplanar forms, where depth and each\ntranslation component can be mutually derived through closed-form geometric\nrelationships, introducing complementary constraints that improve depth\nrobustness. DiMoDE, a general depth and ego-motion joint learning framework\nincorporating these designs, achieves state-of-the-art performance on multiple\npublic datasets and a newly collected diverse real-world dataset, particularly\nunder challenging conditions. Our source code will be publicly available at\nmias.group/DiMoDE upon publication.", "AI": {"tldr": "DiMoDE introduces a discriminative joint learning framework for depth and ego-motion that leverages component-wise geometric constraints from rigid flow. It aligns camera frames, transforms flows, and enforces per-motion constraints to derive depth and translation components with closed-form relations, achieving state-of-the-art results on public datasets and a new diverse real-world dataset.", "motivation": "Existing unsupervised depth and ego-motion methods often treat ego-motion as auxiliary or mix motion types, limiting the use of strong geometric constraints and hurting robustness under diverse conditions. A discriminative, component-wise treatment of motion could enforce precise geometric relations and improve both depth and motion estimates.", "method": "For consecutive frames, the network first aligns the optical axes and imaging planes of source and target cameras. The optical flows are then transformed via these alignments, and deviations are measured to impose geometric constraints on each ego-motion component. This enables targeted refinement. The alignments reformulate joint learning into coaxial and coplanar forms, enabling mutual derivation of depth and each translation component through closed-form geometric relationships, providing complementary constraints.", "result": "DiMoDE achieves state-of-the-art performance on multiple public datasets and on a newly collected diverse real-world dataset, with particular robustness under challenging conditions.", "conclusion": "A general depth and ego-motion joint learning framework that uses discriminative, component-wise geometric constraints and camera-alignment-based reformulations to improve depth robustness and ego-motion estimation; code will be released publicly."}}
{"id": "2511.00475", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00475", "abs": "https://arxiv.org/abs/2511.00475", "authors": ["Travis Barrett", "Amit Kumar Mishra", "Joyce Mwangama"], "title": "Variational Autoencoder for Calibration: A New Approach", "comment": "6 pages, 5 figures", "summary": "In this paper we present a new implementation of a Variational Autoencoder\n(VAE) for the calibration of sensors. We propose that the VAE can be used to\ncalibrate sensor data by training the latent space as a calibration output. We\ndiscuss this new approach and show a proof-of-concept using an existing\nmulti-sensor gas dataset. We show the performance of the proposed calibration\nVAE and found that it was capable of performing as calibration model while\nperforming as an autoencoder simultaneously. Additionally, these models have\nshown that they are capable of creating statistically similar outputs from both\nthe calibration output as well as the reconstruction output to their respective\ntruth data. We then discuss the methods of future testing and planned expansion\nof this work.", "AI": {"tldr": "A VAE-based calibration framework that uses the latent space as calibration output, demonstrated on a multi-sensor gas dataset, achieving calibration while also reconstructing inputs with outputs close to truth data.", "motivation": "Sensor networks require accurate calibration; the work proposes a joint calibration-learning approach within a Variational Autoencoder to both calibrate sensor data and reconstruct it.", "method": "Develop a VAE where latent variables encode calibration parameters; train on sensor data with ground-truth calibration, using a proof-of-concept on an existing multi-sensor gas dataset; evaluate calibration quality and reconstruction similarity.", "result": "The model functions as both a calibration model and an autoencoder; outputs (calibrated and reconstructed) are statistically similar to the ground-truth data.", "conclusion": "Shows promise for unified calibration and reconstruction; warrants broader testing and expansion in future work."}}
{"id": "2511.00728", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00728", "abs": "https://arxiv.org/abs/2511.00728", "authors": ["Hugo Massaroli", "Hernan Chaves", "Pilar Anania", "Mauricio Farez", "Emmanuel Iarussi", "Viviana Siless"], "title": "Validating Deep Models for Alzheimer's 18F-FDG PET Diagnosis Across Populations: A Study with Latin American Data", "comment": "7 pages, 2 figures", "summary": "Deep learning models have shown strong performance in diagnosing Alzheimer's\ndisease (AD) using neuroimaging data, particularly 18F-FDG PET scans, with\ntraining datasets largely composed of North American cohorts such as those in\nthe Alzheimer's Disease Neuroimaging Initiative (ADNI). However, their\ngeneralization to underrepresented populations remains underexplored. In this\nstudy, we benchmark convolutional and Transformer-based models on the ADNI\ndataset and assess their generalization performance on a novel Latin American\nclinical cohort from the FLENI Institute in Buenos Aires, Argentina. We show\nthat while all models achieve high AUCs on ADNI (up to .96, .97), their\nperformance drops substantially on FLENI (down to .82, .80, respectively),\nrevealing a significant domain shift. The tested architectures demonstrated\nsimilar performance, calling into question the supposed advantages of\ntransformers for this specific task. Through ablation studies, we identify\nper-image normalization and a correct sampling selection as key factors for\ngeneralization. Occlusion sensitivity analysis further reveals that models\ntrained on ADNI, generally attend to canonical hypometabolic regions for the AD\nclass, but focus becomes unclear for the other classes and for FLENI scans.\nThese findings highlight the need for population-aware validation of diagnostic\nAI models and motivate future work on domain adaptation and cohort\ndiversification.", "AI": {"tldr": "Transformers do not clearly outperform CNNs for cross-domain AD diagnosis from 18F-FDG PET; models trained on ADNI show strong within-domain performance but substantial generalization gaps on a Latin American cohort, highlighting domain shift and the need for population-aware validation and domain adaptation.", "motivation": "Evaluate generalization of deep learning models for Alzheimer's disease diagnosis across underrepresented populations and assess whether Transformer architectures confer advantages over CNNs in this cross-domain setting.", "method": "Train convolutional and Transformer-based models on the ADNI 18F-FDG PET dataset and evaluate on both ADNI and a novel Latin American cohort (FLENI); conduct ablation studies on per-image normalization and sampling strategies; perform occlusion sensitivity analyses to interpret model attention; compare architectures.", "result": "On ADNI, models achieve high AUCs (up to ~0.96\u20130.97); on FLENI, performance drops notably (to ~0.80\u20130.82). Architectures perform similarly; per-image normalization and proper sampling are key for generalization; occlusion analysis shows ADNI-trained models focus on canonical hypometabolic regions for AD but attention becomes less clear for other classes and FLENI data.", "conclusion": "Population-aware validation is essential; domain adaptation and cohort diversification are needed to ensure robust clinical deployment. Transformers do not demonstrate clear superiority for this task under the studied conditions."}}
{"id": "2511.01571", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01571", "abs": "https://arxiv.org/abs/2511.01571", "authors": ["Wenqi Liang", "Gan Sun", "Yao He", "Jiahua Dong", "Suyan Dai", "Ivan Laptev", "Salman Khan", "Yang Cong"], "title": "PixelVLA: Advancing Pixel-level Understanding in Vision-Language-Action Model", "comment": "17pages,7 figures, 5 tabels", "summary": "Vision-Language-Action models (VLAs) are emerging as powerful tools for\nlearning generalizable visuomotor control policies. However, current VLAs are\nmostly trained on large-scale image-text-action data and remain limited in two\nkey ways: (i) they struggle with pixel-level scene understanding, and (ii) they\nrely heavily on textual prompts, which reduces their flexibility in real-world\nsettings. To address these challenges, we introduce PixelVLA, the first VLA\nmodel designed to support both pixel-level reasoning and multimodal prompting\nwith text and visual inputs. Our approach is built on a new visuomotor\ninstruction tuning framework that integrates a multiscale pixel-aware encoder\nwith a visual prompting encoder. To train PixelVLA effectively, we further\npropose a two-stage automated annotation pipeline that generates Pixel-160K, a\nlarge-scale dataset with pixel-level annotations derived from existing robot\ndata. Experiments on three standard VLA benchmarks and two VLA model variants\nshow that PixelVLA improves manipulation success rates by 10.1%-17.8% over\nOpenVLA, while requiring only 1.5% of its pretraining cost. These results\ndemonstrate that PixelVLA can be integrated into existing VLAs to enable more\naccurate, efficient, and versatile robot control in complex environments. The\ndataset and code will be released as open source.", "AI": {"tldr": "PixelVLA is a VLA model enabling pixel-level reasoning and multimodal prompting, achieving higher manipulation success with much lower pretraining cost; introduces Pixel-160K; open-sourced.", "motivation": "VLAs currently struggle with pixel-level scene understanding and depend heavily on textual prompts, limiting real-world visuomotor flexibility.", "method": "A visuomotor instruction tuning framework built with a multiscale pixel-aware encoder and a visual prompting encoder; a two-stage automated annotation pipeline produces Pixel-160K pixel-level annotations from existing robot data.", "result": "On three VLA benchmarks and two model variants, PixelVLA improves manipulation success rates by 10.1%-17.8% over OpenVLA while using only 1.5% of its pretraining cost.", "conclusion": "PixelVLA can enhance existing VLAs to enable more accurate, efficient, and versatile robot control; dataset and code will be released as open source."}}
{"id": "2511.00521", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00521", "abs": "https://arxiv.org/abs/2511.00521", "authors": ["Bao Nguyen", "Hieu Trung Nguyen", "Ruifeng She", "Xiaojin Fu", "Viet Anh Nguyen"], "title": "Reasoning Planning for Language Models", "comment": "29 pages, 5 figures", "summary": "Selecting an appropriate reasoning method for a given query remains a key\nchallenge in language model generation. Existing approaches typically generate\nmultiple candidate responses and use an aggregation strategy to select the\noutput answer, often assuming that more candidate answers yield higher\naccuracy. We revisit this assumption through a rigorous theoretical analysis,\nderiving accuracy bounds for standard aggregation methods under fixed\ngeneration distributions and candidate sizes. Building on these insights, we\nintroduce EPIC, an Ensemble Planning with Contrastive learning framework to\nlearn a shared representation space that captures both model reasoning\nabilities and query-method compatibility. EPIC incorporates our probability\nbounds as a regularizer in a utility-driven optimization that balances accuracy\nand computational cost. Experiments on diverse mathematical reasoning tasks\nshow that EPIC consistently selects optimal reasoning methods, improving\naccuracy while reducing computational overhead. Our code can be found at\nhttps://github.com/nguyenngocbaocmt02/EPIC.", "AI": {"tldr": "Challenges the belief that more candidate outputs improve accuracy; derives accuracy bounds for standard aggregation under fixed distributions; proposes EPIC to learn a shared representation for reasoning methods and query-method compatibility, regularized by probability bounds to balance accuracy and cost; experiments show improvements in mathematical reasoning tasks.", "motivation": "Understanding when ensemble/aggregation methods for selecting LM outputs are effective and how to optimize the trade-off between accuracy and computation; address the assumption that more candidates always help.", "method": "1) Theoretically derive accuracy bounds for common aggregation methods given fixed generation distributions and candidate sizes. 2) Propose EPIC (Ensemble Planning with Contrastive learning) to learn a shared representation space that encodes model reasoning abilities and query-method compatibility. 3) Use the probabilistic bounds as a regularizer in a utility-driven optimization that balances accuracy and computational cost. 4) Empirically evaluate on diverse mathematical reasoning tasks.", "result": "EPIC consistently selects optimal reasoning methods, achieving higher accuracy while reducing computational overhead compared to baselines.", "conclusion": "Incorporating probability bounds into a contrastive, representation-learning framework enables cost-aware, accurate method selection for LM reasoning. EPIC demonstrates practical gains on mathematical reasoning benchmarks and is available with code at the provided GitHub URL."}}
{"id": "2511.00738", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00738", "abs": "https://arxiv.org/abs/2511.00738", "authors": ["Dmitrii Khizbullin", "Maksim Konoplia"], "title": "Towards classification-based representation learning for place recognition on LiDAR scans", "comment": null, "summary": "Place recognition is a crucial task in autonomous driving, allowing vehicles\nto determine their position using sensor data. While most existing methods rely\non contrastive learning, we explore an alternative approach by framing place\nrecognition as a multi-class classification problem. Our method assigns\ndiscrete location labels to LiDAR scans and trains an encoder-decoder model to\nclassify each scan's position directly. We evaluate this approach on the\nNuScenes dataset and show that it achieves competitive performance compared to\ncontrastive learning-based methods while offering advantages in training\nefficiency and stability.", "AI": {"tldr": "Framing place recognition as a supervised multi-class classification task instead of contrastive learning. Discretizes location into labels for LiDAR scans and trains an encoder\u2013decoder to predict the position, achieving competitive NuScenes results with improved training efficiency and stability.", "motivation": "Contrastive learning is effective but can be data-hungry and unstable. A direct supervised approach may simplify training, reduce computational cost, and offer more stable optimization while maintaining accuracy in place recognition.", "method": "Create discrete location labels for LiDAR scans. Train an encoder\u2013decoder model to classify each scan into its labeled position (multi-class classification), likely using cross-entropy loss. Evaluation performed on the NuScenes dataset.", "result": "The approach yields competitive performance compared to contrastive-learning-based methods, with advantages in training efficiency and stability.", "conclusion": "A supervised multi-class framing for place recognition is a viable alternative to contrastive learning, offering similar accuracy with simpler training dynamics and better efficiency on NuScenes."}}
{"id": "2511.01755", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.01755", "abs": "https://arxiv.org/abs/2511.01755", "authors": ["Rong Li", "Yuhao Dong", "Tianshuai Hu", "Ao Liang", "Youquan Liu", "Dongyue Lu", "Liang Pan", "Lingdong Kong", "Junwei Liang", "Ziwei Liu"], "title": "3EED: Ground Everything Everywhere in 3D", "comment": "NeurIPS 2025 DB Track; 29 pages, 17 figures, 10 tables; Project Page\n  at https://project-3eed.github.io/", "summary": "Visual grounding in 3D is the key for embodied agents to localize\nlanguage-referred objects in open-world environments. However, existing\nbenchmarks are limited to indoor focus, single-platform constraints, and small\nscale. We introduce 3EED, a multi-platform, multi-modal 3D grounding benchmark\nfeaturing RGB and LiDAR data from vehicle, drone, and quadruped platforms. We\nprovide over 128,000 objects and 22,000 validated referring expressions across\ndiverse outdoor scenes -- 10x larger than existing datasets. We develop a\nscalable annotation pipeline combining vision-language model prompting with\nhuman verification to ensure high-quality spatial grounding. To support\ncross-platform learning, we propose platform-aware normalization and\ncross-modal alignment techniques, and establish benchmark protocols for\nin-domain and cross-platform evaluations. Our findings reveal significant\nperformance gaps, highlighting the challenges and opportunities of\ngeneralizable 3D grounding. The 3EED dataset and benchmark toolkit are released\nto advance future research in language-driven 3D embodied perception.", "AI": {"tldr": "A large-scale, multi-platform, multi-modal 3D grounding benchmark (3EED) with RGB and LiDAR data from vehicle, drone, and quadruped platforms, covering 128k objects and 22k referring expressions; introduces a scalable annotation pipeline and platform-aware normalization; shows cross-platform generalization gaps; dataset and toolkit released.", "motivation": "Current 3D grounding benchmarks are indoor-focused, single-platform, and small-scale, hindering open-world and cross-platform generalization in embodied agents. There is a need for outdoor, multi-platform data and robust evaluation protocols to advance language-driven 3D perception.", "method": "Develop a scalable annotation pipeline that combines vision-language model prompting with human verification; implement platform-aware normalization and cross-modal alignment; establish benchmark protocols for in-domain and cross-platform evaluations.", "result": "3EED comprises over 128,000 objects and 22,000 validated referring expressions across diverse outdoor scenes, approximately 10x larger than prior datasets; cross-platform baselines reveal significant performance gaps, underscoring generalization challenges; dataset and benchmark toolkit released for research use.", "conclusion": "3EED advances outdoor, cross-platform 3D grounding research by providing a large-scale benchmark and tools, highlighting generalization gaps and guiding future work in language-guided 3D perception."}}
{"id": "2511.00532", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.00532", "abs": "https://arxiv.org/abs/2511.00532", "authors": ["Drago\u015f-Andrei \u015eerban", "R\u0103zvan-Alexandru Sm\u0103du", "Dumitru-Clementin Cercel"], "title": "Air Pollution Forecasting in Bucharest", "comment": "14 pages 3 figures", "summary": "Air pollution, especially the particulate matter 2.5 (PM2.5), has become a\ngrowing concern in recent years, primarily in urban areas. Being exposed to air\npollution is linked to developing numerous health problems, like the\naggravation of respiratory diseases, cardiovascular disorders, lung function\nimpairment, and even cancer or early death. Forecasting future levels of PM2.5\nhas become increasingly important over the past few years, as it can provide\nearly warnings and help prevent diseases. This paper aims to design, fine-tune,\ntest, and evaluate machine learning models for predicting future levels of\nPM2.5 over various time horizons. Our primary objective is to assess and\ncompare the performance of multiple models, ranging from linear regression\nalgorithms and ensemble-based methods to deep learning models, such as advanced\nrecurrent neural networks and transformers, as well as large language models,\non this forecasting task.", "AI": {"tldr": "The paper aims to compare a broad range of ML models (linear, ensemble, deep learning, transformers, and LLMs) for PM2.5 forecasting across multiple horizons.", "motivation": "PM2.5 pollution poses health risks; forecasting enables early warnings and prevention; evaluating diverse models helps identify effective approaches for urban air quality prediction.", "method": "Design, fine-tune, test, and evaluate multiple ML models on PM2.5 forecasting across various time horizons.", "result": "Abstract does not report results.", "conclusion": "Abstract does not provide conclusions."}}
{"id": "2511.00749", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00749", "abs": "https://arxiv.org/abs/2511.00749", "authors": ["Tanvi Dinkar", "Aiqi Jiang", "Gavin Abercrombie", "Ioannis Konstas"], "title": "Erasing 'Ugly' from the Internet: Propagation of the Beauty Myth in Text-Image Models", "comment": "This is a preprint under review", "summary": "Social media has exacerbated the promotion of Western beauty norms, leading\nto negative self-image, particularly in women and girls, and causing harm such\nas body dysmorphia. Increasingly content on the internet has been artificially\ngenerated, leading to concerns that these norms are being exaggerated. The aim\nof this work is to study how generative AI models may encode 'beauty' and erase\n'ugliness', and discuss the implications of this for society. To investigate\nthese aims, we create two image generation pipelines: a text-to-image model and\na text-to-language model-to image model. We develop a structured beauty\ntaxonomy which we use to prompt three language models (LMs) and two\ntext-to-image models to cumulatively generate 5984 images using our two\npipelines. We then recruit women and non-binary social media users to evaluate\n1200 of the images through a Likert-scale within-subjects study. Participants\nshow high agreement in their ratings. Our results show that 86.5% of generated\nimages depicted people with lighter skin tones, 22% contained explicit content\ndespite Safe for Work (SFW) training, and 74% were rated as being in a younger\nage demographic. In particular, the images of non-binary individuals were rated\nas both younger and more hypersexualised, indicating troubling intersectional\neffects. Notably, prompts encoded with 'negative' or 'ugly' beauty traits (such\nas \"a wide nose\") consistently produced higher Not SFW (NSFW) ratings\nregardless of gender. This work sheds light on the pervasive demographic biases\nrelated to beauty standards present in generative AI models -- biases that are\nactively perpetuated by model developers, such as via negative prompting. We\nconclude by discussing the implications of this on society, which include\npollution of the data streams and active erasure of features that do not fall\ninside the stereotype of what is considered beautiful by developers.", "AI": {"tldr": "Generative AI encodes biased Western beauty norms, producing predominantly lighter-skinned, younger, and hypersexualised images; negative prompts elevate NSFW content and target non-binary individuals, revealing intersectional biases with societal implications.", "motivation": "Assess how generative AI models encode and propagate beauty ideals, and the societal harms from biased representations and negative prompting.", "method": "Two image-generation pipelines (text-to-image; text-to-language-model-to-image) guided by a structured beauty taxonomy; prompts applied to three language models and two image models to generate 5984 images; 1200 images evaluated by women and non-binary social media users via Likert-scale within-subjects design.", "result": "Generated dataset shows 86.5% lighter-skin depictions, 22% NSFW content despite SFW training, and 74% younger age demographics; non-binary representations skew younger and more hypersexualised; negative/ugly prompts (e.g., 'a wide nose') lead to higher NSFW ratings across genders.", "conclusion": "Demographic biases in generative AI are pervasive and reinforced by model developers and prompting practices; implications include data stream pollution and erosion of non-conforming features, necessitating policy attention and responsible design."}}
{"id": "2511.01795", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.RO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01795", "abs": "https://arxiv.org/abs/2511.01795", "authors": ["Gabriel Nobis", "Maximilian Springenberg", "Arina Belova", "Rembert Daems", "Christoph Knochenhauer", "Manfred Opper", "Tolga Birdal", "Wojciech Samek"], "title": "Fractional Diffusion Bridge Models", "comment": "To appear in NeurIPS 2025 proceedings. This version includes\n  post-camera-ready revisions", "summary": "We present Fractional Diffusion Bridge Models (FDBM), a novel generative\ndiffusion bridge framework driven by an approximation of the rich and\nnon-Markovian fractional Brownian motion (fBM). Real stochastic processes\nexhibit a degree of memory effects (correlations in time), long-range\ndependencies, roughness and anomalous diffusion phenomena that are not captured\nin standard diffusion or bridge modeling due to the use of Brownian motion\n(BM). As a remedy, leveraging a recent Markovian approximation of fBM (MA-fBM),\nwe construct FDBM that enable tractable inference while preserving the\nnon-Markovian nature of fBM. We prove the existence of a coupling-preserving\ngenerative diffusion bridge and leverage it for future state prediction from\npaired training data. We then extend our formulation to the Schr\\\"{o}dinger\nbridge problem and derive a principled loss function to learn the unpaired data\ntranslation. We evaluate FDBM on both tasks: predicting future protein\nconformations from aligned data, and unpaired image translation. In both\nsettings, FDBM achieves superior performance compared to the Brownian\nbaselines, yielding lower root mean squared deviation (RMSD) of C$_\\alpha$\natomic positions in protein structure prediction and lower Fr\\'echet Inception\nDistance (FID) in unpaired image translation.", "AI": {"tldr": "Fractional Diffusion Bridge Models (FDBM) introduce a diffusion-bridge framework driven by a Markovian approximation of fractional Brownian motion to capture memory effects, with a coupling-preserving bridge and Schr\u00f6dinger-bridge extension, achieving better protein structure prediction and unpaired image translation than Brownian baselines.", "motivation": "Real stochastic processes exhibit memory, long-range dependence, roughness, and anomalous diffusion, which standard Brownian-based diffusion models fail to capture. A tractable non-Markovian diffusion model is needed.", "method": "Construct FDBM using a Markovian approximation of fBM (MA-fBM); prove the existence of a coupling-preserving generative diffusion bridge; apply it to future state prediction from paired data; extend to Schr\u00f6dinger bridge and derive a loss for unpaired data translation.", "result": "In experiments, FDBM outperforms Brownian baselines with lower RMSD of C\u03b1 positions in protein structure prediction and lower Fr\u00e9chet Inception Distance (FID) in unpaired image translation.", "conclusion": "FDBM provides a tractable, memory-aware diffusion bridge framework that improves predictive performance and can be extended to Schr\u00f6dinger bridges for unpaired data translation, with broad applicability to diffusion-bridge tasks."}}
{"id": "2511.00543", "categories": ["cs.LG", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00543", "abs": "https://arxiv.org/abs/2511.00543", "authors": ["Yunchuan Guan", "Yu Liu", "Ke Zhou", "Hui Li", "Sen Jia", "Zhiqi Shen", "Ziyang Wang", "Xinglin Zhang", "Tao Chen", "Jenq-Neng Hwang", "Lei Li"], "title": "Learning an Efficient Optimizer via Hybrid-Policy Sub-Trajectory Balance", "comment": null, "summary": "Recent advances in generative modeling enable neural networks to generate\nweights without relying on gradient-based optimization. However, current\nmethods are limited by issues of over-coupling and long-horizon. The former\ntightly binds weight generation with task-specific objectives, thereby limiting\nthe flexibility of the learned optimizer. The latter leads to inefficiency and\nlow accuracy during inference, caused by the lack of local constraints. In this\npaper, we propose Lo-Hp, a decoupled two-stage weight generation framework that\nenhances flexibility through learning various optimization policies. It adopts\na hybrid-policy sub-trajectory balance objective, which integrates on-policy\nand off-policy learning to capture local optimization policies. Theoretically,\nwe demonstrate that learning solely local optimization policies can address the\nlong-horizon issue while enhancing the generation of global optimal weights. In\naddition, we validate Lo-Hp's superior accuracy and inference efficiency in\ntasks that require frequent weight updates, such as transfer learning, few-shot\nlearning, domain generalization, and large language model adaptation.", "AI": {"tldr": "Lo-Hp is a decoupled, two-stage weight-generation framework using a hybrid-policy sub-trajectory balance objective to learn local optimization policies, addressing over-coupling and long-horizon issues, with improved accuracy and inference efficiency in tasks with frequent weight updates.", "motivation": "Current generative weight generation methods tightly couple weight generation with task-specific objectives, causing inflexibility and long-horizon inefficiency. There is a need for a decoupled framework that learns flexible, local optimization policies capable of generalizing to global weight generation.", "method": "Lo-Hp proposes a two-stage, decoupled weight generation framework. It introduces a hybrid-policy sub-trajectory balance objective that blends on-policy and off-policy learning to capture local optimization policies. Theoretically, learning solely local optimization policies can mitigate long-horizon issues while improving global weight generation.", "result": "Empirical results claim superior accuracy and inference efficiency in tasks requiring frequent weight updates: transfer learning, few-shot learning, domain generalization, and large language model adaptation.", "conclusion": "Lo-Hp offers a decoupled, flexible weight-generation approach that focuses on local optimization policies to improve both adaptation performance and inference efficiency, with potential applicability across diverse learning scenarios."}}
{"id": "2511.00777", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00777", "abs": "https://arxiv.org/abs/2511.00777", "authors": ["Anis Suttan Shahrir", "Zakiah Ayop", "Syarulnaziah Anawar", "Norulzahrah Mohd Zainudin"], "title": "A Hybrid YOLOv5-SSD IoT-Based Animal Detection System for Durian Plantation Protection", "comment": null, "summary": "Durian plantation suffers from animal intrusions that cause crop damage and\nfinancial loss. The traditional farming practices prove ineffective due to the\nunavailability of monitoring without human intervention. The fast growth of\nmachine learning and Internet of Things (IoT) technology has led to new ways to\ndetect animals. However, current systems are limited by dependence on single\nobject detection algorithms, less accessible notification platforms, and\nlimited deterrent mechanisms. This research suggests an IoT-enabled animal\ndetection system for durian crops. The system integrates YOLOv5 and SSD object\ndetection algorithms to improve detection accuracy. The system provides\nreal-time monitoring, with detected intrusions automatically reported to\nfarmers via Telegram notifications for rapid response. An automated sound\nmechanism (e.g., tiger roar) is triggered once the animal is detected. The\nYOLO+SSD model achieved accuracy rates of elephant, boar, and monkey at 90%,\n85% and 70%, respectively. The system shows the highest accuracy in daytime and\ndecreases at night, regardless of whether the image is still or a video.\nOverall, this study contributes a comprehensive and practical framework that\ncombines detection, notification, and deterrence, paving the way for future\ninnovations in automated farming solutions.", "AI": {"tldr": "IoT-enabled durian farm animal detection using a YOLOv5 + SSD fusion with Telegram alerts and automated deterrent sounds; achieves 90% elephant, 85% boar, 70% monkey accuracy; best in daytime, performance drops at night; practical framework for detection, notification, and deterrence.", "motivation": "Durian plantations face animal intrusions causing crop damage and financial loss. Traditional monitoring is inefficient and requires human intervention. Advances in ML and IoT offer real-time detection and deterrence, but\u73b0\u6709 systems rely on single detectors, limited notification channels, and few deterrents.", "method": "A system that fuses YOLOv5 and SSD detectors for real-time animal detection in durian crops, deployed on an IoT setup. Detected intrusions trigger Telegram notifications for rapid farmer response and automated deterrent sounds (e.g., tiger roar). Evaluation shows class-specific accuracies for elephant (90%), boar (85%), and monkey (70%), with daytime performance higher and night-time performance lower, for both still images and video.", "result": "Fusion of two detectors improves detection accuracy across target species. Real-time monitoring with automated alerts and deterrent mechanism is feasible. The approach yields highest accuracy in daytime and degrades at night, regardless of image type.", "conclusion": "The study offers a practical, integrated framework that combines detection, notification, and deterrence for automated farming solutions and points to potential future innovations in IoT-enabled agricultural monitoring."}}
{"id": "2511.00549", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00549", "abs": "https://arxiv.org/abs/2511.00549", "authors": ["Qiang Li", "Jin Niu", "Lina Yu"], "title": "Robust Single-Agent Reinforcement Learning for Regional Traffic Signal Control Under Demand Fluctuations", "comment": null, "summary": "Traffic congestion, primarily driven by intersection queuing, significantly\nimpacts urban living standards, safety, environmental quality, and economic\nefficiency. While Traffic Signal Control (TSC) systems hold potential for\ncongestion mitigation, traditional optimization models often fail to capture\nreal-world traffic complexity and dynamics. This study introduces a novel\nsingle-agent reinforcement learning (RL) framework for regional adaptive TSC,\ncircumventing the coordination complexities inherent in multi-agent systems\nthrough a centralized decision-making paradigm. The model employs an adjacency\nmatrix to unify the encoding of road network topology, real-time queue states\nderived from probe vehicle data, and current signal timing parameters.\nLeveraging the efficient learning capabilities of the DreamerV3 world model,\nthe agent learns control policies where actions sequentially select\nintersections and adjust their signal phase splits to regulate traffic\ninflow/outflow, analogous to a feedback control system. Reward design\nprioritizes queue dissipation, directly linking congestion metrics (queue\nlength) to control actions. Simulation experiments conducted in SUMO\ndemonstrate the model's effectiveness: under inference scenarios with\nmulti-level (10%, 20%, 30%) Origin-Destination (OD) demand fluctuations, the\nframework exhibits robust anti-fluctuation capability and significantly reduces\nqueue lengths. This work establishes a new paradigm for intelligent traffic\ncontrol compatible with probe vehicle technology. Future research will focus on\nenhancing practical applicability by incorporating stochastic OD demand\nfluctuations during training and exploring regional optimization mechanisms for\ncontingency events.", "AI": {"tldr": "A centralized single-agent reinforcement learning framework using DreamerV3 for regional adaptive traffic signal control (TSC) that encodes network topology with an adjacency matrix and uses probe-vehicle queue states, achieving robust queue reduction under fluctuating OD demand in SUMO.", "motivation": "Traditional TSC optimization models struggle to capture real-world traffic complexity, dynamics, and irregular OD demand; there is a need for a scalable, data-driven, probe-vehicle\u2013enabled control paradigm that coordinates regional signals through a centralized policy.", "method": "The approach uses a single-agent centralized RL with an adjacency matrix to encode topology, real-time queue states from probe data, and current signal timing. DreamerV3 world model guides learning. Actions sequentially select intersections and adjust phase splits; the reward prioritizes queue dissipation. Evaluations are conducted in SUMO under multi-level OD fluctuations (10%, 20%, 30%).", "result": "The framework demonstrates robust anti-fluctuation performance and significantly reduces queue lengths under varying OD demands, indicating effective regional TSC and compatibility with probe-vehicle technology.", "conclusion": "This work proposes a new paradigm for intelligent, probe-vehicle\u2013friendly regional TSC using a centralized single-agent RL framework, with future work focusing on stochastic OD training and regional contingency optimization."}}
{"id": "2511.00785", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00785", "abs": "https://arxiv.org/abs/2511.00785", "authors": ["Juan Wang", "Yasutomo Kawanishi", "Tomo Miyazaki", "Zhijie Wang", "Shinichiro Omachi"], "title": "Class-agnostic 3D Segmentation by Granularity-Consistent Automatic 2D Mask Tracking", "comment": "Under review in Pattern Recognition", "summary": "3D instance segmentation is an important task for real-world applications. To\navoid costly manual annotations, existing methods have explored generating\npseudo labels by transferring 2D masks from foundation models to 3D. However,\nthis approach is often suboptimal since the video frames are processed\nindependently. This causes inconsistent segmentation granularity and\nconflicting 3D pseudo labels, which degrades the accuracy of final\nsegmentation. To address this, we introduce a Granularity-Consistent automatic\n2D Mask Tracking approach that maintains temporal correspondences across\nframes, eliminating conflicting pseudo labels. Combined with a three-stage\ncurriculum learning framework, our approach progressively trains from\nfragmented single-view data to unified multi-view annotations, ultimately\nglobally coherent full-scene supervision. This structured learning pipeline\nenables the model to progressively expose to pseudo-labels of increasing\nconsistency. Thus, we can robustly distill a consistent 3D representation from\ninitially fragmented and contradictory 2D priors. Experimental results\ndemonstrated that our method effectively generated consistent and accurate 3D\nsegmentations. Furthermore, the proposed method achieved state-of-the-art\nresults on standard benchmarks and open-vocabulary ability.", "AI": {"tldr": "A granularity-consistent 2D mask tracking framework, combined with a three-stage curriculum learning pipeline, distills coherent 3D instance segmentation from fragmented, conflicting 2D priors, achieving state-of-the-art results and open-vocabulary capability.", "motivation": "3D instance segmentation struggles with inconsistent pseudo-labels when 2D masks are transferred independently across frames, leading to conflicting 3D labels and degraded performance. Temporal consistency and structured learning are needed to produce reliable 3D representations from weak 2D priors.", "method": "Introduce Granularity-Consistent automatic 2D Mask Tracking to maintain temporal correspondences across frames and eliminate conflicting pseudo labels, integrated with a three-stage curriculum learning framework that progresses from fragmented single-view data to unified multi-view annotations and finally global full-scene supervision.", "result": "The approach yields consistent and accurate 3D segmentations, achieving state-of-the-art results on standard benchmarks and demonstrating open-vocabulary capability.", "conclusion": "By enforcing temporal consistency in 2D priors and guiding learning through a staged curriculum, the method robustly distills a coherent 3D representation from initially fragmented and contradictory 2D priors, enabling superior 3D instance segmentation performance."}}
{"id": "2511.00552", "categories": ["cs.LG", "cs.AI", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2511.00552", "abs": "https://arxiv.org/abs/2511.00552", "authors": ["Santhi Bharath Punati", "Sandeep Kanta", "Udaya Bhasker Cheerala", "Madhusudan G Lanjewar", "Praveen Damacharla"], "title": "Temporal Fusion Transformer for Multi-Horizon Probabilistic Forecasting of Weekly Retail Sales", "comment": "5 pages, 2025 6th International Conference on Data Analytics for\n  Business and Industry (ICDABI)", "summary": "Accurate multi-horizon retail forecasts are critical for inventory and\npromotions. We present a novel study of weekly Walmart sales (45 stores,\n2010--2012) using a Temporal Fusion Transformer (TFT) that fuses static store\nidentifiers with time-varying exogenous signals (holidays, CPI, fuel price,\ntemperature). The pipeline produces 1--5-week-ahead probabilistic forecasts via\nQuantile Loss, yielding calibrated 90\\% prediction intervals and\ninterpretability through variable-selection networks, static enrichment, and\ntemporal attention. On a fixed 2012 hold-out dataset, TFT achieves an RMSE of\n\\$57.9k USD per store-week and an $R^2$ of 0.9875. Across a 5-fold\nchronological cross-validation, the averages are RMSE = \\$64.6k USD and $R^2$ =\n0.9844, outperforming the XGB, CNN, LSTM, and CNN-LSTM baseline models. These\nresults demonstrate practical value for inventory planning and holiday-period\noptimization, while maintaining model transparency.", "AI": {"tldr": "A Temporal Fusion Transformer (TFT) model with static store features and exogenous signals delivers multi-horizon probabilistic Walmart sales forecasts, achieving high accuracy and strong calibration while remaining interpretable.", "motivation": "Accurate multi-horizon retail forecasts are essential for effective inventory management and promotions; there is a need for calibrated probabilistic forecasts and transparent models.", "method": "Apply TFT to weekly Walmart sales (45 stores, 2010\u20132012) combining static store identifiers with time-varying signals (holidays, CPI, fuel price, temperature). Produce 1\u20135 week-ahead probabilistic forecasts via Quantile Loss, with interpretability from variable-selection networks, static enrichment, and temporal attention.", "result": "On a fixed 2012 hold-out, TFT yields RMSE = 57.9k USD per store-week and R^2 = 0.9875. In 5-fold chronological CV, RMSE = 64.6k USD and R^2 = 0.9844, outperforming XGB, CNN, LSTM, and CNN-LSTM baselines.", "conclusion": "Demonstrates practical value for inventory planning and holiday-period optimization, while maintaining model transparency."}}
{"id": "2511.00795", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00795", "abs": "https://arxiv.org/abs/2511.00795", "authors": ["Viswa Chaitanya Marella", "Suhasnadh Reddy Veluru", "Sai Teja Erukude"], "title": "FedOnco-Bench: A Reproducible Benchmark for Privacy-Aware Federated Tumor Segmentation with Synthetic CT Data", "comment": "Published in IEEE", "summary": "Federated Learning (FL) allows multiple institutions to cooperatively train\nmachine learning models while retaining sensitive data at the source, which has\ngreat utility in privacy-sensitive environments. However, FL systems remain\nvulnerable to membership-inference attacks and data heterogeneity. This paper\npresents FedOnco-Bench, a reproducible benchmark for privacy-aware FL using\nsynthetic oncologic CT scans with tumor annotations. It evaluates segmentation\nperformance and privacy leakage across FL methods: FedAvg, FedProx, FedBN, and\nFedAvg with DP-SGD. Results show a distinct trade-off between privacy and\nutility: FedAvg is high performance (Dice around 0.85) with more privacy\nleakage (attack AUC about 0.72), while DP-SGD provides a higher level of\nprivacy (AUC around 0.25) at the cost of accuracy (Dice about 0.79). FedProx\nand FedBN offer balanced performance under heterogeneous data, especially with\nnon-identical distributed client data. FedOnco-Bench serves as a standardized,\nopen-source platform for benchmarking and developing privacy-preserving FL\nmethods for medical image segmentation.", "AI": {"tldr": "FedOnco-Bench provides a reproducible benchmark for privacy-aware FL in medical image segmentation, showing trade-offs between utility and privacy across methods under data heterogeneity.", "motivation": "Privacy concerns and data heterogeneity in federated learning for medical imaging necessitate standardized benchmarks and evaluation of privacy leakage alongside segmentation performance.", "method": "Use synthetic oncologic CT scans with tumor annotations to evaluate FL methods (FedAvg, FedProx, FedBN, FedAvg+DP-SGD) on segmentation (Dice score) and privacy leakage (membership inference attack AUC).", "result": "FedAvg yields highest Dice around 0.85 but higher privacy leakage (AUC ~0.72); DP-SGD improves privacy (AUC ~0.25) at cost of Dice (~0.79). FedProx and FedBN provide balanced performance under non-identical data distributions.", "conclusion": "FedOnco-Bench is an open-source platform that standardizes benchmarking and development of privacy-preserving FL methods for medical image segmentation."}}
{"id": "2511.00554", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00554", "abs": "https://arxiv.org/abs/2511.00554", "authors": ["Phil Blandfort", "Robert Graham"], "title": "Red-teaming Activation Probes using Prompted LLMs", "comment": null, "summary": "Activation probes are attractive monitors for AI systems due to low cost and\nlatency, but their real-world robustness remains underexplored. We ask: What\nfailure modes arise under realistic, black-box adversarial pressure, and how\ncan we surface them with minimal effort? We present a lightweight black-box\nred-teaming procedure that wraps an off-the-shelf LLM with iterative feedback\nand in-context learning (ICL), and requires no fine-tuning, gradients, or\narchitectural access. Running a case study with probes for high-stakes\ninteractions, we show that our approach can help discover valuable insights\nabout a SOTA probe. Our analysis uncovers interpretable brittleness patterns\n(e.g., legalese-induced FPs; bland procedural tone FNs) and reduced but\npersistent vulnerabilities under scenario-constraint attacks. These results\nsuggest that simple prompted red-teaming scaffolding can anticipate failure\npatterns before deployment and might yield promising, actionable insights to\nharden future probes.", "AI": {"tldr": "A lightweight black-box red-teaming approach using an off-the-shelf LLM with iterative feedback and in-context learning to surface robustness issues in activation probes, without fine-tuning, revealing brittleness patterns and persistent vulnerabilities; suggests prompted red-teaming can reveal failure modes before deployment.", "motivation": "Activation probes are low-cost monitors for AI systems but their real-world robustness under realistic adversarial pressure is underexplored. There is a need for capable, low-effort methods to surface failure modes prior to deployment.", "method": "A lightweight black-box red-teaming procedure that wraps an off-the-shelf LLM with iterative feedback and in-context learning (ICL), requiring no fine-tuning, gradients, or architectural access. Applied in a case study with probes for high-stakes interactions to surface failure modes under adversarial pressure, including scenario-constraint attacks.", "result": "The approach helps discover valuable insights about a state-of-the-art probe. It reveals interpretable brittleness patterns\u2014such as legalese-induced false positives and bland procedural tone false negatives\u2014and finds reduced but persistent vulnerabilities under scenario-constraint attacks.", "conclusion": "Simple prompted red-teaming scaffolding can anticipate failure patterns before deployment and yield actionable insights to harden future probes."}}
{"id": "2511.00801", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.00801", "abs": "https://arxiv.org/abs/2511.00801", "authors": ["Zhihui Chen", "Mengling Feng"], "title": "Med-Banana-50K: A Cross-modality Large-Scale Dataset for Text-guided Medical Image Editing", "comment": null, "summary": "Recent advances in multimodal large language models have enabled remarkable\nmedical image editing capabilities. However, the research community's progress\nremains constrained by the absence of large-scale, high-quality, and openly\naccessible datasets built specifically for medical image editing with strict\nanatomical and clinical constraints. We introduce Med-Banana-50K, a\ncomprehensive 50K-image dataset for instruction-based medical image editing\nspanning three modalities (chest X-ray, brain MRI, fundus photography) and 23\ndisease types. Our dataset is constructed by leveraging Gemini-2.5-Flash-Image\nto generate bidirectional edits (lesion addition and removal) from real medical\nimages. What distinguishes Med-Banana-50K from general-domain editing datasets\nis our systematic approach to medical quality control: we employ LLM-as-Judge\nwith a medically grounded rubric (instruction compliance, structural\nplausibility, realism, and fidelity preservation) and history-aware iterative\nrefinement up to five rounds. Beyond single-turn editing, Med-Banana-50K\nincludes 37K failed attempts with full conversation logs for preference\nlearning and alignment research. By providing this large-scale, medically\nvalidated, and fully documented resource, Med-Banana-50K establishes a\nfoundation for training and evaluating the next generation of medical image\nediting models.Our dataset and code are publicly available at\n[https://github.com/richardChenzhihui/med-banana-50k].", "AI": {"tldr": "A new 50K-image medically validated dataset for instruction-based medical image editing across chest X-ray, brain MRI, and fundus photography, with lesion addition/removal, created using Gemini-2.5-Flash-Image and evaluated by an LLM-based judge; includes 37K failed attempts for alignment research; publicly available.", "motivation": "Addresses the lack of large-scale, high-quality, openly accessible datasets for medically constrained image editing, enabling development and evaluation of multimodal LLMs in clinical editing tasks.", "method": "Generate bidirectional edits (lesion addition/removal) on real medical images using Gemini-2.5-Flash-Image. Apply a medically grounded, rubric-driven LLM-as-Judge (instruction compliance, structural plausibility, realism, fidelity preservation) with history-aware iterative refinements up to five rounds. Collect 50K edited images and 37K failed attempts with full conversation logs for preference learning and alignment research.", "result": "A 50K-image Med-Banana-50K dataset spanning 3 modalities and 23 diseases, with high-quality edits validated by a medical rubric, plus a rich set of failed attempts for alignment research. Code and data are publicly available.", "conclusion": "Med-Banana-50K provides a scalable, medically validated resource to train and evaluate medical image editing models, facilitating next-generation model development and alignment research through both successful edits and failed attempts."}}
{"id": "2511.00564", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.00564", "abs": "https://arxiv.org/abs/2511.00564", "authors": ["Varun Teja Chirukiri", "Udaya Bhasker Cheerala", "Sandeep Kanta", "Abdul Karim", "Praveen Damacharla"], "title": "FTT-GRU: A Hybrid Fast Temporal Transformer with GRU for Remaining Useful Life Prediction", "comment": "5 pages, The 2025 International Conference on Computational Science\n  and Computational Intelligence", "summary": "Accurate prediction of the remaining useful life (RUL) of industrial\nmachinery is essential for reducing downtime and optimizing maintenance\nschedules. Existing approaches, such as long short-term memory (LSTM) networks\nand convolutional neural networks (CNNs), often struggle to model both global\ntemporal dependencies and fine-grained degradation trends in multivariate\nsensor data. We propose a hybrid model, FTT-GRU, which combines a Fast Temporal\nTransformer (FTT) -- a lightweight Transformer variant using linearized\nattention via fast Fourier transform (FFT) -- with a gated recurrent unit (GRU)\nlayer for sequential modeling. To the best of our knowledge, this is the first\napplication of an FTT with a GRU for RUL prediction on NASA CMAPSS, enabling\nsimultaneous capture of global and local degradation patterns in a compact\narchitecture. On CMAPSS FD001, FTT-GRU attains RMSE 30.76, MAE 18.97, and\n$R^2=0.45$, with 1.12 ms CPU latency at batch=1. Relative to the best published\ndeep baseline (TCN--Attention), it improves RMSE by 1.16\\% and MAE by 4.00\\%.\nTraining curves averaged over $k=3$ runs show smooth convergence with narrow\n95\\% confidence bands, and ablations (GRU-only, FTT-only) support the\ncontribution of both components. These results demonstrate that a compact\nTransformer-RNN hybrid delivers accurate and efficient RUL predictions on\nCMAPSS, making it suitable for real-time industrial prognostics.", "AI": {"tldr": "A compact FTT-GRU hybrid model for RUL prediction on CMAPSS that captures global and local degradation patterns, achieving competitive accuracy with low latency.", "motivation": "Modeling multivariate sensor data for RUL requires capturing both global temporal dependencies and fine-grained degradation trends. LSTM/CNN baselines often struggle to jointly model these aspects efficiently.", "method": "Proposes a hybrid architecture FTT-GRU that integrates a Fast Temporal Transformer (FTT) with linearized attention via FFT and a GRU layer for sequential modeling. This is applied to NASA CMAPSS (FD001), with ablations (GRU-only, FTT-only) to validate contributions, evaluating performance with RMSE, MAE, and R^2 and reporting CPU latency (batch=1).", "result": "On CMAPSS FD001, the model achieves RMSE 30.76, MAE 18.97, R^2 = 0.45, and 1.12 ms CPU latency (batch=1). Relative to the best published deep baseline (TCN\u2013Attention), RMSE improves by 1.16% and MAE by 4.00%. Training curves over 3 runs show smooth convergence with narrow 95% confidence bands; ablations confirm the contribution of both the FTT and GRU components.", "conclusion": "A compact Transformer-RNN hybrid can deliver accurate and efficient RUL predictions on CMAPSS, enabling real-time prognostics in industrial settings."}}
{"id": "2511.00810", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00810", "abs": "https://arxiv.org/abs/2511.00810", "authors": ["Shijie Zhou", "Viet Dac Lai", "Hao Tan", "Jihyung Kil", "Wanrong Zhu", "Changyou Chen", "Ruiyi Zhang"], "title": "GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding", "comment": null, "summary": "Graphical user interface (GUI) grounding is a key function of computer-use\nagents, which maps natural-language instructions to actionable screen regions.\nExisting approaches based on Multimodal Large Language Models (MLLMs) typically\nformulate it as a text-based coordinate generation task, yet directly\ngenerating precise coordinates from visual inputs remains challenging and\ncomputationally intensive. An intuitive way to implement GUI grounding is to\nfirst select visual patches relevant to the instructions and then determine the\nprecise click location within those patches. Based on the observations that\ngeneral MLLMs have some native grounding capability, nested within their\nattentions, we propose GUI-AIMA, an attention-based and coordinate-free\nsupervised fine-tuning framework for efficient GUI grounding. GUI-AIMA aligns\nthe intrinsic multimodal attention of MLLMs with patch-wise grounding signals.\nThese signals are calculated adaptively for diverse user instructions by\nmulti-head aggregation on simplified query-visual attention matrices. Besides,\nits coordinate-free manner can easily integrate a plug-and-play zoom-in stage.\nGUI-AIMA-3B was trained with only 85k screenshots, demonstrating exceptional\ndata efficiency and verifying that light training can trigger the native\ngrounding capability of MLLMs. It achieves state-of-the-art performance among\n3B models, attaining an average accuracy of 58.6% on ScreenSpot-Pro and 62.2%\non OSWorld-G. Project page: https://github.com/sjz5202/GUI-AIMA", "AI": {"tldr": "A lightweight, coordinate-free GUI grounding method (GUI-AIMA) fine-tunes multimodal LLMs to align their native attention with patch-level grounding signals, enabling efficient GUI grounding with minimal data and optional zoom-in stages, achieving strong results for 3B models.", "motivation": "To reduce reliance on explicit coordinate generation from visual inputs and to exploit MLLMs' intrinsic grounding capabilities, improving data efficiency and computational costs for GUI grounding.", "method": "An attention-based, coordinate-free supervised fine-tuning framework that aligns intrinsic multimodal attention with patch-wise grounding signals. It uses multi-head aggregation on simplified query-visual attention matrices to adapt signals across diverse instructions and supports a plug-and-play zoom-in stage.", "result": "GUI-AIMA-3B trained on 85k screenshots achieves state-of-the-art performance among 3B models, with average accuracies of 58.6% on ScreenSpot-Pro and 62.2% on OSWorld-G.", "conclusion": "The approach demonstrates data-efficient triggering of MLLMs' native grounding for GUI tasks, provides a practical coordinate-free alternative to coordinate generation, and offers plug-in zoom-in capability for improved flexibility."}}
{"id": "2511.00574", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00574", "abs": "https://arxiv.org/abs/2511.00574", "authors": ["Yinghuan Zhang", "Yufei Zhang", "Parisa Kordjamshidi", "Zijun Cui"], "title": "Bayesian Network Structure Discovery Using Large Language Models", "comment": null, "summary": "Understanding probabilistic relationships among variables is crucial for\nanalyzing complex systems. Traditional structure learning methods often require\nextensive observational data and incur high computational costs. Recent studies\nhave explored using large language models (LLMs) for structure learning, but\nmost treat LLMs as auxiliary tools for pre-processing or post-processing,\nleaving the core learning process data-driven. In this work, we propose a\nunified framework for Bayesian network structure discovery that places LLMs at\nthe center, supporting both data-free and data-aware settings. In the data-free\ncase, we introduce \\textbf{PromptBN} to query LLMs with metadata and\nefficiently uncover valid probabilistic relationships. When observational data\nare available, we introduce \\textbf{ReActBN}, which integrates the ReAct\nreasoning paradigm with structure scores such as the Bayesian Information\nCriterion (BIC) for iterative refinement. Unlike prior methods that offload\nrefinement to external algorithms, our framework maintains the LLM actively in\nthe loop throughout the discovery process. Experiments demonstrate that our\nmethod significantly outperforms both existing LLM-based approaches and\ntraditional data-driven algorithms, particularly in the low- or no-data\nscenario. Code is publicly available at\n{\\texttt{\\textcolor{magenta}{https://github.com/sherryzyh/prompt2bn}}}.", "AI": {"tldr": "A unified, LLM-centered framework for Bayesian network structure discovery with data-free (PromptBN) and data-aware (ReActBN) modes, achieving strong performance, especially with little to no data.", "motivation": "Structure learning for probabilistic graphs is data-hungry and computationally costly; leveraging LLMs as core reasoning engines can improve efficiency and enable data-scarce scenarios.", "method": "In data-free mode, PromptBN queries LLMs with metadata to uncover valid relationships. In data-aware mode, ReActBN combines the ReAct reasoning paradigm with BIC-like structure scores for iterative refinement, keeping the LLM in the loop throughout.", "result": "The approach substantially outperforms prior LLM-based methods and traditional data-driven algorithms, particularly in low/no-data regimes.", "conclusion": "A unified framework demonstrates the potential of keeping LLMs at the center of Bayesian network discovery, enabling effective structure learning across data regimes; code is publicly available."}}
{"id": "2511.00815", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00815", "abs": "https://arxiv.org/abs/2511.00815", "authors": ["Yue Gou", "Fanghui Song", "Yuming Xing", "Shengzhu Shi", "Zhichang Guo", "Boying Wu"], "title": "TA-LSDiff:Topology-Aware Diffusion Guided by a Level Set Energy for Pancreas Segmentation", "comment": "14 pages, 7 figures", "summary": "Pancreas segmentation in medical image processing is a persistent challenge\ndue to its small size, low contrast against adjacent tissues, and significant\ntopological variations. Traditional level set methods drive boundary evolution\nusing gradient flows, often ignoring pointwise topological effects. Conversely,\ndeep learning-based segmentation networks extract rich semantic features but\nfrequently sacrifice structural details. To bridge this gap, we propose a novel\nmodel named TA-LSDiff, which combined topology-aware diffusion probabilistic\nmodel and level set energy, achieving segmentation without explicit geometric\nevolution. This energy function guides implicit curve evolution by integrating\nthe input image and deep features through four complementary terms. To further\nenhance boundary precision, we introduce a pixel-adaptive refinement module\nthat locally modulates the energy function using affinity weighting from\nneighboring evidence. Ablation studies systematically quantify the contribution\nof each proposed component. Evaluations on four public pancreas datasets\ndemonstrate that TA-LSDiff achieves state-of-the-art accuracy, outperforming\nexisting methods. These results establish TA-LSDiff as a practical and accurate\nsolution for pancreas segmentation.", "AI": {"tldr": "A topology-aware diffusion-based segmentation framework (TA-LSDiff) combines a diffusion probabilistic model with level-set energy and a pixel-adaptive refinement module to deliver high-precision pancreas segmentation, achieving state-of-the-art results across four public datasets without explicit geometric evolution.", "motivation": "Pancreas segmentation is difficult due to small organ size, low contrast, and large topological variations. Traditional level-set methods underutilize topology; deep networks preserve details but risk losing boundary geometry. A method that jointly enforces topology and boundary precision while leveraging deep features is needed.", "method": "Integrates topology-aware diffusion probabilistic model with a level-set energy to guide implicit curve evolution; four-term energy function combining input image and deep features; pixel-adaptive refinement module modulates energy via affinity weights from neighboring evidence; an ablation study validates components.", "result": "Ablation studies show each component's contribution. On four public pancreas datasets, TA-LSDiff achieves state-of-the-art accuracy and outperforms existing methods.", "conclusion": "TA-LSDiff provides a practical, accurate pancreas segmentation solution that effectively merges topology-aware diffusion with energy-guided evolution and local refinement, delivering superior boundary accuracy without explicit geometric evolution."}}
{"id": "2511.00579", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00579", "abs": "https://arxiv.org/abs/2511.00579", "authors": ["G. Pillonetto", "A. Giaretta", "A. Aravkin", "M. Bisiacco", "T. Elston"], "title": "Sparse and nonparametric estimation of equations governing dynamical systems with applications to biology", "comment": null, "summary": "Data-driven discovery of model equations is a powerful approach for\nunderstanding the behavior of dynamical systems in many scientific fields. In\nparticular, the ability to learn mathematical models from data would benefit\nsystems biology, where the complex nature of these systems often makes a bottom\nup approach to modeling unfeasible. In recent years, sparse estimation\ntechniques have gained prominence in system identification, primarily using\nparametric paradigms to efficiently capture system dynamics with minimal model\ncomplexity. In particular, the Sindy algorithm has successfully used sparsity\nto estimate nonlinear systems by extracting from a library of functions only a\nfew key terms needed to capture the dynamics of these systems. However,\nparametric models often fall short in accurately representing certain\nnonlinearities inherent in complex systems. To address this limitation, we\nintroduce a novel framework that integrates sparse parametric estimation with\nnonparametric techniques. It captures nonlinearities that Sindy cannot describe\nwithout requiring a priori information about their functional form. That is,\nwithout expanding the library of functions to include the one that is trying to\nbe discovered. We illustrate our approach on several examples related to\nestimation of complex biological phenomena.", "AI": {"tldr": "A hybrid data-driven approach augments sparse, parametric model discovery (Sindy) with nonparametric components to capture nonlinearities beyond the library, improving modeling of complex biological dynamics.", "motivation": "Parametric sparse methods like Sindy are efficient but rely on a predefined library of candidate terms; biological systems exhibit nonlinearities that such libraries may miss, requiring more flexible modeling without exhaustive a priori specification.", "method": "Proposes a framework that couples sparse parametric estimation with nonparametric techniques to model unknown nonlinearities without expanding the function library. The approach identifies a sparse set of governing terms and uses nonparametric corrections to capture residual or additional nonlinear behavior; validated on multiple biological scenarios.", "result": "Applied to several illustrative examples involving complex biological phenomena; demonstrates improved ability to capture nonlinear dynamics beyond Sindy's expressiveness, demonstrating viability of the hybrid framework.", "conclusion": "Integrating sparse parametric discovery with nonparametric modeling extends data-driven dynamical system identification in biology, enabling accurate modeling while maintaining sparsity and interpretability; suggests broad applicability and potential for future refinements."}}
{"id": "2511.00821", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00821", "abs": "https://arxiv.org/abs/2511.00821", "authors": ["Ruoxiang Huang", "Xindian Ma", "Rundong Kong", "Zhen Yuan", "Peng Zhang"], "title": "OMEGA: Optimized Multimodal Position Encoding Index Derivation with Global Adaptive Scaling for Vision-Language Models", "comment": null, "summary": "Vision-Language Models (VLMs) have demonstrated strong performance across\nvarious multimodal tasks, where position encoding plays a vital role in\nmodeling both the sequential structure of textual information and the spatial\nstructure of visual information. However, current VLMs commonly adopt\nmodality-unified 1D or 2D positional indexing strategies, which treat textual\nand visual tokens uniformly without accounting for their distinct structural\nproperties and sequential continuity for text and spatial coherence for vision.\nTo address this limitation, we propose OMEGA, a novel position encoding\nframework that employs Modality-Specific Position Encoding (MSPE) to assign\npositional indices while preserving the inherent structures of each modality\nacross separate coordinate dimensions. Additionally, to align the information\ndensity of multimodal data in the positional index space, OMEGA introduces\nGlobal Adaptive Encoding Step Scaling (GAESS), which adaptively adjusts the\nposition encoding step size of visual tokens based on the embedding entropy of\nboth modalities. Experimental results demonstrate that OMEGA consistently\nenhances VLM performance across diverse architectures and VQA benchmarks. On\nvisual-intensive tasks, OMEGA achieves up to 3.43% improvement over baseline\nposition encoding strategies on Qwen2.5-VL-3B, with consistent gains observed\nacross larger models including Qwen2.5-VL-7B and LLaVA-v1.5-7B.", "AI": {"tldr": "OMEGA introduces modality-specific position encoding (MSPE) and global adaptive encoding step scaling (GAESS) to preserve text sequential structure and visual spatial coherence in vision-language models, improving performance across architectures, especially on visually intensive tasks (up to 3.43% gains on a 3B model).", "motivation": "Current VLMs use modality-unified positional indexing (1D/2D) that treats text and vision tokens uniformly, neglecting their distinct structural properties and sequential/spatial continuity. This limits cross-modal integration and efficiency.", "method": "OMEGA employs MSPE to assign positional indices along separate coordinate dimensions for text and vision, preserving each modality's inherent structure. GAESS adaptively adjusts the position encoding step size for visual tokens based on embedding entropy across modalities to balance information density in the encoding space.", "result": "Experiments show consistent gains across diverse architectures and VQA benchmarks. Notably, visual-intensive tasks see up to 3.43% improvement on Qwen2.5-VL-3B, with similar gains on larger models like Qwen2.5-VL-7B and LLaVA-v1.5-7B.", "conclusion": "Modality-specific encoding with adaptive step sizing improves multimodal fusion in VLMs, offering generalizable benefits across models and datasets."}}
{"id": "2511.00588", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.00588", "abs": "https://arxiv.org/abs/2511.00588", "authors": ["Dong Chen", "Yanzhe Wei", "Zonglin He", "Guan-Ming Kuang", "Canhua Ye", "Meiru An", "Huili Peng", "Yong Hu", "Huiren Tao", "Kenneth MC Cheung"], "title": "Diagnosing Hallucination Risk in AI Surgical Decision-Support: A Sequential Framework for Sequential Validation", "comment": null, "summary": "Large language models (LLMs) offer transformative potential for clinical\ndecision support in spine surgery but pose significant risks through\nhallucinations, which are factually inconsistent or contextually misaligned\noutputs that may compromise patient safety. This study introduces a\nclinician-centered framework to quantify hallucination risks by evaluating\ndiagnostic precision, recommendation quality, reasoning robustness, output\ncoherence, and knowledge alignment. We assessed six leading LLMs across 30\nexpert-validated spinal cases. DeepSeek-R1 demonstrated superior overall\nperformance (total score: 86.03 $\\pm$ 2.08), particularly in high-stakes\ndomains such as trauma and infection. A critical finding reveals that\nreasoning-enhanced model variants did not uniformly outperform standard\ncounterparts: Claude-3.7-Sonnet's extended thinking mode underperformed\nrelative to its standard version (80.79 $\\pm$ 1.83 vs. 81.56 $\\pm$ 1.92),\nindicating extended chain-of-thought reasoning alone is insufficient for\nclinical reliability. Multidimensional stress-testing exposed model-specific\nvulnerabilities, with recommendation quality degrading by 7.4% under amplified\ncomplexity. This decline contrasted with marginal improvements in rationality\n(+2.0%), readability (+1.7%) and diagnosis (+4.7%), highlighting a concerning\ndivergence between perceived coherence and actionable guidance. Our findings\nadvocate integrating interpretability mechanisms (e.g., reasoning chain\nvisualization) into clinical workflows and establish a safety-aware validation\nframework for surgical LLM deployment.", "AI": {"tldr": "Six LLMs were evaluated for hallucination risk in spine-surgery decision support using a clinician-centered framework; DeepSeek-R1 led performance; extended chain-of-thought did not reliably improve clinical reliability; results reveal model-specific vulnerabilities under stress; calls for interpretability and safety-focused validation in clinical deployment.", "motivation": "Mitigate patient safety risks from LLM hallucinations in high-stakes spine surgery and establish a framework to quantify and reduce those risks in clinical workflows.", "method": "Evaluation of six leading LLMs across 30 expert-validated spinal cases using a framework assessing diagnostic precision, recommendation quality, reasoning robustness, output coherence, and knowledge alignment; stress-testing under amplified complexity; comparison of reasoning-enhanced variants vs standard.", "result": "DeepSeek-R1 achieved the highest total score (86.03 \u00b1 2.08). Claude-3.7-Sonnet with extended thinking underperformed its standard version (80.79 \u00b1 1.83 vs 81.56 \u00b1 1.92). Recommendation quality degraded by 7.4% under amplified complexity; rationality (+2.0%), readability (+1.7%), and diagnosis (+4.7%) showed only marginal improvements, highlighting a gap between perceived coherence and actionable guidance.", "conclusion": "Recommend integrating interpretability mechanisms (e.g., reasoning chain visualization) into clinical workflows and implementing a safety-aware validation framework for surgical LLM deployment; extended chain-of-thought reasoning alone is insufficient for clinical reliability."}}
{"id": "2511.00831", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00831", "abs": "https://arxiv.org/abs/2511.00831", "authors": ["Xin Liu", "Aoyang Zhou", "Aoyang Zhou"], "title": "Enhancing Adversarial Transferability in Visual-Language Pre-training Models via Local Shuffle and Sample-based Attack", "comment": "Accepted by NAACL2025 findings", "summary": "Visual-Language Pre-training (VLP) models have achieved significant\nperformance across various downstream tasks. However, they remain vulnerable to\nadversarial examples. While prior efforts focus on improving the adversarial\ntransferability of multimodal adversarial examples through cross-modal\ninteractions, these approaches suffer from overfitting issues, due to a lack of\ninput diversity by relying excessively on information from adversarial examples\nin one modality when crafting attacks in another. To address this issue, we\ndraw inspiration from strategies in some adversarial training methods and\npropose a novel attack called Local Shuffle and Sample-based Attack (LSSA).\nLSSA randomly shuffles one of the local image blocks, thus expanding the\noriginal image-text pairs, generating adversarial images, and sampling around\nthem. Then, it utilizes both the original and sampled images to generate the\nadversarial texts. Extensive experiments on multiple models and datasets\ndemonstrate that LSSA significantly enhances the transferability of multimodal\nadversarial examples across diverse VLP models and downstream tasks. Moreover,\nLSSA outperforms other advanced attacks on Large Vision-Language Models.", "AI": {"tldr": "A novel attack, Local Shuffle and Sample-based Attack (LSSA), enhances the transferability of multimodal adversarial examples for Visual-Language Pre-training (VLP) models by increasing input diversity through local image block shuffling and sampling, and by jointly crafting adversarial texts from original and sampled images. It achieves superior transferability across multiple VLP models and downstream tasks and outperforms existing attacks on large vision-language models.", "motivation": "To overcome overfitting in cross-modal adversarial attacks that rely heavily on information from one modality, which hurts transferability when attacking different models or modalities. By expanding input diversity and leveraging both original and perturbed samples, LSSA aims to improve generalization of multimodal adversarial examples.", "method": "1) Randomly shuffle a local block of the image to create diversity. 2) Expand the data by generating adversarial images from the shuffled variant and sampling around them. 3) Use both the original and sampled images to craft adversarial texts, producing multimodal adversarial examples.", "result": "Empirical evaluations across multiple VLP models and downstream tasks show that LSSA significantly improves the transferability of multimodal adversarial examples compared to prior attacks. It also outperforms other advanced attacks on Large Vision-Language Models.", "conclusion": "LSSA demonstrates that increasing input diversity via local image block shuffling and sampling, combined with joint multimodal text crafting, yields stronger and more transferable multimodal adversarial examples. This highlights the importance of data augmentation-like strategies in adversarial methods and has implications for defense against multimodal attacks."}}
{"id": "2511.00615", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00615", "abs": "https://arxiv.org/abs/2511.00615", "authors": ["Daniel Griffiths", "Piper Moskow"], "title": "Gaining Momentum: Uncovering Hidden Scoring Dynamics in Hockey through Deep Neural Sequencing and Causal Modeling", "comment": "5 Pages, 4 Figures, 2 Tables", "summary": "We present a unified, data-driven framework for quantifying and enhancing\noffensive momentum and scoring likelihood (expected goals, xG) in professional\nhockey. Leveraging a Sportlogiq dataset of 541,000 NHL event records, our\nend-to-end pipeline comprises five stages: (1) interpretable momentum weighting\nof micro-events via logistic regression; (2) nonlinear xG estimation using\ngradient-boosted decision trees; (3) temporal sequence modeling with Long\nShort-Term Memory (LSTM) networks; (4) spatial formation discovery through\nprincipal component analysis (PCA) followed by K-Means clustering on\nstandardized player coordinates; and (5) use of an X-Learner causal inference\nestimator to quantify the average treatment effect (ATE) of adopting the\nidentified \"optimal\" event sequences and formations. We observe an ATE of 0.12\n(95% CI: 0.05-0.17, p < 1e-50), corresponding to a 15% relative gain in scoring\npotential. These results demonstrate that strategically structured sequences\nand compact formations causally elevate offensive performance. Our framework\ndelivers real-time, actionable insights for coaches and analysts, advancing\nhockey analytics toward principled, causally grounded tactical optimization.", "AI": {"tldr": "A data-driven five-stage pipeline improves NHL offensive performance and xG through causal analysis, achieving ATE 0.12 and 15% gain.", "motivation": "Quantify and optimize offensive momentum and scoring in professional hockey with causal, real-time analytics.", "method": "Five-stage pipeline: (1) momentum weighting via logistic regression; (2) xG via gradient-boosted trees; (3) LSTM for sequence dynamics; (4) PCA + K-Means for spatial formations; (5) X-Learner for ATE of optimal sequences/formations.", "result": "ATE 0.12 (CI 0.05\u20130.17; p<1e-50), ~15% relative gain in scoring potential; evidence that structured sequences and compact formations causally boost offense.", "conclusion": "Framework enables real-time, actionable insights and advances causally grounded tactical optimization in hockey analytics."}}
{"id": "2511.00833", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00833", "abs": "https://arxiv.org/abs/2511.00833", "authors": ["Yifan Pu", "Jixuan Ying", "Qixiu Li", "Tianzhu Ye", "Dongchen Han", "Xiaochen Wang", "Ziyi Wang", "Xinyu Shao", "Gao Huang", "Xiu Li"], "title": "Linear Differential Vision Transformer: Learning Visual Contrasts via Pairwise Differentials", "comment": "NeurIPS 2025", "summary": "Vision Transformers (ViTs) have become a universal backbone for both image\nrecognition and image generation. Yet their Multi-Head Self-Attention (MHSA)\nlayer still performs a quadratic query-key interaction for every token pair,\nspending the bulk of computation on visually weak or redundant correlations. We\nintroduce Visual-Contrast Attention (VCA), a drop-in replacement for MHSA that\ninjects an explicit notion of discrimination while reducing the theoretical\ncomplexity from O(N N C) to O(N n C) with n << N. VCA first distils each head's\ndense query field into a handful of spatially pooled visual-contrast tokens,\nthen splits them into a learnable positive and negative stream whose\ndifferential interaction highlights what truly separates one region from\nanother. The module adds fewer than 0.3M parameters to a DeiT-Tiny backbone,\nrequires no extra FLOPs, and is wholly architecture-agnostic. Empirically, VCA\nlifts DeiT-Tiny top-1 accuracy on ImageNet-1K from 72.2% to 75.6% (+3.4) and\nimproves three strong hierarchical ViTs by up to 3.1%, while in\nclass-conditional ImageNet generation it lowers FID-50K by 2.1 to 5.2 points\nacross both diffusion (DiT) and flow (SiT) models. Extensive ablations confirm\nthat (i) spatial pooling supplies low-variance global cues, (ii) dual\npositional embeddings are indispensable for contrastive reasoning, and (iii)\ncombining the two in both stages yields the strongest synergy. VCA therefore\noffers a simple path towards faster and sharper Vision Transformers. The source\ncode is available at https://github.com/LeapLabTHU/LinearDiff.", "AI": {"tldr": "Introduce Visual-Contrast Attention (VCA): a drop-in MHSA replacement for Vision Transformers that uses pooled visual-contrast tokens and dual positive/negative streams to concentrate on discriminative relations, reducing complexity from O(N^2 C) to O(N n C) (with n << N) and adding ~0.3M parameters; achieves notable accuracy gains on ImageNet and improves generative model FID, with ablations highlighting the value of spatial pooling and dual positional embeddings.", "motivation": "MHSA in Vision Transformers is computationally heavy due to quadratic query-key interactions, often focusing on weak or redundant correlations. There is a need for a discriminative, efficient attention mechanism that preserves or improves accuracy for recognition and generative tasks while reducing compute.", "method": "Replace MHSA with Visual-Contrast Attention (VCA): distill each head's dense query field into a small set of spatially pooled visual-contrast tokens, split into learnable positive and negative streams, and perform their differential interaction to emphasize discriminative distinctions. Reduces complexity from O(N^2 C) to O(N n C) where n << N. Architecture-agnostic drop-in replacement; leverages spatial pooling and dual positional embeddings; demonstrated across recognition and class-conditional generation.", "result": "Empirically, VCA improves DeiT-Tiny top-1 on ImageNet-1K from 72.2% to 75.6% (+3.4). It also improves three strong hierarchical ViTs by up to 3.1%. In class-conditional ImageNet generation, it lowers FID-50K by 2.1 to 5.2 points across both diffusion (DiT) and flow (SiT) models. Ablations show that spatial pooling provides low-variance global cues and that dual positional embeddings are indispensable for contrastive reasoning; their combination yields the strongest synergy.", "conclusion": "VCA offers a simple, faster, and sharper Vision Transformer with minimal parameter overhead (~0.3M) and no extra FLOPs, and it remains architecture-agnostic. The authors provide source code for reproduction."}}
{"id": "2511.00617", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00617", "abs": "https://arxiv.org/abs/2511.00617", "authors": ["Eric Bigelow", "Daniel Wurgaft", "YingQiao Wang", "Noah Goodman", "Tomer Ullman", "Hidenori Tanaka", "Ekdeep Singh Lubana"], "title": "Belief Dynamics Reveal the Dual Nature of In-Context Learning and Activation Steering", "comment": null, "summary": "Large language models (LLMs) can be controlled at inference time through\nprompts (in-context learning) and internal activations (activation steering).\nDifferent accounts have been proposed to explain these methods, yet their\ncommon goal of controlling model behavior raises the question of whether these\nseemingly disparate methodologies can be seen as specific instances of a\nbroader framework. Motivated by this, we develop a unifying, predictive account\nof LLM control from a Bayesian perspective. Specifically, we posit that both\ncontext- and activation-based interventions impact model behavior by altering\nits belief in latent concepts: steering operates by changing concept priors,\nwhile in-context learning leads to an accumulation of evidence. This results in\na closed-form Bayesian model that is highly predictive of LLM behavior across\ncontext- and activation-based interventions in a set of domains inspired by\nprior work on many-shot in-context learning. This model helps us explain prior\nempirical phenomena - e.g., sigmoidal learning curves as in-context evidence\naccumulates - while predicting novel ones - e.g., additivity of both\ninterventions in log-belief space, which results in distinct phases such that\nsudden and dramatic behavioral shifts can be induced by slightly changing\nintervention controls. Taken together, this work offers a unified account of\nprompt-based and activation-based control of LLM behavior, and a methodology\nfor empirically predicting the effects of these interventions.", "AI": {"tldr": "A Bayesian unifying framework shows that prompt-based (context) and activation-based (internal) control of LLMs can be seen as altering latent concept beliefs: prompts accumulate evidence, activations shift priors. The resulting closed-form model predicts behavior across interventions and reveals additive log-belief effects and phase transitions.", "motivation": "To unify disparate LLM control mechanisms (in-context learning via prompts and activation steering) under a single, predictive theory, enabling better understanding and prediction of how interventions steer model behavior.", "method": "Develop a closed-form Bayesian model where context interventions modify priors over latent concepts and activation interventions accumulate evidence. Validate the model in multi-domain tasks inspired by many-shot in-context learning, deriving predictions (e.g., sigmoidal learning curves, additivity in log-belief space).", "result": "The framework provides highly predictive explanations of behavior under both intervention types and yields novel predictions such as additive effects and distinct phases, explaining past empirical phenomena and predicting abrupt shifts with small control changes.", "conclusion": "Offers a unified Bayesian account of prompt- and activation-based LLM control and a practical methodology to predict effects of such interventions across domains."}}
{"id": "2511.00836", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00836", "abs": "https://arxiv.org/abs/2511.00836", "authors": ["Xin Liu", "Yichen Yang", "Kun He", "John E. Hopcroft"], "title": "Parameter Interpolation Adversarial Training for Robust Image Classification", "comment": "Accepted by TIFS 2025", "summary": "Though deep neural networks exhibit superior performance on various tasks,\nthey are still plagued by adversarial examples. Adversarial training has been\ndemonstrated to be the most effective method to defend against adversarial\nattacks. However, existing adversarial training methods show that the model\nrobustness has apparent oscillations and overfitting issues in the training\nprocess, degrading the defense efficacy. To address these issues, we propose a\nnovel framework called Parameter Interpolation Adversarial Training (PIAT).\nPIAT tunes the model parameters between each epoch by interpolating the\nparameters of the previous and current epochs. It makes the decision boundary\nof model change more moderate and alleviates the overfitting issue, helping the\nmodel converge better and achieving higher model robustness. In addition, we\nsuggest using the Normalized Mean Square Error (NMSE) to further improve the\nrobustness by aligning the relative magnitude of logits between clean and\nadversarial examples rather than the absolute magnitude. Extensive experiments\nconducted on several benchmark datasets demonstrate that our framework could\nprominently improve the robustness of both Convolutional Neural Networks (CNNs)\nand Vision Transformers (ViTs).", "AI": {"tldr": "Interpolate model parameters between epochs during adversarial training and apply Normalized Mean Square Error to logits, improving robustness for CNNs and ViTs.", "motivation": "Adversarial training often suffers from training instability, oscillations, and overfitting, which degrade robustness.", "method": "Introduce Parameter Interpolation Adversarial Training (PIAT) by interpolating parameters of the previous and current epochs to stabilize decision boundaries; use NMSE to align the relative magnitudes of logits between clean and adversarial samples rather than their absolute values.", "result": "Empirical results on benchmark datasets show that PIAT improves robustness and convergence for both CNNs and ViTs, reducing overfitting compared to standard adversarial training.", "conclusion": "PIAT provides a simple, effective framework to boost adversarial robustness with stabilized training, and NMSE offers additional gains by better aligning logit magnitudes across clean and adversarial inputs."}}
{"id": "2511.00637", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00637", "abs": "https://arxiv.org/abs/2511.00637", "authors": ["Emmeran Johnson", "Alberto Rumi", "Ciara Pike-Burke", "Patrick Rebeschini"], "title": "Stochastic Shortest Path with Sparse Adversarial Costs", "comment": null, "summary": "We study the adversarial Stochastic Shortest Path (SSP) problem with sparse\ncosts under full-information feedback. In the known transition setting,\nexisting bounds based on Online Mirror Descent (OMD) with negative-entropy\nregularization scale with $\\sqrt{\\log S A}$, where $SA$ is the size of the\nstate-action space. While we show that this is optimal in the worst-case, this\nbound fails to capture the benefits of sparsity when only a small number $M \\ll\nSA$ of state-action pairs incur cost. In fact, we also show that the\nnegative-entropy is inherently non-adaptive to sparsity: it provably incurs\nregret scaling with $\\sqrt{\\log S}$ on sparse problems. Instead, we propose a\nfamily of $\\ell_r$-norm regularizers ($r \\in (1,2)$) that adapts to the\nsparsity and achieves regret scaling with $\\sqrt{\\log M}$ instead of\n$\\sqrt{\\log SA}$. We show this is optimal via a matching lower bound,\nhighlighting that $M$ captures the effective dimension of the problem instead\nof $SA$. Finally, in the unknown transition setting the benefits of sparsity\nare limited: we prove that even on sparse problems, the minimax regret for any\nlearner scales polynomially with $SA$.", "AI": {"tldr": "Sparse-cost adversarial SSP with full-information feedback: negative-entropy regularization in OMD does not exploit sparsity, yielding regret depending on log S; introducing ell_r-norm regularizers (r in (1,2)) adapts to sparsity and achieves regret ~ sqrt(log M) with matching lower bound; in unknown transitions, sparsity provides no regret improvement, with minimax regret polynomial in SA.", "motivation": "To understand how sparsity of incurred costs affects regret in adversarial stochastic shortest path (SSP) learning under full-information feedback and to develop adaptive regularizers that exploit sparsity.", "method": "Introduce a family of ell_r-norm regularizers (r in (1,2)) within Online Mirror Descent to adapt to sparse cost structure; derive upper bounds showing regret scales with sqrt(log M); establish a matching lower bound; compare with negative-entropy regularization which remains non-adaptive; analyze the unknown-transition setting.", "result": "Under known transitions, the ell_r regularizers achieve regret scaling as sqrt(log M), and this rate is optimal via a matching lower bound; effective dimension shifts from SA to M. Negative-entropy regularization remains non-adaptive to sparsity, incurring sqrt(log S) (or sqrt(log S) in sparse regimes). In the unknown-transition setting, sparsity offers limited gains and the minimax regret scales polynomially with SA, regardless of sparsity.", "conclusion": "Sparsity reduces the effective dimension from the full state-action count SA to the sparse support size M under full-information; adaptive ell_r-regularizers provide optimal regret scaling with sqrt(log M). In unknown transitions, sparsity does not yield similar improvements, highlighting the necessity of problem setting in exploiting sparse costs."}}
{"id": "2511.00846", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00846", "abs": "https://arxiv.org/abs/2511.00846", "authors": ["Zhihao Peng", "Cheng Wang", "Shengyuan Liu", "Zhiying Liang", "Yixuan Yuan"], "title": "OmniBrainBench: A Comprehensive Multimodal Benchmark for Brain Imaging Analysis Across Multi-stage Clinical Tasks", "comment": null, "summary": "Brain imaging analysis is vital for diagnosing and treating brain disorders,\nand multimodal large language models (MLLMs) are increasingly assisting in that\nanalysis. However, current brain-oriented visual question-answering (VQA)\nbenchmarks either cover a few imaging modalities or are limited to\ncoarse-grained pathological descriptions, hindering a comprehensive assessment\nof MLLMs throughout the full clinical continuum. To address these, we introduce\nOmniBrainBench, the first comprehensive multimodal VQA benchmark specifically\ndesigned to assess the multimodal comprehension capabilities of MLLMs in brain\nimaging analysis.OmniBrainBench consists of 15 distinct brain imaging\nmodalities collected from 30 verified medical sources, yielding 9,527 validated\nVQA pairs and 31,706 images. It simulates clinical workflows and encompasses 15\nmulti-stage clinical tasks rigorously validated by a professional radiologist.\nEvaluation of 24 state-of-the-art models, including open-source, medical, and\nproprietary MLLMs, highlights the substantial challenges posed by\nOmniBrainBench. Our experiments reveal: (1) proprietary MLLMs (e.g., GPT-5)\nbeat open-source and medical models but lag physicians; (2) medical MLLMs vary\nwidely in performance; (3) open-source MLLMs trail overall but excel in\nspecific tasks; (4) MLLMs underperform sharply in complex preoperative tasks,\nrevealing a visual-to-clinical reasoning gap. OmniBrainBench sets a new\nstandard for evaluating and advancing MLLMs in brain imaging analysis,\nhighlighting gaps compared to expert clinical reasoning. We release it at\nbenchmark \\& code.", "AI": {"tldr": "Introduces OmniBrainBench, a comprehensive multimodal VQA benchmark for brain imaging with 15 modalities, ~9.5k VQA pairs and 31.7k images across 15 clinical tasks; evaluates 24 MLLMs; finds a significant gap vs physicians and a visual-to-clinical reasoning bottleneck.", "motivation": "Existing brain-imaging VQA benchmarks lack modality breadth and clinical workflow depth; there is a need to evaluate MLLMs\u2019 multimodal and procedural reasoning across the full clinical continuum.", "method": "Assembles OmniBrainBench from 15 imaging modalities using 30 sources; creates 9,527 validated VQA pairs and 31,706 images; frames 15 multi-stage clinical tasks validated by radiologists; benchmarks 24 models (open-source, medical, proprietary).", "result": "Proprietary MLLMs outperform others yet still lag physicians; medical MLLMs vary; open-source MLLMs generally behind but excel on some tasks; MLLMs struggle with complex preoperative tasks, indicating a gap in visual-to-clinical reasoning.", "conclusion": "OmniBrainBench establishes a new standard for evaluating MLLMs in brain imaging analysis and exposes gaps relative to expert clinical reasoning; benchmark and code are released."}}
{"id": "2511.00648", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00648", "abs": "https://arxiv.org/abs/2511.00648", "authors": ["C. D\u00edaz-Faloh", "R. Mulet"], "title": "Diluting Restricted Boltzmann Machines", "comment": null, "summary": "Recent advances in artificial intelligence have relied heavily on\nincreasingly large neural networks, raising concerns about their computational\nand environmental costs. This paper investigates whether simpler, sparser\nnetworks can maintain strong performance by studying Restricted Boltzmann\nMachines (RBMs) under extreme pruning conditions. Inspired by the Lottery\nTicket Hypothesis, we demonstrate that RBMs can achieve high-quality generative\nperformance even when up to 80% of the connections are pruned before training,\nconfirming that they contain viable sub-networks. However, our experiments\nreveal crucial limitations: trained networks cannot fully recover lost\nperformance through retraining once additional pruning is applied. We identify\na sharp transition above which the generative quality degrades abruptly when\npruning disrupts a minimal core of essential connections. Moreover, re-trained\nnetworks remain constrained by the parameters originally learned performing\nworse than networks trained from scratch at equivalent sparsity levels. These\nresults suggest that for sparse networks to work effectively, pruning should be\nimplemented early in training rather than attempted afterwards. Our findings\nprovide practical insights for the development of efficient neural\narchitectures and highlight the persistent influence of initial conditions on\nnetwork capabilities.", "AI": {"tldr": "RBMs can retain strong generative performance under extreme pruning (up to 80% of connections pruned before training), aligning with the Lottery Ticket Hypothesis, but retraining after further pruning cannot fully recover lost performance. There is a sharp transition where pruning disrupts a minimal core of essential connections, and retrained networks underperform those trained from scratch at equivalent sparsity. Early pruning is thus crucial, and initial conditions heavily influence network capabilities.", "motivation": "To address the efficiency and environmental concerns of large neural networks by testing whether smaller, sparse models can match performance. The study uses Restricted Boltzmann Machines to examine the Lottery Ticket Hypothesis under aggressive pruning conditions and its impact on generative quality.", "method": "Systematically prune RBMs up to 80% of their connections before training and evaluate generative performance. Investigate retraining after additional pruning, compare retrained networks to networks trained from scratch at matching sparsity, and identify transitions in generative quality and core connectivity requirements.", "result": "RBMs with substantial pre-training pruning achieve high-quality generative performance. However, retraining after further pruning cannot fully recover performance. A sharp transition occurs when pruning disrupts a minimal core of essential connections. Retrained networks underperform those trained from scratch at the same sparsity level, indicating that pruning must occur early and is heavily influenced by initial conditions.", "conclusion": "Pruning should be applied early in training for sparse networks to work effectively, as initial conditions and the preserved core connections largely determine generative capability. The findings support a practical approach to efficient neural architectures and extend the Lottery Ticket concept to generative models like RBMs."}}
{"id": "2511.00858", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00858", "abs": "https://arxiv.org/abs/2511.00858", "authors": ["Yu Liu", "Zhijie Liu", "Zedong Yang", "You-Fu Li", "He Kong"], "title": "Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction", "comment": "This manuscript has been accepted to the IEEE Transactions on\n  Intelligent Transportation Systems as a regular paper", "summary": "Predicting pedestrian crossing intentions is crucial for the navigation of\nmobile robots and intelligent vehicles. Although recent deep learning-based\nmodels have shown significant success in forecasting intentions, few consider\nincomplete observation under occlusion scenarios. To tackle this challenge, we\npropose an Occlusion-Aware Diffusion Model (ODM) that reconstructs occluded\nmotion patterns and leverages them to guide future intention prediction. During\nthe denoising stage, we introduce an occlusion-aware diffusion transformer\narchitecture to estimate noise features associated with occluded patterns,\nthereby enhancing the model's ability to capture contextual relationships in\noccluded semantic scenarios. Furthermore, an occlusion mask-guided reverse\nprocess is introduced to effectively utilize observation information, reducing\nthe accumulation of prediction errors and enhancing the accuracy of\nreconstructed motion features. The performance of the proposed method under\nvarious occlusion scenarios is comprehensively evaluated and compared with\nexisting methods on popular benchmarks, namely PIE and JAAD. Extensive\nexperimental results demonstrate that the proposed method achieves more robust\nperformance than existing methods in the literature.", "AI": {"tldr": "An Occlusion-Aware Diffusion Model (ODM) reconstructs occluded pedestrian motion to forecast crossing intentions under occlusion, using an occlusion-aware diffusion transformer in denoising and an occlusion mask-guided reverse process; shows robust gains on PIE and JAAD.", "motivation": "Occlusion during observation degrades prediction of pedestrian crossing intentions; current methods struggle to infer hidden motion and context under occlusion, hindering safe navigation.", "method": "ODM combines diffusion modeling with an occlusion-aware transformer to estimate noise features for occluded patterns during denoising; employs an occlusion mask-guided reverse process to effectively leverage observed information and reduce error accumulation; evaluated on PIE and JAAD benchmarks.", "result": "Empirical results indicate ODM achieves more robust performance than existing methods across varying occlusion scenarios on PIE and JAAD.", "conclusion": "Occlusion-aware diffusion with mask-guided inference effectively reconstructs occluded motion and improves crossing-intention prediction, contributing to safer navigation for mobile robots and intelligent vehicles."}}
{"id": "2511.00655", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00655", "abs": "https://arxiv.org/abs/2511.00655", "authors": ["Baris Askin", "Holger R. Roth", "Zhenyu Sun", "Carlee Joe-Wong", "Gauri Joshi", "Ziyue Xu"], "title": "Reviving Stale Updates: Data-Free Knowledge Distillation for Asynchronous Federated Learning", "comment": null, "summary": "Federated Learning (FL) enables collaborative model training across\ndistributed clients without sharing raw data, yet its scalability is limited by\nsynchronization overhead. Asynchronous Federated Learning (AFL) alleviates this\nissue by allowing clients to communicate independently, thereby improving\nwall-clock efficiency in large-scale, heterogeneous environments. However, this\nasynchrony introduces stale updates (client updates computed on outdated global\nmodels) that can destabilize optimization and hinder convergence. We propose\nFedRevive, an asynchronous FL framework that revives stale updates through\ndata-free knowledge distillation (DFKD). FedRevive integrates parameter-space\naggregation with a lightweight, server-side DFKD process that transfers\nknowledge from stale client models to the current global model without access\nto real or public data. A meta-learned generator synthesizes pseudo-samples,\nwhich enables multi-teacher distillation. A hybrid aggregation scheme that\ncombines raw updates with DFKD updates effectively mitigates staleness while\nretaining the scalability of AFL. Experiments on various vision and text\nbenchmarks show that FedRevive achieves faster training up to 32.1% and higher\nfinal accuracy up to 21.5% compared to asynchronous baselines.", "AI": {"tldr": "FedRevive proposes asynchronous federated learning with data-free knowledge distillation to mitigate stale updates, using server-side distillation with a meta-learned generator and a hybrid aggregation to retain scalability.", "motivation": "Asynchronous FL improves wall-clock efficiency but suffers from stale updates that can destabilize optimization and hinder convergence; there is a need to address staleness without relying on real/public data.", "method": "Combine asynchronous federated learning with a server-side data-free knowledge distillation (DFKD) pipeline. A meta-learned generator creates pseudo-samples for multi-teacher distillation. Distillation updates are integrated with raw client updates via a hybrid aggregation scheme to mitigate staleness while preserving AFL scalability.", "result": "Empirical evaluation on vision and text benchmarks shows FedRevive achieves up to 32.1% faster training and up to 21.5% higher final accuracy compared to asynchronous baselines.", "conclusion": "FedRevive effectively mitigates the adverse effects of stale updates in AFL by fusing raw updates with DFKD-derived knowledge, maintaining scalability while improving convergence and accuracy."}}
{"id": "2511.00859", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00859", "abs": "https://arxiv.org/abs/2511.00859", "authors": ["Jaehyun Park", "Konyul Park", "Daehun Kim", "Junseo Park", "Jun Won Choi"], "title": "Layer-Wise Modality Decomposition for Interpretable Multimodal Sensor Fusion", "comment": "Accepted to NeurIPS 2025", "summary": "In autonomous driving, transparency in the decision-making of perception\nmodels is critical, as even a single misperception can be catastrophic. Yet\nwith multi-sensor inputs, it is difficult to determine how each modality\ncontributes to a prediction because sensor information becomes entangled within\nthe fusion network. We introduce Layer-Wise Modality Decomposition (LMD), a\npost-hoc, model-agnostic interpretability method that disentangles\nmodality-specific information across all layers of a pretrained fusion model.\nTo our knowledge, LMD is the first approach to attribute the predictions of a\nperception model to individual input modalities in a sensor-fusion system for\nautonomous driving. We evaluate LMD on pretrained fusion models under\ncamera-radar, camera-LiDAR, and camera-radar-LiDAR settings for autonomous\ndriving. Its effectiveness is validated using structured perturbation-based\nmetrics and modality-wise visual decompositions, demonstrating practical\napplicability to interpreting high-capacity multimodal architectures. Code is\navailable at https://github.com/detxter-jvb/Layer-Wise-Modality-Decomposition.", "AI": {"tldr": "Layer-Wise Modality Decomposition (LMD) provides post-hoc, model-agnostic attribution of modality contributions across all layers of a sensor-fusion model in autonomous driving, enabling attribution of predictions to individual input modalities; evaluated on camera\u2013radar, camera\u2013LiDAR, and camera\u2013radar\u2013LiDAR settings with structured perturbation metrics, and code is released.", "motivation": "In autonomous driving, perception failures can be catastrophic. Sensor fusion entangles modality information, making it hard to interpret which sensor contributed to a prediction. There is a need for interpretable explanations that attribute decisions to specific modalities to improve transparency and safety.", "method": "Propose Layer-Wise Modality Decomposition (LMD), a post-hoc, model-agnostic interpretability method that disentangles modality-specific information across all layers of a pretrained fusion model. It is applied to pretrained fusion models under camera\u2013radar, camera\u2013LiDAR, and camera\u2013radar\u2013LiDAR settings. Evaluation uses structured perturbation-based metrics and modality-wise visual decompositions.", "result": "LMD effectively attributes predictions to individual modalities across all layers, validated on multiple sensor-fusion setups and demonstrated via structured perturbations and modality-wise visualizations. The approach shows practical applicability for interpreting high-capacity multimodal architectures.", "conclusion": "LMD enables first-of-its-kind attribution of autonomous-driving perception predictions to input modalities within sensor-fusion systems. It provides an interpretable, post-hoc tool for understanding modality contributions, with open-source code for broader adoption; future work could explore scalability, broader modality sets, and integration into safety-critical pipelines."}}
{"id": "2511.00663", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00663", "abs": "https://arxiv.org/abs/2511.00663", "authors": ["Alex Dobra", "Jakiw Pidstrigach", "Tim Reichelt", "Paolo Fraccaro", "Johannes Jakubik", "Anne Jones", "Christian Schroeder de Witt", "Philip Stier", "Philip Torr"], "title": "Sensitivity Analysis for Climate Science with Generative Flow Models", "comment": null, "summary": "Sensitivity analysis is a cornerstone of climate science, essential for\nunderstanding phenomena ranging from storm intensity to long-term climate\nfeedbacks. However, computing these sensitivities using traditional physical\nmodels is often prohibitively expensive in terms of both computation and\ndevelopment time. While modern AI-based generative models are orders of\nmagnitude faster to evaluate, computing sensitivities with them remains a\nsignificant bottleneck. This work addresses this challenge by applying the\nadjoint state method for calculating gradients in generative flow models, with\ndiffusion models as a special case. We apply this method to the cBottle\ngenerative model, an emulator of ERA5 data, to perform sensitivity analysis\nwith respect to sea surface temperatures. Furthermore, we propose a novel\ngradient self-consistency check to quantitatively validate the computed\nsensitivities against the model's own outputs. Our results provide initial\nevidence that this approach can produce reliable gradients, reducing the\ncomputational cost of sensitivity analysis from weeks on a supercomputer with a\nphysical model to hours on a GPU, thereby simplifying a critical workflow in\nclimate science.", "AI": {"tldr": "We present an adjoint-state method to compute gradients in generative flow models (diffusion models in particular), apply it to the cBottle ERA5 emulator to analyze sensitivities to Sea Surface Temperature, and introduce a gradient self-consistency check. Early results show reliable gradients and substantial speedups (weeks on HPC to hours on GPU), streamlining climate-sensitivity workflows.", "motivation": "Sensitivity analysis is crucial in climate science but traditional physical models are costly. AI-based generative models offer speed, but gradient computation remains a bottleneck. By combining adjoint-state methods with generative flow models, the work aims to enable efficient, scalable sensitivity analyses.", "method": "Apply the adjoint state method to calculate gradients in generative flow models, treating diffusion models as a special case. Implement and test on the cBottle ERA5 emulator to perform sensitivity analysis with respect to sea surface temperatures. Introduce a gradient self-consistency check to validate computed gradients against the model\u2019s outputs.", "result": "Initial evidence that the adjoint-based gradients in generative flow models can be reliable. The approach reduces sensitivity-analysis computation from weeks on supercomputers to hours on GPUs, enabling a faster, more accessible workflow for climate science.", "conclusion": "Adjoint-state gradient computation in generative flow models, with a diffusion-model special case and a gradient self-consistency check, shows promise for reliable, scalable sensitivity analyses in climate science and substantial computational savings."}}
{"id": "2511.00908", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.00908", "abs": "https://arxiv.org/abs/2511.00908", "authors": ["Heng Zheng", "Yuling Shi", "Xiaodong Gu", "Haochen You", "Zijian Zhang", "Lubin Gan", "Hao Zhang", "Wenjun Huang", "Jin Huang"], "title": "GraphGeo: Multi-Agent Debate Framework for Visual Geo-localization with Heterogeneous Graph Neural Networks", "comment": null, "summary": "Visual geo-localization requires extensive geographic knowledge and\nsophisticated reasoning to determine image locations without GPS metadata.\nTraditional retrieval methods are constrained by database coverage and quality.\nRecent Large Vision-Language Models (LVLMs) enable direct location reasoning\nfrom image content, yet individual models struggle with diverse geographic\nregions and complex scenes. Existing multi-agent systems improve performance\nthrough model collaboration but treat all agent interactions uniformly. They\nlack mechanisms to handle conflicting predictions effectively. We propose\n\\textbf{GraphGeo}, a multi-agent debate framework using heterogeneous graph\nneural networks for visual geo-localization. Our approach models diverse debate\nrelationships through typed edges, distinguishing supportive collaboration,\ncompetitive argumentation, and knowledge transfer. We introduce a dual-level\ndebate mechanism combining node-level refinement and edge-level argumentation\nmodeling. A cross-level topology refinement strategy enables co-evolution\nbetween graph structure and agent representations. Experiments on multiple\nbenchmarks demonstrate GraphGeo significantly outperforms state-of-the-art\nmethods. Our framework transforms cognitive conflicts between agents into\nenhanced geo-localization accuracy through structured debate.", "AI": {"tldr": "GraphGeo uses a heterogeneous GNN with a dual-level debate mechanism to convert agent disagreements into improved visual geo-localization performance.", "motivation": "Visual geo-localization struggles due to knowledge gaps, limited database coverage, and conflicting predictions. While LVLMs enable location reasoning, they struggle across diverse regions and complex scenes. Existing multi-agent systems lack mechanisms to handle conflicts effectively, limiting gains from collaboration.", "method": "GraphGeo builds a heterogeneous graph neural network with typed edges representing supportive collaboration, competitive argumentation, and knowledge transfer. It employs a dual-level debate mechanism: node-level refinement and edge-level argumentation modeling, along with a cross-level topology refinement strategy that co-evolves graph structure and agent representations.", "result": "Experiments on multiple benchmarks show GraphGeo significantly outperforms state-of-the-art methods, indicating that structured debate among heterogeneous agents improves geo-localization accuracy.", "conclusion": "Transforming cognitive conflicts between agents into structured debate yields enhanced geo-localization performance."}}
{"id": "2511.00699", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00699", "abs": "https://arxiv.org/abs/2511.00699", "authors": ["Sophie Li", "Nicholas Huang", "Nayan Saxena", "Nina Luo", "Vincent Lin", "Kevin Zhu", "Sunishchal Dev"], "title": "Inference-Time Chain-of-Thought Pruning with Latent Informativeness Signals", "comment": null, "summary": "Large language models (LLMs) improve reasoning accuracy when generating\nmultiple candidate solutions at test time, but standard methods like Best-of-N\n(BoN) incur high computational cost by fully generating all branches.\nSelf-Truncation Best-of-N (ST-BoN) mitigates this by truncating unpromising\npaths early, but its reliance on consistency-based heuristics is a limitation\nas it does not directly evaluate branch quality. We present KL-Adjusted Pruned\nPath Algorithm (KAPPA), an inference-time method that combines Kullback-Leibler\ndivergence, confidence, and entropy into a principled scoring function to guide\nprogressive pruning. By promoting diversity during exploration and selectively\neliminating low-scoring branches, KAPPA maintains accuracy while substantially\nreducing memory and token usage. Experiments on GSM8K and MATH500 with\nDeepSeek-R1-Distill-Qwen-1.5B and Qwen2.5-7B-Instruct demonstrate that KAPPA\nstabilizes performance in smaller models and achieves up to ~60% reduction in\npeak memory and ~90% reduction in total token generation relative to BoN, with\nminimal impact on accuracy.", "AI": {"tldr": "KAPPA uses KL-divergence, confidence, and entropy to guide progressive pruning of branches in Best-of-N-style decoding, achieving substantial memory and token savings with minimal accuracy loss.", "motivation": "BoN-based decoding is computationally expensive; ST-BoN relies on consistency heuristics and may misjudge branch quality. There is a need for principled, inference-time pruning that preserves diversity and accuracy while reducing resource usage.", "method": "A KL-adjusted pruned path algorithm that scores branches using KL divergence, confidence, and entropy; promotes diverse exploration and selectively eliminates low-scoring branches to prune search space during inference.", "result": "On GSM8K and MATH500 with DeepSeek-R1-Distill-Qwen-1.5B and Qwen2.5-7B-Instruct, KAPPA stabilizes performance in smaller models and achieves up to ~60% peak memory reduction and ~90% reduction in total token generation versus Best-of-N, with minimal impact on accuracy.", "conclusion": "KAPPA provides a principled, scalable inference-time pruning strategy that preserves accuracy while substantially reducing memory and token usage, enabling efficient multi-solution decoding in resource-constrained settings."}}
{"id": "2511.00916", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00916", "abs": "https://arxiv.org/abs/2511.00916", "authors": ["Yan Shu", "Chi Liu", "Robin Chen", "Derek Li", "Bryan Dai"], "title": "Fleming-VL: Towards Universal Medical Visual Reasoning with Multimodal LLMs", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\neffectiveness in various general-domain scenarios, such as visual question\nanswering and image captioning. Recently, researchers have increasingly focused\non empowering MLLMs with medical conversational abilities, which hold\nsignificant promise for clinical applications. However, medical data presents\nunique challenges due to its heterogeneous nature -- encompassing diverse\nmodalities including 2D images, 3D volumetric scans, and temporal video\nsequences. The substantial domain gap and data format inconsistencies across\nthese modalities have hindered the development of unified medical MLLMs. To\naddress these challenges, we propose Fleming-VL, a unified end-to-end framework\nfor comprehensive medical visual understanding across heterogeneous modalities.\nFleming-VL tackles this problem from a data-centric perspective through three\nkey strategies: (1) scaling up pretraining by integrating long-context data\nfrom both natural and medical-specific domains; (2) complementing fine-tuning\nwith rare medical data, including holistic video analysis and underrepresented\n2D modalities such as ultrasound and dermoscopy images; (3) extending existing\nevaluation frameworks to incorporate 3D volumetric and video understanding\nbenchmarks. Through supervised fine-tuning (SFT) and group relative policy\noptimization (GRPO), we develop Fleming-VL in multiple model scales. Extensive\nexperiments demonstrate that Fleming-VL achieves state-of-the-art performance\nacross multiple benchmarks, including medical VQA, video QA, and 3D medical\nimage understanding. We publicly release Fleming-VL to promote transparent,\nreproducible, and auditable progress in medical AI.", "AI": {"tldr": "Fleming-VL is a unified end-to-end medical multimodal LLM that uses data-centric strategies\u2014long-context pretraining, rare medical data fine-tuning (including videos and underrepresented 2D modalities), and expanded 3D/video evaluation\u2014to achieve state-of-the-art results on medical VQA, video QA, and 3D imaging, with public release.", "motivation": "Medical data are highly heterogeneous (2D images, 3D volumes, video) and have a large domain gap, making it hard to build a single unified MLLM for clinical use.", "method": "Three data-centric strategies: (1) scale pretraining with long-context data from natural and medical sources; (2) fine-tune with rare medical data, including holistic video analysis and underrepresented 2D modalities like ultrasound and dermoscopy; (3) expand evaluation to 3D volumetric and video benchmarks. Optimized via supervised fine-tuning (SFT) and group relative policy optimization (GRPO) across multiple model scales.", "result": "Achieves state-of-the-art performance on medical VQA, video QA, and 3D medical image understanding across multiple benchmarks; Fleming-VL is publicly released to promote reproducible medical AI progress.", "conclusion": "A data-centric, unified medical MLLM like Fleming-VL can effectively handle heterogeneous medical modalities and enable transparent, reproducible advancement in medical AI, with broad clinical potential."}}
{"id": "2511.00700", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00700", "abs": "https://arxiv.org/abs/2511.00700", "authors": ["Penghang Liu", "Haibei Zhu", "Eleonora Kreacic", "Svitlana Vyetrenko"], "title": "Privacy-Aware Time Series Synthesis via Public Knowledge Distillation", "comment": "Published on Transactions on Machine Learning Research (TMLR)", "summary": "Sharing sensitive time series data in domains such as finance, healthcare,\nand energy consumption, such as patient records or investment accounts, is\noften restricted due to privacy concerns. Privacy-aware synthetic time series\ngeneration addresses this challenge by enforcing noise during training,\ninherently introducing a trade-off between privacy and utility. In many cases,\nsensitive sequences is correlated with publicly available, non-sensitive\ncontextual metadata (e.g., household electricity consumption may be influenced\nby weather conditions and electricity prices). However, existing privacy-aware\ndata generation methods often overlook this opportunity, resulting in\nsuboptimal privacy-utility trade-offs. In this paper, we present Pub2Priv, a\nnovel framework for generating private time series data by leveraging\nheterogeneous public knowledge. Our model employs a self-attention mechanism to\nencode public data into temporal and feature embeddings, which serve as\nconditional inputs for a diffusion model to generate synthetic private\nsequences. Additionally, we introduce a practical metric to assess privacy by\nevaluating the identifiability of the synthetic data. Experimental results show\nthat Pub2Priv consistently outperforms state-of-the-art benchmarks in improving\nthe privacy-utility trade-off across finance, energy, and commodity trading\ndomains.", "AI": {"tldr": "Pub2Priv uses public contextual knowledge to condition diffusion-based time-series generation, improving privacy-utility trade-offs while introducing a practical identifiability privacy metric.", "motivation": "Sharing sensitive time series is restricted by privacy. Public context (e.g., weather, prices) can influence sensitive data and is underutilized by current privacy-aware generation methods, leading to suboptimal privacy-utility balance.", "method": "A self-attention module encodes heterogeneous public data into temporal and feature embeddings, which condition a diffusion model to generate private synthetic sequences. A practical identifiability-based privacy metric is introduced.", "result": "Pub2Priv consistently outperforms state-of-the-art benchmarks in privacy-utility trade-offs across finance, energy, and commodity trading domains.", "conclusion": "Leveraging public contextual knowledge within a conditional diffusion framework yields better privacy-utility trade-offs for time series data; a practical privacy metric enhances evaluation and applicability."}}
{"id": "2511.00925", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00925", "abs": "https://arxiv.org/abs/2511.00925", "authors": ["Hanwen Su", "Ge Song", "Jiyan Wang", "Yuanbo Zhu"], "title": "Dynamic Multi-level Weighted Alignment Network for Zero-shot Sketch-based Image Retrieval", "comment": null, "summary": "The problem of zero-shot sketch-based image retrieval (ZS-SBIR) has achieved\nincreasing attention due to its wide applications, e.g. e-commerce. Despite\nprogress made in this field, previous works suffer from using imbalanced\nsamples of modalities and inconsistent low-quality information during training,\nresulting in sub-optimal performance. Therefore, in this paper, we introduce an\napproach called Dynamic Multi-level Weighted Alignment Network for ZS-SBIR. It\nconsists of three components: (i) a Uni-modal Feature Extraction Module that\nincludes a CLIP text encoder and a ViT for extracting textual and visual\ntokens, (ii) a Cross-modal Multi-level Weighting Module that produces an\nalignment weight list by the local and global aggregation blocks to measure the\naligning quality of sketch and image samples, (iii) a Weighted Quadruplet Loss\nModule aiming to improve the balance of domains in the triplet loss.\nExperiments on three benchmark datasets, i.e., Sketchy, TU-Berlin, and\nQuickDraw, show our method delivers superior performances over the\nstate-of-the-art ZS-SBIR methods.", "AI": {"tldr": "Dynamic Multi-level Weighted Alignment Network for zero-shot sketch-based image retrieval (ZS-SBIR) using uni-modal feature extraction, cross-modal weighting, and weighted quadruplet loss to improve balance; achieves state-of-the-art on Sketchy, TU-Berlin, QuickDraw.", "motivation": "ZS-SBIR suffers from imbalanced modality samples and inconsistent training information, leading to sub-optimal retrieval performance. There is a need to improve cross-modal alignment quality and balance domain contributions during training.", "method": "Three components: (i) Uni-modal Feature Extraction Module with a CLIP text encoder and ViT to extract textual and visual tokens; (ii) Cross-modal Multi-level Weighting Module producing an alignment weight list via local and global aggregation blocks to measure sketch\u2013image alignment quality; (iii) Weighted Quadruplet Loss Module to balance domain contributions within the triplet-based loss.", "result": "Empirical evaluation on Sketchy, TU-Berlin, and QuickDraw datasets shows the proposed method delivers superior performance compared with state-of-the-art ZS-SBIR methods.", "conclusion": "The Dynamic Multi-level Weighted Alignment Network improves ZS-SBIR by addressing modality imbalance and training information quality through weighted cross-modal alignment and a weighted quadruplet loss, achieving better results on standard benchmarks."}}
{"id": "2511.00704", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00704", "abs": "https://arxiv.org/abs/2511.00704", "authors": ["Morgan Lee", "Artem Frenk", "Eamon Worden", "Karish Gupta", "Thinh Pham", "Ethan Croteau", "Neil Heffernan"], "title": "Investigating the Robustness of Knowledge Tracing Models in the Presence of Student Concept Drift", "comment": "10 pages, 6 figures", "summary": "Knowledge Tracing (KT) has been an established problem in the educational\ndata mining field for decades, and it is commonly assumed that the underlying\nlearning process be- ing modeled remains static. Given the ever-changing land-\nscape of online learning platforms (OLPs), we investigate how concept drift and\nchanging student populations can im- pact student behavior within an OLP\nthrough testing model performance both within a single academic year and across\nmultiple academic years. Four well-studied KT models were applied to five\nacademic years of data to assess how suscep- tible KT models are to concept\ndrift. Through our analysis, we find that all four families of KT models can\nexhibit de- graded performance, Bayesian Knowledge Tracing (BKT) remains the\nmost stable KT model when applied to newer data, while more complex, attention\nbased models lose pre- dictive power significantly faster. To foster more\nlongitu- dinal evaluations of KT models, the data used to conduct our analysis\nis available at https://osf.io/hvfn9/?view_\nonly=b936c63dfdae4b0b987a2f0d4038f72a", "AI": {"tldr": "Knowledge Tracing models degrade under concept drift across academic years; Bayesian Knowledge Tracing (BKT) remains the most stable, while attention-based models lose predictive power faster; advocates for longitudinal evaluation with released dataset.", "motivation": "To test the common assumption that the KT learning process is static by examining how concept drift and shifting student populations affect model performance over time.", "method": "Apply four KT model families to five academic years of data, evaluating performance both within a single year and across years to assess susceptibility to concept drift.", "result": "All four KT model families exhibit degraded performance over time; BKT is the most stable on newer data, while more complex, attention-based models lose predictive power more quickly; cross-year generalization is limited.", "conclusion": "Encourage longitudinal KT benchmarks and reporting; share the dataset for replication and further drift-aware evaluations; future work should account for non-stationarity in KT modeling."}}
{"id": "2511.00956", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00956", "abs": "https://arxiv.org/abs/2511.00956", "authors": ["Liuzhuozheng Li", "Yue Gong", "Shanyuan Liu", "Bo Cheng", "Yuhang Ma", "Liebucha Wu", "Dengyang Jiang", "Zanyi Wang", "Dawei Leng", "Yuhui Yin"], "title": "EVTAR: End-to-End Try on with Additional Unpaired Visual Reference", "comment": null, "summary": "We propose EVTAR, an End-to-End Virtual Try-on model with Additional\nReference, that directly fits the target garment onto the person image while\nincorporating reference images to enhance try-on accuracy. Most existing\nvirtual try-on approaches rely on complex inputs such as agnostic person\nimages, human pose, densepose, or body keypoints, making them labor-intensive\nand impractical for real-world applications. In contrast, EVTAR adopts a\ntwo-stage training strategy, enabling simple inference with only the source\nimage and the target garment inputs. Our model generates try-on results without\nmasks, densepose, or segmentation maps. Moreover, EVTAR leverages additional\nreference images of different individuals wearing the same clothes to preserve\ngarment texture and fine-grained details better. This mechanism is analogous to\nhow humans consider reference models when choosing outfits, thereby simulating\na more realistic and high-quality dressing effect. We enrich the training data\nwith supplementary references and unpaired person images to support these\ncapabilities. We evaluate EVTAR on two widely used benchmarks and diverse\ntasks, and the results consistently validate the effectiveness of our approach.", "AI": {"tldr": "EVTAR is an end-to-end virtual try-on model that uses target garments with additional reference images to preserve texture, enabling simple inference using only the source image and garment input and avoiding masks, densepose, or segmentation maps.", "motivation": "Reduce reliance on heavy, labor-intensive inputs (pose, densepose, segmentation) while achieving higher-quality, texture-preserving try-on that works in realistic settings.", "method": "Two-stage training. The model fits the target garment directly onto the source image, uses additional reference images of different people wearing the same clothes to preserve garment texture and fine details, and trains with supplementary references and unpaired person images. No masks, densepose, or segmentation maps needed.", "result": "Evaluations on two widely used benchmarks across diverse tasks show the approach consistently improves try-on quality and texture preservation, validating the effectiveness of incorporating reference images.", "conclusion": "EVTAR delivers end-to-end virtual try-on with added references, offering simpler inference, better garment texture preservation, and realistic dressing effects suitable for real-world applications."}}
{"id": "2511.00711", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00711", "abs": "https://arxiv.org/abs/2511.00711", "authors": ["Nardeep Kumar", "Arun Kanwar"], "title": "TRISKELION-1: Unified Descriptive-Predictive-Generative AI", "comment": "12 pages, 18 figures, submitted to arXiv (2025)", "summary": "TRISKELION-1 is a unified descriptive-predictive-generative architecture that\nintegrates statistical, mechanistic, and generative reasoning within a single\nencoder-decoder framework. The model demonstrates how descriptive\nrepresentation learning, predictive inference, and generative synthesis can be\njointly optimized using variational objectives. Experiments on MNIST validate\nthat descriptive reconstruction, predictive classification, and generative\nsampling can coexist stably within one model. The framework provides a\nblueprint toward universal intelligence architectures that connect\ninterpretability, accuracy, and creativity.", "AI": {"tldr": "TRISKELION-1 is a unified descriptive-predictive-generative model that jointly optimizes descriptive reconstruction, predictive classification, and generative sampling within a single encoder-decoder using variational objectives; validated on MNIST; suggests a blueprint for universal intelligent architectures.", "motivation": "to bridge interpretability, accuracy, and creativity by integrating descriptive, predictive, and generative reasoning in one architecture.", "method": "single encoder-decoder framework trained with a joint variational objective that combines descriptive reconstruction, predictive inference (classification), and generative sampling; empirical evaluation on MNIST.", "result": "descriptive reconstruction, predictive classification, and generative sampling coexist stably within one model; MNIST demonstrates feasibility.", "conclusion": "proposes a blueprint toward universal intelligence architectures that connect interpretability, accuracy, and creativity; potential for broader applicability beyond MNIST."}}
{"id": "2511.00962", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00962", "abs": "https://arxiv.org/abs/2511.00962", "authors": ["Dongheng Lin", "Mengxue Qu", "Kunyang Han", "Jianbo Jiao", "Xiaojie Jin", "Yunchao Wei"], "title": "A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis", "comment": "NeurIPS 2025 poster", "summary": "Most video-anomaly research stops at frame-wise detection, offering little\ninsight into why an event is abnormal, typically outputting only frame-wise\nanomaly scores without spatial or semantic context. Recent video anomaly\nlocalization and video anomaly understanding methods improve explainability but\nremain data-dependent and task-specific. We propose a unified reasoning\nframework that bridges the gap between temporal detection, spatial\nlocalization, and textual explanation. Our approach is built upon a chained\ntest-time reasoning process that sequentially connects these tasks, enabling\nholistic zero-shot anomaly analysis without any additional training.\nSpecifically, our approach leverages intra-task reasoning to refine temporal\ndetections and inter-task chaining for spatial and semantic understanding,\nyielding improved interpretability and generalization in a fully zero-shot\nmanner. Without any additional data or gradients, our method achieves\nstate-of-the-art zero-shot performance across multiple video anomaly detection,\nlocalization, and explanation benchmarks. The results demonstrate that careful\nprompt design with task-wise chaining can unlock the reasoning power of\nfoundation models, enabling practical, interpretable video anomaly analysis in\na fully zero-shot manner. Project Page:\nhttps://rathgrith.github.io/Unified_Frame_VAA/.", "AI": {"tldr": "A unified zero-shot framework chains temporal, spatial, and textual reasoning for video anomaly analysis, achieving state-of-the-art zero-shot results without training.", "motivation": "To address the lack of explainability and generalization in existing video anomaly methods, which typically output frame-level scores or task-specific results without rich context.", "method": "Chained test-time reasoning that sequentially connects temporal detection, spatial localization, and textual explanation. Intra-task refinement of temporal detections and inter-task chaining for spatial/semantic understanding using prompt design, with no gradient updates or additional data.", "result": "Achieves state-of-the-art zero-shot performance across multiple video anomaly detection, localization, and explanation benchmarks, with improved interpretability and generalization.", "conclusion": "Prompt-based task chaining unlocks foundation-model reasoning for holistic, interpretable video anomaly analysis in a fully zero-shot manner; promising for practical deployment without extra data or training."}}
{"id": "2511.00716", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00716", "abs": "https://arxiv.org/abs/2511.00716", "authors": ["Rama Kassoumeh", "David R\u00fcgamer", "Henning Oppel"], "title": "Enhancing Heavy Rain Nowcasting with Multimodal Data: Integrating Radar and Satellite Observations", "comment": "accepted to ICMLA 2025", "summary": "The increasing frequency of heavy rainfall events, which are a major cause of\nurban flooding, underscores the urgent need for accurate precipitation\nforecasting - particularly in urban areas where localized events often go\nundetected by ground-based sensors. In Germany, only 17.3% of hourly heavy rain\nevents between 2001 and 2018 were recorded by rain gauges, highlighting the\nlimitations of traditional monitoring systems. Radar data are another source\nthat effectively tracks ongoing precipitation; however, forecasting the\ndevelopment of heavy rain using radar alone remains challenging due to the\nbrief and unpredictable nature of such events. Our focus is on evaluating the\neffectiveness of fusing satellite and radar data for nowcasting. We develop a\nmultimodal nowcasting model that combines both radar and satellite imagery for\npredicting precipitation at lead times of 5, 15, and 30 minutes. We demonstrate\nthat this multimodal strategy significantly outperforms radar-only approaches.\nExperimental results show that integrating satellite data improves prediction\naccuracy, particularly for intense precipitation. The proposed model increases\nthe Critical Success Index for heavy rain by 4% and for violent rain by 3% at a\n5-minute lead time. Moreover, it maintains higher predictive skill at longer\nlead times, where radar-only performance declines. A qualitative analysis of\nthe severe flooding event in the state of North Rhine-Westphalia, Germany in\n2021 further illustrates the superior performance of the multimodal model.\nUnlike the radar-only model, which captures general precipitation patterns, the\nmultimodal model yields more detailed and accurate forecasts for regions\naffected by heavy rain. This improved precision enables timely, reliable,\nlife-saving warnings. Implementation available at\nhttps://github.com/RamaKassoumeh/Multimodal_heavy_rain", "AI": {"tldr": "Multimodal fusion of radar and satellite imagery improves nowcasting of heavy rainfall; outperforms radar-only methods for 5, 15, 30 min lead times, with CSI gains of 4% (heavy) and 3% (violent) at 5 min; effective for longer lead times and illustrates NRW 2021 event.", "motivation": "Urban flooding risk and limitations of rain gauges and radar-only nowcasting in Germany; need for accurate, short-term precipitation forecasts.", "method": "Develop a multimodal nowcasting model combining radar and satellite imagery to predict precipitation at 5, 15, 30 min lead times; quantitative evaluation against radar-only baseline; qualitative case study of NRW 2021 event; GitHub implementation.", "result": "Significant performance gains over radar-only, especially for intense precipitation; CSI improvements 4% for heavy rain and 3% for violent rain at 5-min lead; better skill at longer lead times; more detailed forecasts for heavy rain regions in NRW 2021.", "conclusion": "Multimodal data fusion enhances nowcasting accuracy and can enable timely warnings; provides a practical implementation resource (GitHub) for real-time flood risk management."}}
{"id": "2511.00981", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00981", "abs": "https://arxiv.org/abs/2511.00981", "authors": ["Suzhong Fu", "Rui Sun", "Xuan Ding", "Jingqi Dong", "Yiming Yang", "Yao Zhu", "Min Chang Jordan Ren", "Delin Deng", "Angelica Aviles-Rivero", "Shuguang Cui", "Zhen Li"], "title": "VesSAM: Efficient Multi-Prompting for Segmenting Complex Vessel", "comment": null, "summary": "Accurate vessel segmentation is critical for clinical applications such as\ndisease diagnosis and surgical planning, yet remains challenging due to thin,\nbranching structures and low texture contrast. While foundation models like the\nSegment Anything Model (SAM) have shown promise in generic segmentation, they\nperform sub-optimally on vascular structures. In this work, we present VesSAM,\na powerful and efficient framework tailored for 2D vessel segmentation. VesSAM\nintegrates (1) a convolutional adapter to enhance local texture features, (2) a\nmulti-prompt encoder that fuses anatomical prompts, including skeletons,\nbifurcation points, and segment midpoints, via hierarchical cross-attention,\nand (3) a lightweight mask decoder to reduce jagged artifacts. We also\nintroduce an automated pipeline to generate structured multi-prompt\nannotations, and curate a diverse benchmark dataset spanning 8 datasets across\n5 imaging modalities. Experimental results demonstrate that VesSAM consistently\noutperforms state-of-the-art PEFT-based SAM variants by over 10% Dice and 13%\nIoU, and achieves competitive performance compared to fully fine-tuned methods,\nwith significantly fewer parameters. VesSAM also generalizes well to\nout-of-distribution (OoD) settings, outperforming all baselines in average OoD\nDice and IoU.", "AI": {"tldr": "VesSAM proposes a domain-specific, PEFT-friendly framework for 2D vessel segmentation, improving accuracy and generalization with a convolutional adapter, a multi-prompt encoder using anatomical prompts, and a lightweight decoder; achieves state-of-the-art gains with fewer parameters.", "motivation": "Accurate vessel segmentation is hard due to thin, branching vessels and low texture; SAM underperforms on vascular structures; need anatomy-guided prompts and efficient adapters to improve segmentation performance.", "method": "Integrates (1) a convolutional adapter to enhance local texture; (2) a multi-prompt encoder combining skeletons, bifurcation points, and segment midpoints via hierarchical cross-attention; (3) a lightweight mask decoder to reduce jagged edges; plus an automated pipeline to generate structured multi-prompt annotations and a benchmark across 8 datasets and 5 modalities.", "result": "Outperforms state-of-the-art PEFT-based SAM variants by >10% Dice and >13% IoU; competitive with fully fine-tuned methods with far fewer parameters; shows strong OoD generalization, surpassing baselines on average OoD Dice and IoU.", "conclusion": "VesSAM is an effective and efficient framework for 2D vessel segmentation that leverages anatomy-aware prompts and adapters to deliver robust performance across datasets and modalities, with strong generalization capabilities."}}
{"id": "2511.00747", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00747", "abs": "https://arxiv.org/abs/2511.00747", "authors": ["Zixuan Ma", "Chenfeng Huang"], "title": "Effective Series Decomposition and Components Learning for Time Series Generation", "comment": "Accepted at IEEE International Conference on Data Mining (ICDM 2025).\n  Camera-ready version to appear", "summary": "Time series generation focuses on modeling the underlying data distribution\nand resampling to produce authentic time series data. Key components, such as\ntrend and seasonality, drive temporal fluctuations, yet many existing\napproaches fail to employ interpretative decomposition methods, limiting their\nability to synthesize meaningful trend and seasonal patterns. To address this\ngap, we introduce Seasonal-Trend Diffusion (STDiffusion), a novel framework for\nmultivariate time series generation that integrates diffusion probabilistic\nmodels with advanced learnable series decomposition techniques, enhancing the\ninterpretability of the generation process. Our approach separates the trend\nand seasonal learning into distinct blocks: a Multi-Layer Perceptron (MLP)\nstructure captures the trend, while adaptive wavelet distillation facilitates\neffective multi-resolution learning of seasonal components. This decomposition\nimproves the interpretability of the model on multiple scales. In addition, we\ndesigned a comprehensive correction mechanism aimed at ensuring that the\ngenerated components exhibit a high degree of internal consistency and preserve\nmeaningful interrelationships with one another. Our empirical studies on eight\nreal-world datasets demonstrate that STDiffusion achieves state-of-the-art\nperformance in time series generation tasks. Furthermore, we extend the model's\napplication to multi-window long-sequence time series generation, which\ndelivered reliable results and highlighted its robustness and versatility.", "AI": {"tldr": "STDiffusion combines diffusion models with interpretable trend/seasonality decomposition to generate multivariate time series with high fidelity and interpretability, including a correction mechanism and support for long-sequence/multi-window generation.", "motivation": "Many existing time series generators lack interpretable decomposition to separate trend and seasonal patterns, limiting meaningful synthesis and inter-component relationships.", "method": "Use diffusion probabilistic models with a dedicated decomposition architecture: an MLP-based trend learner and adaptive wavelet distillation for seasonal components; a consistency-correction mechanism; supports multi-window long-sequence generation.", "result": "Eight real-world datasets show state-of-the-art generation performance; demonstrates robustness and versatility in multi-window long-sequence tasks.", "conclusion": "STDiffusion improves interpretability and generation quality in multivariate time series generation and suggests a general approach to combining diffusion models with interpretable decomposition for temporal data."}}
{"id": "2511.00997", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00997", "abs": "https://arxiv.org/abs/2511.00997", "authors": ["Chang Nie", "Tianchen Deng", "Zhe Liu", "Hesheng Wang"], "title": "MID: A Self-supervised Multimodal Iterative Denoising Framework", "comment": null, "summary": "Data denoising is a persistent challenge across scientific and engineering\ndomains. Real-world data is frequently corrupted by complex, non-linear noise,\nrendering traditional rule-based denoising methods inadequate. To overcome\nthese obstacles, we propose a novel self-supervised multimodal iterative\ndenoising (MID) framework. MID models the collected noisy data as a state\nwithin a continuous process of non-linear noise accumulation. By iteratively\nintroducing further noise, MID learns two neural networks: one to estimate the\ncurrent noise step and another to predict and subtract the corresponding noise\nincrement. For complex non-linear contamination, MID employs a first-order\nTaylor expansion to locally linearize the noise process, enabling effective\niterative removal. Crucially, MID does not require paired clean-noisy datasets,\nas it learns noise characteristics directly from the noisy inputs. Experiments\nacross four classic computer vision tasks demonstrate MID's robustness,\nadaptability, and consistent state-of-the-art performance. Moreover, MID\nexhibits strong performance and adaptability in tasks within the biomedical and\nbioinformatics domains.", "AI": {"tldr": "A self-supervised, multimodal iterative denoising (MID) framework that learns to denoise complex non-linear noise without clean data by modeling noise as an iterative process and using two networks to estimate the noise state and the increment; achieves SOTA on multiple CV tasks and shows promise in biomedical domains.", "motivation": "Real-world data are often corrupted by complex, non-linear noise, which defeats rule-based denoising and requires clean data for supervised methods; a self-supervised approach that learns noise characteristics directly from noisy inputs is needed.", "method": "Model data as a state in a non-linear noise accumulation process. Iteratively add noise and train two neural networks: one to estimate the current noise step, and another to predict/subtract the corresponding noise increment. Use a first-order Taylor expansion to locally linearize the non-linear noise process. The framework learns from noisy inputs without requiring paired clean data and is multimodal.", "result": "Demonstrates robustness, adaptability, and state-of-the-art performance across four classic computer vision tasks, with strong performance and adaptability in biomedical and bioinformatics tasks.", "conclusion": "MID provides a novel, self-supervised, multimodal denoising framework capable of handling complex non-linear noise across domains without clean data, via iterative noise modeling and local linearization, showing broad applicability."}}
{"id": "2511.00792", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.00792", "abs": "https://arxiv.org/abs/2511.00792", "authors": ["Akshay Sai Banderwaar", "Abhishek Gupta"], "title": "Fast PINN Eigensolvers via Biconvex Reformulation", "comment": "7 pages, 3 figures, Machine Learning and the Physical Sciences\n  Workshop NeurIPS 2025", "summary": "Eigenvalue problems have a distinctive forward-inverse structure and are\nfundamental to characterizing a system's thermal response, stability, and\nnatural modes. Physics-Informed Neural Networks (PINNs) offer a mesh-free\nalternative for solving such problems but are often orders of magnitude slower\nthan classical numerical schemes. In this paper, we introduce a reformulated\nPINN approach that casts the search for eigenpairs as a biconvex optimization\nproblem, enabling fast and provably convergent alternating convex search (ACS)\nover eigenvalues and eigenfunctions using analytically optimal updates.\nNumerical experiments show that PINN-ACS attains high accuracy with convergence\nspeeds up to 500$\\times$ faster than gradient-based PINN training. We release\nour codes at https://github.com/NeurIPS-ML4PS-2025/PINN_ACS_CODES.", "AI": {"tldr": "A reformulated PINN framework (PINN-ACS) for eigenvalue problems casts eigenpair search as a biconvex optimization solved by alternating convex search with analytically optimal updates, yielding up to 500x speedups over gradient-based PINNs and publicly releasing code.", "motivation": "Eigenvalue problems have a forward-inverse structure and are essential for understanding thermal response, stability, and natural modes. Traditional PINNs are accurate but slow; there is a need for a fast, mesh-free, convergent method to compute eigenpairs.", "method": "Reformulate the eigenpair search as a biconvex optimization problem and apply alternating convex search (ACS) with analytically optimal updates for eigenvalues and eigenfunctions, enabling fast convergence and provable guarantees.", "result": "PINN-ACS achieves high accuracy with convergence speeds up to 500\u00d7 faster than gradient-based PINN training in numerical experiments.", "conclusion": "The proposed PINN-ACS provides a fast, provably convergent alternative to standard PINNs for eigenvalue problems, broadening the practicality of PINNs in spectral analysis; code is released for replication."}}
{"id": "2511.01000", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01000", "abs": "https://arxiv.org/abs/2511.01000", "authors": ["Hassan Ugail", "Ismail Lujain Jaleel"], "title": "Integrating Visual and X-Ray Machine Learning Features in the Study of Paintings by Goya", "comment": null, "summary": "Art authentication of Francisco Goya's works presents complex computational\nchallenges due to his heterogeneous stylistic evolution and extensive\nhistorical patterns of forgery. We introduce a novel multimodal machine\nlearning framework that applies identical feature extraction techniques to both\nvisual and X-ray radiographic images of Goya paintings. The unified feature\nextraction pipeline incorporates Grey-Level Co-occurrence Matrix descriptors,\nLocal Binary Patterns, entropy measures, energy calculations, and colour\ndistribution analysis applied consistently across both imaging modalities. The\nextracted features from both visual and X-ray images are processed through an\noptimised One-Class Support Vector Machine with hyperparameter tuning. Using a\ndataset of 24 authenticated Goya paintings with corresponding X-ray images,\nsplit into an 80/20 train-test configuration with 10-fold cross-validation, the\nframework achieves 97.8% classification accuracy with a 0.022 false positive\nrate. Case study analysis of ``Un Gigante'' demonstrates the practical efficacy\nof our pipeline, achieving 92.3% authentication confidence through unified\nmultimodal feature analysis. Our results indicate substantial performance\nimprovement over single-modal approaches, establishing the effectiveness of\napplying identical computational methods to both visual and radiographic\nimagery in art authentication applications.", "AI": {"tldr": "A multimodal, identical-feature pipeline for Goya authentication uses visual and X-ray images with GLCM/LBP/entropy/energy/color features fed into an optimized One-Class SVM; on a small dataset (n=24), it achieves 97.8% accuracy and low FPR, with a case study achieving 92.3% confidence, outperforming single-modal methods.", "motivation": "Goya authentication is hampered by heterogeneous stylistic evolution and forgery patterns. Relying on a single imaging modality may miss complementary cues. A unified multimodal approach aims to leverage information from both visual and radiographic images to improve robustness and accuracy in authentication.", "method": "Apply identical feature extraction across both visual and X-ray images: Grey-Level Co-occurrence Matrix descriptors, Local Binary Patterns, entropy, energy, and colour distribution. Concatenate or jointly process these features and train an optimized One-Class SVM with hyperparameter tuning. Dataset: 24 authenticated Goya paintings with corresponding X-ray images; evaluation via an 80/20 train-test split and 10-fold cross-validation. Case study on Un Gigante to illustrate practical efficacy.", "result": "High performance with 97.8% classification accuracy and 0.022 false positive rate on the dataset. Case study reports 92.3% authentication confidence for Un Gigante. Claimed substantial improvement over single-modal approaches.", "conclusion": "The study suggests that applying identical computational methods to both visual and radiographic modalities yields meaningful gains in art authentication, supporting the value of unified multimodal feature analysis. However, the small sample size and potential generalization concerns warrant cautious interpretation and further validation."}}
{"id": "2511.00794", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00794", "abs": "https://arxiv.org/abs/2511.00794", "authors": ["Yan Sun", "Jia Guo", "Stanley Kok", "Zihao Wang", "Zujie Wen", "Zhiqiang Zhang"], "title": "Efficient Reinforcement Learning for Large Language Models with Intrinsic Exploration", "comment": null, "summary": "Reinforcement learning with verifiable rewards (RLVR) has improved the\nreasoning ability of large language models, yet training remains costly because\nmany rollouts contribute little to optimization, considering the amount of\ncomputation required. This study investigates how simply leveraging intrinsic\ndata properties, almost free benefit during training, can improve data\nefficiency for RLVR. We propose PREPO with two complementary components. First,\nwe adopt prompt perplexity as an indicator of model adaptability in learning,\nenabling the model to progress from well-understood contexts to more\nchallenging ones. Second, we amplify the discrepancy among the rollouts by\ndifferentiating their relative entropy, and prioritize sequences that exhibit a\nhigher degree of exploration. Together, these mechanisms reduce rollout demand\nwhile preserving competitive performance. On the Qwen and Llama models, PREPO\nachieves effective results on mathematical reasoning benchmarks with up to 3\ntimes fewer rollouts than the baselines. Beyond empirical gains, we provide\ntheoretical and in-depth analyses explaining the underlying rationale of our\nmethod to improve the data efficiency of RLVR.", "AI": {"tldr": "PREPO improves data efficiency in RLVR by using prompt perplexity to guide learning from easy to hard contexts and by boosting rollouts diversity via relative-entropy-based prioritization; achieves up to 3x fewer rollouts on Qwen/Llama for math reasoning with competitive performance and theoretical insights.", "motivation": "RLVR training is computation-heavy because many rollouts contribute little to optimization. The paper seeks data-efficient improvements by exploiting intrinsic data properties during training.", "method": "Introduce PREPO: (1) prompt perplexity as an adaptability indicator to schedule progression from well-understood contexts to harder ones; (2) differentiate rollouts by their relative entropy to amplify exploration discrepancy and prioritize highly exploratory sequences.", "result": "On Qwen and Llama models, PREPO yields effective performance on mathematical reasoning benchmarks with up to 3x fewer rollouts than baselines; provides theoretical and in-depth explanations of data-efficiency improvements.", "conclusion": "PREPO reduces rollout requirements while preserving competitive performance in RLVR, offering a principled, data-efficient approach with theoretical grounding."}}
{"id": "2511.01013", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01013", "abs": "https://arxiv.org/abs/2511.01013", "authors": ["Mohammad Amanour Rahman"], "title": "HyFormer-Net: A Synergistic CNN-Transformer with Interpretable Multi-Scale Fusion for Breast Lesion Segmentation and Classification in Ultrasound Images", "comment": "This manuscript has been submitted to Informatics in Medicine\n  Unlocked", "summary": "B-mode ultrasound for breast cancer diagnosis faces challenges: speckle,\noperator dependency, and indistinct boundaries. Existing deep learning suffers\nfrom single-task learning, architectural constraints (CNNs lack global context,\nTransformers local features), and black-box decision-making. These gaps hinder\nclinical adoption.\n  We propose HyFormer-Net, a hybrid CNN-Transformer for simultaneous\nsegmentation and classification with intrinsic interpretability. Its\ndual-branch encoder integrates EfficientNet-B3 and Swin Transformer via\nmulti-scale hierarchical fusion blocks. An attention-gated decoder provides\nprecision and explainability. We introduce dual-pipeline interpretability: (1)\nintrinsic attention validation with quantitative IoU verification (mean: 0.86),\nand (2) Grad-CAM for classification reasoning.\n  On the BUSI dataset, HyFormer-Net achieves Dice Score 0.761 +/- 0.072 and\naccuracy 93.2%, outperforming U-Net, Attention U-Net, and TransUNet. Malignant\nRecall of 92.1 +/- 2.2% ensures minimal false negatives. Ensemble modeling\nyields exceptional Dice 90.2%, accuracy 99.5%, and perfect 100% Malignant\nRecall, eliminating false negatives. Ablation studies confirm multi-scale\nfusion contributes +16.8% Dice and attention gates add +5.9%.\n  Crucially, we conduct the first cross-dataset generalization study for hybrid\nCNN-Transformers in breast ultrasound. Zero-shot transfer fails (Dice: 0.058),\nconfirming domain shift. However, progressive fine-tuning with only 10%\ntarget-domain data (68 images) recovers 92.5% performance. With 50% data, our\nmodel achieves 77.3% Dice, exceeding source-domain performance (76.1%) and\ndemonstrating true generalization.", "AI": {"tldr": "A hybrid CNN-Transformer (HyFormer-Net) for joint segmentation and classification of breast ultrasound, achieving strong performance and interpretable outputs, with a notably limited cross-dataset generalization that improves via progressive fine-tuning on target-domain data.", "motivation": "Address challenges in breast ultrasound imaging\u2014speckle, operator dependency, indistinct boundaries\u2014by combining global context modeling (Transformers) with local feature extraction (CNNs) and providing intrinsic interpretability.", "method": "A dual-branch encoder (EfficientNet-B3 + Swin Transformer) with multi-scale hierarchical fusion blocks feeds an attention-gated decoder. Two interpretability streams: intrinsic attention validation (IoU, mean 0.86) and Grad-CAM for classification reasoning. Includes ensemble modeling and ablation studies; assesses cross-dataset generalization with zero-shot and progressive fine-tuning on limited target-domain data.", "result": "On BUSI, Dice 0.761 \u00b10.072; accuracy 93.2%. Malignant recall 92.1 \u00b12.2%. Ensemble: Dice 90.2%, accuracy 99.5%, malignant recall 100%. Ablations: multi-scale fusion +16.8% Dice; attention gates +5.9%. Cross-dataset: zero-shot Dice 0.058; 10% target data yields 92.5% performance; 50% target data yields 77.3% Dice (exceeding source-domain 76.1%).", "conclusion": "First cross-dataset study for hybrid CNN-Transformers in breast ultrasound; domain shift exists; targeted fine-tuning with modest target-domain data can restore or surpass source-domain performance, supporting practical generalization and indicating interpretability through attention-based measures."}}
{"id": "2511.00797", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00797", "abs": "https://arxiv.org/abs/2511.00797", "authors": ["Wang Zixian"], "title": "Attention Saturation and Gradient Suppression at Inflection Layers: Diagnosing and Mitigating Bottlenecks in Transformer Adaptation", "comment": null, "summary": "Pre-trained Transformers often exhibit over-confidence in source patterns and\ndifficulty in forming new target-domain patterns during fine-tuning. We\nformalize the mechanism of output saturation leading to gradient suppression\nthrough standard cross-entropy and softmax analysis, showing that gradient\nsuppression at inflection layers confines adaptation to high-level\nrecombination of existing features while preventing low-level reconstruction.\nWe introduce a set of layer-wise diagnostic metrics -- attention entropy\n(saturation proxy), activation gradient norm, parameter gradient norm, and\nDelta-CKA under a shared PCA basis -- to identify inflection layers\ncharacterized by both low attention entropy and steep gradient decay. Building\non these findings, we propose a diagnose-first, inject-light fine-tuning\nstrategy: selectively inserting LoRA adapters at inflection layers to restore\nsuppressed backward signals with minimal parameter overhead. Experiments on\nBERT-base transfer from SST-2 to Rotten Tomatoes under under-trained and\nover-trained source regimes reveal that over-trained initialization benefits\nfrom inflection-layer LoRA injection, while under-trained initialization\nsuffers performance degradation. When base features are strong, unblocking\ninflection layers facilitates high-level compositional adaptation; when base\nfeatures are weak, full-pathway unblocking is required for low-level\nreconstruction, as supported by joint analysis of layer-wise activation\ngradients and Delta-CKA dynamics.", "AI": {"tldr": "The paper analyzes gradient saturation in Transformers during fine-tuning that confines adaptation to high-level feature recombination, proposes diagnostics to identify inflection layers, and introduces a diagnose-first, inject-light fine-tuning strategy using LoRA adapters at those layers. Empirical results on SST-2 to Rotten Tomatoes show initialization regime effects: over-trained benefits from inflection-layer LoRA, under-trained may degrade; unblocking strategies depend on base feature strength.", "motivation": "Pre-trained transformers often overfit to source-domain patterns and struggle to form target-domain patterns during fine-tuning. Understanding the saturation mechanism and selectively enabling gradient flow could improve cross-domain transfer with minimal parameter cost.", "method": "Formally analyze gradient saturation via cross-entropy and softmax to show gradient suppression at inflection layers; develop layer-wise diagnostics: attention entropy, activation gradient norm, parameter gradient norm, and Delta-CKA under a shared PCA basis to locate inflection layers with low entropy and steep gradient decay; propose diagnose-first, inject-light fine-tuning by inserting LoRA adapters at inflection layers; test on BERT-base transfer from SST-2 to Rotten Tomatoes under under-trained and over-trained source regimes.", "result": "Demonstrates that saturation confines adaptation to high-level recombination of existing features, while low-level reconstruction remains suppressed; inflection-layer LoRA injection can restore backward signals with minimal parameter cost; results show that over-trained initialization benefits from inflection-layer injection, whereas under-trained initialization may suffer; when base features are strong, unblocking inflection layers aids high-level adaptation; when base features are weak, full-pathway unblocking is needed; supported by analysis of layer-wise activation gradients and Delta-CKA dynamics.", "conclusion": "Inflection-layer targeted, lightweight LoRA fine-tuning shifts enable more effective cross-domain adaptation by selectively restoring backward signals at key layers, with effects depending on the strength of base features and initialization regime; the proposed diagnostics provide a practical mechanism to guide selective adapter placement."}}
{"id": "2511.01026", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01026", "abs": "https://arxiv.org/abs/2511.01026", "authors": ["JunXi Yuan"], "title": "FastBoost: Progressive Attention with Dynamic Scaling for Efficient Deep Learning", "comment": "17pages , 10figures , 12tables", "summary": "We present FastBoost, a parameter-efficient neural architecture that achieves\nstate-of-the-art performance on CIFAR benchmarks through a novel Dynamically\nScaled Progressive Attention (DSPA) mechanism. Our design establishes new\nefficiency frontiers with: CIFAR-10: 95.57% accuracy (0.85M parameters) and\n93.80% (0.37M parameters) CIFAR-100: 81.37% accuracy (0.92M parameters) and\n74.85% (0.44M parameters) The breakthrough stems from three fundamental\ninnovations in DSPA: (1) Adaptive Fusion: Learnt channel-spatial attention\nblending with dynamic weights. (2) Phase Scaling: Training-stage-aware\nintensity modulation (from 0.5 to 1.0). (3) Residual Adaptation: Self-optimized\nskip connections (gamma from 0.5 to 0.72). By integrating DSPA with enhanced\nMBConv blocks, FastBoost achieves a 2.1 times parameter reduction over\nMobileNetV3 while improving accuracy by +3.2 percentage points on CIFAR-10. The\narchitecture features dual attention pathways with real-time weight adjustment,\ncascaded refinement layers (increasing gradient flow by 12.7%), and a\nhardware-friendly design (0.28G FLOPs). This co-optimization of dynamic\nattention and efficient convolution operations demonstrates unprecedented\nparameter-accuracy trade-offs, enabling deployment in resource-constrained edge\ndevices without accuracy degradation.", "AI": {"tldr": "FastBoost introduces a parameter-efficient neural architecture using Dynamically Scaled Progressive Attention (DSPA) to achieve state-of-the-art CIFAR results with very few parameters and low FLOPs. It blends adaptive attention, train-stage scaling, and residual adaptation into enhanced MBConv blocks, yielding dual attention paths and cascaded refinements with real-time weight updates, enabling edge deployment without sacrificing accuracy.", "motivation": "To push the accuracy-parameter-FLOPs frontier on CIFAR datasets by designing a compact, dynamically adaptable attention mechanism that can be embedded into efficient convolutions for edge devices.", "method": "DSPA combines Adaptive Fusion (learned channel-spatial blending with dynamic weights), Phase Scaling (training-stage intensity modulation from 0.5 to 1.0), and Residual Adaptation (self-optimized skip connections with gamma from 0.5 to 0.72). It integrates DSPA with enhanced MBConv blocks, uses dual attention pathways with real-time weight adjustment, cascaded refinement layers to boost gradient flow, and a hardware-friendly design (0.28G FLOPs).", "result": "Achieves CIFAR-10: 95.57% accuracy with 0.85M parameters and 93.80% with 0.37M parameters; CIFAR-100: 81.37% accuracy with 0.92M parameters and 74.85% with 0.44M parameters. Claims 2.1x parameter reduction vs MobileNetV3 and +3.2 percentage points on CIFAR-10, with cascaded refinements improving gradient flow by 12.7%. Overall 0.28G FLOPs.", "conclusion": "The approach claims unprecedented parameter-accuracy trade-offs enabling edge deployment without accuracy degradation, via co-optimized dynamic attention and efficient convolution operations. It positions FastBoost as a new efficiency frontier on CIFAR benchmarks."}}
{"id": "2511.00804", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00804", "abs": "https://arxiv.org/abs/2511.00804", "authors": ["Abhiram Kusumba", "Maitreya Patel", "Kyle Min", "Changhoon Kim", "Chitta Baral", "Yezhou Yang"], "title": "EraseFlow: Learning Concept Erasure Policies via GFlowNet-Driven Alignment", "comment": "NeurIPS'25 Spotlight | Project page: https://eraseflow.github.io/", "summary": "Erasing harmful or proprietary concepts from powerful text to image\ngenerators is an emerging safety requirement, yet current \"concept erasure\"\ntechniques either collapse image quality, rely on brittle adversarial losses,\nor demand prohibitive retraining cycles. We trace these limitations to a myopic\nview of the denoising trajectories that govern diffusion based generation. We\nintroduce EraseFlow, the first framework that casts concept unlearning as\nexploration in the space of denoising paths and optimizes it with GFlowNets\nequipped with the trajectory balance objective. By sampling entire trajectories\nrather than single end states, EraseFlow learns a stochastic policy that steers\ngeneration away from target concepts while preserving the model's prior.\nEraseFlow eliminates the need for carefully crafted reward models and by doing\nthis, it generalizes effectively to unseen concepts and avoids hackable rewards\nwhile improving the performance. Extensive empirical results demonstrate that\nEraseFlow outperforms existing baselines and achieves an optimal trade off\nbetween performance and prior preservation.", "AI": {"tldr": "EraseFlow reframes concept erasure as exploring denoising trajectories in diffusion models, using GFlowNets with trajectory balance to sample full trajectories and learn a stochastic policy that removes target concepts while preserving prior knowledge, avoiding brittle rewards and retraining.", "motivation": "Current concept erasure approaches often degrade image quality, rely on brittle adversarial/reward losses, or require costly retraining. A more robust, generalizable method is needed that can erase harmful or proprietary concepts without harming the model's prior.", "method": "Cast unlearning as exploration in the space of diffusion denoising paths. Use Generative Flow Networks (GFlowNets) with trajectory balance to sample entire denoising trajectories, training a policy that steers generation away from target concepts while preserving priors. This avoids handcrafted rewards and retraining per concept.", "result": "Empirically, EraseFlow outperforms existing baselines, achieving a favorable trade-off between concept erasure and prior preservation, and generalizes to unseen concepts while avoiding hackable rewards.", "conclusion": "EraseFlow provides a novel, generalizable framework for concept unlearning that overcomes limitations of prior methods by treating trajectory spaces as the optimization domain and leveraging GFlowNets to balance exploration with prior preservation."}}
{"id": "2511.01079", "categories": ["cs.CV", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.01079", "abs": "https://arxiv.org/abs/2511.01079", "authors": ["Nikolay I. Kalmykov", "Razan Dibo", "Kaiyu Shen", "Xu Zhonghan", "Anh-Huy Phan", "Yipeng Liu", "Ivan Oseledets"], "title": "T-MLA: A Targeted Multiscale Log--Exponential Attack Framework for Neural Image Compression", "comment": "Submitted to Information Systems. Code will be released upon journal\n  publication", "summary": "Neural image compression (NIC) has become the state-of-the-art for\nrate-distortion performance, yet its security vulnerabilities remain\nsignificantly less understood than those of classifiers. Existing adversarial\nattacks on NICs are often naive adaptations of pixel-space methods, overlooking\nthe unique, structured nature of the compression pipeline. In this work, we\npropose a more advanced class of vulnerabilities by introducing T-MLA, the\nfirst targeted multiscale log--exponential attack framework. Our approach\ncrafts adversarial perturbations in the wavelet domain by directly targeting\nthe quality of the attacked and reconstructed images. This allows for a\nprincipled, offline attack where perturbations are strategically confined to\nspecific wavelet subbands, maximizing distortion while ensuring perceptual\nstealth. Extensive evaluation across multiple state-of-the-art NIC\narchitectures on standard image compression benchmarks reveals a large drop in\nreconstruction quality while the perturbations remain visually imperceptible.\nOur findings reveal a critical security flaw at the core of generative and\ncontent delivery pipelines.", "AI": {"tldr": "Introduces T-MLA, a targeted multiscale log-exponential attack in the wavelet domain for neural image compression (NIC). It degrades reconstruction quality while staying perceptually stealthy, exposing a security vulnerability in NIC pipelines.", "motivation": "Security vulnerabilities in neural image compression are underexplored compared to classifiers. Existing NIC attacks are often naive pixel-space methods that ignore the wavelet-based compression pipeline, necessitating principled, offline attacks that exploit wavelet subbands.", "method": "Develops a targeted multiscale log-exponential attack (T-MLA) that crafts adversarial perturbations directly in the wavelet domain. Perturbations are confined to selected wavelet subbands to maximize distortion of the attacked and reconstructed images while maintaining perceptual stealth, enabling offline, multi-scale optimization across layers of state-of-the-art NICs.", "result": "Across multiple state-of-the-art NIC architectures and standard image compression benchmarks, T-MLA causes a large drop in reconstruction quality with perturbations that remain visually imperceptible.", "conclusion": "Reveals a critical security flaw at the core of generative and content delivery pipelines and underscores the need for robust defenses and secure NIC designs."}}
{"id": "2511.00806", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00806", "abs": "https://arxiv.org/abs/2511.00806", "authors": ["Guangxi Wan", "Peng Zeng", "Xiaoting Dong", "Chunhe Song", "Shijie Cui", "Dong Li", "Qingwei Dong", "Yiyang Liu", "Hongfei Bai"], "title": "Logic-informed reinforcement learning for cross-domain optimization of large-scale cyber-physical systems", "comment": null, "summary": "Cyber-physical systems (CPS) require the joint optimization of discrete cyber\nactions and continuous physical parameters under stringent safety logic\nconstraints. However, existing hierarchical approaches often compromise global\noptimality, whereas reinforcement learning (RL) in hybrid action spaces often\nrelies on brittle reward penalties, masking, or shielding and struggles to\nguarantee constraint satisfaction. We present logic-informed reinforcement\nlearning (LIRL), which equips standard policy-gradient algorithms with\nprojection that maps a low-dimensional latent action onto the admissible hybrid\nmanifold defined on-the-fly by first-order logic. This guarantees feasibility\nof every exploratory step without penalty tuning. Experimental evaluations have\nbeen conducted across multiple scenarios, including industrial manufacturing,\nelectric vehicle charging stations, and traffic signal control, in all of which\nthe proposed method outperforms existing hierarchical optimization approaches.\nTaking a robotic reducer assembly system in industrial manufacturing as an\nexample, LIRL achieves a 36.47\\% to 44.33\\% reduction at most in the combined\nmakespan-energy objective compared to conventional industrial hierarchical\nscheduling methods. Meanwhile, it consistently maintains zero constraint\nviolations and significantly surpasses state-of-the-art hybrid-action\nreinforcement learning baselines. Thanks to its declarative logic-based\nconstraint formulation, the framework can be seamlessly transferred to other\ndomains such as smart transportation and smart grid, thereby paving the way for\nsafe and real-time optimization in large-scale CPS.", "AI": {"tldr": "A logic-informed RL (LIRL) approach projects a latent policy action onto a logic-defined, admissible hybrid action set, ensuring feasibility at every exploration step while using standard policy-gradient methods.", "motivation": "CPS require joint optimization of discrete cyber actions and continuous physical parameters under safety constraints. Existing hierarchical methods may hurt global optimality, and RL in hybrid spaces often relies on penalty/shielding that can fail to guarantee constraint satisfaction.", "method": "Introduce a projection step that maps latent actions to the admissible manifold defined by first-order logic, enabling feasible exploration without penalty tuning. Integrate with standard policy-gradient algorithms, and express constraints declaratively for transferability across domains.", "result": "Empirical evaluation across manufacturing, EV charging, and traffic control shows LIRL outperforms hierarchical optimization and state-of-the-art hybrid RL baselines. In robotic reducer assembly, combined makespan-energy reductions of 36.47\u201344.33%, with zero constraint violations.", "conclusion": "LIRL enables safe, real-time optimization in large-scale CPS and is transferable to domains like smart transportation and smart grids, offering robust feasibility without penalty tuning."}}
{"id": "2511.01082", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01082", "abs": "https://arxiv.org/abs/2511.01082", "authors": ["Narges Ghasemi", "Amir Ziashahabi", "Salman Avestimehr", "Cyrus Shahabi"], "title": "GeoToken: Hierarchical Geolocalization of Images via Next Token Prediction", "comment": "Accepted to IEEE International Conference on Data Mining (ICDM) 2025", "summary": "Image geolocalization, the task of determining an image's geographic origin,\nposes significant challenges, largely due to visual similarities across\ndisparate locations and the large search space. To address these issues, we\npropose a hierarchical sequence prediction approach inspired by how humans\nnarrow down locations from broad regions to specific addresses. Analogously,\nour model predicts geographic tokens hierarchically, first identifying a\ngeneral region and then sequentially refining predictions to increasingly\nprecise locations. Rather than relying on explicit semantic partitions, our\nmethod uses S2 cells, a nested, multiresolution global grid, and sequentially\npredicts finer-level cells conditioned on visual inputs and previous\npredictions. This procedure mirrors autoregressive text generation in large\nlanguage models. Much like in language modeling, final performance depends not\nonly on training but also on inference-time strategy. We investigate multiple\ntop-down traversal methods for autoregressive sampling, incorporating\ntechniques from test-time compute scaling used in language models.\nSpecifically, we integrate beam search and multi-sample inference while\nexploring various selection strategies to determine the final output. This\nenables the model to manage uncertainty by exploring multiple plausible paths\nthrough the hierarchy. We evaluate our method on the Im2GPS3k and YFCC4k\ndatasets against two distinct sets of baselines: those that operate without a\nMultimodal Large Language Model (MLLM) and those that leverage one. In the\nMLLM-free setting, our model surpasses other comparable baselines on nearly all\nmetrics, achieving state-of-the-art performance with accuracy gains of up to\n13.9%. When augmented with an MLLM, our model outperforms all baselines,\nsetting a new state-of-the-art across all metrics. The source code is available\nat https://github.com/NNargesNN/GeoToken.", "AI": {"tldr": "A hierarchical autoregressive geolocation model using S2 grid cells to predict location in coarse-to-fine tokens; uses top-down sampling with beam search and multi-sample inference; achieves state-of-the-art on Im2GPS3k and YFCC4k, with gains up to 13.9% without a Multimodal LLM and best results with MLLM; code released.", "motivation": "Addressing visual similarity across locations and large search space by narrowing down locations through a coarse-to-fine representation and autoregressive token prediction; exploring inference-time strategies to handle uncertainty.", "method": "Predict geographic tokens hierarchically via S2 cells conditioned on image and past predictions, without explicit semantic partitions; autoregressive sampling along a top-down hierarchy; integrate beam search and multi-sample inference; evaluate with and without MLLMs; compare against baselines.", "result": "State-of-the-art on Im2GPS3k and YFCC4k; accuracy gains up to 13.9% in the MLLM-free setting; with MLLM, surpasses all baselines across all metrics.", "conclusion": "The hierarchical autoregressive approach with explicit inference strategies is effective for image geolocalization and benefits from MLLMs; code released."}}
{"id": "2511.00811", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00811", "abs": "https://arxiv.org/abs/2511.00811", "authors": ["Runyu Lu", "Peng Zhang", "Ruochuan Shi", "Yuanheng Zhu", "Dongbin Zhao", "Yang Liu", "Dong Wang", "Cesare Alippi"], "title": "Equilibrium Policy Generalization: A Reinforcement Learning Framework for Cross-Graph Zero-Shot Generalization in Pursuit-Evasion Games", "comment": null, "summary": "Equilibrium learning in adversarial games is an important topic widely\nexamined in the fields of game theory and reinforcement learning (RL).\nPursuit-evasion game (PEG), as an important class of real-world games from the\nfields of robotics and security, requires exponential time to be accurately\nsolved. When the underlying graph structure varies, even the state-of-the-art\nRL methods require recomputation or at least fine-tuning, which can be\ntime-consuming and impair real-time applicability. This paper proposes an\nEquilibrium Policy Generalization (EPG) framework to effectively learn a\ngeneralized policy with robust cross-graph zero-shot performance. In the\ncontext of PEGs, our framework is generally applicable to both pursuer and\nevader sides in both no-exit and multi-exit scenarios. These two\ngeneralizability properties, to our knowledge, are the first to appear in this\ndomain. The core idea of the EPG framework is to train an RL policy across\ndifferent graph structures against the equilibrium policy for each single\ngraph. To construct an equilibrium oracle for single-graph policies, we present\na dynamic programming (DP) algorithm that provably generates pure-strategy Nash\nequilibrium with near-optimal time complexity. To guarantee scalability with\nrespect to pursuer number, we further extend DP and RL by designing a grouping\nmechanism and a sequence model for joint policy decomposition, respectively.\nExperimental results show that, using equilibrium guidance and a distance\nfeature proposed for cross-graph PEG training, the EPG framework guarantees\ndesirable zero-shot performance in various unseen real-world graphs. Besides,\nwhen trained under an equilibrium heuristic proposed for the graphs with exits,\nour generalized pursuer policy can even match the performance of the fine-tuned\npolicies from the state-of-the-art PEG methods.", "AI": {"tldr": "EPG learns a generalized equilibrium policy for pursuit-evasion games across varying graph structures, enabling zero-shot transfer and scalable policy decomposition via a DP-based equilibrium oracle, grouping, and sequence modeling.", "motivation": "Pursuit-evasion games are computationally expensive to solve and their optimal policies depend on graph structure; existing RL needs retraining or fine-tuning for new graphs, hindering real-time deployment. The work aims to enable cross-graph generalization and real-time applicability.", "method": "Train an RL policy across multiple graphs against the equilibrium policy for each graph. Build a DP-based equilibrium oracle to compute pure-strategy Nash equilibria for single-graph policies. Introduce a grouping mechanism to scale with the number of pursuers and a sequence model to decompose joint policies, enabling scalability. Use a distance feature to facilitate cross-graph transfer.", "result": "The framework achieves zero-shot generalization to unseen graphs for both pursuer and evader roles in no-exit and multi-exit PEGs. When using equilibrium guidance and graph-exit heuristics, the generalized pursuer policy can match fine-tuned policies from state-of-the-art PEG methods, demonstrating strong cross-graph robustness and scalability.", "conclusion": "EPG offers a generalizable equilibrium-learning approach for PEGs, delivering robust zero-shot transfer across graphs and scalability with respect to pursuer numbers, and can approach or match tuned baselines under certain heuristics."}}
{"id": "2511.01087", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01087", "abs": "https://arxiv.org/abs/2511.01087", "authors": ["Md. Abid Hasan Rafi", "Mst. Fatematuj Johora", "Pankaj Bhowmik"], "title": "SliceVision-F2I: A Synthetic Feature-to-Image Dataset for Visual Pattern Representation on Network Slices", "comment": null, "summary": "The emergence of 5G and 6G networks has established network slicing as a\nsignificant part of future service-oriented architectures, demanding refined\nidentification methods supported by robust datasets. The article presents\nSliceVision-F2I, a dataset of synthetic samples for studying feature\nvisualization in network slicing for next-generation networking systems. The\ndataset transforms multivariate Key Performance Indicator (KPI) vectors into\nvisual representations through four distinct encoding methods: physically\ninspired mappings, Perlin noise, neural wallpapering, and fractal branching.\nFor each encoding method, 30,000 samples are generated, each comprising a raw\nKPI vector and a corresponding RGB image at low-resolution pixels. The dataset\nsimulates realistic and noisy network conditions to reflect operational\nuncertainties and measurement imperfections. SliceVision-F2I is suitable for\ntasks involving visual learning, network state classification, anomaly\ndetection, and benchmarking of image-based machine learning techniques applied\nto network data. The dataset is publicly available and can be reused in various\nresearch contexts, including multivariate time series analysis, synthetic data\ngeneration, and feature-to-image transformations.", "AI": {"tldr": "A synthetic KPI-to-image dataset (SliceVision-F2I) with four encoding schemes to study feature visualization in network slicing, containing 30k samples per scheme and low-resolution RGB images, enabling visual ML tasks and benchmarking under realistic noise.", "motivation": "Network slicing requires precise identification methods and robust datasets. Visual feature representations can facilitate interpretation and ML on multivariate KPI data, bridging time-series analysis with image-based learning.", "method": "Four encoding pipelines transform multivariate KPI vectors into RGB images: physically inspired mappings, Perlin noise, neural wallpapering, and fractal branching. Each encoding yields 30,000 samples (raw KPI vector + low-res RGB image) under simulated noisy/network conditions to reflect practical uncertainties.", "result": "A publicly available, sizeable synthetic dataset (120,000 samples total) enabling visual learning, state classification, anomaly detection, and benchmarking of image-based ML on network data; supports diverse research such as time-series-to-image transformations and synthetic data generation.", "conclusion": "SliceVision-F2I provides a versatile resource for studying feature-to-image transformations in network slicing, supporting the development and benchmarking of image-based ML approaches for monitoring and managing next-generation networks."}}
{"id": "2511.00812", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.00812", "abs": "https://arxiv.org/abs/2511.00812", "authors": ["Shashank Nag", "Alan T. L. Bacellar", "Zachary Susskind", "Anshul Jha", "Logan Liberty", "Aishwarya Sivakumar", "Eugene B. John", "Krishnan Kailas", "Priscila M. V. Lima", "Neeraja J. Yadwadkar", "Felipe M. G. Franca", "Lizy K. John"], "title": "LL-ViT: Edge Deployable Vision Transformers with Look Up Table Neurons", "comment": "Accepted for FPT 2025, 9 pages, conference", "summary": "Vision Transformers have been tremendously successful in computer vision\ntasks. However, their large computational, memory, and energy demands are a\nchallenge for edge inference on FPGAs -- a field that has seen a recent surge\nin demand. We recognize the benefits of recent works on logic and Look Up Table\n(LUT) based networks, such as LogicNets, NeuraLUT, DWN, among others, in\noffering models that simultaneously reduce both the memory and compute\nfootprints. However, these models natively do not perform well on common vision\ntasks, such as CIFAR-10/100. In this work, we propose LL-ViT, a novel edge\noptimized vision transformer design that integrates layers of LUT neurons\nwithin the transformer architecture. Based on our characterization that reveals\nthat a majority of model weights and computations are from the channel mixer\n(MLP layer), we design an alternate LUT-based channel mixer, and simultaneously\ndevelop an FPGA-based accelerator for LL-ViT. Contrary to some attempts to\nreplace each multiplication with a table lookup, our architecture utilizes a\nneural learning approach which natively learns the LUT functions. This approach\nallows for reduced model sizes, and a computational and energy-efficient\ninference solution for vision transformer models. Evaluating on edge-suitable\nworkloads, we achieve accuracies of 95.5% on CIFAR-10, 78.8% on CIFAR-100, and\n60.9% on Tiny-ImageNet datasets, comparable to the baseline transformer. LL-ViT\neliminates over 60% of the model weights and 50% of the multiplications in the\nmodel, and achieves 1.9x energy efficiency and 1.3x lower latency over an\ninteger quantized ViT accelerator, while also offering superior throughput\nagainst prior works at a 10.9W power budget.", "AI": {"tldr": "LL-ViT integrates LUT-based channel mixer into Vision Transformer for edge FPGA inference, achieving substantial model sparsity and energy savings while maintaining competitive accuracy on CIFAR-10/100 and Tiny-ImageNet.", "motivation": "Vision transformers are powerful but resource-hungry, hindering edge deployment. LUT-based networks offer memory and compute reductions but historically underperform on standard vision tasks. There is a clear need for an edge-optimized transformer that preserves accuracy.", "method": "Introduce LL-ViT by embedding LUT-based channel mixer within the transformer architecture. Use a neural-learning approach to train LUT functions rather than brute-force lookups. Develop an FPGA-based accelerator for LL-ViT, reducing weights and multiplications and improving energy efficiency.", "result": "Achieves 95.5% on CIFAR-10, 78.8% on CIFAR-100, and 60.9% on Tiny-ImageNet, comparable to baseline ViT. Eliminates over 60% of model weights and 50% of multiplications. Delivers 1.9x energy efficiency and 1.3x lower latency versus an integer-quantized ViT accelerator, with superior throughput at 10.9W.", "conclusion": "LL-ViT demonstrates a viable edge-optimized vision transformer by integrating a LUT-based channel mixer and deploying an FPGA accelerator. The approach substantially reduces memory and compute demands while retaining competitive accuracy and delivering notable energy and latency gains, illustrating the promise of LUT-based neural components for CV transformers."}}
{"id": "2511.01098", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01098", "abs": "https://arxiv.org/abs/2511.01098", "authors": ["Veronica Marsico", "Antonio Quintero-Rincon", "Hadj Batatia"], "title": "Epanechnikov nonparametric kernel density estimation based feature-learning in respiratory disease chest X-ray images", "comment": "12 pages, 6 figures, 3 tables", "summary": "This study presents a novel method for diagnosing respiratory diseases using\nimage data. It combines Epanechnikov's non-parametric kernel density estimation\n(EKDE) with a bimodal logistic regression classifier in a\nstatistical-model-based learning scheme. EKDE's flexibility in modeling data\ndistributions without assuming specific shapes and its adaptability to pixel\nintensity variations make it valuable for extracting key features from medical\nimages. The method was tested on 13808 randomly selected chest X-rays from the\nCOVID-19 Radiography Dataset, achieved an accuracy of 70.14%, a sensitivity of\n59.26%, and a specificity of 74.18%, demonstrating moderate performance in\ndetecting respiratory disease while showing room for improvement in\nsensitivity. While clinical expertise remains essential for further refining\nthe model, this study highlights the potential of EKDE-based approaches to\nenhance diagnostic accuracy and reliability in medical imaging.", "AI": {"tldr": "EKDE-based feature extraction combined with a bimodal logistic regression classifier for chest X-ray diagnosis yields moderate performance on a large COVID-19 radiography dataset.", "motivation": "To model flexible feature distributions in medical images without assuming specific shapes, enabling robust feature extraction from radiographs and improving diagnostic reliability in respiratory disease detection.", "method": "Apply Epanechnikov non-parametric kernel density estimation (EKDE) to extract features from chest X-ray images and feed them into a bimodal logistic regression classifier within a statistical-model-based learning framework; evaluated on 13,808 chest X-rays from the COVID-19 Radiography Dataset.", "result": "Accuracy: 70.14%; Sensitivity: 59.26%; Specificity: 74.18%.", "conclusion": "EKDE-based approaches show potential to enhance diagnostic accuracy in medical imaging, but sensitivity remains an area for improvement; clinical expertise remains essential for refinement and deployment."}}
{"id": "2511.00851", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00851", "abs": "https://arxiv.org/abs/2511.00851", "authors": ["Abhishek Patange", "Sharat Chidambaran", "Prabhat Shankar", "Manjunath G. B.", "Anindya Chatterjee"], "title": "Identifying Slug Formation in Oil Well Pipelines: A Use Case from Industrial Analytics", "comment": "This paper ID 254 has been accepted for presentation in the\n  Demonstration Track of the 13th ACM IKDD CODS Conference on Data Science CODS\n  2025, IISER Pune, India, from December 17 to 20, 2025", "summary": "Slug formation in oil and gas pipelines poses significant challenges to\noperational safety and efficiency, yet existing detection approaches are often\noffline, require domain expertise, and lack real-time interpretability. We\npresent an interactive application that enables end-to-end data-driven slug\ndetection through a compact and user-friendly interface. The system integrates\ndata exploration and labeling, configurable model training and evaluation with\nmultiple classifiers, visualization of classification results with time-series\noverlays, and a real-time inference module that generates persistence-based\nalerts when slug events are detected. The demo supports seamless workflows from\nlabeled CSV uploads to live inference on unseen datasets, making it\nlightweight, portable, and easily deployable. By combining domain-relevant\nanalytics with novel UI/UX features such as snapshot persistence, visual\nlabeling, and real-time alerting, our tool adds significant dissemination value\nas both a research prototype and a practical industrial application. The demo\nshowcases how interactive human-in-the-loop ML systems can bridge the gap\nbetween data science methods and real-world decision-making in critical process\nindustries, with broader applicability to time-series fault diagnosis tasks\nbeyond oil and gas.", "AI": {"tldr": "An interactive, end-to-end data-driven slug detection tool for pipelines that merges data labeling, configurable ML training with multiple classifiers, time-series visualization, and real-time persistence-based alerts for live inference, bridging research and industrial decision-making.", "motivation": "Slug formation in oil/gas pipelines poses safety and efficiency risks. Existing detection methods are often offline, require domain expertise, and lack real-time interpretability. There is a need for a lightweight, user-friendly, real-time tool that supports end-to-end data workflows in industry.", "method": "An interactive application enabling data exploration and labeling, configurable model training with multiple classifiers, visualization of time-series overlays, and a real-time inference module that emits persistence-based alerts when slug events are detected. Supports labeled CSV uploads to live inference on unseen data, with features like snapshot persistence and visual labeling to aid human-in-the-loop ML.", "result": "Demonstrates a functional prototype with end-to-end capabilities from data labeling to live inference. The demo showcases how interactive ML with human-in-the-loop can facilitate deployment in critical process industries and is likely generalizable to time-series fault diagnosis beyond oil and gas.", "conclusion": "Interactive human-in-the-loop ML tools can bridge the gap between data science methods and real-world decision-making in critical industries. The approach is lightweight, portable, and broadly applicable to time-series fault diagnosis tasks beyond slug detection."}}
{"id": "2511.01109", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01109", "abs": "https://arxiv.org/abs/2511.01109", "authors": ["Alexander Thorley", "Agis Chartsias", "Jordan Strom", "Jeremy Slivnick", "Dipak Kotecha", "Alberto Gomez", "Jinming Duan"], "title": "Anatomically Constrained Transformers for Echocardiogram Analysis", "comment": null, "summary": "Video transformers have recently demonstrated strong potential for\nechocardiogram (echo) analysis, leveraging self-supervised pre-training and\nflexible adaptation across diverse tasks. However, like other models operating\non videos, they are prone to learning spurious correlations from non-diagnostic\nregions such as image backgrounds. To overcome this limitation, we propose the\nVideo Anatomically Constrained Transformer (ViACT), a novel framework that\nintegrates anatomical priors directly into the transformer architecture. ViACT\nrepresents a deforming anatomical structure as a point set and encodes both its\nspatial geometry and corresponding image patches into transformer tokens.\nDuring pre-training, ViACT follows a masked autoencoding strategy that masks\nand reconstructs only anatomical patches, enforcing that representation\nlearning is focused on the anatomical region. The pre-trained model can then be\nfine-tuned for tasks localized to this region. In this work we focus on the\nmyocardium, demonstrating the framework on echo analysis tasks such as left\nventricular ejection fraction (EF) regression and cardiac amyloidosis (CA)\ndetection. The anatomical constraint focuses transformer attention within the\nmyocardium, yielding interpretable attention maps aligned with regions of known\nCA pathology. Moreover, ViACT generalizes to myocardium point tracking without\nrequiring task-specific components such as correlation volumes used in\nspecialized tracking networks.", "AI": {"tldr": "A video transformer for echocardiography with anatomical priors improves region-focused analysis and tracking by constraining learning to myocardium patches and enabling interpretable attention.", "motivation": "To reduce reliance on non-diagnostic background cues in video models for echocardiography, improving interpretability and diagnostic performance by integrating anatomical priors into the transformer.", "method": "Represent deformable anatomy as a point set, encode its geometry and corresponding image patches as transformer tokens; pre-train with masked autoencoding on anatomical patches to focus learning on the myocardium; fine-tune for region-specific tasks (e.g., EF regression, CA detection); attention is constrained to the myocardial region and attains interpretable maps; can also perform myocardium tracking without task-specific components like correlation volumes.", "result": "Attention maps align with regions showing CA pathology; improved myocardium-focused representations for EF and CA tasks; generalizes to myocardium tracking without specialized tracking modules.", "conclusion": "ViACT demonstrates that injecting anatomical priors into video transformers yields region-focused, interpretable representations for echocardiography, improving performance on targeted tasks and enabling robust myocardium tracking without extra components."}}
{"id": "2511.00868", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00868", "abs": "https://arxiv.org/abs/2511.00868", "authors": ["Nazmul Takbir", "Hamidreza Alikhani", "Nikil Dutt", "Sangeetha Abdu Jyothi"], "title": "FlexiCache: Leveraging Temporal Stability of Attention Heads for Efficient KV Cache Management", "comment": null, "summary": "Large Language Model (LLM) serving is increasingly constrained by the growing\nsize of the key-value (KV) cache, which scales with both context length and\ngeneration length. Prior work shows that attention is dominated by a small\nsubset of critical tokens, yet existing systems struggle to exploit this\nefficiently without degrading accuracy, especially in long generation. We make\na key observation: the temporal stability of these critical tokens varies\nsignificantly across KV heads: some heads consistently focus on the same\ntokens, while others shift frequently. Building on this insight, we introduce\nFlexiCache, a hierarchical KV-cache management system that leverages the\ntemporal stability of KV heads to reduce GPU memory usage and computation\noverhead, while preserving model accuracy. FlexiCache classifies KV heads as\nstable or unstable: it retains all KV-cache pages from unstable heads in GPU\nmemory, whereas for stable heads, it keeps only the top-K pages on the GPU and\noffloads the rest to host memory. By exploiting temporal stability, FlexiCache\nperforms periodic reranking for stable heads to fetch newly promoted top pages.\nImplemented atop vLLM, FlexiCache reduces GPU memory footprint for long-context\nrequests by up to 70%, improves offline serving throughput by 1.38-1.55x, and\nlowers online token latency by 1.6-2.1x, all while maintaining accuracy in\nlong-context, long-generation scenarios.", "AI": {"tldr": "FlexiCache is a hierarchical KV-cache management system that exploits temporal stability in attention heads to reduce GPU memory and computation during LLM serving, while maintaining accuracy in long-context generation.", "motivation": "KV caches grow with context and generation length, and only a subset of critical tokens (across heads) dominate attention. Existing caching strategies either waste memory or risk accuracy loss, especially during long generations.", "method": "Classify KV heads as stable or unstable. Unstable heads keep all their KV pages in GPU memory; stable heads store only the top-K pages on GPU and offload the rest to host memory. Periodic reranking promotes new top pages for stable heads. Implementation is built atop vLLM.", "result": "Up to 70% reduction in GPU memory footprint for long-context requests; offline serving throughput improves by 1.38\u20131.55x; online token latency decreases by 1.6\u20132.1x; accuracy is preserved in long-context, long-generation scenarios.", "conclusion": "Exploiting the temporal stability of KV heads enables a practical, scalable approach to memory- and compute-efficient LLM serving without sacrificing accuracy, as demonstrated by FlexiCache on vLLM."}}
{"id": "2511.01129", "categories": ["cs.CV", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.01129", "abs": "https://arxiv.org/abs/2511.01129", "authors": ["Fabio Diniz Rossi"], "title": "Boosting performance of computer vision applications through embedded GPUs on the edge", "comment": "4 pages, 6 figures", "summary": "Computer vision applications, especially those using augmented reality\ntechnology, are becoming quite popular in mobile devices. However, this type of\napplication is known as presenting significant demands regarding resources. In\norder to enable its utilization in devices with more modest resources, edge\ncomputing can be used to offload certain high intensive tasks. Still, edge\ncomputing is usually composed of devices with limited capacity, which may\nimpact in users quality of experience when using computer vision applications.\nThis work proposes the use of embedded devices with graphics processing units\n(GPUs) to overcome such limitation. Experiments performed shown that GPUs can\nattain a performance gain when compared to using only CPUs, which guarantee a\nbetter experience to users using such kind of application.", "AI": {"tldr": "Embedded GPUs on edge devices improve computer vision/AR performance compared to CPU-only, enabling better QoE on resource-constrained mobile/edge setups.", "motivation": "AR and mobile computer vision are resource-intensive; edge computing can offload workload but edge devices themselves have limited capacity, risking poor user experience; need a solution to boost performance without excessive resources.", "method": "Propose and evaluate embedding GPUs in edge devices to accelerate CV/AR tasks; conduct experiments comparing GPU-enabled devices against CPU-only baselines to assess performance and QoE.", "result": "Experiments show GPU-enabled edge devices achieve performance gains over CPU-only configurations, indicating improved user experience for AR/CV applications.", "conclusion": "Using embedded GPUs on edge devices is an effective approach to mitigate resource constraints in mobile AR/CV tasks, improving QoE; warrants further exploration of energy/thermal implications and broader hardware comparisons."}}
{"id": "2511.00874", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.00874", "abs": "https://arxiv.org/abs/2511.00874", "authors": ["Taowen Liu", "Marta Andronic", "Deniz G\u00fcnd\u00fcz", "George A. Constantinides"], "title": "Training with Fewer Bits: Unlocking Edge LLMs Training with Stochastic Rounding", "comment": null, "summary": "LLM training is resource-intensive. Quantized training improves computational\nand memory efficiency but introduces quantization noise, which can hinder\nconvergence and degrade model accuracy. Stochastic Rounding (SR) has emerged as\na theoretically attractive alternative to deterministic rounding, offering\nunbiased gradient estimates. However, its interaction with other training\nfactors -- especially batch size -- remains under explored. In this paper, we\npresent a theoretical and empirical study of mini-batch stochastic gradient\ndescent (SGD) with SR, showing that increased batch sizes can compensate for\nreduced precision during back-propagation. Furthermore, we show that quantizing\nweights and activations impacts gradient variance in distinct ways. Our\nexperiments validate these theoretical insights.", "AI": {"tldr": "Mini-batch stochastic rounding reduces quantization penalties in SGD; larger batch sizes can offset precision loss, with quantized weights/activations affecting gradient variance differently; theory is supported by experiments.", "motivation": "Quantized training saves compute but introduces quantization noise that can hinder convergence. Stochastic rounding offers unbiased gradients, but its interaction with batch size and quantization types is not well understood.", "method": "Theoretical analysis of mini-batch SGD with stochastic rounding under quantization, examining gradient variance and convergence; empirical validation across varying batch sizes and quantization schemes for weights and activations.", "result": "Increased batch size mitigates the adverse effects of reduced precision under stochastic rounding; quantizing weights and activations affect gradient variance in distinct ways; experimental results align with the theoretical predictions.", "conclusion": "Stochastic rounding can enable efficient quantized training when paired with appropriate batch sizing; attention should be paid to how quantizing weights versus activations shapes gradient statistics to preserve convergence and accuracy."}}
{"id": "2511.01131", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01131", "abs": "https://arxiv.org/abs/2511.01131", "authors": ["Md Nahiduzzaman", "Steven Korevaar", "Alireza Bab-Hadiashar", "Ruwan Tennakoon"], "title": "Weakly Supervised Concept Learning with Class-Level Priors for Interpretable Medical Diagnosis", "comment": null, "summary": "Human-interpretable predictions are essential for deploying AI in medical\nimaging, yet most interpretable-by-design (IBD) frameworks require concept\nannotations for training data, which are costly and impractical to obtain in\nclinical contexts. Recent attempts to bypass annotation, such as zero-shot\nvision-language models or concept-generation frameworks, struggle to capture\ndomain-specific medical features, leading to poor reliability. In this paper,\nwe propose a novel Prior-guided Concept Predictor (PCP), a weakly supervised\nframework that enables concept answer prediction without explicit supervision\nor reliance on language models. PCP leverages class-level concept priors as\nweak supervision and incorporates a refinement mechanism with KL divergence and\nentropy regularization to align predictions with clinical reasoning.\nExperiments on PH2 (dermoscopy) and WBCatt (hematology) show that PCP improves\nconcept-level F1-score by over 33% compared to zero-shot baselines, while\ndelivering competitive classification performance on four medical datasets\n(PH2, WBCatt, HAM10000, and CXR4) relative to fully supervised concept\nbottleneck models (CBMs) and V-IP.", "AI": {"tldr": "Prior-guided Concept Predictor (PCP) is a weakly supervised framework for interpretable medical-imaging predictions that uses class-level concept priors and a KL-divergence/entropy-based refinement to align concept-level predictions with clinical reasoning, without explicit concept annotations or language-model reliance. It achieves notable gains in concept-level F1 over zero-shot baselines and competitive performance with fully supervised approaches across multiple datasets.", "motivation": "Interpretable-by-design models typically require costly concept annotations; zero-shot and concept-generation approaches struggle with domain-specific medical features and reliability. There is a need for an interpretable method that does not rely on explicit supervision or language models.", "method": "PCP leverages class-level concept priors as weak supervision and introduces a refinement mechanism using KL divergence and entropy regularization to align predictions with clinical reasoning. It operates without explicit concept labels or language-model reliance, enabling concept answer prediction in a weakly supervised setting.", "result": "On PH2 (dermoscopy) and WBCatt (hematology), PCP improves concept-level F1-score by over 33% compared to zero-shot baselines, while delivering competitive classification performance on four medical datasets (PH2, WBCatt, HAM10000, and CXR4) relative to fully supervised concept bottleneck models (CBMs) and V-IP.", "conclusion": "PCP offers a practical, weakly supervised path to interpretable medical-imaging predictions by combining concept priors with a principled refinement strategy, yielding reliable concept-level interpretations without requiring explicit annotations or language-model-based supervision while maintaining competitive accuracy."}}
{"id": "2511.00880", "categories": ["cs.LG", "cs.AI", "68T07, 90C15, 93E35"], "pdf": "https://arxiv.org/pdf/2511.00880", "abs": "https://arxiv.org/abs/2511.00880", "authors": ["Joonyoung Lim", "Younghwan Yoo"], "title": "KFCPO: Kronecker-Factored Approximated Constrained Policy Optimization", "comment": "12 pages, 8 figures, submitted to ECAI 2025", "summary": "We propose KFCPO, a novel Safe Reinforcement Learning (Safe RL) algorithm\nthat combines scalable Kronecker-Factored Approximate Curvature (K-FAC) based\nsecond-order policy optimization with safety-aware gradient manipulation. KFCPO\nleverages K-FAC to perform efficient and stable natural gradient updates by\napproximating the Fisher Information Matrix (FIM) in a layerwise, closed form\nmanner, avoiding iterative approximation overheads. To address the tradeoff\nbetween reward maximization and constraint satisfaction, we introduce a margin\naware gradient manipulation mechanism that adaptively adjusts the influence of\nreward and cost gradients based on the agent's proximity to safety boundaries.\nThis method blends gradients using a direction sensitive projection,\neliminating harmful interference and avoiding abrupt changes caused by fixed\nhard thresholds. Additionally, a minibatch level KL rollback strategy is\nadopted to ensure trust region compliance and to prevent destabilizing policy\nshifts. Experiments on Safety Gymnasium using OmniSafe show that KFCPO achieves\n10.3% to 50.2% higher average return across environments compared to the best\nbaseline that respected the safety constraint, demonstrating superior balance\nof safety and performance.", "AI": {"tldr": "KFCPO is a safe RL algorithm that uses K-FAC-based second-order optimization with margin-aware gradient blending and KL rollback to balance reward and safety, achieving notable performance gains on Safety Gymnasium with OmniSafe.", "motivation": "Address the trade-off between maximizing return and satisfying safety constraints in RL, targeting scalable, stable optimization without brittle fixed thresholds.", "method": "1) Use Kronecker-Factored Approximate Curvature (K-FAC) for efficient, layerwise natural-gradient updates by closed-form FIM approximations. 2) Introduce a margin-aware gradient manipulation that adaptively blends reward and cost gradients based on proximity to safety boundaries using a direction-sensitive projection to avoid interference and avoid fixed hard thresholds. 3) Apply a minibatch-level KL rollback strategy to maintain trust-region compliance and prevent destabilizing policy shifts.", "result": "Empirical evaluation on Safety Gymnasium with OmniSafe shows KFCPO achieves 10.3% to 50.2% higher average return across environments than the best baseline that respects the safety constraint, indicating a better safety-performance balance.", "conclusion": "KFCPO delivers scalable, stable safe RL with superior performance under safety constraints, outperforming strong baselines and offering a robust approach to balancing risk and reward; potential for broader applicability and further ablations."}}
{"id": "2511.01139", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01139", "abs": "https://arxiv.org/abs/2511.01139", "authors": ["Yoshihiro Maruyama"], "title": "Learning with Category-Equivariant Architectures for Human Activity Recognition", "comment": null, "summary": "We propose CatEquiv, a category-equivariant neural network for Human Activity\nRecognition (HAR) from inertial sensors that systematically encodes temporal,\namplitude, and structural symmetries. In particular, we introduce the\ncategorical symmetry product where cyclic time shifts, positive gains and the\nsensor-hierarchy poset together capture the categorical symmetry structure of\nthe data. CatEquiv achieves equivariance with respect to the categorical\nsymmetry product. On UCI-HAR under out-of-distribution perturbations, CatEquiv\nattains markedly higher robustness compared with circularly padded CNNs and\nplain CNNs. These results demonstrate that enforcing categorical symmetries\nyields strong invariance and generalization without additional model capacity.", "AI": {"tldr": "CatEquiv is a category-equivariant neural network for HAR that encodes temporal, amplitude, and sensor-structure symmetries via a categorical symmetry product, achieving robustness to OOD perturbations with no extra capacity.", "motivation": "Address robustness and generalization in HAR by embedding symmetry-aware inductive biases derived from category theory to handle temporal shifts, gain variations, and sensor hierarchy.", "method": "Introduce categorical symmetry product combining cyclic time shifts, positive gains, and sensor-hierarchy poset; enforce equivariance of CatEquiv to this product.", "result": "On UCI-HAR with out-of-distribution perturbations, CatEquiv shows markedly higher robustness compared with circularly padded CNNs and plain CNNs.", "conclusion": "Imposing categorical symmetries yields strong invariance and generalization without increasing model capacity."}}
{"id": "2511.00885", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.00885", "abs": "https://arxiv.org/abs/2511.00885", "authors": ["Tal Argov", "Tal Wagner"], "title": "SpEx: A Spectral Approach to Explainable Clustering", "comment": "NeurIPS 2025", "summary": "Explainable clustering by axis-aligned decision trees was introduced by\nMoshkovitz et al. (2020) and has gained considerable interest. Prior work has\nfocused on minimizing the price of explainability for specific clustering\nobjectives, lacking a general method to fit an explanation tree to any given\nclustering, without restrictions. In this work, we propose a new and generic\napproach to explainable clustering, based on spectral graph partitioning. With\nit, we design an explainable clustering algorithm that can fit an explanation\ntree to any given non-explainable clustering, or directly to the dataset\nitself. Moreover, we show that prior algorithms can also be interpreted as\ngraph partitioning, through a generalized framework due to Trevisan (2013)\nwherein cuts are optimized in two graphs simultaneously. Our experiments show\nthe favorable performance of our method compared to baselines on a range of\ndatasets.", "AI": {"tldr": "A general, spectral-graph-based method to fit explanation trees to any clustering, unifying prior explainable-clustering approaches and showing competitive empirical performance.", "motivation": "Existing work on explainable clustering focuses on specific objectives and lacks a universal method to produce explanation trees for arbitrary clustering results or datasets.", "method": "Introduce a generic explainable clustering framework based on spectral graph partitioning. Build an explanation tree by partitioning data via graph cuts, and show that existing algorithms are instances of a two-graph Trevisan (2013) framework. The method can fit to any non-explainable clustering or directly to the dataset.", "result": "Empirical experiments on multiple datasets demonstrate favorable performance against baselines, validating the approach.", "conclusion": "Spectral graph partitioning provides a flexible, unifying, and effective foundation for explainable clustering, enabling a universal way to generate explanation trees for arbitrary clustering."}}
{"id": "2511.01143", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01143", "abs": "https://arxiv.org/abs/2511.01143", "authors": ["Ziyi Wang", "Yuanmei Zhang", "Dorna Esrafilzadeh", "Ali R. Jalili", "Suncheng Xiang"], "title": "MicroAUNet: Boundary-Enhanced Multi-scale Fusion with Knowledge Distillation for Colonoscopy Polyp Image Segmentation", "comment": "Work in progress", "summary": "Early and accurate segmentation of colorectal polyps is critical for reducing\ncolorectal cancer mortality, which has been extensively explored by academia\nand industry. However, current deep learning-based polyp segmentation models\neither compromise clinical decision-making by providing ambiguous polyp margins\nin segmentation outputs or rely on heavy architectures with high computational\ncomplexity, resulting in insufficient inference speeds for real-time colorectal\nendoscopic applications. To address this problem, we propose MicroAUNet, a\nlight-weighted attention-based segmentation network that combines\ndepthwise-separable dilated convolutions with a single-path, parameter-shared\nchannel-spatial attention block to strengthen multi-scale boundary features. On\nthe basis of it, a progressive two-stage knowledge-distillation scheme is\nintroduced to transfer semantic and boundary cues from a high-capacity teacher.\nExtensive experiments on benchmarks also demonstrate the state-of-the-art\naccuracy under extremely low model complexity, indicating that MicroAUNet is\nsuitable for real-time clinical polyp segmentation. The code is publicly\navailable at https://github.com/JeremyXSC/MicroAUNet.", "AI": {"tldr": "A lightweight, attention-based polyp segmentation network (MicroAUNet) achieves real-time performance with depthwise-separable dilated convolutions and a shared channel-spatial attention block, aided by a two-stage knowledge distillation from a high-capacity teacher; code released.", "motivation": "There is a need for accurate polyp boundary segmentation in real-time clinical endoscopy without sacrificing speed or decision quality; current deep learning models trade off accuracy and inference speed.", "method": "MicroAUNet employs depthwise-separable dilated convolutions and a single-path, parameter-shared channel-spatial attention block to enhance multi-scale boundary features, followed by a progressive two-stage knowledge-distillation scheme from a high-capacity teacher to transfer semantic and boundary cues.", "result": "Extensive experiments on benchmarks show state-of-the-art accuracy under extremely low model complexity, indicating suitability for real-time clinical polyp segmentation.", "conclusion": "MicroAUNet is a viable solution for real-time clinical polyp segmentation, with code publicly available at the provided repository."}}
{"id": "2511.00900", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.00900", "abs": "https://arxiv.org/abs/2511.00900", "authors": ["Yoshihiro Maruyama"], "title": "Learning with Category-Equivariant Representations for Human Activity Recognition", "comment": null, "summary": "Human activity recognition is challenging because sensor signals shift with\ncontext, motion, and environment; effective models must therefore remain stable\nas the world around them changes. We introduce a categorical symmetry-aware\nlearning framework that captures how signals vary over time, scale, and sensor\nhierarchy. We build these factors into the structure of feature\nrepresentations, yielding models that automatically preserve the relationships\nbetween sensors and remain stable under realistic distortions such as time\nshifts, amplitude drift, and device orientation changes. On the UCI Human\nActivity Recognition benchmark, this categorical symmetry-driven design\nimproves out-of-distribution accuracy by approx. 46 percentage points (approx.\n3.6x over the baseline), demonstrating that abstract symmetry principles can\ntranslate into concrete performance gains in everyday sensing tasks via\ncategory-equivariant representation theory.", "AI": {"tldr": "Introduces a symmetry-aware learning framework for human activity recognition that uses category symmetries over time, scale, and sensor hierarchy to produce stable, category-equivariant representations; achieves large robustness gains.", "motivation": "Sensor signals drift with context, motion, and environment, causing models to degrade under shifts. Stable models are needed that preserve sensor relationships under realistic distortions.", "method": "A categorical symmetry-aware framework that encodes time/scale/sensor-hierarchy transformations into feature representations, preserving inter-sensor relationships and yielding stability to distortions (time shifts, amplitude drift, device orientation) using category-equivariant representation theory.", "result": "On the UCI HAR benchmark, out-of-distribution accuracy improves by about 46 percentage points (roughly 3.6x over baseline).", "conclusion": "Demonstrates that abstract symmetry principles can yield concrete performance gains in everyday sensing tasks via category-equivariant representations."}}
{"id": "2511.01163", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01163", "abs": "https://arxiv.org/abs/2511.01163", "authors": ["Yongyuan Liang", "Wei Chow", "Feng Li", "Ziqiao Ma", "Xiyao Wang", "Jiageng Mao", "Jiuhai Chen", "Jiatao Gu", "Yue Wang", "Furong Huang"], "title": "ROVER: Benchmarking Reciprocal Cross-Modal Reasoning for Omnimodal Generation", "comment": "Project Page: https://roverbench.github.io/", "summary": "Unified multimodal models (UMMs) have emerged as a powerful paradigm for\nseamlessly unifying text and image understanding and generation. However,\nprevailing evaluations treat these abilities in isolation, such that tasks with\nmultimodal inputs and outputs are scored primarily through unimodal reasoning,\ni.e., textual benchmarks emphasize language-based reasoning, while visual\nbenchmarks emphasize reasoning outcomes manifested in the pixels. We introduce\nROVER to address this pressing need to test reciprocal cross-modal reasoning,\nthe use of one modality to guide, verify, or refine outputs in the other, an\nability central to the vision of unified multimodal intelligence. ROVER is a\nhuman-annotated benchmark that explicitly targets reciprocal cross-modal\nreasoning, which contains 1312 tasks grounded in 1876 images, spanning two\ncomplementary settings. Verbally-augmented reasoning for visual generation\nevaluates whether models can use verbal prompts and reasoning chains to guide\nfaithful image synthesis. Visually-augmented reasoning for verbal generation\nevaluates whether models can generate intermediate visualizations that\nstrengthen their own reasoning processes for question answering. Experiments on\n17 unified models reveal two key findings: (i) Cross-modal reasoning determines\nvisual generation quality, with interleaved models significantly outperforming\nnon-interleaved ones; notably, combining strong unimodal models fails to\nachieve comparable reasoning. (ii) Models show dissociation between physical\nand symbolic reasoning: they succeed at interpreting perceptual concepts\nliterally but fail to construct visual abstractions for symbolic tasks, where\nfaulty reasoning harms performance. These results highlight reciprocal\ncross-modal reasoning as a critical frontier for enabling true omnimodal\ngeneration.", "AI": {"tldr": "ROVER is a new human-annotated benchmark to test reciprocal cross-modal reasoning in unified multimodal models, showing interleaved cross-modal reasoning boosts visual generation and revealing gaps in symbolic reasoning.", "motivation": "Current evaluations treat multimodal tasks in isolation, emphasizing unimodal reasoning. There is a need to test how one modality can guide, verify, or refine outputs in the other to achieve true omnimodal generation.", "method": "ROVER comprises 1,312 tasks grounded in 1,876 images across two settings: verbally-augmented reasoning for visual generation and visually-augmented reasoning for verbal generation. It is evaluated on 17 unified multimodal models.", "result": "Cross-modal reasoning strongly influences visual generation quality; interleaved models outperform non-interleaved ones, and mere combination of strong unimodal models is not enough. There is a dissociation between physical and symbolic reasoning: models handle perceptual concepts but struggle to construct visual abstractions for symbolic tasks, with faulty reasoning harming performance.", "conclusion": "Reciprocal cross-modal reasoning is a critical frontier for enabling true omnimodal generation."}}
{"id": "2511.00904", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00904", "abs": "https://arxiv.org/abs/2511.00904", "authors": ["Ernesto Araya", "Massimiliano Datres", "Gitta Kutyniok"], "title": "Random Spiking Neural Networks are Stable and Spectrally Simple", "comment": null, "summary": "Spiking neural networks (SNNs) are a promising paradigm for energy-efficient\ncomputation, yet their theoretical foundations-especially regarding stability\nand robustness-remain limited compared to artificial neural networks. In this\nwork, we study discrete-time leaky integrate-and-fire (LIF) SNNs through the\nlens of Boolean function analysis. We focus on noise sensitivity and stability\nin classification tasks, quantifying how input perturbations affect outputs.\nOur main result shows that wide LIF-SNN classifiers are stable on average, a\nproperty explained by the concentration of their Fourier spectrum on\nlow-frequency components. Motivated by this, we introduce the notion of\nspectral simplicity, which formalizes simplicity in terms of Fourier spectrum\nconcentration and connects our analysis to the simplicity bias observed in deep\nnetworks. Within this framework, we show that random LIF-SNNs are biased toward\nsimple functions. Experiments on trained networks confirm that these stability\nproperties persist in practice. Together, these results provide new insights\ninto the stability and robustness properties of SNNs.", "AI": {"tldr": "Boolean-analysis of discrete-time LIF SNNs shows that wide classifiers are stable on average due to concentration of the Fourier spectrum on low frequencies; introduces spectral simplicity and finds random LIF-SNNs bias toward simple functions, with experiments supporting robustness.", "motivation": "Address the limited theoretical understanding of stability and robustness in spiking neural networks by applying Boolean function Fourier analysis to quantify noise sensitivity and spectral concentration, and to connect this behavior to observed simplicity biases in deep networks.", "method": "Model SNNs as discrete-time leaky integrate-and-fire networks and analyze them using Boolean function Fourier spectrum. Study noise sensitivity and stability in classification tasks, prove that wide LIF-SNN classifiers concentrate spectrum on low frequencies leading to average stability, formalize spectral simplicity, examine random LIF-SNNs, and validate findings with experiments on trained networks.", "result": "The analysis shows wide LIF-SNN classifiers are stable on average due to low-frequency spectral concentration. Random LIF-SNNs exhibit a bias toward simple functions (spectral simplicity). Experiments on trained networks confirm the theoretical stability properties in practice.", "conclusion": "A spectral perspective explains stability and robustness in SNNs, links to a simplicity bias via spectral simplicity, and provides groundwork for designing robust SNNs and future theoretical exploration."}}
{"id": "2511.01169", "categories": ["cs.CV", "I.2.10; I.4.5"], "pdf": "https://arxiv.org/pdf/2511.01169", "abs": "https://arxiv.org/abs/2511.01169", "authors": ["Brian Nlong Zhao", "Jiajun Wu", "Shangzhe Wu"], "title": "Web-Scale Collection of Video Data for 4D Animal Reconstruction", "comment": "NeurIPS 2025 Datasets and Benchmarks", "summary": "Computer vision for animals holds great promise for wildlife research but\noften depends on large-scale data, while existing collection methods rely on\ncontrolled capture setups. Recent data-driven approaches show the potential of\nsingle-view, non-invasive analysis, yet current animal video datasets are\nlimited--offering as few as 2.4K 15-frame clips and lacking key processing for\nanimal-centric 3D/4D tasks. We introduce an automated pipeline that mines\nYouTube videos and processes them into object-centric clips, along with\nauxiliary annotations valuable for downstream tasks like pose estimation,\ntracking, and 3D/4D reconstruction. Using this pipeline, we amass 30K videos\n(2M frames)--an order of magnitude more than prior works. To demonstrate its\nutility, we focus on the 4D quadruped animal reconstruction task. To support\nthis task, we present Animal-in-Motion (AiM), a benchmark of 230 manually\nfiltered sequences with 11K frames showcasing clean, diverse animal motions. We\nevaluate state-of-the-art model-based and model-free methods on\nAnimal-in-Motion, finding that 2D metrics favor the former despite unrealistic\n3D shapes, while the latter yields more natural reconstructions but scores\nlower--revealing a gap in current evaluation. To address this, we enhance a\nrecent model-free approach with sequence-level optimization, establishing the\nfirst 4D animal reconstruction baseline. Together, our pipeline, benchmark, and\nbaseline aim to advance large-scale, markerless 4D animal reconstruction and\nrelated tasks from in-the-wild videos. Code and datasets are available at\nhttps://github.com/briannlongzhao/Animal-in-Motion.", "AI": {"tldr": "Automates mining of YouTube videos to create a large, object-centric, 4D-animal reconstruction pipeline and a new AiM benchmark; reveals a gap between 2D-metric favoring model-based methods and 3D realism, and introduces a sequence-optimized model-free baseline.", "motivation": "Enable large-scale, markerless 4D animal reconstruction from in-the-wild videos, addressing data scarcity and evaluation gaps that hinder non-invasive wildlife research.", "method": "An automated pipeline extracts 30K YouTube videos (\u22482M frames) into object-centric clips with auxiliary annotations for pose estimation, tracking, and 3D/4D tasks; introduction of AiM benchmark with 230 sequences (~11K frames) for 4D quadruped reconstruction; evaluation of state-of-the-art model-based and model-free methods; enhancement of a model-free approach with sequence-level optimization to establish a first 4D baseline.", "result": "Substantial data resource (30K videos, 2M frames) and a curated 4D quadruped benchmark (AiM) enabling systematic evaluation; 2D metrics prefer model-based methods, but they produce unrealistic 3D shapes; model-free methods yield more natural reconstructions but score lower; sequence-level optimization improves model-free performance, establishing a first 4D baseline; code and datasets released.", "conclusion": "The pipeline, AiM benchmark, and baseline address key gaps in data, evaluation, and baselines for large-scale markerless 4D animal reconstruction, accelerating progress in downstream tasks and related wildlife video analytics."}}
{"id": "2511.00907", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00907", "abs": "https://arxiv.org/abs/2511.00907", "authors": ["Ruifeng Ren", "Sheng Ouyang", "Huayi Tang", "Yong Liu"], "title": "Transformers as Intrinsic Optimizers: Forward Inference through the Energy Principle", "comment": null, "summary": "Transformers have demonstrated strong adaptability across a wide range of\ntasks and have become the backbone of modern Large Language Models (LLMs).\nHowever, their underlying mechanisms remain open for further exploration. The\nenergy-based perspective has long provided a valuable principle for\nunderstanding neural computation. In this paper, we revisit the principle of\nenergy as a lens to understand attention-based Transformer models. We present a\nunified energy-based framework which is composed of three key components: the\nglobal energy $F^*$, the energy function $E_i$ and the employed gradient\ndescent (GD) form. Within this framework, standard softmax attention can be\nviewed as a special case of minimizing the Helmholtz free energy as $F^*$ using\nstandard GD when $E_i$ takes the form of elastic potential energy, with\nresidual connections ensuring that this optimization proceeds in an incremental\nmanner. In addition, linear attentions can also be naturally incorporated into\nthis framework by adjusting the corresponding energy forms. We also extend the\nabove analysis to the multi-head setting, where the energy is defined across\nmultiple low-dimensional subspaces. Building on this framework, we propose\nenergy-based modifications of attention structures. Inspired by classical GD\nalgorithms, we extend the original attention formulation based on standard GD\nto the momentum-based GD, Nesterov Accelerated Gradient (NAG), and Newton's\nmethod variants, each inducing a corresponding new attention structure. Our\nexperiments provide preliminary support for the potential of the energy-based\nframework for designing attention mechanisms.", "AI": {"tldr": "Proposes an energy-based, unified framework for attention in Transformers, recasting softmax and linear attentions as energy-minimization dynamics and extending to advanced optimization methods for new attention variants.", "motivation": "To understand and unify attention mechanisms in Transformer models through an energy-based lens, enabling principled modifications and extensions of attention dynamics.", "method": "Define a global energy F*, an energy function E_i, and a gradient-descent-based optimization; show softmax attention as Helmholtz free energy minimization with elastic-like E_i and residual connections; generalize to linear and multi-head attentions; derive momentum, Nesterov, and Newton variants as new attention forms.", "result": "Preliminary experiments provide initial support that the energy-based framework can guide the design of attention mechanisms and yield viable extensions.", "conclusion": "An energy-based perspective offers a coherent framework to analyze and design attention in Transformers, with promising early results for energy-driven variants and future research directions."}}
{"id": "2511.01175", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01175", "abs": "https://arxiv.org/abs/2511.01175", "authors": ["Peng Du", "Hui Li", "Han Xu", "Paul Barom Jeon", "Dongwook Lee", "Daehyun Ji", "Ran Yang", "Feng Zhu"], "title": "Diffusion Transformer meets Multi-level Wavelet Spectrum for Single Image Super-Resolution", "comment": null, "summary": "Discrete Wavelet Transform (DWT) has been widely explored to enhance the\nperformance of image superresolution (SR). Despite some DWT-based methods\nimproving SR by capturing fine-grained frequency signals, most existing\napproaches neglect the interrelations among multiscale frequency sub-bands,\nresulting in inconsistencies and unnatural artifacts in the reconstructed\nimages. To address this challenge, we propose a Diffusion Transformer model\nbased on image Wavelet spectra for SR (DTWSR).DTWSR incorporates the\nsuperiority of diffusion models and transformers to capture the interrelations\namong multiscale frequency sub-bands, leading to a more consistence and\nrealistic SR image. Specifically, we use a Multi-level Discrete Wavelet\nTransform (MDWT) to decompose images into wavelet spectra. A pyramid\ntokenization method is proposed which embeds the spectra into a sequence of\ntokens for transformer model, facilitating to capture features from both\nspatial and frequency domain. A dual-decoder is designed elaborately to handle\nthe distinct variances in lowfrequency (LF) and high-frequency (HF) sub-bands,\nwithout omitting their alignment in image generation. Extensive experiments on\nmultiple benchmark datasets demonstrate the effectiveness of our method, with\nhigh performance on both perception quality and fidelity.", "AI": {"tldr": "DTWSR introduces a diffusion-transformer SR framework that leverages multi-level DWT wavelet spectra, pyramid tokenization, and a dual-decoder to model interrelations across multiscale frequency sub-bands, yielding more consistent and realistic super-resolved images with strong perceptual quality and fidelity.", "motivation": "Existing DWT-based SR methods often ignore the cross-scale relationships among wavelet sub-bands, leading to inconsistencies and artifacts in the reconstructed images. There is a need to explicitly model interscale dependencies and preserve both high- and low-frequency content for realistic SR.", "method": "1) Decompose images with Multi-level Discrete Wavelet Transform (MDWT) to obtain wavelet spectra across scales. 2) Apply pyramid tokenization to embed spectra into a sequence of tokens suitable for a transformer, capturing spatial and frequency-domain information. 3) Employ a diffusion-transformer framework to model the distribution of clean HR images conditioned on LR input, with a dual-decoder architecture designed to handle low-frequency (LF) and high-frequency (HF) sub-bands separately while maintaining their alignment. 4) Train and evaluate on standard SR benchmarks to assess perceptual quality and fidelity.", "result": "Experiments on multiple benchmark datasets show that DTWSR achieves strong performance in both perceptual quality and fidelity, indicating improved consistency and realism in SR images due to explicit multiscale spectral modeling and effective cross-band alignment.", "conclusion": "DTWSR demonstrates that integrating diffusion models, transformers, and wavelet-based multiscale spectra can effectively model interrelations across sub-bands to produce more coherent and realistic SR results, suggesting a promising direction for wavelet-informed diffusion architectures in image restoration."}}
{"id": "2511.00949", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00949", "abs": "https://arxiv.org/abs/2511.00949", "authors": ["Yangyang Zhao", "Matti Kaisti", "Olli Lahdenoja", "Tero Koivisto"], "title": "Motion-Robust Multimodal Fusion of PPG and Accelerometer Signals for Three-Class Heart Rhythm Classification", "comment": "Accepted for publication in the Companion of the 2025 ACM\n  International Joint Conference on Pervasive and Ubiquitous Computing and the\n  2025 International Symposium on Wearable Computers (UbiComp/ISWC 2025\n  Companion). 5 pages, 3 figures. Author's accepted manuscript (AAM)", "summary": "Atrial fibrillation (AF) is a leading cause of stroke and mortality,\nparticularly in elderly patients. Wrist-worn photoplethysmography (PPG) enables\nnon-invasive, continuous rhythm monitoring, yet suffers from significant\nvulnerability to motion artifacts and physiological noise. Many existing\napproaches rely solely on single-channel PPG and are limited to binary AF\ndetection, often failing to capture the broader range of arrhythmias\nencountered in clinical settings. We introduce RhythmiNet, a residual neural\nnetwork enhanced with temporal and channel attention modules that jointly\nleverage PPG and accelerometer (ACC) signals. The model performs three-class\nrhythm classification: AF, sinus rhythm (SR), and Other. To assess robustness\nacross varying movement conditions, test data are stratified by\naccelerometer-based motion intensity percentiles without excluding any\nsegments. RhythmiNet achieved a 4.3% improvement in macro-AUC over the PPG-only\nbaseline. In addition, performance surpassed a logistic regression model based\non handcrafted HRV features by 12%, highlighting the benefit of multimodal\nfusion and attention-based learning in noisy, real-world clinical data.", "AI": {"tldr": "RhythmiNet: a multimodal, attention-based ResNet that fuses wrist PPG with accelerometer data for three-class rhythm classification (AF, SR, Other); shows robustness to motion and outperforms PPG-only and HRV-based baselines.", "motivation": "Address the vulnerability of wrist-worn PPG to motion artifacts and physiological noise, and the need for multi-class rhythm detection beyond binary AF vs non-AF in real-world settings.", "method": "A residual neural network with temporal and channel attention modules that jointly processes PPG and accelerometer signals, performing three-class rhythm classification (AF, SR, Other). The study stratifies test data by motion intensity percentiles to assess robustness without excluding segments.", "result": "4.3% macro-AUC improvement over PPG-only baseline; 12% performance gain over a logistic regression model based on handcrafted HRV features, demonstrating benefits of multimodal fusion and attention in noisy, real-world data.", "conclusion": "Multimodal fusion with attention enhances robustness of wearable rhythm monitoring in real-world conditions and improves discrimination among AF, SR, and Other compared to single-modality or traditional feature-based approaches."}}
{"id": "2511.01194", "categories": ["cs.CV", "cs.AI", "68T07 (Artificial neural networks and deep learning), 68U10\n  (Computer graphics, computational geometry)"], "pdf": "https://arxiv.org/pdf/2511.01194", "abs": "https://arxiv.org/abs/2511.01194", "authors": ["Minmin Zeng"], "title": "A Topology-Aware Graph Convolutional Network for Human Pose Similarity and Action Quality Assessment", "comment": "10 pages, 5 figures. Submitted as a computer vision paper in the\n  cs.CV category", "summary": "Action Quality Assessment (AQA) requires fine-grained understanding of human\nmotion and precise evaluation of pose similarity. This paper proposes a\ntopology-aware Graph Convolutional Network (GCN) framework, termed GCN-PSN,\nwhich models the human skeleton as a graph to learn discriminative,\ntopology-sensitive pose embeddings. Using a Siamese architecture trained with a\ncontrastive regression objective, our method outperforms coordinate-based\nbaselines and achieves competitive performance on AQA-7 and FineDiving\nbenchmarks. Experimental results and ablation studies validate the\neffectiveness of leveraging skeletal topology for pose similarity and action\nquality assessment.", "AI": {"tldr": "GCN-PSN uses a topology-aware GCN to model the skeleton as a graph for action quality assessment, employing a Siamese network with a contrastive regression objective to learn discriminative pose embeddings; achieves competitive results on AQA-7 and FineDiving.", "motivation": "Action Quality Assessment (AQA) requires fine-grained understanding of human motion and precise pose similarity; skeletal topology provides relational structure that coordinate-based methods may miss, enabling more discriminative embeddings.", "method": "Model the human skeleton as a graph and apply a topology-aware Graph Convolutional Network (GCN-PSN) to learn pose embeddings. Use a Siamese architecture trained with a contrastive regression objective to compare action qualities and assess similarity.", "result": "The method outperforms coordinate-based baselines and achieves competitive performance on AQA-7 and FineDiving. Ablation studies validate the benefit of leveraging skeletal topology for pose similarity and action quality assessment.", "conclusion": "Incorporating skeletal topology via a topology-aware GCN improves action quality assessment and pose similarity, highlighting the importance of graph-structured representations for fine-grained motion analysis."}}
{"id": "2511.00958", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.00958", "abs": "https://arxiv.org/abs/2511.00958", "authors": ["Khoat Than"], "title": "The Hidden Power of Normalization: Exponential Capacity Control in Deep Neural Networks", "comment": null, "summary": "Normalization methods are fundamental components of modern deep neural\nnetworks (DNNs). Empirically, they are known to stabilize optimization dynamics\nand improve generalization. However, the underlying theoretical mechanism by\nwhich normalization contributes to both optimization and generalization remains\nlargely unexplained, especially when using many normalization layers in a DNN\narchitecture.\n  In this work, we develop a theoretical framework that elucidates the role of\nnormalization through the lens of capacity control. We prove that an\nunnormalized DNN can exhibit exponentially large Lipschitz constants with\nrespect to either its parameters or inputs, implying excessive functional\ncapacity and potential overfitting. Such bad DNNs are uncountably many. In\ncontrast, the insertion of normalization layers provably can reduce the\nLipschitz constant at an exponential rate in the number of normalization\noperations. This exponential reduction yields two fundamental consequences: (1)\nit smooths the loss landscape at an exponential rate, facilitating faster and\nmore stable optimization; and (2) it constrains the effective capacity of the\nnetwork, thereby enhancing generalization guarantees on unseen data. Our\nresults thus offer a principled explanation for the empirical success of\nnormalization methods in deep learning.", "AI": {"tldr": "Normalization layers can dramatically reduce a network's Lipschitz constant exponentially with depth, turning unnormalized networks (which can have exponential Lipschitz growth and high capacity) into well-behaved models. This links normalization to both optimization stability and generalization via capacity control.", "motivation": "To theoretically explain why normalization stabilizes optimization and improves generalization, especially in deep networks with many normalization layers, by framing normalization as a mechanism for capacity control through Lipschitz constants.", "method": "Develop a theoretical framework that models DNNs and normalization layers, analyzes Lipschitz constants with respect to inputs and parameters, and proves that inserting normalization layers reduces these constants exponentially in the number of normalization operations, thereby smoothing the loss landscape and constraining capacity.", "result": "Theorem: unnormalized DNNs can have exponentially large Lipschitz constants (bad DNNs, uncountably many). In contrast, inserting normalization reduces the Lipschitz constant exponentially with the number of normalization operations. Consequences include exponentially smoother loss landscapes and stronger generalization guarantees due to capacity control.", "conclusion": "Normalization methods provide a principled mechanism for capacity control in deep networks, offering a theoretical explanation for their empirical success in stabilizing optimization and improving generalization as network depth and normalization usage grow."}}
{"id": "2511.01200", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01200", "abs": "https://arxiv.org/abs/2511.01200", "authors": ["Mengyuan Liu", "Sheng Yan", "Yong Wang", "Yingjie Li", "Gui-Bin Bian", "Hong Liu"], "title": "MoSa: Motion Generation with Scalable Autoregressive Modeling", "comment": null, "summary": "We introduce MoSa, a novel hierarchical motion generation framework for\ntext-driven 3D human motion generation that enhances the Vector\nQuantization-guided Generative Transformers (VQ-GT) paradigm through a\ncoarse-to-fine scalable generation process. In MoSa, we propose a Multi-scale\nToken Preservation Strategy (MTPS) integrated into a hierarchical residual\nvector quantization variational autoencoder (RQ-VAE). MTPS employs\ninterpolation at each hierarchical quantization to effectively retain\ncoarse-to-fine multi-scale tokens. With this, the generative transformer\nsupports Scalable Autoregressive (SAR) modeling, which predicts scale tokens,\nunlike traditional methods that predict only one token at each step.\nConsequently, MoSa requires only 10 inference steps, matching the number of\nRQ-VAE quantization layers. To address potential reconstruction degradation\nfrom frequent interpolation, we propose CAQ-VAE, a lightweight yet expressive\nconvolution-attention hybrid VQ-VAE. CAQ-VAE enhances residual block design and\nincorporates attention mechanisms to better capture global dependencies.\nExtensive experiments show that MoSa achieves state-of-the-art generation\nquality and efficiency, outperforming prior methods in both fidelity and speed.\nOn the Motion-X dataset, MoSa achieves an FID of 0.06 (versus MoMask's 0.20)\nwhile reducing inference time by 27 percent. Moreover, MoSa generalizes well to\ndownstream tasks such as motion editing, requiring no additional fine-tuning.\nThe code is available at https://mosa-web.github.io/MoSa-web", "AI": {"tldr": "MoSa introduces a hierarchical, multi-scale motion generation framework that uses a multi-scale token preservation strategy (MTPS) in a hierarchical residual VQ-VAE (RQ-VAE) and scalable autoregressive (SAR) modeling to achieve high fidelity and efficiency in text-driven 3D human motion generation, with only 10 inference steps and strong results on Motion-X.", "motivation": "Overcome inefficiencies and reconstruction artifacts in existing VQ-GT approaches by enabling multi-scale, scalable generation that preserves coarse-to-fine structure and improves both fidelity and speed, while supporting downstream tasks like motion editing without fine-tuning.", "method": "MoSa integrates MTPS into a hierarchical RQ-VAE, using interpolation to retain coarse-to-fine tokens at each quantization level. It enables scalable autoregressive modeling that predicts scale tokens across 10 steps, matching the number of quantization layers. To mitigate interpolation-induced degradation, it introduces CAQ-VAE, a convolution-attention hybrid VQ-VAE with improved residual blocks and global attention.", "result": "Empirical results show state-of-the-art generation quality and efficiency: on the Motion-X dataset, MoSa achieves FID 0.06 (better than MoMask's 0.20) and reduces inference time by 27%. It generalizes to downstream tasks such as motion editing without additional fine-tuning; code is available at the provided URL.", "conclusion": "MoSa demonstrates that hierarchical, multi-scale token preservation coupled with scalable autoregressive generation and a convolution-attention VQ-VAE can substantially improve both the quality and speed of text-driven 3D motion generation, enabling efficient long-horizon generation and easy downstream adaptation."}}
{"id": "2511.00964", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00964", "abs": "https://arxiv.org/abs/2511.00964", "authors": ["Hai Hoang Thanh", "Duy-Tung Nguyen", "Hung The Tran", "Khoat Than"], "title": "Using Synthetic Data to estimate the True Error is theoretically and practically doable", "comment": "To appear at Machine Learning journal and ACML", "summary": "Accurately evaluating model performance is crucial for deploying machine\nlearning systems in real-world applications. Traditional methods often require\na sufficiently large labeled test set to ensure a reliable evaluation. However,\nin many contexts, a large labeled dataset is costly and labor-intensive.\nTherefore, we sometimes have to do evaluation by a few labeled samples, which\nis theoretically challenging. Recent advances in generative models offer a\npromising alternative by enabling the synthesis of high-quality data. In this\nwork, we make a systematic investigation about the use of synthetic data to\nestimate the test error of a trained model under limited labeled data\nconditions. To this end, we develop novel generalization bounds that take\nsynthetic data into account. Those bounds suggest novel ways to optimize\nsynthetic samples for evaluation and theoretically reveal the significant role\nof the generator's quality. Inspired by those bounds, we propose a\ntheoretically grounded method to generate optimized synthetic data for model\nevaluation. Experimental results on simulation and tabular datasets demonstrate\nthat, compared to existing baselines, our method achieves accurate and more\nreliable estimates of the test error.", "AI": {"tldr": "A theory-guided use of synthetic data to estimate test error with limited labels, deriving bounds and an optimization method to generate synthetic samples; shows improved accuracy and reliability over baselines.", "motivation": "Evaluating model performance with few labeled test samples is challenging but common when labeling is costly. Synthetic data from generative models offers a promising workaround, but reliability hinges on the generator and principled data selection.", "method": "Derive generalization bounds that incorporate synthetic data for evaluation. Propose a method to optimize synthetic samples for the purpose of estimating test error, and analyze how the generator's quality affects bounds. Validate the approach experimentally on simulated and tabular datasets, comparing to baselines.", "result": "The proposed method yields more accurate and reliable estimates of test error than existing baselines, with theory showing the generator's quality plays a significant role.", "conclusion": "Theoretical bounds guide the synthesis of evaluation data under label scarcity, and optimized synthetic data can substantially improve evaluation reliability if the generator is of sufficient quality."}}
{"id": "2511.01210", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01210", "abs": "https://arxiv.org/abs/2511.01210", "authors": ["Heyu Guo", "Shanmu Wang", "Ruichun Ma", "Shiqi Jiang", "Yasaman Ghasempour", "Omid Abari", "Baining Guo", "Lili Qi"], "title": "OmniVLA: Unifiying Multi-Sensor Perception for Physically-Grounded Multimodal VLA", "comment": null, "summary": "Vision-language-action (VLA) models have shown strong generalization for\naction prediction through large-scale vision-language pretraining. However,\nmost existing models rely solely on RGB cameras, limiting their perception and,\nconsequently, manipulation capabilities. We present OmniVLA, an omni-modality\nVLA model that integrates novel sensing modalities for physically-grounded\nspatial intelligence beyond RGB perception. The core of our approach is the\nsensor-masked image, a unified representation that overlays spatially grounded\nand physically meaningful masks onto the RGB images, derived from sensors\nincluding an infrared camera, a mmWave radar, and a microphone array. This\nimage-native unification keeps sensor input close to RGB statistics to\nfacilitate training, provides a uniform interface across sensor hardware, and\nenables data-efficient learning with lightweight per-sensor projectors. Built\non this, we present a multisensory vision-language-action model architecture\nand train the model based on an RGB-pretrained VLA backbone. We evaluate\nOmniVLA on challenging real-world tasks where sensor-modality perception is\nneeded to guide the manipulation. OmniVLA achieves an average task success rate\nof 84%, significantly outperforms both RGB-only and raw-sensor-input baseline\nmodels by 59% and 28% respectively, meanwhile showing higher learning\nefficiency and stronger generalization capability.", "AI": {"tldr": "OmniVLA proposes an omni-modality VLA model using sensor-masked images from IR, mmWave radar, and microphone array to enable physically-grounded spatial understanding for action prediction, achieving 84% average task success and outperforming RGB-only and raw-sensor baselines, with data-efficient learning.", "motivation": "RGB-only VLA models limit perception and manipulation; incorporating diverse sensing modalities provides physically meaningful cues for spatial reasoning and interaction in real-world tasks.", "method": "Introduce sensor-masked image: overlay masks derived from infrared, mmWave radar, and microphone sensors onto RGB images to create a unified, image-native representation. Use lightweight per-sensor projectors, align to an RGB-pretrained VLA backbone, and build a multisensory VLA architecture to fuse modalities.", "result": "On real-world tasks requiring sensor-based perception, OmniVLA achieves 84% average task success, outperforming RGB-only baselines by 59% and raw-sensor baselines by 28%, with improved learning efficiency and generalization.", "conclusion": "Demonstrates the viability of omni-modality fusion for vision-language-action tasks; sensor-masked images enable effective cross-modal fusion with minimal per-sensor overhead and enable data-efficient training; suggests future work on expanding modalities and robustness."}}
{"id": "2511.00977", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.00977", "abs": "https://arxiv.org/abs/2511.00977", "authors": ["Kristiyan Sakalyan", "Alessandro Palma", "Filippo Guerranti", "Fabian J. Theis", "Stephan G\u00fcnnemann"], "title": "Modeling Microenvironment Trajectories on Spatial Transcriptomics with NicheFlow", "comment": "37 pages, 15 figures, to appear in NeurIPS 2025", "summary": "Understanding the evolution of cellular microenvironments in spatiotemporal\ndata is essential for deciphering tissue development and disease progression.\nWhile experimental techniques like spatial transcriptomics now enable\nhigh-resolution mapping of tissue organization across space and time, current\nmethods that model cellular evolution operate at the single-cell level,\noverlooking the coordinated development of cellular states in a tissue. We\nintroduce NicheFlow, a flow-based generative model that infers the temporal\ntrajectory of cellular microenvironments across sequential spatial slides. By\nrepresenting local cell neighborhoods as point clouds, NicheFlow jointly models\nthe evolution of cell states and spatial coordinates using optimal transport\nand Variational Flow Matching. Our approach successfully recovers both global\nspatial architecture and local microenvironment composition across diverse\nspatiotemporal datasets, from embryonic to brain development.", "AI": {"tldr": "NicheFlow is a flow-based generative model that infers temporal trajectories of cellular microenvironments across sequential spatial slides, treating local neighborhoods as point clouds and jointly modeling cell-state and spatial-coordinate evolution via optimal transport and Variational Flow Matching, recovering global tissue architecture and local microenvironment composition across diverse spatiotemporal data.", "motivation": "Current methods model cellular evolution at the single-cell level, missing coordinated changes of cellular states within tissue microenvironments across space and time; spatial transcriptomics provides data to study tissue development and disease progression but requires methods that capture spatiotemporal microenvironments.", "method": "Represent local neighborhoods as point clouds and apply a flow-based generative model across sequential slides. Use optimal transport and Variational Flow Matching to jointly model evolution of cell states and spatial coordinates, enabling inference of temporal trajectories of cellular microenvironments.", "result": "The approach recovers both global spatial architecture and local microenvironment composition across diverse spatiotemporal datasets, from embryonic to brain development.", "conclusion": "NicheFlow advances understanding of tissue development and disease progression by modeling coordinated microenvironment evolution, bridging spatial and temporal dynamics in tissue organization."}}
{"id": "2511.01213", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01213", "abs": "https://arxiv.org/abs/2511.01213", "authors": ["Riddhi Jain", "Manasi Patwardhan", "Parijat Deshpande", "Venkataramana Runkana"], "title": "Thought-For-Food: Reasoning Chain Induced Food Visual Question Answering", "comment": "10 pages, 11 figures, 6 tables", "summary": "The immense diversity in the culture and culinary of Indian cuisines calls\nattention to the major shortcoming of the existing Visual Question\nAnswering(VQA) systems which are inclined towards the foods from Western\nregion. Recent attempt towards building a VQA dataset for Indian food is a step\ntowards addressing this challenge. However, their approach towards VQA follows\na two-step process in which the answer is generated first, followed by the\nexplanation of the expected answer. In this work, we claim that food VQA\nrequires to follow a multi-step reasoning process to arrive at an accurate\nanswer, especially in the context of India food, which involves understanding\ncomplex culinary context and identifying relationships between various food\nitems. With this hypothesis we create reasoning chains upon the QA with minimal\nhuman intervention. We fine-tune smaller LLMs and VLMs with auto-validated\nreasoning chains and further train them using reinforcement learning with\nlarger data. With augmentation of reasoning chains, we observed accuracy\nimprovement of an average 10 percentage points on the baseline. We provide\ndetailed analysis in terms the effect of addition of reasoning chains for the\nIndian Food VQA task.\n  Index Terms - FoodVQA, Reasoning Chains, Reinforcement Learning, Knowledge\nGraph.", "AI": {"tldr": "Auto-generated reasoning chains for Indian Food VQA; small models fine-tuned on these chains, trained with RL on larger data; yields ~10pp accuracy gain over baseline.", "motivation": "Indian cuisine is diverse and context-rich; current VQA methods are Western-biased and often rely on a simple two-step QA-explanation pipeline; multi-step reasoning is needed to capture relationships among ingredients, dishes, and culinary context.", "method": "Generate reasoning chains during QA with minimal human intervention; fine-tune smaller LLMs and VLMs using auto-validated reasoning chains; augment training with reinforcement learning on larger datasets; incorporate reasoning chains and potentially knowledge graphs.", "result": "Average accuracy improvement of about 10 percentage points over the baseline; detailed analysis on how adding reasoning chains affects Indian Food VQA performance.", "conclusion": "Reasoning-chain augmentation combined with reinforcement learning improves VQA for Indian foods; approach reduces reliance on very large models and supports richer reasoning; future work includes refining chain quality and exploring knowledge-graph integration."}}
{"id": "2511.00987", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00987", "abs": "https://arxiv.org/abs/2511.00987", "authors": ["Rongrong Xie", "Guido Sanguinetti"], "title": "Balanced Multimodal Learning via Mutual Information", "comment": null, "summary": "Multimodal learning has increasingly become a focal point in research,\nprimarily due to its ability to integrate complementary information from\ndiverse modalities. Nevertheless, modality imbalance, stemming from factors\nsuch as insufficient data acquisition and disparities in data quality, has\noften been inadequately addressed. This issue is particularly prominent in\nbiological data analysis, where datasets are frequently limited, costly to\nacquire, and inherently heterogeneous in quality. Conventional multimodal\nmethodologies typically fall short in concurrently harnessing intermodal\nsynergies and effectively resolving modality conflicts.\n  In this study, we propose a novel unified framework explicitly designed to\naddress modality imbalance by utilizing mutual information to quantify\ninteractions between modalities. Our approach adopts a balanced multimodal\nlearning strategy comprising two key stages: cross-modal knowledge distillation\n(KD) and a multitask-like training paradigm. During the cross-modal KD\npretraining phase, stronger modalities are leveraged to enhance the predictive\ncapabilities of weaker modalities. Subsequently, our primary training phase\nemploys a multitask-like learning mechanism, dynamically calibrating gradient\ncontributions based on modality-specific performance metrics and intermodal\nmutual information. This approach effectively alleviates modality imbalance,\nthereby significantly improving overall multimodal model performance.", "AI": {"tldr": "A two-stage, mutual-information-guided framework that balances multimodal learning by cross-modal knowledge distillation and a dynamic, multitask-like training regime to address modality imbalance.", "motivation": "Modality imbalance due to limited data and varying data quality, especially in biology, leading to suboptimal cross-modal integration.", "method": "Stage 1: cross-modal knowledge distillation where stronger modalities guide weaker ones. Stage 2: multitask-like training that dynamically adjusts gradient contributions using modality-specific performance and inter-modal mutual information. The framework uses mutual information to quantify inter-modality interactions and balance contributions.", "result": "Reported significant performance gains over baselines and ablations, validating the approach's effectiveness in addressing modality imbalance; improved intermodal synergy and conflict resolution.", "conclusion": "A practical, generalizable strategy for robust multimodal learning under modality imbalance, with potential applicability beyond biology."}}
{"id": "2511.00989", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00989", "abs": "https://arxiv.org/abs/2511.00989", "authors": ["Asal Meskin", "Alireza Mirrokni", "Ali Najar", "Ali Behrouz"], "title": "Hydra: Dual Exponentiated Memory for Multivariate Time Series Analysis", "comment": null, "summary": "In recent years, effectively modeling multivariate time series has gained\nsignificant popularity, mainly due to its wide range of applications, ranging\nfrom healthcare to financial markets and energy management. Transformers, MLPs,\nand linear models as the de facto backbones of modern time series models have\nshown promising results in single-variant and/or short-term forecasting. These\nmodels, however: (1) are permutation equivariant and so lack temporal inductive\nbias, being less expressive to capture the temporal dynamics; (2) are naturally\ndesigned for univariate setup, missing the inter-dependencies of temporal and\nvariate dimensions; and/or (3) are inefficient for Long-term time series\nmodeling. To overcome training and inference efficiency as well as the lack of\ntemporal inductive bias, recently, linear Recurrent Neural Networks (RNNs) have\ngained attention as an alternative to Transformer-based models. These models,\nhowever, are inherently limited to a single sequence, missing inter-variate\ndependencies, and can propagate errors due to their additive nature. In this\npaper, we present Hydra, a by-design two-headed meta in-context memory module\nthat learns how to memorize patterns at test time by prioritizing time series\npatterns that are more informative about the data. Hydra uses a 2-dimensional\nrecurrence across both time and variate at each step, which is more powerful\nthan mixing methods. Although the 2-dimensional nature of the model makes its\ntraining recurrent and non-parallelizable, we present a new 2D-chunk-wise\ntraining algorithm that approximates the actual recurrence with $\\times 10$\nefficiency improvement, while maintaining the effectiveness. Our experimental\nresults on a diverse set of tasks and datasets, including time series\nforecasting, classification, and anomaly detection show the superior\nperformance of Hydra compared to state-of-the-art baselines.", "AI": {"tldr": "Hydra introduces a 2D recurrent memory for multivariate time series with a 2D recurrence across time and variates, using a 2D-chunk-wise training that yields ~10x efficiency, and achieves superior performance on forecasting, classification, and anomaly detection.", "motivation": "Transformers, MLPs, and linear models often lack temporal inductive bias and inter-variate coupling for multivariate time series, while traditional linear RNNs are limited to single sequences and prone to error accumulation; there is a need for efficient, temporally aware models that capture inter-variable dependencies.", "method": "A by-design two-headed meta in-context memory module (Hydra) that employs a 2-dimensional recurrence across time and variate at each step. It uses a 2D-chunk-wise training algorithm that approximates the recurrence to achieve approximately 10x efficiency without sacrificing effectiveness.", "result": "Empirical results across diverse tasks and datasets (forecasting, classification, anomaly detection) demonstrate Hydra\u2019s superior performance over state-of-the-art baselines.", "conclusion": "Hydra provides an efficient, temporally biased, multivariate memory mechanism for time-series modeling, enabling strong performance with scalable training, and showing broad applicability across time-series tasks."}}
{"id": "2511.01233", "categories": ["cs.CV", "cs.GR", "cs.HC", "I.3; I.2"], "pdf": "https://arxiv.org/pdf/2511.01233", "abs": "https://arxiv.org/abs/2511.01233", "authors": ["Rajmund Nagy", "Hendric Voss", "Thanh Hoang-Minh", "Mihail Tsakov", "Teodor Nikolov", "Zeyi Zhang", "Tenglong Ao", "Sicheng Yang", "Shaoli Huang", "Yongkang Cheng", "M. Hamza Mughal", "Rishabh Dabral", "Kiran Chhatre", "Christian Theobalt", "Libin Liu", "Stefan Kopp", "Rachel McDonnell", "Michael Neff", "Taras Kucherenko", "Youngwoo Yoon", "Gustav Eje Henter"], "title": "Gesture Generation (Still) Needs Improved Human Evaluation Practices: Insights from a Community-Driven State-of-the-Art Benchmark", "comment": "23 pages, 10 figures. The last two authors made equal contributions", "summary": "We review human evaluation practices in automated, speech-driven 3D gesture\ngeneration and find a lack of standardisation and frequent use of flawed\nexperimental setups. This leads to a situation where it is impossible to know\nhow different methods compare, or what the state of the art is. In order to\naddress common shortcomings of evaluation design, and to standardise future\nuser studies in gesture-generation works, we introduce a detailed human\nevaluation protocol for the widely-used BEAT2 motion-capture dataset. Using\nthis protocol, we conduct large-scale crowdsourced evaluation to rank six\nrecent gesture-generation models -- each trained by its original authors --\nacross two key evaluation dimensions: motion realism and speech-gesture\nalignment. Our results provide strong evidence that 1) newer models do not\nconsistently outperform earlier approaches; 2) published claims of high motion\nrealism or speech-gesture alignment may not hold up under rigorous evaluation;\nand 3) the field must adopt disentangled assessments of motion quality and\nmultimodal alignment for accurate benchmarking in order to make progress.\nFinally, in order to drive standardisation and enable new evaluation research,\nwe will release five hours of synthetic motion from the benchmarked models;\nover 750 rendered video stimuli from the user studies -- enabling new\nevaluations without model reimplementation required -- alongside our\nopen-source rendering script, and the 16,000 pairwise human preference votes\ncollected for our benchmark.", "AI": {"tldr": "Standardized human evaluation protocol for BEAT2-based gesture generation reveals inconsistencies in current evaluation practices; newer models do not consistently outperform older ones; emphasizes disentangled assessment of motion realism and speech-gesture alignment and provides benchmarking resources.", "motivation": "Address the lack of standardization and flawed experimental setups in evaluating automated, speech-driven 3D gesture generation, which hinders meaningful comparisons and progress.", "method": "Develop and apply a detailed human evaluation protocol for the BEAT2 motion-capture dataset; perform large-scale crowdsourced evaluation comparing six models on motion realism and speech-gesture alignment; release evaluation resources.", "result": "Evidence that newer models do not consistently outperform older ones; published claims of high realism or alignment may not hold under rigorous evaluation; disentangled evaluation of motion quality and multimodal alignment is necessary; provides benchmarking resources (synthetic motion, stimuli, rendering script, and 16,000 votes).", "conclusion": "Standardized, disentangled evaluation is essential for meaningful progress in gesture-generation research; the authors provide data and tools to enable ongoing benchmarking without reimplementation."}}
{"id": "2511.01006", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01006", "abs": "https://arxiv.org/abs/2511.01006", "authors": ["Diantong Li", "Kyunghyun Cho", "Chong Liu"], "title": "None To Optima in Few Shots: Bayesian Optimization with MDP Priors", "comment": null, "summary": "Bayesian Optimization (BO) is an efficient tool for optimizing black-box\nfunctions, but its theoretical guarantees typically hold in the asymptotic\nregime. In many critical real-world applications such as drug discovery or\nmaterials design, where each evaluation can be very costly and time-consuming,\nBO becomes impractical for many evaluations. In this paper, we introduce the\nProcedure-inFormed BO (ProfBO) algorithm, which solves black-box optimization\nwith remarkably few function evaluations. At the heart of our algorithmic\ndesign are Markov Decision Process (MDP) priors that model optimization\ntrajectories from related source tasks, thereby capturing procedural knowledge\non efficient optimization. We embed these MDP priors into a prior-fitted neural\nnetwork and employ model-agnostic meta-learning for fast adaptation to new\ntarget tasks. Experiments on real-world Covid and Cancer benchmarks and\nhyperparameter tuning tasks demonstrate that ProfBO consistently outperforms\nstate-of-the-art methods by achieving high-quality solutions with significantly\nfewer evaluations, making it ready for practical deployment.", "AI": {"tldr": "ProfBO uses prior-informed MDPs and meta-learning to achieve sample-efficient Bayesian optimization, outperforming baselines on biomedical and hyperparameter tasks.", "motivation": "Bayesian optimization is powerful but often requires many evaluations; in costly real-world settings (drug discovery, materials design), reducing evaluations is critical. Leverage procedural knowledge from related tasks to guide optimization.", "method": "Construct MDP priors from related source tasks to capture optimization trajectories; embed these priors into a prior-fitted neural network; apply model-agnostic meta-learning (MAML) for fast adaptation to new target tasks; evaluate on real-world Covid/Cancer benchmarks and hyperparameter tuning.", "result": "ProfBO consistently outperforms state-of-the-art BO methods, achieving high-quality solutions with significantly fewer evaluations and demonstrating readiness for practical deployment.", "conclusion": "MDP-prior informed meta-learning enables highly sample-efficient BO for high-cost black-box problems, enabling practical deployment in domains like healthcare and materials design."}}
{"id": "2511.01237", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01237", "abs": "https://arxiv.org/abs/2511.01237", "authors": ["Vishakha Lall", "Yisi Liu"], "title": "Eyes on Target: Gaze-Aware Object Detection in Egocentric Video", "comment": "Accepted at RAAI 2025", "summary": "Human gaze offers rich supervisory signals for understanding visual attention\nin complex visual environments. In this paper, we propose Eyes on Target, a\nnovel depth-aware and gaze-guided object detection framework designed for\negocentric videos. Our approach injects gaze-derived features into the\nattention mechanism of a Vision Transformer (ViT), effectively biasing spatial\nfeature selection toward human-attended regions. Unlike traditional object\ndetectors that treat all regions equally, our method emphasises\nviewer-prioritised areas to enhance object detection. We validate our method on\nan egocentric simulator dataset where human visual attention is critical for\ntask assessment, illustrating its potential in evaluating human performance in\nsimulation scenarios. We evaluate the effectiveness of our gaze-integrated\nmodel through extensive experiments and ablation studies, demonstrating\nconsistent gains in detection accuracy over gaze-agnostic baselines on both the\ncustom simulator dataset and public benchmarks, including Ego4D Ego-Motion and\nEgo-CH-Gaze datasets. To interpret model behaviour, we also introduce a\ngaze-aware attention head importance metric, revealing how gaze cues modulate\ntransformer attention dynamics.", "AI": {"tldr": "A gaze-guided, depth-aware ViT detector for egocentric video that injects gaze-derived features into attention, yielding improved detection accuracy and interpretability across Ego4D and simulator datasets.", "motivation": "Leverage human gaze as supervisory signal to bias attention toward regions of interest in complex egocentric scenes, addressing the limitation of gaze-agnostic detectors that treat all regions equally.", "method": "A depth-aware, gaze-guided object detection framework (Eyes on Target) that injects gaze-derived features into the attention mechanism of a Vision Transformer (ViT), biasing spatial feature selection toward human-attended regions; includes a gaze-aware attention head importance metric and extensive ablations.", "result": "Demonstrates consistent gains in detection accuracy over gaze-agnostic baselines on a custom egocentric simulator dataset and public benchmarks (Ego4D Ego-Motion and Ego-CH-Gaze); ablations quantify the contribution of gaze cues and depth; introduces an interpretable metric to relate gaze cues to transformer attention.", "conclusion": "Gaze cues can effectively bias transformer attention to improve detection performance in egocentric videos and provide interpretable insights into attention dynamics; this approach also supports evaluating human performance in simulation scenarios."}}
{"id": "2511.01009", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01009", "abs": "https://arxiv.org/abs/2511.01009", "authors": ["Fabricio Olivetti de Franca", "Gabriel Kronberger"], "title": "Equality Graph Assisted Symbolic Regression", "comment": null, "summary": "In Symbolic Regression (SR), Genetic Programming (GP) is a popular search\nalgorithm that delivers state-of-the-art results in term of accuracy. Its\nsuccess relies on the concept of neutrality, which induces large plateaus that\nthe search can safely navigate to more promising regions. Navigating these\nplateaus, while necessary, requires the computation of redundant expressions,\nup to 60% of the total number of evaluation, as noted in a recent study. The\nequality graph (e-graph) structure can compactly store and group equivalent\nexpressions enabling us to verify if a given expression and their variations\nwere already visited by the search, thus enabling us to avoid unnecessary\ncomputation. We propose a new search algorithm for symbolic regression called\nSymRegg that revolves around the e-graph structure following simple steps:\nperturb solutions sampled from a selection of expressions stored in the\ne-graph, if it generates an unvisited expression, insert it into the e-graph\nand generates its equivalent forms. We show that SymRegg is capable of\nimproving the efficiency of the search, maintaining consistently accurate\nresults across different datasets while requiring a choice of a minimalist set\nof hyperparameters.", "AI": {"tldr": "An e-graph\u2013based search (SymRegg) for symbolic regression using GP to reduce redundant evaluations and navigate neutrality plateaus, achieving efficiency with a small hyperparameter set while preserving accuracy.", "motivation": "In Symbolic Regression with Genetic Programming, neutrality creates large search plateaus, leading to many redundant evaluations (reported as up to ~60% of total evaluations). The e-graph structure can compactly store and group equivalent expressions, enabling the search to avoid re-evaluating expressions it has already visited.", "method": "Introduce SymRegg, a search algorithm that uses an e-graph to store expressions. Perturb solutions sampled from expressions in the e-graph; if a perturbation yields an unvisited expression, insert it into the e-graph and generate its equivalent forms. This process reduces redundant evaluations by exploiting equivalence classes, with a minimalist hyperparameter set.", "result": "SymRegg is reported to improve search efficiency while maintaining consistently accurate results across different datasets, and it relies on a minimalist set of hyperparameters.", "conclusion": "An e-graph\u2013based approach (SymRegg) can enhance GP-driven symbolic regression by pruning redundant evaluations, effectively navigating neutrality plateaus and maintaining accuracy with few hyperparameters."}}
{"id": "2511.01240", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01240", "abs": "https://arxiv.org/abs/2511.01240", "authors": ["Zhixuan Zhang", "Pingyu Wang", "Xingjian Zheng", "Linbo Qing", "Qi Liu"], "title": "Beyond Deceptive Flatness: Dual-Order Solution for Strengthening Adversarial Transferability", "comment": "Accepted by Pattern Recognition in Nov 01,2025", "summary": "Transferable attacks generate adversarial examples on surrogate models to\nfool unknown victim models, posing real-world threats and growing research\ninterest. Despite focusing on flat losses for transferable adversarial\nexamples, recent studies still fall into suboptimal regions, especially the\nflat-yet-sharp areas, termed as deceptive flatness. In this paper, we introduce\na novel black-box gradient-based transferable attack from a perspective of\ndual-order information. Specifically, we feasibly propose Adversarial Flatness\n(AF) to the deceptive flatness problem and a theoretical assurance for\nadversarial transferability. Based on this, using an efficient approximation of\nour objective, we instantiate our attack as Adversarial Flatness Attack (AFA),\naddressing the altered gradient sign issue. Additionally, to further improve\nthe attack ability, we devise MonteCarlo Adversarial Sampling (MCAS) by\nenhancing the inner-loop sampling efficiency. The comprehensive results on\nImageNet-compatible dataset demonstrate superiority over six baselines,\ngenerating adversarial examples in flatter regions and boosting transferability\nacross model architectures. When tested on input transformation attacks or the\nBaidu Cloud API, our method outperforms baselines.", "AI": {"tldr": "Proposes Adversarial Flatness Attack (AFA) to address deceptive flatness in transferable adversarial attacks, introducing Adversarial Flatness (AF) and MonteCarlo Adversarial Sampling (MCAS) to improve black-box transferability; provides theoretical guarantees and shows empirical gains on ImageNet-compatible data against multiple baselines and defenses.", "motivation": "Transferable adversarial examples are effective but often get stuck in flat yet non-transferable regions (deceptive flatness). There is a need for methods that identify and exploit flatter regions under black-box conditions to improve cross-model transferability.", "method": "Introduce Adversarial Flatness (AF) to tackle deceptive flatness; instantiate as Adversarial Flatness Attack (AFA) with a practical objective approximation and corrected gradient-sign behavior; develop MonteCarlo Adversarial Sampling (MCAS) to enhance inner-loop sampling efficiency.", "result": "Empirical results on ImageNet-compatible datasets show AFA/MCAS outperform six baselines, producing adversarial examples in flatter regions and improving transferability across model architectures; also effective against input transformation attacks and Baidu Cloud API.", "conclusion": "AF provides a theoretical and practical framework for improving black-box transferability by targeting flatness properties; the combined AFA and MCAS yield stronger transferable attacks across diverse settings, suggesting broader applicability and potential future extensions."}}
{"id": "2511.01015", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01015", "abs": "https://arxiv.org/abs/2511.01015", "authors": ["Nabeel Seedat", "Jiashuo Liu", "Mihaela van der Schaar"], "title": "What's the next frontier for Data-centric AI? Data Savvy Agents", "comment": "Presented at ICLR 2025 Data-FM. Seedat & Liu contributed equally", "summary": "The recent surge in AI agents that autonomously communicate, collaborate with\nhumans and use diverse tools has unlocked promising opportunities in various\nreal-world settings. However, a vital aspect remains underexplored: how agents\nhandle data. Scalable autonomy demands agents that continuously acquire,\nprocess, and evolve their data. In this paper, we argue that data-savvy\ncapabilities should be a top priority in the design of agentic systems to\nensure reliable real-world deployment. Specifically, we propose four key\ncapabilities to realize this vision: (1) Proactive data acquisition: enabling\nagents to autonomously gather task-critical knowledge or solicit human input to\naddress data gaps; (2) Sophisticated data processing: requiring context-aware\nand flexible handling of diverse data challenges and inputs; (3) Interactive\ntest data synthesis: shifting from static benchmarks to dynamically generated\ninteractive test data for agent evaluation; and (4) Continual adaptation:\nempowering agents to iteratively refine their data and background knowledge to\nadapt to shifting environments. While current agent research predominantly\nemphasizes reasoning, we hope to inspire a reflection on the role of data-savvy\nagents as the next frontier in data-centric AI.", "AI": {"tldr": "Proposes a four-capability framework to make autonomous agents data-savvy: proactive data acquisition, sophisticated data processing, interactive test data synthesis, and continual adaptation.", "motivation": "To enable scalable, reliable real-world deployment of AI agents by focusing on how agents acquire, process, and evolve data, addressing gaps left by current reasoning-centric work.", "method": "Conceptual framework that defines four data-centric capabilities, with design considerations and a shift in evaluation toward dynamic, interactive data rather than static benchmarks.", "result": "Articulates a vision and justification for data-savvy agents; no empirical results are reported in the abstract.", "conclusion": "Data-focused capabilities should be prioritized in agent design; data-centric AI is the next frontier for reliable, real-world deployment."}}
{"id": "2511.01243", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01243", "abs": "https://arxiv.org/abs/2511.01243", "authors": ["Yu Tian", "Zhongheng Yang", "Chenshi Liu", "Yiyun Su", "Ziwei Hong", "Zexi Gong", "Jingyuan Xu"], "title": "CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation", "comment": null, "summary": "Brain lesion segmentation remains challenging due to small, low-contrast\nlesions, anisotropic sampling, and cross-slice discontinuities. We propose\nCenterMamba-SAM, an end-to-end framework that freezes a pretrained backbone and\ntrains only lightweight adapters for efficient fine-tuning. At its core is the\nCenterMamba encoder, which employs a novel 3x3 corner-axis-center\nshort-sequence scanning strategy to enable center-prioritized, axis-reinforced,\nand diagonally compensated information aggregation. This design enhances\nsensitivity to weak boundaries and tiny foci while maintaining sparse yet\neffective feature representation. A memory-driven structural prompt generator\nmaintains a prototype bank across neighboring slices, enabling automatic\nsynthesis of reliable prompts without user interaction, thereby improving\ninter-slice coherence. The memory-augmented multi-scale decoder integrates\nmemory attention modules at multiple levels, combining deep supervision with\nprogressive refinement to restore fine details while preserving global\nconsistency. Extensive experiments on public benchmarks demonstrate that\nCenterMamba-SAM achieves state-of-the-art performance in brain lesion\nsegmentation.", "AI": {"tldr": "CenterMamba-SAM delivers state-of-the-art brain lesion segmentation by freezing a pretrained backbone, fine-tuning lightweight adapters, and employing a CenterMamba encoder with corner-axis-center short-sequence scanning, memory-driven structural prompts for inter-slice coherence, and a memory-augmented multi-scale decoder for detailed, globally consistent segmentation.", "motivation": "To address small, low-contrast lesions, anisotropic sampling, and cross-slice discontinuities that hinder accurate segmentation; the goal is to enhance center-prioritized information aggregation and inter-slice coherence while keeping efficient fine-tuning.", "method": "End-to-end framework CenterMamba-SAM: (1) freeze backbone, train adapters; CenterMamba encoder with 3x3 corner-axis-center short-sequence scanning; memory-driven structural prompt generator with prototype bank across neighboring slices; memory-augmented multi-scale decoder with memory attention and deep supervision for progressive refinement.", "result": "Achieves state-of-the-art performance on public brain lesion segmentation benchmarks.", "conclusion": "The architecture improves weak boundary sensitivity and tiny foci detection, preserves sparse representations, and delivers coherent, high-quality segmentations across slices."}}
{"id": "2511.01017", "categories": ["cs.LG", "62M10, 62P12", "G.3; H.2.8"], "pdf": "https://arxiv.org/pdf/2511.01017", "abs": "https://arxiv.org/abs/2511.01017", "authors": ["Haoran Ye", "Qiuzhuang Sun", "Yang Yang"], "title": "SARIMAX-Based Power Outage Prediction During Extreme Weather Events", "comment": "12 pages, 3 figures. This paper presents the solution of Team 12 for\n  the 2025 INFORMS Data Mining Society Data Challenge. The open-source code is\n  available at: https://github.com/yhr-code/2025-INFORMS-DM-Challenge-Team12", "summary": "This study develops a SARIMAX-based prediction system for short-term power\noutage forecasting during extreme weather events. Using hourly data from\nMichigan counties with outage counts and comprehensive weather features, we\nimplement a systematic two-stage feature engineering pipeline: data cleaning to\nremove zero-variance and unknown features, followed by correlation-based\nfiltering to eliminate highly correlated predictors. The selected features are\naugmented with temporal embeddings, multi-scale lag features, and weather\nvariables with their corresponding lags as exogenous inputs to the SARIMAX\nmodel. To address data irregularity and numerical instability, we apply\nstandardization and implement a hierarchical fitting strategy with sequential\noptimization methods, automatic downgrading to ARIMA when convergence fails,\nand historical mean-based fallback predictions as a final safeguard. The model\nis optimized separately for short-term (24 hours) and medium-term (48 hours)\nforecast horizons using RMSE as the evaluation metric. Our approach achieves an\nRMSE of 177.2, representing an 8.4\\% improvement over the baseline method (RMSE\n= 193.4), thereby validating the effectiveness of our feature engineering and\nrobust optimization strategy for extreme weather-related outage prediction.", "AI": {"tldr": "A SARIMAX-based framework with extensive feature engineering and robust optimization improves short-term and 48-hour outage forecasts during extreme weather, achieving RMSE 177.2 (8.4% better than baseline 193.4).", "motivation": "Forecasts of power outages during extreme weather enable grid resilience and proactive mitigation. A SARIMAX model with exogenous weather inputs, combined with systematic feature engineering and robust optimization, can handle irregular data and improve predictive accuracy.", "method": "1) Data cleaning to remove zero-variance and unknown features. 2) Correlation-based feature filtering to reduce multicollinearity. 3) Feature augmentation with temporal embeddings, multi-scale lag features, and weather variables with lags as exogenous inputs. 4) Standardization for numerical stability. 5) Hierarchical fitting with sequential optimization, automatic downgrading to ARIMA if convergence fails, and historical-mean fallback. 6) Separate optimization for short-term (24h) and medium-term (48h) horizons using RMSE. ", "result": "The approach achieves RMSE of 177.2 for outage prediction, an 8.4% improvement over a baseline RMSE of 193.4, validating the feature engineering and robust optimization strategy.", "conclusion": "The proposed pipeline effectively improves extreme-weather outage forecasting performance, with a robust fitting strategy that handles data irregularities and enhances short- and medium-term predictions. Potential generalization to other regions and resilience applications."}}
{"id": "2511.01250", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01250", "abs": "https://arxiv.org/abs/2511.01250", "authors": ["YoungJae Cheong", "Jhonghyun An"], "title": "Source-Only Cross-Weather LiDAR via Geometry-Aware Point Drop", "comment": null, "summary": "LiDAR semantic segmentation degrades in adverse weather because refraction,\nscattering, and point dropouts corrupt geometry. Prior work in weather\nsimulation, mixing-based augmentation, domain randomization, and uncertainty or\nboundary regularization improves robustness but still overlooks structural\nvulnerabilities near boundaries, corners, and sparse regions. We present a\nLight Geometry-aware adapter. The module aligns azimuth and applies horizontal\ncircular padding to preserve neighbor continuity across the 0~360 degree\nwrap-around boundary. A local-window K-Nearest Neighbors gathers nearby points\nand computes simple local statistics, which are compressed into compact\ngeometry-aware cues. During training, these cues drive region-aware\nregularization that stabilizes predictions in structurally fragile areas. The\nadapter is plug and play, complements augmentation, and can be enabled only\nduring training with negligible inference cost. We adopt a source-only\ncross-weather setup where models train on SemanticKITTI and are evaluated on\nSemanticSTF without target labels or fine-tuning. The adapter improves mIoU by\n7.9 percentage points over the data-centric augmentation baseline and by 0.6\npoints over the class-centric regularization baseline. These results indicate\nthat geometry-driven regularization is a key direction for all-weather LiDAR\nsegmentation.", "AI": {"tldr": "A Light Geometry-aware adapter improves all-weather LiDAR segmentation by training-time geometry cues, yielding significant cross-weather gains (up to +7.9 mIoU over augmentation baselines).", "motivation": "LiDAR semantic segmentation degrades in adverse weather due to refraction, scattering, and point dropouts. Prior robustness methods address data issues but miss vulnerabilities near boundaries, corners, and sparse regions.", "method": "Introduce a plug-in module that (1) aligns azimuth with horizontal circular padding to preserve wrap-around continuity, (2) uses a local-window KNN to gather neighbors and compute simple local statistics, and (3) compresses these into geometry-aware cues. During training, cues drive region-aware regularization to stabilize predictions in structurally fragile areas. It is train-only and inference-friendly, and evaluated in a source-only cross-weather setup (train on SemanticKITTI, evaluate on SemanticSTF) without target labels or fine-tuning.", "result": "The adapter achieves +7.9 percentage points in mIoU over a data-centric augmentation baseline and +0.6 points over a class-centric regularization baseline in the cross-weather setting.", "conclusion": "Geometry-driven regularization is a key direction for improving all-weather LiDAR segmentation."}}
{"id": "2511.01054", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01054", "abs": "https://arxiv.org/abs/2511.01054", "authors": ["Sama Salarian", "Yue Zhang", "Swati Padhee", "Srinivasan Parthasarathy"], "title": "MedEqualizer: A Framework Investigating Bias in Synthetic Medical Data and Mitigation via Augmentation", "comment": null, "summary": "Synthetic healthcare data generation presents a viable approach to enhance\ndata accessibility and support research by overcoming limitations associated\nwith real-world medical datasets. However, ensuring fairness across protected\nattributes in synthetic data is critical to avoid biased or misleading results\nin clinical research and decision-making. In this study, we assess the fairness\nof synthetic data generated by multiple generative adversarial network\n(GAN)-based models using the MIMIC-III dataset, with a focus on\nrepresentativeness across protected demographic attributes. We measure subgroup\nrepresentation using the logarithmic disparity metric and observe significant\nimbalances, with many subgroups either underrepresented or overrepresented in\nthe synthetic data, compared to the real data. To mitigate these disparities,\nwe introduce MedEqualizer, a model-agnostic augmentation framework that\nenriches the underrepresented subgroups prior to synthetic data generation. Our\nresults show that MedEqualizer significantly improves demographic balance in\nthe resulting synthetic datasets, offering a viable path towards more equitable\nand representative healthcare data synthesis.", "AI": {"tldr": "GAN-based synthetic healthcare data reveal fairness gaps across protected demographics in MIMIC-III; MedEqualizer, a model-agnostic augmentation framework, improves representation of underrepresented subgroups before generation, yielding more balanced synthetic data.", "motivation": "To enable accessible and useful synthetic healthcare data without bias, ensuring fair representation of protected attributes so clinical research and decisions are not distorted by imbalanced synthetic datasets.", "method": "Assess multiple GAN-based generative models on MIMIC-III. Use logarithmic disparity to quantify subgroup representation. Identify under-/overrepresented subgroups. Propose MedEqualizer, an augmentation framework that enriches underrepresented subgroups prior to synthetic data generation, and evaluate its impact on synthetic data fairness.", "result": "MedEqualizer substantially improves demographic balance in the resulting synthetic datasets, addressing disparities observed in baseline GAN-generated data.", "conclusion": "MedEqualizer provides a practical, model-agnostic route to fairer, more representative healthcare data synthesis and can be extended to other datasets and protected attributes."}}
{"id": "2511.01266", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01266", "abs": "https://arxiv.org/abs/2511.01266", "authors": ["Joonghyuk Shin", "Zhengqi Li", "Richard Zhang", "Jun-Yan Zhu", "Jaesik Park", "Eli Schechtman", "Xun Huang"], "title": "MotionStream: Real-Time Video Generation with Interactive Motion Controls", "comment": "Project webpage: https://joonghyuk.com/motionstream-web/", "summary": "Current motion-conditioned video generation methods suffer from prohibitive\nlatency (minutes per video) and non-causal processing that prevents real-time\ninteraction. We present MotionStream, enabling sub-second latency with up to 29\nFPS streaming generation on a single GPU. Our approach begins by augmenting a\ntext-to-video model with motion control, which generates high-quality videos\nthat adhere to the global text prompt and local motion guidance, but does not\nperform inference on the fly. As such, we distill this bidirectional teacher\ninto a causal student through Self Forcing with Distribution Matching\nDistillation, enabling real-time streaming inference. Several key challenges\narise when generating videos of long, potentially infinite time-horizons: (1)\nbridging the domain gap from training on finite length and extrapolating to\ninfinite horizons, (2) sustaining high quality by preventing error\naccumulation, and (3) maintaining fast inference, without incurring growth in\ncomputational cost due to increasing context windows. A key to our approach is\nintroducing carefully designed sliding-window causal attention, combined with\nattention sinks. By incorporating self-rollout with attention sinks and KV\ncache rolling during training, we properly simulate inference-time\nextrapolations with a fixed context window, enabling constant-speed generation\nof arbitrarily long videos. Our models achieve state-of-the-art results in\nmotion following and video quality while being two orders of magnitude faster,\nuniquely enabling infinite-length streaming. With MotionStream, users can paint\ntrajectories, control cameras, or transfer motion, and see results unfold in\nreal-time, delivering a truly interactive experience.", "AI": {"tldr": "MotionStream enables sub-second, real-time, infinite-horizon motion-conditioned video streaming by distilling a non-causal teacher into a causal student using Self Forcing with Distribution Matching Distillation, aided by sliding-window attention and KV cache rolling, achieving up to 29 FPS on a single GPU.", "motivation": "Existing motion-conditioned video generation suffers from prohibitive latency (minutes per video) and non-causal processing that blocks interactive use; there is a need for real-time, streaming, interactive video synthesis.", "method": "Train a non-causal, bidirectional teacher for motion-conditioned video with global text prompts and local motion guidance; perform Self Forcing with Distribution Matching Distillation to train a causal student; implement sliding-window causal attention, attention sinks, self-rollout, and KV cache rolling during training to simulate inference with a fixed context window; enable constant-speed generation of arbitrarily long videos.", "result": "State-of-the-art in motion following and video quality; two orders of magnitude faster than previous methods; uniquely supports infinite-length streaming with real-time generation (~29 FPS on a single GPU).", "conclusion": "MotionStream enables interactive, real-time video synthesis for tasks like painting trajectories, camera control, and motion transfer, delivering results in real-time and enabling a truly interactive experience."}}
{"id": "2511.01060", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01060", "abs": "https://arxiv.org/abs/2511.01060", "authors": ["Andrew Hallam", "R G Gayathri", "Glory Lee", "Atul Sajjanhar"], "title": "Window-Based Feature Engineering for Cognitive Workload Detection", "comment": "9 pages, 3 figures", "summary": "Cognitive workload is a topic of increasing interest across various fields\nsuch as health, psychology, and defense applications. In this research, we\nfocus on classifying cognitive workload using the COLET dataset, employing a\nwindow-based approach for feature generation and machine/deep learning\ntechniques for classification. We apply window-based temporal partitioning to\nenhance features used in existing research, followed by machine learning and\ndeep learning models to classify different levels of cognitive workload. The\nresults demonstrate that deep learning models, particularly tabular\narchitectures, outperformed traditional machine learning methods in precision,\nF1-score, accuracy, and classification precision. This study highlights the\neffectiveness of window-based temporal feature extraction and the potential of\ndeep learning techniques for real-time cognitive workload assessment in complex\nand dynamic tasks.", "AI": {"tldr": "Window-based temporal feature extraction on the COLET dataset with ML/DL classifiers; deep/tabular DL models outperform traditional ML across precision, F1, and accuracy, enabling real-time cognitive workload assessment.", "motivation": "Cognitive workload is critical across health, psychology, and defense; accurate, real-time assessment is needed. The COLET dataset and windowed features aim to capture temporal context to improve classification performance over existing methods.", "method": "Apply window-based temporal partitioning to COLET to generate features, then train both traditional machine learning models and deep learning models (notably tabular architectures) for classifying cognitive workload levels; compare performance using standard metrics.", "result": "Deep learning models, especially tabular architectures, outperform traditional ML methods in precision, F1-score, accuracy, and overall classification performance.", "conclusion": "Window-based temporal feature extraction combined with deep learning is effective for cognitive workload classification on COLET and shows potential for real-time assessment in dynamic tasks; future work could explore more datasets, model interpretability, and real-time deployment considerations."}}
{"id": "2511.01274", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01274", "abs": "https://arxiv.org/abs/2511.01274", "authors": ["Tan Tang", "Yanhong Wu", "Junming Gao", "Yingcai Wu"], "title": "PRevivor: Reviving Ancient Chinese Paintings using Prior-Guided Color Transformers", "comment": null, "summary": "Ancient Chinese paintings are a valuable cultural heritage that is damaged by\nirreversible color degradation. Reviving color-degraded paintings is\nextraordinarily difficult due to the complex chemistry mechanism. Progress is\nfurther slowed by the lack of comprehensive, high-quality datasets, which\nhampers the creation of end-to-end digital restoration tools. To revive colors,\nwe propose PRevivor, a prior-guided color transformer that learns from recent\npaintings (e.g., Ming and Qing Dynasty) to restore ancient ones (e.g., Tang and\nSong Dynasty). To develop PRevivor, we decompose color restoration into two\nsequential sub-tasks: luminance enhancement and hue correction. For luminance\nenhancement, we employ two variational U-Nets and a multi-scale mapping module\nto translate faded luminance into restored counterparts. For hue correction, we\ndesign a dual-branch color query module guided by localized hue priors\nextracted from faded paintings. Specifically, one branch focuses attention on\nregions guided by masked priors, enforcing localized hue correction, whereas\nthe other branch remains unconstrained to maintain a global reasoning\ncapability. To evaluate PRevivor, we conduct extensive experiments against\nstate-of-the-art colorization methods. The results demonstrate superior\nperformance both quantitatively and qualitatively.", "AI": {"tldr": "PRevivor is a prior-guided color transformer for ancient Chinese paintings that decomposes color restoration into luminance enhancement and hue correction, using variational U-Nets and a dual-branch color query module guided by localized hue priors. It leverages recent paintings (Ming/Qing) as priors to restore older ones (Tang/Song) and outperforms state-of-the-art colorization methods in experiments.", "motivation": "Ancient paintings suffer irreversible color degradation and current datasets and end-to-end restoration tools are lacking. The work aims to exploit priors from recently preserved paintings to guide restoration of older works, addressing both luminance fading and hue distortion with a structured, learnable approach.", "method": "1) Luminance enhancement via two variational U-Nets and a multi-scale mapping module to translate faded luminance to restored luminance. 2) Hue correction via a dual-branch color query module: one branch uses masked priors to enforce localized hue correction, the other branch is unconstrained to preserve global reasoning. The priors are localized hue priors extracted from faded paintings. Training uses recent Ming/Qing paintings to restore Tang/Song pieces. Evaluation against state-of-the-art colorization methods.", "result": "Experiments show superior performance both quantitatively and qualitatively compared to state-of-the-art colorization methods.", "conclusion": "PRevivor demonstrates that a prior-guided, two-stage color restoration framework can effectively revive colors in degraded ancient paintings. The combination of luminance-focused enhancement and pose-aware hue correction with priors enables better restoration quality and suggests a viable path for end-to-end digital restoration tools in cultural heritage contexts."}}
{"id": "2511.01061", "categories": ["cs.LG", "cs.AI", "68T07", "I.2.0"], "pdf": "https://arxiv.org/pdf/2511.01061", "abs": "https://arxiv.org/abs/2511.01061", "authors": ["Przemys\u0142aw Spyra", "Witold Dzwinel"], "title": "Energy-Efficient Deep Learning Without Backpropagation: A Rigorous Evaluation of Forward-Only Algorithms", "comment": null, "summary": "The long-held assumption that backpropagation (BP) is essential for\nstate-of-the-art performance is challenged by this work. We present rigorous,\nhardware-validated evidence that the Mono-Forward (MF) algorithm, a\nbackpropagation-free method, consistently surpasses an optimally tuned BP\nbaseline in classification accuracy on its native Multi-Layer Perceptron (MLP)\narchitectures. This superior generalization is achieved with profound\nefficiency gains, including up to 41% less energy consumption and up to 34%\nfaster training. Our analysis, which charts an evolutionary path from Geoffrey\nHinton's Forward-Forward (FF) to the Cascaded Forward (CaFo) and finally to MF,\nis grounded in a fair comparative framework using identical architectures and\nuniversal hyperparameter optimization. We further provide a critical\nre-evaluation of memory efficiency in BP-free methods, empirically\ndemonstrating that practical overhead can offset theoretical gains. Ultimately,\nthis work establishes MF as a practical, high-performance, and sustainable\nalternative to BP for MLPs.", "AI": {"tldr": "A backpropagation-free Mono-Forward (MF) algorithm outperforms an optimally tuned BP baseline on MLPs, with substantial energy and speed gains, while challenging common beliefs about BP's necessity.", "motivation": "Question the indispensability of backpropagation for state-of-the-art performance; provide hardware-validated evidence of BP-free learning achieving better generalization; re-evaluate memory efficiency and practical overhead in BP-free methods.", "method": "Compare MF across native MLP architectures to a tuned BP baseline using identical models and universal hyperparameter optimization; measure accuracy, energy, training time; trace the evolutionary path FF -> CaFo -> MF; assess memory implications empirically.", "result": "MF consistently achieves higher classification accuracy than tuned BP on MLPs; energy consumption reduced up to 41%; training time reduced up to 34%; memory considerations reveal practical overhead can offset theoretical gains; generalization improvements observed.", "conclusion": "MF emerges as a viable, high-performance, and sustainable alternative to BP for MLPs, with a documented evolutionary lineage and practical guidelines, albeit with caveats around memory efficiency."}}
{"id": "2511.01284", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01284", "abs": "https://arxiv.org/abs/2511.01284", "authors": ["Karma Phuntsho", "Abdullah", "Kyungmi Lee", "Ickjai Lee", "Euijoon Ahn"], "title": "Adaptation of Foundation Models for Medical Image Analysis: Strategies, Challenges, and Future Directions", "comment": null, "summary": "Foundation models (FMs) have emerged as a transformative paradigm in medical\nimage analysis, offering the potential to provide generalizable, task-agnostic\nsolutions across a wide range of clinical tasks and imaging modalities. Their\ncapacity to learn transferable representations from large-scale data has the\npotential to address the limitations of conventional task-specific models.\nHowever, adaptation of FMs to real-world clinical practice remains constrained\nby key challenges, including domain shifts, limited availability of\nhigh-quality annotated data, substantial computational demands, and strict\nprivacy requirements. This review presents a comprehensive assessment of\nstrategies for adapting FMs to the specific demands of medical imaging. We\nexamine approaches such as supervised fine-tuning, domain-specific pretraining,\nparameter-efficient fine-tuning, self-supervised learning, hybrid methods, and\nmultimodal or cross-modal frameworks. For each, we evaluate reported\nperformance gains, clinical applicability, and limitations, while identifying\ntrade-offs and unresolved challenges that prior reviews have often overlooked.\nBeyond these established techniques, we also highlight emerging directions\naimed at addressing current gaps. These include continual learning to enable\ndynamic deployment, federated and privacy-preserving approaches to safeguard\nsensitive data, hybrid self-supervised learning to enhance data efficiency,\ndata-centric pipelines that combine synthetic generation with human-in-the-loop\nvalidation, and systematic benchmarking to assess robust generalization under\nreal-world clinical variability. By outlining these strategies and associated\nresearch gaps, this review provides a roadmap for developing adaptive,\ntrustworthy, and clinically integrated FMs capable of meeting the demands of\nreal-world medical imaging.", "AI": {"tldr": "Foundation models show promise for generalizable medical imaging tasks but require strategies to tackle domain shifts, data scarcity, privacy, and compute; a multi-faceted roadmap (continual learning, federated privacy, data-centric pipelines, benchmarking) is proposed.", "motivation": "Bridge the gap between FM potential and real-world clinical deployment by addressing practical constraints and ensuring trustworthy, generalizable performance.", "method": "Review and synthesize strategies: supervised fine-tuning, domain-specific pretraining, parameter-efficient fine-tuning, self-supervised learning, hybrids, and multimodal frameworks; discuss emerging directions and their trade-offs.", "result": "Summarizes reported gains, applicability, and limitations; highlights overlooked trade-offs; proposes roadmap and research gaps; emphasizes need for systematic benchmarking and privacy-preserving approaches.", "conclusion": "FM adaptation to medical imaging is feasible but requires addressing real-world variability, privacy, and resource constraints; aims to guide development of adaptive, clinically integrated FMs."}}
{"id": "2511.01069", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01069", "abs": "https://arxiv.org/abs/2511.01069", "authors": ["Georg Pichler", "Marco Romanelli", "Pablo Piantanida"], "title": "Happiness as a Measure of Fairness", "comment": null, "summary": "In this paper, we propose a novel fairness framework grounded in the concept\nof happi- ness, a measure of the utility each group gains fromdecisionoutcomes.\nBycapturingfairness through this intuitive lens, we not only offer a more\nhuman-centered approach, but also one that is mathematically rigorous: In order\nto compute the optimal, fair post-processing strategy, only a linear program\nneeds to be solved. This makes our method both efficient and scalable with\nexisting optimization tools. Furthermore, it unifies and extends several\nwell-known fairness definitions, and our em- pirical results highlight its\npractical strengths across diverse scenarios.", "AI": {"tldr": "Proposes happiness-based fairness, a human-centered utility-based framework; optimal fair post-processing via a linear program; unifies existing fairness definitions; empirically effective.", "motivation": "Fairness in decision outcomes is human-centered but requires formal, scalable optimization. Existing definitions are fragmented; a framework capturing group welfare with tractable computation is desirable.", "method": "Define happiness as the utility gained by each group from outcomes; formulate post-processing as a linear program to compute the optimal fair strategy; show that the framework subsumes several fairness definitions; validate with experiments across diverse scenarios.", "result": "The linear program yields the optimal fair post-processing; the approach is efficient and scalable with standard solvers; empirical results demonstrate practical strengths and support unification of fairness notions.", "conclusion": "Happiness-based fairness provides a rigorous, scalable, and human-centric framework that unifies and extends fairness definitions and is validated empirically."}}
{"id": "2511.01293", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01293", "abs": "https://arxiv.org/abs/2511.01293", "authors": ["Yonggang Zhang", "Jun Nie", "Xinmei Tian", "Mingming Gong", "Kun Zhang", "Bo Han"], "title": "Detecting Generated Images by Fitting Natural Image Distributions", "comment": "25 pages, 9 figures, NeurIPS 2025 spotlight", "summary": "The increasing realism of generated images has raised significant concerns\nabout their potential misuse, necessitating robust detection methods. Current\napproaches mainly rely on training binary classifiers, which depend heavily on\nthe quantity and quality of available generated images. In this work, we\npropose a novel framework that exploits geometric differences between the data\nmanifolds of natural and generated images. To exploit this difference, we\nemploy a pair of functions engineered to yield consistent outputs for natural\nimages but divergent outputs for generated ones, leveraging the property that\ntheir gradients reside in mutually orthogonal subspaces. This design enables a\nsimple yet effective detection method: an image is identified as generated if a\ntransformation along its data manifold induces a significant change in the loss\nvalue of a self-supervised model pre-trained on natural images. Further more,\nto address diminishing manifold disparities in advanced generative models, we\nleverage normalizing flows to amplify detectable differences by extruding\ngenerated images away from the natural image manifold. Extensive experiments\ndemonstrate the efficacy of this method. Code is available at\nhttps://github.com/tmlr-group/ConV.", "AI": {"tldr": "A geometry-based detection framework distinguishes real vs. generated images by exploiting mutually orthogonal gradient subspaces of two functions. It checks if transforming an image along the data manifold significantly changes a self-supervised model\u2019s loss; to counteract evolving generators, it uses normalizing flows to push generated images off the natural manifold. Empirical results show strong efficacy with code released at the given URL.", "motivation": "Current detectors rely on data-hungry binary classifiers that are sensitive to the available pool of generated images and fail as generators improve. A geometry-based, self-supervised approach aims to provide robust detection less dependent on labeled generated data and resilient to shifts in generator behavior by leveraging data-manifold differences.", "method": "Construct a pair of functions whose gradients lie in mutually orthogonal subspaces, yielding consistent outputs on natural images but divergent outputs on generated ones. Detection is performed by applying a transformation along the data manifold and monitoring whether the self-supervised model pre-trained on natural images experiences a significant loss change. To maintain detectability as generators improve, employ normalizing flows to push generated images away from the natural-manifold region, amplifying the detectable signal.", "result": "Extensive experiments demonstrate the effectiveness of the proposed framework. The approach achieves robust detection performance and demonstrates resilience to changes in generative models. Code is available at the provided GitHub repository.", "conclusion": "A geometry-based, self-supervised detection framework that leverages orthogonal gradient directions and manifold transformations offers robust detection of generated images, with normalizing flows helping to sustain detectability as generators evolve. This approach reduces reliance on large labeled datasets and adapts to advancing generative models."}}
{"id": "2511.01077", "categories": ["cs.LG", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.01077", "abs": "https://arxiv.org/abs/2511.01077", "authors": ["David McCoy", "Yulun Wu", "Zachary Butzin-Dozier"], "title": "AI Progress Should Be Measured by Capability-Per-Resource, Not Scale Alone: A Framework for Gradient-Guided Resource Allocation in LLMs", "comment": "9 pages (main) + appendix, 3 figures. Accepted at NeurIPS 2025\n  (Position Paper Track), submission #491. OpenReview:\n  https://openreview.net/forum?id=6plSmhBI33&noteId=KP5ZqY7JLg", "summary": "This position paper challenges the \"scaling fundamentalism\" dominating AI\nresearch, where unbounded growth in model size and computation has led to\nunsustainable environmental impacts and widening resource inequality. We argue\nthat LLM development should be fundamentally reoriented toward\ncapability-per-resource rather than capability alone. We present a theoretical\nframework demonstrating that resource-allocation decisions guided by gradient\ninfluence patterns can dramatically improve efficiency throughout the AI\nlifecycle. Our analysis shows that in transformer-based models, where a small\nfraction of parameters exert outsized influence (following heavy-tailed\ndistributions), three critical insights emerge: (1) updating only\nhigh-influence parameters strictly outperforms full-parameter tuning on a\nperformance-per-resource basis; (2) simple gradient norms provide\ncomputationally efficient proxies for identifying these high-influence\ncomponents; and (3) coordinated parameter and data selection yields\nmultiplicative efficiency gains, potentially reducing resource requirements by\norders of magnitude. Building on these theoretical foundations, we propose a\ntwo stage paradigm marginal-return pretraining for foundation developers and\ninfluence guided adaptation for downstream users bridged by gradient\nblueprints, metadata describing which parameters matter most for various tasks.\nThis capability-per-resource perspective transforms what were once considered\npragmatic hardware workarounds into theoretically optimal strategies,\ndemocratizing access to cutting-edge AI capabilities while significantly\nreducing environmental impact. By embedding resource consciousness into how we\ndevelop, adapt, and evaluate models, we can reshape AI progress toward a more\nsustainable and equitable future.", "AI": {"tldr": "A position paper argues to shift AI scaling from pure capacity growth to efficiency per resource, using gradient-influence analysis in transformers to identify high-impact parameters and data, achieving orders-of-magnitude resource reductions via high-influence parameter updates, gradient norms as proxies, and coordinated parameter-data selection; proposes a two-stage paradigm: marginal-return pretraining and influence-guided adaptation with gradient blueprints to democratize access while reducing environmental impact.", "motivation": "Critique of scaling fundamentalism and its environmental and equity costs; advocate a resource-aware reorientation of LLM development toward capability-per-resource; provide a theory and actionable framework to optimize AI progress with less resource use.", "method": "Theoretical framework analyzing transformer weight distributions as heavy-tailed; identify high-influence parameters via gradient influence patterns; show updating only these parameters beats full-parameter tuning on efficiency; propose gradient norms as proxies; advocate coordinated parameter and data selection; propose two-stage paradigm and gradient blueprints to bridge pretraining and downstream adaptation.", "result": "The work presents three core insights: (1) high-influence parameter updates outperform full tuning in performance-per-resource; (2) gradient norms serve as efficient proxies to locate high-influence components; (3) coordinated parameter and data selection yields multiplicative efficiency gains, potentially reducing resource needs by orders of magnitude. It couples these findings into a two-stage paradigm and gradient blueprint mechanism to operationalize resource-per-resource development.", "conclusion": "Embedding resource-consciousness into AI development reframes progress toward sustainability and equity. The proposed marginal-return pretraining and influence-guided adaptation, via gradient blueprints, offers a practical path to democratize access to capabilities while reducing environmental impact."}}
{"id": "2511.01295", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01295", "abs": "https://arxiv.org/abs/2511.01295", "authors": ["Feng Han", "Yibin Wang", "Chenglin Li", "Zheming Liang", "Dianyi Wang", "Yang Jiao", "Zhipeng Wei", "Chao Gong", "Cheng Jin", "Jingjing Chen", "Jiaqi Wang"], "title": "UniREditBench: A Unified Reasoning-based Image Editing Benchmark", "comment": "Project page: https://maplebb.github.io/UniREditBench", "summary": "Recent advances in multi-modal generative models have driven substantial\nimprovements in image editing. However, current generative models still\nstruggle with handling diverse and complex image editing tasks that require\nimplicit reasoning, underscoring the need for a comprehensive benchmark to\nsystematically assess their performance across various reasoning scenarios.\nExisting benchmarks primarily focus on single-object attribute transformation\nin realistic scenarios, which, while effective, encounter two key challenges:\n(1) they largely overlook multi-object interactions as well as game-world\nscenarios that involve human-defined rules, which are common in real-life\napplications; (2) they only rely on textual references to evaluate the\ngenerated images, potentially leading to systematic misjudgments, especially in\ncomplex reasoning scenarios. To this end, this work proposes UniREditBench, a\nunified benchmark for reasoning-based image editing evaluation. It comprises\n2,700 meticulously curated samples, covering both real- and game-world\nscenarios across 8 primary dimensions and 18 sub-dimensions. To improve\nevaluation reliability, we introduce multimodal dual-reference evaluation,\nproviding both textual and ground-truth image references for each sample\nassessment. Furthermore, we design an automated multi-scenario data synthesis\npipeline and construct UniREdit-Data-100K, a large-scale synthetic dataset with\nhigh-quality chain-of-thought (CoT) reasoning annotations. We fine-tune Bagel\non this dataset and develop UniREdit-Bagel, demonstrating substantial\nimprovements in both in-domain and out-of-distribution settings. Through\nthorough benchmarking of both open-source and closed-source image editing\nmodels, we reveal their strengths and weaknesses across various aspects.", "AI": {"tldr": "Introduces UniREditBench, a multimodal, reasoning-focused benchmark for image editing, with 2,700 samples across real/game-world scenarios, dual-reference evaluation, a 100K synthetic CoT dataset, and a Bagel-based baseline, showing improved in-domain/out-of-distribution performance and detailed model diagnostics.", "motivation": "Existing benchmarks underrepresent multi-object interactions and rule-based reasoning in game-like scenarios; they rely on text-only references, which can cause misjudgments in complex reasoning. A unified, multimodal benchmark is needed to reliably evaluate reasoning-based image editing.", "method": "Develop UniREditBench with 2,700 samples spanning 8 primary dimensions and 18 sub-dimensions across real and game-world contexts. Implement multimodal dual-reference evaluation (text and ground-truth images). Build an automated multi-scenario data-synthesis pipeline and UniREdit-Data-100K, a synthetic dataset with high-quality chain-of-thought annotations. Fine-tune Bagel on this dataset to create UniREdit-Bagel. Benchmark both open-source and closed-source image editing models.", "result": "UniREdit-Bagel achieves substantial improvements in both in-domain and out-of-distribution settings. The benchmark and data enable more reliable evaluation, revealing strengths and weaknesses of models across various aspects.", "conclusion": "UniREditBench offers a comprehensive, reliable framework for reasoning-based image editing evaluation that can guide model development, enable fairer cross-model comparisons, and support future extensions to more complex scenarios."}}
{"id": "2511.01093", "categories": ["cs.LG", "cs.AI", "F.2.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2511.01093", "abs": "https://arxiv.org/abs/2511.01093", "authors": ["Aman Jaglan", "Jarrod Barnes"], "title": "Continual Learning, Not Training: Online Adaptation For Agents", "comment": "12 pages, 4 figures", "summary": "Continual Learning (CL) methods have traditionally focused on mitigating\ncatastrophic forgetting through gradient-based retraining, an approach\nill-suited for deployed agents that must adapt in real time. We introduce our\nAdaptive Teaching and Learning System (ATLAS), a dual-agent architecture that\ndecouples reasoning (Teacher) from execution (Student) and incorporates a\npersistent learning memory that stores distilled guidance from experience. This\ninforms the orchestration layer, enabling the system to dynamically adjust its\noperational strategies, such as supervision level or initial plan selection, at\ninference time. In doing so, ATLAS achieves gradient-free continual learning,\nshifting the locus of adaptation from model parameters to system-level\norchestration. We formulate this as a system-centric paradigm for continual\nlearning, where the objective is adaptive efficiency: maximizing task success\nwhile minimizing computational cost through inference-time orchestration rather\nthan parameter updates. Evaluated on Microsoft's ExCyTIn-Bench, an open-source\nbenchmark simulating complex cyberthreat investigation, ATLAS achieves 54.1%\nsuccess with GPT-5-mini as its Student, outperforming the larger GPT-5 (High)\nby 13% while reducing cost by 86%. Cross-incident validation demonstrates\ngeneralization: frozen pamphlets from Incident #5 improve accuracy from 28% to\n41% with zero retraining, while shifting output composition from verbose\nexploration to structured reasoning. Together, these findings establish\ngradient-free continual learning as a viable path toward adaptive, deployable\nAI systems and provide causally annotated traces valuable for training explicit\nworld models.", "AI": {"tldr": "ATLAS introduces a dual-agent system (Teacher/Student) with a persistent memory to guide inference-time orchestration, enabling gradient-free continual learning and reduced compute.", "motivation": "Mitigate catastrophic forgetting in deployed agents and enable real-time adaptation without gradient updates; shift from parameter updates to system-level orchestration.", "method": "A two-agent architecture with memory distillation, an orchestration layer controlling supervision level and plan selection at inference, evaluated on ExCyTIn-Bench; demonstrates gradient-free continual learning and world-model traces.", "result": "Achieves 54.1% success with GPT-5-mini Student, 13% better than GPT-5 (High); cost reduced by 86%; cross-incident transfer improves accuracy from 28% to 41% without retraining.", "conclusion": "Gradient-free continual learning is a viable path for deployable, adaptive AI; system-level orchestration can replace parameter updates and provide generalization via stored guidance."}}
{"id": "2511.01302", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01302", "abs": "https://arxiv.org/abs/2511.01302", "authors": ["Nu-Fnag Xiao", "De-Xing Huang", "Le-Tian Wang", "Mei-Jiang Gui", "Qi Fu", "Xiao-Liang Xie", "Shi-Qi Liu", "Shuangyi Wang", "Zeng-Guang Hou", "Ying-Wei Wang", "Xiao-Hu Zhou"], "title": "REASON: Probability map-guided dual-branch fusion framework for gastric content assessment", "comment": "Under Review. 12 pages, 10 figures, 6 tables", "summary": "Accurate assessment of gastric content from ultrasound is critical for\nstratifying aspiration risk at induction of general anesthesia. However,\ntraditional methods rely on manual tracing of gastric antra and empirical\nformulas, which face significant limitations in both efficiency and accuracy.\nTo address these challenges, a novel two-stage probability map-guided\ndual-branch fusion framework (REASON) for gastric content assessment is\nproposed. In stage 1, a segmentation model generates probability maps that\nsuppress artifacts and highlight gastric anatomy. In stage 2, a dual-branch\nclassifier fuses information from two standard views, right lateral decubitus\n(RLD) and supine (SUP), to improve the discrimination of learned features.\nExperimental results on a self-collected dataset demonstrate that the proposed\nframework outperforms current state-of-the-art approaches by a significant\nmargin. This framework shows great promise for automated preoperative\naspiration risk assessment, offering a more robust, efficient, and accurate\nsolution for clinical practice.", "AI": {"tldr": "A two-stage framework called REASON improves gastric content assessment from ultrasound by combining probabilistic segmentation with a dual-view classifier, outperforming existing methods on a self-collected dataset and enabling automated preoperative aspiration risk assessment.", "motivation": "Manual tracing of gastric antra and reliance on empirical formulas are inefficient and often inaccurate, hindering reliable aspiration risk stratification during induction.", "method": "Stage 1 uses a segmentation model to produce probability maps that suppress artifacts and emphasize gastric anatomy. Stage 2 employs a dual-branch classifier that fuses features from two standard ultrasound views, right lateral decubitus (RLD) and supine (SUP), to improve discrimination of learned features.", "result": "The proposed framework outperforms current state-of-the-art approaches by a significant margin on a self-collected dataset.", "conclusion": "REASON shows promise as an automated, robust, and efficient solution for preoperative aspiration risk assessment in clinical practice."}}
{"id": "2511.01125", "categories": ["cs.LG", "cs.NA", "math.AP", "math.NA", "math.PR", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2511.01125", "abs": "https://arxiv.org/abs/2511.01125", "authors": ["Takashi Furuya", "Anastasis Kratsios", "Dylan Possama\u00ef", "Bogdan Raoni\u0107"], "title": "One model to solve them all: 2BSDE families via neural operators", "comment": null, "summary": "We introduce a mild generative variant of the classical neural operator\nmodel, which leverages Kolmogorov--Arnold networks to solve infinite families\nof second-order backward stochastic differential equations ($2$BSDEs) on\nregular bounded Euclidean domains with random terminal time. Our first main\nresult shows that the solution operator associated with a broad range of\n$2$BSDE families is approximable by appropriate neural operator models. We then\nidentify a structured subclass of (infinite) families of $2$BSDEs whose neural\noperator approximation requires only a polynomial number of parameters in the\nreciprocal approximation rate, as opposed to the exponential requirement in\ngeneral worst-case neural operator guarantees.", "AI": {"tldr": "Mild generative neural operator using Kolmogorov\u2013Arnol'd networks to solve families of 2BSDEs; proves neural operators approximate solution operators; identifies a structured subclass where parameter count scales polynomially with 1/epsilon rather than exponentially.", "motivation": "Address solving infinite families of second-order backward stochastic differential equations (2BSDEs) on bounded domains with random terminal time, and improve neural-operator efficiency guarantees beyond worst-case exponential complexity.", "method": "Introduce a mild generative variant of neural operators, leveraging Kolmogorov\u2013Arnol'd networks to represent solution operators for 2BSDE families; prove universal approximation for broad 2BSDE families; isolate a structured subclass with favorable (polynomial) parameter complexity in the reciprocal approximation rate.", "result": "The solution operator for a broad class of 2BSDE families is approximable by the proposed neural-operator models; within a structured subclass, neural-operator approximation requires only a polynomial number of parameters in 1/epsilon, contrasting general exponential guarantees.", "conclusion": "Neural-operator methods augmented with Kolmogorov\u2013Arnol'd networks effectively approximate solution operators for 2BSDEs on bounded domains with random terminal time, with potential practical efficiency gains for structured families due to polynomial complexity."}}
{"id": "2511.01304", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01304", "abs": "https://arxiv.org/abs/2511.01304", "authors": ["Chentao Li", "Behzad Bozorgtabar", "Yifang Ping", "Pan Huang", "Jing Qin"], "title": "Positive Semi-definite Latent Factor Grouping-Boosted Cluster-reasoning Instance Disentangled Learning for WSI Representation", "comment": "Our code is available at https://github.com/Prince-Lee-PathAI/PG-CIDL", "summary": "Multiple instance learning (MIL) has been widely used for representing\nwhole-slide pathology images. However, spatial, semantic, and decision\nentanglements among instances limit its representation and interpretability. To\naddress these challenges, we propose a latent factor grouping-boosted\ncluster-reasoning instance disentangled learning framework for whole-slide\nimage (WSI) interpretable representation in three phases. First, we introduce a\nnovel positive semi-definite latent factor grouping that maps instances into a\nlatent subspace, effectively mitigating spatial entanglement in MIL. To\nalleviate semantic entanglement, we employs instance probability counterfactual\ninference and optimization via cluster-reasoning instance disentangling.\nFinally, we employ a generalized linear weighted decision via instance effect\nre-weighting to address decision entanglement. Extensive experiments on\nmulticentre datasets demonstrate that our model outperforms all\nstate-of-the-art models. Moreover, it attains pathologist-aligned\ninterpretability through disentangled representations and a transparent\ndecision-making process.", "AI": {"tldr": "A MIL framework for whole-slide images that disentangles spatial, semantic, and decision entanglements through latent factor grouping, cluster-reasoning, and instance re-weighting, achieving state-of-the-art accuracy with interpretable, pathologist-aligned decisions.", "motivation": "MIL on whole-slide images suffers from entanglements (spatial, semantic, decision) among instances, which hurts representation quality and interpretability. There is a need for disentangled, interpretable representations that align with pathologist reasoning while improving performance.", "method": "Three-phase approach: (1) positive semi-definite latent factor grouping to map instances into a latent subspace, reducing spatial entanglement; (2) address semantic entanglement via instance probability counterfactual inference and cluster-reasoning instance disentangling; (3) generalized linear weighted decision via instance effect re-weighting to mitigate decision entanglement.", "result": "Experimental results on multicentre datasets show the proposed method outperforms all state-of-the-art models, with pathologist-aligned interpretability arising from disentangled representations and a transparent decision-making process.", "conclusion": "The latent factor grouping-boosted cluster-reasoning framework provides disentangled, interpretable MIL representations for WSIs, delivering superior performance and clearer alignment with expert reasoning."}}
{"id": "2511.01126", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2511.01126", "abs": "https://arxiv.org/abs/2511.01126", "authors": ["Parvin Nazari", "Bojian Hou", "Davoud Ataee Tarzanagh", "Li Shen", "George Michailidis"], "title": "Stochastic Regret Guarantees for Online Zeroth- and First-Order Bilevel Optimization", "comment": "Published at NeurIPS 2025. 88 pages and 3 figures", "summary": "Online bilevel optimization (OBO) is a powerful framework for machine\nlearning problems where both outer and inner objectives evolve over time,\nrequiring dynamic updates. Current OBO approaches rely on deterministic\n\\textit{window-smoothed} regret minimization, which may not accurately reflect\nsystem performance when functions change rapidly. In this work, we introduce a\nnovel search direction and show that both first- and zeroth-order (ZO)\nstochastic OBO algorithms leveraging this direction achieve sublinear\n{stochastic bilevel regret without window smoothing}. Beyond these guarantees,\nour framework enhances efficiency by: (i) reducing oracle dependence in\nhypergradient estimation, (ii) updating inner and outer variables alongside the\nlinear system solution, and (iii) employing ZO-based estimation of Hessians,\nJacobians, and gradients. Experiments on online parametric loss tuning and\nblack-box adversarial attacks validate our approach.", "AI": {"tldr": "A new search direction enables online bilevel optimization with sublinear stochastic bilevel regret without window smoothing, using first- and zeroth-order algorithms; it also improves efficiency via reduced oracle cost and joint updates, demonstrated on online parametric loss tuning and black-box adversarial attacks.", "motivation": "In online settings where both outer and inner objectives change over time, existing window-smoothed regret measures may misjudge performance when functions evolve rapidly. There is a need for regret guarantees without window smoothing and for more efficient hypergradient estimation.", "method": "Proposes a novel search direction for OBO and develops both first- and zeroth-order stochastic OBO algorithms that leverage this direction. The framework reduces oracle dependence in hypergradient estimation, updates inner and outer variables in tandem with solving the linear system, and uses zeroth-order estimates for Hessians, Jacobians, and gradients.", "result": "The approach achieves sublinear stochastic bilevel regret without window smoothing. It also offers efficiency gains in hypergradient estimation and update steps, validated by experiments on online parametric loss tuning and black-box adversarial attacks.", "conclusion": "The proposed search direction and accompanying OBO algorithms improve theoretical guarantees (sublinear regret without window smoothing) and practical efficiency for non-stationary bilevel problems, supported by empirical validation."}}
{"id": "2511.01307", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01307", "abs": "https://arxiv.org/abs/2511.01307", "authors": ["Tae-Young Lee", "Juwon Seo", "Jong Hwan Ko", "Gyeong-Moon Park"], "title": "Perturb a Model, Not an Image: Towards Robust Privacy Protection via Anti-Personalized Diffusion Models", "comment": "26 pages, 9 figures, 16 tables, NeurIPS 2025", "summary": "Recent advances in diffusion models have enabled high-quality synthesis of\nspecific subjects, such as identities or objects. This capability, while\nunlocking new possibilities in content creation, also introduces significant\nprivacy risks, as personalization techniques can be misused by malicious users\nto generate unauthorized content. Although several studies have attempted to\ncounter this by generating adversarially perturbed samples designed to disrupt\npersonalization, they rely on unrealistic assumptions and become ineffective in\nthe presence of even a few clean images or under simple image transformations.\nTo address these challenges, we shift the protection target from the images to\nthe diffusion model itself to hinder the personalization of specific subjects,\nthrough our novel framework called Anti-Personalized Diffusion Models (APDM).\nWe first provide a theoretical analysis demonstrating that a naive approach of\nexisting loss functions to diffusion models is inherently incapable of ensuring\nconvergence for robust anti-personalization. Motivated by this finding, we\nintroduce Direct Protective Optimization (DPO), a novel loss function that\neffectively disrupts subject personalization in the target model without\ncompromising generative quality. Moreover, we propose a new dual-path\noptimization strategy, coined Learning to Protect (L2P). By alternating between\npersonalization and protection paths, L2P simulates future personalization\ntrajectories and adaptively reinforces protection at each step. Experimental\nresults demonstrate that our framework outperforms existing methods, achieving\nstate-of-the-art performance in preventing unauthorized personalization. The\ncode is available at https://github.com/KU-VGI/APDM.", "AI": {"tldr": "APDM introduces protective optimization and a dual-path training regime to disrupt subject personalization in diffusion models, achieving state-of-the-art protection against unauthorized personalization while preserving generation quality; code released.", "motivation": "Personalization-enabled diffusion models pose privacy risks as malicious users can generate unauthorized content. Existing defenses rely on unrealistic assumptions and falter with clean images or simple transformations, motivating a model-centric protection approach.", "method": "The authors provide a theoretical analysis showing naive loss functions cannot ensure convergence for robust anti-personalization. They propose Direct Protective Optimization (DPO), a loss function that disrupts personalization without harming generative quality, and Learning to Protect (L2P), a dual-path optimization that alternates between personalization and protection paths to simulate future personalization trajectories and reinforce protection.", "result": "Experiments show APDM outperforms existing methods, achieving state-of-the-art protection against unauthorized personalization while maintaining high-quality generation. Code is available at the provided GitHub link.", "conclusion": "APDM effectively protects diffusion models from being personalized by adversaries through DPO and L2P, shifting protection from images to the model itself without sacrificing generative performance."}}
{"id": "2511.01137", "categories": ["cs.LG", "math.AG", "math.DS", "stat.ML", "14L24, 37J15, 37C10, 68T07, 93B10, 53D20, 49J15, 37N40"], "pdf": "https://arxiv.org/pdf/2511.01137", "abs": "https://arxiv.org/abs/2511.01137", "authors": ["Kathryn Lindsey", "Govind Menon"], "title": "Regularization Implies balancedness in the deep linear network", "comment": "18 pages, 3 figures", "summary": "We use geometric invariant theory (GIT) to study the deep linear network\n(DLN). The Kempf-Ness theorem is used to establish that the $L^2$ regularizer\nis minimized on the balanced manifold. This allows us to decompose the training\ndynamics into two distinct gradient flows: a regularizing flow on fibers and a\nlearning flow on the balanced manifold. We show that the regularizing flow is\nexactly solvable using the moment map.\n  This approach provides a common mathematical framework for balancedness in\ndeep learning and linear systems theory. We use this framework to interpret\nbalancedness in terms of model reduction and Bayesian principles.", "AI": {"tldr": "GIT-based analysis of deep linear nets shows L2 regularization minimizes on the balanced manifold, enabling a two-flow training dynamics and exact solvability of the regularizing flow via the moment map, linking balancedness to model reduction and Bayesian ideas.", "motivation": "to understand and formalize balancedness in deep linear networks using geometric invariant theory and to connect it with linear systems theory and Bayesian interpretations.", "method": "apply Kempf-Ness theorem from GIT to show the L2 regularizer is minimized on the balanced manifold; decompose training into a regularizing flow on fibers and a learning flow on the balanced manifold; obtain exact solvability for the regularizing flow via the moment map.", "result": "provides a unifying mathematical framework for balancedness in deep learning and linear systems; demonstrates that balancedness can be interpreted through model reduction and Bayesian principles.", "conclusion": "offers a common framework and interpretative lens for balancedness, potentially guiding design and analysis of DL networks and related linear systems."}}
{"id": "2511.01315", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01315", "abs": "https://arxiv.org/abs/2511.01315", "authors": ["Jianfei Jiang", "Qiankun Liu", "Hongyuan Liu", "Haochen Yu", "Liyong Wang", "Jiansheng Chen", "Huimin Ma"], "title": "MVSMamba: Multi-View Stereo with State Space Model", "comment": "Accepted by NeurIPS 2025", "summary": "Robust feature representations are essential for learning-based Multi-View\nStereo (MVS), which relies on accurate feature matching. Recent MVS methods\nleverage Transformers to capture long-range dependencies based on local\nfeatures extracted by conventional feature pyramid networks. However, the\nquadratic complexity of Transformer-based MVS methods poses challenges to\nbalance performance and efficiency. Motivated by the global modeling capability\nand linear complexity of the Mamba architecture, we propose MVSMamba, the first\nMamba-based MVS network. MVSMamba enables efficient global feature aggregation\nwith minimal computational overhead. To fully exploit Mamba's potential in MVS,\nwe propose a Dynamic Mamba module (DM-module) based on a novel\nreference-centered dynamic scanning strategy, which enables: (1) Efficient\nintra- and inter-view feature interaction from the reference to source views,\n(2) Omnidirectional multi-view feature representations, and (3) Multi-scale\nglobal feature aggregation. Extensive experimental results demonstrate MVSMamba\noutperforms state-of-the-art MVS methods on the DTU dataset and the\nTanks-and-Temples benchmark with both superior performance and efficiency. The\nsource code is available at https://github.com/JianfeiJ/MVSMamba.", "AI": {"tldr": "MVSMamba introduces a Mamba-based MVS network that uses a Dynamic Mamba module with a reference-centered dynamic scanning strategy to achieve efficient global feature aggregation and cross-view interaction, achieving state-of-the-art results with improved efficiency.", "motivation": "Transformer-based MVS methods struggle with quadratic complexity and limited efficiency. A linear-complexity global modeling approach like Mamba could provide robust, scalable feature representations for multi-view stereo.", "method": "Propose MVSMamba, the first Mamba-based MVS network. It employs a Dynamic Mamba (DM) module with a reference-centered dynamic scanning strategy to enable efficient intra- and inter-view feature interaction from the reference view to source views, produce omnidirectional multi-view feature representations, and perform multi-scale global feature aggregation.", "result": "MVSMamba outperforms state-of-the-art MVS methods on the DTU dataset and Tanks-and-Temples benchmark, delivering both higher performance and better efficiency.", "conclusion": "The work demonstrates the effectiveness of Mamba-based models for MVS and presents a scalable, efficient approach for global feature aggregation and cross-view interaction; code is released for reproducibility."}}
{"id": "2511.01172", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01172", "abs": "https://arxiv.org/abs/2511.01172", "authors": ["Ali Owfi", "Amirmohammad Bamdad", "Tolunay Seyfi", "Fatemeh Afghah"], "title": "Adapt under Attack and Domain Shift: Unified Adversarial Meta-Learning and Domain Adaptation for Robust Automatic Modulation Classification", "comment": null, "summary": "Deep learning has emerged as a leading approach for Automatic Modulation\nClassification (AMC), demonstrating superior performance over traditional\nmethods. However, vulnerability to adversarial attacks and susceptibility to\ndata distribution shifts hinder their practical deployment in real-world,\ndynamic environments. To address these threats, we propose a novel, unified\nframework that integrates meta-learning with domain adaptation, making AMC\nsystems resistant to both adversarial attacks and environmental changes. Our\nframework utilizes a two-phase strategy. First, in an offline phase, we employ\na meta-learning approach to train the model on clean and adversarially\nperturbed samples from a single source domain. This method enables the model to\ngeneralize its defense, making it resistant to a combination of previously\nunseen attacks. Subsequently, in the online phase, we apply domain adaptation\nto align the model's features with a new target domain, allowing it to adapt\nwithout requiring substantial labeled data. As a result, our framework achieves\na significant improvement in modulation classification accuracy against these\ncombined threats, offering a critical solution to the deployment and\noperational challenges of modern AMC systems.", "AI": {"tldr": "A unified meta-learning and domain-adaptation framework for Automatic Modulation Classification that is robust to both adversarial attacks and environmental distribution shifts; it trains offline with clean and adversarial samples from a single source domain and adapts online to a new target domain, yielding improved accuracy under combined threats.", "motivation": "AMC models are vulnerable to adversarial perturbations and non-stationary data distributions in real-world environments, which hampers deployment.", "method": "Two-phase approach: (1) offline meta-learning on clean and adversarial samples from one source domain to learn defenses that generalize to unseen attacks, and (2) online domain adaptation to align features to a new target domain with limited labeled data, enabling adaptation without extensive labeling.", "result": "The framework achieves significant improvement in modulation classification accuracy under the combined threats of adversarial attacks and distribution shifts.", "conclusion": "This unified framework provides a practical solution for deploying robust AMC systems, addressing both adversarial robustness and environmental adaptation in real-world settings."}}
{"id": "2511.01317", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01317", "abs": "https://arxiv.org/abs/2511.01317", "authors": ["Sampriti Soor", "Alik Pramanick", "Jothiprakash K", "Arijit Sur"], "title": "A Generative Adversarial Approach to Adversarial Attacks Guided by Contrastive Language-Image Pre-trained Model", "comment": "18 pages, 3 figures", "summary": "The rapid growth of deep learning has brought about powerful models that can\nhandle various tasks, like identifying images and understanding language.\nHowever, adversarial attacks, an unnoticed alteration, can deceive models,\nleading to inaccurate predictions. In this paper, a generative adversarial\nattack method is proposed that uses the CLIP model to create highly effective\nand visually imperceptible adversarial perturbations. The CLIP model's ability\nto align text and image representation helps incorporate natural language\nsemantics with a guided loss to generate effective adversarial examples that\nlook identical to the original inputs. This integration allows extensive scene\nmanipulation, creating perturbations in multi-object environments specifically\ndesigned to deceive multilabel classifiers. Our approach integrates the\nconcentrated perturbation strategy from Saliency-based Auto-Encoder (SSAE) with\nthe dissimilar text embeddings similar to Generative Adversarial Multi-Object\nScene Attacks (GAMA), resulting in perturbations that both deceive\nclassification models and maintain high structural similarity to the original\nimages. The model was tested on various tasks across diverse black-box victim\nmodels. The experimental results show that our method performs competitively,\nachieving comparable or superior results to existing techniques, while\npreserving greater visual fidelity.", "AI": {"tldr": "A CLIP-guided generative adversarial attack creates perceptually invisible perturbations for multi-object multilabel classifiers by combining SSAE-like concentrated perturbations with semantically dissimilar text embeddings (GAMA), achieving competitive results with higher visual fidelity across black-box models.", "motivation": "Adversarial attacks require effective perturbations that fool models while remaining visually imperceptible; multi-object scenes and multilabel classifiers pose additional challenges; leveraging CLIP's text\u2013image alignment can inject natural language semantics into the attack.", "method": "Use CLIP to guide perturbations via a loss that aligns perturbed image features with target text semantics; integrate SSAE concentrated perturbation strategy and dissimilar text embeddings akin to GAMA to manipulate multi-object scenes; ensure high structural similarity (SSIM) to original; evaluate on various black-box victim models.", "result": "Competitive performance relative to existing techniques; achieving comparable or superior attack success with greater visual fidelity; demonstrates effectiveness across diverse black-box models and multi-object scenes.", "conclusion": "CLIP-based semantic guidance combined with SSAE and GAMA-inspired embeddings yields strong, perceptually faithful adversarial perturbations for multilabel, multi-object vision tasks, expanding transferable attack capabilities in black-box settings."}}
{"id": "2511.01185", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01185", "abs": "https://arxiv.org/abs/2511.01185", "authors": ["Ruyue Zhang", "Xiaopeng Ke", "Ming Liu", "Fangzhou Shi", "Chang Men", "Zhengdan Zhu"], "title": "A Comparative Study of Model Adaptation Strategies for Multi-Treatment Uplift Modeling", "comment": null, "summary": "Uplift modeling has emerged as a crucial technique for individualized\ntreatment effect estimation, particularly in fields such as marketing and\nhealthcare. Modeling uplift effects in multi-treatment scenarios plays a key\nrole in real-world applications. Current techniques for modeling\nmulti-treatment uplift are typically adapted from binary-treatment works. In\nthis paper, we investigate and categorize all current model adaptations into\ntwo types: Structure Adaptation and Feature Adaptation. Through our empirical\nexperiments, we find that these two adaptation types cannot maintain\neffectiveness under various data characteristics (noisy data, mixed with\nobservational data, etc.). To enhance estimation ability and robustness, we\npropose Orthogonal Function Adaptation (OFA) based on the function\napproximation theorem. We conduct comprehensive experiments with multiple data\ncharacteristics to study the effectiveness and robustness of all model\nadaptation techniques. Our experimental results demonstrate that our proposed\nOFA can significantly improve uplift model performance compared to other\nvanilla adaptation methods and exhibits the highest robustness.", "AI": {"tldr": "Orthogonal Function Adaptation (OFA) yields superior and robust uplift estimates in multi-treatment settings, outperforming existing Structure and Feature adaptation methods.", "motivation": "Uplift modeling for individualized treatment effects is crucial in marketing and healthcare. In multi-treatment settings, current adaptations (Structure and Feature) struggle with noise and observational data, prompting a need for a principled, robust approach.", "method": "Introduce Orthogonal Function Adaptation (OFA) grounded in the function approximation theorem. Classify existing model adaptations into Structure Adaptation and Feature Adaptation, and develop an orthogonalization-based method to improve uplift estimation. Conduct comprehensive experiments across varied data characteristics to assess effectiveness and robustness.", "result": "OFA significantly improves uplift model performance compared to vanilla adaptation methods and shows the highest robustness across noisy data and observational data mixtures.", "conclusion": "OFA provides a robust, effective framework for multi-treatment uplift modeling, offering improved estimation accuracy and resilience against data quality issues."}}
{"id": "2511.01328", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01328", "abs": "https://arxiv.org/abs/2511.01328", "authors": ["Jierui Qu", "Jianchun Zhao"], "title": "RDTE-UNet: A Boundary and Detail Aware UNet for Precise Medical Image Segmentation", "comment": null, "summary": "Medical image segmentation is essential for computer-assisted diagnosis and\ntreatment planning, yet substantial anatomical variability and boundary\nambiguity hinder reliable delineation of fine structures. We propose RDTE-UNet,\na segmentation network that unifies local modeling with global context to\nstrengthen boundary delineation and detail preservation. RDTE-UNet employs a\nhybrid ResBlock detail-aware Transformer backbone and three modules: ASBE for\nadaptive boundary enhancement, HVDA for fine-grained feature modeling, and\nEulerFF for fusion weighting guided by Euler's formula. Together, these\ncomponents improve structural consistency and boundary accuracy across\nmorphology, orientation, and scale. On Synapse and BUSI dataset, RDTE-UNet has\nachieved a comparable level in terms of segmentation accuracy and boundary\nquality.", "AI": {"tldr": "RDTE-UNet is a UNet-like segmentation network that fuses local transformer-based decoding with global context to improve boundary delineation and detail preservation. It introduces three modules\u2014ASBE, HVDA, and EulerFF\u2014for adaptive boundary enhancement, fine-grained feature modeling, and Euler-guided fusion weighting. It achieves competitive segmentation accuracy and boundary quality on Synapse and BUSI datasets.", "motivation": "Medical image segmentation faces substantial anatomical variability and boundary ambiguity, which complicates reliable delineation of fine structures. A model that unifies local detail modeling with global context and robust boundary handling is needed.", "method": "RDTE-UNet uses a hybrid ResBlock detail-aware Transformer backbone. It incorporates three modules: ASBE (adaptive boundary enhancement) to sharpen boundaries, HVDA (high-definition feature modeling) for fine-grained feature extraction, and EulerFF (fusion weighting guided by Euler's formula) for principled feature fusion. This design aims to improve structural consistency across morphology, orientation, and scale.", "result": "On Synapse and BUSI datasets, RDTE-UNet achieves a comparable level of segmentation accuracy and boundary quality to existing methods, indicating effective boundary delineation and detail preservation.", "conclusion": "RDTE-UNet demonstrates that combining a ResBlock detail-aware Transformer backbone with ASBE, HVDA, and EulerFF can yield competitive segmentation performance and improved boundary delineation in medical images, across varying morphologies and scales."}}
{"id": "2511.01190", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01190", "abs": "https://arxiv.org/abs/2511.01190", "authors": ["Lijia Yu", "Xiao-Shan Gao", "Lijun Zhang"], "title": "Analyzing the Power of Chain of Thought through Memorization Capabilities", "comment": null, "summary": "It has been shown that the chain of thought (CoT) can enhance the power of\nlarge language models (LLMs) to solve certain mathematical reasoning problems.\nHowever, the capacity of CoT is still not fully explored. As an important\ninstance, the following basic question has not yet been answered: Does CoT\nexpand the capability of transformers across all reasoning tasks? We\ndemonstrate that reasoning with transformers is essentially a memorization\nproblem for reasoning datasets. Thus, examining the power of CoT across all\nreasoning tasks amounts to analyzing the memorization capabilities of CoT\ntransformers. In this paper, we give a complete description of the memorization\ncapabilities of fixed-precision transformers with or without CoT and give a\nnegative answer to the above-mentioned question. Precisely, we first give\nnecessary and sufficient conditions for fixed-precision transformers with and\nwithout CoT to memorize a finite reasoning dataset and show that these two\nconditions do not imply each other. Then, we give lower and upper bounds for\nthe number of parameters needed for transformers with or without CoT to\nmemorize a finite reasoning dataset with $N$ elements, which are\n$\\overline{\\Theta}(N)$ in all cases. This implies that there exist reasoning\ntasks for which CoT does not enhance the reasoning power of transformers,\nleading to a negative answer to the above-mentioned question. Finally, we give\nthe first results on memorizing infinite reasoning datasets by CoT transformers\nand show that some simple infinite datasets cannot be memorized by transformers\nwith or without CoT.", "AI": {"tldr": "CoT does not universally improve transformer reasoning; memorization governs capability, with linear (N) parameter scaling for finite datasets, and some tasks/infinite datasets defy memorization.", "motivation": "To determine whether chain-of-thought prompts extend transformers' reasoning across all tasks by examining the memorization capabilities of CoT-enabled transformers.", "method": "Theoretical analysis of fixed-precision transformers with and without CoT, deriving necessary and sufficient memorization conditions for finite datasets, establishing lower/upper bounds on parameters (linear in N) for memorization, and exploring memorization for infinite datasets.", "result": "Identifies that the two memorization conditions (with vs without CoT) are not equivalent; CoT does not universally enhance reasoning power; provides linear bounds \u0398(N) for memorization with or without CoT on finite datasets; extends preliminary results to some infinite datasets showing non-memorizability.", "conclusion": "CoT is not a universal fix for reasoning capabilities; the power of CoT is bounded by memorization limits, and even with CoT, some finite and infinite datasets cannot be memorized by fixed-precision transformers; this frames the limits of CoT in reasoning tasks."}}
{"id": "2511.01340", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01340", "abs": "https://arxiv.org/abs/2511.01340", "authors": ["Trishanu Das", "Abhilash Nandy", "Khush Bajaj", "Deepiha S"], "title": "$\\left|\\,\\circlearrowright\\,\\boxed{\\text{BUS}}\\,\\right|$: A Large and Diverse Multimodal Benchmark for evaluating the ability of Vision-Language Models to understand Rebus Puzzles", "comment": "7 pages, 5 figures, 4 tables", "summary": "Understanding Rebus Puzzles (Rebus Puzzles use pictures, symbols, and letters\nto represent words or phrases creatively) requires a variety of skills such as\nimage recognition, cognitive skills, commonsense reasoning, multi-step\nreasoning, image-based wordplay, etc., making this a challenging task for even\ncurrent Vision-Language Models. In this paper, we present\n$\\left|\\,\\circlearrowright\\,\\boxed{\\text{BUS}}\\,\\right|$, a large and diverse\nbenchmark of $1,333$ English Rebus Puzzles containing different artistic styles\nand levels of difficulty, spread across 18 categories such as food, idioms,\nsports, finance, entertainment, etc. We also propose $RebusDescProgICE$, a\nmodel-agnostic framework which uses a combination of an unstructured\ndescription and code-based, structured reasoning, along with better,\nreasoning-based in-context example selection, improving the performance of\nVision-Language Models on\n$\\left|\\,\\circlearrowright\\,\\boxed{\\text{BUS}}\\,\\right|$ by $2.1-4.1\\%$ and\n$20-30\\%$ using closed-source and open-source models respectively compared to\nChain-of-Thought Reasoning.", "AI": {"tldr": "A new large rebus puzzle benchmark and a model-agnostic reasoning framework improve Vision-Language models on rebus tasks.", "motivation": "Rebus puzzles demand diverse reasoning skills and current V-L models struggle; a standardized benchmark and improved reasoning strategies are needed.", "method": "Create the Rebus BUS benchmark with 1,333 puzzles across 18 categories; propose RebusDescProgICE, combining an unstructured description with code-based structured reasoning and improved in-context example selection; evaluate across closed-source and open-source models against Chain-of-Thought.", "result": "Closed-source models see 2.1\u20134.1 percentage point gains; open-source models see 20\u201330 percentage point gains over Chain-of-Thought; framework is model-agnostic and improves LLM/V-L reasoning on rebus tasks.", "conclusion": "A sizable, diverse benchmark plus the RebusDescProgICE framework advances reasoning performance on complex visual-linguistic puzzles and provides a resource for future research."}}
{"id": "2511.01198", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01198", "abs": "https://arxiv.org/abs/2511.01198", "authors": ["Tariq Abdul-Quddoos", "Tasnia Sharmin", "Xiangfang Li", "Lijun Qian"], "title": "Transmitter Identification and Protocol Categorization in Shared Spectrum via Multi-Task RF Classification at the Network Edge", "comment": null, "summary": "As spectrum sharing becomes increasingly vital to meet rising wireless\ndemands in the future, spectrum monitoring and transmitter identification are\nindispensable for enforcing spectrum usage policy, efficient spectrum\nutilization, and net- work security. This study proposed a robust framework for\ntransmitter identification and protocol categorization via multi- task RF\nsignal classification in shared spectrum environments, where the spectrum\nmonitor will classify transmission protocols (e.g., 4G LTE, 5G-NR, IEEE\n802.11a) operating within the same frequency bands, and identify different\ntransmitting base stations, as well as their combinations. A Convolutional\nNeural Network (CNN) is designed to tackle critical challenges such as\noverlapping signal characteristics and environmental variability. The proposed\nmethod employs a multi-channel input strategy to extract meaningful signal\nfeatures, achieving remarkable accuracy: 90% for protocol classification, 100%\nfor transmitting base station classification, and 92% for joint classification\ntasks, utilizing RF data from the POWDER platform. These results highlight the\nsignificant potential of the proposed method to enhance spectrum monitoring,\nmanagement, and security in modern wireless networks.", "AI": {"tldr": "A multi-task CNN-based RF signal classifier for protocol and base-station identification in shared spectrum, achieving high accuracy on POWDER data.", "motivation": "With rising wireless demand, spectrum monitoring and transmitter identification are essential for enforcing spectrum usage, efficient utilization, and security in shared bands.", "method": "A multi-channel input Convolutional Neural Network designed to perform multi-task RF signal classification: (1) protocol categorization (e.g., 4G LTE, 5G-NR, IEEE 802.11a), (2) transmitter base-station identification, and (3) joint classification tasks; trained/validated on RF data from the POWDER platform.", "result": "High accuracies were achieved: 90% for protocol classification, 100% for base-station identification, and 92% for joint classification.", "conclusion": "The approach demonstrates strong potential to enhance spectrum monitoring, management, and security in modern wireless networks, while indicating robustness to overlapping signals and environmental variability; future work could address generalization, real-time deployment, and broader protocol coverage."}}
{"id": "2511.01345", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01345", "abs": "https://arxiv.org/abs/2511.01345", "authors": ["Jierui Qu", "Jianchun Zhao"], "title": "MIQ-SAM3D: From Single-Point Prompt to Multi-Instance Segmentation via Competitive Query Refinement", "comment": null, "summary": "Accurate segmentation of medical images is fundamental to tumor diagnosis and\ntreatment planning. SAM-based interactive segmentation has gained attention for\nits strong generalization, but most methods follow a\nsingle-point-to-single-object paradigm, which limits multi-lesion segmentation.\nMoreover, ViT backbones capture global context but often miss high-fidelity\nlocal details. We propose MIQ-SAM3D, a multi-instance 3D segmentation framework\nwith a competitive query optimization strategy that shifts from\nsingle-point-to-single-mask to single-point-to-multi-instance. A\nprompt-conditioned instance-query generator transforms a single point prompt\ninto multiple specialized queries, enabling retrieval of all semantically\nsimilar lesions across the 3D volume from a single exemplar. A hybrid\nCNN-Transformer encoder injects CNN-derived boundary saliency into ViT\nself-attention via spatial gating. A competitively optimized query decoder then\nenables end-to-end, parallel, multi-instance prediction through inter-query\ncompetition. On LiTS17 and KiTS21 dataset, MIQ-SAM3D achieved comparable levels\nand exhibits strong robustness to prompts, providing a practical solution for\nefficient annotation of clinically relevant multi-lesion cases.", "AI": {"tldr": "A 3D medical image segmentation method (MIQ-SAM3D) extends SAM-based interactive segmentation from single-point-to-single-object to single-point-to-multi-instance. It uses a prompt-conditioned query generator to retrieve all semantically similar lesions from a 3D volume, a hybrid CNN-Transformer encoder that injects boundary saliency into ViT attention, and a competitively optimized decoder enabling parallel multi-instance predictions. Evaluated on LiTS17 and KiTS21, it shows competitive performance and robustness to prompts for multi-lesion cases.", "motivation": "Address limitations of SAM-based segmentation in medical imaging: single-point-to-single-object prompts restrict multi-lesion segmentation; ViT lacks fine-grained local detail. The work seeks to enable multi-lesion, efficient, robust 3D segmentation.", "method": "Introduce MIQ-SAM3D with (1) prompt-conditioned instance-query generator converting a single point into multiple specialized queries to fetch all semantically similar lesions in 3D; (2) a hybrid CNN-Transformer encoder injecting boundary saliency into ViT self-attention via spatial gating; (3) a competitively optimized query decoder enabling end-to-end, parallel, multi-instance prediction through inter-query competition.", "result": "On LiTS17 and KiTS21, MIQ-SAM3D achieves comparable performance to existing methods and demonstrates strong robustness to different prompts, enabling efficient annotation of multi-lesion cases.", "conclusion": "MIQ-SAM3D advances SAM-based interactive segmentation by supporting multi-instance 3D segmentation with better integration of local detail and cross-lesion retrieval, offering a practical approach for multi-lesion annotation in clinical workflows."}}
{"id": "2511.01203", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01203", "abs": "https://arxiv.org/abs/2511.01203", "authors": ["Pavel Rumiantsev", "Soumyasundar Pal", "Yingxue Zhang", "Mark Coates"], "title": "FEval-TTC: Fair Evaluation Protocol for Test-Time Compute", "comment": null, "summary": "The performance of Large Language Models (LLMs) and the associated dollar\ncosts of API calls can fluctuate over time, potentially invalidating\nconclusions drawn in prior research. To address this, we propose a Fair\nEvaluation protocol for Test-Time Compute (FEval-TTC), designed to ensure\nconsistent assessment of test-time compute (TTC) methods, regardless of such\nfluctuations. FEval-TTC focuses on the evaluation of TTC methods that utilize\nunderlying Chains-of-Thought (CoT). It supports evaluations across multiple\nLLMs on a diverse set of mathematical and commonsense reasoning datasets. The\nfew-shot prompting and answer extraction processes are standardized across\ndatasets, reducing both time and monetary overhead for researchers.\nFurthermore, we provide a cost modelling procedure that estimates both the\ntoken and dollar cost per query, facilitating equitable comparisons of\nprevalent TTC methods. We open-source FEval-TTC for public use at\nhttps://github.com/networkslab/feval_ttc .", "AI": {"tldr": "FEval-TTC is a protocol and open-source toolkit to fairly evaluate test-time compute (TTC) for LLMs, normalizing few-shot prompts and answer extraction, evaluating CoT-based TTC across multiple models and datasets, with a cost model for token and dollar costs.", "motivation": "LLM performance and API costs fluctuate over time, which can invalidate conclusions from prior studies. A stable, fair evaluation protocol for test-time compute is needed, especially for CoT-based TTC methods.", "method": "Introduce FEval-TTC protocol that supports evaluations across multiple LLMs on diverse math and commonsense datasets. Standardizes few-shot prompting and answer extraction to reduce overhead. Includes a cost modeling procedure to estimate token and dollar costs per query. Open-sources FEval-TTC for public use.", "result": "Provides a framework and tooling for consistent, fair TTC evaluation and cost accounting across LLMs and datasets. Reduces time and monetary overhead and enables equitable comparisons of TTC methods.", "conclusion": "FEval-TTC offers a standardized, open-source approach for fair evaluation of TTC methods, addressing fluctuations in model performance and costs."}}
{"id": "2511.01355", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01355", "abs": "https://arxiv.org/abs/2511.01355", "authors": ["Linhao Huang"], "title": "Expanding the Content-Style Frontier: a Balanced Subspace Blending Approach for Content-Style LoRA Fusion", "comment": null, "summary": "Recent advancements in text-to-image diffusion models have significantly\nimproved the personalization and stylization of generated images. However,\nprevious studies have only assessed content similarity under a single style\nintensity. In our experiments, we observe that increasing style intensity leads\nto a significant loss of content features, resulting in a suboptimal\ncontent-style frontier. To address this, we propose a novel approach to expand\nthe content-style frontier by leveraging Content-Style Subspace Blending and a\nContent-Style Balance loss. Our method improves content similarity across\nvarying style intensities, significantly broadening the content-style frontier.\nExtensive experiments demonstrate that our approach outperforms existing\ntechniques in both qualitative and quantitative evaluations, achieving superior\ncontent-style trade-off with significantly lower Inverted Generational Distance\n(IGD) and Generational Distance (GD) scores compared to current methods.", "AI": {"tldr": "Introduces Content-Style Subspace Blending and a Content-Style Balance loss to expand the content-style frontier in text-to-image diffusion, maintaining content fidelity across varying style intensities.", "motivation": "To address the deterioration of content features when increasing style intensity and to broaden the range of achievable content-style trade-offs.", "method": "Proposes Content-Style Subspace Blending plus a Content-Style Balance loss to preserve content similarity while applying different style intensities, thereby expanding the frontier.", "result": "Significant improvement in content similarity across style intensities, a broader content-style frontier, and superior trade-offs compared with existing methods, demonstrated by qualitative and quantitative metrics including lower IGD and GD scores.", "conclusion": "The proposed approach effectively expands the content-style frontier and yields better content-style trade-offs in diffusion-based generation."}}
{"id": "2511.01218", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01218", "abs": "https://arxiv.org/abs/2511.01218", "authors": ["Minh-Duc Nguyen", "Dung D. Le", "Phi Long Nguyen"], "title": "Optimizing Electric Vehicle Charging Station Placement Using Reinforcement Learning and Agent-Based Simulations", "comment": "Under Review", "summary": "The rapid growth of electric vehicles (EVs) necessitates the strategic\nplacement of charging stations to optimize resource utilization and minimize\nuser inconvenience. Reinforcement learning (RL) offers an innovative approach\nto identifying optimal charging station locations; however, existing methods\nface challenges due to their deterministic reward systems, which limit\nefficiency. Because real-world conditions are dynamic and uncertain, a\ndeterministic reward structure cannot fully capture the complexities of\ncharging station placement. As a result, evaluation becomes costly and\ntime-consuming, and less reflective of real-world scenarios. To address this\nchallenge, we propose a novel framework that integrates deep RL with\nagent-based simulations to model EV movement and estimate charging demand in\nreal time. Our approach employs a hybrid RL agent with dual Q-networks to\nselect optimal locations and configure charging ports, guided by a hybrid\nreward function that combines deterministic factors with simulation-derived\nfeedback. Case studies in Hanoi, Vietnam, show that our method reduces average\nwaiting times by 53.28% compared to the initial state, outperforming static\nbaseline methods. This scalable and adaptive solution enhances EV\ninfrastructure planning, effectively addressing real-world complexities and\nimproving user experience.", "AI": {"tldr": "Hybrid deep RL with agent-based simulation optimizes EV charging station placement and port configuration; uses dual Q-networks and a hybrid reward; shows 53.28% waiting-time reduction in Hanoi, outperforming static baselines.", "motivation": "Deterministic rewards in RL fail to capture dynamic, uncertain real-world charging demand; existing methods lack efficiency and realistic modeling of EV movement and demand; need real-time demand estimation and simulation-informed feedback for infrastructure planning.", "method": "Integrates deep reinforcement learning with agent-based simulations of EV movement to estimate charging demand in real time. A hybrid RL agent uses two Q-networks (one for location selection, one for port configuration) and a hybrid reward combining deterministic factors with simulation-derived feedback to guide decisions.", "result": "Case study in Hanoi shows a 53.28% reduction in average waiting times from the initial state, outperforming static baseline methods.", "conclusion": "The framework provides a scalable, adaptive approach to EV infrastructure planning that better captures real-world dynamics, improving user experience and enabling more efficient charging networks."}}
{"id": "2511.01357", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01357", "abs": "https://arxiv.org/abs/2511.01357", "authors": ["Qiangguo Jin", "Xianyao Zheng", "Hui Cui", "Changming Sun", "Yuqi Fang", "Cong Cong", "Ran Su", "Leyi Wei", "Ping Xuan", "Junbo Wang"], "title": "CMI-MTL: Cross-Mamba interaction based multi-task learning for medical visual question answering", "comment": "The paper has been accepted by the 33rd Pacific Conference on\n  Computer Graphics and Applications (Pacific Graphics 2025)", "summary": "Medical visual question answering (Med-VQA) is a crucial multimodal task in\nclinical decision support and telemedicine. Recent self-attention based methods\nstruggle to effectively handle cross-modal semantic alignments between vision\nand language. Moreover, classification-based methods rely on predefined answer\nsets. Treating this task as a simple classification problem may make it unable\nto adapt to the diversity of free-form answers and overlook the detailed\nsemantic information of free-form answers. In order to tackle these challenges,\nwe introduce a Cross-Mamba Interaction based Multi-Task Learning (CMI-MTL)\nframework that learns cross-modal feature representations from images and\ntexts. CMI-MTL comprises three key modules: fine-grained visual-text feature\nalignment (FVTA), cross-modal interleaved feature representation (CIFR), and\nfree-form answer-enhanced multi-task learning (FFAE). FVTA extracts the most\nrelevant regions in image-text pairs through fine-grained visual-text feature\nalignment. CIFR captures cross-modal sequential interactions via cross-modal\ninterleaved feature representation. FFAE leverages auxiliary knowledge from\nopen-ended questions through free-form answer-enhanced multi-task learning,\nimproving the model's capability for open-ended Med-VQA. Experimental results\nshow that CMI-MTL outperforms the existing state-of-the-art methods on three\nMed-VQA datasets: VQA-RAD, SLAKE, and OVQA. Furthermore, we conduct more\ninterpretability experiments to prove the effectiveness. The code is publicly\navailable at https://github.com/BioMedIA-repo/CMI-MTL.", "AI": {"tldr": "Introduces CMI-MTL, a cross-modal multi-task framework for Medical VQA that integrates fine-grained visual-text alignment, cross-modal interleaved representations, and free-form answer-enhanced learning to improve open-ended VQA; achieves state-of-the-art on VQA-RAD, SLAKE, and OVQA with added interpretability analyses.", "motivation": "Med-VQA methods struggle with cross-modal semantic alignment and open-ended answers. Self-attention methods often miss fine-grained image-text correspondence, and classification-based approaches limit free-form answer diversity and semantic detail. A framework that fuses fine-grained alignment, cross-modal interactions, and open-ended guidance could improve performance and interpretability.", "method": "Three modules: (1) FVTA for fine-grained visual-text feature alignment to select relevant image regions; (2) CIFR for cross-modal interleaved feature representation capturing sequential cross-modal interactions; (3) FFAE for free-form answer-enhanced multi-task learning by leveraging auxiliary knowledge from open-ended questions to boost open-ended Med-VQA.", "result": "CMI-MTL outperforms state-of-the-art methods on three Med-VQA datasets: VQA-RAD, SLAKE, and OVQA. Additional interpretability experiments validate effectiveness.", "conclusion": "The proposed CMI-MTL effectively tackles cross-modal alignment and open-ended answer generation in Med-VQA, improving accuracy and interpretability; code is publicly available for reproduction."}}
{"id": "2511.01226", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01226", "abs": "https://arxiv.org/abs/2511.01226", "authors": ["Themistoklis Vargiemezis", "Charilaos Kanatsoulis", "Catherine Gorl\u00e9"], "title": "WindMiL: Equivariant Graph Learning for Wind Loading Prediction", "comment": null, "summary": "Accurate prediction of wind loading on buildings is crucial for structural\nsafety and sustainable design, yet conventional approaches such as wind tunnel\ntesting and large-eddy simulation (LES) are prohibitively expensive for\nlarge-scale exploration. Each LES case typically requires at least 24 hours of\ncomputation, making comprehensive parametric studies infeasible. We introduce\nWindMiL, a new machine learning framework that combines systematic dataset\ngeneration with symmetry-aware graph neural networks (GNNs). First, we\nintroduce a large-scale dataset of wind loads on low-rise buildings by applying\nsigned distance function interpolation to roof geometries and simulating 462\ncases with LES across varying shapes and wind directions. Second, we develop a\nreflection-equivariant GNN that guarantees physically consistent predictions\nunder mirrored geometries. Across interpolation and extrapolation evaluations,\nWindMiL achieves high accuracy for both the mean and the standard deviation of\nsurface pressure coefficients (e.g., RMSE $\\leq 0.02$ for mean $C_p$) and\nremains accurate under reflected-test evaluation, maintaining hit rates above\n$96\\%$ where the non-equivariant baseline model drops by more than $10\\%$. By\npairing a systematic dataset with an equivariant surrogate, WindMiL enables\nefficient, scalable, and accurate predictions of wind loads on buildings.", "AI": {"tldr": "WindMiL combines a large LES-derived wind-load dataset with a symmetry-aware, reflection-equivariant Graph Neural Network to predict wind pressures on buildings. It delivers high accuracy for mean and variability (e.g., RMSE \u2264 0.02 for mean Cp) and robust performance under mirrored geometries (reflected-test hit rate > 96%), enabling scalable parametric studies.", "motivation": "Accurate wind loading is critical for safety and sustainable design, but traditional methods (wind tunnel, LES) are computationally expensive, hindering large-scale parametric exploration.", "method": "1) Dataset: generate a large wind-load dataset for low-rise buildings by interpolating roof geometries with signed distance functions and running 462 LES simulations across varying shapes and wind directions. 2) Model: develop a reflection-equivariant Graph Neural Network that guarantees physical consistency under mirrored geometries; evaluate on interpolation and extrapolation tasks.", "result": "Mean Cp RMSE \u2264 0.02; accurate prediction of the mean and standard deviation of surface pressure coefficients; reflected-test accuracy maintains hit rates above 96%, while a non-equivariant baseline loses more than 10% in this regime.", "conclusion": "Pairing a systematic, LES-derived dataset with a symmetry-aware surrogate yields efficient, scalable, and physically consistent wind-load predictions suitable for large-scale parametric studies and design optimization."}}
{"id": "2511.01234", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01234", "abs": "https://arxiv.org/abs/2511.01234", "authors": ["Min Gan", "Guang-Yong Chen", "Yang Yi", "Lin Yang"], "title": "A Saddle Point Remedy: Power of Variable Elimination in Non-convex Optimization", "comment": null, "summary": "The proliferation of saddle points, rather than poor local minima, is\nincreasingly understood to be a primary obstacle in large-scale non-convex\noptimization for machine learning. Variable elimination algorithms, like\nVariable Projection (VarPro), have long been observed to exhibit superior\nconvergence and robustness in practice, yet a principled understanding of why\nthey so effectively navigate these complex energy landscapes has remained\nelusive. In this work, we provide a rigorous geometric explanation by comparing\nthe optimization landscapes of the original and reduced formulations. Through a\nrigorous analysis based on Hessian inertia and the Schur complement, we prove\nthat variable elimination fundamentally reshapes the critical point structure\nof the objective function, revealing that local maxima in the reduced landscape\nare created from, and correspond directly to, saddle points in the original\nformulation. Our findings are illustrated on the canonical problem of\nnon-convex matrix factorization, visualized directly on two-parameter neural\nnetworks, and finally validated in training deep Residual Networks, where our\napproach yields dramatic improvements in stability and convergence to superior\nminima. This work goes beyond explaining an existing method; it establishes\nlandscape simplification via saddle point transformation as a powerful\nprinciple that can guide the design of a new generation of more robust and\nefficient optimization algorithms.", "AI": {"tldr": "Variable elimination (VarPro) reshapes optimization landscapes by transforming saddle points into local maxima in the reduced problem, explaining robust convergence in non-convex ML optimization. The work provides a geometric explanation via Hessian inertia and Schur complement, with empirical validation on matrix factorization, two-parameter nets, and deep ResNets, and posits landscape simplification as a design principle for robust optimization algorithms.", "motivation": "To understand why variable elimination methods like VarPro exhibit superior convergence and robustness in large-scale non-convex optimization relevant to machine learning, where saddle points proliferate.", "method": "Rigorous geometric analysis comparing original and reduced formulations using Hessian inertia and the Schur complement to characterize critical points; mapping of how maxima in reduced space correspond to saddles in the original; empirical illustrations on non-convex matrix factorization, visualization on simple neural nets, and validation in training deep residual networks.", "result": "Proves that variable elimination reshapes the critical point structure so that local maxima in the reduced landscape are created from saddle points in the original formulation; demonstrates dramatic improvements in stability and convergence in deep networks; establishes a principle of landscape simplification via saddle point transformation.", "conclusion": "Landscape simplification through saddle point transformation is a powerful principle that can guide the design of a new generation of more robust and efficient optimization algorithms."}}
{"id": "2511.01390", "categories": ["cs.CV", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.01390", "abs": "https://arxiv.org/abs/2511.01390", "authors": ["Xinyu Mao", "Junsi Li", "Haoji Zhang", "Yu Liang", "Ming Sun"], "title": "SEPS: Semantic-enhanced Patch Slimming Framework for fine-grained cross-modal alignment", "comment": null, "summary": "Fine-grained cross-modal alignment aims to establish precise local\ncorrespondences between vision and language, forming a cornerstone for visual\nquestion answering and related multimodal applications. Current approaches face\nchallenges in addressing patch redundancy and ambiguity, which arise from the\ninherent information density disparities across modalities. Recently,\nMultimodal Large Language Models (MLLMs) have emerged as promising solutions to\nbridge this gap through their robust semantic generation capabilities. However,\nthe dense textual outputs from MLLMs may introduce conflicts with the original\nsparse captions. Furthermore, accurately quantifying semantic relevance between\nrich visual patches and concise textual descriptions remains a core challenge.\nTo overcome these limitations, we introduce the Semantic-Enhanced Patch\nSlimming (SEPS) framework, which systematically addresses patch redundancy and\nambiguity. Our approach employs a two-stage mechanism to integrate unified\nsemantics from both dense and sparse texts, enabling the identification of\nsalient visual patches. Additionally, it leverages relevance-aware selection\nwith mean value computation to highlight crucial patch-word correspondences,\nthereby improving cross-modal similarity assessment. Comprehensive experiments\non Flickr30K and MS-COCO datasets validate that SEPS achieves superior\nperformance, surpassing existing approaches by 23\\%-86\\% in rSum across diverse\nmodel architectures, with notable enhancements in text-to-image retrieval\nscenarios. Our implementation is available at\nhttps://github.com/Sweet4tars/seps.git.", "AI": {"tldr": "SEPS proposes a Semantic-Enhanced Patch Slimming framework to reduce patch redundancy and ambiguity in fine-grained cross-modal alignment by merging semantics from dense and sparse texts, and using relevance-aware patch-word selection to improve cross-modal similarity; shows large gains on Flickr30K and MS-COCO, and is open-sourced.", "motivation": "Address patch redundancy and ambiguity caused by information density disparities between visual patches and textual descriptions. Dense outputs from MLLMs can conflict with sparse captions, making semantic relevance estimation difficult in cross-modal tasks like VQA and image-text retrieval.", "method": "A two-stage mechanism that integrates unified semantics from dense and sparse texts to identify salient visual patches. It employs relevance-aware selection with mean value computation to highlight crucial patch-word correspondences, improving cross-modal similarity assessment.", "result": "SEPS achieves 23%-86% gains in rSum over various model architectures on Flickr30K and MS-COCO, with notable improvements in text-to-image retrieval.", "conclusion": "SEPS effectively mitigates patch redundancy and ambiguity, enhances fine-grained cross-modal alignment, and provides strong, architecture-agnostic performance gains with open-source availability."}}
{"id": "2511.01249", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01249", "abs": "https://arxiv.org/abs/2511.01249", "authors": ["Kun-Wei Lin", "Yu-Chen Kuo", "Hsin-Yao Wang", "Yi-Ju Tseng"], "title": "KAT-GNN: A Knowledge-Augmented Temporal Graph Neural Network for Risk Prediction in Electronic Health Records", "comment": "10 pages, 3 figures", "summary": "Clinical risk prediction using electronic health records (EHRs) is vital to\nfacilitate timely interventions and clinical decision support. However,\nmodeling heterogeneous and irregular temporal EHR data presents significant\nchallenges. We propose \\textbf{KAT-GNN} (Knowledge-Augmented Temporal Graph\nNeural Network), a graph-based framework that integrates clinical knowledge and\ntemporal dynamics for risk prediction. KAT-GNN first constructs\nmodality-specific patient graphs from EHRs. These graphs are then augmented\nusing two knowledge sources: (1) ontology-driven edges derived from SNOMED CT\nand (2) co-occurrence priors extracted from EHRs. Subsequently, a time-aware\ntransformer is employed to capture longitudinal dynamics from the graph-encoded\npatient representations. KAT-GNN is evaluated on three distinct datasets and\ntasks: coronary artery disease (CAD) prediction using the Chang Gung Research\nDatabase (CGRD) and in-hospital mortality prediction using the MIMIC-III and\nMIMIC-IV datasets. KAT-GNN achieves state-of-the-art performance in CAD\nprediction (AUROC: 0.9269 $\\pm$ 0.0029) and demonstrated strong results in\nmortality prediction in MIMIC-III (AUROC: 0.9230 $\\pm$ 0.0070) and MIMIC-IV\n(AUROC: 0.8849 $\\pm$ 0.0089), consistently outperforming established baselines\nsuch as GRASP and RETAIN. Ablation studies confirm that both knowledge-based\naugmentation and the temporal modeling component are significant contributors\nto performance gains. These findings demonstrate that the integration of\nclinical knowledge into graph representations, coupled with a time-aware\nattention mechanism, provides an effective and generalizable approach for risk\nprediction across diverse clinical tasks and datasets.", "AI": {"tldr": "A knowledge-augmented temporal graph neural network (KAT-GNN) for EHR risk prediction that combines ontology-driven SNOMED edges and data-driven co-occurrence priors with a time-aware transformer, achieving state-of-the-art CAD prediction and strong mortality results across MIMIC-III/IV; ablations show both knowledge augmentation and temporal modeling are beneficial.", "motivation": "Modeling heterogeneous, irregular temporal EHR data is challenging; leveraging structured clinical knowledge and temporal dynamics could improve predictive performance across diverse tasks and datasets.", "method": "Construct modality-specific patient graphs from EHRs. Augment graphs with (1) ontology-derived edges from SNOMED CT and (2) co-occurrence priors learned from EHR data. Use a time-aware transformer to capture longitudinal dynamics on graph-encoded patient representations.", "result": "CAD prediction on CGRD with AUROC 0.9269\u00b10.0029. In-hospital mortality prediction on MIMIC-III AUROC 0.9230\u00b10.0070; on MIMIC-IV AUROC 0.8849\u00b10.0089. Outperforms baselines such as GRASP and RETAIN. Ablation studies show both augmentation and temporal modeling contribute significantly to performance.", "conclusion": "Integrating clinical knowledge into graph representations, along with a time-aware attention mechanism, provides an effective and generalizable approach for risk prediction across diverse clinical tasks and datasets."}}
{"id": "2511.01399", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01399", "abs": "https://arxiv.org/abs/2511.01399", "authors": ["Ya Wen", "Yutong Qiao", "Chi Chiu Lam", "Ioannis Brilakis", "Sanghoon Lee", "Mun On Wong"], "title": "Semantic BIM enrichment for firefighting assets: Fire-ART dataset and panoramic image-based 3D reconstruction", "comment": null, "summary": "Inventory management of firefighting assets is crucial for emergency\npreparedness, risk assessment, and on-site fire response. However, conventional\nmethods are inefficient due to limited capabilities in automated asset\nrecognition and reconstruction. To address the challenge, this research\nintroduces the Fire-ART dataset and develops a panoramic image-based\nreconstruction approach for semantic enrichment of firefighting assets into BIM\nmodels. The Fire-ART dataset covers 15 fundamental assets, comprising 2,626\nimages and 6,627 instances, making it an extensive and publicly accessible\ndataset for asset recognition. In addition, the reconstruction approach\nintegrates modified cube-map conversion and radius-based spherical camera\nprojection to enhance recognition and localization accuracy. Through\nvalidations with two real-world case studies, the proposed approach achieves\nF1-scores of 73% and 88% and localization errors of 0.620 and 0.428 meters,\nrespectively. The Fire-ART dataset and the reconstruction approach offer\nvaluable resources and robust technical solutions to enhance the accurate\ndigital management of fire safety equipment.", "AI": {"tldr": "Introduces the Fire-ART dataset and a panoramic image-based reconstruction method to embed firefighting assets into BIM, enabling improved recognition and localization for inventory management.", "motivation": "There is a need for automated, accurate recognition and reconstruction of firefighting assets to support emergency preparedness, risk assessment, and rapid on-site response, overcoming limitations of conventional methods.", "method": "Develop a panoramic reconstruction pipeline using the Fire-ART dataset (15 asset types, 2,626 images, 6,627 instances) and apply modified cube-map conversion plus radius-based spherical camera projection to enhance asset recognition and localization for BIM integration.", "result": "Two real-world case studies yielded F1-scores of 0.73 and 0.88, with localization errors of 0.620 m and 0.428 m, respectively.", "conclusion": "The Fire-ART dataset and the reconstruction approach provide valuable resources and robust methods for accurate digital management of fire safety equipment in BIM."}}
{"id": "2511.01267", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01267", "abs": "https://arxiv.org/abs/2511.01267", "authors": ["Yiyang Yang", "Xiejian Chi", "Shanxing Gao", "Kaidong Wang", "Yao Wang"], "title": "A Spatio-Temporal Online Robust Tensor Recovery Approach for Streaming Traffic Data Imputation", "comment": null, "summary": "Data quality is critical to Intelligent Transportation Systems (ITS), as\ncomplete and accurate traffic data underpin reliable decision-making in traffic\ncontrol and management. Recent advances in low-rank tensor recovery algorithms\nhave shown strong potential in capturing the inherent structure of\nhigh-dimensional traffic data and restoring degraded observations. However,\ntraditional batch-based methods demand substantial computational and storage\nresources, which limits their scalability in the face of continuously expanding\ntraffic data volumes. Moreover, recent online tensor recovery methods often\nsuffer from severe performance degradation in complex real-world scenarios due\nto their insufficient exploitation of the intrinsic structural properties of\ntraffic data. To address these challenges, we reformulate the traffic data\nrecovery problem within a streaming framework, and propose a novel online\nrobust tensor recovery algorithm that simultaneously leverages both the global\nspatio-temporal correlations and local consistency of traffic data, achieving\nhigh recovery accuracy and significantly improved computational efficiency in\nlarge-scale scenarios. Our method is capable of simultaneously handling missing\nand anomalous values in traffic data, and demonstrates strong adaptability\nacross diverse missing patterns. Experimental results on three real-world\ntraffic datasets demonstrate that the proposed approach achieves high recovery\naccuracy while significantly improving computational efficiency by up to three\norders of magnitude compared to state-of-the-art batch-based methods. These\nfindings highlight the potential of the proposed approach as a scalable and\neffective solution for traffic data quality enhancement in ITS.", "AI": {"tldr": "An online robust tensor recovery method for streaming traffic data that exploits global spatio-temporal correlations and local consistency, handling missing and anomalous values; achieves high recovery accuracy with up to 1000x faster performance than batch methods, validated on three real-world datasets.", "motivation": "Data quality in Intelligent Transportation Systems is critical for reliable traffic control and management. Batch-based low-rank tensor methods are computationally expensive and poorly scalable to growing data streams, while existing online methods underutilize structural properties of traffic data. There is a need for a scalable, accurate online approach that can handle missing data and outliers.", "method": "An online robust tensor recovery algorithm embedded in a streaming framework that simultaneously leverages global spatio-temporal correlations and local data consistency. The method handles missing values and anomalies, adapts to diverse missing patterns, and updates incrementally to maintain scalability for large-scale traffic data.", "result": "Experiments on three real-world traffic datasets show high recovery accuracy and substantially improved computational efficiency, up to three orders of magnitude faster than state-of-the-art batch-based methods, demonstrating scalability and effectiveness for traffic data quality enhancement in ITS.", "conclusion": "The proposed online robust tensor recovery approach is a scalable and effective solution for ITS traffic data quality improvement, capable of handling missing and anomalous observations while exploiting both global and local structural properties of traffic data."}}
{"id": "2511.01411", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01411", "abs": "https://arxiv.org/abs/2511.01411", "authors": ["Reza Karimzadeh", "Albert Alonso", "Frans Zdyb", "Julius B. Kirkegaard", "Bulat Ibragimov"], "title": "Extremal Contours: Gradient-driven contours for compact visual attribution", "comment": null, "summary": "Faithful yet compact explanations for vision models remain a challenge, as\ncommonly used dense perturbation masks are often fragmented and overfitted,\nneeding careful post-processing. Here, we present a training-free explanation\nmethod that replaces dense masks with smooth tunable contours. A star-convex\nregion is parameterized by a truncated Fourier series and optimized under an\nextremal preserve/delete objective using the classifier gradients. The approach\nguarantees a single, simply connected mask, cuts the number of free parameters\nby orders of magnitude, and yields stable boundary updates without cleanup.\nRestricting solutions to low-dimensional, smooth contours makes the method\nrobust to adversarial masking artifacts. On ImageNet classifiers, it matches\nthe extremal fidelity of dense masks while producing compact, interpretable\nregions with improved run-to-run consistency. Explicit area control also\nenables importance contour maps, yielding a transparent fidelity-area profiles.\nFinally, we extend the approach to multi-contour and show how it can localize\nmultiple objects within the same framework. Across benchmarks, the method\nachieves higher relevance mass and lower complexity than gradient and\nperturbation based baselines, with especially strong gains on self-supervised\nDINO models where it improves relevance mass by over 15% and maintains positive\nfaithfulness correlations.", "AI": {"tldr": "A training-free explanation method for vision models that uses smooth, Fourier-parameterized star-convex contours to replace dense masks, yielding compact, faithful, and robust explanations with multi-contour extensions.", "motivation": "Dense perturbation masks in local explanations are often fragmented, overfitted, and require post-processing. A simple, robust, training-free approach that delivers faithful explanations with compact boundary representations would improve interpretability and stability across models.", "method": "Parameterize a star-convex region by a truncated Fourier series to form a smooth, simply connected mask. Optimize with an extremal preserve/delete objective using classifier gradients, yielding a single (or multiple) low-parameter contours with stable boundary updates and explicit area control. Extendable to multi-contour setups to localize multiple objects.", "result": "On ImageNet classifiers, the method matches the extremal fidelity of dense masks while producing compact, interpretable regions and better run-to-run consistency. It provides explicit area control for importance contour maps. The approach outperforms gradient and perturbation baselines in relevance mass and complexity, with notable gains on self-supervised DINO models (relevance mass up >15%).", "conclusion": "The proposed training-free, contour-based explanations yield faithful, compact, and robust region masks with scalable multi-object localization, offering improved stability and interpretability over existing dense-mask methods and baselines."}}
{"id": "2511.01275", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01275", "abs": "https://arxiv.org/abs/2511.01275", "authors": ["Zan Li", "Kyongmin Yeo", "Wesley Gifford", "Lara Marcuse", "Madeline Fields", "B\u00fclent Yener"], "title": "Adversarial Spatio-Temporal Attention Networks for Epileptic Seizure Forecasting", "comment": null, "summary": "Forecasting epileptic seizures from multivariate EEG signals represents a\ncritical challenge in healthcare time series prediction, requiring high\nsensitivity, low false alarm rates, and subject-specific adaptability. We\npresent STAN, an Adversarial Spatio-Temporal Attention Network that jointly\nmodels spatial brain connectivity and temporal neural dynamics through cascaded\nattention blocks with alternating spatial and temporal modules. Unlike existing\napproaches that assume fixed preictal durations or separately process spatial\nand temporal features, STAN captures bidirectional dependencies between spatial\nand temporal patterns through a unified cascaded architecture. Adversarial\ntraining with gradient penalty enables robust discrimination between interictal\nand preictal states learned from clearly defined 15-minute preictal windows.\nContinuous 90-minute pre-seizure monitoring reveals that the learned\nspatio-temporal attention patterns enable early detection: reliable alarms\ntrigger at subject-specific times (typically 15-45 minutes before onset),\nreflecting the model's capacity to capture subtle preictal dynamics without\nrequiring individualized training. Experiments on two benchmark EEG datasets\n(CHB-MIT scalp: 8 subjects, 46 events; MSSM intracranial: 4 subjects, 14\nevents) demonstrate state-of-the-art performance: 96.6% sensitivity with 0.011\nfalse detections per hour and 94.2% sensitivity with 0.063 false detections per\nhour, respectively, while maintaining computational efficiency (2.3M\nparameters, 45 ms latency, 180 MB memory) for real-time edge deployment. Beyond\nepilepsy, the proposed framework provides a general paradigm for\nspatio-temporal forecasting in healthcare and other time series domains where\nindividual heterogeneity and interpretability are crucial.", "AI": {"tldr": "STAN is an adversarial spatio-temporal attention network for forecasting epileptic seizures from multivariate EEG, achieving state-of-the-art accuracy and enabling early, subject-specific detection with efficient edge deployment.", "motivation": "Forecasting seizures is critical for patient safety and care, requiring high sensitivity, low false alarms, and adaptability to individual differences; existing methods struggle with fixed preictal windows and decoupled spatial/temporal processing.", "method": "STAN uses cascaded attention blocks that alternately model spatial brain connectivity and temporal neural dynamics, jointly learning bidirectional dependencies. It uses adversarial training with gradient penalty on clearly defined 15-minute preictal windows, enabling robust interictal/preictal discrimination. The architecture supports continuous 90-minute monitoring and is designed for real-time edge deployment (2.3M parameters, ~45 ms latency, ~180 MB memory).", "result": "On CHB-MIT scalp data (8 subjects, 46 events): 96.6% sensitivity with 0.011 false detections per hour; on MSSM intracranial data (4 subjects, 14 events): 94.2% sensitivity with 0.063 false detections per hour.", "conclusion": "The framework provides a general, interpretable paradigm for spatio-temporal forecasting in healthcare and other domains with heterogeneity across individuals, enabling early, customizable detections without extensive per-subject training and supporting real-time deployment."}}
{"id": "2511.01419", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01419", "abs": "https://arxiv.org/abs/2511.01419", "authors": ["Yongqi Yang", "Huayang Huang", "Xu Peng", "Xiaobin Hu", "Donghao Luo", "Jiangning Zhang", "Chengjie Wang", "Yu Wu"], "title": "Towards One-step Causal Video Generation via Adversarial Self-Distillation", "comment": "Under double-blind review as a conference paper", "summary": "Recent hybrid video generation models combine autoregressive temporal\ndynamics with diffusion-based spatial denoising, but their sequential,\niterative nature leads to error accumulation and long inference times. In this\nwork, we propose a distillation-based framework for efficient causal video\ngeneration that enables high-quality synthesis with extremely limited denoising\nsteps. Our approach builds upon the Distribution Matching Distillation (DMD)\nframework and proposes a novel Adversarial Self-Distillation (ASD) strategy,\nwhich aligns the outputs of the student model's n-step denoising process with\nits (n+1)-step version at the distribution level. This design provides smoother\nsupervision by bridging small intra-student gaps and more informative guidance\nby combining teacher knowledge with locally consistent student behavior,\nsubstantially improving training stability and generation quality in extremely\nfew-step scenarios (e.g., 1-2 steps). In addition, we present a First-Frame\nEnhancement (FFE) strategy, which allocates more denoising steps to the initial\nframes to mitigate error propagation while applying larger skipping steps to\nlater frames. Extensive experiments on VBench demonstrate that our method\nsurpasses state-of-the-art approaches in both one-step and two-step video\ngeneration. Notably, our framework produces a single distilled model that\nflexibly supports multiple inference-step settings, eliminating the need for\nrepeated re-distillation and enabling efficient, high-quality video synthesis.", "AI": {"tldr": "A distillation-based framework for fast, high-quality causal video generation using Adversarial Self-Distillation (ASD) and First-Frame Enhancement (FFE) to enable 1\u20132 denoising steps with a single flexible distilled model.", "motivation": "Hybrid video generation methods suffer from error accumulation and slow inference due to iterative denoising; there is a need for efficient, high-quality video synthesis with very few denoising steps without retraining for different step settings.", "method": "Builds on Distribution Matching Distillation (DMD). Introduces Adversarial Self-Distillation (ASD) to align the student model's n-step denoising distribution with its (n+1)-step version at the distribution level, providing smoother supervision and combining teacher guidance with locally consistent student behavior. Adds First-Frame Enhancement (FFE) to allocate more denoising steps to initial frames while using larger skips for later frames. Results enable a single distilled model supporting multiple inference-step settings.", "result": "Outperforms state-of-the-art methods in 1-step and 2-step video generation on VBench; achieves high-quality synthesis with extremely limited denoising steps; no need for repeated re-distillation.", "conclusion": "ASD and FFE substantially improve training stability and generation quality in extremely few-step video generation, delivering a flexible, efficient distilled model for high-quality video synthesis across multiple inference-step budgets."}}
{"id": "2511.01277", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.01277", "abs": "https://arxiv.org/abs/2511.01277", "authors": ["Annabelle Martin", "Daphne Kontogiorgos-Heintz", "Jeff Nivala"], "title": "Identification of Capture Phases in Nanopore Protein Sequencing Data Using a Deep Learning Model", "comment": null, "summary": "Nanopore protein sequencing produces long, noisy ionic current traces in\nwhich key molecular phases, such as protein capture and translocation, are\nembedded. Capture phases mark the successful entry of a protein into the pore\nand serve as both a checkpoint and a signal that a channel merits further\nanalysis. However, manual identification of capture phases is time-intensive,\noften requiring several days for expert reviewers to annotate the data due to\nthe need for domain-specific interpretation of complex signal patterns. To\naddress this, a lightweight one-dimensional convolutional neural network (1D\nCNN) was developed and trained to detect capture phases in down-sampled signal\nwindows. Evaluated against CNN-LSTM (Long Short-Term Memory) hybrids,\nhistogram-based classifiers, and other CNN variants using run-level data\nsplits, our best model, CaptureNet-Deep, achieved an F1 score of 0.94 and\nprecision of 93.39% on held-out test data. The model supports low-latency\ninference and is integrated into a dashboard for Oxford Nanopore experiments,\nreducing the total analysis time from several days to under thirty minutes.\nThese results show that efficient, real-time capture detection is possible\nusing simple, interpretable architectures and suggest a broader role for\nlightweight ML models in sequencing workflows.", "AI": {"tldr": "A lightweight 1D CNN (CaptureNet-Deep) detects nanopore protein capture phases with high accuracy (F1 0.94, precision 93.39%), enabling real-time, low-latency inference and dramatically reducing analysis time.", "motivation": "Manual annotation of capture phases is labor-intensive and time-consuming (days) due to complex, long, noisy ionic current traces; there is a need for real-time, interpretable ML in nanopore sequencing workflows.", "method": "Developed a 1D CNN (CaptureNet-Deep) trained on down-sampled signal windows to detect capture events. Compared against CNN-LSTM hybrids, histogram-based classifiers, and other CNN variants using run-level data splits. Integrated into a dashboard for Oxford Nanopore experiments to enable real-time use.", "result": "Best model achieved F1 score of 0.94 and precision of 93.39% on held-out test data. Demonstrated low-latency inference and integration into a dashboard, reducing analysis time from days to under thirty minutes.", "conclusion": "Shows that efficient, real-time capture detection is possible with simple, interpretable architectures and suggests a broader role for lightweight ML models in sequencing workflows."}}
{"id": "2511.01427", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01427", "abs": "https://arxiv.org/abs/2511.01427", "authors": ["Yinchao Ma", "Yuyang Tang", "Wenfei Yang", "Tianzhu Zhang", "Xu Zhou", "Feng Wu"], "title": "UniSOT: A Unified Framework for Multi-Modality Single Object Tracking", "comment": "The paper has been accepted by TPAMI", "summary": "Single object tracking aims to localize target object with specific reference\nmodalities (bounding box, natural language or both) in a sequence of specific\nvideo modalities (RGB, RGB+Depth, RGB+Thermal or RGB+Event.). Different\nreference modalities enable various human-machine interactions, and different\nvideo modalities are demanded in complex scenarios to enhance tracking\nrobustness. Existing trackers are designed for single or several video\nmodalities with single or several reference modalities, which leads to separate\nmodel designs and limits practical applications. Practically, a unified tracker\nis needed to handle various requirements. To the best of our knowledge, there\nis still no tracker that can perform tracking with these above reference\nmodalities across these video modalities simultaneously. Thus, in this paper,\nwe present a unified tracker, UniSOT, for different combinations of three\nreference modalities and four video modalities with uniform parameters.\nExtensive experimental results on 18 visual tracking, vision-language tracking\nand RGB+X tracking benchmarks demonstrate that UniSOT shows superior\nperformance against modality-specific counterparts. Notably, UniSOT outperforms\nprevious counterparts by over 3.0\\% AUC on TNL2K across all three reference\nmodalities and outperforms Un-Track by over 2.0\\% main metric across all three\nRGB+X video modalities.", "AI": {"tldr": "UniSOT is a unified tracker that supports combinations of three reference modalities (bounding box, natural language, or both) and four video modalities (RGB, RGB+Depth, RGB+Thermal, RGB+Event) using uniform parameters, achieving strong results across 18 benchmarks, including >3% AUC gains on TNL2K and >2% gains on RGB+X tracking.", "motivation": "Existing trackers are specialized to specific modality pairs, requiring multiple models and hindering broad applicability. A single, unified tracker across reference and video modalities would simplify deployment and potentially improve robustness in diverse scenarios.", "method": "Developed UniSOT with a single architecture and shared parameters that can handle three reference modalities and four video modalities. Conducted extensive experiments on 18 benchmarks spanning visual tracking, vision-language tracking, and RGB+X tracking to demonstrate cross-modal generalization and superiority over modality-specific baselines.", "result": "UniSOT demonstrates superior performance against modality-specific counterparts. It outperforms prior methods by over 3.0% AUC on TNL2K across all three reference modalities and by over 2.0% main metric across all three RGB+X video modalities.", "conclusion": "A practical, unified tracking framework that accommodates multiple reference and video modalities with uniform parameters, delivering robust and superior performance across diverse tracking scenarios."}}
{"id": "2511.01434", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01434", "abs": "https://arxiv.org/abs/2511.01434", "authors": ["Seongkyu Choi", "Jhonghyun An"], "title": "Terrain-Enhanced Resolution-aware Refinement Attention for Off-Road Segmentation", "comment": null, "summary": "Off-road semantic segmentation suffers from thick, inconsistent boundaries,\nsparse supervision for rare classes, and pervasive label noise. Designs that\nfuse only at low resolution blur edges and propagate local errors, whereas\nmaintaining high-resolution pathways or repeating high-resolution fusions is\ncostly and fragile to noise. We introduce a resolutionaware token decoder that\nbalances global semantics, local consistency, and boundary fidelity under\nimperfect supervision. Most computation occurs at a low-resolution bottleneck;\na gated cross-attention injects fine-scale detail, and only a sparse,\nuncertainty-selected set of pixels is refined. The components are co-designed\nand tightly integrated: global self-attention with lightweight dilated\ndepthwise refinement restores local coherence; a gated cross-attention\nintegrates fine-scale features from a standard high-resolution encoder stream\nwithout amplifying noise; and a class-aware point refinement corrects residual\nambiguities with negligible overhead. During training, we add a boundary-band\nconsistency regularizer that encourages coherent predictions in a thin\nneighborhood around annotated edges, with no inference-time cost. Overall, the\nresults indicate competitive performance and improved stability across\ntransitions.", "AI": {"tldr": "A resolution-aware token decoder for off-road semantic segmentation balances global semantics, local boundary fidelity, and supervision noise by processing mostly at low resolution and selectively refining sparse high-resolution pixels; it includes a global self-attention backbone, gated cross-attention for fine-scale details, and a class-aware refinement, plus a boundary-consistency regularizer during training for edge coherence.", "motivation": "Off-road semantic segmentation faces thick, inconsistent boundaries, sparse supervision for rare classes, and noise-laden labels. Many methods either fuse only at low resolution (blurring edges) or rely on high-resolution pathways (costly and fragile to noise).", "method": "Propose a resolution-aware token decoder that operates mainly at a low-resolution bottleneck. Use a gated cross-attention to inject fine-scale detail from a high-resolution encoder stream while avoiding noise amplification. Employ a global self-attention with lightweight dilated depthwise refinement to restore local coherence. Include a class-aware point refinement to correct residual ambiguities with negligible overhead. All components are tightly integrated and co-designed. Train with a boundary-band consistency regularizer that enforces coherent predictions in a thin neighborhood around annotated edges, without adding inference cost.", "result": "The approach yields competitive performance and improved stability across transitions in off-road segmentation tasks, indicating robustness to boundary imprecision, sparse supervision, and label noise.", "conclusion": "A tightly integrated, low-cost, resolution-aware decoder that combines global semantics with local boundary fidelity and selective refinement achieves robust off-road segmentation under imperfect supervision, with no inference-time cost from the boundary regularizer."}}
{"id": "2511.01286", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.01286", "abs": "https://arxiv.org/abs/2511.01286", "authors": ["Sivaram Krishnan", "Jinho Choi", "Jihong Park", "Gregory Sherman", "Benjamin Campbell"], "title": "Koopman-based Prediction of Connectivity for Flying Ad Hoc Networks", "comment": null, "summary": "The application of machine learning (ML) to communication systems is expected\nto play a pivotal role in future artificial intelligence (AI)-based\nnext-generation wireless networks. While most existing works focus on ML\ntechniques for static wireless environments, they often face limitations when\napplied to highly dynamic environments, such as flying ad hoc networks\n(FANETs). This paper explores the use of data-driven Koopman approaches to\naddress these challenges. Specifically, we investigate how these approaches can\nmodel UAV trajectory dynamics within FANETs, enabling more accurate predictions\nand improved network performance. By leveraging Koopman operator theory, we\npropose two possible approaches -- centralized and distributed -- to\nefficiently address the challenges posed by the constantly changing topology of\nFANETs. To demonstrate this, we consider a FANET performing surveillance with\nUAVs following pre-determined trajectories and predict\nsignal-to-interference-plus-noise ratios (SINRs) to ensure reliable\ncommunication between UAVs. Our results show that these approaches can\naccurately predict connectivity and isolation events that lead to modelled\ncommunication outages. This capability could help UAVs schedule their\ntransmissions based on these predictions.", "AI": {"tldr": "Koopman-based data-driven schemes (centralized and distributed) model UAV dynamics in FANETs to predict SINR/connectivity and outages, enabling proactive scheduling.", "motivation": "ML in wireless networks often assumes static channels; FANETs are highly dynamic with changing topology. Koopman operator theory offers a way to linearize nonlinear dynamics in lifted space, enabling data-driven prediction of connectivity and outages in UAV networks.", "method": "Develop two approaches (centralized and distributed) using Koopman operator theory to learn UAV trajectory dynamics from data and predict SINR/connectivity and isolation events in FANETs. Evaluate on a surveillance scenario with predefined UAV trajectories.", "result": "Both centralized and distributed Koopman approaches accurately predict connectivity and isolation events leading to outages; predictions enable UAVs to schedule transmissions proactively. The methods demonstrate reliable SINR forecasts and outage predictions with trade-offs in scalability and communication overhead between the two variants.", "conclusion": "Koopman-based data-driven modeling is effective for highly dynamic FANETs. Centralized and distributed variants address topology changes and enable proactive resource management and reliable communications in AI-driven next-generation networks."}}
{"id": "2511.01435", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01435", "abs": "https://arxiv.org/abs/2511.01435", "authors": ["SiWoo Kim", "JhongHyun An"], "title": "Contrast-Guided Cross-Modal Distillation for Thermal Object Detection", "comment": null, "summary": "Robust perception at night remains challenging for thermal-infrared\ndetection: low contrast and weak high-frequency cues lead to duplicate,\noverlapping boxes, missed small objects, and class confusion. Prior remedies\neither translate TIR to RGB and hope pixel fidelity transfers to detection --\nmaking performance fragile to color or structure artifacts -- or fuse RGB and\nTIR at test time, which requires extra sensors, precise calibration, and higher\nruntime cost. Both lines can help in favorable conditions, but do not directly\nshape the thermal representation used by the detector. We keep mono-modality\ninference and tackle the root causes during training. Specifically, we\nintroduce training-only objectives that sharpen instance-level decision\nboundaries by pulling together features of the same class and pushing apart\nthose of different classes -- suppressing duplicate and confusing detections --\nand that inject cross-modal semantic priors by aligning the student's\nmulti-level pyramid features with an RGB-trained teacher, thereby strengthening\ntexture-poor thermal features without visible input at test time. In\nexperiments, our method outperformed prior approaches and achieved\nstate-of-the-art performance.", "AI": {"tldr": "Training-time objectives tighten intra-class features and align thermal detector features with an RGB teacher, enabling robust mono-modal (TIR) detection at night without extra sensors or test-time RGB input; it achieves state-of-the-art performance.", "motivation": "Thermal infrared detection at night suffers from low contrast and weak high-frequency cues, causing duplicate boxes, missed small objects, and class confusion. Traditional fixes (RGB translation or RGB-T fusion) either degrade due to color/structure artifacts or require extra sensors and calibration.", "method": "Introduce training-only objectives: (1) push-pull losses that pull together features of the same class and push apart different classes to sharpen instance-level decision boundaries; (2) cross-modal priors by aligning the student detector's multi-level pyramid features with an RGB-trained teacher, transferring semantic texture information to texture-poor TIR features without using RGB input at test time.", "result": "Experiments show the proposed method outperforms prior approaches and achieves state-of-the-art performance in robust night perception using thermal imaging.", "conclusion": "Maintaining mono-modality inference while training with cross-modal priors and intra-class feature sharpening yields stronger thermal representations and improved detection under challenging night conditions, without requiring additional sensors at test time."}}
{"id": "2511.01296", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01296", "abs": "https://arxiv.org/abs/2511.01296", "authors": ["Guanjie Cheng", "Mengzhen Yang", "Xinkui Zhao", "Shuyi Yu", "Tianyu Du", "Yangyang Wu", "Mengying Zhu", "Shuiguang Deng"], "title": "LSHFed: Robust and Communication-Efficient Federated Learning with Locally-Sensitive Hashing Gradient Mapping", "comment": null, "summary": "Federated learning (FL) enables collaborative model training across\ndistributed nodes without exposing raw data, but its decentralized nature makes\nit vulnerable in trust-deficient environments. Inference attacks may recover\nsensitive information from gradient updates, while poisoning attacks can\ndegrade model performance or induce malicious behaviors. Existing defenses\noften suffer from high communication and computation costs, or limited\ndetection precision. To address these issues, we propose LSHFed, a robust and\ncommunication-efficient FL framework that simultaneously enhances aggregation\nrobustness and privacy preservation. At its core, LSHFed incorporates LSHGM, a\nnovel gradient verification mechanism that projects high-dimensional gradients\ninto compact binary representations via multi-hyperplane locally-sensitive\nhashing. This enables accurate detection and filtering of malicious gradients\nusing only their irreversible hash forms, thus mitigating privacy leakage risks\nand substantially reducing transmission overhead. Extensive experiments\ndemonstrate that LSHFed maintains high model performance even when up to 50% of\nparticipants are collusive adversaries while achieving up to a 1000x reduction\nin gradient verification communication compared to full-gradient methods.", "AI": {"tldr": "LSHFed is a robust, communication-efficient federated learning framework that uses LSH-based gradient verification (LSHGM) to detect and filter malicious gradients, preserving privacy and reducing communication, while tolerating colluding adversaries.", "motivation": "Federated learning is vulnerable to inference and poisoning attacks in trust-deficient environments. Existing defenses have high costs or limited precision; a method that is robust, privacy-preserving, and communication-efficient is needed.", "method": "LSHFed introduces LSHGM, which projects high-dimensional gradients into compact binary representations using multi-hyperplane locally-sensitive hashing. Progressively verifies gradients via irreversible hash forms to detect and filter malicious updates, enabling robust aggregation with reduced data transmission.", "result": "Experiments show LSHFed maintains model performance even with up to 50% collusive adversaries and achieves up to a 1000x reduction in gradient verification communication compared to full-gradient methods.", "conclusion": "LSHFed provides a robust and privacy-preserving FL framework with substantially lower communication costs, suitable for trust-deficient environments where malicious participants may collude."}}
{"id": "2511.01449", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01449", "abs": "https://arxiv.org/abs/2511.01449", "authors": ["Riddhi Jain", "Manasi Patwardhan", "Aayush Mishra", "Parijat Deshpande", "Beena Rai"], "title": "Privacy Preserving Ordinal-Meta Learning with VLMs for Fine-Grained Fruit Quality Prediction", "comment": "9 pages, 1 figure, 4 tables", "summary": "To effectively manage the wastage of perishable fruits, it is crucial to\naccurately predict their freshness or shelf life using non-invasive methods\nthat rely on visual data. In this regard, deep learning techniques can offer a\nviable solution. However, obtaining fine-grained fruit freshness labels from\nexperts is costly, leading to a scarcity of data. Closed proprietary Vision\nLanguage Models (VLMs), such as Gemini, have demonstrated strong performance in\nfruit freshness detection task in both zero-shot and few-shot settings.\nNonetheless, food retail organizations are unable to utilize these proprietary\nmodels due to concerns related to data privacy, while existing open-source VLMs\nyield sub-optimal performance for the task. Fine-tuning these open-source\nmodels with limited data fails to achieve the performance levels of proprietary\nmodels. In this work, we introduce a Model-Agnostic Ordinal Meta-Learning\n(MAOML) algorithm, designed to train smaller VLMs. This approach utilizes\nmeta-learning to address data sparsity and leverages label ordinality, thereby\nachieving state-of-the-art performance in the fruit freshness classification\ntask under both zero-shot and few-shot settings. Our method achieves an\nindustry-standard accuracy of 92.71%, averaged across all fruits.\n  Keywords: Fruit Quality Prediction, Vision Language Models, Meta Learning,\nOrdinal Regression", "AI": {"tldr": "MAOML enables small open-source VLMs to reach SOTA in fruit freshness classification under zero-/few-shot, addressing data scarcity and privacy by using meta-learning and ordinal labels, achieving 92.71% accuracy.", "motivation": "Perishable fruit spoilage leads to waste; visual data to predict freshness; data labeling is costly; proprietary VLMs perform well but privacy concerns; open-source models underperform and fine-tuning with limited data is insufficient.", "method": "Proposes Model-Agnostic Ordinal Meta-Learning (MAOML) that uses meta-learning to adapt to data-scarce scenarios and exploit label ordinality; trains smaller VLMs possibly with ordinal regression.", "result": "State-of-the-art performance in fruit freshness classification in zero-shot and few-shot; 92.71% accuracy averaged across fruits.", "conclusion": "MAOML mitigates data sparsity and privacy barriers, enabling strong performance with smaller models; promising for fruit quality prediction tasks."}}
{"id": "2511.01343", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01343", "abs": "https://arxiv.org/abs/2511.01343", "authors": ["\u00c1lvaro V\u00e1zquez Rodr\u00edguez", "Manuel Fern\u00e1ndez-Veiga", "Carlos Giraldo-Rodr\u00edguez"], "title": "Diffusion-Based Solver for CNF Placement on the Cloud-Continuum", "comment": "7 pages, 7 figures. Presented at PE-WASUN'25 (IEEE International\n  Symposium on Performance Evaluation of Wireless Ad Hoc, Sensor, and\n  Ubiquitous Networks)", "summary": "The placement of Cloud-Native Network Functions (CNFs) across the\nCloud-Continuum represents a core challenge in the orchestration of current 5G\nand future 6G networks. The process involves the placement of interdependent\ncomputing tasks, structured as Service Function Chains, over distributed cloud\ninfrastructures. This is achieved while satisfying strict resource, bandwidth\nand latency constraints. It is acknowledged that classical approaches,\nincluding mixed-integer nonlinear programming, heuristics and reinforcement\nlearning are limited in terms of scalability, constraint handling and\ngeneralisation capacity. In the present study, a novel theoretical framework is\nproposed, which is based on Denoising Diffusion Probabilistic Models (DDPM) for\nCNF placement. The present approach proposes a reconceptualisation of placement\nas a generative graph to assignment task, where the placement problem is\nencoded as a heterogeneous graph, and a Graph Neural Network denoiser is\ntrained to iteratively refine noisy CNF-to-cloud assignment matrices. The model\nincorporates constraint-specific losses directly into the loss function,\nthereby allowing it to learn feasible solution spaces. The integration of the\nDDPM formulation with structured combinatorial constraints is achieved through\na rigorous and systematic approach. Extensive evaluations across diverse\ntopologies have been conducted, which have confirmed that the model\nconsistently produces feasible solutions with orders of magnitude faster\ninference than MINLP solvers. The results obtained demonstrate the potential of\ndiffusion-based generative modelling for constrained network embedding\nproblems, making an impact towards the practical, scalable orchestration of\ndistributed Cloud-Native Network Functions.", "AI": {"tldr": "A diffusion-based generative framework with a graph neural network denoiser is proposed to tackle constrained CNF placement in the cloud continuum, achieving feasible placements with orders of magnitude faster inference than MINLP solvers.", "motivation": "Placing interdependent CNFs across distributed cloud infrastructures (cloud continuum) for 5G/6G faces tight resource, bandwidth, and latency constraints. Traditional optimization and ML approaches struggle with scalability, constraint handling, and generalization, motivating a scalable, constraint-aware solution.", "method": "Formulate placement as a generative graph-to-assignment problem by encoding CNF-to-cloud mapping as a heterogeneous graph. Train a Graph Neural Network denoiser within a Denoising Diffusion Probabilistic Model (DDPM) to iteratively refine noisy CNF-to-cloud assignment matrices. Incorporate constraint-specific losses into the training objective so the model learns feasible solutions. Use rigorous integration of DDPM with structured combinatorial constraints and evaluate across diverse topologies.", "result": "The approach consistently yields feasible CNF placements with inference times orders of magnitude faster than traditional MINLP solvers, demonstrating the practicality and scalability of diffusion-based generative modeling for constrained network embedding problems.", "conclusion": "Diffusion-based generative modeling shows strong potential for constrained CNF placement in cloud-native networks, enabling scalable, feasible orchestration in the cloud continuum; the approach could generalize to other constrained network embedding problems."}}
{"id": "2511.01450", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01450", "abs": "https://arxiv.org/abs/2511.01450", "authors": ["Jie Du", "Xinyu Gong", "Qingshan Tan", "Wen Li", "Yangming Cheng", "Weitao Wang", "Chenlu Zhan", "Suhui Wu", "Hao Zhang", "Jun Zhang"], "title": "Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for Improving Video Generation", "comment": null, "summary": "Recent studies have identified Direct Preference Optimization (DPO) as an\nefficient and reward-free approach to improving video generation quality.\nHowever, existing methods largely follow image-domain paradigms and are mainly\ndeveloped on small-scale models (approximately 2B parameters), limiting their\nability to address the unique challenges of video tasks, such as costly data\nconstruction, unstable training, and heavy memory consumption. To overcome\nthese limitations, we introduce a GT-Pair that automatically builds\nhigh-quality preference pairs by using real videos as positives and\nmodel-generated videos as negatives, eliminating the need for any external\nannotation. We further present Reg-DPO, which incorporates the SFT loss as a\nregularization term into the DPO objective to enhance training stability and\ngeneration fidelity. Additionally, by combining the FSDP framework with\nmultiple memory optimization techniques, our approach achieves nearly three\ntimes higher training capacity than using FSDP alone. Extensive experiments on\nboth I2V and T2V tasks across multiple datasets demonstrate that our method\nconsistently outperforms existing approaches, delivering superior video\ngeneration quality.", "AI": {"tldr": "GT-Pair enables automatic preference data for DPO in video generation; Reg-DPO adds SFT regularization; FSDP-based memory optimizations yield ~3x training capacity; experiments on I2V/T2V show superior quality.", "motivation": "Overcome limitations of image-centric DPO when scaling to video tasks: costly data, unstable training, and memory constraints; aim for automated preference data and stable, scalable training.", "method": "Introduce GT-Pair to construct positive/negative pairs from real vs model-generated videos; integrate SFT loss as regularization in DPO objective; apply FSDP with memory optimization to boost training capacity; conduct extensive I2V/T2V experiments.", "result": "Consistent improvements over baselines in video quality; higher training capacity (~3x) with FSDP-based approach; strong results across multiple datasets.", "conclusion": "GT-Pair + Reg-DPO with memory-optimized FSDP provides stable, high-quality video generation and scalable training for I2V/T2V tasks."}}
{"id": "2511.01352", "categories": ["cs.LG", "astro-ph.HE", "astro-ph.IM", "hep-ex", "physics.data-an", "J.2; I.2.6"], "pdf": "https://arxiv.org/pdf/2511.01352", "abs": "https://arxiv.org/abs/2511.01352", "authors": ["Lucie Flek", "Oliver Janik", "Philipp Alexander Jung", "Akbar Karimi", "Timo Saala", "Alexander Schmidt", "Matthias Schott", "Philipp Soldin", "Matthias Thiesmeyer", "Christopher Wiebusch", "Ulrich Willemsen"], "title": "MiniFool - Physics-Constraint-Aware Minimizer-Based Adversarial Attacks in Deep Neural Networks", "comment": "Submitted to Computing and Software for Big Science", "summary": "In this paper, we present a new algorithm, MiniFool, that implements\nphysics-inspired adversarial attacks for testing neural network-based\nclassification tasks in particle and astroparticle physics. While we initially\ndeveloped the algorithm for the search for astrophysical tau neutrinos with the\nIceCube Neutrino Observatory, we apply it to further data from other science\ndomains, thus demonstrating its general applicability. Here, we apply the\nalgorithm to the well-known MNIST data set and furthermore, to Open Data data\nfrom the CMS experiment at the Large Hadron Collider. The algorithm is based on\nminimizing a cost function that combines a $\\chi^2$ based test-statistic with\nthe deviation from the desired target score. The test statistic quantifies the\nprobability of the perturbations applied to the data based on the experimental\nuncertainties. For our studied use cases, we find that the likelihood of a\nflipped classification differs for both the initially correctly and incorrectly\nclassified events. When testing changes of the classifications as a function of\nan attack parameter that scales the experimental uncertainties, the robustness\nof the network decision can be quantified. Furthermore, this allows testing the\nrobustness of the classification of unlabeled experimental data.", "AI": {"tldr": "MiniFool is a physics-inspired adversarial attack algorithm that tests neural network robustness across particle physics datasets (IceCube tau neutrinos, MNIST, CMS Open Data). It minimizes a cost combining a chi-square test statistic with deviation to a target score, and studies flips in classification under varying uncertainty scaling, enabling robustness assessment on labeled and unlabeled data.", "motivation": "To assess and quantify the vulnerability of NN classifications in physics contexts, and to provide a general, physics-grounded framework for adversarial testing that accounts for experimental uncertainties.", "method": "Develop MiniFool that uses a cost function: chi-square-based stat plus distance to target score; perturb data within experimental uncertainties; attack parameter scales uncertainties; apply to various domains including MNIST and CMS Open Data, starting from IceCube neutrino analysis.", "result": "Classification flip likelihood differs for initially correct vs incorrect events; robustness can be quantified as function of attack parameter; demonstrates general applicability and ability to test unlabeled data robustness.", "conclusion": "MiniFool offers a flexible, physics-informed approach to evaluate and compare classifier robustness across domains, enabling testing on unlabeled data and providing a metric to compare models under perturbations."}}
{"id": "2511.01458", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01458", "abs": "https://arxiv.org/abs/2511.01458", "authors": ["Dennis Pierantozzi", "Luca Carlini", "Mauro Orazio Drago", "Chiara Lena", "Cesare Hassan", "Elena De Momi", "Danail Stoyanov", "Sophia Bano", "Mobarak I. Hoque"], "title": "When to Trust the Answer: Question-Aligned Semantic Nearest Neighbor Entropy for Safer Surgical VQA", "comment": null, "summary": "Safety and reliability are essential for deploying Visual Question Answering\n(VQA) in surgery, where incorrect or ambiguous responses can harm the patient.\nMost surgical VQA research focuses on accuracy or linguistic quality while\noverlooking safety behaviors such as ambiguity awareness, referral to human\nexperts, or triggering a second opinion. Inspired by Automatic Failure\nDetection (AFD), we study uncertainty estimation as a key enabler of safer\ndecision making. We introduce Question Aligned Semantic Nearest Neighbor\nEntropy (QA-SNNE), a black box uncertainty estimator that incorporates question\nsemantics into prediction confidence. It measures semantic entropy by comparing\ngenerated answers with nearest neighbors in a medical text embedding space,\nconditioned on the question. We evaluate five models, including domain specific\nParameter-Efficient Fine-Tuned (PEFT) models and zero-shot Large\nVision-Language Models (LVLMs), on EndoVis18-VQA and PitVQA. PEFT models\ndegrade under mild paraphrasing, while LVLMs are more resilient. Across three\nLVLMs and two PEFT baselines, QA-SNNE improves AUROC in most in-template\nsettings and enhances hallucination detection. The Area Under the ROC Curve\n(AUROC) increases by 15-38% for zero-shot models, with gains maintained under\nout-of-template stress. QA-SNNE offers a practical and interpretable step\ntoward AFD in surgical VQA by linking semantic uncertainty to question context.\nCombining LVLM backbones with question aligned uncertainty estimation can\nimprove safety and clinician trust. The code and model are available at\nhttps://github.com/DennisPierantozzi/QASNNE", "AI": {"tldr": "QA-SNNE is a black-box uncertainty estimator for surgical VQA that aligns question semantics with nearest-neighbor semantic entropy to detect uncertainty and reduce hallucinations; it improves AUROC significantly for zero-shot LVLMs and PEFT models, supporting safer decisions.", "motivation": "Safety concerns in surgical VQA: incorrect or ambiguous answers can harm patients. Most work emphasizes accuracy or linguistic quality and ignores safety behaviors like ambiguity awareness, referrals, or second opinions. Uncertainty estimation inspired by Automatic Failure Detection (AFD) is proposed to enable safer decision making.", "method": "Introduce QA-SNNE: a question-aligned semantic nearest neighbor entropy estimator that computes semantic entropy by comparing generated answers with nearest neighbors in a medical text embedding space, conditioned on the question. It is a black-box approach and is evaluated on EndoVis18-VQA and PitVQA across five models (including domain-specific PEFTs and zero-shot LVLMs). Performance is assessed via AUROC and hallucination detection, including robustness to paraphrasing and out-of-template shifts.", "result": "QA-SNNE improves AUROC in most in-template settings and enhances hallucination detection. Zero-shot models gain 15\u201338% AUROC, with gains maintained under out-of-template stress. The improvements are observed across three LVLMs and two PEFT baselines.", "conclusion": "QA-SNNE provides a practical and interpretable step toward AFD in surgical VQA by linking semantic uncertainty to question context. Using LVLM backbones with question-aligned uncertainty estimation can improve safety and clinician trust. Code and model are available at the authors\u2019 GitHub repository."}}
{"id": "2511.01356", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01356", "abs": "https://arxiv.org/abs/2511.01356", "authors": ["Rana Alaa", "Dar\u00edo Gonz\u00e1lez-Ferreiro", "Carlos Beis-Penedo", "Manuel Fern\u00e1ndez-Veiga", "Rebeca P. D\u00edaz-Redondo", "Ana Fern\u00e1ndez-Vilas"], "title": "Verifiable Split Learning via zk-SNARKs", "comment": "Submitted to CAI'26 (IEEE Conference on Artificial Intelligence 2026)", "summary": "Split learning is an approach to collaborative learning in which a deep\nneural network is divided into two parts: client-side and server-side at a cut\nlayer. The client side executes its model using its raw input data and sends\nthe intermediate activation to the server side. This configuration architecture\nis very useful for enabling collaborative training when data or resources are\nseparated between devices. However, split learning lacks the ability to verify\nthe correctness and honesty of the computations that are performed and\nexchanged between the parties. To this purpose, this paper proposes a\nverifiable split learning framework that integrates a zk-SNARK proof to ensure\ncorrectness and verifiability. The zk-SNARK proof and verification are\ngenerated for both sides in forward propagation and backward propagation on the\nserver side, guaranteeing verifiability on both sides. The verifiable split\nlearning architecture is compared to a blockchain-enabled system for the same\ndeep learning network, one that records updates but without generating the\nzero-knowledge proof. From the comparison, it can be deduced that applying the\nzk-SNARK test achieves verifiability and correctness, while blockchains are\nlightweight but unverifiable.", "AI": {"tldr": "Verifiable split learning using zk-SNARKs ensures correctness and verifiability of client-server computations in split DL; compared to a blockchain-only recording approach which is lightweight but unverifiable.", "motivation": "Split learning currently cannot verify the correctness of the exchanged computations, risking dishonesty or errors across client and server. There is a need for a trusted mechanism to verify both forward and backward computations in the split architecture.", "method": "Integrate a zk-SNARK proof into the split learning framework to certify correctness. Generate zk-SNARK proofs and verifications for both client and server sides during forward propagation and backward propagation on the server side, ensuring verifiability on both sides. Compare this verifiable setup to a blockchain-enabled system that records updates without zero-knowledge proofs.", "result": "The zk-SNARK\u2013based approach achieves verifiability and correctness in the split learning process. The blockchain-based system, while lightweight, remains unverifiable without zero-knowledge proofs.", "conclusion": "Incorporating zk-SNARK proofs into split learning provides verifiability and correctness, addressing the limitations of veracity in traditional split learning; blockchain-only recording lacks verifiability, though it may be lighter in overhead."}}
{"id": "2511.01462", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01462", "abs": "https://arxiv.org/abs/2511.01462", "authors": ["Peng Xia", "Junbiao Pang", "Tianyang Cai"], "title": "Efficiently Training A Flat Neural Network Before It has been Quantizated", "comment": "ongoing work, more results would be added", "summary": "Post-training quantization (PTQ) for vision transformers (ViTs) has garnered\nsignificant attention due to its efficiency in compressing models. However,\nexisting methods typically overlook the relationship between a well-trained NN\nand the quantized model, leading to considerable quantization error for PTQ.\nHowever, it is unclear how to efficiently train a model-agnostic neural network\nwhich is tailored for a predefined precision low-bit model. In this paper, we\nfirstly discover that a flat full precision neural network is crucial for\nlow-bit quantization. To achieve this, we propose a framework that proactively\npre-conditions the model by measuring and disentangling the error sources.\nSpecifically, both the Activation Quantization Error (AQE) and the Weight\nQuantization Error (WQE) are statistically modeled as independent Gaussian\nnoises. We study several noise injection optimization methods to obtain a flat\nminimum. Experimental results attest to the effectiveness of our approach.\nThese results open novel pathways for obtaining low-bit PTQ models.", "AI": {"tldr": "Post-training quantization for vision transformers can be improved by training toward a flat minimum using a model-agnostic Gaussian-noise framework that disentangles activation and weight quantization errors, enabling more accurate low-bit PTQ.", "motivation": "Current PTQ methods often ignore the relationship between a well-trained full-precision NN and its quantized version, leading to large quantization errors. A model-agnostic framework tailored to a predefined low-bit precision could systematically reduce this gap by preparing the network for quantization.", "method": "Propose a preconditioning framework that measures and disentangles error sources. Model Activation Quantization Error (AQE) and Weight Quantization Error (WQE) as independent Gaussian noises. Investigate noise injection strategies to drive the model toward a flat minimum suitable for low-bit quantization.", "result": "Experimental results demonstrate the approach's effectiveness and suggest new directions for achieving low-bit PTQ models.", "conclusion": "A flat full-precision network is crucial for successful low-bit quantization. Modeling AQE and WQE as independent Gaussian noises with noise-injection optimization provides a promising, model-agnostic path to improved PTQ for vision transformers."}}
{"id": "2511.01374", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01374", "abs": "https://arxiv.org/abs/2511.01374", "authors": ["Ziqi Wang", "Jiashun Liu", "Ling Pan"], "title": "Learning Intractable Multimodal Policies with Reparameterization and Diversity Regularization", "comment": "NeurIPS 2025", "summary": "Traditional continuous deep reinforcement learning (RL) algorithms employ\ndeterministic or unimodal Gaussian actors, which cannot express complex\nmultimodal decision distributions. This limitation can hinder their performance\nin diversity-critical scenarios. There have been some attempts to design online\nmultimodal RL algorithms based on diffusion or amortized actors. However, these\nactors are intractable, making existing methods struggle with balancing\nperformance, decision diversity, and efficiency simultaneously. To overcome\nthis challenge, we first reformulate existing intractable multimodal actors\nwithin a unified framework, and prove that they can be directly optimized by\npolicy gradient via reparameterization. Then, we propose a distance-based\ndiversity regularization that does not explicitly require decision\nprobabilities. We identify two diversity-critical domains, namely multi-goal\nachieving and generative RL, to demonstrate the advantages of multimodal\npolicies and our method, particularly in terms of few-shot robustness. In\nconventional MuJoCo benchmarks, our algorithm also shows competitive\nperformance. Moreover, our experiments highlight that the amortized actor is a\npromising policy model class with strong multimodal expressivity and high\nperformance. Our code is available at https://github.com/PneuC/DrAC", "AI": {"tldr": "A study on tractable multimodal RL via an amortized/distance-regularized actor, enabling policy-gradient optimization of multimodal policies and improving few-shot robustness in multi-goal and generative RL; competitive on MuJoCo; code released.", "motivation": "Traditional RL with deterministic or unimodal Gaussian actors cannot express complex multimodal decision distributions, hindering diversity and performance; existing multimodal approaches (diffusion/amortized actors) are intractable and struggle to balance performance, diversity, and efficiency.", "method": "Reformulate intractable multimodal actors within a unified framework and show they can be optimized by policy gradient via reparameterization. Introduce a distance-based diversity regularization that does not require explicit decision probabilities. Identify two diversity-critical domains (multi-goal achieving and generative RL) and demonstrate advantages of multimodal policies and the proposed method, especially in few-shot robustness. Use an amortized actor as the policy class and validate on MuJoCo benchmarks.", "result": "The approach yields improved diversity and few-shot robustness in the targeted domains, with competitive performance on conventional MuJoCo benchmarks. Experiments indicate the amortized actor offers strong multimodal expressivity and high performance.", "conclusion": "Multimodal policies, together with the distance-based regularization and the amortized actor, can achieve robust and diverse behavior without sacrificing efficiency; the amortized actor emerges as a promising policy class for multimodal RL. Code available at the provided GitHub link."}}
{"id": "2511.01463", "categories": ["cs.CV", "cs.AI", "cs.GR", "68T45", "I.2.10; I.3.7"], "pdf": "https://arxiv.org/pdf/2511.01463", "abs": "https://arxiv.org/abs/2511.01463", "authors": ["Lei Hu", "Yongjing Ye", "Shihong Xia"], "title": "HMVLM: Human Motion-Vision-Lanuage Model via MoE LoRA", "comment": "10 pages, 5figures. The Thirty-Ninth Annual Conference on Neural\n  Information Processing Systems", "summary": "The expansion of instruction-tuning data has enabled foundation language\nmodels to exhibit improved instruction adherence and superior performance\nacross diverse downstream tasks. Semantically-rich 3D human motion is being\nprogressively integrated with these foundation models to enhance multimodal\nunderstanding and cross-modal generation capabilities. However, the modality\ngap between human motion and text raises unresolved concerns about catastrophic\nforgetting during this integration. In addition, developing\nautoregressive-compatible pose representations that preserve generalizability\nacross heterogeneous downstream tasks remains a critical technical barrier. To\naddress these issues, we propose the Human Motion-Vision-Language Model\n(HMVLM), a unified framework based on the Mixture of Expert Low-Rank\nAdaption(MoE LoRA) strategy. The framework leverages the gating network to\ndynamically allocate LoRA expert weights based on the input prompt, enabling\nsynchronized fine-tuning of multiple tasks. To mitigate catastrophic forgetting\nduring instruction-tuning, we introduce a novel zero expert that preserves the\npre-trained parameters for general linguistic tasks. For pose representation,\nwe implement body-part-specific tokenization by partitioning the human body\ninto different joint groups, enhancing the spatial resolution of the\nrepresentation. Experiments show that our method effectively alleviates\nknowledge forgetting during instruction-tuning and achieves remarkable\nperformance across diverse human motion downstream tasks.", "AI": {"tldr": "Proposes Human Motion-Vision-Language Model (HMVLM) using Mixture-of-Expert LoRA (MoE LoRA) to enable prompt-conditioned, multi-task fine-tuning across motion, vision, and language modalities. Introduces a zero expert to preserve pre-trained linguistic abilities, and body-part-specific tokenization for better pose representation. Empirically, the framework mitigates catastrophic forgetting during instruction-tuning and delivers strong performance on diverse human motion tasks.", "motivation": "To close the modality gap between semantically rich 3D human motion and text, address catastrophic forgetting during instruction-tuning in multimodal models, and develop autoregressive-compatible pose representations that generalize across heterogeneous downstream tasks.", "method": "A unified framework (HMVLM) built on Mixture-of-Expert LoRA with a gating network that dynamically allocates LoRA expert weights according to the input prompt. Includes a zero expert to preserve pre-trained parameters for general linguistic tasks, and body-part-specific tokenization by partitioning the body into joint groups to enhance pose representation. Enables synchronized fine-tuning across multiple tasks.", "result": "Experiments indicate reduced forgetting during instruction-tuning and strong performance across diverse human motion downstream tasks.", "conclusion": "The proposed MoE LoRA-based HMVLM effectively mitigates knowledge forgetting while delivering high performance in multimodal human motion understanding/generation, supported by a pose-representation scheme that improves spatial granularity and task adaptability."}}
{"id": "2511.01377", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01377", "abs": "https://arxiv.org/abs/2511.01377", "authors": ["Amir Hossein Khorasani", "Ali Jahanian", "Maryam Rastgarpour"], "title": "Protecting the Neural Networks against FGSM Attack Using Machine Unlearning", "comment": "7 pages, 9 figures, 1 table", "summary": "Machine learning is a powerful tool for building predictive models. However,\nit is vulnerable to adversarial attacks. Fast Gradient Sign Method (FGSM)\nattacks are a common type of adversarial attack that adds small perturbations\nto input data to trick a model into misclassifying it. In response to these\nattacks, researchers have developed methods for \"unlearning\" these attacks,\nwhich involves retraining a model on the original data without the added\nperturbations. Machine unlearning is a technique that tries to \"forget\"\nspecific data points from the training dataset, to improve the robustness of a\nmachine learning model against adversarial attacks like FGSM. In this paper, we\nfocus on applying unlearning techniques to the LeNet neural network, a popular\narchitecture for image classification. We evaluate the efficacy of unlearning\nFGSM attacks on the LeNet network and find that it can significantly improve\nits robustness against these types of attacks.", "AI": {"tldr": "Unlearning FGSM perturbations on LeNet improves robustness to FGSM adversarial attacks.", "motivation": "FGSM attacks exploit model vulnerabilities; unlearning aims to forget perturbed data and reduce attack efficacy, improving robustness.", "method": "Apply machine unlearning techniques to LeNet, retraining to forget FGSM-perturbed data, and evaluate robustness against FGSM.", "result": "Significant robustness improvement against FGSM demonstrated on LeNet with unlearning.", "conclusion": "Unlearning is a promising defense against FGSM for LeNet and motivates further exploration on other models and attack types."}}
{"id": "2511.01466", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01466", "abs": "https://arxiv.org/abs/2511.01466", "authors": ["Changyuan Zhao", "Jiacheng Wang", "Ruichen Zhang", "Dusit Niyato", "Hongyang Du", "Zehui Xiong", "Dong In Kim", "Ping Zhang"], "title": "SecDiff: Diffusion-Aided Secure Deep Joint Source-Channel Coding Against Adversarial Attacks", "comment": "13 pages, 6 figures", "summary": "Deep joint source-channel coding (JSCC) has emerged as a promising paradigm\nfor semantic communication, delivering significant performance gains over\nconventional separate coding schemes. However, existing JSCC frameworks remain\nvulnerable to physical-layer adversarial threats, such as pilot spoofing and\nsubcarrier jamming, compromising semantic fidelity. In this paper, we propose\nSecDiff, a plug-and-play, diffusion-aided decoding framework that significantly\nenhances the security and robustness of deep JSCC under adversarial wireless\nenvironments. Different from prior diffusion-guided JSCC methods that suffer\nfrom high inference latency, SecDiff employs pseudoinverse-guided sampling and\nadaptive guidance weighting, enabling flexible step-size control and efficient\nsemantic reconstruction. To counter jamming attacks, we introduce a power-based\nsubcarrier masking strategy and recast recovery as a masked inpainting problem,\nsolved via diffusion guidance. For pilot spoofing, we formulate channel\nestimation as a blind inverse problem and develop an expectation-minimization\n(EM)-driven reconstruction algorithm, guided jointly by reconstruction loss and\na channel operator. Notably, our method alternates between pilot recovery and\nchannel estimation, enabling joint refinement of both variables throughout the\ndiffusion process. Extensive experiments over orthogonal frequency-division\nmultiplexing (OFDM) channels under adversarial conditions show that SecDiff\noutperforms existing secure and generative JSCC baselines by achieving a\nfavorable trade-off between reconstruction quality and computational cost. This\nbalance makes SecDiff a promising step toward practical, low-latency, and\nattack-resilient semantic communications.", "AI": {"tldr": "SecDiff is a diffusion-guided deep JSCC framework that boosts defense against pilot spoofing and subcarrier jamming in OFDM by combining pseudoinverse-guided sampling with adaptive guidance, subcarrier masking (inpainting) for jamming, and EM-driven joint pilot/channel estimation; it achieves better reconstruction quality with lower latency than prior diffusion-based JSCC methods, offering attack-resilient, practical semantic communications.", "motivation": "Deep JSCC is vulnerable to physical-layer adversaries (pilot spoofing, subcarrier jamming) which can degrade semantic fidelity; there is a need for robust, low-latency defenses compatible with practical wireless systems.", "method": "Introduce SecDiff: diffusion-aided decoding with pseudoinverse-guided sampling and adaptive guidance; power-based subcarrier masking to treat jamming as masked inpainting; EM-driven reconstruction for blind channel estimation (pilot spoofing), with alternating refinement of pilots and channel within the diffusion process.", "result": "Extensive OFDM experiments under adversarial conditions show SecDiff outperforms secure and generative JSCC baselines in reconstruction quality for a given computational cost.", "conclusion": "SecDiff is a plug-and-play, low-latency, attack-resilient framework that advances practical semantic communications under adversarial wireless environments."}}
{"id": "2511.01385", "categories": ["cs.LG", "I.2.6; G.1.2; D.1.3"], "pdf": "https://arxiv.org/pdf/2511.01385", "abs": "https://arxiv.org/abs/2511.01385", "authors": ["Xinyu Ding", "Bangtian Liu", "Siyu Liao", "Zhongfeng Wang"], "title": "Memory-Efficient Training with In-Place FFT Implementation", "comment": "Accepted at NeurIPS 2025. Presents a real-domain in-place FFT (rdFFT)\n  operator for memory-efficient fine-tuning of large language models", "summary": "Fast Fourier Transforms (FFT) are widely used to reduce memory and\ncomputational costs in deep learning. However, existing implementations,\nincluding standard FFT and real FFT (rFFT), cannot achieve true in-place\ncomputation. In particular, rFFT maps an input of size n to a complex output of\nsize n/2+1, causing dimensional mismatch and requiring additional memory\nallocation. We propose the first real-domain, fully in-place FFT framework\n(rdFFT) that preserves input-output memory space consistency. By leveraging\nbutterfly operation symmetry and conjugate properties in the frequency domain,\nwe design an implicit complex encoding scheme that eliminates intermediate\ncache usage entirely. Experiments on multiple natural language understanding\ntasks demonstrate the method effectiveness in reducing training memory cost,\noffering a promising direction for frequency-domain lightweight adaptation.", "AI": {"tldr": "A real-domain, fully in-place FFT (rdFFT) that preserves input-output memory space and eliminates intermediate cache usage by exploiting butterfly symmetry and conjugate properties, addressing the dimensional mismatch in rFFT and reducing training memory in NLP tasks.", "motivation": "Existing FFT/rFFT implementations do not support true in-place computation, incurring extra memory and dimensional mismatches. A memory-consistent real-domain FFT could enable memory-efficient frequency-domain adaptation in deep learning.", "method": "Develop an implicit complex encoding scheme that leverages butterfly symmetry and conjugate properties to perform FFT entirely in place in the real domain, avoiding intermediate cache allocations and preserving input-output memory footprint.", "result": "Empirical evaluations on several NLP tasks show reduced training memory usage with rdFFT while maintaining accuracy/throughput, indicating practical benefits for memory-efficient frequency-domain models.", "conclusion": "rdFFT provides the first real-domain, fully in-place real FFT framework, enabling memory-space consistency and cache-free computation, representing a promising direction for frequency-domain lightweight adaptation in NLP."}}
{"id": "2511.01498", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01498", "abs": "https://arxiv.org/abs/2511.01498", "authors": ["Zhiyang Jia", "Hongyan Cui", "Ge Gao", "Bo Li", "Minjie Zhang", "Zishuo Gao", "Huiwen Huang", "Caisheng Zhuo"], "title": "EPAN: Robust Pedestrian Re-Identification via Enhanced Alignment Network for IoT Surveillance", "comment": "12 page, 5 figures", "summary": "Person re-identification (ReID) plays a pivotal role in computer vision,\nparticularly in surveillance and security applications within IoT-enabled smart\nenvironments. This study introduces the Enhanced Pedestrian Alignment Network\n(EPAN), tailored for robust ReID across diverse IoT surveillance conditions.\nEPAN employs a dual-branch architecture to mitigate the impact of perspective\nand environmental changes, extracting alignment information under varying\nscales and viewpoints. Here, we demonstrate EPAN's strong feature extraction\ncapabilities, achieving outstanding performance on the Inspection-Personnel\ndataset with a Rank-1 accuracy of 90.09% and a mean Average Precision (mAP) of\n78.82%. This highlights EPAN's potential for real-world IoT applications,\nenabling effective and reliable person ReID across diverse cameras in\nsurveillance and security systems. The code and data are available at:\nhttps://github.com/ggboy2580/EPAN", "AI": {"tldr": "Proposes Enhanced Pedestrian Alignment Network (EPAN) for robust cross-camera person re-identification in IoT surveillance; a dual-branch design extracts alignment cues across multiple scales and viewpoints to counter perspective and environmental changes; achieves 90.09% Rank-1 and 78.82% mAP on the Inspection-Personnel dataset; code available on GitHub.", "motivation": "IoT-enabled surveillance systems suffer from strong cross-camera variability due to\u4e0d\u540c perspectives, scales, and environmental conditions. There is a need for robust feature extraction and alignment that remains effective across diverse cameras.", "method": "EPAN employs a dual-branch architecture to capture and fuse alignment information across varying scales and viewpoints, enhancing pedestrian feature robustness for re-identification.", "result": "On the Inspection-Personnel dataset, EPAN achieves Rank-1 of 90.09% and mAP of 78.82%, indicating strong feature extraction and alignment capabilities suitable for real-world IoT surveillance deployments.", "conclusion": "EPAN demonstrates strong potential for reliable cross-camera person ReID in diverse surveillance settings; the provided code and data enable replication and practical adoption in IoT security systems."}}
{"id": "2511.01408", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01408", "abs": "https://arxiv.org/abs/2511.01408", "authors": ["Markus B. Pettersson", "Adel Daoud"], "title": "Leveraging Compact Satellite Embeddings and Graph Neural Networks for Large-Scale Poverty Mapping", "comment": null, "summary": "Accurate, fine-grained poverty maps remain scarce across much of the Global\nSouth. While Demographic and Health Surveys (DHS) provide high-quality\nsocioeconomic data, their spatial coverage is limited and reported coordinates\nare randomly displaced for privacy, further reducing their quality. We propose\na graph-based approach leveraging low-dimensional AlphaEarth satellite\nembeddings to predict cluster-level wealth indices across Sub-Saharan Africa.\nBy modeling spatial relations between surveyed and unlabeled locations, and by\nintroducing a probabilistic \"fuzzy label\" loss to account for coordinate\ndisplacement, we improve the generalization of wealth predictions beyond\nexisting surveys. Our experiments on 37 DHS datasets (2017-2023) show that\nincorporating graph structure slightly improves accuracy compared to\n\"image-only\" baselines, demonstrating the potential of compact EO embeddings\nfor large-scale socioeconomic mapping.", "AI": {"tldr": "Graph-based model with AlphaEarth embeddings and fuzzy-label loss improves cluster-level wealth prediction beyond image-only baselines, leveraging spatial relations and robustness to coordinate displacement.", "motivation": "Fine-grained poverty maps are scarce in the Global South; DHS data are spatially noisy due to coordinate displacement and have limited coverage. Exploit spatial structure and robust supervision to generalize wealth estimates to unlabeled locations.", "method": "Construct a graph over surveyed and unlabeled locations using AlphaEarth low-dimensional satellite embeddings as features; train with a probabilistic 'fuzzy label' loss to account for displaced coordinates; compare against image-only baselines on 37 DHS datasets (2017\u20132023).", "result": "In experiments, incorporating graph structure yields small accuracy improvements over image-only baselines; results across 37 DHS datasets demonstrate the potential of compact EO embeddings for large-scale socioeconomic mapping.", "conclusion": "A graph-based framework with fuzzy labeling can improve generalization of wealth prediction in data-sparse, noisy settings; AlphaEarth embeddings show promise for scalable poverty mapping, though gains are modest and may depend on data quality and graph design."}}
{"id": "2511.01433", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01433", "abs": "https://arxiv.org/abs/2511.01433", "authors": ["Seunghun Yu", "Youngjoon Lee", "Jinu Gong", "Joonhyuk Kang"], "title": "CG-FKAN: Compressed-Grid Federated Kolmogorov-Arnold Networks for Communication Constrained Environment", "comment": "5 pages", "summary": "Federated learning (FL), widely used in privacy-critical applications,\nsuffers from limited interpretability, whereas Kolmogorov-Arnold Networks (KAN)\naddress this limitation via learnable spline functions. However, existing FL\nstudies applying KAN overlook the communication overhead introduced by grid\nextension, which is essential for modeling complex functions. In this letter,\nwe propose CG-FKAN, which compresses extended grids by sparsifying and\ntransmitting only essential coefficients under a communication budget.\nExperiments show that CG-FKAN achieves up to 13.6% lower RMSE than fixed-grid\nKAN in communication-constrained settings. In addition, we derive a theoretical\nupper bound on its approximation error.", "AI": {"tldr": "A communication-budget aware CG-FKAN sparsifies extended grids in FL with Kolmogorov-Arnold Networks (KAN) to reduce transmission, achieving up to 13.6% RMSE improvement over fixed-grid KAN and providing a theoretical approximation-error bound.", "motivation": "Federated learning often lacks interpretability. KAN offers interpretable learnable spline representations, but extending grids for complex functions incurs significant communication overhead. There is a need to compress grid information efficiently under a communication budget without losing interpretability.", "method": "CG-FKAN compresses extended grids by sparsifying and transmitting only the essential coefficients within a specified communication budget.", "result": "Empirical results show up to 13.6% lower RMSE than fixed-grid KAN in communication-constrained settings. The work also derives a theoretical upper bound on the approximation error.", "conclusion": "CG-FKAN improves performance under communication constraints while preserving interpretability through KAN, and provides a theoretical guarantee on its approximation error."}}
{"id": "2511.01438", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01438", "abs": "https://arxiv.org/abs/2511.01438", "authors": ["Jacob Poschl"], "title": "The Curvature Rate \u03bb: A Scalar Measure of Input-Space Sharpness in Neural Networks", "comment": "14 pages", "summary": "Curvature influences generalization, robustness, and how reliably neural\nnetworks respond to small input perturbations. Existing sharpness metrics are\ntypically defined in parameter space (e.g., Hessian eigenvalues) and can be\nexpensive, sensitive to reparameterization, and difficult to interpret in\nfunctional terms. We introduce a scalar curvature measure defined directly in\ninput space: the curvature rate {\\lambda}, given by the exponential growth rate\nof higher-order input derivatives. Empirically, {\\lambda} is estimated as the\nslope of log ||D^n f|| versus n for small n. This growth-rate perspective\nunifies classical analytic quantities: for analytic functions, {\\lambda}\ncorresponds to the inverse radius of convergence, and for bandlimited signals,\nit reflects the spectral cutoff. The same principle extends to neural networks,\nwhere {\\lambda} tracks the emergence of high-frequency structure in the\ndecision boundary. Experiments on analytic functions and neural networks (Two\nMoons and MNIST) show that {\\lambda} evolves predictably during training and\ncan be directly shaped using a simple derivative-based regularizer, Curvature\nRate Regularization (CRR). Compared to Sharpness-Aware Minimization (SAM), CRR\nachieves similar accuracy while yielding flatter input-space geometry and\nimproved confidence calibration. By grounding curvature in differentiation\ndynamics, {\\lambda} provides a compact, interpretable, and\nparameterization-invariant descriptor of functional smoothness in learned\nmodels.", "AI": {"tldr": "A new input-space curvature measure lambda, defined as the exponential growth rate of higher-order derivatives, with a derivative-based regularizer (CRR); shows comparable performance to SAM, with flatter input-space geometry and improved calibration; offers an interpretable, parameterization-invariant view of functional smoothness.", "motivation": "Current sharpness metrics live in parameter space (e.g., Hessian eigenvalues) and are expensive, reparameterization-sensitive, and hard to interpret in functional terms. The work seeks a parameterization-invariant, input-space curvature descriptor grounded in differentiation dynamics that relates to analytic properties and high-frequency boundary structure.", "method": "Define lambda as the exponential growth rate of higher-order input derivatives: the slope of log ||D^n f|| vs n for small n. This unifies analytic notions (inverse radius of convergence for analytic functions; spectral cutoff for bandlimited signals). Extend to neural networks to track high-frequency structure in the decision boundary. Introduce Curvature Rate Regularization (CRR), a simple derivative-based regularizer to shape lambda during training.", "result": "Empirical studies on analytic functions and on neural networks (Two Moons, MNIST) show that lambda evolves predictably during training and can be steered by CRR. CRR achieves similar accuracy to Sharpness-Aware Minimization (SAM) while yielding flatter input-space geometry and improved confidence calibration.", "conclusion": "Lambda provides a compact, interpretable, and parameterization-invariant descriptor of functional smoothness in learned models by grounding curvature in differentiation dynamics."}}
{"id": "2511.01510", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01510", "abs": "https://arxiv.org/abs/2511.01510", "authors": ["Derong Kong", "Zhixiong Yang", "Shengxi Li", "Shuaifeng Zhi", "Li Liu", "Zhen Liu", "Jingyuan Xia"], "title": "Luminance-Aware Statistical Quantization: Unsupervised Hierarchical Learning for Illumination Enhancement", "comment": "Accepted at NeurIPS 2025", "summary": "Low-light image enhancement (LLIE) faces persistent challenges in balancing\nreconstruction fidelity with cross-scenario generalization. While existing\nmethods predominantly focus on deterministic pixel-level mappings between\npaired low/normal-light images, they often neglect the continuous physical\nprocess of luminance transitions in real-world environments, leading to\nperformance drop when normal-light references are unavailable. Inspired by\nempirical analysis of natural luminance dynamics revealing power-law\ndistributed intensity transitions, this paper introduces Luminance-Aware\nStatistical Quantification (LASQ), a novel framework that reformulates LLIE as\na statistical sampling process over hierarchical luminance distributions. Our\nLASQ re-conceptualizes luminance transition as a power-law distribution in\nintensity coordinate space that can be approximated by stratified power\nfunctions, therefore, replacing deterministic mappings with probabilistic\nsampling over continuous luminance layers. A diffusion forward process is\ndesigned to autonomously discover optimal transition paths between luminance\nlayers, achieving unsupervised distribution emulation without normal-light\nreferences. In this way, it considerably improves the performance in practical\nsituations, enabling more adaptable and versatile light restoration. This\nframework is also readily applicable to cases with normal-light references,\nwhere it achieves superior performance on domain-specific datasets alongside\nbetter generalization-ability across non-reference datasets.", "AI": {"tldr": "Recasts LLIE as probabilistic luminance sampling via a diffusion-based process, enabling unsupervised distribution emulation and better cross-domain generalization without strictly paired references.", "motivation": "Deterministic pixel mappings and dependency on paired data limit generalization; luminance dynamics in real scenes follow power-law transitions, which are not captured by existing methods; need a framework that models continuous luminance transitions and handles missing normal-light references.", "method": "LASQ models luminance as hierarchical distributions with power-law in intensity space, uses stratified power functions; replaces deterministic mappings with probabilistic sampling across luminance layers; introduces a diffusion forward process to discover optimal transition paths between layers, enabling unsupervised emulation; applicable with and without normal-light references.", "result": "Expected improved reconstruction quality and generalization on domain-specific datasets; superior performance when normal-light references are available and better zero-shot generalization to non-reference datasets; more adaptable light restoration in practical settings.", "conclusion": "LASQ offers a principled probabilistic framework for LLIE that aligns with natural luminance dynamics, enhancing robustness across domains and reference availability by leveraging diffusion-based distribution learning rather than fixed mappings."}}
{"id": "2511.01443", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01443", "abs": "https://arxiv.org/abs/2511.01443", "authors": ["Chaoqun Fei", "Tinglve Zhou", "Tianyong Hao", "Yangyang Li"], "title": "Efficient Curvature-aware Graph Network", "comment": null, "summary": "Graph curvature provides geometric priors for Graph Neural Networks (GNNs),\nenhancing their ability to model complex graph structures, particularly in\nterms of structural awareness, robustness, and theoretical interpretability.\nAmong existing methods, Ollivier-Ricci curvature has been extensively studied\ndue to its strong geometric interpretability, effectively characterizing the\nlocal geometric distribution between nodes. However, its prohibitively high\ncomputational complexity limits its applicability to large-scale graph\ndatasets. To address this challenge, we propose a novel graph curvature\nmeasure--Effective Resistance Curvature--which quantifies the ease of message\npassing along graph edges using the effective resistance between node pairs,\ninstead of the optimal transport distance. This method significantly\noutperforms Ollivier-Ricci curvature in computational efficiency while\npreserving comparable geometric expressiveness. Theoretically, we prove the low\ncomputational complexity of effective resistance curvature and establish its\nsubstitutability for Ollivier-Ricci curvature. Furthermore, extensive\nexperiments on diverse GNN tasks demonstrate that our method achieves\ncompetitive performance with Ollivier-Ricci curvature while drastically\nreducing computational overhead.", "AI": {"tldr": "Introduces Effective Resistance Curvature as a scalable alternative to Ollivier-Ricci curvature for GNNs, achieving similar expressiveness with much lower computational cost; theory and experiments validate substitutability and efficiency.", "motivation": "Ollivier-Ricci curvature provides geometric interpretability but is computationally expensive; scalable curvature measures are needed for large graphs.", "method": "Define curvature via effective resistance between node pairs to measure ease of message passing, avoiding optimal transport. Proves low computational complexity and substitutability with Ollivier-Ricci; validates with experiments.", "result": "Theoretically establish low complexity and substitutability; empirically, competitive performance with Ollivier-Ricci curvature across diverse GNN tasks, with drastically reduced overhead.", "conclusion": "Effective Resistance Curvature offers a scalable, interpretable geometric prior for GNNs and can substitute Ollivier-Ricci curvature without sacrificing performance, enabling efficient large-scale graph learning."}}
{"id": "2511.01513", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.01513", "abs": "https://arxiv.org/abs/2511.01513", "authors": ["Andrei-Timotei Ardelean", "Tim Weyrich"], "title": "Example-Based Feature Painting on Textures", "comment": "\"\\c{opyright} 2025 Andrei-Timotei Ardelean, Tim Weyrich. This is the\n  author's version of the work. It is posted here for your personal use. Not\n  for redistribution. The definitive Version of Record was published in ACM\n  Trans. Graph., Vol. 44, No. 6, https://doi.org/10.1145/3763301", "summary": "In this work, we propose a system that covers the complete workflow for\nachieving controlled authoring and editing of textures that present distinctive\nlocal characteristics. These include various effects that change the surface\nappearance of materials, such as stains, tears, holes, abrasions,\ndiscoloration, and more. Such alterations are ubiquitous in nature, and\nincluding them in the synthesis process is crucial for generating realistic\ntextures. We introduce a novel approach for creating textures with such\nblemishes, adopting a learning-based approach that leverages unlabeled\nexamples. Our approach does not require manual annotations by the user;\ninstead, it detects the appearance-altering features through unsupervised\nanomaly detection. The various textural features are then automatically\nclustered into semantically coherent groups, which are used to guide the\nconditional generation of images. Our pipeline as a whole goes from a small\nimage collection to a versatile generative model that enables the user to\ninteractively create and paint features on textures of arbitrary size. Notably,\nthe algorithms we introduce for diffusion-based editing and infinite stationary\ntexture generation are generic and should prove useful in other contexts as\nwell. Project page: https://reality.tf.fau.de/pub/ardelean2025examplebased.html", "AI": {"tldr": "A learning-based, annotation-free system for controlled texture blemish editing and synthesis using unsupervised anomaly detection to discover and cluster appearance-altering features, enabling diffusion-based editing and infinite texture generation from a small image collection.", "motivation": "Real-world textures often include blemishes (stains, tears, holes, abrasions, discoloration) that are essential for realism. Manual annotation is costly; the work aims to automatically discover and organize blemish-like features to drive conditional generation.", "method": "Use unsupervised anomaly detection to identify appearance-altering features in texture images, cluster these features into semantically coherent groups, and use these clusters to guide diffusion-based editing and conditional generation. The pipeline converts a small image collection into a versatile generative model that supports interactive painting on textures of arbitrary size, with novel diffusion-based editing and infinite stationary texture generation algorithms.", "result": "A practical pipeline that automatically detects and clusters blemish-like features, enabling interactive texture editing and infinite texture generation. The diffusion-based editing and infinite texture algorithms are presented as generic, applicable beyond this task, and the project page provides access to the implementation.", "conclusion": "The approach delivers an annotation-free, flexible tool for realistic texture synthesis and editing of blemishes, with diffusion-based editing and infinite texture generation algorithms that are broadly applicable to other domains."}}
{"id": "2511.01468", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01468", "abs": "https://arxiv.org/abs/2511.01468", "authors": ["Hao Wang", "Zixuan Weng", "Jindong Han", "Wei Fan", "Hao Liu"], "title": "DAMBench: A Multi-Modal Benchmark for Deep Learning-based Atmospheric Data Assimilation", "comment": null, "summary": "Data Assimilation is a cornerstone of atmospheric system modeling, tasked\nwith reconstructing system states by integrating sparse, noisy observations\nwith prior estimation. While traditional approaches like variational and\nensemble Kalman filtering have proven effective, recent advances in deep\nlearning offer more scalable, efficient, and flexible alternatives better\nsuited for complex, real-world data assimilation involving large-scale and\nmulti-modal observations. However, existing deep learning-based DA research\nsuffers from two critical limitations: (1) reliance on oversimplified scenarios\nwith synthetically perturbed observations, and (2) the absence of standardized\nbenchmarks for fair model comparison. To address these gaps, in this work, we\nintroduce DAMBench, the first large-scale multi-modal benchmark designed to\nevaluate data-driven DA models under realistic atmospheric conditions. DAMBench\nintegrates high-quality background states from state-of-the-art forecasting\nsystems and real-world multi-modal observations (i.e., real-world weather\nstations and satellite imagery). All data are resampled to a common grid and\ntemporally aligned to support systematic training, validation, and testing. We\nprovide unified evaluation protocols and benchmark representative data\nassimilation approaches, including latent generative models and neural process\nframeworks. Additionally, we propose a lightweight multi-modal plugin to\ndemonstrate how integrating realistic observations can enhance even simple\nbaselines. Through comprehensive experiments, DAMBench establishes a rigorous\nfoundation for future research, promoting reproducibility, fair comparison, and\nextensibility to real-world multi-modal scenarios. Our dataset and code are\npublicly available at https://github.com/figerhaowang/DAMBench.", "AI": {"tldr": "DAMBench is a large-scale, multi-modal benchmark for data assimilation in atmospheric science, designed to enable realistic, reproducible, and fair evaluation of deep learning-based DA models using real background states and real observations on a unified grid.", "motivation": "To overcome two key limitations in deep learning-based data assimilation research: (i) reliance on oversimplified, synthetic perturbations, and (ii) lack of standardized benchmarks for fair model comparison in realistic, multi-modal settings.", "method": "Assemble DAMBench by collecting high-quality background states from state-of-the-art forecasting systems and real-world multi-modal observations (weather stations and satellite imagery), resample to a common grid, and temporally align. Provide unified evaluation protocols, benchmark representative approaches (latent generative models, neural processes), and a lightweight multi-modal plugin to demonstrate integration of realistic observations with simple baselines.", "result": "DAMBench offers a rigorous foundation for reproducibility, fair comparison, and extensibility to real-world multi-modal DA scenarios. The dataset and code are publicly available, and comprehensive experiments validate the benchmarking framework and evaluation protocols.", "conclusion": "DAMBench establishes a practical, scalable benchmark platform for data-driven data assimilation in atmospheric science, enabling fair comparisons and future research into multi-modal, real-world DA methods."}}
{"id": "2511.01517", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01517", "abs": "https://arxiv.org/abs/2511.01517", "authors": ["Serkan Ozturk", "Samet Hicsonmez", "Pinar Duygulu"], "title": "NSYNC: Negative Synthetic Image Generation for Contrastive Training to Improve Stylized Text-To-Image Translation", "comment": "Under review", "summary": "Current text conditioned image generation methods output realistic looking\nimages, but they fail to capture specific styles. Simply finetuning them on the\ntarget style datasets still struggles to grasp the style features. In this\nwork, we present a novel contrastive learning framework to improve the\nstylization capability of large text-to-image diffusion models. Motivated by\nthe astonishing advance in image generation models that makes synthetic data an\nintrinsic part of model training in various computer vision tasks, we exploit\nsynthetic image generation in our approach. Usually, the generated synthetic\ndata is dependent on the task, and most of the time it is used to enlarge the\navailable real training dataset. With NSYNC, alternatively, we focus on\ngenerating negative synthetic sets to be used in a novel contrastive training\nscheme along with real positive images. In our proposed training setup, we\nforward negative data along with positive data and obtain negative and positive\ngradients, respectively. We then refine the positive gradient by subtracting\nits projection onto the negative gradient to get the orthogonal component,\nbased on which the parameters are updated. This orthogonal component eliminates\nthe trivial attributes that are present in both positive and negative data and\ndirects the model towards capturing a more unique style. Experiments on various\nstyles of painters and illustrators show that our approach improves the\nperformance over the baseline methods both quantitatively and qualitatively.\nOur code is available at https://github.com/giddyyupp/NSYNC.", "AI": {"tldr": "NSYNC presents a contrastive training framework for stylizing text-to-image diffusion models by using negative synthetic data to orthogonalize the gradient against positive data, improving style capture over baselines on painter/illustrator styles.", "motivation": "Current text-conditioned image generators produce realistic images but struggle to capture specific artistic styles; fine-tuning on style data is insufficient. Leveraging synthetic data in a contrastive setup, especially negative samples, can isolate non-trivial style features and improve stylization.", "method": "Generate negative synthetic data and compute both positive and negative gradients during training. Refine the positive gradient by subtracting its projection onto the negative gradient, producing an orthogonal component that emphasizes unique style attributes. Update model parameters using this orthogonal component. This NSYNC approach uses a contrastive signal with (positive, negative) pairs to enhance style capture during training of large text-to-image diffusion models.", "result": "Experiments across various painter and illustrator styles show quantitative and qualitative improvements over baseline methods, indicating better stylization performance. The authors also release their code at the provided GitHub link.", "conclusion": "NSYNC introduces a novel, gradient-orthogonalized contrastive training scheme that leverages negative synthetic data to sharpen style-specific features in diffusion models, offering a practical route to improved stylization in text-to-image generation."}}
{"id": "2511.01553", "categories": ["cs.LG", "cs.AI", "cs.DC", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.01553", "abs": "https://arxiv.org/abs/2511.01553", "authors": ["Elvin Hajizada", "Danielle Rager", "Timothy Shea", "Leobardo Campos-Macias", "Andreas Wild", "Eyke H\u00fcllermeier", "Yulia Sandamirskaya", "Mike Davies"], "title": "Real-time Continual Learning on Intel Loihi 2", "comment": null, "summary": "AI systems on edge devices face a critical challenge in open-world\nenvironments: adapting when data distributions shift and novel classes emerge.\nWhile offline training dominates current paradigms, online continual learning\n(OCL)--where models learn incrementally from non-stationary streams without\ncatastrophic forgetting--remains challenging in power-constrained settings. We\npresent a neuromorphic solution called CLP-SNN: a spiking neural network\narchitecture for Continually Learning Prototypes and its implementation on\nIntel's Loihi 2 chip. Our approach introduces three innovations: (1)\nevent-driven and spatiotemporally sparse local learning, (2) a self-normalizing\nthree-factor learning rule maintaining weight normalization, and (3) integrated\nneurogenesis and metaplasticity for capacity expansion and forgetting\nmitigation. On OpenLORIS few-shot learning experiments, CLP-SNN achieves\naccuracy competitive with replay methods while being rehearsal-free. CLP-SNN\ndelivers transformative efficiency gains: 70\\times faster (0.33ms vs 23.2ms),\nand 5,600\\times more energy efficient (0.05mJ vs 281mJ) than the best\nalternative OCL on edge GPU. This demonstrates that co-designed brain-inspired\nalgorithms and neuromorphic hardware can break traditional accuracy-efficiency\ntrade-offs for future edge AI systems.", "AI": {"tldr": "A neuromorphic SNN approach (CLP-SNN) enables rehearsal-free online continual learning on edge devices via spiking prototypes, achieving competitive accuracy with massive gains in speed and energy efficiency on Loihi 2 compared to edge GPUs.", "motivation": "Open-world edge AI must adapt to non-stationary distributions and emerging classes under strict power and compute limits; offline training is insufficient, and traditional continual learning methods struggle with energy constraints on devices.", "method": "CLP-SNN implements Continually Learning Prototypes as a spiking neural network on Intel Loihi 2, featuring (1) event-driven, sparsely local learning across space and time; (2) a self-normalizing three-factor learning rule that preserves weight normalization; (3) integrated neurogenesis and metaplasticity to expand capacity and mitigate forgetting.", "result": "On OpenLORIS few-shot tasks, CLP-SNN achieves accuracy competitive with replay-based methods while being rehearsal-free; it is 70x faster (0.33 ms vs 23.2 ms) and 5,600x more energy efficient (0.05 mJ vs 281 mJ) than the best existing OCL approach on edge GPUs.", "conclusion": "Demonstrates that brain-inspired algorithms co-designed with neuromorphic hardware can break traditional accuracy\u2013efficiency trade-offs for future edge AI systems; suggests promising viability of online continual learning on power-constrained devices."}}
{"id": "2511.01541", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01541", "abs": "https://arxiv.org/abs/2511.01541", "authors": ["Arthur Hubert", "Gamal Elghazaly", "Rapha\u00ebl Frank"], "title": "Driving scenario generation and evaluation using a structured layer representation and foundational models", "comment": null, "summary": "Rare and challenging driving scenarios are critical for autonomous vehicle\ndevelopment. Since they are difficult to encounter, simulating or generating\nthem using generative models is a popular approach. Following previous efforts\nto structure driving scenario representations in a layer model, we propose a\nstructured five-layer model to improve the evaluation and generation of rare\nscenarios. We use this model alongside large foundational models to generate\nnew driving scenarios using a data augmentation strategy. Unlike previous\nrepresentations, our structure introduces subclasses and characteristics for\nevery agent of the scenario, allowing us to compare them using an embedding\nspecific to our layer-model. We study and adapt two metrics to evaluate the\nrelevance of a synthetic dataset in the context of a structured representation:\nthe diversity score estimates how different the scenarios of a dataset are from\none another, while the originality score calculates how similar a synthetic\ndataset is from a real reference set. This paper showcases both metrics in\ndifferent generation setup, as well as a qualitative evaluation of synthetic\nvideos generated from structured scenario descriptions. The code and extended\nresults can be found at https://github.com/Valgiz/5LMSG.", "AI": {"tldr": "Introduces a five-layer structured model (5L) for driving scenarios to improve generation and evaluation of rare scenarios; combines agent-level attributes with embeddings and two metrics (diversity and originality) for synthetic data quality; demonstrates via qualitative video outputs and code release.", "motivation": "Rare driving scenarios are hard to encounter and mimic; existing layer-based representations are limited. A richer, multi-layer structure with agent-specific attributes enables better generation, comparison, and evaluation of synthetic data for autonomous driving.", "method": "Proposes a five-layer structure with subclasses and characteristics for every agent; uses large foundational models to generate synthetic scenarios; adapts diversity and originality metrics to the structured representation; evaluates via synthetic datasets and qualitative videos; provides code at GitHub.", "result": "Shows the behavior of the two metrics across generation setups; provides qualitative evaluation of synthetic driving videos; releases code and extended results.", "conclusion": "A structured five-layer model with agent-level embeddings improves the evaluation and generation of rare driving scenarios and supports more effective data augmentation for autonomous driving research."}}
{"id": "2511.01570", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01570", "abs": "https://arxiv.org/abs/2511.01570", "authors": ["Xiaosha Xue", "Peibo Duan", "Zhipeng Liu", "Qi Chu", "Changsheng Zhang", "Bin zhang"], "title": "Gated Fusion Enhanced Multi-Scale Hierarchical Graph Convolutional Network for Stock Movement Prediction", "comment": null, "summary": "Accurately predicting stock market movements remains a formidable challenge\ndue to the inherent volatility and complex interdependencies among stocks.\nAlthough multi-scale Graph Neural Networks (GNNs) hold potential for modeling\nthese relationships, they frequently neglect two key points: the subtle\nintra-attribute patterns within each stock affecting inter-stock correlation,\nand the biased attention to coarse- and fine-grained features during\nmulti-scale sampling. To overcome these challenges, we introduce MS-HGFN\n(Multi-Scale Hierarchical Graph Fusion Network). The model features a\nhierarchical GNN module that forms dynamic graphs by learning patterns from\nintra-attributes and features from inter-attributes over different time scales,\nthus comprehensively capturing spatio-temporal dependencies. Additionally, a\ntop-down gating approach facilitates the integration of multi-scale\nspatio-temporal features, preserving critical coarse- and fine-grained features\nwithout too much interference. Experiments utilizing real-world datasets from\nU.S. and Chinese stock markets demonstrate that MS-HGFN outperforms both\ntraditional and advanced models, yielding up to a 1.4% improvement in\nprediction accuracy and enhanced stability in return simulations. The code is\navailable at https://anonymous.4open.science/r/MS-HGFN.", "AI": {"tldr": "MS-HGFN introduces a hierarchical, multi-scale GNN framework with a top-down gating mechanism to jointly model intra-stock attributes and inter-stock relations across time scales, achieving improved stock movement prediction.", "motivation": "Stock markets are volatile and exhibit complex interdependencies; conventional GNNs at a single scale may miss subtle intra-attribute patterns and misweight multi-scale features. There is a need to capture both intra-attribute patterns and multi-scale spatio-temporal dependencies while preserving coarse- and fine-grained information.", "method": "A hierarchical GNN module constructs dynamic graphs by learning intra-attribute patterns and inter-attribute features across time scales; a top-down gating mechanism fuses multi-scale features, preserving important coarse- and fine-grained information.", "result": "MS-HGFN outperforms traditional and advanced models on real-world U.S. and Chinese market data, achieving up to 1.4% higher prediction accuracy and more stable return simulations; code released at the provided URL.", "conclusion": "The proposed framework effectively captures spatio-temporal dependencies across scales, addressing intra-attribute and feature-weighting biases, and offers robust stock movement prediction with improved stability."}}
{"id": "2511.01546", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01546", "abs": "https://arxiv.org/abs/2511.01546", "authors": ["Ge Gao", "Zishuo Gao", "Hongyan Cui", "Zhiyang Jia", "Zhuang Luo", "ChaoPeng Liu"], "title": "PCD-ReID: Occluded Person Re-Identification for Base Station Inspection", "comment": "11 pages, 7 figures", "summary": "Occluded pedestrian re-identification (ReID) in base station environments is\na critical task in computer vision, particularly for surveillance and security\napplications. This task faces numerous challenges, as occlusions often obscure\nkey body features, increasing the complexity of identification. Traditional\nResNet-based ReID algorithms often fail to address occlusions effectively,\nnecessitating new ReID methods. We propose the PCD-ReID (Pedestrian Component\nDiscrepancy) algorithm to address these issues. The contributions of this work\nare as follows: To tackle the occlusion problem, we design a Transformer-based\nPCD network capable of extracting shared component features, such as helmets\nand uniforms. To mitigate overfitting on public datasets, we collected new\nreal-world patrol surveillance images for model training, covering six months,\n10,000 individuals, and over 50,000 images. Comparative experiments with\nexisting ReID algorithms demonstrate that our model achieves a mean Average\nPrecision (mAP) of 79.0% and a Rank-1 accuracy of 82.7%, marking a 15.9% Rank-1\nimprovement over ResNet50-based methods. Experimental evaluations indicate that\nPCD-ReID effectively achieves occlusion-aware ReID performance for personnel in\ntower inspection scenarios, highlighting its potential for practical deployment\nin surveillance and security applications.", "AI": {"tldr": "Transformer-based PCD-ReID uses Pedestrian Component Discrepancy to tackle occluded ReID; introduces real-world patrol dataset; demonstrates strong occlusion-aware performance with notable improvements over ResNet50-based methods.", "motivation": "Occlusion severely hinders pedestrian re-identification, and traditional ResNet-based methods struggle to capture discriminative cues under occlusion. Public ReID datasets may not reflect real-world patrol surveillance conditions, risking overfitting.", "method": "Introduce a Transformer-based PCD (Pedestrian Component Discrepancy) network that extracts shared component features (e.g., helmets, uniforms) and leverages component discrepancy to handle occlusions. To reduce overfitting, the authors collected a real-world patrol surveillance dataset (six months, 10,000 individuals, >50,000 images) for training. The model aims to be occlusion-aware and robust for tower inspection surveillance scenarios.", "result": "On the proposed dataset and benchmark comparisons, PCD-ReID achieved a mean Average Precision (mAP) of 79.0% and Rank-1 accuracy of 82.7%, representing a 15.9 percentage-point improvement in Rank-1 over ResNet50-based methods.", "conclusion": "PCD-ReID demonstrates effective occlusion-aware ReID suitable for surveillance deployment, with real-world dataset support enhancing generalization and practical applicability in security contexts."}}
{"id": "2511.01572", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01572", "abs": "https://arxiv.org/abs/2511.01572", "authors": ["Wang Hao", "Kuang Zhang", "Hou Chengyu", "Yuan Zhonghao", "Tan Chenxing", "Fu Weifeng", "Zhu Yangying"], "title": "HIT-ROCKET: Hadamard-vector Inner-product Transformer for ROCKET", "comment": null, "summary": "Time series classification holds broad application value in communications,\ninformation countermeasures, finance, and medicine. However, state-of-the-art\n(SOTA) methods-including HIVE-COTE, Proximity Forest, and TS-CHIEF-exhibit high\ncomputational complexity, coupled with lengthy parameter tuning and training\ncycles. In contrast, lightweight solutions like ROCKET (Random Convolutional\nKernel Transform) offer greater efficiency but leave substantial room for\nimprovement in kernel selection and computational overhead. To address these\nchallenges, we propose a feature extraction approach based on Hadamard\nconvolutional transform, utilizing column or row vectors of Hadamard matrices\nas convolution kernels with extended lengths of varying sizes. This enhancement\nmaintains full compatibility with existing methods (e.g., ROCKET) while\nleveraging kernel orthogonality to boost computational efficiency, robustness,\nand adaptability. Comprehensive experiments on multi-domain datasets-focusing\non the UCR time series dataset-demonstrate SOTA performance: F1-score improved\nby at least 5% vs. ROCKET, with 50% shorter training time than miniROCKET\n(fastest ROCKET variant) under identical hyperparameters, enabling deployment\non ultra-low-power embedded devices. All code is available on GitHub.", "AI": {"tldr": "A Hadamard convolutional transform-based feature extractor augments ROCKET-like time-series classifiers by using orthogonal Hadamard kernels of varying lengths, achieving state-of-the-art accuracy with substantially reduced training time, enabling deployment on ultra-low-power devices.", "motivation": "State-of-the-art time-series classifiers (e.g., HIVE-COTE, Proximity Forest, TS-CHIEF) deliver high accuracy but at high computational cost and long training cycles. Lightweight methods like ROCKET are efficient but leave room for improvement in kernel selection and overhead. The paper seeks a simple, orthogonal-kernel approach to boost ROCKET\u2019s performance without increasing training overhead.", "method": "Introduce a Hadamard convolutional transform that uses rows/columns of Hadamard matrices as convolution kernels of extended, varying lengths. This approach remains compatible with existing pipelines (e.g., ROCKET) and exploits kernel orthogonality to improve feature robustness and computational efficiency. Extensive experiments on multi-domain datasets, focusing on UCR time series, assess accuracy and training time.", "result": "F1-score improves by at least 5% over ROCKET; training time is about 50% shorter than miniROCKET under the same hyperparameters; demonstrates SOTA performance on UCR datasets and suitability for ultra-low-power embedded devices; code is available on GitHub.", "conclusion": "Orthogonal Hadamard-based kernel transforms offer a simple yet effective enhancement to ROCKET-like pipelines, delivering higher accuracy with reduced training time while preserving compatibility. This supports deployment in resource-constrained environments and opens avenues for further work on kernel-length selection and hardware acceleration."}}
{"id": "2511.01549", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01549", "abs": "https://arxiv.org/abs/2511.01549", "authors": ["Mikhail Konov", "Lion J. Gleiter", "Khoa Co", "Monica Yabal", "Tingying Peng"], "title": "NOA: a versatile, extensible tool for AI-based organoid analysis", "comment": null, "summary": "AI tools can greatly enhance the analysis of organoid microscopy images, from\ndetection and segmentation to feature extraction and classification. However,\ntheir limited accessibility to biologists without programming experience\nremains a major barrier, resulting in labor-intensive and largely manual\nworkflows. Although a few AI models for organoid analysis have been developed,\nmost existing tools remain narrowly focused on specific tasks. In this work, we\nintroduce the Napari Organoid Analyzer (NOA), a general purpose graphical user\ninterface to simplify AI-based organoid analysis. NOA integrates modules for\ndetection, segmentation, tracking, feature extraction, custom feature\nannotation and ML-based feature prediction. It interfaces multiple\nstate-of-the-art algorithms and is implemented as an open-source napari plugin\nfor maximal flexibility and extensibility. We demonstrate the versatility of\nNOA through three case studies, involving the quantification of morphological\nchanges during organoid differentiation, assessment of phototoxicity effects,\nand prediction of organoid viability and differentiation state. Together, these\nexamples illustrate how NOA enables comprehensive, AI-driven organoid image\nanalysis within an accessible and extensible framework.", "AI": {"tldr": "Napari Organoid Analyzer (NOA) is an open-source GUI plugin that unifies AI-based organoid image analysis (detection, segmentation, tracking, feature extraction, ML prediction) into a flexible, accessible workflow, demonstrated across three case studies.", "motivation": "Biologists face barriers using AI due to lack of programming expertise; existing tools are task-specific; need a general, accessible, extensible solution for organoid image analysis.", "method": "Develop NOA as a Napari plugin with modules for detection, segmentation, tracking, feature extraction, custom feature annotation, and ML-based feature prediction; interfaces multiple state-of-the-art algorithms; implemented as open-source; supports extensibility.", "result": "Shows versatility via three case studies: morphological changes during differentiation, phototoxicity effects, and predicting viability/differentiation state; demonstrates comprehensive, AI-driven analysis within accessible framework.", "conclusion": "NOA lowers barriers to AI-enabled organoid analysis, providing a general, extensible platform that combines multiple AI tools in a user-friendly GUI."}}
{"id": "2511.01588", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01588", "abs": "https://arxiv.org/abs/2511.01588", "authors": ["Zhicheng Wang", "Chen Ju", "Xu Chen", "Shuai Xiao", "Jinsong Lan", "Xiaoyong Zhu", "Ying Chen", "Zhiguo Cao"], "title": "Explore More, Learn Better: Parallel MLLM Embeddings under Mutual Information Minimization", "comment": null, "summary": "Embedding models are a cornerstone of modern AI. Driven by Multimodal Large\nLanguage Models (MLLMs), they have made great progress in architecture and data\ncuration, while the holistic paradigm is still limited to SSC, i.e., single\ninput, singular embedding, contrastive supervision, which collapses rich,\nmultifaceted inputs into monolithic embeddings and fails to fully exploit MLLM\ncapabilities. In this paper, we tailor one Parallel Decoupling Framework (PDF)\nfor multimodal embedding learning, by utilizing the proprietary steerability of\nMLLMs, i.e., their ability to flexibly generate quite differentiated response\nunder explicit instructions. Concretely, PDF conditions a shared MLLM backbone\non distinct, learnable prefixes to roll out multiple parallel paths for one\ninput, then relies on these paths to obtain parallel embeddings. To promote\nfull parallel diversity, we employ Mutual Information Minimization (MIM) as an\nexplicit constraint, coupled with per-path contrastive supervision to maintain\nsemantic alignment. Such dual-objectives force PDF to yield robust semantic\ncoverage and a generalizable embedding space. Ultimately, the remarkable\nembedding space are accessible at inference via one single forward pass,\nincurring negligible computational overhead. We instantiate PDF on multiple\nMLLM backbones and prove its effectiveness on MMEB benchmark. Significant gains\nare consistently achieved across various resolutions and model sizes, e.g.,\nboosting the VLM2Vec-LLaVA-1.6-LR model by a remarkable +8.9% (7B), while the\nVLM2Vec-Qwen2VL models by +4.2% (2B) and +3.1% (7B). In terms of efficiency,\nour 2B model surpasses its baseline by +2.6% using only half the computational\nbudget.", "AI": {"tldr": "PDF: a parallel decoupling framework for multimodal embeddings using distinct prefixes on an MLLM backbone with mutual information minimization and per-path contrastive loss to achieve diverse, robust embeddings with a single forward pass.", "motivation": "SSC (single input, single embedding, contrastive supervision) underutilizes MLLMs\u2019 steerability and rich multimodal signals; need diversified, robust, and efficient multimodal embeddings.", "method": "Introduce PDF that applies learnable prefixes to a shared MLLM backbone to create multiple parallel paths for one input; enforce diversity via Mutual Information Minimization (MIM) and per-path contrastive supervision to align semantics; enable inference with a single forward pass.", "result": "Significant gains across backbones and model sizes on MMEB: +8.9% for VLM2Vec-LLaVA-1.6-LR (7B); +4.2% (2B) and +3.1% (7B) for VLM2Vec-Qwen2VL; 2B model shows +2.6% efficiency gain with half the compute budget.", "conclusion": "PDF yields a robust, semantically rich and generalizable embedding space with negligible overhead, demonstrated across multiple backbones and resolutions, highlighting the value of MLLM steerability for efficient, diverse multimodal embeddings."}}
{"id": "2511.01592", "categories": ["cs.LG", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2511.01592", "abs": "https://arxiv.org/abs/2511.01592", "authors": ["Nat\u00e1lia Ribeiro Marinho", "Richard Loendersloot", "Frank Grooteman", "Jan Willem Wiegman", "Uraz Odyurt", "Tiedo Tinga"], "title": "Defining Energy Indicators for Impact Identification on Aerospace Composites: A Physics-Informed Machine Learning Perspective", "comment": null, "summary": "Energy estimation is critical to impact identification on aerospace\ncomposites, where low-velocity impacts can induce internal damage that is\nundetectable at the surface. Current methodologies for energy prediction are\noften constrained by data sparsity, signal noise, complex feature\ninterdependencies, non-linear dynamics, massive design spaces, and the\nill-posed nature of the inverse problem. This study introduces a\nphysics-informed framework that embeds domain knowledge into machine learning\nthrough a dedicated input space. The approach combines observational biases,\nwhich guide the design of physics-motivated features, with targeted feature\nselection to retain only the most informative indicators. Features are\nextracted from time, frequency, and time-frequency domains to capture\ncomplementary aspects of the structural response. A structured feature\nselection process integrating statistical significance, correlation filtering,\ndimensionality reduction, and noise robustness ensures physical relevance and\ninterpretability. Exploratory data analysis further reveals domain-specific\ntrends, yielding a reduced feature set that captures essential dynamic\nphenomena such as amplitude scaling, spectral redistribution, and transient\nsignal behaviour. Together, these steps produce a compact set of\nenergy-sensitive indicators with both statistical robustness and physical\nsignificance, resulting in impact energy predictions that remain interpretable\nand traceable to measurable structural responses. Using this optimised input\nspace, a fully-connected neural network is trained and validated with\nexperimental data from multiple impact scenarios, including pristine and\ndamaged states. The resulting model demonstrates significantly improved impact\nenergy prediction accuracy, reducing errors by a factor of three compared to\nconventional time-series techniques and purely data-driven models.", "AI": {"tldr": "A physics-informed ML approach using a physics-motivated input space and structured feature selection yields threefold improvement in predicting impact energy for aerospace composites.", "motivation": "Energy estimation from low-velocity impacts on aerospace composites is challenging due to data sparsity, signal noise, complex feature interdependencies, non-linear dynamics, large design spaces, and the ill-posed inverse problem. A model that is interpretable and grounded in physical insight is needed.", "method": "Construct a dedicated physics-informed input space by extracting features from time, frequency, and time-frequency domains guided by observational biases. Apply a structured feature selection process combining statistical significance testing, correlation filtering, dimensionality reduction, and noise-robustness to retain only informative and physically relevant indicators. Use exploratory data analysis to identify domain trends and produce a compact feature set that captures amplitude scaling, spectral redistribution, and transient behavior. Train a fully-connected neural network on the optimized inputs using experimental data from multiple impact scenarios (pristine and damaged states).", "result": "The optimized input space with physics-informed features enabled significantly improved energy prediction accuracy, achieving a threefold reduction in error compared to conventional time-series methods and purely data-driven models, while maintaining interpretability linked to measurable structural responses.", "conclusion": "Embedding domain knowledge into the learning framework yields robust, interpretable energy estimates across impact scenarios, highlighting the value of physics-informed feature design and structured selection for aerospace composite health assessment."}}
{"id": "2511.01574", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01574", "abs": "https://arxiv.org/abs/2511.01574", "authors": ["Md Sumon Ali", "Muzammil Behzad"], "title": "Generative Adversarial Synthesis and Deep Feature Discrimination of Brain Tumor MRI Images", "comment": "9 pagers, 8 Figures", "summary": "Compared to traditional methods, Deep Learning (DL) becomes a key technology\nfor computer vision tasks. Synthetic data generation is an interesting use case\nfor DL, especially in the field of medical imaging such as Magnetic Resonance\nImaging (MRI). The need for this task since the original MRI data is limited.\nThe generation of realistic medical images is completely difficult and\nchallenging. Generative Adversarial Networks (GANs) are useful for creating\nsynthetic medical images. In this paper, we propose a DL based methodology for\ncreating synthetic MRI data using the Deep Convolutional Generative Adversarial\nNetwork (DC-GAN) to address the problem of limited data. We also employ a\nConvolutional Neural Network (CNN) classifier to classify the brain tumor using\nsynthetic data and real MRI data. CNN is used to evaluate the quality and\nutility of the synthetic images. The classification result demonstrates\ncomparable performance on real and synthetic images, which validates the\neffectiveness of GAN-generated images for downstream tasks.", "AI": {"tldr": "DC-GAN generated MRI data used to train a CNN classifier; synthetic data yields comparable brain tumor classification performance to real data, supporting GAN-based data augmentation for medical imaging.", "motivation": "MRI datasets are limited; synthetic data can augment training and enable effective DL for tumor classification.", "method": "Use Deep Convolutional GAN to generate synthetic MRI images; train/evaluate a CNN classifier on synthetic and real MRI data to assess quality and utility.", "result": "CNN classification performance on synthetic images is comparable to that on real images, indicating GAN-generated MRI data are usable for downstream tasks.", "conclusion": "GAN-generated synthetic MRI data can alleviate data scarcity and support medical image classification without substantial loss in accuracy."}}
{"id": "2511.01605", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01605", "abs": "https://arxiv.org/abs/2511.01605", "authors": ["Daniel Busbib", "Ami Wiesel"], "title": "Estimation of Toeplitz Covariance Matrices using Overparameterized Gradient Descent", "comment": null, "summary": "We consider covariance estimation under Toeplitz structure. Numerous\nsophisticated optimization methods have been developed to maximize the Gaussian\nlog-likelihood under Toeplitz constraints. In contrast, recent advances in deep\nlearning demonstrate the surprising power of simple gradient descent (GD)\napplied to overparameterized models. Motivated by this trend, we revisit\nToeplitz covariance estimation through the lens of overparameterized GD. We\nmodel the $P\\times P$ covariance as a sum of $K$ complex sinusoids with\nlearnable parameters and optimize them via GD. We show that when $K = P$, GD\nmay converge to suboptimal solutions. However, mild overparameterization ($K =\n2P$ or $4P$) consistently enables global convergence from random\ninitializations. We further propose an accelerated GD variant with separate\nlearning rates for amplitudes and frequencies. When frequencies are fixed and\nonly amplitudes are optimized, we prove that the optimization landscape is\nasymptotically benign and any stationary point recovers the true covariance.\nFinally, numerical experiments demonstrate that overparameterized GD can match\nor exceed the accuracy of state-of-the-art methods in challenging settings,\nwhile remaining simple and scalable.", "AI": {"tldr": "Model Toeplitz covariance as a sum of K complex sinusoids and optimize with overparameterized gradient descent; mild overparameterization (K ~ 2P or 4P) yields global convergence from random starts, offering a simple, scalable alternative that matches or exceeds state-of-the-art performance.", "motivation": "Toeplitz covariance estimation using Gaussian likelihood constraints is optimization-heavy. The success of gradient-based methods in deep learning motivates exploring simple GD for this structured problem, asking whether overparameterization guarantees global convergence and good empirical performance.", "method": "Represent the P\u00d7P Toeplitz covariance as a sum of K complex sinusoids with learnable amplitudes and frequencies; optimize these parameters via gradient descent. Findings: (i) K = P can lead to suboptimal solutions; (ii) mild overparameterization with K = 2P or 4P yields global convergence from random initializations. An accelerated GD variant with separate learning rates for amplitudes and frequencies is proposed. When frequencies are fixed and only amplitudes are optimized, the landscape is asymptotically benign and any stationary point recovers the true covariance.", "result": "Overparameterized GD can match or exceed the accuracy of state-of-the-art Toeplitz covariance estimation methods in challenging settings, while remaining simple and scalable.", "conclusion": "Mild overparameterization in an overparameterized GD framework provides a theoretically and empirically effective approach to Toeplitz covariance estimation, offering a simple, scalable alternative to more complex optimization methods."}}
{"id": "2511.01593", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01593", "abs": "https://arxiv.org/abs/2511.01593", "authors": ["Yizhu Chen", "Chen Ju", "Zhicheng Wang", "Shuai Xiao", "Xu Chen", "Jinsong Lan", "Xiaoyong Zhu", "Ying Chen"], "title": "Wave-Particle (Continuous-Discrete) Dualistic Visual Tokenization for Unified Understanding and Generation", "comment": null, "summary": "The unification of understanding and generation within a single multi-modal\nlarge model (MLLM) remains one significant challenge, largely due to the\ndichotomy between continuous and discrete visual tokenizations. Continuous\ntokenizer (CT) achieves strong performance by bridging multiple\nindependently-trained understanding modules and generation modules, but suffers\nfrom complex multi-stage pipelines and substantial engineering overhead.\nConversely, discrete tokenizers (DT) offer a conceptually elegant idea by\nquantizing each image into a primitive, but inevitably leading to information\nloss and performance degradation. To resolve this tension, we question the\nbinary choice between CT and DT, inspired by the wave-particle duality of\nlight, and propose the Continuous-Discrete Dualistic Visual Tokenizer (CDD-VT).\nWe treat visual data as a flexible composition of image primitives derived from\nquantized codebooks, with the crucial insight that the primitive number\nassigned to each visual sample is adaptively determined according to its\ncomplexity: simple instances use a few primitives, emulating discrete\ntokenization, while complex instances use many, approximating continuous\ntokenization. Two core components are designed: Diverse Quantitative\nPrimitives, which encourage primitives orthogonality to better populate\ninformation space, and Dynamic Primitive Allocator, which assesses sample\ncomplexity to determine the optimal set of primitives. Extensive experiments on\nreconstruction, retrieval and classification show that CDD-VT achieves superior\nperformance over to specialized CT and DT, effectively getting strong result\nwithin a concise and scalable MLLM.", "AI": {"tldr": "Presents CDD-VT, a hybrid continuous-discrete visual tokenizer that adaptively assigns the number of primitives per image sample to balance information preservation and efficiency, surpassing purely continuous or discrete tokenizers in multiple tasks.", "motivation": "To resolve the trade-off between continuous tokenizers (strong performance but complex pipelines) and discrete tokenizers (simplicity but information loss) by proposing a wave-particle inspired dualistic tokenizer for unified multi-modal modeling.", "method": "Introduce two components: Diverse Quantitative Primitives to enforce orthogonality among tokens, and Dynamic Primitive Allocator to estimate sample complexity and select the optimal primitive count from a quantized codebook; evaluate on reconstruction, retrieval, and classification.", "result": "CDD-VT outperforms specialized CT and DT baselines on reconstruction, retrieval, and classification tasks, demonstrating strong performance with a concise, scalable MLLM.", "conclusion": "Adaptive hybrid tokenization can unify understanding and generation in MLLMs, offering improved performance and reduced engineering complexity; adaptive token counts per sample effectively balance fidelity and efficiency."}}
{"id": "2511.01633", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01633", "abs": "https://arxiv.org/abs/2511.01633", "authors": ["Chengying Huan", "Ziheng Meng", "Yongchao Liu", "Zhengyi Yang", "Yun Zhu", "Yue Yun", "Shipeng Li", "Rong Gu", "Xiabao Wu", "Haitao Zhang", "Chuntao Hong", "Shaonan Ma", "Guihai Chen", "Chen Tian"], "title": "Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with Efficient LLM Serving", "comment": null, "summary": "Graph Chain-of-Thought (Graph-CoT) enables large language models (LLMs) to\nperform step-by-step reasoning over graph-structured knowledge, but existing\npipelines suffer from low accuracy, excessive token usage, high latency, and\nlow throughput due to single-agent monolithic prompts, repeated context\nre-encoding, and inefficient serving execution. We present GLM, the first\nmulti-agent Graph-CoT system co-designed with an optimized LLM serving\narchitecture. GLM decomposes reasoning into specialized agents for\nclassification, reasoning, action generation, and graph retrieval, enabling\nbranching and selective context sharing to reduce prompt length and reasoning\niterations while preserving reasoning quality, thereby improving accuracy and\nreducing overall token consumption. To scale inference, we introduce a\nGraph-CoT-aware LLM inference mechanism with graph-specific KV-cache\nmanagement, priority-based eviction, and pipelined execution to improve serving\nefficiency. Experiments demonstrate that GLM improves answer accuracy by up to\n38%, reduces token cost by up to 95.7%, lowers inference latency by 90.3%, and\nachieves up to 15.1x higher throughput compared to state-of-the-art Graph-CoT\nbaselines, enabling efficient adoption for complex real-world reasoning at\nscale.", "AI": {"tldr": "GLM presents a multi-agent Graph-CoT system that distributes graph-based reasoning across specialized agents (classification, reasoning, action generation, graph retrieval) and couples this with an optimized LLM serving stack. This co-design reduces prompt length and reasoning iterations via branching/selective context sharing, and accelerates inference through a graph-aware KV-cache, eviction policy, and pipelined execution. Empirically, GLM improves accuracy, reduces token cost and latency, and boosts throughput versus Graph-CoT baselines.", "motivation": "Graph-CoT methods improve reasoning over graph-structured knowledge but suffer from high cost in time and tokens due to monolithic prompts, repeated context re-encoding, and inefficient serving. There is a need for scalable, efficient, and accurate reasoning systems that can handle complex graphs in real time.", "method": "GLM introduces a multi-agent framework with specialized roles: classification, reasoning, action generation, and graph retrieval. It enables branching and selective context sharing to prune prompt length and reduce reasoning iterations. For inference scalability, it employs a graph-aware LLM backend with dedicated KV-cache management, priority-based eviction, and pipelined execution to improve serving latency and throughput.", "result": "Empirical results show GLM achieving up to 38% accuracy improvement, up to 95.7% reduction in token cost, up to 90.3% lower inference latency, and up to 15.1x higher throughput compared with state-of-the-art Graph-CoT baselines.", "conclusion": "Co-designing specialized reasoning agents with an optimized serving stack enables more accurate and efficient Graph-CoT reasoning, making complex graph-based reasoning more scalable for real-world use."}}
{"id": "2511.01600", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01600", "abs": "https://arxiv.org/abs/2511.01600", "authors": ["Agnar Martin Bj\u00f8rnstad", "Elias Stenhede", "Arian Ranjbar"], "title": "Lite ENSAM: a lightweight cancer segmentation model for 3D Computed Tomography", "comment": null, "summary": "Accurate tumor size measurement is a cornerstone of evaluating cancer\ntreatment response. The most widely adopted standard for this purpose is the\nResponse Evaluation Criteria in Solid Tumors (RECIST) v1.1, which relies on\nmeasuring the longest tumor diameter in a single plane. However, volumetric\nmeasurements have been shown to provide a more reliable assessment of treatment\neffect. Their clinical adoption has been limited, though, due to the\nlabor-intensive nature of manual volumetric annotation. In this paper, we\npresent Lite ENSAM, a lightweight adaptation of the ENSAM architecture designed\nfor efficient volumetric tumor segmentation from CT scans annotated with RECIST\nannotations. Lite ENSAM was submitted to the MICCAI FLARE 2025 Task 1:\nPan-cancer Segmentation in CT Scans, Subtask 2, where it achieved a Dice\nSimilarity Coefficient (DSC) of 60.7% and a Normalized Surface Dice (NSD) of\n63.6% on the hidden test set, and an average total RAM time of 50.6 GBs and an\naverage inference time of 14.4 s on CPU on the public validation dataset.", "AI": {"tldr": "A lightweight adaptation (Lite ENSAM) of the ENSAM architecture for fast volumetric tumor segmentation from RECIST-annotated CTs; achieved DSC 60.7%, NSD 63.6% on hidden test in FLARE 2025 Subtask 2, with ~50.6 GB RAM and 14.4 s CPU inference on public validation.", "motivation": "Enable volumetric tumor assessment without heavy manual labeling by delivering an efficient automated segmentation method that leverages RECIST annotations.", "method": "Lite ENSAM, a lightweight adaptation of ENSAM, for efficient volumetric tumor segmentation from CT scans annotated with RECIST. Evaluated on MICCAI FLARE 2025 Task 1: Subtask 2; CPU-based inference reported on public validation dataset; metrics computed on hidden test set.", "result": "DSC 60.7% and NSD 63.6% on the hidden test set. Average total RAM time 50.6 GBs and average CPU inference time 14.4 seconds on the public validation dataset.", "conclusion": "A lightweight model approach (Lite ENSAM) can deliver competitive volumetric segmentation performance with practical CPU-based efficiency, supporting more reliable and scalable RECIST-informed volumetric assessment in clinical workflows, though current metrics indicate room for improvement to reach higher clinical acceptance."}}
{"id": "2511.01641", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01641", "abs": "https://arxiv.org/abs/2511.01641", "authors": ["Xiaopeng Ke", "Yihan Yu", "Ruyue Zhang", "Zhishuo Zhou", "Fangzhou Shi", "Chang Men", "Zhengdan Zhu"], "title": "Cross-Treatment Effect Estimation for Multi-Category, Multi-Valued Causal Inference via Dynamic Neural Masking", "comment": null, "summary": "Counterfactual causal inference faces significant challenges when extended to\nmulti-category, multi-valued treatments, where complex cross-effects between\nheterogeneous interventions are difficult to model. Existing methodologies\nremain constrained to binary or single-type treatments and suffer from\nrestrictive assumptions, limited scalability, and inadequate evaluation\nframeworks for complex intervention scenarios.\n  We present XTNet, a novel network architecture for multi-category,\nmulti-valued treatment effect estimation. Our approach introduces a\ncross-effect estimation module with dynamic masking mechanisms to capture\ntreatment interactions without restrictive structural assumptions. The\narchitecture employs a decomposition strategy separating basic effects from\ncross-treatment interactions, enabling efficient modeling of combinatorial\ntreatment spaces. We also propose MCMV-AUCC, a suitable evaluation metric that\naccounts for treatment costs and interaction effects. Extensive experiments on\nsynthetic and real-world datasets demonstrate that XTNet consistently\noutperforms state-of-the-art baselines in both ranking accuracy and effect\nestimation quality. The results of the real-world A/B test further confirm its\neffectiveness.", "AI": {"tldr": "XTNet introduces a cross-effect estimation module with dynamic masking for multi-category, multi-valued treatments, enabling decomposition of basic effects and cross-treatment interactions to efficiently model combinatorial intervention spaces; it also proposes MCMV-AUCC for evaluation accounting for costs and interactions, and shows superior ranking and estimation performance on synthetic/real data and in a real-world A/B test.", "motivation": "The problem is causal inference with multi-category, multi-valued treatments where interactions between heterogeneous interventions are complex. Existing methods are limited to binary/single-type treatments, rely on restrictive assumptions, scale poorly, and lack proper evaluation frameworks for complex interventions.", "method": "XTNet architecture with a cross-effect estimation module that uses dynamic masking to capture treatment interactions without strong structural assumptions. It employs a decomposition strategy separating basic effects from cross-treatment interactions to efficiently model large combinatorial treatment spaces.", "result": "Empirical results show XTNet consistently outperforms state-of-the-art baselines in both ranking accuracy and effect estimation quality across synthetic and real-world datasets; real-world A/B test results corroborate its effectiveness.", "conclusion": "XTNet provides a scalable and accurate solution for estimating causal effects under multi-category, multi-valued treatments by explicitly modeling cross-effects and interactions, and introduces a suitable evaluation metric (MCMV-AUCC) to assess both costs and interactions."}}
{"id": "2511.01610", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01610", "abs": "https://arxiv.org/abs/2511.01610", "authors": ["Mahmut Selman Gokmen", "Cody Bumgardner"], "title": "DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning", "comment": null, "summary": "Vision Foundation Models (VFMs) have advanced representation learning through\nself-supervised methods. However, existing training pipelines are often\ninflexible, domain-specific, or computationally expensive, which limits their\nusability across different domains and resource settings. DINO-MX is a modular\nand extensible training framework that combines the core principles of DINO,\nDINOv2 and DINOv3 within a unified configuration-driven system. It supports a\nvariety of transformer-based architectures and is fully compatible with the\nHugging Face ecosystem. The framework includes multiple training strategies\nsuch as low-rank adaptation (LoRA), layer freezing, and knowledge distillation,\nalong with support for distributed training through both Distributed Data\nParallel (DDP) and Fully Sharded Data Parallel (FSDP). DINO-MX is designed to\nwork with both natural and specialized data types, including single- and\nmulti-channel images. Experimental results on diverse datasets show that\nDINO-MX achieves competitive performance while significantly reducing\ncomputational costs. Additionally, it offers interpretability tools and a\nlabel-guided data augmentation method that improves attention-based\nlocalization without the need for extra detection or segmentation heads.\nDINO-MX provides a reproducible and scalable foundation for developing,\nadapting, and benchmarking self-supervised vision models across a range of\nresearch and real-world applications.", "AI": {"tldr": "A modular, configurable training framework DINO-MX unifies DINO family methods for vision transformers, enabling flexible training across domains with reduced compute, interpretability tools, and label-guided augmentation.", "motivation": "Existing vision foundation model pipelines are inflexible, domain-specific, or compute-intensive; there is a need for a configurable, scalable framework compatible with Hugging Face for diverse data and architectures.", "method": "DINO-MX unifies DINO, DINOv2, DINOv3 principles in a config-driven system; supports transformer architectures; integration with Hugging Face; uses strategies like LoRA, layer freezing, knowledge distillation; distributed training via DDP and FSDP; supports natural and specialized data (single/multi-channel images); includes interpretability tools and label-guided augmentation.", "result": "Experimental results show competitive performance at significantly reduced computational costs; provides reproducible, scalable foundation; works across research and real-world applications.", "conclusion": "DINO-MX offers a flexible, extensible platform for developing, adapting, and benchmarking self-supervised vision models across diverse domains and resource settings."}}
{"id": "2511.01694", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01694", "abs": "https://arxiv.org/abs/2511.01694", "authors": ["Hossein Abdi", "Mingfei Sun", "Wei Pan"], "title": "Bayesian Natural Gradient Fine-Tuning of CLIP Models via Kalman Filtering", "comment": null, "summary": "Vision-language pre-trained models, such as CLIP, have established new\nbenchmarks in multimodal data mining. In such models, few-shot fine-tuning is a\nmajor challenge to achieve optimal performance on both in-distribution (ID) and\nout-of-distribution (OOD) datasets, especially when labeled data is scarce.\nMost existing fine-tuning approaches rely on first-order gradient-based\noptimizers, which typically suffer from slow convergence, sensitivity to\nstep-size hyperparameters, and poor generalization in OOD settings. In\ncontrast, second-order methods utilize local curvature information of the loss\nlandscape to adjust the update step size. This is particularly beneficial for\nCLIP models, whose non-convex loss functions often contain sharp critical\npoints. In such cases, natural gradient direction can offer more substantial\nand efficient per-iteration updates when fine-tuning with limited data. Natural\nGradient Descent (NGD) is obtained by preconditioning the standard gradient\nwith the inverse Fisher Information Matrix (FIM), which is computationally\nexpensive for large models. To address this, we propose a Bayesian\napproximation of NGD using a Kalman filter for CLIP models. Our method combines\nthe benefits of second-order optimization with Bayesian inference, which\nenhances generalization while providing uncertainty quantification. Extensive\nexperiments conducted on diverse image classification datasets demonstrate that\nour algorithm consistently achieves superior--or comparable--ID performance and\nimproved OOD robustness compared to state-of-the-art baselines. To the best of\nour knowledge, this work represents the first successful application of Kalman\nfiltering to fine-tuning CLIP-based models, which enables more robust and\nefficient learning in vision-language tasks.", "AI": {"tldr": "A Bayesian Kalman-filter-based natural gradient fine-tuning method for CLIP that uses second-order information to achieve robust few-shot learning, offering uncertainty quantification and improved ID/OOD performance with efficient updates.", "motivation": "Fine-tuning CLIP with limited labeled data is challenging for both ID and OOD generalization. First-order optimizers suffer from slow convergence, hyperparameter sensitivity, and poor OOD generalization. Second-order methods can leverage curvature information; natural gradient is promising but computationally expensive for large models.", "method": "Introduce a Bayesian approximation of Natural Gradient Descent (NGD) by applying a Kalman filter to estimate and update a preconditioner (inverse Fisher Information Matrix) for CLIP models during fine-tuning. This yields second-order updates with uncertainty quantification, reducing computational burden while improving robustness.", "result": "Empirical evaluation across diverse image classification datasets shows that the proposed Kalman-filtered NGD method achieves superior or comparable in-distribution performance and improved out-of-distribution robustness relative to strong baselines, highlighting improved efficiency and generalization.", "conclusion": "This work represents the first successful application of Kalman filtering to fine-tune CLIP-based models, enabling more robust and efficient learning in vision-language tasks and offering uncertainty estimates that can inform model deployment."}}
{"id": "2511.01613", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01613", "abs": "https://arxiv.org/abs/2511.01613", "authors": ["Tom\u00e1\u0161 Krsi\u010dka", "Tibor Kub\u00edk"], "title": "Benchmark-Ready 3D Anatomical Shape Classification", "comment": "Shape in Medical Imaging, ShapeMI 2025, Held in Conjunction with\n  MICCAI 2025", "summary": "Progress in anatomical 3D shape classification is limited by the complexity\nof mesh data and the lack of standardized benchmarks, highlighting the need for\nrobust learning methods and reproducible evaluation. We introduce two key steps\ntoward clinically and benchmark-ready anatomical shape classification via\nself-supervised graph autoencoding. We propose Precomputed Structural Pooling\n(PSPooling), a non-learnable mesh pooling operator designed for efficient and\nstructure-preserving graph coarsening in 3D anatomical shape analysis.\nPSPooling precomputes node correspondence sets based on geometric proximity,\nenabling parallelizable and reversible pooling and unpooling operations with\nguaranteed support structure. This design avoids the sparsity and\nreconstruction issues of selection-based methods and the sequential overhead of\nedge contraction approaches, making it particularly suitable for\nhigh-resolution medical meshes. To demonstrate its effectiveness, we integrate\nPSPooling into a self-supervised graph autoencoder that learns anatomy-aware\nrepresentations from unlabeled surface meshes. We evaluate the downstream\nbenefits on MedShapeNet19, a new curated benchmark dataset we derive from\nMedShapeNet, consisting of 19 anatomical classes with standardized training,\nvalidation, and test splits. Experiments show that PSPooling significantly\nimproves reconstruction fidelity and classification accuracy in low-label\nregimes, establishing a strong baseline for medical 3D shape learning. We hope\nthat MedShapeNet19 will serve as a widely adopted benchmark for anatomical\nshape classification and further research in medical 3D shape analysis. Access\nthe complete codebase, model weights, and dataset information here:\nhttps://github.com/TomasKrsicka/MedShapeNet19-PSPooling.", "AI": {"tldr": "PSPooling is a non-learnable, precomputed pooling operator for structure-preserving mesh coarsening in 3D anatomical shape analysis, integrated into a self-supervised graph autoencoder. On MedShapeNet19, it improves reconstruction fidelity and low-label classification, establishing a strong benchmark with released code and data.", "motivation": "Anatomical 3D shape classification faces mesh complexity and a lack of standardized benchmarks. There is a need for robust, efficient pooling that preserves structure and supports reproducible evaluation, enabling effective self-supervised learning on high-resolution medical meshes.", "method": "Introduce Precomputed Structural Pooling (PSPooling): a non-learnable pooling operator that precomputes node correspondences based on geometric proximity, enabling parallelizable and reversible pooling/unpooling with guaranteed support structure. Integrate PSPooling into a self-supervised graph autoencoder trained on unlabeled surface meshes. Evaluate on MedShapeNet19 (19 anatomical classes with standardized splits) and provide code, weights, and dataset info.", "result": "PSPooling significantly improves reconstruction fidelity and downstream classification accuracy in low-label regimes, establishing a strong baseline for medical 3D shape learning.", "conclusion": "PSPooling is effective for medical 3D shape learning, offering efficient, structure-preserving pooling suitable for high-resolution meshes. MedShapeNet19 serves as a benchmark to advance reproducible research, with the authors providing open-source code and data."}}
{"id": "2511.01695", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.01695", "abs": "https://arxiv.org/abs/2511.01695", "authors": ["Jungyeon Koh", "Hyun Jong Yang"], "title": "Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding", "comment": null, "summary": "The growing demand for on-device large language model (LLM) inference\nhighlights the need for efficient mobile edge computing (MEC) solutions,\nespecially in resource-constrained settings. Speculative decoding offers a\npromising solution by partitioning token generation between a lightweight draft\nmodel on mobile devices and a powerful target model on edge servers, but\nsuffers from communication overhead and asynchronous delays. This paper is the\nfirst to propose a unified framework that jointly optimizes user association\nand resource allocation (UARA) to support efficient parallel speculative\ndecoding. We solve the UARA problem using a multi-agent deep reinforcement\nlearning algorithm. To evaluate our approach under realistic conditions, we\nconduct experiments using the Sionna simulator. Results show that our method\nachieves up to 28.0% and an average of 23.7% reduction in end-to-end latency\nwithout compromising inference accuracy, enabling scalable and low-latency LLM\nservices in MEC systems.", "AI": {"tldr": "Unified UARA-DRL framework for parallel speculative decoding in MEC; achieves latency reductions up to 28% (avg 23.7%) with no accuracy loss.", "motivation": "Address the demand for on-device LLM inference in resource-constrained mobile edge computing (MEC). Speculative decoding reduces compute but incurs communication overhead and asynchronous delays; a joint optimization of user association and resource allocation is needed to enable efficient parallel speculative decoding.", "method": "Propose a unified framework that jointly optimizes user association and resource allocation (UARA) to support parallel speculative decoding. Solve the UARA problem using a multi-agent deep reinforcement learning algorithm. Evaluate under realistic conditions with the Sionna simulator.", "result": "End-to-end latency is reduced by up to 28.0% and on average by 23.7%, without compromising inference accuracy, enabling scalable, low-latency LLM services in MEC systems.", "conclusion": "A joint UARA optimization via multi-agent DRL can significantly improve latency for speculative decoding in MEC without sacrificing accuracy, demonstrating viability for scalable MEC-based LLM services."}}
{"id": "2511.01617", "categories": ["cs.CV", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.01617", "abs": "https://arxiv.org/abs/2511.01617", "authors": ["Mohamed Eltahir", "Ali Habibullah", "Lama Ayash", "Tanveer Hussain", "Naeemullah Khan"], "title": "Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers", "comment": null, "summary": "In the retrieval domain, candidates' fusion from heterogeneous retrievers is\na long-standing challenge, particularly for complex, multi-modal data such as\nvideos. While typical fusion techniques are training-free, they rely solely on\nrank or score signals, disregarding candidates' representations. This work\nintroduces Vote-in-Context (ViC), a generalized, training-free framework that\nre-thinks list-wise reranking and fusion as a zero-shot reasoning task for a\nVision-Language Model (VLM). The core insight is to serialize both content\nevidence and retriever metadata directly within the VLM's prompt, allowing the\nmodel to adaptively weigh retriever consensus against visual-linguistic\ncontent. We demonstrate the generality of this framework by applying it to the\nchallenging domain of cross-modal video retrieval. To this end, we introduce\nthe S-Grid, a compact serialization map that represents each video as an image\ngrid, optionally paired with subtitles to enable list-wise reasoning over video\ncandidates. ViC is evaluated both as a single-list reranker, where it\ndramatically improves the precision of individual retrievers, and as an\nensemble fuser, where it consistently outperforms strong baselines like\nCombSUM. Across video retrieval benchmarks including ActivityNet and VATEX, the\nframework establishes new state-of-the-art zero-shot retrieval performance,\ndemonstrating its effectiveness in handling complex visual and temporal signals\nalongside text. In zero-shot settings, ViC achieves Recall@1 scores of 87.1%\n(t2v) / 89.0% (v2t) on MSR-VTT and 99.6% (v2t) on VATEX, representing massive\ngains of up to +40 Recall@1 over previous state-of-the-art baselines. We\npresent ViC as a simple, reproducible, and highly effective recipe for turning\nmodern VLMs into powerful zero-shot rerankers and fusers. Code and resources\nare publicly available at: https://github.com/mohammad2012191/ViC", "AI": {"tldr": "ViC is a training-free, zero-shot framework that reframes listwise fusion/reranking for cross-modal video retrieval as prompt-based reasoning in a Vision-Language Model, using an S-Grid serialization; it achieves state-of-the-art zero-shot Recall@1 on MSR-VTT and VATEX.\n", "motivation": "Fusion from heterogeneous retrievers is challenging and typically relies on score signals, ignoring candidates' representations. There is a need to leverage content evidence and retriever metadata within a unified, train-free framework to handle complex multi-modal data like videos.", "method": "Serialize content evidence and retriever metadata into the VLM prompt. Use S-Grid to represent each video as an image grid (optionally with subtitles) to enable list-wise reasoning. ViC can operate as a single-list reranker or as an ensemble fuser, and is evaluated in zero-shot settings on video benchmarks.", "result": "ViC improves individual retrievers' precision, outperforms CombSUM as a fusion baseline, and achieves new state-of-the-art zero-shot retrieval on ActivityNet and VATEX, with MSR-VTT Recall@1 of 87.1% (t2v) / 89.0% (v2t) and VATEX Recall@1 of 99.6% (v2t). Gains up to ~40 points in Recall@1 over prior baselines.", "conclusion": "ViC offers a simple, reproducible recipe for turning modern Vision-Language Models into powerful zero-shot rerankers and fusers for cross-modal video retrieval; code and resources are publicly available."}}
{"id": "2511.01737", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.01737", "abs": "https://arxiv.org/abs/2511.01737", "authors": ["Obaidullah Zaland", "Feras M. Awaysheh", "Sawsan Al Zubi", "Abdul Rahman Safi", "Monowar Bhuyan"], "title": "Edge AI in Highly Volatile Environments: Is Fairness Worth the Accuracy Trade-off?", "comment": "Presented at IEEE FLTA 2025", "summary": "Federated learning (FL) has emerged as a transformative paradigm for edge\nintelligence, enabling collaborative model training while preserving data\nprivacy across distributed personal devices. However, the inherent volatility\nof edge environments, characterized by dynamic resource availability and\nheterogeneous client capabilities, poses significant challenges for achieving\nhigh accuracy and fairness in client participation. This paper investigates the\nfundamental trade-off between model accuracy and fairness in highly volatile\nedge environments. This paper provides an extensive empirical evaluation of\nfairness-based client selection algorithms such as RBFF and RBCSF against\nrandom and greedy client selection regarding fairness, model performance, and\ntime, in three benchmarking datasets (CIFAR10, FashionMNIST, and EMNIST). This\nwork aims to shed light on the fairness-performance and fairness-speed\ntrade-offs in a volatile edge environment and explore potential future research\nopportunities to address existing pitfalls in \\textit{fair client selection}\nstrategies in FL. Our results indicate that more equitable client selection\nalgorithms, while providing a marginally better opportunity among clients, can\nresult in slower global training in volatile environments\\footnote{The code for\nour experiments can be found at\nhttps://github.com/obaidullahzaland/FairFL_FLTA.", "AI": {"tldr": "Fairness-aware client selection in volatile FL trades slight per-client fairness and sometimes small accuracy gains for some clients, but slows global training; empirical study across CIFAR10, FashionMNIST, and EMNIST shows a fairness-performance-speed trade-off.", "motivation": "Edge FL suffers from volatile resources and heterogeneous clients; this paper investigates the fundamental trade-off between accuracy and fairness under volatility and evaluates fairness-based selection algorithms (RBFF, RBCSF) against baselines.", "method": "Empirical study on three datasets; compare fairness-based client selection algorithms RBFF and RBCSF with random and greedy selection; assess fairness, model accuracy, and training time; provide code repository.", "result": "Fairness-based selection yields more equitable client participation and marginally better opportunities for some clients, but induces slower global training in volatile environments; trade-offs depend on dataset and scenario.", "conclusion": "Highlights fairness-performance and fairness-speed trade-offs in volatile edge FL; suggests future work to address pitfalls in fair client selection and to design strategies balancing fairness and convergence speed."}}
{"id": "2511.01618", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01618", "abs": "https://arxiv.org/abs/2511.01618", "authors": ["Xiaoyu Zhan", "Wenxuan Huang", "Hao Sun", "Xinyu Fu", "Changfeng Ma", "Shaosheng Cao", "Bohan Jia", "Shaohui Lin", "Zhenfei Yin", "Lei Bai", "Wanli Ouyang", "Yuanqi Li", "Jie Guo", "Yanwen Guo"], "title": "Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models", "comment": null, "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have\nsignificantly improved 2D visual understanding, prompting interest in their\napplication to complex 3D reasoning tasks. However, it remains unclear whether\nthese models can effectively capture the detailed spatial information required\nfor robust real-world performance, especially cross-view consistency, a key\nrequirement for accurate 3D reasoning. Considering this issue, we introduce\nViewpoint Learning, a task designed to evaluate and improve the spatial\nreasoning capabilities of MLLMs. We present the Viewpoint-100K dataset,\nconsisting of 100K object-centric image pairs with diverse viewpoints and\ncorresponding question-answer pairs. Our approach employs a two-stage\nfine-tuning strategy: first, foundational knowledge is injected to the baseline\nMLLM via Supervised Fine-Tuning (SFT) on Viewpoint-100K, resulting in\nsignificant improvements across multiple tasks; second, generalization is\nenhanced through Reinforcement Learning using the Group Relative Policy\nOptimization (GRPO) algorithm on a broader set of questions. Additionally, we\nintroduce a hybrid cold-start initialization method designed to simultaneously\nlearn viewpoint representations and maintain coherent reasoning thinking.\nExperimental results show that our approach significantly activates the spatial\nreasoning ability of MLLM, improving performance on both in-domain and\nout-of-domain reasoning tasks. Our findings highlight the value of developing\nfoundational spatial skills in MLLMs, supporting future progress in robotics,\nautonomous systems, and 3D scene understanding.", "AI": {"tldr": "A two-stage fine-tuning pipeline (SFT on Viewpoint-100K, followed by GRPO-based reinforcement learning) equips Multimodal LLMs with cross-view spatial reasoning, improving 3D tasks and cross-view consistency in both in-domain and out-of-domain scenarios.", "motivation": "To address the gap in spatial reasoning and cross-view consistency in Multimodal LLMs, which limits robust real-world 3D understanding and robotics applications.", "method": "Introduce Viewpoint-100K, a 100K object-centric image pair dataset with diverse viewpoints and QA pairs. Employ a two-stage fine-tuning: (1) Supervised Fine-Tuning on Viewpoint-100K to inject foundational spatial knowledge; (2) Reinforcement Learning with Group Relative Policy Optimization (GRPO) to enhance generalization across broader questions. Add a hybrid cold-start initialization to learn viewpoint representations while preserving coherent reasoning. ", "result": "The method activates the spatial reasoning abilities of MLLMs, yielding improved performance on both in-domain and out-of-domain spatial tasks and cross-view reasoning, with notable gains in 3D-related understanding.", "conclusion": "Foundational spatial skills can be learned by MLLMs via targeted data and optimization strategies, boosting capabilities for robotics, autonomous systems, and 3D scene understanding, and guiding future research in spatially grounded multimodal AI."}}
{"id": "2511.01740", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01740", "abs": "https://arxiv.org/abs/2511.01740", "authors": ["Dmitrij Schlesinger", "Boris Flach"], "title": "Game-theoretic distributed learning of generative models for heterogeneous data collections", "comment": "The manuscript is accepted for publishing at the 2025 Symposium on\n  Federated Learning and Intelligent Computing Systems (FLICS 2025)", "summary": "One of the main challenges in distributed learning arises from the difficulty\nof handling heterogeneous local models and data. In light of the recent success\nof generative models, we propose to meet this challenge by building on the idea\nof exchanging synthetic data instead of sharing model parameters. Local models\ncan then be treated as ``black boxes'' with the ability to learn their\nparameters from data and to generate data according to these parameters.\nMoreover, if the local models admit semi-supervised learning, we can extend the\napproach by enabling local models on different probability spaces. This allows\nto handle heterogeneous data with different modalities. We formulate the\nlearning of the local models as a cooperative game starting from the principles\nof game theory. We prove the existence of a unique Nash equilibrium for\nexponential family local models and show that the proposed learning approach\nconverges to this equilibrium. We demonstrate the advantages of our approach on\nstandard benchmark vision datasets for image classification and conditional\ngeneration.", "AI": {"tldr": "Exchanges synthetic data instead of model parameters to coordinate heterogeneous local models in distributed learning, with a game-theoretic framework that yields a unique Nash equilibrium for exponential-family models and converges to it; empirically validated on vision tasks.", "motivation": "Distributed learning with heterogeneous local models and data is challenging. Sharing model parameters is fragile when modalities and data distributions differ; synthetic-data exchange enables model-agnostic collaboration and can accommodate semi-supervised learning across different probability spaces.", "method": "Treat local models as black boxes that generate data according to their parameters. Exchange synthetic data to coordinate learning. Extend to semi-supervised settings across different probability spaces to handle modality heterogeneity. Formulate the learning as a cooperative game and prove the existence of a unique Nash equilibrium for exponential-family local models, with convergence to this equilibrium. Validate on standard vision benchmarks for image classification and conditional generation.", "result": "The approach achieves advantages on standard benchmark vision datasets for image classification and conditional generation, supported by a theoretical guarantee of a unique Nash equilibrium and convergence for exponential-family local models.", "conclusion": "Exchanging synthetic data offers a robust, model-agnostic way to address heterogeneity in distributed learning, enabling black-box local models to learn from data, potentially incorporating semi-supervised and multi-modality settings, with provable equilibrium convergence and empirical gains on vision tasks."}}
{"id": "2511.01645", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01645", "abs": "https://arxiv.org/abs/2511.01645", "authors": ["Xiaogang Xu", "Ruihang Chu", "Jian Wang", "Kun Zhou", "Wenjie Shu", "Harry Yang", "Ser-Nam Lim", "Hao Chen", "Liang Lin"], "title": "Enhancing Diffusion-based Restoration Models via Difficulty-Adaptive Reinforcement Learning with IQA Reward", "comment": null, "summary": "Reinforcement Learning (RL) has recently been incorporated into diffusion\nmodels, e.g., tasks such as text-to-image. However, directly applying existing\nRL methods to diffusion-based image restoration models is suboptimal, as the\nobjective of restoration fundamentally differs from that of pure generation: it\nplaces greater emphasis on fidelity. In this paper, we investigate how to\neffectively integrate RL into diffusion-based restoration models. First,\nthrough extensive experiments with various reward functions, we find that an\neffective reward can be derived from an Image Quality Assessment (IQA) model,\ninstead of intuitive ground-truth-based supervision, which has already been\noptimized during the Supervised Fine-Tuning (SFT) stage prior to RL. Moreover,\nour strategy focuses on using RL for challenging samples that are significantly\ndistant from the ground truth, and our RL approach is innovatively implemented\nusing MLLM-based IQA models to align distributions with high-quality images\ninitially. As the samples approach the ground truth's distribution, RL is\nadaptively combined with SFT for more fine-grained alignment. This dynamic\nprocess is facilitated through an automatic weighting strategy that adjusts\nbased on the relative difficulty of the training samples. Our strategy is\nplug-and-play that can be seamlessly applied to diffusion-based restoration\nmodels, boosting its performance across various restoration tasks. Extensive\nexperiments across multiple benchmarks demonstrate the effectiveness of our\nproposed RL framework.", "AI": {"tldr": "A plug-and-play RL framework for diffusion-based image restoration uses IQA-model rewards, focusing RL on hard samples and adaptively blending with supervised fine-tuning to boost restoration fidelity across tasks.", "motivation": "Restoration requires high fidelity, and naive RL with ground-truth rewards may be suboptimal since SFT already encodes GT information. The aim is to tailor RL feedback to perceptual quality and sample difficulty to improve diffusion-based restoration.", "method": "1) Use an IQA-based reward derived from MLLM-based IQA models instead of GT-based supervision. 2) Apply RL primarily to challenging samples far from ground truth. 3) Initialize distributions with high-quality images via MLLM-IQA guidance. 4) As samples approach GT distribution, adaptively blend RL with SFT using an automatic weighting strategy that measures sample difficulty. 5) This approach is plug-and-play for diffusion-based restoration models.", "result": "Extensive experiments across multiple benchmarks show that the RL framework improves performance on various restoration tasks.", "conclusion": "The study demonstrates that IQA-rewarded RL, coupled with an adaptive RL\u2013SFT mix, effectively enhances diffusion-based restoration, especially for difficult samples, and can be readily applied as a general enhancement to such models."}}
{"id": "2511.01741", "categories": ["cs.LG", "cs.IT", "math.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.01741", "abs": "https://arxiv.org/abs/2511.01741", "authors": ["Ameya S. Bhave", "Navnil Choudhury", "Kanad Basu"], "title": "HyperNQ: A Hypergraph Neural Network Decoder for Quantum LDPC Codes", "comment": "6 pages, 4 figures, Submitted to the IEEE International Conference on\n  Communications (ICC 2026). Preprint version", "summary": "Quantum computing requires effective error correction strategies to mitigate\nnoise and decoherence. Quantum Low-Density Parity-Check (QLDPC) codes have\nemerged as a promising solution for scalable Quantum Error Correction (QEC)\napplications by supporting constant-rate encoding and a sparse parity-check\nstructure. However, decoding QLDPC codes via traditional approaches such as\nBelief Propagation (BP) suffers from poor convergence in the presence of short\ncycles. Machine learning techniques like Graph Neural Networks (GNNs) utilize\nlearned message passing over their node features; however, they are restricted\nto pairwise interactions on Tanner graphs, which limits their ability to\ncapture higher-order correlations. In this work, we propose HyperNQ, the first\nHypergraph Neural Network (HGNN)- based QLDPC decoder that captures\nhigher-order stabilizer constraints by utilizing hyperedges-thus enabling\nhighly expressive and compact decoding. We use a two-stage message passing\nscheme and evaluate the decoder over the pseudo-threshold region. Below the\npseudo-threshold mark, HyperNQ improves the Logical Error Rate (LER) up to 84%\nover BP and 50% over GNN-based strategies, demonstrating enhanced performance\nover the existing state-of-the-art decoders.", "AI": {"tldr": "HyperNQ uses a hypergraph neural network to decode Quantum LDPC codes, capturing higher-order stabilizer constraints; it achieves substantial logical error rate reductions below the pseudo-threshold compared with BP and GNN-based decoders.", "motivation": "Quantum LDPC codes offer scalable QEC via constant-rate encoding and sparse parity checks, but Belief Propagation struggles with short cycles and standard GNNs only model pairwise interactions, limiting decoding performance.", "method": "Introduce HyperNQ, a Hypergraph Neural Network decoder that encodes higher-order stabilizer constraints through hyperedges and employs a two-stage message-passing scheme for QLDPC decoding; evaluate performance in the sub-pseudo-threshold regime.", "result": "HyperNQ reduces logical error rate by up to 84% relative to BP and up to 50% relative to GNN-based strategies in the sub-pseudo-threshold region, outperforming existing decoders.", "conclusion": "HyperNQ demonstrates that modeling higher-order correlations via HGNNs can significantly enhance QLDPC decoding, establishing HGNN-based decoders as a promising direction for scalable quantum error correction."}}
{"id": "2511.01678", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01678", "abs": "https://arxiv.org/abs/2511.01678", "authors": ["Ropeway Liu", "Hangjie Yuan", "Bo Dong", "Jiazheng Xing", "Jinwang Wang", "Rui Zhao", "Yan Xing", "Weihua Chen", "Fan Wang"], "title": "UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback", "comment": "NeurIPS 2025", "summary": "Relighting is a crucial task with both practical demand and artistic value,\nand recent diffusion models have shown strong potential by enabling rich and\ncontrollable lighting effects. However, as they are typically optimized in\nsemantic latent space, where proximity does not guarantee physical correctness\nin visual space, they often produce unrealistic results, such as overexposed\nhighlights, misaligned shadows, and incorrect occlusions. We address this with\nUniLumos, a unified relighting framework for both images and videos that brings\nRGB-space geometry feedback into a flow matching backbone. By supervising the\nmodel with depth and normal maps extracted from its outputs, we explicitly\nalign lighting effects with the scene structure, enhancing physical\nplausibility. Nevertheless, this feedback requires high-quality outputs for\nsupervision in visual space, making standard multi-step denoising\ncomputationally expensive. To mitigate this, we employ path consistency\nlearning, allowing supervision to remain effective even under few-step training\nregimes. To enable fine-grained relighting control and supervision, we design a\nstructured six-dimensional annotation protocol capturing core illumination\nattributes. Building upon this, we propose LumosBench, a disentangled\nattribute-level benchmark that evaluates lighting controllability via large\nvision-language models, enabling automatic and interpretable assessment of\nrelighting precision across individual dimensions. Extensive experiments\ndemonstrate that UniLumos achieves state-of-the-art relighting quality with\nsignificantly improved physical consistency, while delivering a 20x speedup for\nboth image and video relighting. Code is available at\nhttps://github.com/alibaba-damo-academy/Lumos-Custom.", "AI": {"tldr": "UniLumos proposes a unified RGB-space relighting framework for images and videos that enforces physical plausibility by using depth/normal supervision, enabling path-consistent, fast training; paired with LumosBench for fine-grained, attribute-level evaluation of lighting control via vision-language models.", "motivation": "Relighting with diffusion models often occurs in a semantic latent space where proximity is not guaranteed to correlate with physical correctness, leading to unrealistic highlights, shadows, and occlusions. Supervision in visual space is costly, and there is a need for fine-grained control and reliable evaluation of lighting edits.", "method": "Introduce UniLumos with a flow-matching backbone that receives RGB-space geometry feedback through depth and normal maps extracted from outputs to align lighting with scene structure. Employ path-consistency learning to enable effective supervision under few-step training. Propose a six-dimensional annotation protocol for core illumination attributes. Build LumosBench, a disentangled attribute-level benchmark that assesses lighting controllability using large vision-language models.", "result": "Achieves state-of-the-art relighting quality with significantly improved physical consistency and about a 20\u00d7 speedup for both image and video relighting.", "conclusion": "UniLumos delivers a physically grounded, efficient relighting framework for images and videos, complemented by LumosBench for interpretable, attribute-level evaluation of lighting control."}}
{"id": "2511.01743", "categories": ["cs.LG", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.01743", "abs": "https://arxiv.org/abs/2511.01743", "authors": ["Song Gao", "Shusen Jing", "Shuai Zhang", "Yue Wang", "Xiangwei Zhou", "Songyang Zhang"], "title": "Towards Efficient Federated Learning of Networked Mixture-of-Experts for Mobile Edge Computing", "comment": null, "summary": "Recent advancements in large artificial intelligence models (LAMs) are\ndriving significant innovations in mobile edge computing within next-generation\nwireless networks. However, the substantial demands for computational resources\nand large-scale training data required to train LAMs conflict with the limited\nstorage and computational capacity of edge devices, posing significant\nchallenges to training and deploying LAMs at the edge. In this work, we\nintroduce the Networked Mixture-of-Experts (NMoE) system, in which clients\ninfer collaboratively by distributing tasks to suitable neighbors based on\ntheir expertise and aggregate the returned results. For training the NMoE, we\npropose a federated learning framework that integrates both supervised and\nself-supervised learning to balance personalization and generalization, while\npreserving communication efficiency and data privacy. We conduct extensive\nexperiments to demonstrate the efficacy of the proposed NMoE system, providing\ninsights and benchmarks for the NMoE training algorithms.", "AI": {"tldr": "A networked mixture-of-experts framework (NMoE) enabling collaborative edge inference and federated training of large AI models by routing tasks to expert neighbors and combining supervised and self-supervised learning to balance personalization and generalization, with privacy-preserving and communication-efficient training.", "motivation": "LAMs require vast resources that exceed edge devices; current edge constraints in storage and computation hinder training/deployment at the edge. A distributed, privacy-preserving, and communication-efficient approach is needed to leverage edge networks for LAMs.", "method": "Introduce Networked Mixture-of-Experts (NMoE) where clients infer by distributing tasks to neighboring experts based on their expertise; train via a federated learning framework that integrates supervised and self-supervised learning to balance personalization and generalization while preserving privacy and communication efficiency.", "result": "Extensive experiments demonstrate the efficacy of the proposed NMoE system and provide insights and benchmarks for its training algorithms.", "conclusion": "NMoE provides a practical framework for training and deploying large AI models at the edge through collaborative inference and federated learning that combines supervised and self-supervised objectives, with emphasis on privacy and communication efficiency."}}
{"id": "2511.01698", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01698", "abs": "https://arxiv.org/abs/2511.01698", "authors": ["Yuhang Kang", "Ziyu Su", "Tianyang Wang", "Zaibo Li", "Wei Chen", "Muhammad Khalid Khan Niazi"], "title": "Progressive Translation of H&E to IHC with Enhanced Structural Fidelity", "comment": null, "summary": "Compared to hematoxylin-eosin (H&E) staining, immunohistochemistry (IHC) not\nonly maintains the structural features of tissue samples, but also provides\nhigh-resolution protein localization, which is essential for aiding in\npathology diagnosis. Despite its diagnostic value, IHC remains a costly and\nlabor-intensive technique. Its limited scalability and constraints in\nmultiplexing further hinder widespread adoption, especially in resource-limited\nsettings. Consequently, researchers are increasingly exploring computational\nstain translation techniques to synthesize IHC-equivalent images from\nH&E-stained slides, aiming to extract protein-level information more\nefficiently and cost-effectively. However, most existing stain translation\ntechniques rely on a linearly weighted summation of multiple loss terms within\na single objective function, strategy that often overlooks the interdepedence\namong these components-resulting in suboptimal image quality and an inability\nto simultaneously preserve structural authenticity and color fidelity. To\naddress this limitation, we propose a novel network architecture that follows a\nprogressive structure, incorporating color and cell border generation logic,\nwhich enables each visual aspect to be optimized in a stage-wise and decoupled\nmanner. To validate the effectiveness of our proposed network architecture, we\nbuild upon the Adaptive Supervised PatchNCE (ASP) framework as our baseline. We\nintroduce additional loss functions based on 3,3'-diaminobenzidine (DAB)\nchromogen concentration and image gradient, enhancing color fidelity and cell\nboundary clarity in the generated IHC images. By reconstructing the generation\npipeline using our structure-color-cell boundary progressive mechanism,\nexperiments on HER2 and ER datasets demonstrated that the model significantly\nimproved visual quality and achieved finer structural details.", "AI": {"tldr": "A progressive, decoupled architecture for translating H&E to IHC-like images enhances color fidelity and cell boundaries, outperforming baseline loss-combination approaches on HER2/ER datasets.", "motivation": "IHC provides protein localization but is costly and hard to scale; existing stain translation methods use a single objective with linearly weighted losses, neglecting interdependencies and decoupled optimization; need efficient, high-quality synthetic IHC to enable broader access.", "method": "Extend Adaptive Supervised PatchNCE (ASP) baseline with a progressive structure that decouples color, cell border, and structure generation. Introduce DAB concentration-based loss and image gradient loss, and implement a structure-color-cell boundary progressive generation pipeline.", "result": "On HER2 and ER datasets, the proposed network significantly improves visual quality and yields finer structural details in generated IHC-like images.", "conclusion": "A stage-wise, decoupled optimization framework improves both color fidelity and structural accuracy in computational stain translation, addressing limitations of single-objective loss schemes and enhancing the utility of synthetic IHC images."}}
{"id": "2511.01745", "categories": ["cs.LG", "cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.01745", "abs": "https://arxiv.org/abs/2511.01745", "authors": ["Mei-Chin Pang", "Suraj Adhikari", "Takuma Kasahara", "Nagihiro Haba", "Saneyuki Ohno"], "title": "An Open-Access Benchmark of Statistical and Machine-Learning Anomaly Detection Methods for Battery Applications", "comment": null, "summary": "Battery safety is critical in applications ranging from consumer electronics\nto electric vehicles and aircraft, where undetected anomalies could trigger\nsafety hazards or costly downtime. In this study, we present OSBAD as an\nopen-source benchmark for anomaly detection frameworks in battery applications.\nBy benchmarking 15 diverse algorithms encompassing statistical, distance-based,\nand unsupervised machine-learning methods, OSBAD enables a systematic\ncomparison of anomaly detection methods across heterogeneous datasets. In\naddition, we demonstrate how a physics- and statistics-informed feature\ntransformation workflow enhances anomaly separability by decomposing collective\nanomalies into point anomalies. To address a major bottleneck in unsupervised\nanomaly detection due to incomplete labels, we propose a Bayesian optimization\npipeline that facilitates automated hyperparameter tuning based on\ntransfer-learning and regression proxies. Through validation on datasets\ncovering both liquid and solid-state chemistries, we further demonstrate the\ncross-chemistry generalization capability of OSBAD to identify irregularities\nacross different electrochemical systems. By making benchmarking database with\nopen-source reproducible anomaly detection workflows available to the\ncommunity, OSBAD establishes a unified foundation for developing safe,\nscalable, and transferable anomaly detection tools in battery analytics. This\nresearch underscores the significance of physics- and statistics-informed\nfeature engineering as well as model selection with probabilistic\nhyperparameter tuning, in advancing trustworthy, data-driven diagnostics for\nsafety-critical energy systems.", "AI": {"tldr": "OSBAD is an open-source battery anomaly detection benchmark enabling systematic cross-method comparison across 15 algorithms, with physics-/stats-informed feature engineering, Bayesian hyperparameter tuning, and cross-chemistry validation, all released as reproducible open-source workflows and datasets.", "motivation": "To create a unified, scalable, and transferable framework for safe, data-driven anomaly detection in safety-critical battery systems, addressing incomplete labels, heterogeneous datasets, and cross-chemistry generalization.", "method": "Develop OSBAD benchmark; benchmark 15 statistical, distance-based, and unsupervised ML methods across diverse datasets; introduce a physics- and statistics-informed feature transformation to decompose collective anomalies into point anomalies; implement a Bayesian optimization pipeline using transfer learning and regression proxies for automated hyperparameter tuning; validate on datasets spanning liquid and solid-state chemistries; release benchmarking database and reproducible workflows.", "result": "OSBAD enables systematic method comparison and demonstrates improved anomaly separability and cross-chemistry generalization; the open benchmark and workflows provide a foundation for developing safe, scalable anomaly detection tools in battery analytics.", "conclusion": "Physics-/statistics-informed feature engineering and probabilistic hyperparameter tuning are crucial for trustworthy, data-driven diagnostics in safety-critical energy systems, and OSBAD operationalizes this through an open, transferable benchmarking platform."}}
{"id": "2511.01704", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01704", "abs": "https://arxiv.org/abs/2511.01704", "authors": ["Xin Qiao", "Matteo Poggi", "Xing Wei", "Pengchao Deng", "Yanhui Zhou", "Stefano Mattoccia"], "title": "Learnable Fractional Reaction-Diffusion Dynamics for Under-Display ToF Imaging and Beyond", "comment": null, "summary": "Under-display ToF imaging aims to achieve accurate depth sensing through a\nToF camera placed beneath a screen panel. However, transparent OLED (TOLED)\nlayers introduce severe degradations-such as signal attenuation, multi-path\ninterference (MPI), and temporal noise-that significantly compromise depth\nquality. To alleviate this drawback, we propose Learnable Fractional\nReaction-Diffusion Dynamics (LFRD2), a hybrid framework that combines the\nexpressive power of neural networks with the interpretability of physical\nmodeling. Specifically, we implement a time-fractional reaction-diffusion\nmodule that enables iterative depth refinement with dynamically generated\ndifferential orders, capturing long-term dependencies. In addition, we\nintroduce an efficient continuous convolution operator via coefficient\nprediction and repeated differentiation to further improve restoration quality.\nExperiments on four benchmark datasets demonstrate the effectiveness of our\napproach. The code is publicly available at https://github.com/wudiqx106/LFRD2.", "AI": {"tldr": "Proposes Learnable Fractional Reaction-Diffusion Dynamics (LFRD2) for under-display ToF imaging, combining neural networks with fractional reaction-diffusion to restore depth maps degraded by TOLED layers; introduces a time-fractional RD module with dynamic differential orders and an efficient continuous convolution via coefficient prediction; validated on four datasets; code released.", "motivation": "TOLED layers cause signal attenuation, MPI, and temporal noise, degrading ToF depth quality; need interpretable physics-inspired restoration combined with learning to capture long-term dependencies.", "method": "Hybrid framework with time-fractional reaction-diffusion module for iterative depth refinement with dynamically generated differential orders; efficient continuous convolution via coefficient prediction and repeated differentiation; end-to-end training.", "result": "Demonstrates effectiveness on four benchmark datasets; improved depth restoration quality; code available.", "conclusion": "LFRD2 provides an effective, interpretable, and data-driven approach for under-display ToF depth restoration, achieving strong performance and offering code for reproducibility."}}
{"id": "2511.01758", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01758", "abs": "https://arxiv.org/abs/2511.01758", "authors": ["Mian Wu", "Gavin Zhang", "Sewon Min", "Sergey Levine", "Aviral Kumar"], "title": "RLAC: Reinforcement Learning with Adversarial Critic for Free-Form Generation Tasks", "comment": "Project page: https://mianwu01.github.io/RLAC_website/", "summary": "Open-ended generation tasks require outputs to satisfy diverse and often\nimplicit task-specific evaluation rubrics. The sheer number of relevant rubrics\nleads to prohibitively high verification costs and incomplete assessments of a\nresponse, making reinforcement learning (RL) post-training with rubric-based\nrewards difficult to scale. This problem is exacerbated by the fact that often\nthe best way to combine these rubrics into one single reward is also highly\nprompt-specific. We propose Reinforcement Learning with Adversarial Critic\n(RLAC), a post-training approach that addresses these challenges via dynamic\nrubric verification. Our approach employs a large language model (LLM) as a\ncritic that dynamically identifies only the most likely failure modes (e.g., a\nfactual error or unhandled edge case), which are then verified by an external\nvalidator to optimize both generator and critic jointly. By training both the\ngenerator and the critic, this game enhances the critic's error detection and\nthe generator's output quality while reducing required verifications. Our\nexperiments demonstrate that RLAC improves factual accuracy in text generation\nand correctness in code generation, while also outperforming exhaustive\nverification and reward model methods. We show that dynamic critics are more\neffective than fixed critics, showcasing the potential of RLAC for scaling RL\npost-training to free-form generation tasks.", "AI": {"tldr": "RLAC is a post-training RL framework that uses a dynamic LLM-based critic to identify the most likely failure modes in open-ended generation, with an external validator, jointly training generator and critic to improve quality while reducing verification effort.", "motivation": "Open-ended generation demands satisfying diverse, implicit rubrics; verifying every rubric is costly and combining rubrics into a single reward is prompt-specific. There is a need for scalable, selective verification of outputs.", "method": "A large language model acts as a dynamic critic to pinpoint the most probable failure modes (e.g., factual errors, edge cases). These failures are verified by an external validator. The generator and the critic are trained jointly, with dynamic critics outperforming fixed ones and reducing verification requirements.", "result": "RLAC improves factual accuracy in text generation and correctness in code generation and outperforms exhaustive verification and reward-model baselines. Dynamic critics are more effective than fixed critics.", "conclusion": "Dynamic adversarial critics enable scalable RL post-training for free-form generation tasks by focusing verification on the most likely failure modes, improving output quality while reducing verification costs."}}
{"id": "2511.01724", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01724", "abs": "https://arxiv.org/abs/2511.01724", "authors": ["Yi Zhang", "Zheng Wang", "Chen Zhen", "Wenjie Ruan", "Qing Guo", "Siddartha Khastgir", "Carsten Maple", "Xingyu Zhao"], "title": "Probabilistic Robustness for Free? Revisiting Training via a Benchmark", "comment": null, "summary": "Deep learning models are notoriously vulnerable to imperceptible\nperturbations. Most existing research centers on adversarial robustness (AR),\nwhich evaluates models under worst-case scenarios by examining the existence of\ndeterministic adversarial examples (AEs). In contrast, probabilistic robustness\n(PR) adopts a statistical perspective, measuring the probability that\npredictions remain correct under stochastic perturbations. While PR is widely\nregarded as a practical complement to AR, dedicated training methods for\nimproving PR are still relatively underexplored, albeit with emerging progress.\nAmong the few PR-targeted training methods, we identify three limitations: i\nnon-comparable evaluation protocols; ii limited comparisons to strong AT\nbaselines despite anecdotal PR gains from AT; and iii no unified framework to\ncompare the generalization of these methods. Thus, we introduce PRBench, the\nfirst benchmark dedicated to evaluating improvements in PR achieved by\ndifferent robustness training methods. PRBench empirically compares most common\nAT and PR-targeted training methods using a comprehensive set of metrics,\nincluding clean accuracy, PR and AR performance, training efficiency, and\ngeneralization error (GE). We also provide theoretical analysis on the GE of PR\nperformance across different training methods. Main findings revealed by\nPRBench include: AT methods are more versatile than PR-targeted training\nmethods in terms of improving both AR and PR performance across diverse\nhyperparameter settings, while PR-targeted training methods consistently yield\nlower GE and higher clean accuracy. A leaderboard comprising 222 trained models\nacross 7 datasets and 10 model architectures is publicly available at\nhttps://tmpspace.github.io/PRBenchLeaderboard/.", "AI": {"tldr": "PRBench is a benchmark for probabilistic robustness (PR) in deep learning that compares adversarial training (AT) and PR-targeted training across datasets and architectures. It finds AT generally improves both AR and PR, while PR-targeted methods achieve lower generalization error and higher clean accuracy. The benchmark covers 222 trained models, 7 datasets, and 10 architectures, with a theoretical GE analysis and a public leaderboard at the provided URL.", "motivation": "There is a lack of unified, comparable evaluation for probabilistic robustness and a clear framework to assess generalization across training methods. PR-focused training methods are underexplored and hard to compare to strong AT baselines.", "method": "Introduce PRBench, a comprehensive benchmark that evaluates AT and PR-targeted training methods using metrics such as clean accuracy, PR and AR performance, training efficiency, and generalization error (GE). Includes theoretical GE analysis and a public leaderboard (222 models across 7 datasets and 10 architectures).", "result": "The study finds that AT methods are more versatile in improving both AR and PR across varied hyperparameters, whereas PR-targeted methods consistently reduce GE and improve clean accuracy.", "conclusion": "PRBench is the first dedicated benchmark for probabilistic robustness training, enabling standardized evaluation and cross-method comparison. It reveals trade-offs: AT offers broader AR/PR improvements but PR-targeted methods achieve better generalization and clean accuracy, supported by a public leaderboard to track progress."}}
{"id": "2511.01794", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01794", "abs": "https://arxiv.org/abs/2511.01794", "authors": ["Vi Retault", "Yoha\u00ef-Eliel Berreby"], "title": "Random Initialization of Gated Sparse Adapters", "comment": "13 pages (8 main), 6 figures (4 main). Accepted by NewInML workshop @\n  ICML 2025 on June 27, 2025", "summary": "When fine-tuning language models on new tasks, catastrophic forgetting --\nperformance degradation on previously-learned tasks -- is a ubiquitous problem.\nWhile Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA address this\nthrough low-rank adapters, sparse adaptation offers an alternative that doesn't\nimpose rank constraints. We introduce Random Initialization of Gated Sparse\nAdapters (RIGSA), which starts from randomly-initialized full-rank adapters,\ngates them with a ReZero analog, and sparsifies them with iterative magnitude\npruning. We evaluate RIGSA on SmolLM2-1.7B-Instruct using a novel\nvision-in-text task (Textual MNIST) and measure forgetting on PIQA, HellaSwag,\nand GSM8k. SmolLM2-1.7B-Instruct initially performs around chance level on\nTextual MNIST, and is capable of learning the task through RIGSA, 4-bit QLoRA\nand random masking. In spite of having more trainable parameters than QLoRA,\nthe RIGSA configurations that we studied displayed less forgetting than QLoRA,\nparticularly on GSM8k, though it performs comparably to random masking.", "AI": {"tldr": "RIGSA introduces random-initialized full-rank adapters with gating and iterative magnitude pruning to reduce forgetting in PEFT. On SmolLM2-1.7B-Instruct, it enables learning Textual MNIST and shows less forgetting than QLoRA (notably on GSM8k), though it can resemble random masking in some settings.", "motivation": "Catastrophic forgetting during fine-tuning on new tasks remains a challenge. While PEFT methods like LoRA use low-rank adapters, sparse adaptation offers an alternative without rank constraints, potentially reducing forgetting.", "method": "Start from randomly-initialized full-rank adapters, gate them with a ReZero-like mechanism, sparsify via iterative magnitude pruning, and evaluate on SmolLM2-1.7B-Instruct with a novel Textual MNIST task. Compare against 4-bit QLoRA and random masking baselines and assess forgetting on PIQA, HellaSwag, and GSM8k.", "result": "Textual MNIST: the model begins near chance level but can learn the task with RIGSA, 4-bit QLoRA, and random masking. Across configurations, RIGSA exhibits less forgetting than QLoRA, especially on GSM8k, though performance is comparable to random masking. Notably, some RIGSA setups use more trainable parameters than QLoRA yet show reduced forgetting.", "conclusion": "RIGSA demonstrates that random-initialized full-rank adapters gated and sparsified can mitigate forgetting in PEFT and, in at least some tasks (e.g., GSM8k), outperform QLoRA in terms of forgetting. The approach remains competitive with random masking and highlights the viability of sparse, gated adaptation as an alternative to traditional low-rank methods."}}
{"id": "2511.01728", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01728", "abs": "https://arxiv.org/abs/2511.01728", "authors": ["Tom Odem"], "title": "Toward Strategy Identification and Subtask Decomposition In Task Exploration", "comment": null, "summary": "This research builds on work in anticipatory human-machine interaction, a\nsubfield of human-machine interaction where machines can facilitate\nadvantageous interactions by anticipating a user's future state. The aim of\nthis research is to further a machine's understanding of user knowledge, skill,\nand behavior in pursuit of implicit coordination. A task explorer pipeline was\ndeveloped that uses clustering techniques, paired with factor analysis and\nstring edit distance, to automatically identify key global and local strategies\nthat are used to complete tasks. Global strategies identify generalized sets of\nactions used to complete tasks, while local strategies identify sequences that\nused those sets of actions in a similar composition. Additionally, meaningful\nsubtasks of various lengths are identified within the tasks. The task explorer\npipeline was able to automatically identify key strategies used to complete\ntasks and encode user runs with hierarchical subtask structures. In addition, a\nTask Explorer application was developed to easily review pipeline results. The\ntask explorer pipeline can be easily modified to any action-based time-series\ndata and the identified strategies and subtasks help to inform humans and\nmachines on user knowledge, skill, and behavior.", "AI": {"tldr": "A pipeline that automatically identifies global and local task strategies and meaningful subtasks in anticipatory human-machine interaction, using clustering, factor analysis, and string edit distance, with a Task Explorer app; adaptable to action-based time-series data.", "motivation": "To improve machines' understanding of user knowledge, skill, and behavior to enable implicit coordination", "method": "Developed a Task Explorer pipeline combining clustering, factor analysis, and string edit distance to discover global strategies, local sequences, and subtasks; encoded runs with hierarchical subtask structures and built a reviewable Task Explorer application; adaptable to various action-based time-series data.", "result": "Automated identification of key task strategies and hierarchical subtasks; a review tool (Task Explorer); the pipeline is adaptable to other datasets and informs human-machine design about user knowledge, skill, and behavior.", "conclusion": "The pipeline provides a practical, adaptable framework for uncovering structured task knowledge to support anticipatory HMI through implicit coordination."}}
{"id": "2511.01730", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01730", "abs": "https://arxiv.org/abs/2511.01730", "authors": ["Yefeng Wu", "Yucheng Song", "Ling Wu", "Shan Wan", "Yecheng Zhao"], "title": "CGF-DETR: Cross-Gated Fusion DETR for Enhanced Pneumonia Detection in Chest X-rays", "comment": null, "summary": "Pneumonia remains a leading cause of morbidity and mortality worldwide,\nnecessitating accurate and efficient automated detection systems. While recent\ntransformer-based detectors like RT-DETR have shown promise in object detection\ntasks, their application to medical imaging, particularly pneumonia detection\nin chest X-rays, remains underexplored. This paper presents CGF-DETR, an\nenhanced real-time detection transformer specifically designed for pneumonia\ndetection. We introduce XFABlock in the backbone to improve multi-scale feature\nextraction through convolutional attention mechanisms integrated with CSP\narchitecture. To achieve efficient feature aggregation, we propose SPGA module\nthat replaces standard multi-head attention with dynamic gating mechanisms and\nsingle-head self-attention. Additionally, GCFC3 is designed for the neck to\nenhance feature representation through multi-path convolution fusion while\nmaintaining real-time performance via structural re-parameterization. Extensive\nexperiments on the RSNA Pneumonia Detection dataset demonstrate that CGF-DETR\nachieves 82.2\\% mAP@0.5, outperforming the baseline RT-DETR-l by 3.7\\% while\nmaintaining comparable inference speed at 48.1 FPS. Our ablation studies\nconfirm that each proposed module contributes meaningfully to the overall\nperformance improvement, with the complete model achieving 50.4\\%\nmAP@[0.5:0.95]", "AI": {"tldr": "CGF-DETR is a real-time pneumonia detector for chest X-rays that adds three modules to enhance feature extraction and efficient attention, achieving higher accuracy with minimal speed loss on RSNA data.", "motivation": "Pneumonia detection in chest X-rays is clinically important but challenging for real-time detectors. Transformer-based detectors lag in medical imaging due to computational demands; a real-time, accurate detector tailored for pneumonia is needed.", "method": "Introduce CGF-DETR with: XFABlock backbone for multi-scale feature extraction using convolutional attention within a CSP framework; SPGA module replacing standard multi-head attention with dynamic gating and single-head self-attention for efficiency; GCFC3 neck with multi-path convolution fusion and structural re-parameterization to preserve speed. Train and evaluate on RSNA Pneumonia Detection dataset; report mAP@0.5 and mAP@[0.5:0.95], plus FPS.", "result": "On RSNA Pneumonia Detection dataset, CGF-DETR achieves 82.2% mAP@0.5, beating the RT-DETR-l baseline by 3.7% while running at 48.1 FPS. Ablation studies show each proposed module contributes to performance gains, with the full model achieving 50.4% mAP@[0.5:0.95].", "conclusion": "CGF-DETR delivers improved pneumonia detection accuracy in chest X-rays with real-time capabilities. The XFABlock, SPGA, and GCFC3 components collectively enhance multi-scale feature extraction, efficient attention, and feature fusion, supporting practical deployment in clinical workflows."}}
{"id": "2511.01800", "categories": ["cs.LG", "I.2.6; H.3.3"], "pdf": "https://arxiv.org/pdf/2511.01800", "abs": "https://arxiv.org/abs/2511.01800", "authors": ["Prateek Chanda", "Shrey Modi", "Ganesh Ramakrishnan"], "title": "Bayesian Coreset Optimization for Personalized Federated Learning", "comment": "9 pages, 5 figures, ICLR 2024", "summary": "In a distributed machine learning setting like Federated Learning where there\nare multiple clients involved which update their individual weights to a single\ncentral server, often training on the entire individual client's dataset for\neach client becomes cumbersome. To address this issue we propose $\\methodprop$:\na personalized coreset weighted federated learning setup where the training\nupdates for each individual clients are forwarded to the central server based\non only individual client coreset based representative data points instead of\nthe entire client data. Through theoretical analysis we present how the average\ngeneralization error is minimax optimal up to logarithm bounds (upper bounded\nby $\\mathcal{O}(n_k^{-\\frac{2 \\beta}{2 \\beta+\\boldsymbol{\\Lambda}}} \\log ^{2\n\\delta^{\\prime}}(n_k))$) and lower bounds of $\\mathcal{O}(n_k^{-\\frac{2\n\\beta}{2 \\beta+\\boldsymbol{\\Lambda}}})$, and how the overall generalization\nerror on the data likelihood differs from a vanilla Federated Learning setup as\na closed form function ${\\boldsymbol{\\Im}}(\\boldsymbol{w}, n_k)$ of the coreset\nweights $\\boldsymbol{w}$ and coreset sample size $n_k$. Our experiments on\ndifferent benchmark datasets based on a variety of recent personalized\nfederated learning architectures show significant gains as compared to random\nsampling on the training data followed by federated learning, thereby\nindicating how intelligently selecting such training samples can help in\nperformance. Additionally, through experiments on medical datasets our proposed\nmethod showcases some gains as compared to other submodular optimization based\napproaches used for subset selection on client's data.", "AI": {"tldr": "A personalized coreset weighted federated learning (methodprop) selects and uses small, weighted per-client data coresets to update a central model, achieving near-minimax optimal generalization bounds and practical gains over random sampling and submodular subset methods.", "motivation": "Federated learning faces high communication costs and privacy restrictions; training on full client data is costly and may not generalize uniformly across clients. A per-client coreset approach aims to reduce data exchanged while preserving or improving generalization, enabling personalization.", "method": "For each client, construct a representative coreset with weights w and sample size n_k. Forward updates to the server using only these coreset points instead of entire client data. Theoretical analysis yields minimax-optimal generalization bounds (upper bound O(n_k^{-2\u03b2/(2\u03b2+\u039b)} log^{2\u03b4'}(n_k)) and lower bound O(n_k^{-2\u03b2/(2\u03b2+\u039b)})), and a closed-form generalization error function Im(w, n_k) dependent on coreset weights and size. Empirical evaluation across FL architectures and medical datasets compares against random sampling and submodular subset selection.", "result": "The proposed method achieves significant gains over random data sampling in diverse personalized FL architectures and datasets, and shows competitive improvements over submodular-based subset selection on client data, with the generalization error bounded as described and a clear dependence on coreset design via Im(w, n_k).", "conclusion": "Coreset-weighted personalization in federated learning is effective in reducing data sent and computation while maintaining or improving generalization; the approach provides theoretical guarantees and practical gains, though success hinges on appropriate coreset construction and tuning of n_k and w."}}
{"id": "2511.01804", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01804", "abs": "https://arxiv.org/abs/2511.01804", "authors": ["Viraj Patel", "Lisa Kreusser", "Katharine Fraser"], "title": "Dynamic Reconstruction of Ultrasound-Derived Flow Fields With Physics-Informed Neural Fields", "comment": "29 pages, 18 figures", "summary": "Blood flow is sensitive to disease and provides insight into cardiac\nfunction, making flow field analysis valuable for diagnosis. However, while\nsafer than radiation-based imaging and more suitable for patients with medical\nimplants, ultrasound suffers from attenuation with depth, limiting the quality\nof the image. Despite advances in echocardiographic particle image velocimetry\n(EchoPIV), accurately measuring blood velocity remains challenging due to the\ntechnique's limitations and the complexity of blood flow dynamics.\nPhysics-informed machine learning can enhance accuracy and robustness,\nparticularly in scenarios where noisy or incomplete data challenge purely\ndata-driven approaches. We present a physics-informed neural field model with\nmulti-scale Fourier Feature encoding for estimating blood flow from sparse and\nnoisy ultrasound data without requiring ground truth supervision. We\ndemonstrate that this model achieves consistently low mean squared error in\ndenoising and inpainting both synthetic and real datasets, verified against\nreference flow fields and ground truth flow rate measurements. While\nphysics-informed neural fields have been widely used to reconstruct medical\nimages, applications to medical flow reconstruction are mostly prominent in\nFlow MRI. In this work, we adapt methods that have proven effective in other\nimaging modalities to address the specific challenge of ultrasound-based flow\nreconstruction.", "AI": {"tldr": "A physics-informed neural field with multi-scale Fourier features estimates blood flow from sparse, noisy ultrasound data without ground-truth supervision, achieving low denoising/inpainting error and validating against reference flow fields and flow-rate measurements.", "motivation": "Ultrasound-based flow imaging is safer and implant-friendly but suffers from attenuation with depth and noisy, sparse data. EchoPIV is challenged by complex blood dynamics; a data-efficient, physics-informed approach could improve accuracy without requiring ground-truth labels.", "method": "A physics-informed neural field (PINN) model using multi-scale Fourier Feature encoding to reconstruct blood flow from sparse, noisy ultrasound data. The model does not require ground-truth supervision and is evaluated on synthetic and real datasets, with validation against reference flow fields and ground-truth flow-rate measurements. The approach adapts successful PINN concepts from other imaging modalities to ultrasound-based flow reconstruction.", "result": "The method achieves consistently low mean squared error in denoising and inpainting for both synthetic and real datasets, as verified against reference flow fields and ground-truth flow-rate measurements.", "conclusion": "Physics-informed neural fields can be effectively adapted for ultrasound-based medical flow reconstruction, offering robust flow estimation without ground-truth supervision and bridging approaches previously used mainly in Flow MRI to ultrasound imaging."}}
{"id": "2511.01756", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01756", "abs": "https://arxiv.org/abs/2511.01756", "authors": ["Kai Zhai", "Ziyan Huang", "Qiang Nie", "Xiang Li", "Bo Ouyang"], "title": "HGFreNet: Hop-hybrid GraphFomer for 3D Human Pose Estimation with Trajectory Consistency in Frequency Domain", "comment": null, "summary": "2D-to-3D human pose lifting is a fundamental challenge for 3D human pose\nestimation in monocular video, where graph convolutional networks (GCNs) and\nattention mechanisms have proven to be inherently suitable for encoding the\nspatial-temporal correlations of skeletal joints. However, depth ambiguity and\nerrors in 2D pose estimation lead to incoherence in the 3D trajectory. Previous\nstudies have attempted to restrict jitters in the time domain, for instance, by\nconstraining the differences between adjacent frames while neglecting the\nglobal spatial-temporal correlations of skeletal joint motion. To tackle this\nproblem, we design HGFreNet, a novel GraphFormer architecture with hop-hybrid\nfeature aggregation and 3D trajectory consistency in the frequency domain.\nSpecifically, we propose a hop-hybrid graph attention (HGA) module and a\nTransformer encoder to model global joint spatial-temporal correlations. The\nHGA module groups all $k$-hop neighbors of a skeletal joint into a hybrid group\nto enlarge the receptive field and applies the attention mechanism to discover\nthe latent correlations of these groups globally. We then exploit global\ntemporal correlations by constraining trajectory consistency in the frequency\ndomain. To provide 3D information for depth inference across frames and\nmaintain coherence over time, a preliminary network is applied to estimate the\n3D pose. Extensive experiments were conducted on two standard benchmark\ndatasets: Human3.6M and MPI-INF-3DHP. The results demonstrate that the proposed\nHGFreNet outperforms state-of-the-art (SOTA) methods in terms of positional\naccuracy and temporal consistency.", "AI": {"tldr": "HGFreNet introduces a GraphFormer with hop-hybrid attention and frequency-domain 3D trajectory consistency for robust 2D-to-3D pose lifting, improving temporal coherence and pose accuracy.", "motivation": "2D-to-3D pose lifting from monocular video suffers from depth ambiguity and 2D detection errors, causing incoherent 3D trajectories. Prior work focuses on frame-to-frame jitters and neglects global spatial-temporal correlations of skeletal motion.", "method": "Introduce HGFreNet with a hop-hybrid graph attention (HGA) module and a Transformer encoder to capture global spatial-temporal correlations. HGA groups k-hop neighbors into hybrid groups to enlarge the receptive field and uses attention to learn global group correlations. Additionally, enforce global temporal consistency by constraining trajectory in the frequency domain, preceded by a preliminary network that estimates 3D pose to provide depth cues across frames.", "result": "Empirical evaluation on Human3.6M and MPI-INF-3DHP shows HGFreNet achieves superior positional accuracy and temporal coherence compared to SOTA methods.", "conclusion": "The GraphFormer-based HGFreNet effectively models global spatial-temporal correlations and enforces 3D trajectory consistency in the frequency domain, yielding improved 2D-to-3D pose lifting on standard benchmarks."}}
{"id": "2511.01816", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.01816", "abs": "https://arxiv.org/abs/2511.01816", "authors": ["Maryam Bagherian"], "title": "No-rank Tensor Decomposition Using Metric Learning", "comment": null, "summary": "Tensor decomposition faces fundamental challenges in analyzing\nhigh-dimensional data, where traditional methods based on reconstruction and\nfixed-rank constraints often fail to capture semantically meaningful\nstructures. This paper introduces a no-rank tensor decomposition framework\ngrounded in metric learning, which replaces reconstruction objectives with a\ndiscriminative, similarity-based optimization. The proposed approach learns\ndata-driven embeddings by optimizing a triplet loss with diversity and\nuniformity regularization, creating a feature space where distance directly\nreflects semantic similarity. We provide theoretical guarantees for the\nframework's convergence and establish bounds on its metric properties.\nEvaluations across diverse domains --including face recognition (LFW,\nOlivetti), brain connectivity analysis (ABIDE), and simulated data (galaxy\nmorphology, crystal structures)-- demonstrate that our method outperforms\nbaseline techniques, including PCA, t-SNE, UMAP, and tensor decomposition\nbaselines (CP and Tucker). Results show substantial improvements in clustering\nmetrics (Silhouette Score, Davies--Bouldin Index, Calinski--Harabasz Index,\nSeparation Ratio, Adjusted Rand Index, Normalized Mutual Information) and\nreveal a fundamental trade-off: while metric learning optimizes global class\nseparation, it deliberately transforms local geometry to align with semantic\nrelationships. Crucially, our approach achieves superior performance with\nsmaller training datasets compared to transformer-based methods, offering an\nefficient alternative for domains with limited labeled data. This work\nestablishes metric learning as a paradigm for tensor-based analysis,\nprioritizing semantic relevance over pixel-level fidelity while providing\ncomputational advantages in data-scarce scenarios.", "AI": {"tldr": "No-rank tensor decomposition via metric learning with triplet loss and diversity/uniformity regularization; learns semantic embeddings without reconstruction; theoretical convergence and metric bounds; strong clustering improvements across faces, brain networks, and simulations, especially with limited data; outperforms PCA, t-SNE, UMAP, CP/Tucker and transformer baselines.", "motivation": "Traditional reconstruction-based, fixed-rank tensor decompositions often miss semantically meaningful structure in high-dimensional data and struggle under limited labeled data. A discriminative, metric-learning approach aims to align distances with semantic similarity and enable data-efficient analysis.", "method": "A no-rank tensor decomposition framework that optimizes a discriminative metric-learning objective using triplet loss augmented with diversity and uniformity regularization. Learns data-driven embeddings where geometric distance encodes semantic similarity; provides theoretical convergence guarantees and bounds on metric properties.", "result": "Empirical evaluations across diverse domains (face recognition on LFW and Olivetti, brain connectivity ABIDE, and simulated data on galaxy morphology and crystal structures) show substantial improvements in clustering metrics (Silhouette, Davies\u2013Bouldin, Calinski\u2013Harabasz, Separation Ratio, ARI, NMI) over baselines including PCA, t-SNE, UMAP, CP, and Tucker, with better performance in data-scarce settings.", "conclusion": "Metric learning is a viable paradigm for tensor analysis that emphasizes semantic relevance over pixel-level fidelity, offering computational advantages and strong performance with limited labeled data; introduces a fundamental trade-off between global class separation and local geometric preservation."}}
{"id": "2511.01767", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01767", "abs": "https://arxiv.org/abs/2511.01767", "authors": ["Yuxiao Yang", "Xiao-Xiao Long", "Zhiyang Dou", "Cheng Lin", "Yuan Liu", "Qingsong Yan", "Yuexin Ma", "Haoqian Wang", "Zhiqiang Wu", "Wei Yin"], "title": "Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image", "comment": "21 pages, 19 figures, accepted by TPAMI", "summary": "In this work, we introduce \\textbf{Wonder3D++}, a novel method for\nefficiently generating high-fidelity textured meshes from single-view images.\nRecent methods based on Score Distillation Sampling (SDS) have shown the\npotential to recover 3D geometry from 2D diffusion priors, but they typically\nsuffer from time-consuming per-shape optimization and inconsistent geometry. In\ncontrast, certain works directly produce 3D information via fast network\ninferences, but their results are often of low quality and lack geometric\ndetails. To holistically improve the quality, consistency, and efficiency of\nsingle-view reconstruction tasks, we propose a cross-domain diffusion model\nthat generates multi-view normal maps and the corresponding color images. To\nensure the consistency of generation, we employ a multi-view cross-domain\nattention mechanism that facilitates information exchange across views and\nmodalities. Lastly, we introduce a cascaded 3D mesh extraction algorithm that\ndrives high-quality surfaces from the multi-view 2D representations in only\nabout $3$ minute in a coarse-to-fine manner. Our extensive evaluations\ndemonstrate that our method achieves high-quality reconstruction results,\nrobust generalization, and good efficiency compared to prior works. Code\navailable at https://github.com/xxlong0/Wonder3D/tree/Wonder3D_Plus.", "AI": {"tldr": "Wonder3D++ introduces a cross-domain diffusion-based pipeline that outputs multi-view normal maps and colors, uses cross-view/domain attention, and a cascaded mesh extraction method to efficiently produce high-fidelity textured meshes from a single image, achieving fast ~3-minute mesh extraction with strong generalization.", "motivation": "Address the limitations of SDS-based single-view 3D reconstruction (slow optimization and inconsistent geometry) and of fast single-network methods (low quality and missing geometric detail) by combining diffusion priors with cross-domain, multi-view signals to improve quality, consistency, and efficiency.", "method": "1) A cross-domain diffusion model that generates multi-view normal maps and corresponding color images. 2) A multi-view cross-domain attention mechanism enabling information exchange across views and modalities. 3) A cascaded 3D mesh extraction algorithm that converts the multi-view 2D representations into high-quality surfaces in a coarse-to-fine process, taking about 3 minutes.", "result": "Extensive evaluations show high-quality reconstructions, robust generalization, and favorable efficiency compared with prior works. Code is available at the provided GitHub link.", "conclusion": "The approach advances single-view 3D reconstruction by jointly improving quality, consistency, and efficiency through cross-domain diffusion, cross-view attention, and cascaded mesh extraction, delivering practical, high-quality textured meshes from a single image."}}
{"id": "2511.01819", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01819", "abs": "https://arxiv.org/abs/2511.01819", "authors": ["Hamed Fard", "Mahsa Kholghi", "Benedikt Gro\u00df", "Gerhard Wunder"], "title": "Machine and Deep Learning for Indoor UWB Jammer Localization", "comment": "Accepted at the 20th International Conference on Risks and Security\n  of Internet and Systems (CRiSIS 2025, Gatineau-Canada,\n  https://crisis2025.uqo.ca/). The paper will soon be published as\n  post-proceedings in Springer's LNCS", "summary": "Ultra-wideband (UWB) localization delivers centimeter-scale accuracy but is\nvulnerable to jamming attacks, creating security risks for asset tracking and\nintrusion detection in smart buildings. Although machine learning (ML) and deep\nlearning (DL) methods have improved tag localization, localizing malicious\njammers within a single room and across changing indoor layouts remains largely\nunexplored. Two novel UWB datasets, collected under original and modified room\nconfigurations, are introduced to establish comprehensive ML/DL baselines.\nPerformance is rigorously evaluated using a variety of classification and\nregression metrics. On the source dataset with the collected UWB features,\nRandom Forest achieves the highest F1-macro score of 0.95 and XGBoost achieves\nthe lowest mean Euclidean error of 20.16 cm. However, deploying these\nsource-trained models in the modified room layout led to severe performance\ndegradation, with XGBoost's mean Euclidean error increasing tenfold to 207.99\ncm, demonstrating significant domain shift. To mitigate this degradation, a\ndomain-adversarial ConvNeXt autoencoder (A-CNT) is proposed that leverages a\ngradient-reversal layer to align CIR-derived features across domains. The A-CNT\nframework restores localization performance by reducing the mean Euclidean\nerror to 34.67 cm. This represents a 77 percent improvement over\nnon-adversarial transfer learning and an 83 percent improvement over the best\nbaseline, restoring the fraction of samples within 30 cm to 0.56. Overall, the\nresults demonstrate that adversarial feature alignment enables robust and\ntransferable indoor jammer localization despite environmental changes. Code and\ndataset available at https://github.com/afbf4c8996f/Jammer-Loc", "AI": {"tldr": "Adversarial domain adaptation improves transferable indoor jammer localization in UWB across room-layout changes.", "motivation": "UWB localization achieves centimeter accuracy but is vulnerable to jamming; localizing malicious jammers within a single room and across changing indoor layouts is challenging due to domain shift; need robust ML/DL methods and datasets to baseline performance.", "method": "Two novel UWB datasets (original and modified rooms) are used to establish ML/DL baselines. Evaluation uses classification and regression metrics. A domain-adversarial ConvNeXt autoencoder (A-CNT) with a gradient-reversal layer aligns CIR-derived features across domains and mitigates performance drop in the modified room.", "result": "On the source dataset, Random Forest achieves F1-macro 0.95; XGBoost achieves lowest mean Euclidean error (MAE) of 20.16 cm. In the modified room, MAE for XGBoost rises to 207.99 cm (domain shift). A-CNT reduces MAE to 34.67 cm (77% improvement over non-adversarial transfer and 83% over best baseline); fraction within 30 cm restored to 0.56.", "conclusion": "Adversarial feature alignment enables robust, transferable indoor jammer localization under environmental changes; dataset/code available at the provided GitHub link."}}
{"id": "2511.01768", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01768", "abs": "https://arxiv.org/abs/2511.01768", "authors": ["Zhe Liu", "Jinghua Hou", "Xiaoqing Ye", "Jingdong Wang", "Hengshuang Zhao", "Xiang Bai"], "title": "UniLION: Towards Unified Autonomous Driving Model with Linear Group RNNs", "comment": null, "summary": "Although transformers have demonstrated remarkable capabilities across\nvarious domains, their quadratic attention mechanisms introduce significant\ncomputational overhead when processing long-sequence data. In this paper, we\npresent a unified autonomous driving model, UniLION, which efficiently handles\nlarge-scale LiDAR point clouds, high-resolution multi-view images, and even\ntemporal sequences based on the linear group RNN operator (i.e., performs\nlinear RNN for grouped features). Remarkably, UniLION serves as a single\nversatile architecture that can seamlessly support multiple specialized\nvariants (i.e., LiDAR-only, temporal LiDAR, multi-modal, and multi-modal\ntemporal fusion configurations) without requiring explicit temporal or\nmulti-modal fusion modules. Moreover, UniLION consistently delivers competitive\nand even state-of-the-art performance across a wide range of core tasks,\nincluding 3D perception (e.g., 3D object detection, 3D object tracking, 3D\noccupancy prediction, BEV map segmentation), prediction (e.g., motion\nprediction), and planning (e.g., end-to-end planning). This unified paradigm\nnaturally simplifies the design of multi-modal and multi-task autonomous\ndriving systems while maintaining superior performance. Ultimately, we hope\nUniLION offers a fresh perspective on the development of 3D foundation models\nin autonomous driving. Code is available at\nhttps://github.com/happinesslz/UniLION", "AI": {"tldr": "UniLION is a unified linear-group RNN-based architecture for autonomous driving that efficiently handles large-scale LiDAR, high-resolution multi-view images, and temporal sequences with linear complexity, offering LiDAR-only, temporal LiDAR, multi-modal, and multi-modal-temporal variants and achieving competitive to state-of-the-art across 3D perception, motion prediction, and planning; code is released.", "motivation": "Transformers with quadratic attention are a bottleneck for long sequences and high-resolution multi-modal data in autonomous driving. There is a need for a scalable, unified model that can efficiently process diverse modalities and tasks without complicated fusion modules.", "method": "Introduce UniLION using a linear group RNN operator to perform linear RNNs on grouped features, enabling efficient processing of LiDAR points, multi-view images, and temporal data. The architecture supports multiple specialization variants (LiDAR-only, temporal LiDAR, multi-modal, and multi-modal temporal fusion) without explicit temporal or multi-modal fusion modules, and is evaluated across a suite of core tasks.", "result": "Demonstrates competitive and often state-of-the-art performance across core autonomous-driving tasks, including 3D perception (detection, tracking, occupancy, BEV segmentation), motion prediction, and end-to-end planning, with a unified architecture across variants.", "conclusion": "UniLION offers a fresh perspective on 3D foundation model design for autonomous driving by simplifying multi-modal and multi-task system construction without sacrificing performance, and provides a flexible, scalable path toward unified 3D foundation models; code is available at the provided repository."}}
{"id": "2511.01830", "categories": ["cs.LG", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.01830", "abs": "https://arxiv.org/abs/2511.01830", "authors": ["Paul Setinek", "Gianluca Galletti", "Johannes Brandstetter"], "title": "Towards Multi-Fidelity Scaling Laws of Neural Surrogates in CFD", "comment": null, "summary": "Scaling laws describe how model performance grows with data, parameters and\ncompute. While large datasets can usually be collected at relatively low cost\nin domains such as language or vision, scientific machine learning is often\nlimited by the high expense of generating training data through numerical\nsimulations. However, by adjusting modeling assumptions and approximations,\nsimulation fidelity can be traded for computational cost, an aspect absent in\nother domains. We investigate this trade-off between data fidelity and cost in\nneural surrogates using low- and high-fidelity Reynolds-Averaged Navier-Stokes\n(RANS) simulations. Reformulating classical scaling laws, we decompose the\ndataset axis into compute budget and dataset composition. Our experiments\nreveal compute-performance scaling behavior and exhibit budget-dependent\noptimal fidelity mixes for the given dataset configuration. These findings\nprovide the first study of empirical scaling laws for multi-fidelity neural\nsurrogate datasets and offer practical considerations for compute-efficient\ndataset generation in scientific machine learning.", "AI": {"tldr": "Empirical scaling laws for multi-fidelity neural surrogates show that, in scientific ML, optimal data fidelity mixes depend on the compute budget and dataset configuration; reformulating scaling laws to separate compute from dataset composition reveals compute-performance trade-offs and guides compute-efficient data generation.", "motivation": "Scientific ML faces high data-generation costs via simulations. Unlike language/vision, fidelity can be traded for compute. Understanding this trade-off is key to efficient dataset construction and model performance.", "method": "Reformulate classical scaling laws to decompose the dataset axis into compute budget and dataset composition. Conduct experiments with low- and high-fidelity RANS simulations to train neural surrogates on multi-fidelity data and analyze scaling across budget, fidelity mix, and dataset size.", "result": "Observed compute-performance scaling behavior and budget-dependent optimal fidelity mixes for given dataset configurations. This is the first empirical study of scaling laws for multi-fidelity neural surrogate datasets and offers guidance for compute-efficient dataset generation in scientific ML.", "conclusion": "Tailor the fidelity mix to the available compute and dataset configuration using the proposed scaling framework; results enable planning of data generation strategies and motivate further development of multi-fidelity surrogates and scaling analyses across domains."}}
{"id": "2511.01775", "categories": ["cs.CV", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.01775", "abs": "https://arxiv.org/abs/2511.01775", "authors": ["Zhen Chen", "Qing Xu", "Jinlin Wu", "Biao Yang", "Yuhao Zhai", "Geng Guo", "Jing Zhang", "Yinlu Ding", "Nassir Navab", "Jiebo Luo"], "title": "How Far Are Surgeons from Surgical World Models? A Pilot Study on Zero-shot Surgical Video Generation with Expert Assessment", "comment": null, "summary": "Foundation models in video generation are demonstrating remarkable\ncapabilities as potential world models for simulating the physical world.\nHowever, their application in high-stakes domains like surgery, which demand\ndeep, specialized causal knowledge rather than general physical rules, remains\na critical unexplored gap. To systematically address this challenge, we present\nSurgVeo, the first expert-curated benchmark for video generation model\nevaluation in surgery, and the Surgical Plausibility Pyramid (SPP), a novel,\nfour-tiered framework tailored to assess model outputs from basic appearance to\ncomplex surgical strategy. On the basis of the SurgVeo benchmark, we task the\nadvanced Veo-3 model with a zero-shot prediction task on surgical clips from\nlaparoscopic and neurosurgical procedures. A panel of four board-certified\nsurgeons evaluates the generated videos according to the SPP. Our results\nreveal a distinct \"plausibility gap\": while Veo-3 achieves exceptional Visual\nPerceptual Plausibility, it fails critically at higher levels of the SPP,\nincluding Instrument Operation Plausibility, Environment Feedback Plausibility,\nand Surgical Intent Plausibility. This work provides the first quantitative\nevidence of the chasm between visually convincing mimicry and causal\nunderstanding in surgical AI. Our findings from SurgVeo and the SPP establish a\ncrucial foundation and roadmap for developing future models capable of\nnavigating the complexities of specialized, real-world healthcare domains.", "AI": {"tldr": "Video-generation foundation models show high visual plausibility but lack surgical causal understanding; SurgVeo benchmark and the Surgical Plausibility Pyramid reveal a gap between appearance and higher-order surgical reasoning.", "motivation": "High-stakes medical domains require specialized causal knowledge beyond general physical rules; current evaluations emphasize visuals and realism, not clinical plausibility; a framework is needed to assess surgical video generation in terms of actionable, domain-specific understanding.", "method": "Introduce SurgVeo, the first expert-curated benchmark for evaluating surgical video generation; propose the Surgical Plausibility Pyramid (SPP) with four tiers; perform a zero-shot evaluation of Veo-3 on laparoscopic and neurosurgical clips; four board-certified surgeons rate outputs using the SPP.", "result": "Veo-3 achieves strong Visual Perceptual Plausibility but significantly underperforms at higher levels of the SPP\u2014Instrument Operation Plausibility, Environment Feedback Plausibility, and Surgical Intent Plausibility\u2014revealing a gap between visually convincing videos and actual causal, procedural understanding in surgery.", "conclusion": "SurgVeo and the SPP establish a foundational framework and roadmap for developing and evaluating future surgical video-generation models that must navigate specialized healthcare knowledge and real-world clinical reasoning."}}
{"id": "2511.01831", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01831", "abs": "https://arxiv.org/abs/2511.01831", "authors": ["Jay Mohta", "Kenan Emir Ak", "Dimitrios Dimitriadis", "Yan Xu", "Mingwei Shen"], "title": "Dynamic Routing Between Experts: A Data-Efficient Approach to Continual Learning in Vision-Language Models", "comment": null, "summary": "Vision-Language Models (VLMs) suffer from catastrophic forgetting when\nsequentially fine-tuned on new tasks, degrading performance on previously\nlearned foundational and task-specific capabilities. While multi-task learning\ncan mitigate forgetting, it requires simultaneous access to all datasets and\nimposes computational overhead that scales linearly with the number of tasks.\nIn this work, we introduce a routing-based approach that enables the\nintegration of new tasks while preserving the foundational knowledge acquired\nduring pretraining. We evaluate our method using InternVL-2 models (2B and 8B\nparameters) and demonstrate that routing preserves the model's foundational\ncapabilities by maintaining performance on general-purpose benchmarks such as\nChartQA, MMBench, and DocVQA, while simultaneously improving accuracy on\nspecialized tasks. Importantly, our approach achieves this without requiring\nconcurrent access to data from all tasks, avoiding the significant\ncomputational and data overhead associated with traditional multi-task\nlearning. We further conduct extensive ablation studies to evaluate the\nscalability and robustness of routing-based learning, showing that the approach\nis resilient to a growing number of tasks and performs particularly well when\nnew tasks are semantically related. Finally, we show that the routing mechanism\nenables superior cross-modal transfer between language and vision capabilities,\nallowing knowledge learned in one modality to enhance performance in another\ncapability not achieved by existing continual learning methods.", "AI": {"tldr": "Routing-based continual learning for Vision-Language Models preserves foundational abilities while adding new tasks without requiring simultaneous data access, improves specialized task accuracy, and enables cross-modal transfer; shows scalable behavior when tasks are semantically related.", "motivation": "Addresses catastrophic forgetting during sequential fine-tuning of vision-language models and the overhead of multi-task learning that requires access to all datasets and linear scaling with the number of tasks.", "method": "Introduces a routing-based learning mechanism that delegates new tasks to task-specific components while preserving the foundational knowledge from pretraining; evaluated on InternVL-2 models (2B and 8B params); demonstrates no need for concurrent data from all tasks and strong ablations on scalability and robustness.", "result": "Foundational capabilities remain intact as general-purpose benchmarks (ChartQA, MMBench, DocVQA) stay performant, while specialized tasks see improved accuracy; routing scales as the task count grows, is robust to more tasks, and benefits when new tasks are semantically related; enables superior cross-modal transfer between language and vision beyond existing continual-learning methods.", "conclusion": "Routing-based learning offers an effective and scalable solution for continual adaptation of Vision-Language Models, maintaining core capabilities, reducing data/computational overhead, and fostering cross-modal knowledge transfer."}}
{"id": "2511.01802", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01802", "abs": "https://arxiv.org/abs/2511.01802", "authors": ["Tejas Sarnaik", "Manan Shah", "Ravi Hegde"], "title": "PROPEX-RAG: Enhanced GraphRAG using Prompt-Driven Prompt Execution", "comment": "Accepted in PReMI 2025", "summary": "Retrieval-Augmented Generation (RAG) has become a robust framework for\nenhancing Large Language Models (LLMs) with external knowledge. Recent advances\nin RAG have investigated graph based retrieval for intricate reasoning;\nhowever, the influence of prompt design on enhancing the retrieval and\nreasoning process is still considerably under-examined. In this paper, we\npresent a prompt-driven GraphRAG framework that underscores the significance of\nprompt formulation in facilitating entity extraction, fact selection, and\npassage reranking for multi-hop question answering. Our approach creates a\nsymbolic knowledge graph from text data by encoding entities and factual\nrelationships as structured facts triples. We use LLMs selectively during\nonline retrieval to perform semantic filtering and answer generation. We also\nuse entity-guided graph traversal through Personalized PageRank (PPR) to\nsupport efficient, scalable retrieval based on the knowledge graph we built.\nOur system gets state-of-the-art performance on HotpotQA and 2WikiMultiHopQA,\nwith F1 scores of 80.7% and 78.9%, and Recall@5 scores of 97.1% and 98.1%,\nrespectively. These results show that prompt design is an important part of\nimproving retrieval accuracy and response quality. This research lays the\ngroundwork for more efficient and comprehensible multi-hop question-answering\nsystems, highlighting the importance of prompt-aware graph reasoning.", "AI": {"tldr": "Prompt-driven GraphRAG enhances RAG by using a symbolic knowledge graph and prompt-guided reasoning for entity extraction, fact selection, and passage reranking in multi-hop QA, achieving state-of-the-art results.", "motivation": "To address under-explored impact of prompt design on retrieval and reasoning in graph-based RAG for multi-hop QA.", "method": "Build a symbolic knowledge graph from text by encoding entities and relations as triples. Use prompt-driven prompts to guide entity extraction, fact selection, and passage reranking. Leverage LLMs selectively during online retrieval for semantic filtering and answer generation. Employ entity-guided graph traversal via Personalized PageRank (PPR) for efficient, scalable retrieval on the knowledge graph.", "result": "State-of-the-art on HotpotQA (F1 80.7%, Recall@5 97.1%) and 2WikiMultiHopQA (F1 78.9%, Recall@5 98.1%).", "conclusion": "Demonstrates that prompt design is crucial for improving retrieval accuracy and response quality, and lays groundwork for more efficient and interpretable prompt-aware graph-based multi-hop QA."}}
{"id": "2511.01836", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01836", "abs": "https://arxiv.org/abs/2511.01836", "authors": ["Ekdeep Singh Lubana", "Can Rager", "Sai Sumedh R. Hindupur", "Valerie Costa", "Greta Tuckute", "Oam Patel", "Sonia Krishna Murthy", "Thomas Fel", "Daniel Wurgaft", "Eric J. Bigelow", "Johnny Lin", "Demba Ba", "Martin Wattenberg", "Fernanda Viegas", "Melanie Weber", "Aaron Mueller"], "title": "Priors in Time: Missing Inductive Biases for Language Model Interpretability", "comment": "Preprint", "summary": "Recovering meaningful concepts from language model activations is a central\naim of interpretability. While existing feature extraction methods aim to\nidentify concepts that are independent directions, it is unclear if this\nassumption can capture the rich temporal structure of language. Specifically,\nvia a Bayesian lens, we demonstrate that Sparse Autoencoders (SAEs) impose\npriors that assume independence of concepts across time, implying stationarity.\nMeanwhile, language model representations exhibit rich temporal dynamics,\nincluding systematic growth in conceptual dimensionality, context-dependent\ncorrelations, and pronounced non-stationarity, in direct conflict with the\npriors of SAEs. Taking inspiration from computational neuroscience, we\nintroduce a new interpretability objective -- Temporal Feature Analysis --\nwhich possesses a temporal inductive bias to decompose representations at a\ngiven time into two parts: a predictable component, which can be inferred from\nthe context, and a residual component, which captures novel information\nunexplained by the context. Temporal Feature Analyzers correctly parse garden\npath sentences, identify event boundaries, and more broadly delineate abstract,\nslow-moving information from novel, fast-moving information, while existing\nSAEs show significant pitfalls in all the above tasks. Overall, our results\nunderscore the need for inductive biases that match the data in designing\nrobust interpretability tools.", "AI": {"tldr": "Temporal Feature Analysis (TFA) introduces a temporal inductive bias to interpret LM activations by decomposing representations into a context-predictable component and a residual for novel information, outperforming Sparse Autoencoders on temporal language tasks.", "motivation": "Existing feature extractors (e.g., Sparse Autoencoders) assume independence and stationarity, which clashes with language models that exhibit rich temporal dynamics (non-stationarity, increasing conceptual dimensionality, context-dependent correlations). This mismatch can hinder robust interpretability.", "method": "Propose Temporal Feature Analysis (TFA) inspired by computational neuroscience. At each time step, decompose the representation into a predictable component inferred from context and a residual component capturing novel information. Evaluate on tasks such as garden-path sentence parsing, event boundary detection, and separating slow-moving abstract information from fast-moving novel information; compare to SAEs.", "result": "TFA correctly parses garden-path sentences, identifies event boundaries, and differentiates slow-moving abstract information from fast-moving novel information, while SAEs show significant pitfalls across these tasks.", "conclusion": "Inductive biases that match the data distribution are crucial for robust interpretability tools; incorporating temporal structure via TFA provides a more faithful decomposition of language model activations than stationary, independent-direction methods like SAEs."}}
{"id": "2511.01817", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01817", "abs": "https://arxiv.org/abs/2511.01817", "authors": ["Sagi Eppel", "Alona Strugatski"], "title": "SciTextures: Collecting and Connecting Visual Patterns, Models, and Code Across Science and Art", "comment": null, "summary": "The ability to connect visual patterns with the processes that form them\nrepresents one of the deepest forms of visual understanding. Textures of clouds\nand waves, the growth of cities and forests, or the formation of materials and\nlandscapes are all examples of patterns emerging from underlying mechanisms. We\npresent the Scitextures dataset, a large-scale collection of textures and\nvisual patterns from all domains of science, tech, and art, along with the\nmodels and code that generate these images. Covering over 1,200 different\nmodels and 100,000 images of patterns and textures from physics, chemistry,\nbiology, sociology, technology, mathematics, and art, this dataset offers a way\nto explore the connection between the visual patterns that shape our world and\nthe mechanisms that produce them. Created by an agentic AI pipeline that\nautonomously collects and implements models in standardized form, we use\nSciTextures to evaluate the ability of leading AI models to link visual\npatterns to the models and code that generate them, and to identify different\npatterns that emerged from the same process. We also test AIs ability to infer\nand recreate the mechanisms behind visual patterns by providing a natural image\nof a real-world pattern and asking the AI to identify, model, and code the\nmechanism that formed the pattern, then run this code to generate a simulated\nimage that is compared to the real image. These benchmarks show that\nvision-language models (VLMs) can understand and simulate the physical system\nbeyond a visual pattern. The dataset and code are available at:\nhttps://zenodo.org/records/17485502", "AI": {"tldr": "A large-scale SciTextures dataset links visual textures to underlying generative mechanisms and benchmarks AI models on inferring and recreating those mechanisms.", "motivation": "To bridge perception and causal understanding by connecting textures and patterns to their generating processes across science, tech, and art.", "method": "An agentic AI pipeline autonomously collects and standardizes ~1,200 models and 100,000 images of textures from diverse domains; uses these to evaluate AI models on linking visuals to their mechanisms, and on inferring/recreating mechanisms from real-world images by generating simulations and comparing to originals.", "result": "Shows that vision-language models can understand and simulate physical systems beyond mere appearance; dataset and code are released for benchmarking.", "conclusion": "SciTextures provides a scalable benchmark that connects visual patterns with their mechanisms, enabling evaluation and advancement of AI systems that reason about physical processes."}}
{"id": "2511.01837", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01837", "abs": "https://arxiv.org/abs/2511.01837", "authors": ["Isabela Suaza-Sierra", "Hernan A. Moreno", "Luis A De la Fuente", "Thomas M. Neeson"], "title": "Interpretable Machine Learning for Reservoir Water Temperatures in the U.S. Red River Basin of the South", "comment": null, "summary": "Accurate prediction of Reservoir Water Temperature (RWT) is vital for\nsustainable water management, ecosystem health, and climate resilience. Yet,\nprediction alone offers limited insight into the governing physical processes.\nTo bridge this gap, we integrated explainable machine learning (ML) with\nsymbolic modeling to uncover the drivers of RWT dynamics across ten reservoirs\nin the Red River Basin, USA, using over 10,000 depth-resolved temperature\nprofiles. We first employed ensemble and neural models, including Random Forest\n(RF), Extreme Gradient Boosting (XGBoost), and Multilayer Perceptron (MLP),\nachieving high predictive skill (best RMSE = 1.20 degree Celsius, R^2 = 0.97).\nUsing SHAP (SHapley Additive exPlanations), we quantified the contribution of\nphysical drivers such as air temperature, depth, wind, and lake volume,\nrevealing consistent patterns across reservoirs. To translate these data-driven\ninsights into compact analytical expressions, we developed Kolmogorov Arnold\nNetworks (KANs) to symbolically approximate RWT. Ten progressively complex KAN\nequations were derived, improving from R^2 = 0.84 using a single predictor\n(7-day antecedent air temperature) to R^2 = 0.92 with ten predictors, though\ngains diminished beyond five, highlighting a balance between simplicity and\naccuracy. The resulting equations, dominated by linear and rational forms,\nincrementally captured nonlinear behavior while preserving interpretability.\nDepth consistently emerged as a secondary but critical predictor, whereas\nprecipitation had limited effect. By coupling predictive accuracy with\nexplanatory power, this framework demonstrates how KANs and explainable ML can\ntransform black-box models into transparent surrogates that advance both\nprediction and understanding of reservoir thermal dynamics.", "AI": {"tldr": "Integrates explainable ML with symbolic modeling (KANs) to predict reservoir water temperature across ten reservoirs, uncovering key drivers and providing compact, interpretable equations that balance accuracy and simplicity.", "motivation": "Fill the gap between prediction and understanding by identifying physical drivers of reservoir water temperature and providing interpretable models that support management and resilience.", "method": "Train ensemble/NN models (RF, XGBoost, MLP) for RWT prediction; use SHAP to quantify driver contributions; develop Kolmogorov Arnold Networks (KANs) to symbolically approximate RWT; derive 10 progressively complex equations; compare performance and interpretability across predictors.", "result": "Best predictive performance: RMSE = 1.20\u00b0C, R^2 = 0.97. SHAP identifies air temperature, depth, wind, and lake volume as key drivers with consistent reservoir patterns. KANs improve from R^2 = 0.84 with a single predictor (7-day air temperature) to R^2 = 0.92 with ten predictors, with diminishing gains beyond five predictors. Depth is a secondary but important predictor; precipitation has limited effect.", "conclusion": "Coupling explainable ML with symbolic surrogates (KANs) yields accurate, interpretable models for reservoir thermal dynamics, enabling understanding of governing processes and practical, compact equations for decision-making."}}
{"id": "2511.01833", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.01833", "abs": "https://arxiv.org/abs/2511.01833", "authors": ["Ming Li", "Jike Zhong", "Shitian Zhao", "Haoquan Zhang", "Shaoheng Lin", "Yuxiang Lai", "Wei Chen", "Konstantinos Psounis", "Kaipeng Zhang"], "title": "TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning", "comment": "Preprint", "summary": "The frontier of visual reasoning is shifting toward models like OpenAI o3,\nwhich can intelligently create and operate tools to transform images for\nproblem-solving, also known as thinking-\\textit{with}-images in\nchain-of-thought. Yet existing benchmarks fail to fully capture this advanced\ncapability. Even Visual Search, the most common benchmark for current\nthinking-\\textit{with}-images methods, tests only basic operations such as\nlocalization and cropping, offering little insight into more complex, dynamic,\nand tool-dependent reasoning. We introduce \\textbf{TIR-Bench}, a comprehensive\nbenchmark for evaluating agentic thinking-with-images across 13 diverse tasks,\neach requiring novel tool use for image processing and manipulation in\nchain-of-thought. We evaluate 22 multimodal large language models (MLLMs), from\nleading open-sourced and proprietary models to those with explicit tool-use\naugmentation. Results show that TIR-Bench is universally challenging, and\nstrong performance requires genuine thinking-with-images capabilities. Finally,\nwe present a pilot study comparing direct versus agentic fine-tuning.", "AI": {"tldr": "TIR-Bench is a new, comprehensive benchmark for agentic thinking-with-images across 13 tasks, evaluating 22 MLLMs on tool-use-enabled image reasoning; results show universal difficulty and highlight genuine thinking-with-images requirements; includes a pilot study on fine-tuning approaches.", "motivation": "Current Visual Search benchmarks fail to evaluate complex, dynamic, and tool-dependent reasoning required by thinking-with-images models; a robust benchmark is needed to measure agentic capabilities.", "method": "Introduce TIR-Bench with 13 tasks requiring novel image-processing tool use in chain-of-thought; evaluate 22 multimodal LLMs including open-source and proprietary models, some augmented with explicit tool-use; conduct a pilot study comparing direct versus agentic fine-tuning.", "result": "TIR-Bench proves universally challenging; strong performance demands genuine thinking-with-images capabilities; study quantifies gap across models; pilot fine-tuning results discussed.", "conclusion": "The benchmark reveals current models' limitations and underscores the value of tool-enabled, agentic reasoning; supports future development and evaluation of thinking-with-images systems."}}
{"id": "2511.01847", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.01847", "abs": "https://arxiv.org/abs/2511.01847", "authors": ["Zhi Wang", "Chicheng Zhang", "Ramya Korlakai Vinayak"], "title": "Bridging Lifelong and Multi-Task Representation Learning via Algorithm and Complexity Measure", "comment": null, "summary": "In lifelong learning, a learner faces a sequence of tasks with shared\nstructure and aims to identify and leverage it to accelerate learning. We study\nthe setting where such structure is captured by a common representation of\ndata. Unlike multi-task learning or learning-to-learn, where tasks are\navailable upfront to learn the representation, lifelong learning requires the\nlearner to make use of its existing knowledge while continually gathering\npartial information in an online fashion. In this paper, we consider a\ngeneralized framework of lifelong representation learning. We propose a simple\nalgorithm that uses multi-task empirical risk minimization as a subroutine and\nestablish a sample complexity bound based on a new notion we introduce--the\ntask-eluder dimension. Our result applies to a wide range of learning problems\ninvolving general function classes. As concrete examples, we instantiate our\nresult on classification and regression tasks under noise.", "AI": {"tldr": "Proposes lifelong representation learning with a task-eluder dimension, giving sample complexity bounds for online learning of shared representations via multi-task ERM, applicable to classification and regression under noise.", "motivation": "Address continual learning where tasks arrive sequentially; exploit a common data representation to accelerate learning and reduce forgetting.", "method": "Introduce generalized lifelong representation learning framework; algorithm uses multi-task empirical risk minimization as a subroutine; analyzes via a new metric task-eluder dimension; applies to general function classes.", "result": "Derives sample complexity bounds parameterized by task-eluder dimension; demonstrates applicability to classification and regression with noise.", "conclusion": "Extends lifelong learning theory to representation learning with a unifying task-eluder concept; broad applicability and potential for empirical validation; future work could explore tighter bounds and practical algorithms."}}
{"id": "2511.01855", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01855", "abs": "https://arxiv.org/abs/2511.01855", "authors": ["Bettina Hanlon", "Angel Garcia Fernandez"], "title": "Coordinate ascent neural Kalman-MLE for state estimation", "comment": null, "summary": "This paper presents a coordinate ascent algorithm to learn dynamic and\nmeasurement models in dynamic state estimation using maximum likelihood\nestimation in a supervised manner. In particular, the dynamic and measurement\nmodels are assumed to be Gaussian and the algorithm learns the neural network\nparameters that model the dynamic and measurement functions, and also the noise\ncovariance matrices. The trained dynamic and measurement models are then used\nwith a non-linear Kalman filter algorithm to estimate the state during the\ntesting phase.", "AI": {"tldr": "Learn dynamic and measurement models for state estimation via a coordinate ascent ML approach under Gaussian assumptions, training neural networks for dynamics and measurements and their noise covariances, then apply a nonlinear Kalman filter for testing-state estimation.", "motivation": "Improve dynamic state estimation by jointly learning flexible, nonlinear models for dynamics and measurements and their uncertainties, enabling more accurate sequential inference in uncertain environments.", "method": "Coordinate ascent to maximize likelihood with Gaussian dynamic and measurement models. Train neural networks to parameterize the dynamic function f and measurement function h, and learn associated noise covariance matrices Q and R. Use trained models within a nonlinear Kalman filter for state estimation during testing.", "result": "The abstract indicates that learned models are used with a nonlinear Kalman filter for state estimation during testing; specific empirical results are not provided in the abstract.", "conclusion": "Not explicitly stated in the abstract. Likely suggests that jointly learned models enable effective nonlinear state estimation, but empirical conclusions are not reported here."}}
