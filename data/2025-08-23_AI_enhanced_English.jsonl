{"id": "2508.15520", "categories": ["cs.CG", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2508.15520", "abs": "https://arxiv.org/abs/2508.15520", "authors": ["Oswin Aichholzer", "Joseph Dorfer", "Birgit Vogtenhuber"], "title": "Constrained Flips in Plane Spanning Trees", "comment": "To appear at GD25", "summary": "A flip in a plane spanning tree $T$ is the operation of removing one edge\nfrom $T$ and adding another edge such that the resulting structure is again a\nplane spanning tree. For trees on a set of points in convex position we study\ntwo classic types of constrained flips: (1)~Compatible flips are flips in which\nthe removed and inserted edge do not cross each other. We relevantly improve\nthe previous upper bound of $2n-O(\\sqrt{n})$ on the diameter of the compatible\nflip graph to~$\\frac{5n}{3}-O(1)$, by this matching the upper bound for\nunrestricted flips by Bjerkevik, Kleist, Ueckerdt, and Vogtenhuber [SODA~2025]\nup to an additive constant of $1$. We further show that no shortest compatible\nflip sequence removes an edge that is already in its target position. Using\nthis so-called happy edge property, we derive a fixed-parameter tractable\nalgorithm to compute the shortest compatible flip sequence between two given\ntrees. (2)~Rotations are flips in which the removed and inserted edge share a\ncommon vertex. Besides showing that the happy edge property does not hold for\nrotations, we improve the previous upper bound of $2n-O(1)$ for the diameter of\nthe rotation graph to~$\\frac{7n}{4}-O(1)$.", "AI": {"tldr": "Two constrained flip types on plane spanning trees of convex point sets are analyzed: compatible flips (non-crossing edges) and rotations (edges share a vertex). The study tightens diameter bounds for both flip graphs, proves a happy-edge property for compatible flips enabling an FPT algorithm to compute shortest sequences, and shows this property fails for rotations.", "motivation": "To understand the reconfiguration landscape of plane spanning trees under constrained flips, close gaps with unrestricted flip results, and derive algorithmic consequences for transforming trees.", "method": "Combinatorial analysis of flip sequences on convex point sets; definition and exploitation of the happy-edge property for compatible flips; derivation of improved diameter bounds; development of a fixed-parameter tractable algorithm for the shortest compatible flip sequence; contrast with rotations by showing the happy-edge property does not hold; comparison to the unrestricted-flips bound from SODA 2025.", "result": "Compatible flips: diameter bound improved to 5n/3 - O(1); shortest compatible flip sequence never removes a correctly placed edge (happy-edge property) enabling an FPT algorithm to compute it. Rotations: diameter bound improved to 7n/4 - O(1); the happy-edge property does not hold.", "conclusion": "The paper delivers tighter diameter bounds for both flip types on convex-point sets, establishes a useful happy-edge property and an FPT method for compatible flips, and reveals a fundamental difference between compatible flips and rotations by showing the property fails for rotations."}}
{"id": "2508.15557", "categories": ["cs.CG"], "pdf": "https://arxiv.org/pdf/2508.15557", "abs": "https://arxiv.org/abs/2508.15557", "authors": ["Simon van Wageningen", "Tamara Mchedlidze", "Alexandru C. Telea"], "title": "Same Quality Metrics, Different Graph Drawings", "comment": "Short paper accepted at the International Graph Drawing Conference of\n  2025", "summary": "Graph drawings are commonly used to visualize relational data. User\nunderstanding and performance are linked to the quality of such drawings, which\nis measured by quality metrics. The tacit knowledge in the graph drawing\ncommunity about these quality metrics is that they are not always able to\naccurately capture the quality of graph drawings. In particular, such metrics\nmay rate drawings with very poor quality as very good. In this work we make\nthis tacit knowledge explicit by showing that we can modify existing graph\ndrawings into arbitrary target shapes while keeping one or more quality metrics\nalmost identical. This supports the claim that more advanced quality metrics\nare needed to capture the 'goodness' of a graph drawing and that we cannot\nconfidently rely on the value of a single (or several) certain quality metrics.", "AI": {"tldr": "Existing quality metrics for graph drawings can be manipulated: a drawing can be transformed into arbitrary shapes while keeping metrics almost unchanged. This reveals that current metrics may not accurately reflect drawing quality and that relying on single or few metrics is fragile; more advanced metrics are needed.", "motivation": "To address the gap between commonly used quality metrics for graph drawings and the actual perceived quality, showing that current metrics can be gamed and may fail to capture true goodness.", "method": "The authors construct or demonstrate a process that transforms existing graph drawings into arbitrary target shapes while keeping one or more quality metrics nearly identical, thereby exposing the fragility of these metrics.", "result": "Quality metrics can be preserved under substantial shape changes, including drastic deformations, which implies they may misjudge poor-quality drawings as good.", "conclusion": "There is a need for more robust, perhaps multi-faceted quality metrics for graph drawings, as relying on a handful of standard metrics is insufficient to guarantee drawing quality."}}
{"id": "2508.14994", "categories": ["cs.RO", "cs.CV", "cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.14994", "abs": "https://arxiv.org/abs/2508.14994", "authors": ["Murilo Vinicius da Silva", "Matheus Hipolito Carvalho", "Juliano Negri", "Thiago Segreto", "Gustavo J. G. Lahr", "Ricardo V. Godoy", "Marcelo Becker"], "title": "A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot", "comment": null, "summary": "In hazardous and remote environments, robotic systems perform critical tasks\ndemanding improved safety and efficiency. Among these, quadruped robots with\nmanipulator arms offer mobility and versatility for complex operations.\nHowever, teleoperating quadruped robots is challenging due to the lack of\nintegrated obstacle detection and intuitive control methods for the robotic\narm, increasing collision risks in confined or dynamically changing workspaces.\nTeleoperation via joysticks or pads can be non-intuitive and demands a high\nlevel of expertise due to its complexity, culminating in a high cognitive load\non the operator. To address this challenge, a teleoperation approach that\ndirectly maps human arm movements to the robotic manipulator offers a simpler\nand more accessible solution. This work proposes an intuitive remote control by\nleveraging a vision-based pose estimation pipeline that utilizes an external\ncamera with a machine learning-based model to detect the operator's wrist\nposition. The system maps these wrist movements into robotic arm commands to\ncontrol the robot's arm in real-time. A trajectory planner ensures safe\nteleoperation by detecting and preventing collisions with both obstacles and\nthe robotic arm itself. The system was validated on the real robot,\ndemonstrating robust performance in real-time control. This teleoperation\napproach provides a cost-effective solution for industrial applications where\nsafety, precision, and ease of use are paramount, ensuring reliable and\nintuitive robotic control in high-risk environments.", "AI": {"tldr": "A wrist-based, vision-driven teleoperation system maps human arm movements to a quadruped robot's manipulator with a collision-aware planner, validated in real-time on hardware.", "motivation": "In hazardous remote settings, traditional teleoperation (e.g., joysticks) is non-intuitive, cognitively demanding, and prone to collisions. An intuitive, safe, real-time control method that integrates obstacle avoidance is needed for quadruped robots with arms in industrial, high-risk environments.", "method": "Use an external camera and a machine-learning pose-estimation model to detect the operator's wrist position. Map wrist trajectories to commands for the robot's manipulator in real time. Employ a trajectory planner to detect and prevent collisions with environmental obstacles and the manipulator itself. Validate the system on a real robot to demonstrate real-time, robust performance.", "result": "The approach achieved robust real-time control and reliable teleoperation on hardware, with effective obstacle and self-collision avoidance demonstrated in real-world tests.", "conclusion": "The proposed wrist-based vision teleoperation offers an intuitive, safer, and cost-effective solution for controlling quadruped robots with arms in industrial settings, with potential for broader deployment and extension to more complex manipulation tasks."}}
{"id": "2508.14926", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14926", "abs": "https://arxiv.org/abs/2508.14926", "authors": ["Dianzhao Li", "Ostap Okhrin"], "title": "Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving", "comment": null, "summary": "Autonomous vehicles hold great promise for reducing traffic fatalities and\nimproving transportation efficiency, yet their widespread adoption hinges on\nembedding robust ethical reasoning into routine and emergency maneuvers. Here,\nwe present a hierarchical Safe Reinforcement Learning (Safe RL) framework that\nexplicitly integrates moral considerations with standard driving objectives. At\nthe decision level, a Safe RL agent is trained using a composite ethical risk\ncost, combining collision probability and harm severity, to generate high-level\nmotion targets. A dynamic Prioritized Experience Replay mechanism amplifies\nlearning from rare but critical, high-risk events. At the execution level,\npolynomial path planning coupled with Proportional-Integral-Derivative (PID)\nand Stanley controllers translates these targets into smooth, feasible\ntrajectories, ensuring both accuracy and comfort. We train and validate our\napproach on rich, real-world traffic datasets encompassing diverse vehicles,\ncyclists, and pedestrians, and demonstrate that it outperforms baseline methods\nin reducing ethical risk and maintaining driving performance. To our knowledge,\nthis is the first study of ethical decision-making for autonomous vehicles via\nSafe RL in real-world scenarios. Our results highlight the potential of\ncombining formal control theory and data-driven learning to advance ethically\naccountable autonomy in complex, human-mixed traffic environments.", "AI": {"tldr": "A hierarchical Safe RL framework for autonomous driving that optimizes ethical risk (collision probability and harm severity) at decision level with dynamic prioritized replay, and uses polynomial planning with PID/Stanley at execution level to yield smooth trajectories. Validated on real-world traffic data, it outperforms baselines in reducing ethical risk while preserving driving performance; claims novelty in real-world ethical decision-making via Safe RL.", "motivation": "To embed robust ethical reasoning into autonomous driving, balancing safety and efficiency, especially for rare high-risk events and in mixed-traffic environments with pedestrians and cyclists.", "method": "Decision level: Safe RL agent trained with a composite ethical risk cost (collision probability + harm severity) to generate high-level motion targets. Learning enhancement: dynamic Prioritized Experience Replay emphasizes rare, high-risk events. Execution level: polynomial path planning plus PID and Stanley controllers to convert targets into smooth, feasible trajectories.", "result": "The approach outperforms baseline methods in reducing ethical risk while maintaining driving performance on real-world traffic datasets containing diverse actors (vehicles, cyclists, pedestrians). It is presented as the first real-world Safe RL study for ethical decision-making in autonomous driving.", "conclusion": "Combining formal control theory with data-driven Safe RL can advance ethically accountable autonomy in complex, human-mixed traffic environments."}}
{"id": "2508.14929", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14929", "abs": "https://arxiv.org/abs/2508.14929", "authors": ["Chiao-An Yang", "Raymond A. Yeh"], "title": "Heatmap Regression without Soft-Argmax for Facial Landmark Detection", "comment": null, "summary": "Facial landmark detection is an important task in computer vision with\nnumerous applications, such as head pose estimation, expression analysis, face\nswapping, etc. Heatmap regression-based methods have been widely used to\nachieve state-of-the-art results in this task. These methods involve computing\nthe argmax over the heatmaps to predict a landmark. Since argmax is not\ndifferentiable, these methods use a differentiable approximation, Soft-argmax,\nto enable end-to-end training on deep-nets. In this work, we revisit this\nlong-standing choice of using Soft-argmax and demonstrate that it is not the\nonly way to achieve strong performance. Instead, we propose an alternative\ntraining objective based on the classic structured prediction framework.\nEmpirically, our method achieves state-of-the-art performance on three facial\nlandmark benchmarks (WFLW, COFW, and 300W), converging 2.2x faster during\ntraining while maintaining better/competitive accuracy. Our code is available\nhere: https://github.com/ca-joe-yang/regression-without-softarg.", "AI": {"tldr": "Revisits heatmap-based facial landmark regression by replacing Soft-argmax with a structured prediction training objective; shows state-of-the-art results on WFLW, COFW, 300W and 2.2x faster training.", "motivation": "Soft-argmax is a common differentiable proxy for predicting landmark coordinates from heatmaps, but it may not be the best or only viable approach. The paper argues for a structured prediction framework to directly optimize landmark configurations, aiming for better training efficiency and potentially higher accuracy.", "method": "Introduce a structured prediction objective for heatmap-based facial landmark detection that replaces the standard Soft-argmax training path. The objective aligns predictions with global facial structure via a structured loss, rather than relying on a differentiable argmax proxy.", "result": "Achieves state-of-the-art performance on WFLW, COFW, and 300W benchmarks. Training converges roughly 2.2x faster while maintaining or improving accuracy. Code is released for replication.", "conclusion": "Soft-argmax is not the sole viable route for heatmap-based landmark regression. A classic structured prediction objective can yield superior training efficiency and competitive accuracy, reinforcing the viability of non-Soft-argmax training in this domain."}}
{"id": "2508.14923", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.14923", "abs": "https://arxiv.org/abs/2508.14923", "authors": ["Andrew Kiruluta"], "title": "A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone", "comment": null, "summary": "We propose a fully spectral, neuro\\-symbolic reasoning architecture that\nleverages Graph Signal Processing (GSP) as the primary computational backbone\nfor integrating symbolic logic and neural inference. Unlike conventional\nreasoning models that treat spectral graph methods as peripheral components,\nour approach formulates the entire reasoning pipeline in the graph spectral\ndomain. Logical entities and relationships are encoded as graph signals,\nprocessed via learnable spectral filters that control multi-scale information\npropagation, and mapped into symbolic predicates for rule-based inference. We\npresent a complete mathematical framework for spectral reasoning, including\ngraph Fourier transforms, band-selective attention, and spectral rule\ngrounding. Experiments on benchmark reasoning datasets (ProofWriter,\nEntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in\nlogical consistency, interpretability, and computational efficiency over\nstate\\-of\\-the\\-art neuro\\-symbolic models. Our results suggest that GSP\nprovides a mathematically grounded and computationally efficient substrate for\nrobust and interpretable reasoning systems.", "AI": {"tldr": "A fully spectral neuro-symbolic reasoning framework using Graph Signal Processing as the backbone for end-to-end reasoning, achieving improvements on standard benchmarks.", "motivation": "To unify logical reasoning with neural inference under a mathematically grounded spectral framework, addressing interpretability and efficiency in neuro-symbolic reasoning.", "method": "Encode entities and relations as graph signals and perform reasoning entirely in the spectral domain using graph Fourier transforms, band-selective attention, and spectral rule grounding; learn spectral filters to control multi-scale information propagation; map spectral representations to symbolic predicates for rule-based inference.", "result": "Outperforms state-of-the-art neuro-symbolic models on reasoning benchmarks (ProofWriter, EntailmentBank, bAbI, CLUTRR, ARC-Challenge) in logical consistency, interpretability, and computational efficiency.", "conclusion": "Graph Signal Processing provides a principled, scalable substrate for robust and interpretable reasoning systems; the spectral approach yields effective and efficient neuro-symbolic reasoning."}}
{"id": "2508.15002", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15002", "abs": "https://arxiv.org/abs/2508.15002", "authors": ["Ren\u00e9 Zurbr\u00fcgg", "Andrei Cramariuc", "Marco Hutter"], "title": "GraspQP: Differentiable Optimization of Force Closure for Diverse and Robust Dexterous Grasping", "comment": null, "summary": "Dexterous robotic hands enable versatile interactions due to the flexibility\nand adaptability of multi-fingered designs, allowing for a wide range of\ntask-specific grasp configurations in diverse environments. However, to fully\nexploit the capabilities of dexterous hands, access to diverse and high-quality\ngrasp data is essential -- whether for developing grasp prediction models from\npoint clouds, training manipulation policies, or supporting high-level task\nplanning with broader action options. Existing approaches for dataset\ngeneration typically rely on sampling-based algorithms or simplified\nforce-closure analysis, which tend to converge to power grasps and often\nexhibit limited diversity. In this work, we propose a method to synthesize\nlarge-scale, diverse, and physically feasible grasps that extend beyond simple\npower grasps to include refined manipulations, such as pinches and tri-finger\nprecision grasps. We introduce a rigorous, differentiable energy formulation of\nforce closure, implicitly defined through a Quadratic Program (QP).\nAdditionally, we present an adjusted optimization method (MALA*) that improves\nperformance by dynamically rejecting gradient steps based on the distribution\nof energy values across all samples. We extensively evaluate our approach and\ndemonstrate significant improvements in both grasp diversity and the stability\nof final grasp predictions. Finally, we provide a new, large-scale grasp\ndataset for 5,700 objects from DexGraspNet, comprising five different grippers\nand three distinct grasp types.\n  Dataset and Code:https://graspqp.github.io/", "AI": {"tldr": "Proposes a differentiable, energy-based force-closure formulation via a QP and an MALA*-like optimization to synthesize diverse, physically feasible grasps beyond power grasps, producing a large-scale dataset (DexGraspNet-based) for 5,700 objects across 5 grippers and 3 grasp types; improves grasp diversity and stability.", "motivation": "There is a need for large-scale, high-quality grasp data to train grasp prediction from point clouds, manipulation policies, and task planning. Existing dataset generation methods tend to converge on power grasps and lack diversity, limiting learning and robustness.", "method": "Develop a rigorous differentiable energy formulation of force closure defined via a Quadratic Program (QP). Introduce an adjusted optimization method (MALA*) that dynamically rejects gradient steps based on energy distribution across samples to improve convergence and diversity. Use this pipeline to synthesize large-scale grasps across five grippers and three grasp types, yielding a new dataset for 5,700 objects from DexGraspNet.", "result": "The approach yields significantly improved grasp diversity and stability of final grasp predictions. It enables a large-scale grasp dataset spanning multiple grippers and grasp types for many objects, demonstrated on 5,700 DexGraspNet objects with five grippers and three grasp types.", "conclusion": "This method advances dexterous-hand data generation by enabling physically feasible, diverse grasps beyond power grasps and provides a ready-to-use dataset and code to facilitate research in prediction, manipulation policy learning, and planning with richer action options."}}
{"id": "2508.14940", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14940", "abs": "https://arxiv.org/abs/2508.14940", "authors": ["Chongyu Qu", "Allen J. Luna", "Thomas Z. Li", "Junchao Zhu", "Junlin Guo", "Juming Xiong", "Kim L. Sandler", "Bennett A. Landman", "Yuankai Huo"], "title": "Cohort-Aware Agents for Individualized Lung Cancer Risk Prediction Using a Retrieval-Augmented Model Selection Framework", "comment": null, "summary": "Accurate lung cancer risk prediction remains challenging due to substantial\nvariability across patient populations and clinical settings -- no single model\nperforms best for all cohorts. To address this, we propose a personalized lung\ncancer risk prediction agent that dynamically selects the most appropriate\nmodel for each patient by combining cohort-specific knowledge with modern\nretrieval and reasoning techniques. Given a patient's CT scan and structured\nmetadata -- including demographic, clinical, and nodule-level features -- the\nagent first performs cohort retrieval using FAISS-based similarity search\nacross nine diverse real-world cohorts to identify the most relevant patient\npopulation from a multi-institutional database. Second, a Large Language Model\n(LLM) is prompted with the retrieved cohort and its associated performance\nmetrics to recommend the optimal prediction algorithm from a pool of eight\nrepresentative models, including classical linear risk models (e.g., Mayo,\nBrock), temporally-aware models (e.g., TDVIT, DLSTM), and multi-modal computer\nvision-based approaches (e.g., Liao, Sybil, DLS, DLI). This two-stage agent\npipeline -- retrieval via FAISS and reasoning via LLM -- enables dynamic,\ncohort-aware risk prediction personalized to each patient's profile. Building\non this architecture, the agent supports flexible and cohort-driven model\nselection across diverse clinical populations, offering a practical path toward\nindividualized risk assessment in real-world lung cancer screening.", "AI": {"tldr": "A two-stage retrieval-and-reasoning agent dynamically selects the best lung cancer risk model for each patient by retrieving the most relevant cohort via FAISS and asking an LLM to pick among eight models, enabling cohort-aware personalized prediction across nine real-world cohorts.", "motivation": "To tackle substantial cross-cohort variability in model performance and the lack of a single best model, the work aims to tailor risk prediction to the individual patient by leveraging cohort knowledge and modern AI tools.", "method": "Stage 1: FAISS-based cohort retrieval across nine diverse cohorts using patient CT and structured metadata. Stage 2: An LLM is prompted with the retrieved cohort and its performance metrics to recommend the optimal algorithm from eight models (Mayo, Brock, TDVIT, DLSTM, Liao, Sybil, DLS, DLI). The pipeline combines retrieval with reasoning to select a model per patient.", "result": "The abstract presents a conceptual framework with no reported quantitative results; it claims dynamic, cohort-aware model selection and practical path toward individualized risk assessment.", "conclusion": "The proposed agent enables flexible, cohort-driven model selection for real-world, personalized lung cancer risk prediction, potentially improving accuracy across diverse clinical populations."}}
{"id": "2508.14958", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14958", "abs": "https://arxiv.org/abs/2508.14958", "authors": ["Mustafa Mohammadi Gharasuie", "Luis Rueda"], "title": "Fast Graph Neural Network for Image Classification", "comment": "12 pages, proceeding into CanadianAI 2025", "summary": "The rapid progress in image classification has been largely driven by the\nadoption of Graph Convolutional Networks (GCNs), which offer a robust framework\nfor handling complex data structures. This study introduces a novel approach\nthat integrates GCNs with Voronoi diagrams to enhance image classification by\nleveraging their ability to effectively model relational data. Unlike\nconventional convolutional neural networks (CNNs), our method represents images\nas graphs, where pixels or regions function as vertices. These graphs are then\nrefined using corresponding Delaunay triangulations, optimizing their\nrepresentation. The proposed model achieves significant improvements in both\npreprocessing efficiency and classification accuracy across various benchmark\ndatasets, surpassing state-of-the-art approaches, particularly in challenging\nscenarios involving intricate scenes and fine-grained categories. Experimental\nresults, validated through cross-validation, underscore the effectiveness of\ncombining GCNs with Voronoi diagrams for advancing image classification. This\nresearch not only presents a novel perspective on image classification but also\nexpands the potential applications of graph-based learning paradigms in\ncomputer vision and unstructured data analysis.", "AI": {"tldr": "A graph-based image classification framework combining Graph Convolutional Networks with Voronoi/Delaunay graph refinements to improve accuracy and preprocessing efficiency, outperforming CNN baselines on benchmarks.", "motivation": "Images exhibit rich relational structure; CNNs on grids may miss nonlocal relations. Graph-based representations plus geometric triangulations aim to better capture spatial relations, potentially improving classification, especially in complex or fine-grained scenes.", "method": "Represent images as graphs with pixels or regions as vertices; refine graphs using Delaunay triangulations and Voronoi diagrams; apply Graph Convolutional Networks for classification; evaluate on benchmark datasets with cross-validation; claim improved preprocessing efficiency and accuracy.", "result": "Reported significant improvements in preprocessing efficiency and classification accuracy; surpasses state-of-the-art, particularly in challenging and fine-grained categories; validated via cross-validation.", "conclusion": "Demonstrates the viability of integrating GCNs with Voronoi-based graph refinements for image classification and highlights broader potential of graph-based learning in computer vision and unstructured data analysis."}}
{"id": "2508.15013", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2508.15013", "abs": "https://arxiv.org/abs/2508.15013", "authors": ["Nadav Amir", "Stas Tiomkin", "Angela Langdon"], "title": "Goals and the Structure of Experience", "comment": null, "summary": "Purposeful behavior is a hallmark of natural and artificial intelligence. Its\nacquisition is often believed to rely on world models, comprising both\ndescriptive (what is) and prescriptive (what is desirable) aspects that\nidentify and evaluate state of affairs in the world, respectively. Canonical\ncomputational accounts of purposeful behavior, such as reinforcement learning,\nposit distinct components of a world model comprising a state representation\n(descriptive aspect) and a reward function (prescriptive aspect). However, an\nalternative possibility, which has not yet been computationally formulated, is\nthat these two aspects instead co-emerge interdependently from an agent's goal.\nHere, we describe a computational framework of goal-directed state\nrepresentation in cognitive agents, in which the descriptive and prescriptive\naspects of a world model co-emerge from agent-environment interaction\nsequences, or experiences. Drawing on Buddhist epistemology, we introduce a\nconstruct of goal-directed, or telic, states, defined as classes of\ngoal-equivalent experience distributions. Telic states provide a parsimonious\naccount of goal-directed learning in terms of the statistical divergence\nbetween behavioral policies and desirable experience features. We review\nempirical and theoretical literature supporting this novel perspective and\ndiscuss its potential to provide a unified account of behavioral,\nphenomenological and neural dimensions of purposeful behaviors across diverse\nsubstrates.", "AI": {"tldr": "A theoretical framework where descriptive (state) and prescriptive (desirable) world-model aspects co-emerge from goal-directed experiences, via telic states\u2014classes of goal-equivalent experience distributions. Grounded in Buddhist epistemology, this framework uses statistical divergence between policies and desirable experience features to explain goal-directed learning, aiming to unify behavioral, phenomenological, and neural dimensions across substrates.", "motivation": "Canonical accounts (e.g., reinforcement learning) separate state representations and rewards; the authors propose that these aspects co-emerge from agent-environment interactions guided by goals, offering a more parsimonious foundation for purposeful behavior and aligning computational models with phenomenology and neural data.", "method": "Develop a computational framework that defines telic states as classes of goal-equivalent experience distributions. Formalize goal-directed learning via the statistical divergence between behavioral policies and desirable experience features. Review empirical and theoretical literature to support the notion and discuss implications for across-substrate unification.", "result": "A theoretical framework that provides a parsimonious account of goal-directed learning through telic (goal-directed) states, positing that descriptive and prescriptive world-model aspects co-emerge from experience distributions. It synthesizes behavioral, phenomenological, and neural dimensions and draws support from existing literature, without reporting new empirical results.", "conclusion": "Telic-states offer a unifying, goal-driven account of purposeful behavior that transcends traditional RL separations, with potential to integrate behavioral, phenomenological, and neural perspectives across substrates; future work should operationalize and test predictions arising from this framework."}}
{"id": "2508.15021", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15021", "abs": "https://arxiv.org/abs/2508.15021", "authors": ["Mark Van der Merwe", "Devesh Jha"], "title": "In-Context Iterative Policy Improvement for Dynamic Manipulation", "comment": "14 pages. Accepted at CoRL 2025", "summary": "Attention-based architectures trained on internet-scale language data have\ndemonstrated state of the art reasoning ability for various language-based\ntasks, such as logic problems and textual reasoning. Additionally, these Large\nLanguage Models (LLMs) have exhibited the ability to perform few-shot\nprediction via in-context learning, in which input-output examples provided in\nthe prompt are generalized to new inputs. This ability furthermore extends\nbeyond standard language tasks, enabling few-shot learning for general\npatterns. In this work, we consider the application of in-context learning with\npre-trained language models for dynamic manipulation. Dynamic manipulation\nintroduces several crucial challenges, including increased dimensionality,\ncomplex dynamics, and partial observability. To address this, we take an\niterative approach, and formulate our in-context learning problem to predict\nadjustments to a parametric policy based on previous interactions. We show\nacross several tasks in simulation and on a physical robot that utilizing\nin-context learning outperforms alternative methods in the low data regime.\nVideo summary of this work and experiments can be found\nhttps://youtu.be/2inxpdrq74U?si=dAdDYsUEr25nZvRn.", "AI": {"tldr": "In-context learning with pre-trained language models is applied to dynamic manipulation by predicting policy adjustments from previous interactions, enabling data-efficient control that outperforms baselines in low-data regimes across simulated and real-robot tasks.", "motivation": "Large Language Models demonstrate few-shot learning and reasoning capabilities, but applying them to dynamic manipulation is challenging due to high dimensionality, complex dynamics, and partial observability. This work seeks to transfer in-context learning to adaptive robotic control to improve data efficiency.", "method": "An iterative in-context learning setup where the model predicts adjustments to a parametric policy based on prior interactions. The approach leverages previous demonstrations/interactions as context to guide policy updates. Evaluations span several dynamic manipulation tasks in simulation and on a physical robot, with a video summary linked in the abstract.", "result": "Across tasks in both simulation and real-robot settings, in-context learning outperforms alternative methods in the low data regime.", "conclusion": "In-context learning with pre-trained language models offers a data-efficient pathway for dynamic manipulation, enabling rapid policy adaptation with limited task data; future work could explore scaling, robustness to observation noise, and richer forms of contextual history."}}
{"id": "2508.14942", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14942", "abs": "https://arxiv.org/abs/2508.14942", "authors": ["Jiacheng Hu", "Bo Zhang", "Ting Xu", "Haifeng Yang", "Min Gao"], "title": "Structure-Aware Temporal Modeling for Chronic Disease Progression Prediction", "comment": null, "summary": "This study addresses the challenges of symptom evolution complexity and\ninsufficient temporal dependency modeling in Parkinson's disease progression\nprediction. It proposes a unified prediction framework that integrates\nstructural perception and temporal modeling. The method leverages graph neural\nnetworks to model the structural relationships among multimodal clinical\nsymptoms and introduces graph-based representations to capture semantic\ndependencies between symptoms. It also incorporates a Transformer architecture\nto model dynamic temporal features during disease progression. To fuse\nstructural and temporal information, a structure-aware gating mechanism is\ndesigned to dynamically adjust the fusion weights between structural encodings\nand temporal features, enhancing the model's ability to identify key\nprogression stages. To improve classification accuracy and stability, the\nframework includes a multi-component modeling pipeline, consisting of a graph\nconstruction module, a temporal encoding module, and a prediction output layer.\nThe model is evaluated on real-world longitudinal Parkinson's disease data. The\nexperiments involve comparisons with mainstream models, sensitivity analysis of\nhyperparameters, and graph connection density control. Results show that the\nproposed method outperforms existing approaches in AUC, RMSE, and IPW-F1\nmetrics. It effectively distinguishes progression stages and improves the\nmodel's ability to capture personalized symptom trajectories. The overall\nframework demonstrates strong generalization and structural scalability,\nproviding reliable support for intelligent modeling of chronic progressive\ndiseases such as Parkinson's disease.", "AI": {"tldr": "A unified GNN-Transformer framework for Parkinson's disease progression prediction that fuses structural relationships among multimodal symptoms with temporal dynamics using a structure-aware fusion gate, improving accuracy and personalized trajectory modeling.", "motivation": "Address the challenges of symptom evolution complexity and insufficient temporal dependency modeling in PD progression prediction by integrating structural perception with temporal modeling.", "method": "Construct a graph of multimodal clinical symptoms to capture structural relationships using graph neural networks; represent semantic dependencies via graph-based encodings; apply a Transformer to model dynamic temporal features; introduce a structure-aware gating mechanism to dynamically fuse structural encodings with temporal features; implement a multi-component pipeline (graph construction, temporal encoding, prediction output) and evaluate on real-world longitudinal PD data.", "result": "On real-world longitudinal PD data, the approach outperforms mainstream models in AUC, RMSE, and IPW-F1, with better discrimination of progression stages and enhanced capture of personalized symptom trajectories; demonstrates strong generalization and scalability to chronic progressive diseases.", "conclusion": "A unified, scalable framework that integrates structural perception and temporal modeling to improve PD progression prediction and potentially support intelligent modeling of chronic progressive diseases."}}
{"id": "2508.14965", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.14965", "abs": "https://arxiv.org/abs/2508.14965", "authors": ["Hakjin Lee", "Junghoon Seo", "Jaehoon Sim"], "title": "You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation", "comment": "https://mikigom.github.io/YOPO-project-page", "summary": "Accurately recovering the full 9-DoF pose of unseen instances within specific\ncategories from a single RGB image remains a core challenge for robotics and\nautomation. Most existing solutions still rely on pseudo-depth, CAD models, or\nmulti-stage cascades that separate 2D detection from pose estimation. Motivated\nby the need for a simpler, RGB-only alternative that learns directly at the\ncategory level, we revisit a longstanding question: Can object detection and\n9-DoF pose estimation be unified with high performance, without any additional\ndata? We show that they can with our method, YOPO, a single-stage, query-based\nframework that treats category-level 9-DoF estimation as a natural extension of\n2D detection. YOPO augments a transformer detector with a lightweight pose\nhead, a bounding-box-conditioned translation module, and a 6D-aware Hungarian\nmatching cost. The model is trained end-to-end only with RGB images and\ncategory-level pose labels. Despite its minimalist design, YOPO sets a new\nstate of the art on three benchmarks. On the REAL275 dataset, it achieves 79.6%\n$\\rm{IoU}_{50}$ and 54.1% under the $10^\\circ$$10{\\rm{cm}}$ metric, surpassing\nprior RGB-only methods and closing much of the gap to RGB-D systems. The code,\nmodels, and additional qualitative results can be found on our project.", "AI": {"tldr": "YOPO is a single-stage RGB-only framework that unifies category-level 9-DoF pose estimation with 2D detection, using a transformer detector augmented with a pose head, translation module, and 6D-aware matching; achieves state-of-the-art on REAL275 and other benchmarks.", "motivation": "To abolish the need for pseudo-depth, CAD models, and multi-stage pipelines by showing end-to-end RGB-only category-level pose estimation is possible.", "method": "A single-stage, query-based transformer detector (YOPO) with a lightweight pose head, a bounding-box-conditioned translation module, and a 6D-aware Hungarian matching cost; trained end-to-end with RGB images and category-level pose labels.", "result": "Sets new state of the art on three benchmarks; REAL275 IoU50 79.6%, and 10\u00b0/10cm 54.1%; surpasses previous RGB-only methods and closes much of the gap to RGB-D.", "conclusion": "Demonstrates the feasibility and effectiveness of an RGB-only, unified detection-and-pose-estimation approach; provides a strong new baseline and code release."}}
{"id": "2508.15030", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15030", "abs": "https://arxiv.org/abs/2508.15030", "authors": ["Ashmi Banerjee", "Fitri Nur Aisyah", "Adithi Satish", "Wolfgang W\u00f6rndl", "Yashar Deldjoo"], "title": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism", "comment": null, "summary": "We propose Collab-REC, a multi-agent framework designed to counteract\npopularity bias and enhance diversity in tourism recommendations. In our\nsetting, three LLM-based agents -- Personalization, Popularity, and\nSustainability generate city suggestions from complementary perspectives. A\nnon-LLM moderator then merges and refines these proposals via multi-round\nnegotiation, ensuring each agent's viewpoint is incorporated while penalizing\nspurious or repeated responses. Experiments on European city queries show that\nCollab-REC improves diversity and overall relevance compared to a single-agent\nbaseline, surfacing lesser-visited locales that often remain overlooked. This\nbalanced, context-aware approach addresses over-tourism and better aligns with\nconstraints provided by the user, highlighting the promise of multi-stakeholder\ncollaboration in LLM-driven recommender systems.", "AI": {"tldr": "Collab-REC is a multi-agent LLM framework for tourism recommendations that uses three specialized agents (Personalization, Popularity, Sustainability) and a non-LLM moderator to merge and refine their outputs, aiming to reduce popularity bias and increase diversity while maintaining relevance.", "motivation": "Address popularity bias and over-tourism in recommender systems, particularly for tourism, by integrating diverse stakeholder perspectives and ensuring user constraints are respected.", "method": "Three LLM-based agents generate city suggestions from complementary angles: Personalization (user-tailored), Popularity (crowd-driven appeal), and Sustainability (environmental and cultural considerations). A non-LLM moderator conducts multi-round negotiation to merge proposals, penalize spurious or repetitive content, and ensure inclusion of each agent's viewpoint. Evaluation on European city queries comparing against a single-agent baseline.", "result": "Collab-REC improves diversity and overall relevance over the single-agent baseline, surfacing lesser-visited locales that are often overlooked; the approach balances context-aware recommendations and aims to mitigate over-tourism while aligning with user constraints.", "conclusion": "Multi-agent, multi-perspective collaboration with a moderator shows promise for reducing popularity bias and increasing diversity in LLM-driven recommender systems, particularly for tourism contexts."}}
{"id": "2508.15038", "categories": ["cs.RO", "cs.AI", "cs.CV", "cs.MA", "I.2.9"], "pdf": "https://arxiv.org/pdf/2508.15038", "abs": "https://arxiv.org/abs/2508.15038", "authors": ["Makram Chahine", "William Yang", "Alaa Maalouf", "Justin Siriska", "Ninad Jadhav", "Daniel Vogt", "Stephanie Gil", "Robert Wood", "Daniela Rus"], "title": "Decentralized Vision-Based Autonomous Aerial Wildlife Monitoring", "comment": null, "summary": "Wildlife field operations demand efficient parallel deployment methods to\nidentify and interact with specific individuals, enabling simultaneous\ncollective behavioral analysis, and health and safety interventions. Previous\nrobotics solutions approach the problem from the herd perspective, or are\nmanually operated and limited in scale. We propose a decentralized vision-based\nmulti-quadrotor system for wildlife monitoring that is scalable, low-bandwidth,\nand sensor-minimal (single onboard RGB camera). Our approach enables robust\nidentification and tracking of large species in their natural habitat. We\ndevelop novel vision-based coordination and tracking algorithms designed for\ndynamic, unstructured environments without reliance on centralized\ncommunication or control. We validate our system through real-world\nexperiments, demonstrating reliable deployment in diverse field conditions.", "AI": {"tldr": "Decentralized, vision-based, single-camera multi-quadrotor system for scalable wildlife monitoring with novel coordination/tracking in unstructured environments, validated in real-world field tests.", "motivation": "Address limitations of herd-centric or manually operated wildlife robotics by enabling scalable, low-bandwidth, sensor-minimal monitoring with robust identification and tracking in natural habitats.", "method": "Develop decentralized vision-based coordination and tracking algorithms for dynamic, unstructured environments without centralized control; use a single onboard RGB camera per drone; validate through real-world field experiments.", "result": "Demonstrates reliable deployment and robust identification/tracking across diverse field conditions, indicating scalability and low-bandwidth operation.", "conclusion": "Proposes a scalable wildlife monitoring framework with decentralized coordination and vision-based tracking, suitable for large-scale behavioral analysis and health/safety interventions in natural habitats."}}
{"id": "2508.14946", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14946", "abs": "https://arxiv.org/abs/2508.14946", "authors": ["Anurag Tripathi", "Ajeet Kumar Singh", "Rajsabi Surya", "Aum Gupta", "Sahiinii Lemaina Veikho", "Dorien Herremans", "Sudhir Bisane"], "title": "HHNAS-AM: Hierarchical Hybrid Neural Architecture Search using Adaptive Mutation Policies", "comment": null, "summary": "Neural Architecture Search (NAS) has garnered significant research interest\ndue to its capability to discover architectures superior to manually designed\nones. Learning text representation is crucial for text classification and other\nlanguage-related tasks. The NAS model used in text classification does not have\na Hybrid hierarchical structure, and there is no restriction on the\narchitecture structure, due to which the search space becomes very large and\nmostly redundant, so the existing RL models are not able to navigate the search\nspace effectively. Also, doing a flat architecture search leads to an\nunorganised search space, which is difficult to traverse. For this purpose, we\npropose HHNAS-AM (Hierarchical Hybrid Neural Architecture Search with Adaptive\nMutation Policies), a novel approach that efficiently explores diverse\narchitectural configurations. We introduce a few architectural templates to\nsearch on which organise the search spaces, where search spaces are designed on\nthe basis of domain-specific cues. Our method employs mutation strategies that\ndynamically adapt based on performance feedback from previous iterations using\nQ-learning, enabling a more effective and accelerated traversal of the search\nspace. The proposed model is fully probabilistic, enabling effective\nexploration of the search space. We evaluate our approach on the database id\n(db_id) prediction task, where it consistently discovers high-performing\narchitectures across multiple experiments. On the Spider dataset, our method\nachieves an 8% improvement in test accuracy over existing baselines.", "AI": {"tldr": "Hierarchical Hybrid Neural Architecture Search with Adaptive Mutation Policies (HHNAS-AM) for text classification networks; uses template-driven, hierarchical search with Q-learning guided mutations; achieves notable gains (8% test accuracy on Spider) and consistent high-performing architectures.", "motivation": "NAS in text classification faces enormous, often redundant search spaces and flat architectures; a structured, adaptive search strategy is needed to efficiently navigate the space and discover effective text representations.", "method": "Introduce architectural templates to organize the search space; propose a hierarchical hybrid search framework; apply adaptive mutation policies via Q-learning to guide exploration; model is fully probabilistic to encourage exploration; evaluated on text-centric tasks (db_id prediction and Spider).", "result": "Consistently discovers high-performing architectures across experiments; 8% improvement in test accuracy on the Spider dataset compared with existing baselines.", "conclusion": "HHNAS-AM demonstrates that template-guided hierarchical NAS with adaptive mutations can effectively navigate large text-architecture search spaces, yielding improved performance and robust search behavior; the probabilistic approach supports comprehensive exploration."}}
{"id": "2508.14980", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.14980", "abs": "https://arxiv.org/abs/2508.14980", "authors": ["Andrei Balykin", "Anvar Ganiev", "Denis Kondranin", "Kirill Polevoda", "Nikolai Liudkevich", "Artem Petrov"], "title": "Paired-Sampling Contrastive Framework for Joint Physical-Digital Face Attack Detection", "comment": "Accepted to ICCV2025 FAS workshop", "summary": "Modern face recognition systems remain vulnerable to spoofing attempts,\nincluding both physical presentation attacks and digital forgeries.\nTraditionally, these two attack vectors have been handled by separate models,\neach targeting its own artifacts and modalities. However, maintaining distinct\ndetectors increases system complexity and inference latency and leaves systems\nexposed to combined attack vectors. We propose the Paired-Sampling Contrastive\nFramework, a unified training approach that leverages automatically matched\npairs of genuine and attack selfies to learn modality-agnostic liveness cues.\nEvaluated on the 6th Face Anti-Spoofing Challenge Unified Physical-Digital\nAttack Detection benchmark, our method achieves an average classification error\nrate (ACER) of 2.10 percent, outperforming prior solutions. The framework is\nlightweight (4.46 GFLOPs) and trains in under one hour, making it practical for\nreal-world deployment. Code and pretrained models are available at\nhttps://github.com/xPONYx/iccv2025_deepfake_challenge.", "AI": {"tldr": "Unified paired-sampling contrastive framework for detecting both physical and digital face spoofing, achieving strong accuracy with low compute.", "motivation": "Combine physical (presentation) attacks and digital (forgery) attacks into a single detector to reduce complexity, latency, and vulnerability to combined attacks.", "method": "Paired-Sampling Contrastive Framework that uses automatically matched pairs of genuine and attack selfies to learn modality-agnostic liveness cues; trains in a unified fashion for joint detection.", "result": "ACER 2.10% on the 6th Face Anti-Spoofing Challenge Unified Physical-Digital Attack Detection benchmark; 4.46 GFLOPs; training in under one hour; outperforms prior solutions.", "conclusion": "Demonstrates practicality for real-world deployment with a compact, unified detector; reduces system complexity and latency and increases resilience to combined spoofing vectors; code and pretrained models released."}}
{"id": "2508.15047", "categories": ["cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2508.15047", "abs": "https://arxiv.org/abs/2508.15047", "authors": ["Yibo Liu", "Liam Shatzel", "Brandon Haworth", "Teseo Schneider"], "title": "Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions", "comment": null, "summary": "Animating and simulating crowds using an agent-based approach is a\nwell-established area where every agent in the crowd is individually controlled\nsuch that global human-like behaviour emerges. We observe that human navigation\nand movement in crowds are often influenced by complex social and environmental\ninteractions, driven mainly by language and dialogue. However, most existing\nwork does not consider these dimensions and leads to animations where\nagent-agent and agent-environment interactions are largely limited to steering\nand fixed higher-level goal extrapolation.\n  We propose a novel method that exploits large language models (LLMs) to\ncontrol agents' movement. Our method has two main components: a dialogue system\nand language-driven navigation. We periodically query agent-centric LLMs\nconditioned on character personalities, roles, desires, and relationships to\ncontrol the generation of inter-agent dialogue when necessitated by the spatial\nand social relationships with neighbouring agents. We then use the conversation\nand each agent's personality, emotional state, vision, and physical state to\ncontrol the navigation and steering of each agent. Our model thus enables\nagents to make motion decisions based on both their perceptual inputs and the\nongoing dialogue.\n  We validate our method in two complex scenarios that exemplify the interplay\nbetween social interactions, steering, and crowding. In these scenarios, we\nobserve that grouping and ungrouping of agents automatically occur.\nAdditionally, our experiments show that our method serves as an\ninformation-passing mechanism within the crowd. As a result, our framework\nproduces more realistic crowd simulations, with emergent group behaviours\narising naturally from any environmental setting.", "AI": {"tldr": "An LLM-driven agent-based crowd simulation framework that uses agent-centric dialogue to influence navigation, enabling emergent group behaviors and information sharing within crowds.", "motivation": "Traditional crowd simulations focus on steering and fixed goals, largely ignoring social language and dialogue which are central to human navigation in crowds; incorporating language can capture nuanced social interactions and coordination.", "method": "Two components: (1) a dialogue system that periodically queries agent-centric LLMs (conditioned on personalities, roles, desires, relationships) to generate inter-agent dialogue; (2) language-driven navigation that uses dialogue plus each agent's personality, emotions, vision, and physical state to control movement. Agents decide motion based on perceptual inputs and ongoing dialogue.", "result": "Validated in two complex scenarios showing interactions between social dynamics and steering; observed automatic grouping/ungrouping; the framework acts as an information-passing mechanism within the crowd and yields more realistic simulations with emergent group behaviors.", "conclusion": "Language-informed, dialogue-driven control can substantially enhance realism in crowd simulations, producing natural emergent behaviors across environments; the approach is promising but may demand careful evaluation and resource considerations to manage LLM costs and reliability."}}
{"id": "2508.15160", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15160", "abs": "https://arxiv.org/abs/2508.15160", "authors": ["Hesam Azadjou", "Suraj Chakravarthi Raja", "Ali Marjaninejad", "Francisco J. Valero-Cuevas"], "title": "Hardware Implementation of a Zero-Prior-Knowledge Approach to Lifelong Learning in Kinematic Control of Tendon-Driven Quadrupeds", "comment": null, "summary": "Like mammals, robots must rapidly learn to control their bodies and interact\nwith their environment despite incomplete knowledge of their body structure and\nsurroundings. They must also adapt to continuous changes in both. This work\npresents a bio-inspired learning algorithm, General-to-Particular (G2P),\napplied to a tendon-driven quadruped robotic system developed and fabricated\nin-house. Our quadruped robot undergoes an initial five-minute phase of\ngeneralized motor babbling, followed by 15 refinement trials (each lasting 20\nseconds) to achieve specific cyclical movements. This process mirrors the\nexploration-exploitation paradigm observed in mammals. With each refinement,\nthe robot progressively improves upon its initial \"good enough\" solution. Our\nresults serve as a proof-of-concept, demonstrating the hardware-in-the-loop\nsystem's ability to learn the control of a tendon-driven quadruped with\nredundancies in just a few minutes to achieve functional and adaptive cyclical\nnon-convex movements. By advancing autonomous control in robotic locomotion,\nour approach paves the way for robots capable of dynamically adjusting to new\nenvironments, ensuring sustained adaptability and performance.", "AI": {"tldr": "A bio-inspired General-to-Particular (G2P) learning approach enables rapid, hardware-in-the-loop learning of locomotion for a tendon-driven quadruped, using initial generalized motor babbling followed by short refinement trials to achieve functional, adaptive cyclical movements in minutes.", "motivation": "Robots need fast, adaptive motor learning under incomplete body/ environment models and continuous changes. The method aims to emulate mammals' exploration-exploitation to handle redundancies and non-convex control problems in tendon-driven robots.", "method": "G2P framework: 1) ~5 minutes of generalized motor babbling to capture broad motor mappings; 2) 15 refinement trials (20 seconds each) to progressively shape the control policy toward specific cyclical movements. Hardware-in-the-loop demonstration on a home-built tendon-driven quadruped with redundant joints.", "result": "Proof-of-concept showing the system can learn to control a tendon-driven, redundant quadruped to perform functional, adaptive cyclical non-convex locomotion within a few minutes.", "conclusion": "G2P offers a pathway toward autonomous, adaptive locomotion in robotics, enabling rapid adjustment to new environments with minimal handcrafted modeling, though future work should address scalability, robustness, and quantitative benchmarks."}}
{"id": "2508.14947", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14947", "abs": "https://arxiv.org/abs/2508.14947", "authors": ["Rui Wang", "Qianguo Sun", "Chao Song", "Junlong Wu", "Tianrong Chen", "Zhiyun Zeng", "Yu Li"], "title": "Linear Preference Optimization: Decoupled Gradient Control via Absolute Regularization", "comment": null, "summary": "DPO (Direct Preference Optimization) has become a widely used offline\npreference optimization algorithm due to its simplicity and training stability.\nHowever, DPO is prone to overfitting and collapse. To address these challenges,\nwe propose Linear Preference Optimization (LPO), a novel alignment framework\nfeaturing three key innovations. First, we introduce gradient decoupling by\nreplacing the log-sigmoid function with an absolute difference loss, thereby\nisolating the optimization dynamics. Second, we improve stability through an\noffset constraint combined with a positive regularization term to preserve the\nchosen response quality. Third, we implement controllable rejection suppression\nusing gradient separation with straightforward estimation and a tunable\ncoefficient that linearly regulates the descent of the rejection probability.\nThrough extensive experiments, we demonstrate that LPO consistently improves\nperformance on various tasks, including general text tasks, math tasks, and\ntext-to-speech (TTS) tasks. These results establish LPO as a robust and tunable\nparadigm for preference alignment, and we release the source code, models, and\ntraining data publicly.", "AI": {"tldr": "LPO improves on DPO by decoupling optimization dynamics via absolute-difference loss, stabilizing training with an offset constraint and positive regularization, and suppressing unwanted rejection through gradient separation with a tunable coefficient; shows consistent gains across text, math, and TTS tasks; code released.", "motivation": "DPO is simple and stable but susceptible to overfitting and collapse; a more robust, tunable alignment method is needed to preserve quality while reducing degeneration.", "method": "Three innovations: 1) gradient decoupling by using an absolute-difference loss instead of log-sigmoid to isolate optimization dynamics; 2) stability via an offset constraint plus a positive regularization term to preserve chosen response quality; 3) controllable rejection suppression using gradient separation with a tunable coefficient that regulates decline of rejection probability.", "result": "Extensive experiments show LPO consistently improves performance on general text tasks, math tasks, and text-to-speech tasks; claims robustness and tunability; source code, models, and data released.", "conclusion": "LPO provides a robust, tunable preference-alignment paradigm that overcomes DPO shortcomings; supports broader applicability across modalities; open-source resources accompany the work."}}
{"id": "2508.15020", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15020", "abs": "https://arxiv.org/abs/2508.15020", "authors": ["Susim Roy", "Anubhooti Jain", "Mayank Vatsa", "Richa Singh"], "title": "TAIGen: Training-Free Adversarial Image Generation via Diffusion Models", "comment": "Accepted at ICCVW-CV4BIOM 2025", "summary": "Adversarial attacks from generative models often produce low-quality images\nand require substantial computational resources. Diffusion models, though\ncapable of high-quality generation, typically need hundreds of sampling steps\nfor adversarial generation. This paper introduces TAIGen, a training-free\nblack-box method for efficient adversarial image generation. TAIGen produces\nadversarial examples using only 3-20 sampling steps from unconditional\ndiffusion models. Our key finding is that perturbations injected during the\nmixing step interval achieve comparable attack effectiveness without processing\nall timesteps. We develop a selective RGB channel strategy that applies\nattention maps to the red channel while using GradCAM-guided perturbations on\ngreen and blue channels. This design preserves image structure while maximizing\nmisclassification in target models. TAIGen maintains visual quality with PSNR\nabove 30 dB across all tested datasets. On ImageNet with VGGNet as source,\nTAIGen achieves 70.6% success against ResNet, 80.8% against MNASNet, and 97.8%\nagainst ShuffleNet. The method generates adversarial examples 10x faster than\nexisting diffusion-based attacks. Our method achieves the lowest robust\naccuracy, indicating it is the most impactful attack as the defense mechanism\nis least successful in purifying the images generated by TAIGen.", "AI": {"tldr": "TAIGen is a training-free black-box adversarial attack using diffusion models, requiring only 3\u201320 sampling steps and a selective RGB perturbation strategy to achieve high attack success with PSNR > 30 dB, while being ~10x faster than prior diffusion-based attacks.", "motivation": "Diffusion models offer high-quality image generation but adversarial generation is expensive and slow. There is a need for training-free, black-box methods that can craft effective adversarial examples efficiently without full diffusion sampling.", "method": "TAIGen injects perturbations during a limited mixing-step interval of unconditional diffusion sampling, using a selective RGB strategy: attention maps perturb the red channel while GradCAM-guided perturbations affect green and blue channels. This preserves image structure while maximizing misclassification, and requires only 3\u201320 steps from the diffusion model.", "result": "On ImageNet with VGGNet as source, TAIGen achieves 70.6% attack success against ResNet, 80.8% against MNASNet, and 97.8% against ShuffleNet; PSNR > 30 dB across datasets; ~10\u00d7 faster than existing diffusion-based attacks.", "conclusion": "A training-free, black-box diffusion attack can produce high-quality adversarial images with minimal diffusion steps and a channel-aware perturbation strategy, achieving strong attack effectiveness and exposing vulnerabilities even against defenses that purify diffusion-generated content."}}
{"id": "2508.15050", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15050", "abs": "https://arxiv.org/abs/2508.15050", "authors": ["Romain Lacombe", "Kerrie Wu", "Eddie Dilworth"], "title": "Don't Think Twice! Over-Reasoning Impairs Confidence Calibration", "comment": "Published at ICML 2025 Workshop on Reliable and Responsible\n  Foundation Models", "summary": "Large Language Models deployed as question answering tools require robust\ncalibration to avoid overconfidence. We systematically evaluate how reasoning\ncapabilities and budget affect confidence assessment accuracy, using the\nClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary\nhealth. Our key finding challenges the \"test-time scaling\" paradigm: while\nrecent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,\nincreasing reasoning budgets consistently impairs rather than improves\ncalibration. Extended reasoning leads to systematic overconfidence that worsens\nwith longer thinking budgets, producing diminishing and negative returns beyond\nmodest computational investments. Conversely, search-augmented generation\ndramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving\nrelevant evidence. Our results suggest that information access, rather than\nreasoning depth or inference budget, may be the critical bottleneck for\nimproved confidence calibration of knowledge-intensive tasks.", "AI": {"tldr": "Deeper reasoning hurts confidence calibration in LLM QA; retrieval-based evidence access boosts calibration much more, indicating information access is the bottleneck in knowledge-intensive tasks.", "motivation": "Calibrate LLMs to avoid overconfidence in QA by examining how reasoning depth and compute budgets affect confidence accuracy, across climate, health, and planetary health domains.", "method": "Empirically compare reasoning-only vs. extended reasoning budgets and retrieval-augmented generation on the ClimateX dataset (expanded to human and planetary health), measuring accuracy of expert-confidence assessments.", "result": "Pure reasoning with larger budgets yields 48.7% accuracy in assessing expert confidence and becomes more overconfident with longer thinking; extended budgets give diminishing/negative returns. Retrieval-augmented generation attains 89.3% accuracy by retrieving relevant evidence.", "conclusion": "Access to information via retrieval, not deeper reasoning or larger budgets, is the key bottleneck for calibrating confidence in knowledge-intensive tasks; retrieval-augmented approaches substantially outperform pure reasoning for confidence calibration."}}
{"id": "2508.15201", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15201", "abs": "https://arxiv.org/abs/2508.15201", "authors": ["Haoran Li", "Yuhui Chen", "Wenbo Cui", "Weiheng Liu", "Kai Liu", "Mingcai Zhou", "Zhengtao Zhang", "Dongbin Zhao"], "title": "Survey of Vision-Language-Action Models for Embodied Manipulation", "comment": "in Chinese language", "summary": "Embodied intelligence systems, which enhance agent capabilities through\ncontinuous environment interactions, have garnered significant attention from\nboth academia and industry. Vision-Language-Action models, inspired by\nadvancements in large foundation models, serve as universal robotic control\nframeworks that substantially improve agent-environment interaction\ncapabilities in embodied intelligence systems. This expansion has broadened\napplication scenarios for embodied AI robots. This survey comprehensively\nreviews VLA models for embodied manipulation. Firstly, it chronicles the\ndevelopmental trajectory of VLA architectures. Subsequently, we conduct a\ndetailed analysis of current research across 5 critical dimensions: VLA model\nstructures, training datasets, pre-training methods, post-training methods, and\nmodel evaluation. Finally, we synthesize key challenges in VLA development and\nreal-world deployment, while outlining promising future research directions.", "AI": {"tldr": "Survey of Vision-Language-Action (VLA) models for embodied manipulation; covers architecture evolution, datasets, pre-training/post-training strategies, evaluation, and future challenges.", "motivation": "Embodied AI seeks robust, flexible control by integrating perception, language, and action; VLA models offer a unified framework to improve agent-environment interaction.", "method": "Literature survey across five dimensions: model structures, training datasets, pre-training methods, post-training methods, and evaluation; analyzes historical trends and current research; synthesizes challenges and future directions.", "result": "Provides a comprehensive taxonomy and critical synthesis; identifies gaps and needs for standardized evaluation, data and computation efficiency, real-world deployment considerations.", "conclusion": "VLA models hold promise for embodied manipulation; realization requires addressing data efficiency, alignment, safety, generalization, and deployment scalability; outlines directions for future work."}}
{"id": "2508.14948", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14948", "abs": "https://arxiv.org/abs/2508.14948", "authors": ["Shangyu Zhang", "Shijie Quan", "Zhongren Wang", "Junwei Pan", "Tianqu Zhuang", "Bo Fu", "Yilong Sun", "Jieying Lin", "Jushuo Chen", "Xiaotian Li", "Zhixiang Feng", "Xian Hu", "Huiting Deng", "Hua Lu", "Jinpeng Wang", "Boqi Dai", "Xiaoyu Chen", "Bin Hu", "Lili Huang", "Yanwen Wu", "Yeshou Cai", "Qi Zhou", "Huang Tang", "Chunfeng Yang", "Chengguo Yin", "Tingyu Jiang", "Lifeng Wang", "Shudong Huang", "Dapeng Liu", "Lei Xiao", "Haijie Gu", "Shu-Tao Xia", "Jie Jiang"], "title": "Large Foundation Model for Ads Recommendation", "comment": null, "summary": "Online advertising relies on accurate recommendation models, with recent\nadvances using pre-trained large-scale foundation models (LFMs) to capture\nusers' general interests across multiple scenarios and tasks. However, existing\nmethods have critical limitations: they extract and transfer only user\nrepresentations (URs), ignoring valuable item representations (IRs) and\nuser-item cross representations (CRs); and they simply use a UR as a feature in\ndownstream applications, which fails to bridge upstream-downstream gaps and\noverlooks more transfer granularities. In this paper, we propose LFM4Ads, an\nAll-Representation Multi-Granularity transfer framework for ads recommendation.\nIt first comprehensively transfers URs, IRs, and CRs, i.e., all available\nrepresentations in the pre-trained foundation model. To effectively utilize the\nCRs, it identifies the optimal extraction layer and aggregates them into\ntransferable coarse-grained forms. Furthermore, we enhance the transferability\nvia multi-granularity mechanisms: non-linear adapters for feature-level\ntransfer, an Isomorphic Interaction Module for module-level transfer, and\nStandalone Retrieval for model-level transfer. LFM4Ads has been successfully\ndeployed in Tencent's industrial-scale advertising platform, processing tens of\nbillions of daily samples while maintaining terabyte-scale model parameters\nwith billions of sparse embedding keys across approximately two thousand\nfeatures. Since its production deployment in Q4 2024, LFM4Ads has achieved 10+\nsuccessful production launches across various advertising scenarios, including\nprimary ones like Weixin Moments and Channels. These launches achieve an\noverall GMV lift of 2.45% across the entire platform, translating to estimated\nannual revenue increases in the hundreds of millions of dollars.", "AI": {"tldr": "A comprehensive all-representation, multi-granularity transfer framework (LFM4Ads) for ads recommendation that transfers URs, IRs, and CRs from a foundation model, with layer-optimized extraction and multi-granularity adapters/modules, deployed at Tencent achieving a 2.45% GMV lift platform-wide.", "motivation": "Addresses limitations of prior methods that use only user representations and single-transfer granularity. Seeks to leverage all representations (URs, IRs, CRs) and bridge upstream-downstream gaps to improve transferability and performance in ads recommendations.", "method": "Transfer all representations (URs, IRs, CRs) from a pre-trained foundation model. For CRs, identify the optimal extraction layer and aggregate them into transferable coarse-grained forms. Employ multi-granularity mechanisms: non-linear adapters for feature-level transfer, Isomorphic Interaction Module for module-level transfer, and Standalone Retrieval for model-level transfer.", "result": "Industrial deployment in Tencent\u2019s platform, handling tens of billions of daily samples with terabyte-scale model parameters and billions of sparse embeddings across about 2000 features. Since Q4 2024 deployment, 10+ production launches across ad scenarios (e.g., Weixin Moments, Channels) with an overall GMV lift of 2.45% across the platform, implying hundreds of millions in estimated annual revenue increases.", "conclusion": "Transferring all representations with multi-granularity mechanisms yields tangible gains in ads recommendation quality and revenue at industrial scale, validating the approach\u2019s effectiveness and scalability."}}
{"id": "2508.15027", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15027", "abs": "https://arxiv.org/abs/2508.15027", "authors": ["Chunming He", "Fengyang Xiao", "Rihan Zhang", "Chengyu Fang", "Deng-Ping Fan", "Sina Farsiu"], "title": "Reversible Unfolding Network for Concealed Visual Perception with Generative Refinement", "comment": "18 pages, 21 tables, 13 figures", "summary": "Existing methods for concealed visual perception (CVP) often leverage\nreversible strategies to decrease uncertainty, yet these are typically confined\nto the mask domain, leaving the potential of the RGB domain underexplored. To\naddress this, we propose a reversible unfolding network with generative\nrefinement, termed RUN++. Specifically, RUN++ first formulates the CVP task as\na mathematical optimization problem and unfolds the iterative solution into a\nmulti-stage deep network. This approach provides a principled way to apply\nreversible modeling across both mask and RGB domains while leveraging a\ndiffusion model to resolve the resulting uncertainty. Each stage of the network\nintegrates three purpose-driven modules: a Concealed Object Region Extraction\n(CORE) module applies reversible modeling to the mask domain to identify core\nobject regions; a Context-Aware Region Enhancement (CARE) module extends this\nprinciple to the RGB domain to foster better foreground-background separation;\nand a Finetuning Iteration via Noise-based Enhancement (FINE) module provides a\nfinal refinement. The FINE module introduces a targeted Bernoulli diffusion\nmodel that refines only the uncertain regions of the segmentation mask,\nharnessing the generative power of diffusion for fine-detail restoration\nwithout the prohibitive computational cost of a full-image process. This unique\nsynergy, where the unfolding network provides a strong uncertainty prior for\nthe diffusion model, allows RUN++ to efficiently direct its focus toward\nambiguous areas, significantly mitigating false positives and negatives.\nFurthermore, we introduce a new paradigm for building robust CVP systems that\nremain effective under real-world degradations and extend this concept into a\nbroader bi-level optimization framework.", "AI": {"tldr": "A reversible unfolding network RUN++ for concealed visual perception that unifies mask and RGB domains with diffusion-based refinement, using CORE, CARE, and FINE modules and a targeted Bernoulli diffusion on uncertain regions to improve robustness and efficiency.", "motivation": "Extend reversible modeling from the mask domain to the RGB domain, address uncertainty more effectively, and leverage diffusion models for fine-detail restoration without full-image cost; provide a robust CVP framework under real-world degradations.", "method": "Formulates CVP as an optimization problem and unfolds the iterative solution into a multi-stage network. CORE applies reversible modeling in the mask domain to identify core object regions; CARE extends the principle to the RGB domain for better foreground-background separation; FINE performs a final refinement via a targeted Bernoulli diffusion model that refines only the uncertain mask regions, guided by the unfolding prior; diffusion resolves remaining uncertainty, enabling efficient, focused refinement. The approach also introduces a bi-level optimization framework for robustness under degradations.", "result": "Claims improved handling of uncertainty, reduced false positives/negatives, and efficiency through targeted diffusion that focuses on uncertain regions, plus enhanced robustness to real-world degradations; quantitative performance is not provided in the abstract.", "conclusion": "RUN++ offers a principled, efficient framework for reversible CVP across mask and RGB domains and introduces a broader bi-level optimization paradigm to build robust CVP systems."}}
{"id": "2508.15053", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15053", "abs": "https://arxiv.org/abs/2508.15053", "authors": ["Itai Zilberstein", "Alberto Candela", "Steve Chien", "David Rijlaarsdam", "Tom Hendrix", "Leonie Buckley", "Aubrey Dunne"], "title": "Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning", "comment": "International Symposium on Artificial Intelligence, Robotics and\n  Automation in Space, November 2024", "summary": "In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is\ndemonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).\nCS-6 is a satellite with a visible and near infrared range hyperspectral\ninstrument and neural network acceleration hardware. Performing data analysis\nat the edge (e.g. onboard) can enable new Earth science measurements and\nresponses. We will demonstrate data analysis and inference onboard CS-6 for\nnumerous applications using deep learning and spectral analysis algorithms.", "AI": {"tldr": "Onboard data analysis and inference on CogniSAT-6/HAMMER using hyperspectral data and neural-network accelerators to enable edge Earth-observation analytics.", "motivation": "Enable real-time or near-real-time Earth observation analytics, reduce data downlink bandwidth, and unlock new measurements by performing spectral analysis and DL inference onboard the satellite.", "method": "Demonstration of onboard data analysis and inference on CS-6, leveraging a hyperspectral instrument (visible and NIR) and neural network acceleration hardware, in collaboration with Ubotica Technologies; application of deep learning and spectral analysis algorithms.", "result": "No results are reported in the abstract; it describes planned demonstrations of onboard analysis.", "conclusion": "If successful, the work would validate edge computing for hyperspectral missions and enable faster, more responsive Earth science measurements with onboard DL inference."}}
{"id": "2508.15300", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15300", "abs": "https://arxiv.org/abs/2508.15300", "authors": ["William McDonald", "Cedric Le Gentil", "Jennifer Wakulicz", "Teresa Vidal-Calleja"], "title": "Mag-Match: Magnetic Vector Field Features for Map Matching and Registration", "comment": "To be published in IROS: IEEE/RSJ International Conference on\n  Intelligent Robots and Systems, 2025", "summary": "Map matching and registration are essential tasks in robotics for\nlocalisation and integration of multi-session or multi-robot data. Traditional\nmethods rely on cameras or LiDARs to capture visual or geometric information\nbut struggle in challenging conditions like smoke or dust. Magnetometers, on\nthe other hand, detect magnetic fields, revealing features invisible to other\nsensors and remaining robust in such environments. In this paper, we introduce\nMag-Match, a novel method for extracting and describing features in 3D magnetic\nvector field maps to register different maps of the same area. Our feature\ndescriptor, based on higher-order derivatives of magnetic field maps, is\ninvariant to global orientation, eliminating the need for gravity-aligned\nmapping. To obtain these higher-order derivatives map-wide given point-wise\nmagnetometer data, we leverage a physics-informed Gaussian Process to perform\nefficient and recursive probabilistic inference of both the magnetic field and\nits derivatives. We evaluate Mag-Match in simulated and real-world experiments\nagainst a SIFT-based approach, demonstrating accurate map-to-map, robot-to-map,\nand robot-to-robot transformations - even without initial gravitational\nalignment.", "AI": {"tldr": "Mag-Match introduces a magnetometer-based map matching/descriptors for 3D magnetic vector field maps, using a physics-informed Gaussian Process to compute higher-order derivatives, yielding gravity-orientation-invariant registration without gravity alignment.", "motivation": "Robust map registration in smoke/dust environments where visual/Geometric sensors fail. Magnetometers capture features invisible to cameras/LiDAR and enable gravity-invariant, robust localization and multi-robot data fusion.", "method": "Extract and describe features from 3D magnetic vector field maps using higher-order derivatives. Use a physics-informed Gaussian Process to infer the magnetic field and its derivatives across the map, enabling efficient, recursive probabilistic inference. Derive a gravity-invariant descriptor that does not require gravity alignment. Perform map-wide derivative estimation from point-wise magnetometer data.", "result": "Evaluated on simulated and real-world data against a SIFT-based baseline. Demonstrates accurate map-to-map, robot-to-map, and robot-to-robot transformations without initial gravity alignment, showing robustness in challenging environments.", "conclusion": "Mag-Match demonstrates effective magnetometer-based map registration with gravity-invariant descriptors and GP-based derivative inference, enabling robust localization and data fusion in environments where vision-based methods struggle."}}
{"id": "2508.14955", "categories": ["cs.LG", "cs.AI", "cs.ET", "cs.NE", "quant-ph"], "pdf": "https://arxiv.org/pdf/2508.14955", "abs": "https://arxiv.org/abs/2508.14955", "authors": ["Samuel Yen-Chi Chen", "Prayag Tiwari"], "title": "Quantum Long Short-term Memory with Differentiable Architecture Search", "comment": "Accepted by the IEEE International Conference on Quantum Artificial\n  Intelligence (QAI) 2025", "summary": "Recent advances in quantum computing and machine learning have given rise to\nquantum machine learning (QML), with growing interest in learning from\nsequential data. Quantum recurrent models like QLSTM are promising for\ntime-series prediction, NLP, and reinforcement learning. However, designing\neffective variational quantum circuits (VQCs) remains challenging and often\ntask-specific. To address this, we propose DiffQAS-QLSTM, an end-to-end\ndifferentiable framework that optimizes both VQC parameters and architecture\nselection during training. Our results show that DiffQAS-QLSTM consistently\noutperforms handcrafted baselines, achieving lower loss across diverse test\nsettings. This approach opens the door to scalable and adaptive quantum\nsequence learning.", "AI": {"tldr": "End-to-end differentiable optimization of both VQC parameters and architecture in DiffQAS-QLSTM leads to improved performance on quantum sequence learning over handcrafted baselines.", "motivation": "There is strong interest in QML for sequential data, but designing effective VQCs is hard and often task-specific; an end-to-end approach could jointly optimize parameters and architecture for scalable adaptive quantum sequence models.", "method": "Introduce DiffQAS-QLSTM, an end-to-end differentiable framework that jointly optimizes VQC parameters and architecture selection during training for quantum recurrent models (QLSTM).", "result": "DiffQAS-QLSTM consistently achieves lower loss than handcrafted baselines across diverse test settings.", "conclusion": "This framework enables scalable, adaptive quantum sequence learning by integrating architecture search with parameter optimization."}}
{"id": "2508.15057", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15057", "abs": "https://arxiv.org/abs/2508.15057", "authors": ["Toqi Tahamid Sarker", "Mohamed Embaby", "Taminul Islam", "Amer AbuGhazaleh", "Khaled R Ahmed"], "title": "GasTwinFormer: A Hybrid Vision Transformer for Livestock Methane Emission Segmentation and Dietary Classification in Optical Gas Imaging", "comment": "Accepted for publication at ICCVW 2025", "summary": "Livestock methane emissions represent 32% of human-caused methane production,\nmaking automated monitoring critical for climate mitigation strategies. We\nintroduce GasTwinFormer, a hybrid vision transformer for real-time methane\nemission segmentation and dietary classification in optical gas imaging through\na novel Mix Twin encoder alternating between spatially-reduced global attention\nand locally-grouped attention mechanisms. Our architecture incorporates a\nlightweight LR-ASPP decoder for multi-scale feature aggregation and enables\nsimultaneous methane segmentation and dietary classification in a unified\nframework. We contribute the first comprehensive beef cattle methane emission\ndataset using OGI, containing 11,694 annotated frames across three dietary\ntreatments. GasTwinFormer achieves 74.47% mIoU and 83.63% mF1 for segmentation\nwhile maintaining exceptional efficiency with only 3.348M parameters, 3.428G\nFLOPs, and 114.9 FPS inference speed. Additionally, our method achieves perfect\ndietary classification accuracy (100%), demonstrating the effectiveness of\nleveraging diet-emission correlations. Extensive ablation studies validate each\narchitectural component, establishing GasTwinFormer as a practical solution for\nreal-time livestock emission monitoring. Please see our project page at\ngastwinformer.github.io.", "AI": {"tldr": "GasTwinFormer is a lightweight hybrid transformer for real-time methane emission segmentation and dietary classification in optical gas imaging, achieving high accuracy with a small model on a new beef cattle dataset.", "motivation": "Livestock methane accounts for a large share of anthropogenic methane; automated, real-time monitoring is critical for effective climate mitigation and management.", "method": "Introduces GasTwinFormer with a Mix Twin encoder that alternates spatially-reduced global attention and locally-grouped attention, plus a lightweight LR-ASPP decoder for multi-scale feature aggregation. Supports simultaneous methane segmentation and dietary classification in a unified framework. Builds the first comprehensive beef cattle methane emission dataset (11,694 annotated frames across three diets).", "result": "Segmentation: 74.47% mIoU and 83.63% mF1. Efficiency: 3.348M parameters, 3.428 GFLOPs, 114.9 FPS. Diet classification: 100% accuracy. Dataset enables diet-emission correlation analysis. Extensive ablations validate architectural components.", "conclusion": "GasTwinFormer offers a practical solution for real-time livestock emission monitoring and introduces a valuable dataset for diet-emission studies, demonstrating strong performance with efficiency suitable for field deployment."}}
{"id": "2508.15068", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15068", "abs": "https://arxiv.org/abs/2508.15068", "authors": ["Shuang Ao", "Gopal Rumchurn"], "title": "S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner", "comment": "9 pages, 2 figures", "summary": "Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning\n(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based\nagents. However, these adaptations can unintentionally compromise safety\nalignment, leading to unsafe or unstable behaviors, particularly in agent\nplanning tasks. Existing safety-aware adaptation methods often require access\nto both base and instruction-tuned model checkpoints, which are frequently\nunavailable in practice, limiting their applicability. We propose S3LoRA (Safe\nSpectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and\nmodel-independent framework that mitigates safety risks in LoRA-adapted models\nby inspecting only the fine-tuned weight updates. We first introduce\nMagnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes\nthe structural properties of LoRA updates while preserving global magnitude\ninformation. We then design the Spectral Sharpness Index (SSI), a\nsharpness-aware metric to detect layers with highly concentrated and\npotentially unsafe updates. These layers are pruned post-hoc to reduce risk\nwithout sacrificing task performance. Extensive experiments and ablation\nstudies across agent planning and language generation tasks show that S3LoRA\nconsistently improves safety metrics while maintaining or improving utility\nmetrics and significantly reducing inference cost. These results establish\nS3LoRA as a practical and scalable solution for safely deploying LLM-based\nagents in real-world, resource-constrained, and safety-critical environments.", "AI": {"tldr": "A data-free, model-independent safety-enhancement method for PEFT LoRA-based LLMs, S3LoRA, that prunes risky updates via MAS-SVD and SSI to improve safety without harming performance.", "motivation": "Safety risks emerge when adapting LLMs with PEFT techniques like LoRA, especially in planning tasks; existing safety methods rely on base and instruction-tuned checkpoints that are often unavailable, hindering practical deployment.", "method": "Introduce MAS-SVD to analyze the structural properties of LoRA updates while preserving global magnitudes. Propose Spectral Sharpness Index (SSI) to identify layers with highly concentrated updates that may be unsafe. Apply post-hoc pruning of those layers to reduce safety risk while maintaining task performance; data-free and model-independent.", "result": "Experiments across agent planning and language generation tasks show that S3LoRA improves safety metrics while maintaining or improving utility metrics and reduces inference cost; ablations support the importance of MAS-SVD and SSI.", "conclusion": "S3LoRA offers a practical, scalable, data-free safety mechanism for LoRA-adapted LLMs, enabling safer deployment in resource-constrained and safety-critical environments."}}
{"id": "2508.15354", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15354", "abs": "https://arxiv.org/abs/2508.15354", "authors": ["Chaoran Xiong", "Yulong Huang", "Fangwen Yu", "Changhao Chen", "Yue Wang", "Songpengchen Xia", "Ling Pei"], "title": "Sensing, Social, and Motion Intelligence in Embodied Navigation: A Comprehensive Survey", "comment": null, "summary": "Embodied navigation (EN) advances traditional navigation by enabling robots\nto perform complex egocentric tasks through sensing, social, and motion\nintelligence. In contrast to classic methodologies that rely on explicit\nlocalization and pre-defined maps, EN leverages egocentric perception and\nhuman-like interaction strategies. This survey introduces a comprehensive EN\nformulation structured into five stages: Transition, Observation, Fusion,\nReward-policy construction, and Action (TOFRA). The TOFRA framework serves to\nsynthesize the current state of the art, provide a critical review of relevant\nplatforms and evaluation metrics, and identify critical open research\nchallenges. A list of studies is available at\nhttps://github.com/Franky-X/Awesome-Embodied-Navigation.", "AI": {"tldr": "A survey of Embodied Navigation (EN) framed by the TOFRA five-stage model, organizing current work, platforms, and metrics, and pointing to a GitHub resource; highlights open challenges.", "motivation": "EN enables robots to perform egocentric tasks using sensing, social, and motion intelligence, addressing limitations of traditional localization and pre-defined maps.", "method": "Proposes TOFRA (Transition, Observation, Fusion, Reward-policy construction, Action) as a unifying formulation; conducts a critical review of the literature, platforms, and evaluation metrics; synthesizes findings and identifies gaps; provides a compiled study list at GitHub (https://github.com/Franky-X/Awesome-Embodied-Navigation).", "result": "Provides a structured synthesis of the EN state-of-the-art, including platforms and evaluation metrics; identifies key challenges and directions for future work; offers a centralized resource for researchers.", "conclusion": "TOFRA offers a coherent framework to structure and advance Embodied Navigation; the field is evolving with open research challenges; the linked GitHub resource serves as a comprehensive reference for researchers."}}
{"id": "2508.14957", "categories": ["cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2508.14957", "abs": "https://arxiv.org/abs/2508.14957", "authors": ["Anurup Naskar", "Nathanael Zhixin Wong", "Sara Shamekh"], "title": "CuMoLoS-MAE: A Masked Autoencoder for Remote Sensing Data Reconstruction", "comment": "4 pages, 2 figures", "summary": "Accurate atmospheric profiles from remote sensing instruments such as Doppler\nLidar, Radar, and radiometers are frequently corrupted by low-SNR (Signal to\nNoise Ratio) gates, range folding, and spurious discontinuities. Traditional\ngap filling blurs fine-scale structures, whereas deep models lack confidence\nestimates. We present CuMoLoS-MAE, a Curriculum-Guided Monte Carlo Stochastic\nEnsemble Masked Autoencoder designed to (i) restore fine-scale features such as\nupdraft and downdraft cores, shear lines, and small vortices, (ii) learn a\ndata-driven prior over atmospheric fields, and (iii) quantify pixel-wise\nuncertainty. During training, CuMoLoS-MAE employs a mask-ratio curriculum that\nforces a ViT decoder to reconstruct from progressively sparser context. At\ninference, we approximate the posterior predictive by Monte Carlo over random\nmask realisations, evaluating the MAE multiple times and aggregating the\noutputs to obtain the posterior predictive mean reconstruction together with a\nfinely resolved per-pixel uncertainty map. Together with high-fidelity\nreconstruction, this novel deep learning-based workflow enables enhanced\nconvection diagnostics, supports real-time data assimilation, and improves\nlong-term climate reanalysis.", "AI": {"tldr": "A curriculum-guided masked autoencoder with Monte Carlo ensemble (CuMoLoS-MAE) restores fine-scale atmospheric features from noisy remote sensing data, learns a data-driven prior, and provides pixel-wise uncertainty via posterior predictive estimation.", "motivation": "Remote-sensing atmospheric profiles suffer from low SNR, range folding, and discontinuities. Conventional gap-filling blurs fine details and standard deep models lack uncertainty estimates; there is a need for high-fidelity reconstructions with quantified confidence to improve diagnostics and data assimilation.", "method": "CuMoLoS-MAE uses a Vision Transformer-based masked autoencoder trained with a mask-ratio curriculum that forces reconstruction from progressively sparser context. During inference, it performs Monte Carlo estimation over random mask realizations to approximate the posterior predictive, yielding a mean reconstruction and per-pixel uncertainty maps.", "result": "The approach achieves high-fidelity restoration of fine-scale features (updraft/downdraft cores, shear lines, small vortices), learns a data-driven atmospheric prior, and provides calibrated per-pixel uncertainty. It supports enhanced convection diagnostics, real-time data assimilation, and improved long-term climate reanalysis.", "conclusion": "A novel DL workflow that combines curriculum-guided masked autoencoding with Monte Carlo masking to deliver accurate atmospheric reconstructions with uncertainty quantification, enabling improved diagnostics and assimilation in atmospheric remote sensing."}}
{"id": "2508.15093", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15093", "abs": "https://arxiv.org/abs/2508.15093", "authors": ["Yan Luo", "Drake Du", "Hao Huang", "Yi Fang", "Mengyu Wang"], "title": "CurveFlow: Curvature-Guided Flow Matching for Image Generation", "comment": null, "summary": "Existing rectified flow models are based on linear trajectories between data\nand noise distributions. This linearity enforces zero curvature, which can\ninadvertently force the image generation process through low-probability\nregions of the data manifold. A key question remains underexplored: how does\nthe curvature of these trajectories correlate with the semantic alignment\nbetween generated images and their corresponding captions, i.e., instructional\ncompliance? To address this, we introduce CurveFlow, a novel flow matching\nframework designed to learn smooth, non-linear trajectories by directly\nincorporating curvature guidance into the flow path. Our method features a\nrobust curvature regularization technique that penalizes abrupt changes in the\ntrajectory's intrinsic dynamics.Extensive experiments on MS COCO 2014 and 2017\ndemonstrate that CurveFlow achieves state-of-the-art performance in\ntext-to-image generation, significantly outperforming both standard rectified\nflow variants and other non-linear baselines like Rectified Diffusion. The\nimprovements are especially evident in semantic consistency metrics such as\nBLEU, METEOR, ROUGE, and CLAIR. This confirms that our curvature-aware modeling\nsubstantially enhances the model's ability to faithfully follow complex\ninstructions while simultaneously maintaining high image quality. The code is\nmade publicly available at\nhttps://github.com/Harvard-AI-and-Robotics-Lab/CurveFlow.", "AI": {"tldr": "CurveFlow introduces curvature-aware non-linear trajectory learning for flow-based text-to-image generation, achieving state-of-the-art semantic alignment on COCO by regularizing trajectory curvature.", "motivation": "Rectified flow models use linear trajectories with zero curvature, which can push samples through low-probability regions and misalign with complex captions. Curvature might drive better instruction compliance.", "method": "Propose CurveFlow, a flow-matching framework that enforces smooth, non-linear trajectories via a curvature regularization term; penalizes abrupt changes in intrinsic dynamics while guiding the flow path with curvature cues; evaluated on MS COCO 2014/2017.", "result": "Achieves state-of-the-art text-to-image generation on COCO; outperforms standard rectified flows and non-linear baselines (e.g., Rectified Diffusion); notable gains in semantic metrics (BLEU, METEOR, ROUGE, CLAIR); code released.", "conclusion": "Curvature-aware trajectory modeling substantially enhances semantic fidelity and instruction compliance without sacrificing image quality."}}
{"id": "2508.15118", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15118", "abs": "https://arxiv.org/abs/2508.15118", "authors": ["Jennifer Leigh", "Dimitrios Letsios", "Alessandro Mella", "Lucio Machetti", "Francesca Toni"], "title": "Argumentation for Explainable Workforce Optimisation (with Appendix)", "comment": "Accepted to PAIS 2025", "summary": "Workforce management is a complex problem optimising the makespan and travel\ndistance required for a team of operators to complete a set of jobs, using a\nset of instruments. A crucial challenge in workforce management is\naccommodating changes at execution time so that explanations are provided to\nall stakeholders involved. Here, we show that, by understanding workforce\nmanagement as abstract argumentation in an industrial application, we can\naccommodate change and obtain faithful explanations. We show, with a user\nstudy, that our tool and explanations lead to faster and more accurate problem\nsolving than conventional solutions by hand.", "AI": {"tldr": "Model workforce management as abstract argumentation to handle execution-time changes and explain decisions; user study shows faster, more accurate problem solving than manual methods.", "motivation": "Dynamic execution-time changes and the need for faithful explanations to stakeholders in workforce planning.", "method": "Represent the problem using abstract argumentation frameworks within an industrial tool; generate explanations; conduct a user study comparing against conventional solutions.", "result": "The approach yields faster and more accurate problem solving; explanations are perceived as more faithful by users; improved stakeholder communication.", "conclusion": "Abstract argumentation is a viable framework for dynamic workforce management with interpretable explanations; potential for broader adoption in industry."}}
{"id": "2508.15427", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15427", "abs": "https://arxiv.org/abs/2508.15427", "authors": ["Huy Hoang Nguyen", "Johannes Huemer", "Markus Murschitz", "Tobias Glueck", "Minh Nhat Vu", "Andreas Kugi"], "title": "Lang2Lift: A Framework for Language-Guided Pallet Detection and Pose Estimation Integrated in Autonomous Outdoor Forklift Operation", "comment": "8 pages, 7 figures", "summary": "The logistics and construction industries face persistent challenges in\nautomating pallet handling, especially in outdoor environments with variable\npayloads, inconsistencies in pallet quality and dimensions, and unstructured\nsurroundings. In this paper, we tackle automation of a critical step in pallet\ntransport: the pallet pick-up operation. Our work is motivated by labor\nshortages, safety concerns, and inefficiencies in manually locating and\nretrieving pallets under such conditions. We present Lang2Lift, a framework\nthat leverages foundation models for natural language-guided pallet detection\nand 6D pose estimation, enabling operators to specify targets through intuitive\ncommands such as \"pick up the steel beam pallet near the crane.\" The perception\npipeline integrates Florence-2 and SAM-2 for language-grounded segmentation\nwith FoundationPose for robust pose estimation in cluttered, multi-pallet\noutdoor scenes under variable lighting. The resulting poses feed into a motion\nplanning module for fully autonomous forklift operation. We validate Lang2Lift\non the ADAPT autonomous forklift platform, achieving 0.76 mIoU pallet\nsegmentation accuracy on a real-world test dataset. Timing and error analysis\ndemonstrate the system's robustness and confirm its feasibility for deployment\nin operational logistics and construction environments. Video demonstrations\nare available at https://eric-nguyen1402.github.io/lang2lift.github.io/", "AI": {"tldr": "Lang2Lift introduces a language-guided perception and 6D pose estimation pipeline for autonomous pallet pickup in outdoor settings, integrating foundation models (Florence-2, SAM-2) with FoundationPose, enabling natural-language command execution and autonomous forklift operation; achieves 0.76 mIoU pallet segmentation on real data and shows feasibility for deployment.", "motivation": "Address labor shortages, safety concerns, and inefficiencies in manually locating and retrieving pallets in outdoor, unstructured environments with variable payloads and pallet quality/dimensions.", "method": "A perception pipeline that uses language-grounded segmentation (Florence-2 + SAM-2) and a robust 6D pose estimator (FoundationPose) to detect and localize pallets described by natural language commands (e.g., \u201cpick up the steel beam pallet near the crane\u201d), followed by integration into a motion planning module for autonomous forklift control. Validation on the ADAPT autonomous forklift platform with real-world test data and timing/error analyses.", "result": "Achieves 0.76 mIoU pallet segmentation accuracy on real-world data; robust pose estimation in cluttered outdoor scenes under variable lighting; timing and error analyses indicate robustness and deployment feasibility; video demonstrations available.", "conclusion": "Lang2Lift demonstrates the feasibility of natural-language-guided pallet pickup in practical logistics/construction environments by bridging language-grounded perception with reliable 6D pose estimation and autonomous motion planning, suggesting potential for deployment and further real-world validation."}}
{"id": "2508.14976", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.14976", "abs": "https://arxiv.org/abs/2508.14976", "authors": ["Joydeep Chandra", "Prabal Manhas", "Ramanjot Kaur", "Rashi Sahay"], "title": "Aura-CAPTCHA: A Reinforcement Learning and GAN-Enhanced Multi-Modal CAPTCHA System", "comment": null, "summary": "Aura-CAPTCHA was developed as a multi-modal CAPTCHA system to address\nvulnerabilities in traditional methods that are increasingly bypassed by AI\ntechnologies, such as Optical Character Recognition (OCR) and adversarial image\nprocessing. The design integrated Generative Adversarial Networks (GANs) for\ngenerating dynamic image challenges, Reinforcement Learning (RL) for adaptive\ndifficulty tuning, and Large Language Models (LLMs) for creating text and audio\nprompts. Visual challenges included 3x3 grid selections with at least three\ncorrect images, while audio challenges combined randomized numbers and words\ninto a single task. RL adjusted difficulty based on incorrect attempts,\nresponse time, and suspicious user behavior. Evaluations on real-world traffic\ndemonstrated a 92% human success rate and a 10% bot bypass rate, significantly\noutperforming existing CAPTCHA systems. The system provided a robust and\nscalable approach for securing online applications while remaining accessible\nto users, addressing gaps highlighted in previous research.", "AI": {"tldr": "Aura-CAPTCHA uses GAN-generated dynamic image challenges, RL-based difficulty tuning, and LLM-generated prompts to create a multi-modal CAPTCHA that improves resilience against AI-based bypassing, achieving 92% human success and 10% bot bypass in real-world traffic.", "motivation": "Traditional CAPTCHAs are increasingly vulnerable to AI-based bypasses (OCR, adversarial image processing). There is a need for robust, scalable, multi-modal CAPTCHAs that adapt to user behavior while remaining accessible.", "method": "GANs generate dynamic image challenges; RL tunes difficulty based on incorrect attempts, response time, and suspicious behavior; LLMs produce text and audio prompts. Visual challenges: 3x3 grid with at least three correct images. Audio challenges mix randomized numbers and words in a single task. Evaluated on real-world traffic with measured human success and bot bypass rates.", "result": "97?", "conclusion": "Aura-CAPTCHA provides a robust, scalable multi-modal CAPTCHA leveraging GANs, RL, and LLMs to enhance resilience to automation while remaining accessible. Real-world results show high human success and low bot bypass, outperforming traditional CAPTCHA systems."}}
{"id": "2508.15130", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15130", "abs": "https://arxiv.org/abs/2508.15130", "authors": ["Vaishnav Ramesh", "Haining Wang", "Md Jahidul Islam"], "title": "HiRQA: Hierarchical Ranking and Quality Alignment for Opinion-Unaware Image Quality Assessment", "comment": "10 pages, 8 figures", "summary": "Despite significant progress in no-reference image quality assessment\n(NR-IQA), dataset biases and reliance on subjective labels continue to hinder\ntheir generalization performance. We propose HiRQA, Hierarchical Ranking and\nQuality Alignment), a self-supervised, opinion-unaware framework that offers a\nhierarchical, quality-aware embedding through a combination of ranking and\ncontrastive learning. Unlike prior approaches that depend on pristine\nreferences or auxiliary modalities at inference time, HiRQA predicts quality\nscores using only the input image. We introduce a novel higher-order ranking\nloss that supervises quality predictions through relational ordering across\ndistortion pairs, along with an embedding distance loss that enforces\nconsistency between feature distances and perceptual differences. A\ntraining-time contrastive alignment loss, guided by structured textual prompts,\nfurther enhances the learned representation. Trained only on synthetic\ndistortions, HiRQA generalizes effectively to authentic degradations, as\ndemonstrated through evaluation on various distortions such as lens flare,\nhaze, motion blur, and low-light conditions. For real-time deployment, we\nintroduce \\textbf{HiRQA-S}, a lightweight variant with an inference time of\nonly 3.5 ms per image. Extensive experiments across synthetic and authentic\nbenchmarks validate HiRQA's state-of-the-art (SOTA) performance, strong\ngeneralization ability, and scalability.", "AI": {"tldr": "HiRQA is a self-supervised, no-reference IQA framework using hierarchical ranking and quality alignment to learn quality-aware embeddings from synthetic distortions, achieving SOTA generalization to authentic degradations and enabling a fast HiRQA-S variant (3.5 ms per image).", "motivation": "NR-IQA suffers from dataset biases and reliance on subjective labels, which harms generalization. A pristine-reference-free, opinion-unaware approach with robust cross-distortion generalization is needed.", "method": "A self-supervised framework that combines higher-order ranking loss over distortion pairs, an embedding distance loss aligning feature distances with perceptual differences, and a training-time contrastive alignment loss guided by structured textual prompts. Trains only on synthetic distortions and predicts quality scores using only the input image. A lightweight HiRQA-S variant provides real-time inference (~3.5 ms/image).", "result": "HiRQA generalizes effectively to authentic degradations (lens flare, haze, motion blur, low-light) and achieves state-of-the-art performance on both synthetic and authentic IQA benchmarks, with strong generalization and scalability.", "conclusion": "HiRQA offers a no-reference, opinion-unaware, hierarchical quality representation that generalizes from synthetic to real-world distortions, and delivers scalable, real-time inference via HiRQA-S."}}
{"id": "2508.15119", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2508.15119", "abs": "https://arxiv.org/abs/2508.15119", "authors": ["Rachel Ma", "Jingyi Qu", "Andreea Bobu", "Dylan Hadfield-Menell"], "title": "Open-Universe Assistance Games", "comment": "7 pages + 2 pages references + 7 pages appendix", "summary": "Embodied AI agents must infer and act in an interpretable way on diverse\nhuman goals and preferences that are not predefined. To formalize this setting,\nwe introduce Open-Universe Assistance Games (OU-AGs), a framework where the\nagent must reason over an unbounded and evolving space of possible goals. In\nthis context, we introduce GOOD (GOals from Open-ended Dialogue), a\ndata-efficient, online method that extracts goals in the form of natural\nlanguage during an interaction with a human, and infers a distribution over\nnatural language goals. GOOD prompts an LLM to simulate users with different\ncomplex intents, using its responses to perform probabilistic inference over\ncandidate goals. This approach enables rich goal representations and\nuncertainty estimation without requiring large offline datasets. We evaluate\nGOOD in a text-based grocery shopping domain and in a text-operated simulated\nhousehold robotics environment (AI2Thor), using synthetic user profiles. Our\nmethod outperforms a baseline without explicit goal tracking, as confirmed by\nboth LLM-based and human evaluations.", "AI": {"tldr": "Introduces Open-Universe Assistance Games (OU-AGs) and GOOD for online, data-efficient goal inference from open-ended dialogue via LLM-based simulation and probabilistic reasoning; validated in text-based grocery and AI2Thor with synthetic users; outperforms a baseline lacking goal tracking.", "motivation": "AI agents must operate in open-ended, evolving spaces of human goals and preferences that are not predefined. This requires interpretable representations and uncertainty estimation, and cannot rely on large offline datasets.", "method": "Formalize Open-Universe Assistance Games (OU-AGs) and present GOOD (GOals from Open-ended Dialogue), an online, data-efficient method. GOOD prompts an LLM to simulate users with diverse intents; uses their responses to perform probabilistic inference over candidate natural-language goals, yielding a distribution over goals without large offline data.", "result": "Empirically, GOOD outperforms a baseline that does not explicitly track goals. Evaluation uses text-based grocery shopping and AI2Thor with synthetic user profiles, with assessments from both LLMs and human evaluators.", "conclusion": "GOOD enables rich, interpretable goal representations and uncertainty estimation in open-ended settings without large offline datasets, improving interpretability and performance; suggests promise for scalable, open-world AI assistance and motivates future real-user studies and broader domain tests."}}
{"id": "2508.15501", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15501", "abs": "https://arxiv.org/abs/2508.15501", "authors": ["Deyu Zhang", "Xicheng Zhang", "Jiahao Li", "Tingting Long", "Xunhua Dai", "Yongjian Fu", "Jinrui Zhang", "Ju Ren", "Yaoxue Zhang"], "title": "LLM-Driven Self-Refinement for Embodied Drone Task Planning", "comment": "14pages", "summary": "We introduce SRDrone, a novel system designed for self-refinement task\nplanning in industrial-grade embodied drones. SRDrone incorporates two key\ntechnical contributions: First, it employs a continuous state evaluation\nmethodology to robustly and accurately determine task outcomes and provide\nexplanatory feedback. This approach supersedes conventional reliance on\nsingle-frame final-state assessment for continuous, dynamic drone operations.\nSecond, SRDrone implements a hierarchical Behavior Tree (BT) modification\nmodel. This model integrates multi-level BT plan analysis with a constrained\nstrategy space to enable structured reflective learning from experience.\nExperimental results demonstrate that SRDrone achieves a 44.87% improvement in\nSuccess Rate (SR) over baseline methods. Furthermore, real-world deployment\nutilizing an experience base optimized through iterative self-refinement\nattains a 96.25% SR. By embedding adaptive task refinement capabilities within\nan industrial-grade BT planning framework, SRDrone effectively integrates the\ngeneral reasoning intelligence of Large Language Models (LLMs) with the\nstringent physical execution constraints inherent to embodied drones. Code is\navailable at https://github.com/ZXiiiC/SRDrone.", "AI": {"tldr": "SRDrone introduces self-refinement task planning for industrial drones via continuous state evaluation and a hierarchical BT modification model to enable reflective learning, achieving substantial SR gains in simulation and real-world deployment.", "motivation": "Motivated by the inadequacy of single-frame final-state checks for continuous, dynamic drone operations and the need to combine general reasoning (LLMs) with stringent physical constraints in embodied drones.", "method": "1) A continuous state evaluation method to determine task outcomes with explanatory feedback; 2) A hierarchical Behavior Tree (BT) modification model that analyzes BT plans at multiple levels within a constrained strategy space to support reflective learning from experience.", "result": "SRDrone yields a 44.87% improvement in Success Rate (SR) over baselines; real-world deployment with an improved experience base reaches 96.25% SR.", "conclusion": "Embedding adaptive task refinement in an industrial BT planning framework enables integrating LLM-level reasoning with physical execution constraints, showing strong performance gains; code is available at the provided GitHub link."}}
{"id": "2508.14995", "categories": ["cs.LG", "cs.NA", "math.NA", "math.OC", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2508.14995", "abs": "https://arxiv.org/abs/2508.14995", "authors": ["Anastasis Kratsios", "Ariel Neufeld", "Philipp Schmocker"], "title": "Generative Neural Operators of Log-Complexity Can Simultaneously Solve Infinitely Many Convex Programs", "comment": null, "summary": "Neural operators (NOs) are a class of deep learning models designed to\nsimultaneously solve infinitely many related problems by casting them into an\ninfinite-dimensional space, whereon these NOs operate. A significant gap\nremains between theory and practice: worst-case parameter bounds from universal\napproximation theorems suggest that NOs may require an unrealistically large\nnumber of parameters to solve most operator learning problems, which stands in\ndirect opposition to a slew of experimental evidence. This paper closes that\ngap for a specific class of {NOs}, generative {equilibrium operators} (GEOs),\nusing (realistic) finite-dimensional deep equilibrium layers, when solving\nfamilies of convex optimization problems over a separable Hilbert space $X$.\nHere, the inputs are smooth, convex loss functions on $X$, and outputs are the\nassociated (approximate) solutions to the optimization problem defined by each\ninput loss.\n  We show that when the input losses lie in suitable infinite-dimensional\ncompact sets, our GEO can uniformly approximate the corresponding solutions to\narbitrary precision, with rank, depth, and width growing only logarithmically\nin the reciprocal of the approximation error. We then validate both our\ntheoretical results and the trainability of GEOs on three applications: (1)\nnonlinear PDEs, (2) stochastic optimal control problems, and (3) hedging\nproblems in mathematical finance under liquidity constraints.", "AI": {"tldr": "GEOs are finite-dimensional deep equilibrium operators designed to uniformly approximate solutions to a family of convex optimization problems over infinite-dimensional spaces, with logarithmic growth in network size relative to accuracy, bridging theory-practice gap in neural operators.", "motivation": "Address the gap between worst-case universal approximation bounds (which imply many parameters) and practical evidence of efficiency in neural operators by focusing on a concrete, realizable class (generative equilibrium operators) for convex problems in Hilbert spaces.", "method": "Introduce Generative Equilibrium Operators (GEOs) built from finite-dimensional deep equilibrium layers. Inputs are smooth convex loss functions on a separable Hilbert space X; outputs are approximate solutions to the corresponding optimization problem. Prove uniform approximation of the solutions for losses lying in suitable infinite-dimensional compact sets, with rank/depth/width growing only logarithmically in 1/\u03b5. Validate theory and trainability on three applications: nonlinear PDEs, stochastic optimal control, and liquidity-constrained hedging in finance.", "result": "Theoretical result: uniform approximation with logarithmic growth in model complexity. Empirical validation across three domains\u2014nonlinear PDEs, stochastic control, and finance hedging\u2014demonstrating trainability and practical performance.", "conclusion": "GEOs can close the theory-practice gap for a class of neural operators by providing scalable, finite-dimensional, trainable models that uniformly approximate solutions to a broad family of convex optimization problems in infinite-dimensional spaces."}}
{"id": "2508.15158", "categories": ["cs.CV", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.15158", "abs": "https://arxiv.org/abs/2508.15158", "authors": ["Md. Nurul Absur", "Abhinav Kumar", "Swastik Brahma", "Saptarshi Debroy"], "title": "Reliable Multi-view 3D Reconstruction for `Just-in-time' Edge Environments", "comment": "11 Pages, 7 Figures", "summary": "Multi-view 3D reconstruction applications are revolutionizing critical use\ncases that require rapid situational-awareness, such as emergency response,\ntactical scenarios, and public safety. In many cases, their near-real-time\nlatency requirements and ad-hoc needs for compute resources necessitate\nadoption of `Just-in-time' edge environments where the system is set up on the\nfly to support the applications during the mission lifetime. However,\nreliability issues can arise from the inherent dynamism and operational\nadversities of such edge environments, resulting in spatiotemporally correlated\ndisruptions that impact the camera operations, which can lead to sustained\ndegradation of reconstruction quality. In this paper, we propose a novel\nportfolio theory inspired edge resource management strategy for reliable\nmulti-view 3D reconstruction against possible system disruptions. Our proposed\nmethodology can guarantee reconstruction quality satisfaction even when the\ncameras are prone to spatiotemporally correlated disruptions. The portfolio\ntheoretic optimization problem is solved using a genetic algorithm that\nconverges quickly for realistic system settings. Using publicly available and\ncustomized 3D datasets, we demonstrate the proposed camera selection strategy's\nbenefits in guaranteeing reliable 3D reconstruction against traditional\nbaseline strategies, under spatiotemporal disruptions.", "AI": {"tldr": "Portfolio-theory\u2013inspired edge resource management for reliable multi-view 3D reconstruction under spatiotemporal disruptions, solved with a genetic algorithm.", "motivation": "Emergency response, tactical, and public-safety applications require near-real-time multi-view reconstruction in ad-hoc edge environments. Spatiotemporal disruptions cause camera failures and degrade reconstruction quality, and existing strategies lack reliability guarantees.", "method": "Formulates camera selection and edge resource allocation as a portfolio-optimization problem using portfolio theory to balance reconstruction quality against disruption risk; solves the optimization with a genetic algorithm that converges quickly in realistic settings; evaluates on public and customized 3D datasets.", "result": "Demonstrates improved reliability of 3D reconstruction under correlated disruptions compared with traditional baselines; the GA-based solution achieves fast convergence and practical performance on realistic datasets.", "conclusion": "A practical, fast-converging approach to guarantee reconstruction quality under adverse, dynamic edge conditions, enabling reliable multi-view 3D reconstruction in ad-hoc edge deployments."}}
{"id": "2508.15126", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15126", "abs": "https://arxiv.org/abs/2508.15126", "authors": ["Pengsong Zhang", "Xiang Hu", "Guowei Huang", "Yang Qi", "Heng Zhang", "Xiuxu Li", "Jiaxing Song", "Jiabin Luo", "Yijiang Li", "Shuo Yin", "Chengxiao Dai", "Eric Hanchen Jiang", "Xiaoyan Zhou", "Zhenfei Yin", "Boqin Yuan", "Jing Dong", "Guinan Su", "Guanren Qiao", "Haiming Tang", "Anghong Du", "Lili Pan", "Zhenzhong Lan", "Xinyu Liu"], "title": "aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists", "comment": "Preprint under review. Code is available at\n  https://github.com/aixiv-org. Website is available at\n  https://forms.gle/DxQgCtXFsJ4paMtn8", "summary": "Recent advances in large language models (LLMs) have enabled AI agents to\nautonomously generate scientific proposals, conduct experiments, author papers,\nand perform peer reviews. Yet this flood of AI-generated research content\ncollides with a fragmented and largely closed publication ecosystem.\nTraditional journals and conferences rely on human peer review, making them\ndifficult to scale and often reluctant to accept AI-generated research content;\nexisting preprint servers (e.g. arXiv) lack rigorous quality-control\nmechanisms. Consequently, a significant amount of high-quality AI-generated\nresearch lacks appropriate venues for dissemination, hindering its potential to\nadvance scientific progress. To address these challenges, we introduce aiXiv, a\nnext-generation open-access platform for human and AI scientists. Its\nmulti-agent architecture allows research proposals and papers to be submitted,\nreviewed, and iteratively refined by both human and AI scientists. It also\nprovides API and MCP interfaces that enable seamless integration of\nheterogeneous human and AI scientists, creating a scalable and extensible\necosystem for autonomous scientific discovery. Through extensive experiments,\nwe demonstrate that aiXiv is a reliable and robust platform that significantly\nenhances the quality of AI-generated research proposals and papers after\niterative revising and reviewing on aiXiv. Our work lays the groundwork for a\nnext-generation open-access ecosystem for AI scientists, accelerating the\npublication and dissemination of high-quality AI-generated research content.\nCode is available at https://github.com/aixiv-org. Website is available at\nhttps://forms.gle/DxQgCtXFsJ4paMtn8.", "AI": {"tldr": "aiXiv proposes an open-access, multi-agent platform enabling human and AI scientists to submit, review, and iteratively refine AI-generated research, aiming to improve quality and dissemination at scale.", "motivation": "The current publication ecosystem is fragmented and largely closed, with traditional peer review and preprint servers insufficient for AI-generated research; there is a need for scalable, quality-controlled venues to disseminate AI-driven scientific content.", "method": "Design of aiXiv with a multi-agent architecture; supports submitting research proposals and papers; iterative revising and reviewing by both human and AI scientists; API and MCP interfaces for integration with heterogeneous agents; extensive experiments to assess quality improvements.", "result": "aiXiv is reported as reliable and robust, significantly enhancing the quality of AI-generated proposals and papers after iterative revising and reviewing on the platform.", "conclusion": "aiXiv lays the groundwork for a next-generation open-access ecosystem for AI scientists, potentially accelerating publication and dissemination of AI-generated research; code is available."}}
{"id": "2508.15663", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15663", "abs": "https://arxiv.org/abs/2508.15663", "authors": ["Nikita Kachaev", "Andrei Spiridonov", "Andrey Gorodetsky", "Kirill Muravyev", "Nikita Oskolkov", "Aditya Narendra", "Vlad Shakhuro", "Dmitry Makarov", "Aleksandr I. Panov", "Polina Fedotova", "Alexey K. Kovalev"], "title": "Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation", "comment": null, "summary": "Benchmarks are crucial for evaluating progress in robotics and embodied AI.\nHowever, a significant gap exists between benchmarks designed for high-level\nlanguage instruction following, which often assume perfect low-level execution,\nand those for low-level robot control, which rely on simple, one-step commands.\nThis disconnect prevents a comprehensive evaluation of integrated systems where\nboth task planning and physical execution are critical. To address this, we\npropose Kitchen-R, a novel benchmark that unifies the evaluation of task\nplanning and low-level control within a simulated kitchen environment. Built as\na digital twin using the Isaac Sim simulator and featuring more than 500\ncomplex language instructions, Kitchen-R supports a mobile manipulator robot.\nWe provide baseline methods for our benchmark, including a task-planning\nstrategy based on a vision-language model and a low-level control policy based\non diffusion policy. We also provide a trajectory collection system. Our\nbenchmark offers a flexible framework for three evaluation modes: independent\nassessment of the planning module, independent assessment of the control\npolicy, and, crucially, an integrated evaluation of the whole system. Kitchen-R\nbridges a key gap in embodied AI research, enabling more holistic and realistic\nbenchmarking of language-guided robotic agents.", "AI": {"tldr": "Kitchen-R unifies task planning and low-level control benchmarking in a simulated kitchen, offering 500+ language instructions, three evaluation modes, and baselines for planning and control.", "motivation": "Bridges the gap between benchmarks that assume perfect low-level execution (high-level language tasks) and those with simple one-step control, enabling holistic evaluation of integrated planning-and-execution systems in embodied AI.", "method": "A digital twin benchmark in Isaac Sim featuring a mobile manipulator and a simulated kitchen. It includes 500+ complex language instructions, a task-planning baseline using a vision-language model, a low-level control baseline based on a diffusion policy, and a trajectory-collection system. It supports three evaluation modes: planning-only, control-only, and integrated evaluation of the whole system.", "result": "Provides a flexible framework and baseline methods for independent and integrated evaluation, along with a trajectory collection system, to enable holistic benchmarking of language-guided robotic agents in a realistic kitchen domain.", "conclusion": "Kitchen-R fills a key gap by enabling holistic benchmarking of language-guided robotic agents, uniting task planning and low-level control in a realistic simulated environment."}}
{"id": "2508.15008", "categories": ["cs.LG", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2508.15008", "abs": "https://arxiv.org/abs/2508.15008", "authors": ["Hamza A. Abushahla", "Dara Varam", "Ariel J. N. Panopio", "Mohamed I. AlHajri"], "title": "Quantized Neural Networks for Microcontrollers: A Comprehensive Review of Methods, Platforms, and Applications", "comment": "39 pages, 16 figures, 8 Tables, submitted to the Proceedings of the\n  IEEE", "summary": "The deployment of Quantized Neural Networks (QNNs) on resource-constrained\ndevices, such as microcontrollers, has introduced significant challenges in\nbalancing model performance, computational complexity and memory constraints.\nTiny Machine Learning (TinyML) addresses these issues by integrating\nadvancements across machine learning algorithms, hardware acceleration, and\nsoftware optimization to efficiently run deep neural networks on embedded\nsystems. This survey presents a hardware-centric introduction to quantization,\nsystematically reviewing essential quantization techniques employed to\naccelerate deep learning models for embedded applications. In particular,\nfurther emphasis is put on critical trade-offs among model performance and\nhardware capabilities. The survey further evaluates existing software\nframeworks and hardware platforms designed specifically for supporting QNN\nexecution on microcontrollers. Moreover, we provide an analysis of the current\nchallenges and an outline of promising future directions in the rapidly\nevolving domain of QNN deployment.", "AI": {"tldr": "A hardware-centric survey on QNN quantization for TinyML, detailing techniques, trade-offs, frameworks, platforms, challenges, and future directions.", "motivation": "Efficient deployment of quantized neural networks on microcontrollers and embedded devices under strict resource limits, requiring balancing accuracy, latency, memory, and energy through hardware-software co-design.", "method": "Systematic literature review of quantization techniques; survey of software frameworks and hardware platforms; analysis of trade-offs between model performance and hardware constraints; synthesis of guidelines and future directions.", "result": "Provides a structured taxonomy of quantization techniques for embedded deployment, comparative analysis of software frameworks and hardware targets, and discussion of practical trade-offs, design guidelines, gaps, and future research directions.", "conclusion": "Quantized neural networks are essential for TinyML; success hinges on integrated hardware\u2013software optimization, with ongoing advances in quantization methods, tooling, and platform support to meet memory, compute, and energy constraints."}}
{"id": "2508.15168", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15168", "abs": "https://arxiv.org/abs/2508.15168", "authors": ["Masato Ito", "Kaito Tanaka", "Keisuke Matsuda", "Aya Nakayama"], "title": "XDR-LVLM: An Explainable Vision-Language Large Model for Diabetic Retinopathy Diagnosis", "comment": null, "summary": "Diabetic Retinopathy (DR) is a major cause of global blindness, necessitating\nearly and accurate diagnosis. While deep learning models have shown promise in\nDR detection, their black-box nature often hinders clinical adoption due to a\nlack of transparency and interpretability. To address this, we propose XDR-LVLM\n(eXplainable Diabetic Retinopathy Diagnosis with LVLM), a novel framework that\nleverages Vision-Language Large Models (LVLMs) for high-precision DR diagnosis\ncoupled with natural language-based explanations. XDR-LVLM integrates a\nspecialized Medical Vision Encoder, an LVLM Core, and employs Multi-task Prompt\nEngineering and Multi-stage Fine-tuning to deeply understand pathological\nfeatures within fundus images and generate comprehensive diagnostic reports.\nThese reports explicitly include DR severity grading, identification of key\npathological concepts (e.g., hemorrhages, exudates, microaneurysms), and\ndetailed explanations linking observed features to the diagnosis. Extensive\nexperiments on the Diabetic Retinopathy (DDR) dataset demonstrate that XDR-LVLM\nachieves state-of-the-art performance, with a Balanced Accuracy of 84.55% and\nan F1 Score of 79.92% for disease diagnosis, and superior results for concept\ndetection (77.95% BACC, 66.88% F1). Furthermore, human evaluations confirm the\nhigh fluency, accuracy, and clinical utility of the generated explanations,\nshowcasing XDR-LVLM's ability to bridge the gap between automated diagnosis and\nclinical needs by providing robust and interpretable insights.", "AI": {"tldr": "XDR-LVLM uses Vision-Language LLMs with a medical encoder and multi-task prompting to provide explainable diabetic retinopathy diagnosis and natural-language reports, achieving strong accuracy and interpretability on the DDR dataset.", "motivation": "To tackle the black-box nature of deep learning DR models and supply transparent, clinically meaningful explanations that improve trust and decision-making.", "method": "A modular framework combining a specialized Medical Vision Encoder, LVLM Core, and multi-task prompt engineering with multi-stage fine-tuning to extract pathological features from fundus images and generate diagnostic reports that include DR severity, key pathologies (hemorrhages, exudates, microaneurysms), and explanatory links between features and diagnosis.", "result": "On the DDR dataset, disease diagnosis achieves Balanced Accuracy 84.55% and F1 score 79.92%; concept detection reaches 77.95% BACC and 66.88% F1. Human evaluations report high fluency, accuracy, and clinical utility of the explanations.", "conclusion": "XDR-LVLM demonstrates that explainable, high-performance DR diagnosis is feasible, providing robust, interpretable insights that bridge automated analysis with clinical needs and potentially enhance adoption in clinical workflow."}}
{"id": "2508.15144", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15144", "abs": "https://arxiv.org/abs/2508.15144", "authors": ["Jiabo Ye", "Xi Zhang", "Haiyang Xu", "Haowei Liu", "Junyang Wang", "Zhaoqing Zhu", "Ziwei Zheng", "Feiyu Gao", "Junjie Cao", "Zhengxi Lu", "Jitong Liao", "Qi Zheng", "Fei Huang", "Jingren Zhou", "Ming Yan"], "title": "Mobile-Agent-v3: Foundamental Agents for GUI Automation", "comment": null, "summary": "This paper introduces GUI-Owl, a foundational GUI agent model that achieves\nstate-of-the-art performance among open-source end-to-end models on ten GUI\nbenchmarks across desktop and mobile environments, covering grounding, question\nanswering, planning, decision-making, and procedural knowledge. GUI-Owl-7B\nachieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose\nMobile-Agent-v3, a general-purpose GUI agent framework that further improves\nperformance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new\nstate-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates\nthree key innovations: (1) Large-scale Environment Infrastructure: a\ncloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,\nenabling our Self-Evolving GUI Trajectory Production framework. This generates\nhigh-quality interaction data via automated query generation and correctness\nvalidation, leveraging GUI-Owl to refine trajectories iteratively, forming a\nself-improving loop. It supports diverse data pipelines and reduces manual\nannotation. (2) Diverse Foundational Agent Capabilities: by integrating UI\ngrounding, planning, action semantics, and reasoning patterns, GUI-Owl supports\nend-to-end decision-making and can act as a modular component in multi-agent\nsystems. (3) Scalable Environment RL: we develop a scalable reinforcement\nlearning framework with fully asynchronous training for real-world alignment.\nWe also introduce Trajectory-aware Relative Policy Optimization (TRPO) for\nonline RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are\nopen-sourced at https://github.com/X-PLUG/MobileAgent.", "AI": {"tldr": "GUI-Owl is an open-source GUI agent family that achieves leading end-to-end performance on ten GUI benchmarks, driven by a cloud-based self-evolving environment and TRPO-based online RL, with Mobile-Agent-v3 setting new SOTA.", "motivation": "To build versatile, scalable GUI agents capable of cross-platform grounding, planning, decision-making, and procedural knowledge with minimal manual annotation and real-world alignment.", "method": "Three innovations: (1) Large-scale Environment Infrastructure enabling Self-Evolving GUI Trajectory Production for automated data generation and trajectory refinement; (2) Diverse Foundational Agent Capabilities integrating UI grounding, planning, action semantics, and reasoning for end-to-end decision-making; (3) Scalable Environment RL with asynchronous training and Trajectory-aware Relative Policy Optimization (TRPO) for online RL.", "result": "GUI-Owl-7B achieves 66.4 on AndroidWorld and 29.4 on OSWorld; Mobile-Agent-v3 reaches 73.3 AndroidWorld and 37.7 OSWorld, establishing new SOTA among open-source GUI agents; TRPO reports 34.9 on OSWorld; code released at GitHub.", "conclusion": "The GUI-Owl framework and Mobile-Agent-v3 deliver strong SOTA performance, scalable data-generation, and modular, multi-agent-ready components, advancing open-source GUI intelligence and providing reusable infrastructure for further research."}}
{"id": "2508.15669", "categories": ["cs.RO", "cs.LG", "68T40", "I.2.9"], "pdf": "https://arxiv.org/pdf/2508.15669", "abs": "https://arxiv.org/abs/2508.15669", "authors": ["Annie S. Chen", "Philemon Brakel", "Antonia Bronars", "Annie Xie", "Sandy Huang", "Oliver Groth", "Maria Bauza", "Markus Wulfmeier", "Nicolas Heess", "Dushyant Rao"], "title": "Exploiting Policy Idling for Dexterous Manipulation", "comment": "A similar version to this paper was accepted at IROS 2025", "summary": "Learning-based methods for dexterous manipulation have made notable progress\nin recent years. However, learned policies often still lack reliability and\nexhibit limited robustness to important factors of variation. One failure\npattern that can be observed across many settings is that policies idle, i.e.\nthey cease to move beyond a small region of states when they reach certain\nstates. This policy idling is often a reflection of the training data. For\ninstance, it can occur when the data contains small actions in areas where the\nrobot needs to perform high-precision motions, e.g., when preparing to grasp an\nobject or object insertion. Prior works have tried to mitigate this phenomenon\ne.g. by filtering the training data or modifying the control frequency.\nHowever, these approaches can negatively impact policy performance in other\nways. As an alternative, we investigate how to leverage the detectability of\nidling behavior to inform exploration and policy improvement. Our approach,\nPause-Induced Perturbations (PIP), applies perturbations at detected idling\nstates, thus helping it to escape problematic basins of attraction. On a range\nof challenging simulated dual-arm tasks, we find that this simple approach can\nalready noticeably improve test-time performance, with no additional\nsupervision or training. Furthermore, since the robot tends to idle at critical\npoints in a movement, we also find that learning from the resulting episodes\nleads to better iterative policy improvement compared to prior approaches. Our\nperturbation strategy also leads to a 15-35% improvement in absolute success\nrate on a real-world insertion task that requires complex multi-finger\nmanipulation.", "AI": {"tldr": "A simple, training-free perturbation technique called Pause-Induced Perturbations (PIP) detects when policies idle and perturbs them to break out of stuck basins, improving performance in both simulated and real-world dexterous manipulation tasks.", "motivation": "Policy idling is a common failure pattern in learning-based dexterous manipulation, stemming from biased training data and insufficient exploration of high-precision regions; improving robustness without heavy supervision is desirable.", "method": "Detect idling states (regions where the policy's actions are near zero) and apply perturbations at those states to push the policy into more informative regions. Evaluate on challenging simulated dual-arm tasks and a real-world multi-finger insertion task, comparing test-time performance and iterative policy improvement without additional supervision or training changes.", "result": "Notable improvements in test-time performance across simulated tasks. In a real-world insertion task requiring complex multi-finger manipulation, the approach yielded a 15\u201335% absolute improvement in success rate. Perturbations also facilitated better iterative policy improvement compared to prior methods, with no extra supervision required.", "conclusion": "Leveraging idling detection to trigger perturbations is an effective, lightweight strategy to enhance exploration and policy improvement in dexterous manipulation, compatible with existing training pipelines and without additional supervision."}}
{"id": "2508.15010", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2508.15010", "abs": "https://arxiv.org/abs/2508.15010", "authors": ["Sami Alabed", "Dominik Grewe", "Norman Alexander Rink", "Timur Sitdikov", "Agnieszka Swietlik", "Dimitrios Vytiniotis", "Daniel Belov"], "title": "TOAST: Fast and scalable auto-partitioning based on principled static analysis", "comment": null, "summary": "Partitioning large machine learning models across distributed accelerator\nsystems is a complex process, requiring a series of interdependent decisions\nthat are further complicated by internal sharding ambiguities. Consequently,\nexisting auto-partitioners often suffer from out-of-memory errors or are\nprohibitively slow when exploring the exponentially large space of possible\npartitionings. To mitigate this, they artificially restrict the search space,\nbut this approach frequently yields infeasible solutions that violate device\nmemory constraints or lead to sub-optimal performance.\n  We propose a system that combines a novel static compiler analysis with a\nMonte Carlo Tree Search. Our analysis constructs an efficient decision space by\nidentifying (i) tensor dimensions requiring identical sharding, and (ii)\npartitioning \"conflicts\" that require resolution.\n  Our system significantly outperforms state-of-the-art industrial methods\nacross diverse hardware platforms and model architectures, discovering\npreviously unknown, superior solutions, and the process is fully automated even\nfor complex and large models.", "AI": {"tldr": "A static compiler analysis plus Monte Carlo Tree Search for hardware-aware partitioning of large ML models across distributed accelerators, outperforming industrial baselines and fully automated.", "motivation": "Auto-partitioners struggle with out-of-memory and slowness due to exploring an exponentially large search space; restricting the search often yields infeasible or suboptimal partitions.", "method": "A static compiler analysis identifies tensor dimensions requiring identical sharding and partitioning conflicts to resolve, then uses Monte Carlo Tree Search to explore feasible partitionings within this reduced decision space.", "result": "System significantly outperforms state-of-the-art industrial methods across diverse hardware platforms and model architectures, discovering previously unknown, superior partitionings.", "conclusion": "The approach provides a fully automated, scalable solution for partitioning large models across distributed accelerators, mitigating memory constraints and search time while improving performance."}}
{"id": "2508.15169", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15169", "abs": "https://arxiv.org/abs/2508.15169", "authors": ["Xuyang Chen", "Zhijun Zhai", "Kaixuan Zhou", "Zengmao Wang", "Jianan He", "Dong Wang", "Yanfeng Zhang", "mingwei Sun", "R\u00fcdiger Westermann", "Konrad Schindler", "Liqiu Meng"], "title": "MeSS: City Mesh-Guided Outdoor Scene Generation with Cross-View Consistent Diffusion", "comment": null, "summary": "Mesh models have become increasingly accessible for numerous cities; however,\nthe lack of realistic textures restricts their application in virtual urban\nnavigation and autonomous driving. To address this, this paper proposes MeSS\n(Meshbased Scene Synthesis) for generating high-quality, styleconsistent\noutdoor scenes with city mesh models serving as the geometric prior. While\nimage and video diffusion models can leverage spatial layouts (such as depth\nmaps or HD maps) as control conditions to generate street-level perspective\nviews, they are not directly applicable to 3D scene generation. Video diffusion\nmodels excel at synthesizing consistent view sequences that depict scenes but\noften struggle to adhere to predefined camera paths or align accurately with\nrendered control videos. In contrast, image diffusion models, though unable to\nguarantee cross-view visual consistency, can produce more geometry-aligned\nresults when combined with ControlNet. Building on this insight, our approach\nenhances image diffusion models by improving cross-view consistency. The\npipeline comprises three key stages: first, we generate geometrically\nconsistent sparse views using Cascaded Outpainting ControlNets; second, we\npropagate denser intermediate views via a component dubbed AGInpaint; and\nthird, we globally eliminate visual inconsistencies (e.g., varying exposure)\nusing the GCAlign module. Concurrently with generation, a 3D Gaussian Splatting\n(3DGS) scene is reconstructed by initializing Gaussian balls on the mesh\nsurface. Our method outperforms existing approaches in both geometric alignment\nand generation quality. Once synthesized, the scene can be rendered in diverse\nstyles through relighting and style transfer techniques.", "AI": {"tldr": "MeSS uses a three-stage diffusion-based pipeline with 3D Gaussian splatting to synthesize textured, geometry-aligned outdoor city scenes from mesh priors, achieving improved cross-view consistency and enabling relighting/styling.", "motivation": "There is a need for realistic textures on city mesh models for virtual urban navigation and autonomous driving. Diffusion models struggle with 3D consistency and adhering to predefined camera paths, so a geometry-aware approach is desirable.", "method": "Three-stage pipeline: (1) Cascaded Outpainting ControlNets to generate geometrically consistent sparse views; (2) AGInpaint to propagate denser intermediate views; (3) GCAlign to remove global inconsistencies (e.g., exposure). Concurrent 3D Gaussian Splatting (3DGS) reconstructs a scene by placing Gaussian balls on the mesh surface. The synthesized scene can be relit and style-transferred.", "result": "The approach outperforms existing methods in geometric alignment and generation quality, producing texture-rich outdoor scenes aligned to the city mesh priors.", "conclusion": "MeSS effectively integrates geometry priors with diffusion-based generation to produce high-quality, style-consistent outdoor scenes, with 3DGS enabling rendering in diverse styles through relighting and style transfer."}}
{"id": "2508.15180", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.15180", "abs": "https://arxiv.org/abs/2508.15180", "authors": ["Kai Xiong", "Yanwei Huang", "Rongjunchen Zhang", "Kun Chen", "Haipang Wu"], "title": "PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data", "comment": null, "summary": "High-quality mathematical and logical datasets with verifiable answers are\nessential for strengthening the reasoning capabilities of large language models\n(LLMs). While recent data augmentation techniques have facilitated the creation\nof large-scale benchmarks, existing LLM-generated datasets often suffer from\nlimited reliability, diversity, and scalability. To address these challenges,\nwe introduce PuzzleClone, a formal framework for synthesizing verifiable data\nat scale using Satisfiability Modulo Theories (SMT). Our approach features\nthree key innovations: (1) encoding seed puzzles into structured logical\nspecifications, (2) generating scalable variants through systematic variable\nand constraint randomization, and (3) ensuring validity via a reproduction\nmechanism. Applying PuzzleClone, we construct a curated benchmark comprising\nover 83K diverse and programmatically validated puzzles. The generated puzzles\nspan a wide spectrum of difficulty and formats, posing significant challenges\nto current state-of-the-art models. We conduct post training (SFT and RL) on\nPuzzleClone datasets. Experimental results show that training on PuzzleClone\nyields substantial improvements not only on PuzzleClone testset but also on\nlogic and mathematical benchmarks. Post training raises PuzzleClone average\nfrom 14.4 to 56.2 and delivers consistent improvements across 7 logic and\nmathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from\n52.5 to 65.0). Our code and data are available at\nhttps://github.com/puzzleclone.", "AI": {"tldr": "SMT-based PuzzleClone synthesizes 83k verifiable, diverse puzzles to scale LLM reasoning data; post-training on PuzzleClone improves performance on logic/maths benchmarks.", "motivation": "Need for high-quality, verifiable datasets to strengthen reasoning in LLMs; existing LLM-generated data suffer from unreliability, limited diversity, and scalability.", "method": "Encode seed puzzles into SMT-based structured specifications; generate scalable variants via systematic variable and constraint randomization; validate by reproduction; assemble a large benchmark; perform SFT and RL on the dataset.", "result": "Created 83k puzzles; improved model performance on PuzzleClone testset and broader benchmarks; PuzzleClone average score from 14.4 to 56.2; AMC2023 improved from 52.5 to 65.0; code and data released.", "conclusion": "Demonstrates scalable, verifiable data synthesis for reasoning tasks, yielding better generalization and providing open-source resources for the community."}}
{"id": "2508.15732", "categories": ["cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.15732", "abs": "https://arxiv.org/abs/2508.15732", "authors": ["Gargi Das", "Daegyun Choi", "Donghoon Kim"], "title": "Understanding and Utilizing Dynamic Coupling in Free-Floating Space Manipulators for On-Orbit Servicing", "comment": "17 pages, 7 figures, 2025 AAS/AIAA Astrodynamics Specialist\n  Conference", "summary": "This study proposes a dynamic coupling-informed trajectory optimization\nalgorithm for free-floating space manipulator systems (SMSs). Dynamic coupling\nbetween the base and the manipulator arms plays a critical role in influencing\nthe system's behavior. While prior research has predominantly focused on\nminimizing this coupling, often overlooking its potential advantages, this work\ninvestigates how dynamic coupling can instead be leveraged to improve\ntrajectory planning. Singular value decomposition (SVD) of the dynamic coupling\nmatrix is employed to identify the dominant components governing coupling\nbehavior. A quantitative metric is then formulated to characterize the strength\nand directionality of the coupling and is incorporated into a trajectory\noptimization framework. To assess the feasibility of the optimized trajectory,\na sliding mode control-based tracking controller is designed to generate the\nrequired joint torque inputs. Simulation results demonstrate that explicitly\naccounting for dynamic coupling in trajectory planning enables more informed\nand potentially more efficient operation, offering new directions for the\ncontrol of free-floating SMSs.", "AI": {"tldr": "Dynamic-coupling-aware trajectory optimization for free-floating space manipulators using SVD to extract dominant coupling modes and a coupling metric integrated into optimization; a sliding-mode controller ensures feasible torque tracking; simulations show potential efficiency gains.", "motivation": "Dynamic coupling between base and manipulators strongly shapes system behavior; previous work minimized coupling rather than leveraging it; exploiting coupling could improve trajectory efficiency and performance.", "method": "Compute dynamic coupling matrix, apply singular value decomposition to identify principal coupling directions, define a coupling strength/directionality metric, incorporate into a trajectory optimization objective/constraints, design a sliding-mode tracking controller to produce joint torques for feasibility.", "result": "Simulations demonstrate that including the coupling metric in planning yields more informed and potentially more efficient trajectories; methodology offers new directions for free-floating SMS control.", "conclusion": "Dynamic coupling is not merely a disturbance but a resource to be exploited; the proposed framework provides a quantitative tool and control approach to harness coupling for better trajectory planning in free-floating space manipulators."}}
{"id": "2508.15015", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15015", "abs": "https://arxiv.org/abs/2508.15015", "authors": ["Sebastian Musia\u0142", "Bartosz Zieli\u0144ski", "Tomasz Danel"], "title": "Fragment-Wise Interpretability in Graph Neural Networks via Molecule Decomposition and Contribution Analysis", "comment": null, "summary": "Graph neural networks have demonstrated remarkable success in predicting\nmolecular properties by leveraging the rich structural information encoded in\nmolecular graphs. However, their black-box nature reduces interpretability,\nwhich limits trust in their predictions for important applications such as drug\ndiscovery and materials design. Furthermore, existing explanation techniques\noften fail to reliably quantify the contribution of individual atoms or\nsubstructures due to the entangled message-passing dynamics. We introduce SEAL\n(Substructure Explanation via Attribution Learning), a new interpretable graph\nneural network that attributes model predictions to meaningful molecular\nsubgraphs. SEAL decomposes input graphs into chemically relevant fragments and\nestimates their causal influence on the output. The strong alignment between\nfragment contributions and model predictions is achieved by explicitly reducing\ninter-fragment message passing in our proposed model architecture. Extensive\nevaluations on synthetic benchmarks and real-world molecular datasets\ndemonstrate that SEAL outperforms other explainability methods in both\nquantitative attribution metrics and human-aligned interpretability. A user\nstudy further confirms that SEAL provides more intuitive and trustworthy\nexplanations to domain experts. By bridging the gap between predictive\nperformance and interpretability, SEAL offers a promising direction for more\ntransparent and actionable molecular modeling.", "AI": {"tldr": "SEAL is an interpretable GNN for molecules that attributes predictions to chemically meaningful subgraphs by fragment-based attribution and limited inter-fragment message passing, achieving superior attribution accuracy and human-aligned explanations.", "motivation": "Molecular property prediction with GNNs is powerful but often opaque. There is a need for reliable, human-aligned explanations of how individual atoms/substructures drive predictions, and existing explainers struggle due to entangled message passing.", "method": "Decompose input graphs into chemically relevant fragments. Train an attribution model (attribution learning) to estimate the causal influence of fragments on the output. Modify the GNN architecture to explicitly reduce inter-fragment message passing, aligning fragment-level contributions with predictions.", "result": "SEAL outperforms baseline explainability methods on synthetic and real molecular datasets across attribution metrics and human-aligned interpretability; a user study with domain experts shows explanations are more intuitive and trustworthy.", "conclusion": "SEAL advances the interpretability of molecular GNNs by enabling substructure-level explanations with improved trustworthiness, suggesting a promising path toward transparent and actionable molecular modeling."}}
{"id": "2508.15189", "categories": ["cs.AI", "cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2508.15189", "abs": "https://arxiv.org/abs/2508.15189", "authors": ["Jiahao Xu", "Changchang Yin", "Odysseas Chatzipanagiotou", "Diamantis Tsilimigras", "Kevin Clear", "Bingsheng Yao", "Dakuo Wang", "Timothy Pawlik", "Ping Zhang"], "title": "SurgWound-Bench: A Benchmark for Surgical Wound Diagnosis", "comment": null, "summary": "Surgical site infection (SSI) is one of the most common and costly\nhealthcare-associated infections and and surgical wound care remains a\nsignificant clinical challenge in preventing SSIs and improving patient\noutcomes. While recent studies have explored the use of deep learning for\npreliminary surgical wound screening, progress has been hindered by concerns\nover data privacy and the high costs associated with expert annotation.\nCurrently, no publicly available dataset or benchmark encompasses various types\nof surgical wounds, resulting in the absence of an open-source Surgical-Wound\nscreening tool. To address this gap: (1) we present SurgWound, the first\nopen-source dataset featuring a diverse array of surgical wound types. It\ncontains 697 surgical wound images annotated by 3 professional surgeons with\neight fine-grained clinical attributes. (2) Based on SurgWound, we introduce\nthe first benchmark for surgical wound diagnosis, which includes visual\nquestion answering (VQA) and report generation tasks to comprehensively\nevaluate model performance. (3) Furthermore, we propose a three-stage learning\nframework, WoundQwen, for surgical wound diagnosis. In the first stage, we\nemploy five independent MLLMs to accurately predict specific surgical wound\ncharacteristics. In the second stage, these predictions serve as additional\nknowledge inputs to two MLLMs responsible for diagnosing outcomes, which assess\ninfection risk and guide subsequent interventions. In the third stage, we train\na MLLM that integrates the diagnostic results from the previous two stages to\nproduce a comprehensive report. This three-stage framework can analyze detailed\nsurgical wound characteristics and provide subsequent instructions to patients\nbased on surgical images, paving the way for personalized wound care, timely\nintervention, and improved patient outcomes.", "AI": {"tldr": "Introduces SurgWound, an open-source surgical wound dataset with 697 images and eight attributes, plus a benchmarking suite for surgical wound diagnosis (VQA and report generation) and a three-stage learning framework, WoundQwen, to predict wound characteristics, diagnose outcomes, and generate comprehensive patient reports.", "motivation": "Surgical site infections (SSIs) are common and costly, and progress in deep learning for wound screening is hampered by data privacy and annotation costs. There is no public, diverse wound dataset or open-source screening tool.", "method": "1) Create SurgWound: 697 wound images annotated by 3 professional surgeons with eight fine-grained attributes. 2) Establish a benchmark for surgical wound diagnosis including VQA and wound report generation tasks. 3) Propose WoundQwen: a three-stage framework where Stage 1 uses five independent multilingual LLMs to predict wound characteristics; Stage 2 uses these predictions as inputs to two LLMs to diagnose outcomes (infection risk and interventions); Stage 3 trains an LLM to integrate results and produce a comprehensive report.", "result": "The work provides the first open surgical wound dataset (SurgWound) and the first benchmark for surgical wound diagnosis, alongside a novel three-stage LLM-based framework (WoundQwen) that enables detailed wound analysis and generated patient reports, supporting personalized wound care.", "conclusion": "By delivering an open dataset and benchmark plus a modular diagnostic/reporting framework, the study aims to enable open-source surgical wound screening, facilitate timely interventions, and improve patient outcomes."}}
{"id": "2508.15192", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15192", "abs": "https://arxiv.org/abs/2508.15192", "authors": ["Wenjie Lin", "Jin Wei-Kocsis"], "title": "LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support", "comment": null, "summary": "While large language models (LLMs) have shown promise in healthcare, their\napplication for rare medical conditions is still hindered by scarce and\nunreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing\nexcessive sweating beyond physiological needs, is one such rare disorder,\naffecting 2-3% of the population and significantly impacting both physical\ncomfort and psychosocial well-being. To date, no work has tailored LLMs to\nadvance the diagnosis or care of hyperhidrosis. To address this gap, we present\nLLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and\nempathetic hyperhidrosis support. The system follows a three-stage pipeline. In\nthe data augmentation stage, a frontier LLM generates medically plausible\nsynthetic vignettes from curated open-source data to create a diverse and\nbalanced question-answer dataset. In the fine-tuning stage, an open-source\nfoundation model is fine-tuned on the dataset to provide diagnosis,\npersonalized treatment recommendations, and empathetic psychological support.\nIn the inference and expert evaluation stage, clinical and psychological\nspecialists assess accuracy, appropriateness, and empathy, with validated\nresponses iteratively enriching the dataset. Experiments show that LLM4Sweat\noutperforms baselines and delivers the first open-source LLM framework for\nhyperhidrosis, offering a generalizable approach for other rare diseases with\nsimilar data and trustworthiness challenges.", "AI": {"tldr": "LLM4Sweat: an open-source, domain-specific LLM for hyperhidrosis enabling diagnosis, personalized treatment, and empathetic support via a three-stage pipeline (data augmentation with frontier LLM, fine-tuning on synthetic data, expert evaluation), outperforming baselines and applicable to other rare diseases.", "motivation": "Addresses data scarcity and trustworthiness in applying LLMs to rare diseases; provides an open, reproducible framework for clinical empathy and decision support in hyperhidrosis.", "method": "Three-stage pipeline: 1) data augmentation: frontier LLM generates medically plausible synthetic vignettes from curated data to create diverse QA dataset; 2) fine-tuning: open-source foundation model trained on dataset to output diagnosis, treatment recommendations, empathy; 3) inference/expert evaluation: clinicians assess accuracy, appropriateness, empathy; iterative dataset enrichment.", "result": "Outperforms baselines; first open-source LLM framework for hyperhidrosis; generalizable approach for other rare diseases with similar data and trustworthiness challenges.", "conclusion": "Open-source, domain-specific LLMs can enable trustworthy, empathetic care for rare diseases; LLM4Sweat provides a replicable template to tackle data scarcity and trust in medical AI."}}
{"id": "2508.15755", "categories": ["cs.RO", "cs.AI", "cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15755", "abs": "https://arxiv.org/abs/2508.15755", "authors": ["Jie Xu", "Eric Heiden", "Iretiayo Akinola", "Dieter Fox", "Miles Macklin", "Yashraj Narang"], "title": "Neural Robot Dynamics", "comment": null, "summary": "Accurate and efficient simulation of modern robots remains challenging due to\ntheir high degrees of freedom and intricate mechanisms. Neural simulators have\nemerged as a promising alternative to traditional analytical simulators,\ncapable of efficiently predicting complex dynamics and adapting to real-world\ndata; however, existing neural simulators typically require\napplication-specific training and fail to generalize to novel tasks and/or\nenvironments, primarily due to inadequate representations of the global state.\nIn this work, we address the problem of learning generalizable neural\nsimulators for robots that are structured as articulated rigid bodies. We\npropose NeRD (Neural Robot Dynamics), learned robot-specific dynamics models\nfor predicting future states for articulated rigid bodies under contact\nconstraints. NeRD uniquely replaces the low-level dynamics and contact solvers\nin an analytical simulator and employs a robot-centric and spatially-invariant\nsimulation state representation. We integrate the learned NeRD models as an\ninterchangeable backend solver within a state-of-the-art robotics simulator. We\nconduct extensive experiments to show that the NeRD simulators are stable and\naccurate over a thousand simulation steps; generalize across tasks and\nenvironment configurations; enable policy learning exclusively in a neural\nengine; and, unlike most classical simulators, can be fine-tuned from\nreal-world data to bridge the gap between simulation and reality.", "AI": {"tldr": "NeRD is a neural dynamics backend for articulated robots that replaces low-level solvers, enabling generalizable, trainable dynamics and sim-to-real adaptation within a physics simulator.", "motivation": "Accurate and efficient robotic simulation is difficult due to high degrees of freedom and intricate mechanisms. Existing neural simulators often require task-specific training and struggle to generalize because of inadequate global state representations; there is a need for robot-centric, generalizable models that can adapt across tasks and environments.", "method": "Introduce NeRD (Neural Robot Dynamics), a learned dynamics model for articulated rigid bodies under contact constraints. It replaces the low-level dynamics and contact solvers in an analytical simulator and uses a robot-centric, spatially-invariant representation of the simulation state. NeRD is integrated as an interchangeable backend solver within a state-of-the-art robotics simulator.", "result": "Empirical evaluation shows NeRD is stable and accurate over 1,000 simulation steps, generalizes across tasks and environment configurations, enables policy learning entirely within the neural engine, and can be fine-tuned from real-world data to bridge the sim-to-real gap.", "conclusion": "NeRD demonstrates a viable, generalizable neural backend for robot dynamics that can be tuned with real data and integrated with existing simulators to improve generalization and sim-to-real transfer."}}
{"id": "2508.15019", "categories": ["cs.LG", "cs.AI", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.15019", "abs": "https://arxiv.org/abs/2508.15019", "authors": ["Carlos Stein Brito"], "title": "Twin-Boot: Uncertainty-Aware Optimization via Online Two-Sample Bootstrapping", "comment": "12 pages, 6 figures", "summary": "Standard gradient descent methods yield point estimates with no measure of\nconfidence. This limitation is acute in overparameterized and low-data regimes,\nwhere models have many parameters relative to available data and can easily\noverfit. Bootstrapping is a classical statistical framework for uncertainty\nestimation based on resampling, but naively applying it to deep learning is\nimpractical: it requires training many replicas, produces post-hoc estimates\nthat cannot guide learning, and implicitly assumes comparable optima across\nruns - an assumption that fails in non-convex landscapes. We introduce\nTwin-Bootstrap Gradient Descent (Twin-Boot), a resampling-based training\nprocedure that integrates uncertainty estimation into optimization. Two\nidentical models are trained in parallel on independent bootstrap samples, and\na periodic mean-reset keeps both trajectories in the same basin so that their\ndivergence reflects local (within-basin) uncertainty. During training, we use\nthis estimate to sample weights in an adaptive, data-driven way, providing\nregularization that favors flatter solutions. In deep neural networks and\ncomplex high-dimensional inverse problems, the approach improves calibration\nand generalization and yields interpretable uncertainty maps.", "AI": {"tldr": "Twin-Bootstrap Gradient Descent trains two identical networks on bootstrap samples with a periodic mean-reset to stay in the same basin; their divergence estimates local, within-basin uncertainty and is used to adaptively regularize weights toward flatter minima, improving calibration and generalization with interpretable uncertainty maps.", "motivation": "Uncertainty estimates are essential but hard to obtain in deep learning, especially in overparameterized or low-data regimes. Traditional bootstrapping is impractical for deep nets and fails in non-convex landscapes where optima vary across runs.", "method": "Two identical models are trained in parallel on independent bootstrap samples. A periodic mean-reset keeps both trajectories in the same basin. The divergence between the models serves as a local uncertainty measure, which is then used to adaptively sample weights, providing data-driven regularization that biases toward flatter minima.", "result": "The approach improves calibration and generalization in deep neural networks and complex high-dimensional inverse problems and yields interpretable uncertainty maps.", "conclusion": "Twin-Boot offers a practical framework that integrates uncertainty estimation into optimization, yielding better-calibrated predictions, improved generalization, and interpretable uncertainty quantification through training-time adaptive regularization."}}
{"id": "2508.15207", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15207", "abs": "https://arxiv.org/abs/2508.15207", "authors": ["Arjun Srinivasan", "Anubhav Paras", "Aniket Bera"], "title": "Adversarial Agent Behavior Learning in Autonomous Driving Using Deep Reinforcement Learning", "comment": null, "summary": "Existing approaches in reinforcement learning train an agent to learn desired\noptimal behavior in an environment with rule based surrounding agents. In\nsafety critical applications such as autonomous driving it is crucial that the\nrule based agents are modelled properly. Several behavior modelling strategies\nand IDM models are used currently to model the surrounding agents. We present a\nlearning based method to derive the adversarial behavior for the rule based\nagents to cause failure scenarios. We evaluate our adversarial agent against\nall the rule based agents and show the decrease in cumulative reward.", "AI": {"tldr": "Proposes a learning-based adversary to cause failure scenarios for rule-based agents in RL for autonomous driving, and shows the adversary reduces the rule-based agents' cumulative rewards.", "motivation": "In safety-critical settings like autonomous driving, accurately modeling surrounding agents is essential. Existing rule-based/ IDM models may be brittle, so it is important to study adversarial behaviors that can exploit these models to reveal vulnerabilities.", "method": "Introduce a learning-based method to derive adversarial behavior targeting rule-based agents (modeled by IDM/behavior strategies). Evaluate the adversarial agent against all rule-based agents and measure the resulting change in cumulative reward.", "result": "The adversarial agent successfully reduces the cumulative reward of the rule-based agents, indicating vulnerabilities in current behavior modeling.", "conclusion": "Adversarial strategies reveal weaknesses in rule-based surrounding-agent models; robust modeling and adversarially-aware training or testing should be pursued to improve safety in RL for autonomous driving."}}
{"id": "2508.15204", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15204", "abs": "https://arxiv.org/abs/2508.15204", "authors": ["Raj Jain", "Marc Wetter"], "title": "R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling", "comment": null, "summary": "Effective scheduling under tight resource, timing, and operational\nconstraints underpins large-scale planning across sectors such as capital\nprojects, manufacturing, logistics, and IT fleet transitions. However, the\nreliability of large language models (LLMs) when reasoning under\nhigh-constraint regimes is insufficiently characterized. To address this gap,\nwe present R-ConstraintBench, a scalable framework that evaluates models on\nResource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete\nfeasibility class, while difficulty increases via linear growth in constraints.\nR-ConstraintBench incrementally increases non-redundant precedence constraints\nin Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal\nwindows, and disjunctive constraints. As an illustrative example, we\ninstantiate the benchmark in a data center migration setting and evaluate\nmultiple LLMs using feasibility and error analysis, identifying degradation\nthresholds and constraint types most associated with failure. Empirically,\nstrong models are near-ceiling on precedence-only DAGs, but feasibility\nperformance collapses when downtime, temporal windows, and disjunctive\nconstraints interact, implicating constraint interaction, not graph depth, as\nthe principal bottleneck. Performance on clean synthetic ramps also does not\nguarantee transfer to domain-grounded scenarios, underscoring limited\ngeneralization.", "AI": {"tldr": "Introduces R-ConstraintBench, a scalable benchmarking framework to evaluate LLM performance on Resource-Constrained Project Scheduling Problems (RCPSP); shows constraint interaction degrades feasibility; generalization issues.", "motivation": "Assess reliability of LLMs under tight resource and timing constraints; RCPSP is NP-Complete and representative of real-world scheduling challenges; existing LLMs may not generalize to high-constraint regimes.", "method": "Develop R-ConstraintBench by incrementally increasing non-redundant precedence constraints in DAGs; then add downtime, temporal windows, disjunctive constraints; instantiate in data center migration scenario; evaluate multiple LLMs on feasibility and error analysis; analyze degradation thresholds and constraint types.", "result": "On precedence-only DAGs, strong models near ceiling; when downtime, windows, and disjunctive constraints interact, feasibility collapses; constraint interaction is main bottleneck, not graph depth; synthetic ramps do not guarantee domain-grounded transfer; limited generalization.", "conclusion": "Benchmark reveals core bottlenecks in LLM reasoning under complex scheduling constraints; constraint interactions create hardness; generalization gap between synthetic benchmarks and real-world tasks; suggests need for improved models or approaches to handle constrained reasoning."}}
{"id": "2508.15025", "categories": ["cs.LG", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.15025", "abs": "https://arxiv.org/abs/2508.15025", "authors": ["Omkar Tupe", "Max Hartman", "Lav R. Varshney", "Saurav Prakash"], "title": "Nonlinear Federated System Identification", "comment": null, "summary": "We consider federated learning of linearly-parameterized nonlinear systems.\nWe establish theoretical guarantees on the effectiveness of federated nonlinear\nsystem identification compared to centralized approaches, demonstrating that\nthe convergence rate improves as the number of clients increases. Although the\nconvergence rates in the linear and nonlinear cases differ only by a constant,\nthis constant depends on the feature map $\\phi$, which can be carefully chosen\nin the nonlinear setting to increase excitation and improve performance. We\nexperimentally validate our theory in physical settings where client devices\nare driven by i.i.d. control inputs and control policies exhibiting i.i.d.\nrandom perturbations, ensuring non-active exploration. Experiments use\ntrajectories from nonlinear dynamical systems characterized by real-analytic\nfeature functions, including polynomial and trigonometric components,\nrepresentative of physical systems including pendulum and quadrotor dynamics.\nWe analyze the convergence behavior of the proposed method under varying noise\nlevels and data distributions. Results show that federated learning\nconsistently improves convergence of any individual client as the number of\nparticipating clients increases.", "AI": {"tldr": "Federated learning for linearly-parameterized nonlinear system identification improves convergence with more clients; the rate gap to centralized is a constant that depends on the feature map, which can be chosen to boost excitation in nonlinear settings.", "motivation": "Assess whether federated nonlinear system identification can match or surpass centralized methods and how the number of clients affects convergence; explore how feature map choice influences excitation and performance.", "method": "Theoretical analysis establishing convergence rates for federated vs centralized identification in the nonlinear, linearly-parameterized setting; shows the rate gap is a constant determined by the feature map \u03c6. Proposes selecting \u03c6 to increase excitation in the nonlinear regime. Experimental validation on physical systems with i.i.d. control inputs and random perturbations, using real-analytic feature functions (polynomials, trigonometric terms) modeling pendulum/quadrotor dynamics; analyzes convergence under different noise levels and data distributions.", "result": "Convergence of each client improves as the number of participating clients grows, with federated learning delivering a consistent gain over isolated learning. In both linear and nonlinear cases, the rates differ only by a constant that depends on \u03c6; by choosing \u03c6 to enhance excitation, the nonlinear setting can achieve stronger performance.", "conclusion": "Federated nonlinear system identification offers practical gains over isolated approaches, with feature-map design playing a critical role in achieving excitation and improving convergence. The framework validates applicability to real nonlinear physical systems and shows robustness to varying data distributions and noise."}}
{"id": "2508.15208", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15208", "abs": "https://arxiv.org/abs/2508.15208", "authors": ["Leiyue Zhao", "Yuechen Yang", "Yanfan Zhu", "Haichun Yang", "Yuankai Huo", "Paul D. Simonson", "Kenji Ikemura", "Mert R. Sabuncu", "Yihe Yang", "Ruining Deng"], "title": "DyMorph-B2I: Dynamic and Morphology-Guided Binary-to-Instance Segmentation for Renal Pathology", "comment": "9 pages, 5 figures", "summary": "Accurate morphological quantification of renal pathology functional units\nrelies on instance-level segmentation, yet most existing datasets and automated\nmethods provide only binary (semantic) masks, limiting the precision of\ndownstream analyses. Although classical post-processing techniques such as\nwatershed, morphological operations, and skeletonization, are often used to\nseparate semantic masks into instances, their individual effectiveness is\nconstrained by the diverse morphologies and complex connectivity found in renal\ntissue. In this study, we present DyMorph-B2I, a dynamic, morphology-guided\nbinary-to-instance segmentation pipeline tailored for renal pathology. Our\napproach integrates watershed, skeletonization, and morphological operations\nwithin a unified framework, complemented by adaptive geometric refinement and\ncustomizable hyperparameter tuning for each class of functional unit. Through\nsystematic parameter optimization, DyMorph-B2I robustly separates adherent and\nheterogeneous structures present in binary masks. Experimental results\ndemonstrate that our method outperforms individual classical approaches and\nna\\\"ive combinations, enabling superior instance separation and facilitating\nmore accurate morphometric analysis in renal pathology workflows. The pipeline\nis publicly available at: https://github.com/ddrrnn123/DyMorph-B2I.", "AI": {"tldr": "Dynamic, morphology-guided binary-to-instance segmentation (DyMorph-B2I) for renal pathology that combines watershed, skeletonization, and morphological operations with adaptive refinement and class-specific hyperparameters to convert semantic masks into reliable instance segmentations; achieves superior separation and morphometric accuracy, with code released.", "motivation": "Need for accurate instance-level segmentation of renal functional units; semantic masks limit downstream morphometrics; renal tissue exhibits diverse morphologies and connectivity that hinder classical post-processing.", "method": "Unified framework integrating watershed, skeletonization, morphologic operations; adaptive geometric refinement; class-specific hyperparameter tuning; systematic parameter optimization to separate adherent/heterogeneous structures.", "result": "DyMorph-B2I outperforms individual classical methods and naive combinations on instance separation, enabling more accurate morphometric analyses.", "conclusion": "The pipeline advances renal pathology workflows by providing robust, adaptable binary-to-instance segmentation; code available at GitHub."}}
{"id": "2508.15222", "categories": ["cs.AI", "cs.CV", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.15222", "abs": "https://arxiv.org/abs/2508.15222", "authors": ["Hantao Zhang", "Jingyang Liu", "Ed Li"], "title": "See it. Say it. Sorted: Agentic System for Compositional Diagram Generation", "comment": null, "summary": "We study sketch-to-diagram generation: converting rough hand sketches into\nprecise, compositional diagrams. Diffusion models excel at photorealism but\nstruggle with the spatial precision, alignment, and symbolic structure required\nfor flowcharts. We introduce See it. Say it. Sorted., a training-free agentic\nsystem that couples a Vision-Language Model (VLM) with Large Language Models\n(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system\nruns an iterative loop in which a Critic VLM proposes a small set of\nqualitative, relational edits; multiple candidate LLMs synthesize SVG updates\nwith diverse strategies (conservative->aggressive, alternative, focused); and a\nJudge VLM selects the best candidate, ensuring stable improvement. This design\nprioritizes qualitative reasoning over brittle numerical estimates, preserves\nglobal constraints (e.g., alignment, connectivity), and naturally supports\nhuman-in-the-loop corrections. On 10 sketches derived from flowcharts in\npublished papers, our method more faithfully reconstructs layout and structure\nthan two frontier closed-source image generation LLMs (GPT-5 and\nGemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)\nwithout inserting unwanted text. Because outputs are programmatic SVGs, the\napproach is readily extensible to presentation tools (e.g., PowerPoint) via\nAPIs and can be specialized with improved prompts and task-specific tools. The\ncodebase is open-sourced at\nhttps://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.", "AI": {"tldr": "A training-free agentic system that uses a critic VLM, multiple LLMs, and a judge VLM to iteratively produce editable SVG diagrams from rough sketches, preserving layout and structure and outperforming two frontier image-generation LLMs on flowcharts; outputs are open-source SVGs.", "motivation": "Diffusion models excel at realism but lack the spatial precision, alignment, and symbolic structure needed for diagrams like flowcharts; there is a need for editable, constraint-preserving tools that support human-in-the-loop.", "method": "An iterative loop: a Critic VLM proposes a small set of qualitative edits; multiple candidate LLMs generate SVG updates with diverse strategies (conservative\u2192aggressive, alternative, focused); a Judge VLM selects the best candidate to ensure stable improvement.", "result": "On 10 sketches derived from published flowcharts, the method yields more faithful reconstruction of layout and structure than two frontier closed-source image-generation LLMs (GPT-5 and Gemini-2.5-Pro), and accurately composes primitives (e.g., multi-headed arrows) without unwanted text.", "conclusion": "Because outputs are programmatic SVGs, the approach is readily extensible to presentation tools via APIs and can be augmented with improved prompts and task-specific tools; the codebase is open-sourced."}}
{"id": "2508.15033", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15033", "abs": "https://arxiv.org/abs/2508.15033", "authors": ["Chence Yang", "Ci Zhang", "Lei Lu", "Qitao Tan", "Sheng Li", "Ao Li", "Xulong Tang", "Shaoyi Huang", "Jinzhen Wang", "Guoming Li", "Jundong Li", "Xiaoming Zhai", "Jin Lu", "Geng Yuan"], "title": "Rethinking the Potential of Layer Freezing for Efficient DNN Training", "comment": null, "summary": "With the growing size of deep neural networks and datasets, the computational\ncosts of training have significantly increased. The layer-freezing technique\nhas recently attracted great attention as a promising method to effectively\nreduce the cost of network training. However, in traditional layer-freezing\nmethods, frozen layers are still required for forward propagation to generate\nfeature maps for unfrozen layers, limiting the reduction of computation costs.\nTo overcome this, prior works proposed a hypothetical solution, which caches\nfeature maps from frozen layers as a new dataset, allowing later layers to\ntrain directly on stored feature maps. While this approach appears to be\nstraightforward, it presents several major challenges that are severely\noverlooked by prior literature, such as how to effectively apply augmentations\nto feature maps and the substantial storage overhead introduced. If these\noverlooked challenges are not addressed, the performance of the caching method\nwill be severely impacted and even make it infeasible. This paper is the first\nto comprehensively explore these challenges and provides a systematic solution.\nTo improve training accuracy, we propose \\textit{similarity-aware channel\naugmentation}, which caches channels with high augmentation sensitivity with a\nminimum additional storage cost. To mitigate storage overhead, we incorporate\nlossy data compression into layer freezing and design a \\textit{progressive\ncompression} strategy, which increases compression rates as more layers are\nfrozen, effectively reducing storage costs. Finally, our solution achieves\nsignificant reductions in training cost while maintaining model accuracy, with\na minor time overhead. Additionally, we conduct a comprehensive evaluation of\nfreezing and compression strategies, providing insights into optimizing their\napplication for efficient DNN training.", "AI": {"tldr": "This work proposes a caching-based layer-freezing approach for DNN training that avoids forward passes through frozen layers by storing their outputs as a dataset, and introduces similarity-aware channel augmentation and progressive compression to manage augmentation effects and storage overhead, achieving large training cost reductions with minimal accuracy loss.", "motivation": "As neural networks and datasets grow, training cost rises dramatically. Traditional layer-freezing still requires forward propagation through frozen layers to produce feature maps, limiting cost reductions. Caching feature maps seems straightforward but faces key issues: how to apply augmentations to cached feature maps, and substantial storage overhead. This work identifies these challenges and provides a systematic solution to address them.", "method": "Propose similarity-aware channel augmentation that caches channels with high augmentation sensitivity to improve accuracy with minimal extra storage. Integrate lossy data compression into layer freezing via progressive compression, increasing compression rates as more layers become frozen to reduce storage costs. Conduct comprehensive evaluation of freezing and compression strategies to guide practical application and optimization.", "result": "Demonstrates significant reductions in training cost while maintaining model accuracy, with only minor time overhead. Provides extensive evaluation and practical insights for effectively applying freezing and compression strategies in DNN training.", "conclusion": "Offers a practical, systematic solution to cache-based layer-freezing challenges, enabling efficient DNN training at scale. The approach provides guidance on when and how to apply augmentation and compression to maximize training efficiency while preserving accuracy."}}
{"id": "2508.15216", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15216", "abs": "https://arxiv.org/abs/2508.15216", "authors": ["Vipooshan Vipulananthan", "Kumudu Mohottala", "Kavindu Chinthana", "Nimsara Paramulla", "Charith D Chitraranjan"], "title": "STAGNet: A Spatio-Temporal Graph and LSTM Framework for Accident Anticipation", "comment": null, "summary": "Accident prediction and timely warnings play a key role in improving road\nsafety by reducing the risk of injury to road users and minimizing property\ndamage. Advanced Driver Assistance Systems (ADAS) are designed to support human\ndrivers and are especially useful when they can anticipate potential accidents\nbefore they happen. While many existing systems depend on a range of sensors\nsuch as LiDAR, radar, and GPS, relying solely on dash-cam video input presents\na more challenging but a more cost-effective and easily deployable solution. In\nthis work, we incorporate better spatio-temporal features and aggregate them\nthrough a recurrent network to improve upon state-of-the-art graph neural\nnetworks for predicting accidents from dash-cam videos. Experiments using three\npublicly available datasets show that our proposed STAGNet model achieves\nhigher average precision and mean time-to-collision values than previous\nmethods, both when cross-validated on a given dataset and when trained and\ntested on different datasets.", "AI": {"tldr": "STAGNet uses enhanced spatio-temporal features and a recurrent aggregator to predict accidents from dash-cam video, outperforming state-of-the-art graph networks on three public datasets in both within-dataset and cross-dataset evaluations.", "motivation": "Accident prediction is crucial for road safety and requires low-cost, easily deployable solutions. Dash-cam only systems are attractive but challenging; the work aims to improve predictive performance using video alone, without dependence on LiDAR/radar/GPS.", "method": "Introduce STAGNet, a model that learns richer spatio-temporal features from dash-cam videos and aggregates them with a recurrent network, surpassing graph neural network baselines. Evaluated on three public datasets with cross-validation and cross-dataset tests, using metrics such as average precision and mean time-to-collision.", "result": "STAGNet achieves higher average precision and MTTC values than prior methods across both within-dataset and cross-dataset evaluations on three public datasets.", "conclusion": "Enhanced spatio-temporal feature extraction combined with recurrent aggregation yields improved accident prediction from dash-cam video, offering a cost-effective and generalizable approach for ADAS."}}
{"id": "2508.15240", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15240", "abs": "https://arxiv.org/abs/2508.15240", "authors": ["Sabab Aosaf", "Muhammad Ali Nayeem", "Afsana Haque", "M Sohel Rahmana"], "title": "Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas", "comment": null, "summary": "Urban land-use allocation represents a complex multi-objective optimization\nproblem critical for sustainable urban development policy. This paper presents\nnovel computational intelligence approaches for optimizing land-use allocation\nin mixed-use areas, addressing inherent trade-offs between land-use\ncompatibility and economic objectives. We develop multiple optimization\nalgorithms, including custom variants integrating differential evolution with\nmulti-objective genetic algorithms. Key contributions include: (1) CR+DES\nalgorithm leveraging scaled difference vectors for enhanced exploration, (2)\nsystematic constraint relaxation strategy improving solution quality while\nmaintaining feasibility, and (3) statistical validation using Kruskal-Wallis\ntests with compact letter displays. Applied to a real-world case study with\n1,290 plots, CR+DES achieves 3.16\\% improvement in land-use compatibility\ncompared to state-of-the-art methods, while MSBX+MO excels in price\noptimization with 3.3\\% improvement. Statistical analysis confirms algorithms\nincorporating difference vectors significantly outperform traditional\napproaches across multiple metrics. The constraint relaxation technique enables\nbroader solution space exploration while maintaining practical constraints.\nThese findings provide urban planners and policymakers with evidence-based\ncomputational tools for balancing competing objectives in land-use allocation,\nsupporting more effective urban development policies in rapidly urbanizing\nregions.", "AI": {"tldr": "Novel CV-based multi-objective optimization hybrids for urban land-use allocation in mixed-use areas, combining differential evolution with genetic algorithms, plus constraint relaxation and nonparametric validation; demonstrates modest improvements (\u22483%) in land-use compatibility and price optimization on a 1,290-plot real-world case study.", "motivation": "Address the complex, multi-objective trade-offs in sustainable urban land-use planning, balancing land-use compatibility with economic objectives in rapidly urbanizing, mixed-use contexts.", "method": "Develop multiple optimization algorithms, notably CR+DES (scaled difference vectors with differential evolution) and MSBX+MO, along with a systematic constraint-relaxation strategy; validate performance using Kruskal-Wallis tests with compact letter displays on a real-world dataset of 1,290 plots.", "result": "CR+DES achieves a 3.16% improvement in land-use compatibility over state-of-the-art methods; MSBX+MO achieves 3.3% improvement in price optimization; statistical analyses indicate difference-vector-based algorithms outperform traditional approaches; constraint relaxation broadens solution space while maintaining feasibility.", "conclusion": "The combination of difference-vector-driven exploration and constraint relaxation yields practical, evidence-based tools for urban planners to balance competing land-use objectives, supporting more effective policy in rapidly urbanizing regions."}}
{"id": "2508.15051", "categories": ["cs.LG", "cs.IT", "math.IT", "math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2508.15051", "abs": "https://arxiv.org/abs/2508.15051", "authors": ["Syomantak Chaudhuri", "Jerry Li", "Thomas A. Courtade"], "title": "Robust Estimation Under Heterogeneous Corruption Rates", "comment": "NeurIPS 2025", "summary": "We study the problem of robust estimation under heterogeneous corruption\nrates, where each sample may be independently corrupted with a known but\nnon-identical probability. This setting arises naturally in distributed and\nfederated learning, crowdsourcing, and sensor networks, yet existing robust\nestimators typically assume uniform or worst-case corruption, ignoring\nstructural heterogeneity. For mean estimation for multivariate bounded\ndistributions and univariate gaussian distributions, we give tight minimax\nrates for all heterogeneous corruption patterns. For multivariate gaussian mean\nestimation and linear regression, we establish the minimax rate for squared\nerror up to a factor of $\\sqrt{d}$, where $d$ is the dimension. Roughly, our\nfindings suggest that samples beyond a certain corruption threshold may be\ndiscarded by the optimal estimators -- this threshold is determined by the\nempirical distribution of the corruption rates given.", "AI": {"tldr": "The authors study robust estimation under known, non-identical sample-wise corruption rates and derive minimax rates for several tasks; they show a thresholding phenomenon where samples with high corruption are discarded, and the rates depend on the corruption-rate distribution (up to a sqrt(d) gap in some multivariate problems).", "motivation": "Heterogeneous corruption arises in distributed/federated learning, crowdsourcing, and sensor networks; existing robust methods assume uniform or worst-case corruption and miss structural heterogeneity; there is a need for minimax characterizations that incorporate heterogeneous corruption patterns.", "method": "Derive minimax rates for mean estimation under heterogeneous Bernoulli-type corruption for univariate Gaussian and multivariate bounded distributions; for multivariate Gaussian mean estimation and linear regression in higher dimensions, establish minimax rates for squared error up to a factor of sqrt(d); use analysis showing that an adaptive sample discard strategy (thresholding) achieves optimal rates, with the threshold determined by the empirical distribution of corruption rates.", "result": "Tight minimax rates are established for mean estimation under heterogeneous corruption patterns for univariate and multivariate distributions. For multivariate Gaussian mean estimation and linear regression, the minimax rate is shown to hold up to a factor sqrt(d). The results reveal a threshold phenomenon: beyond a certain corruption level, optimal estimators discard samples, and this threshold is dictated by the observed corruption-rate distribution.", "conclusion": "Heterogeneous corruption materially affects the information in the data; optimal estimators should adaptively discard highly corrupted samples according to the corruption-rate distribution, yielding minimax rates that depend on that distribution and, in high dimensions, incur a sqrt(d) loss factor. These insights guide the design of robust estimators in heterogeneous data environments."}}
{"id": "2508.15228", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15228", "abs": "https://arxiv.org/abs/2508.15228", "authors": ["Ziang Cao", "Zhaoxi Chen", "Liang Pan", "Ziwei Liu"], "title": "Collaborative Multi-Modal Coding for High-Quality 3D Generation", "comment": null, "summary": "3D content inherently encompasses multi-modal characteristics and can be\nprojected into different modalities (e.g., RGB images, RGBD, and point clouds).\nEach modality exhibits distinct advantages in 3D asset modeling: RGB images\ncontain vivid 3D textures, whereas point clouds define fine-grained 3D\ngeometries. However, most existing 3D-native generative architectures either\noperate predominantly within single-modality paradigms-thus overlooking the\ncomplementary benefits of multi-modality data-or restrict themselves to 3D\nstructures, thereby limiting the scope of available training datasets. To\nholistically harness multi-modalities for 3D modeling, we present TriMM, the\nfirst feed-forward 3D-native generative model that learns from basic\nmulti-modalities (e.g., RGB, RGBD, and point cloud). Specifically, 1) TriMM\nfirst introduces collaborative multi-modal coding, which integrates\nmodality-specific features while preserving their unique representational\nstrengths. 2) Furthermore, auxiliary 2D and 3D supervision are introduced to\nraise the robustness and performance of multi-modal coding. 3) Based on the\nembedded multi-modal code, TriMM employs a triplane latent diffusion model to\ngenerate 3D assets of superior quality, enhancing both the texture and the\ngeometric detail. Extensive experiments on multiple well-known datasets\ndemonstrate that TriMM, by effectively leveraging multi-modality, achieves\ncompetitive performance with models trained on large-scale datasets, despite\nutilizing a small amount of training data. Furthermore, we conduct additional\nexperiments on recent RGB-D datasets, verifying the feasibility of\nincorporating other multi-modal datasets into 3D generation.", "AI": {"tldr": "TriMM is a feed-forward 3D-native generator that learns from multiple modalities (RGB, RGBD, and point clouds) via collaborative multi-modal coding and a triplane latent diffusion model, achieving high-quality 3D assets with limited data.", "motivation": "3D content is inherently multi-modal; existing 3D generators are often single-modality or 3D-only, underutilizing complementary information from RGB, depth, and point clouds.", "method": "TriMM introduces collaborative multi-modal coding to fuse modality-specific features while preserving their strengths, adds auxiliary 2D and 3D supervision, and uses a triplane latent diffusion model conditioned on the multi-modal code to generate 3D assets.", "result": "Experiments across multiple datasets show TriMM achieves competitive performance with models trained on large-scale data despite limited training data; RGB-D data and other modalities can be incorporated, validating the approach\u2019s data-efficiency and versatility.", "conclusion": "Multi-modal integration in 3D generation enhances texture and geometry quality with higher data efficiency; TriMM demonstrates a scalable framework for leveraging multiple modalities in 3D generation."}}
{"id": "2508.15294", "categories": ["cs.AI", "cs.CL", "cs.MA", "I.2.7"], "pdf": "https://arxiv.org/pdf/2508.15294", "abs": "https://arxiv.org/abs/2508.15294", "authors": ["Gaoke Zhang", "Bo Wang", "Yunlong Ma", "Dongming Zhao", "Zifei Yu"], "title": "Multiple Memory Systems for Enhancing the Long-term Memory of Agent", "comment": null, "summary": "An agent powered by large language models have achieved impressive results,\nbut effectively handling the vast amounts of historical data generated during\ninteractions remains a challenge. The current approach is to design a memory\nmodule for the agent to process these data. However, existing methods, such as\nMemoryBank and A-MEM, have poor quality of stored memory content, which affects\nrecall performance and response quality. In order to better construct\nhigh-quality long-term memory content, we have designed a multiple memory\nsystem (MMS) inspired by cognitive psychology theory. The system processes\nshort-term memory to multiple long-term memory fragments, and constructs\nretrieval memory units and contextual memory units based on these fragments,\nwith a one-to-one correspondence between the two. During the retrieval phase,\nMMS will match the most relevant retrieval memory units based on the user's\nquery. Then, the corresponding contextual memory units is obtained as the\ncontext for the response stage to enhance knowledge, thereby effectively\nutilizing historical data. Experiments on LoCoMo dataset compared our method\nwith three others, proving its effectiveness. Ablation studies confirmed the\nrationality of our memory units. We also analyzed the robustness regarding the\nnumber of selected memory segments and the storage overhead, demonstrating its\npractical value.", "AI": {"tldr": "A cognitive-inspired multiple memory system (MMS) improves long-term memory for LLM agents by converting short-term interactions into structured retrieval and contextual memory units, enabling effective retrieval-based context; validated on LoCoMo with ablations showing robustness and efficiency.", "motivation": "Handling vast historical interaction data is challenging; existing memory modules (e.g., MemoryBank, A-MEM) yield low-quality stored content, hurting recall and response quality; need high-quality long-term memory content and scalable retrieval.", "method": "Propose MMS that processes short-term memory into multiple long-term memory fragments, forming a one-to-one correspondence between retrieval memory units and contextual memory units. During retrieval, MMS selects the most relevant retrieval memory units for the user query and uses the corresponding contextual memory units as context for response generation.", "result": "Evaluated on the LoCoMo dataset, MMS outperforms three baselines. Ablation studies validate the necessity of the memory units. Analyses show robustness to the number of selected memory segments and storage overhead, indicating practical viability.", "conclusion": "MMS provides a cognitively inspired long-term memory architecture for LLM agents, yielding higher recall quality and response quality by organizing historical data into structured memory units and leveraging them during retrieval. The approach demonstrates robustness and practical storage efficiency."}}
{"id": "2508.15071", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.15071", "abs": "https://arxiv.org/abs/2508.15071", "authors": ["Rustem Islamov", "Niccolo Ajroldi", "Antonio Orvieto", "Aurelien Lucchi"], "title": "Enhancing Optimizer Stability: Momentum Adaptation of The NGN Step-size", "comment": null, "summary": "Modern optimization algorithms that incorporate momentum and adaptive\nstep-size offer improved performance in numerous challenging deep learning\ntasks. However, their effectiveness is often highly sensitive to the choice of\nhyperparameters, especially the step-size. Tuning these parameters is often\ndifficult, resource-intensive, and time-consuming. Therefore, recent efforts\nhave been directed toward enhancing the stability of optimizers across a wide\nrange of hyperparameter choices [Schaipp et al., 2024]. In this paper, we\nintroduce an algorithm that matches the performance of state-of-the-art\noptimizers while improving stability to the choice of the step-size\nhyperparameter through a novel adaptation of the NGN step-size method [Orvieto\nand Xiao, 2024]. Specifically, we propose a momentum-based version (NGN-M) that\nattains the standard convergence rate of $\\mathcal{O}(1/\\sqrt{K})$ under less\nrestrictive assumptions, without the need for interpolation condition or\nassumptions of bounded stochastic gradients or iterates, in contrast to\nprevious approaches. Additionally, we empirically demonstrate that the\ncombination of the NGN step-size with momentum results in enhanced robustness\nto the choice of the step-size hyperparameter while delivering performance that\nis comparable to or surpasses other state-of-the-art optimizers.", "AI": {"tldr": "NGN-M: a momentum-based NGN step-size adaptation that matches state-of-the-art optimizers while being more robust to step-size hyperparameter choices; achieves O(1/\u221aK) convergence under weaker assumptions.", "motivation": "Hyperparameter sensitivity of momentum/adaptive optimizers, especially step-size, leads to costly tuning. There is a need for algorithms that perform well across a wide range of step-sizes.", "method": "Introduce NGN-M, a momentum-based extension of the NGN step-size method. Theoretical analysis shows standard 1/\u221aK convergence under weaker conditions (no interpolation, no bounded gradients/iterates). Empirical experiments compare NGN-M against other optimizers, highlighting robustness to step-size choice.", "result": "NGN-M achieves performance comparable to or better than state-of-the-art optimizers and demonstrates enhanced robustness to step-size hyperparameters in practice.", "conclusion": "NGN-M provides stable and competitive optimization with reduced sensitivity to step-size, broadening practical applicability of adaptive/momentum-based methods."}}
{"id": "2508.15231", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15231", "abs": "https://arxiv.org/abs/2508.15231", "authors": ["Shihao Dong", "Xiaotong Zhou", "Yuhui Zheng", "Huiying Xu", "Xinzhong Zhu"], "title": "Center-Oriented Prototype Contrastive Clustering", "comment": null, "summary": "Contrastive learning is widely used in clustering tasks due to its\ndiscriminative representation. However, the conflict problem between classes is\ndifficult to solve effectively. Existing methods try to solve this problem\nthrough prototype contrast, but there is a deviation between the calculation of\nhard prototypes and the true cluster center. To address this problem, we\npropose a center-oriented prototype contrastive clustering framework, which\nconsists of a soft prototype contrastive module and a dual consistency learning\nmodule. In short, the soft prototype contrastive module uses the probability\nthat the sample belongs to the cluster center as a weight to calculate the\nprototype of each category, while avoiding inter-class conflicts and reducing\nprototype drift. The dual consistency learning module aligns different\ntransformations of the same sample and the neighborhoods of different samples\nrespectively, ensuring that the features have transformation-invariant semantic\ninformation and compact intra-cluster distribution, while providing reliable\nguarantees for the calculation of prototypes. Extensive experiments on five\ndatasets show that the proposed method is effective compared to the SOTA. Our\ncode is published on https://github.com/LouisDong95/CPCC.", "AI": {"tldr": "A center-oriented prototype contrastive clustering method with soft prototype weighting and dual consistency to reduce inter-class conflicts and prototype drift, achieving state-of-the-art results on five datasets.", "motivation": "Contrastive clustering often struggles with conflicts between classes and prototype drift when using hard prototypes; need center-aligned prototypes to improve clustering accuracy.", "method": "Proposes a two-module framework: (1) soft prototype contrastive module that weights prototypes by the probability of a sample belonging to a cluster center to reduce inter-class conflicts; (2) dual consistency learning module that enforces transformation-invariance and compact intra-cluster neighborhoods to stabilize prototypes.", "result": "Empirical evaluation on five datasets shows the method outperforms state-of-the-art methods; code released.", "conclusion": "Center-oriented prototype contrastive clustering effectively mitigates prototype drift and class conflicts, yielding robust clustering with better semantic alignment; the approach is practical and reproducible."}}
{"id": "2508.15305", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15305", "abs": "https://arxiv.org/abs/2508.15305", "authors": ["Wei Yang", "Jinwei Xiao", "Hongming Zhang", "Qingyang Zhang", "Yanna Wang", "Bo Xu"], "title": "Coarse-to-Fine Grounded Memory for LLM Agent Planning", "comment": "Accepted to EMNLP 2025 Main Conference;27 pages,15 figures", "summary": "Recent advancements in Large Language Models (LLMs) have driven growing\ninterest in LLM-based agents for complex planning tasks. To avoid costly agent\ntraining, many studies adopted memory mechanism that enhances LLM with offline\nexperiences or online trajectory analysis. However, existing works focus on\nsingle-granularity memory derived from dynamic environmental interactions,\nwhich are inherently constrained by the quality of the collected experiences.\nThis limitation, in turn, constrain the diversity of knowledge and the\nflexibility of planning. We propose Coarse-to-Fine Grounded Memory (\\Ours{}), a\nnovel framework that grounds coarse-to-fine memories with LLM, thereby fully\nleverage them for flexible adaptation to diverse scenarios. \\Ours{} grounds\nenvironmental information into coarse-grained focus points to guide experience\ncollection in training tasks, followed by grounding of actionable\nhybrid-grained tips from each experience. At inference, \\Ours{} retrieves\ntask-relevant experiences and tips to support planning. When facing\nenvironmental anomalies, the LLM grounds the current situation into\nfine-grained key information, enabling flexible self-QA reflection and plan\ncorrection.", "AI": {"tldr": "A framework (Coarse-to-Fine Grounded Memory) for LLM-based agents that uses coarse-grained memories to guide experience collection and fine-grained tips to support planning; retrieves experiences and tips at inference; uses fine-grained grounding for self-reflection and plan correction when anomalies occur.", "motivation": "Single-granularity memory limits knowledge diversity and planning flexibility due to reliance on the quality of collected experiences; there is a need for scalable, diverse grounding that enables flexible planning without costly retraining.", "method": "Ground environment into coarse-grained focus points to guide experience collection during training; extract actionable hybrid-grained tips from each experience; at inference, retrieve task-relevant experiences and tips to aid planning; when facing environmental anomalies, ground the current situation into fine-grained key information to enable self-questioning and plan correction.", "result": "Not specified in the abstract; the work proposes a framework and expected benefits (flexible adaptation and planning) but reports no empirical results in the abstract.", "conclusion": "Grounding current situations with fine-grained information enables flexible self-QA reflection and plan correction, supporting adaptation across diverse scenarios."}}
{"id": "2508.15086", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15086", "abs": "https://arxiv.org/abs/2508.15086", "authors": ["Yen-Lung Lai", "Zhe Jin"], "title": "Wormhole Dynamics in Deep Neural Networks", "comment": null, "summary": "This work investigates the generalization behavior of deep neural networks\n(DNNs), focusing on the phenomenon of \"fooling examples,\" where DNNs\nconfidently classify inputs that appear random or unstructured to humans. To\nexplore this phenomenon, we introduce an analytical framework based on maximum\nlikelihood estimation, without adhering to conventional numerical approaches\nthat rely on gradient-based optimization and explicit labels. Our analysis\nreveals that DNNs operating in an overparameterized regime exhibit a collapse\nin the output feature space. While this collapse improves network\ngeneralization, adding more layers eventually leads to a state of degeneracy,\nwhere the model learns trivial solutions by mapping distinct inputs to the same\noutput, resulting in zero loss. Further investigation demonstrates that this\ndegeneracy can be bypassed using our newly derived \"wormhole\" solution. The\nwormhole solution, when applied to arbitrary fooling examples, reconciles\nmeaningful labels with random ones and provides a novel perspective on shortcut\nlearning. These findings offer deeper insights into DNN generalization and\nhighlight directions for future research on learning dynamics in unsupervised\nsettings to bridge the gap between theory and practice.", "AI": {"tldr": "Overparameterized DNNs exhibit a collapse of the output feature space that initially improves generalization but eventually leads to degeneracy where distinct inputs map to the same output, causing zero loss; a proposed 'wormhole' solution bypasses this degeneracy and links fooling examples to meaningful labels, offering a new view on shortcut learning.", "motivation": "Understand generalization and fooling examples from a theoretical, maximum-likelihood perspective, avoiding reliance on gradient-based optimization and explicit labels.", "method": "An analytical framework based on maximum likelihood estimation; analysis of overparameterized regimes, output-space collapse and degeneracy; introduction of a 'wormhole' solution to bypass degeneracy in fooling examples.", "result": "Demonstrates that output-space collapse can improve generalization but deeper networks induce degeneracy; the wormhole solution resolves this by reconciling fooling inputs with meaningful labels, offering a novel lens on shortcut learning.", "conclusion": "Provides deeper theoretical insights into DNN generalization, identifies the limits of overparameterized regimes, and suggests future work in learning dynamics for unsupervised settings to bridge theory and practice."}}
{"id": "2508.15232", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15232", "abs": "https://arxiv.org/abs/2508.15232", "authors": ["Ruipu Wu", "Yige Zhang", "Jinyu Chen", "Linjiang Huang", "Shifeng Zhang", "Xu Zhou", "Liang Wang", "Si Liu"], "title": "AeroDuo: Aerial Duo for UAV-based Vision and Language Navigation", "comment": "Accepted by ACM MM 2025", "summary": "Aerial Vision-and-Language Navigation (VLN) is an emerging task that enables\nUnmanned Aerial Vehicles (UAVs) to navigate outdoor environments using natural\nlanguage instructions and visual cues. However, due to the extended\ntrajectories and complex maneuverability of UAVs, achieving reliable UAV-VLN\nperformance is challenging and often requires human intervention or overly\ndetailed instructions. To harness the advantages of UAVs' high mobility, which\ncould provide multi-grained perspectives, while maintaining a manageable motion\nspace for learning, we introduce a novel task called Dual-Altitude UAV\nCollaborative VLN (DuAl-VLN). In this task, two UAVs operate at distinct\naltitudes: a high-altitude UAV responsible for broad environmental reasoning,\nand a low-altitude UAV tasked with precise navigation. To support the training\nand evaluation of the DuAl-VLN, we construct the HaL-13k, a dataset comprising\n13,838 collaborative high-low UAV demonstration trajectories, each paired with\ntarget-oriented language instructions. This dataset includes both unseen maps\nand an unseen object validation set to systematically evaluate the model's\ngeneralization capabilities across novel environments and unfamiliar targets.\nTo consolidate their complementary strengths, we propose a dual-UAV\ncollaborative VLN framework, AeroDuo, where the high-altitude UAV integrates a\nmultimodal large language model (Pilot-LLM) for target reasoning, while the\nlow-altitude UAV employs a lightweight multi-stage policy for navigation and\ntarget grounding. The two UAVs work collaboratively and only exchange minimal\ncoordinate information to ensure efficiency.", "AI": {"tldr": "Introduce DuAl-VLN, a dual-altitude UAV joint task for navigation, with HaL-13k dataset and AeroDuo framework enabling high-altitude reasoning via Pilot-LLM and low-altitude precise grounding with a lightweight policy; minimal inter-UAV communication.", "motivation": "VLN for UAVs is challenging due to long trajectories and maneuverability; dual-altitude collaboration provides complementary perspectives (global reasoning vs local precision) while keeping the policy space manageable and reducing human intervention.", "method": "Define a Dual-Altitude UAV Collaborative VLN (DuAl-VLN) task; build HaL-13k dataset with 13,838 high-low collaborative trajectories and target-oriented instructions; propose AeroDuo framework where high-altitude UAV uses a multimodal LLM (Pilot-LLM) for target reasoning and low-altitude UAV uses a multi-stage lightweight policy for navigation and grounding; exchange of only minimal coordinate information.", "result": "HaL-13k dataset and the DuAl-VLN task are introduced; AeroDuo demonstrates how dual perspectives can be integrated to handle unseen maps and objects via evaluation with unseen maps and object validation; provides a foundation for generalization in UAV-VLN with limited communication.", "conclusion": "Dual-altitude collaboration synergizes global reasoning and local navigation to address UAV-VLN challenges, enabling robust, generalizable navigation in outdoor environments with reduced human input and efficient communication."}}
{"id": "2508.15327", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15327", "abs": "https://arxiv.org/abs/2508.15327", "authors": ["Xiancheng Gao", "Yufeng Shi", "Wengang Zhou", "Houqiang Li"], "title": "Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning", "comment": "7 pages, 6 figures, under review", "summary": "Offline reinforcement learning refers to the process of learning policies\nfrom fixed datasets, without requiring additional environment interaction.\nHowever, it often relies on well-defined reward functions, which are difficult\nand expensive to design. Human feedback is an appealing alternative, but its\ntwo common forms, expert demonstrations and preferences, have complementary\nlimitations. Demonstrations provide stepwise supervision, but they are costly\nto collect and often reflect limited expert behavior modes. In contrast,\npreferences are easier to collect, but it is unclear which parts of a behavior\ncontribute most to a trajectory segment, leaving credit assignment unresolved.\nIn this paper, we introduce a Search-Based Preference Weighting (SPW) scheme to\nunify these two feedback sources. For each transition in a preference labeled\ntrajectory, SPW searches for the most similar state-action pairs from expert\ndemonstrations and directly derives stepwise importance weights based on their\nsimilarity scores. These weights are then used to guide standard preference\nlearning, enabling more accurate credit assignment that traditional approaches\nstruggle to achieve. We demonstrate that SPW enables effective joint learning\nfrom preferences and demonstrations, outperforming prior methods that leverage\nboth feedback types on challenging robot manipulation tasks.", "AI": {"tldr": "A method named SPW unifies offline RL with human feedback by assigning stepwise weights to transitions based on similarity to expert demonstrations, enabling joint learning from preferences and demonstrations and improving credit assignment on robot manipulation tasks.", "motivation": "Offline RL typically needs reward signals; expert demonstrations and preferences each have limitations. Demonstrations are costly and cover limited behaviors; preferences are easier to collect but suffer from credit assignment. A unified approach could leverage both sources effectively.", "method": "SPW, for every transition in a preference-labeled trajectory, searches for the most similar state-action pairs from expert demonstrations and derives stepwise importance weights from their similarity. These weights guide standard preference learning, improving credit assignment and usage of both feedback types.", "result": "The approach enables effective joint learning from preferences and demonstrations and outperforms prior methods that use both feedback types on challenging robot manipulation tasks.", "conclusion": "SPW provides a unified framework for combining demonstrations and preferences in offline RL, improving credit assignment and performance, and reducing reliance on carefully designed reward functions."}}
{"id": "2508.15094", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15094", "abs": "https://arxiv.org/abs/2508.15094", "authors": ["Moghis Fereidouni", "Muhammad Umair Haider", "Peizhong Ju", "A. B. Siddique"], "title": "Evaluating Sparse Autoencoders for Monosemantic Representation", "comment": null, "summary": "A key barrier to interpreting large language models is polysemanticity, where\nneurons activate for multiple unrelated concepts. Sparse autoencoders (SAEs)\nhave been proposed to mitigate this issue by transforming dense activations\ninto sparse, more interpretable features. While prior work suggests that SAEs\npromote monosemanticity, there has been no quantitative comparison with their\nbase models. This paper provides the first systematic evaluation of SAEs\nagainst base models concerning monosemanticity. We introduce a fine-grained\nconcept separability score based on the Jensen-Shannon distance, which captures\nhow distinctly a neuron's activation distributions vary across concepts. Using\nGemma-2-2B and multiple SAE variants across five benchmarks, we show that SAEs\nreduce polysemanticity and achieve higher concept separability. However,\ngreater sparsity of SAEs does not always yield better separability and often\nimpairs downstream performance. To assess practical utility, we evaluate\nconcept-level interventions using two strategies: full neuron masking and\npartial suppression. We find that, compared to base models, SAEs enable more\nprecise concept-level control when using partial suppression. Building on this,\nwe propose Attenuation via Posterior Probabilities (APP), a new intervention\nmethod that uses concept-conditioned activation distributions for targeted\nsuppression. APP outperforms existing approaches in targeted concept removal.", "AI": {"tldr": "Sparse autoencoders (SAEs) reduce polysemanticity and improve concept separability in LLM neurons compared to base models, but higher sparsity can hurt downstream performance; concept-level interventions like APP enable more precise targeted suppression.", "motivation": "Address polysemanticity in large language models by quantifying monosemanticity with a Jensen-Shannon-based separability score and systematically comparing SAEs to base models; evaluate practical concept-level interventions.", "method": "Evaluate Gemma-2-2B with multiple SAE variants over five benchmarks; compute a fine-grained concept separability score via Jensen-Shannon distance; test two intervention strategies (full neuron masking and partial suppression); propose Attenuation via Posterior Probabilities (APP) using concept-conditioned activation distributions for targeted suppression; compare against existing methods.", "result": "SAEs reduce polysemanticity and increase concept separability relative to base models; however, greater sparsity does not consistently improve separability and can impair downstream performance; partial suppression affords more precise concept-level control; APP outperforms existing approaches for targeted concept removal.", "conclusion": "SAEs offer interpretability benefits with caveats about sparsity levels; achieving a balance is important; APP provides a strong, targeted intervention for removing specific concepts, suggesting a practical path for controllable, monosemantic activation in LLMs."}}
{"id": "2508.15233", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15233", "abs": "https://arxiv.org/abs/2508.15233", "authors": ["Wenju Xu"], "title": "Pretrained Diffusion Models Are Inherently Skipped-Step Samplers", "comment": null, "summary": "Diffusion models have been achieving state-of-the-art results across various\ngeneration tasks. However, a notable drawback is their sequential generation\nprocess, requiring long-sequence step-by-step generation. Existing methods,\nsuch as DDIM, attempt to reduce sampling steps by constructing a class of\nnon-Markovian diffusion processes that maintain the same training objective.\nHowever, there remains a gap in understanding whether the original diffusion\nprocess can achieve the same efficiency without resorting to non-Markovian\nprocesses. In this paper, we provide a confirmative answer and introduce\nskipped-step sampling, a mechanism that bypasses multiple intermediate\ndenoising steps in the iterative generation process, in contrast with the\ntraditional step-by-step refinement of standard diffusion inference. Crucially,\nwe demonstrate that this skipped-step sampling mechanism is derived from the\nsame training objective as the standard diffusion model, indicating that\naccelerated sampling via skipped-step sampling via a Markovian way is an\nintrinsic property of pretrained diffusion models. Additionally, we propose an\nenhanced generation method by integrating our accelerated sampling technique\nwith DDIM. Extensive experiments on popular pretrained diffusion models,\nincluding the OpenAI ADM, Stable Diffusion, and Open Sora models, show that our\nmethod achieves high-quality generation with significantly reduced sampling\nsteps.", "AI": {"tldr": "Skipped-step sampling enables faster, Markovian diffusion sampling without changing the training objective, by bypassing multiple denoising steps and integrating with DDIM, yielding high-quality results with far fewer steps.", "motivation": "Address the efficiency gap in diffusion models by showing that the original (Markovian) diffusion process can achieve competitive sampling speed without resorting to non-Markovian variants like DDIM.", "method": "Introduce skipped-step sampling that bypasses multiple intermediate denoising steps in the iterative generation process. Derive this mechanism from the standard diffusion training objective (no changes to training). Combine the technique with DDIM. Validate on pretrained models (OpenAI ADM, Stable Diffusion, Open Sora).", "result": "The approach achieves high-quality generation with significantly reduced sampling steps across multiple pretrained diffusion models, demonstrating that accelerated, yet principled, sampling is feasible in a Markovian setting.", "conclusion": "Skipped-step sampling reveals an intrinsic, Markovian pathway to accelerated diffusion sampling, enabling faster generation without altering the training objective, and complements DDIM to further boost efficiency."}}
{"id": "2508.15335", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15335", "abs": "https://arxiv.org/abs/2508.15335", "authors": ["Bin Deng", "Yizhe Feng", "Zeming Liu", "Qing Wei", "Xiangrong Zhu", "Shuai Chen", "Yuanfang Guo", "Yunhong Wang"], "title": "RETAIL: Towards Real-world Travel Planning for Large Language Models", "comment": null, "summary": "Although large language models have enhanced automated travel planning\nabilities, current systems remain misaligned with real-world scenarios. First,\nthey assume users provide explicit queries, while in reality requirements are\noften implicit. Second, existing solutions ignore diverse environmental factors\nand user preferences, limiting the feasibility of plans. Third, systems can\nonly generate plans with basic POI arrangements, failing to provide all-in-one\nplans with rich details. To mitigate these challenges, we construct a novel\ndataset \\textbf{RETAIL}, which supports decision-making for implicit queries\nwhile covering explicit queries, both with and without revision needs. It also\nenables environmental awareness to ensure plan feasibility under real-world\nscenarios, while incorporating detailed POI information for all-in-one travel\nplans. Furthermore, we propose a topic-guided multi-agent framework, termed\nTGMA. Our experiments reveal that even the strongest existing model achieves\nmerely a 1.0% pass rate, indicating real-world travel planning remains\nextremely challenging. In contrast, TGMA demonstrates substantially improved\nperformance 2.72%, offering promising directions for real-world travel\nplanning.", "AI": {"tldr": "Introduces RETAIL dataset and TGMA framework for travel planning with implicit queries and environmental awareness; shows modest gains over baselines (1.0% vs 2.72% pass rate) and highlights remaining real-world challenges.", "motivation": "Current LLM-based travel planners assume explicit user queries and ignore environmental constraints, diverse user preferences, and rich POI details. There is a need for mechanisms that handle implicit requirements, feasibility under real-world conditions, and all-in-one, detail-rich itineraries.", "method": "Proposes RETAIL, a dataset supporting implicit queries (with/without revision) and explicit queries, plus environmental awareness and rich POI information. Introduces TGMA, a topic-guided multi-agent framework that coordinates agents to produce feasible, detailed travel plans.", "result": "The strongest existing model achieves a 1.0% pass rate on the task; TGMA improves to 2.72%, indicating substantial but still limited progress toward real-world applicability.", "conclusion": "TGMA and RETAIL advance real-world travel planning by accommodating implicit queries, environmental factors, and rich POI details; however the overall performance remains low, signaling the need for further research and validation."}}
{"id": "2508.15099", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.15099", "abs": "https://arxiv.org/abs/2508.15099", "authors": ["Siddharth Chaudhary", "Bennett Browning"], "title": "Hydra: A 1.6B-Parameter State-Space Language Model with Sparse Attention, Mixture-of-Experts, and Memory", "comment": null, "summary": "We present Hydra as an architectural proposal for hybrid long-context\nlanguage models that combine conditional computation, long-context memory\nmechanisms, and sparse mixture-of-experts within an approximately 1.6B\nparameter design envelope. Hydra integrates a Mamba-style Structured State\nSpace Model (SSM) backbone with intermittent sparse global attention,\nchunk-level MoE feed-forward routing, and dual (workspace plus factual PKM)\nmemories. We formalize the component interfaces, give transparent parameter and\ncomplexity accounting, and outline a staged curriculum intended to stably\nactivate the parts. We accompany the specification with illustrative toy-scale\nprototype measurements (tens of millions of parameters on synthetic data) whose\nsole purpose is to demonstrate implementation feasibility and qualitative\nscaling behaviors (for example, long-context throughput crossover and\ncontrollable expert routing), not to claim competitive full-scale performance.\nWe explicitly delineate assumptions and open risks (training complexity, memory\nutilization, specialization dynamics) and position Hydra as a blueprint to\nstimulate empirical follow-up rather than a finished system. By combining SSM\nefficiency, selective sparse attention, MoE capacity, and learnable memory,\nHydra sketches a path toward modular, input-adaptive long-context language\nmodels; validating end-task gains at target scale remains future work.", "AI": {"tldr": "A blueprint for a modular, hybrid long-context LLM architecture (Hydra) at ~1.6B params, combining SSM backbones, intermittent sparse attention, chunk-level MoE routing, and dual memory systems; toy-scale results show feasibility but not full-scale performance, highlighting future empirical validation.", "motivation": "Address the challenge of efficient, scalable, long-context language modeling by proposing a modular architecture that blends structured state-space modeling, selective attention, mixture-of-experts, and persistent memory; provide a blueprint to guide empirical exploration and future validation of end-task gains at scale.", "method": "Propose an architectural design: Mamba-style Structured State Space Model backbone with intermittent sparse global attention, chunk-level MoE feed-forward routing, and dual memories (workspace + factual PKM). Formalize component interfaces, provide parameter and complexity accounting, and outline a staged curriculum to stably activate parts. Include toy-scale prototype measurements (tens of millions of parameters on synthetic data) to demonstrate feasibility and qualitative scaling (e.g., long-context throughput crossover, controllable expert routing) rather than full-scale performance claims.", "result": "Toy-scale prototype measurements on synthetic data with tens of millions of parameters demonstrate feasibility of implementation and show qualitative scaling trends (long-context throughput crossover, controllable expert routing). No claims of competitive full-scale performance.", "conclusion": "Hydra is positioned as a blueprint to stimulate empirical follow-up for modular, input-adaptive long-context LMs. Explicit open risks (training complexity, memory utilization, specialization dynamics) are acknowledged, and validating end-task gains at target scale remains future work."}}
{"id": "2508.15243", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15243", "abs": "https://arxiv.org/abs/2508.15243", "authors": ["Yixin Gao", "Xin Li", "Xiaohan Pan", "Runsen Feng", "Bingchen Li", "Yunpeng Qi", "Yiting Lu", "Zhengxue Cheng", "Zhibo Chen", "J\u00f6rn Ostermann"], "title": "Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent", "comment": null, "summary": "We present Comp-X, the first intelligently interactive image compression\nparadigm empowered by the impressive reasoning capability of large language\nmodel (LLM) agent. Notably, commonly used image codecs usually suffer from\nlimited coding modes and rely on manual mode selection by engineers, making\nthem unfriendly for unprofessional users. To overcome this, we advance the\nevolution of image coding paradigm by introducing three key innovations: (i)\nmulti-functional coding framework, which unifies different coding modes of\nvarious objective/requirements, including human-machine perception, variable\ncoding, and spatial bit allocation, into one framework. (ii) interactive coding\nagent, where we propose an augmented in-context learning method with coding\nexpert feedback to teach the LLM agent how to understand the coding request,\nmode selection, and the use of the coding tools. (iii) IIC-bench, the first\ndedicated benchmark comprising diverse user requests and the corresponding\nannotations from coding experts, which is systematically designed for\nintelligently interactive image compression evaluation. Extensive experimental\nresults demonstrate that our proposed Comp-X can understand the coding requests\nefficiently and achieve impressive textual interaction capability. Meanwhile,\nit can maintain comparable compression performance even with a single coding\nframework, providing a promising avenue for artificial general intelligence\n(AGI) in image compression.", "AI": {"tldr": "Comp-X introduces an LLM-driven interactive image compression framework that unifies multiple coding modes, enables interactive coding with expert-guided learning, and provides IIC-bench for evaluation; it achieves efficient understanding and competitive compression under a single framework, signaling AGI potential in image compression.", "motivation": "Conventional image codecs offer limited modes and rely on manual mode selection, creating a usability gap for non-experts; an intelligent, interactive solution could democratize image compression and adapt to diverse tasks.", "method": "Three innovations: (i) multi-functional coding framework unifying varied coding modes (perception-oriented, variable coding, spatial bit allocation); (ii) interactive coding agent using augmented in-context learning with coding expert feedback to guide request interpretation, mode selection, and tool use; (iii) IIC-bench benchmark with diverse user requests and expert annotations to evaluate intelligent interactivity in image compression.", "result": "Experiments show Comp-X understands coding requests efficiently, demonstrates strong textual interaction, and maintains compression performance comparable to traditional frameworks when using a single framework.", "conclusion": "This work points toward AGI in image compression, demonstrating that an LLM-powered, interactive approach can generalize across coding tasks while preserving efficiency."}}
{"id": "2508.15338", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15338", "abs": "https://arxiv.org/abs/2508.15338", "authors": ["Jinning Yang", "Wen Shi"], "title": "DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized ECG Tokenization", "comment": null, "summary": "Electrocardiography plays a central role in cardiovascular diagnostics, yet\nexisting automated approaches often struggle to generalize across clinical\ntasks and offer limited support for open-ended reasoning. We present DiagECG, a\nnovel framework that integrates time-series and language modeling by enabling\nlarge language models to process 12-lead ECG signals for clinical text\ngeneration tasks. Our approach discretizes continuous ECG embeddings into\nsymbolic tokens using a lead-independent encoder and quantization module. These\ntokens are then used to extend the vocabulary of LLM, allowing the model to\nhandle both ECG and natural language inputs in a unified manner. To bridge the\nmodality gap, we pretrain the model on an autoregressive ECG forecasting task,\nenabling the LLM to model temporal dynamics using its native language modeling\ncapabilities. Finally, we perform instruction tuning on both ECG question\nanswering and diagnostic report generation. Without modifying the core model,\nDiagECG achieves strong performance across tasks while maintaining\ngeneralization to out-of-distribution settings. Extensive experiments\ndemonstrate the effectiveness of each component and highlight the potential of\nintegrating symbolic ECG representations into LLMs for medical reasoning.", "AI": {"tldr": "DiagECG: a framework that tokenizes 12-lead ECG signals into symbolic tokens and fuses them with an LLM for unified ECG-text reasoning, using autoregressive ECG forecasting and instruction tuning to enable robust open-ended clinical tasks.", "motivation": "Generalization gaps across clinical tasks and limited open-ended reasoning in current automated ECG systems.", "method": "Lead-independent encoder+quantizer to produce ECG tokens; extend LLM vocabulary with ECG tokens; autoregressive ECG forecasting pretraining; instruction tuning on ECG QA and diagnostic report generation; no modifications to core LLM.", "result": "Strong performance across tasks and out-of-distribution generalization; ablations show contributions; demonstrates potential of symbolic ECG representations for medical reasoning.", "conclusion": "Symbolic ECG representations integrated into LLMs enable unified ECG and language reasoning for clinical workflows."}}
{"id": "2508.15124", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15124", "abs": "https://arxiv.org/abs/2508.15124", "authors": ["Shaswati Saha", "Sourajit Saha", "Manas Gaur", "Tejas Gokhale"], "title": "Side Effects of Erasing Concepts from Diffusion Models", "comment": "Findings of the Association for Computational Linguistics: EMNLP 2025", "summary": "Concerns about text-to-image (T2I) generative models infringing on privacy,\ncopyright, and safety have led to the development of Concept Erasure Techniques\n(CETs).\n  The goal of an effective CET is to prohibit the generation of undesired\n``target'' concepts specified by the user, while preserving the ability to\nsynthesize high-quality images of the remaining concepts.\n  In this work, we demonstrate that CETs can be easily circumvented and present\nseveral side effects of concept erasure.\n  For a comprehensive measurement of the robustness of CETs, we present Side\nEffect Evaluation (\\see), an evaluation benchmark that consists of hierarchical\nand compositional prompts that describe objects and their attributes.\n  This dataset and our automated evaluation pipeline quantify side effects of\nCETs across three aspects: impact on neighboring concepts, evasion of targets,\nand attribute leakage.\n  Our experiments reveal that CETs can be circumvented by using\nsuperclass-subclass hierarchy and semantically similar prompts, such as\ncompositional variants of the target. We show that CETs suffer from attribute\nleakage and counterintuitive phenomena of attention concentration or dispersal.\n  We release our dataset, code, and evaluation tools to aid future work on\nrobust concept erasure.", "AI": {"tldr": "CETs for erasing target concepts in text-to-image models are fragile and easy to circumvent; the authors introduce Side Effect Evaluation (SEE) to measure robustness and side effects, finding issues like attribute leakage and attention shifts; they release data, code, and tools to advance robust concept erasure.", "motivation": "With growing concerns about privacy, copyright, and safety in text-to-image generation, there is a need to evaluate and improve concept erasure techniques beyond simply removing a target concept, ensuring negligible impact on related concepts and preventing side-channel leakage.", "method": "Propose Side Effect Evaluation (SEE) benchmark consisting of hierarchical and compositional prompts that describe objects and attributes. Develop an automated evaluation pipeline to quantify CET side effects across three axes: impact on neighboring concepts, evasion of targets, and attribute leakage. Conduct experiments showing CETs can be circumvented via superclass-subclass relationships and semantically similar prompts, and analyze attention behavior.", "result": "CETs are vulnerable to circumvention; SEE reveals side effects including attribute leakage and non-intuitive attention patterns (concentration or dispersal) when erasing concepts; the work provides a dataset, code, and tooling for robust evaluation.", "conclusion": "Encourages building more robust CETs and provides resources (dataset, code, tools) to facilitate future research on reliable concept erasure and safety in T2I models."}}
{"id": "2508.15256", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15256", "abs": "https://arxiv.org/abs/2508.15256", "authors": ["Jinsol Song", "Jiamu Wang", "Anh Tien Nguyen", "Keunho Byeon", "Sangjeong Ahn", "Sung Hak Lee", "Jin Tae Kwak"], "title": "Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images", "comment": "Accepted at ICCV 2025. \\c{opyright} IEEE 2025. This is the author's\n  accepted version (camera-ready) of the paper. The definitive version is\n  published in the Proceedings of the IEEE/CVF International Conference on\n  Computer Vision (ICCV 2025). DOI will be updated when available", "summary": "Anomaly detection in computational pathology aims to identify rare and scarce\nanomalies where disease-related data are often limited or missing. Existing\nanomaly detection methods, primarily designed for industrial settings, face\nlimitations in pathology due to computational constraints, diverse tissue\nstructures, and lack of interpretability. To address these challenges, we\npropose Ano-NAViLa, a Normal and Abnormal pathology knowledge-augmented\nVision-Language model for Anomaly detection in pathology images. Ano-NAViLa is\nbuilt on a pre-trained vision-language model with a lightweight trainable MLP.\nBy incorporating both normal and abnormal pathology knowledge, Ano-NAViLa\nenhances accuracy and robustness to variability in pathology images and\nprovides interpretability through image-text associations. Evaluated on two\nlymph node datasets from different organs, Ano-NAViLa achieves the\nstate-of-the-art performance in anomaly detection and localization,\noutperforming competing models.", "AI": {"tldr": "Ano-NAViLa is a vision-language anomaly detection model for pathology that uses a knowledge-augmented normal/abnormal framework with a lightweight MLP, achieving state-of-the-art anomaly detection and localization on two lymph node datasets, with interpretable image-text associations.", "motivation": "Anomaly detection in computational pathology suffers from limited disease data, heterogeneity of tissue structures, computational constraints, and lack of interpretability; existing industrial methods don't translate well to pathology.", "method": "A pre-trained vision-language backbone with a trainable lightweight MLP; integrates normal and abnormal pathology knowledge; leverages image-text associations for interpretability.", "result": "State-of-the-art performance in anomaly detection and localization on two lymph node datasets across organs, outperforming competing models.", "conclusion": "Ano-NAViLa provides robust, interpretable anomaly detection in pathology under limited data and variability, enabling better localization and understanding via image-text alignment."}}
{"id": "2508.15358", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15358", "abs": "https://arxiv.org/abs/2508.15358", "authors": ["Alberto Pozanco", "Marianela Morales", "Daniel Borrajo", "Manuela Veloso"], "title": "Planning with Minimal Disruption", "comment": null, "summary": "In many planning applications, we might be interested in finding plans that\nminimally modify the initial state to achieve the goals. We refer to this\nconcept as plan disruption. In this paper, we formally introduce it, and define\nvarious planning-based compilations that aim to jointly optimize both the sum\nof action costs and plan disruption. Experimental results in different\nbenchmarks show that the reformulated task can be effectively solved in\npractice to generate plans that balance both objectives.", "AI": {"tldr": "Introduces plan disruption as minimal-change planning, formalizes the concept, and presents planning-based compilations that co-optimize action costs with plan disruption; experiments demonstrate practical balance between the two objectives.", "motivation": "To find plans that achieve goals while minimally modifying the initial state, preserving existing conditions and reducing disruption.", "method": "Formally define plan disruption and develop planning-based compilations that optimize a combined objective: the sum of action costs plus plan disruption; evaluate the approach on multiple benchmarks.", "result": "The reformulated task is effectively solvable in practice, producing plans that balance low cost with minimal disruption across tested benchmarks.", "conclusion": "Plan disruption is a viable objective in planning; joint optimization frameworks can yield practical plans that trade off cost against minimal initial-state modification."}}
{"id": "2508.15127", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15127", "abs": "https://arxiv.org/abs/2508.15127", "authors": ["Sk Miraj Ahmed", "Umit Yigit Basaran", "Dripta S. Raychaudhuri", "Arindam Dutta", "Rohit Kundu", "Fahim Faisal Niloy", "Basak Guler", "Amit K. Roy-Chowdhury"], "title": "Towards Source-Free Machine Unlearning", "comment": "Accepted by CVPR 2025", "summary": "As machine learning becomes more pervasive and data privacy regulations\nevolve, the ability to remove private or copyrighted information from trained\nmodels is becoming an increasingly critical requirement. Existing unlearning\nmethods often rely on the assumption of having access to the entire training\ndataset during the forgetting process. However, this assumption may not hold\ntrue in practical scenarios where the original training data may not be\naccessible, i.e., the source-free setting. To address this challenge, we focus\non the source-free unlearning scenario, where an unlearning algorithm must be\ncapable of removing specific data from a trained model without requiring access\nto the original training dataset. Building on recent work, we present a method\nthat can estimate the Hessian of the unknown remaining training data, a crucial\ncomponent required for efficient unlearning. Leveraging this estimation\ntechnique, our method enables efficient zero-shot unlearning while providing\nrobust theoretical guarantees on the unlearning performance, while maintaining\nperformance on the remaining data. Extensive experiments over a wide range of\ndatasets verify the efficacy of our method.", "AI": {"tldr": "Proposes a source-free unlearning method that estimates the Hessian of the remaining data to enable zero-shot unlearning with theoretical guarantees and maintained performance on the remaining data.", "motivation": "The need to remove private or copyrighted information from trained models without access to the original training data, due to privacy/copyright regulations and practicality of data access.", "method": "Estimating the Hessian of the unknown remaining training data and using this estimate to perform unlearning. The method enables zero-shot unlearning and provides theoretical guarantees on unlearning performance while preserving performance on the remaining data.", "result": "Extensive experiments across diverse datasets validating the efficacy and robustness of the proposed source-free unlearning approach.", "conclusion": "The work enables practical source-free unlearning by leveraging Hessian estimation to achieve efficient, theoretically grounded zero-shot unlearning with maintained accuracy on remaining data."}}
{"id": "2508.15272", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15272", "abs": "https://arxiv.org/abs/2508.15272", "authors": ["Han Li", "Shaofei Huang", "Longfei Xu", "Yulu Gao", "Beipeng Mu", "Si Liu"], "title": "RATopo: Improving Lane Topology Reasoning via Redundancy Assignment", "comment": "Accepted by ACM MM 2025", "summary": "Lane topology reasoning plays a critical role in autonomous driving by\nmodeling the connections among lanes and the topological relationships between\nlanes and traffic elements. Most existing methods adopt a\nfirst-detect-then-reason paradigm, where topological relationships are\nsupervised based on the one-to-one assignment results obtained during the\ndetection stage. This supervision strategy results in suboptimal topology\nreasoning performance due to the limited range of valid supervision. In this\npaper, we propose RATopo, a Redundancy Assignment strategy for lane Topology\nreasoning that enables quantity-rich and geometry-diverse topology supervision.\nSpecifically, we restructure the Transformer decoder by swapping the\ncross-attention and self-attention layers. This allows redundant lane\npredictions to be retained before suppression, enabling effective one-to-many\nassignment. We also instantiate multiple parallel cross-attention blocks with\nindependent parameters, which further enhances the diversity of detected lanes.\nExtensive experiments on OpenLane-V2 demonstrate that our RATopo strategy is\nmodel-agnostic and can be seamlessly integrated into existing topology\nreasoning frameworks, consistently improving both lane-lane and lane-traffic\ntopology performance.", "AI": {"tldr": "RATopo introduces redundancy in lane topology reasoning by reconfiguring the Transformer decoder to preserve multiple lane predictions, enabling one-to-many assignments and diverse cross-attention, yielding consistent topology gains across models.", "motivation": "Current one-to-one supervision in first-detect-then-reason pipelines limits topology reasoning quality due to a narrow supervision signal; richer, geometry-diverse supervision is needed.", "method": "Swap cross-attention and self-attention in the Transformer decoder to keep redundant lane predictions prior to suppression, and deploy multiple parallel cross-attention blocks with independent parameters to boost diversity of detected lanes.", "result": "Empirical evaluation on OpenLane-V2 shows RATopo is model-agnostic and improves both lane-lane and lane-traffic topology performance when integrated into existing topology reasoning frameworks.", "conclusion": "RATopo provides a plug-in redundancy assignment strategy that enhances topology reasoning by enabling one-to-many predictions and diverse attention, leading to consistent gains across frameworks."}}
{"id": "2508.15432", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15432", "abs": "https://arxiv.org/abs/2508.15432", "authors": ["Bidyapati Pradhan", "Surajit Dasgupta", "Amit Kumar Saha", "Omkar Anustoop", "Sriram Puttagunta", "Vipul Mittal", "Gopal Sarda"], "title": "GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO", "comment": null, "summary": "The advancement of large language models (LLMs) is critically dependent on\nthe availability of high-quality datasets for Supervised Fine-Tuning (SFT),\nalignment tasks like Direct Preference Optimization (DPO), etc. In this work,\nwe present a comprehensive synthetic data generation framework that facilitates\nscalable, configurable, and high-fidelity generation of synthetic data tailored\nfor these training paradigms. Our approach employs a modular and\nconfiguration-based pipeline capable of modeling complex dialogue flows with\nminimal manual intervention. This framework uses a dual-stage quality tagging\nmechanism, combining heuristic rules and LLM-based evaluations, to\nautomatically filter and score data extracted from OASST-formatted\nconversations, ensuring the curation of high-quality dialogue samples. The\nresulting datasets are structured under a flexible schema supporting both SFT\nand DPO use cases, enabling seamless integration into diverse training\nworkflows. Together, these innovations offer a robust solution for generating\nand managing synthetic conversational data at scale, significantly reducing the\noverhead of data preparation in LLM training pipelines.", "AI": {"tldr": "Modular synthetic data generation framework for LLM training (SFT, DPO) with configurable pipeline and dual-stage quality tagging to curate high-quality OASST-based dialogues; scalable and flexible.", "motivation": "Need high-quality datasets for SFT and alignment tasks; reduce data preparation overhead; enable scalable, high-fidelity synthetic dialogue generation.", "method": "Config-driven, modular pipeline capable of modeling complex dialogue flows with minimal manual intervention; dual-stage quality tagging combining heuristic rules and LLM evaluations; data extracted from OASST-formatted conversations; flexible schema supporting SFT and DPO.", "result": "Produces high-quality synthetic datasets; automated filtering improves data quality; reduces manual data curation overhead; integrates into diverse training workflows.", "conclusion": "Offers a robust, scalable solution for generating and managing synthetic conversational data at scale, enabling easier integration into LLM training pipelines."}}
{"id": "2508.15128", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15128", "abs": "https://arxiv.org/abs/2508.15128", "authors": ["Sridhar Mahadevan"], "title": "Universal Reinforcement Learning in Coalgebras: Asynchronous Stochastic Computation via Conduction", "comment": "45 pages", "summary": "In this paper, we introduce a categorial generalization of RL, termed\nuniversal reinforcement learning (URL), building on powerful mathematical\nabstractions from the study of coinduction on non-well-founded sets and\nuniversal coalgebras, topos theory, and categorial models of asynchronous\nparallel distributed computation. In the first half of the paper, we review the\nbasic RL framework, illustrate the use of categories and functors in RL,\nshowing how they lead to interesting insights. In particular, we also introduce\na standard model of asynchronous distributed minimization proposed by Bertsekas\nand Tsitsiklis, and describe the relationship between metric coinduction and\ntheir proof of the Asynchronous Convergence Theorem. The space of algorithms\nfor MDPs or PSRs can be modeled as a functor category, where the co-domain\ncategory forms a topos, which admits all (co)limits, possesses a subobject\nclassifier, and has exponential objects. In the second half of the paper, we\nmove on to universal coalgebras. Dynamical system models, such as Markov\ndecision processes (MDPs), partially observed MDPs (POMDPs), a predictive state\nrepresentation (PSRs), and linear dynamical systems (LDSs) are all special\ntypes of coalgebras. We describe a broad family of universal coalgebras,\nextending the dynamic system models studied previously in RL. The core problem\nin finding fixed points in RL to determine the exact or approximate (action)\nvalue function is generalized in URL to determining the final coalgebra\nasynchronously in a parallel distributed manner.", "AI": {"tldr": "A category-theoretic generalization of reinforcement learning (URL) that uses coinduction, universal coalgebras, and topos theory to model RL and dynamical systems as universal coalgebras, enabling asynchronous, distributed fixed-point computations via final coalgebras.", "motivation": "To unify reinforcement learning with powerful abstract frameworks (category theory, coalgebras, topos theory) to study convergence, fixed points, and distributed/asynchronous computation in RL, and to extend RL models (MDPs, PSRs, LDSs) within a universal coalgebraic setting.", "method": "Survey and formal synthesis: treat RL with categories and functors; relate asynchronous distributed minimization to Bertsekas\u2013Tsitsiklis framework; model the space of RL algorithms as a functor category whose codomain is a topos; characterize RL dynamical models (MDPs, POMDPs, PSRs, LDSs) as coalgebras; generalize the fixed-point problem to finding the final coalgebra asynchronously in parallel.", "result": "Establishes a cohesive mathematical framework that reinterprets RL constructs as coalgebraic/topos-theoretic objects; connects metric coinduction to asynchronous convergence; shows how the algorithmic landscape for RL can be organized as a functor category with a topos, and extends these ideas to a broad class of universal coalgebras.", "conclusion": "URL provides a unifying, high-level framework that integrates RL with coinductive and coalgebraic methods, enabling asynchronous, distributed computation and offering new avenues for convergence analysis and model generalization across RL variants."}}
{"id": "2508.15297", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15297", "abs": "https://arxiv.org/abs/2508.15297", "authors": ["Zhu Wang", "Homaira Huda Shomee", "Sathya N. Ravi", "Sourav Medya"], "title": "DesignCLIP: Multimodal Learning with CLIP for Design Patent Understanding", "comment": "Accepted by EMNLP 2025. 22 pages, 14 figures", "summary": "In the field of design patent analysis, traditional tasks such as patent\nclassification and patent image retrieval heavily depend on the image data.\nHowever, patent images -- typically consisting of sketches with abstract and\nstructural elements of an invention -- often fall short in conveying\ncomprehensive visual context and semantic information. This inadequacy can lead\nto ambiguities in evaluation during prior art searches. Recent advancements in\nvision-language models, such as CLIP, offer promising opportunities for more\nreliable and accurate AI-driven patent analysis. In this work, we leverage CLIP\nmodels to develop a unified framework DesignCLIP for design patent applications\nwith a large-scale dataset of U.S. design patents. To address the unique\ncharacteristics of patent data, DesignCLIP incorporates class-aware\nclassification and contrastive learning, utilizing generated detailed captions\nfor patent images and multi-views image learning. We validate the effectiveness\nof DesignCLIP across various downstream tasks, including patent classification\nand patent retrieval. Additionally, we explore multimodal patent retrieval,\nwhich provides the potential to enhance creativity and innovation in design by\noffering more diverse sources of inspiration. Our experiments show that\nDesignCLIP consistently outperforms baseline and SOTA models in the patent\ndomain on all tasks. Our findings underscore the promise of multimodal\napproaches in advancing patent analysis. The codebase is available here:\nhttps://anonymous.4open.science/r/PATENTCLIP-4661/README.md.", "AI": {"tldr": "A CLIP-based multimodal framework, DesignCLIP, enhances design patent classification and retrieval by leveraging generated captions, multi-view images, and class-aware contrastive learning, outperforming baselines and SOTA.", "motivation": "Patent design images often lack complete visual/semantic context, leading to ambiguities in prior art searches; CLIP-style vision-language models offer a path to more reliable, AI-driven patent analysis.", "method": "DesignCLIP uses a CLIP backbone with class-aware classification and contrastive learning, generates detailed captions for patent images, and employs multi-view image learning on a large-scale U.S. design patent dataset, targeting classification and retrieval tasks and exploring multimodal patent retrieval.", "result": "DesignCLIP consistently outperforms baseline and SOTA models across design patent classification and retrieval tasks; multimodal retrieval shows potential to broaden sources of inspiration; codebase is available.", "conclusion": "Multimodal, CLIP-based design patent analysis is a promising direction that improves accuracy and versatility in patent analysis, with practical utility for prior art searches and creativity support; a large-scale dataset and code are available to advance this line."}}
{"id": "2508.15447", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15447", "abs": "https://arxiv.org/abs/2508.15447", "authors": ["Zihao Wang", "Junming Zhang"], "title": "From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence", "comment": "Accepted by ECAI 2025", "summary": "Large Language Models (LLMs) have shown promising potential in business\napplications, particularly in enterprise decision support and strategic\nplanning, yet current approaches often struggle to reconcile intricate\noperational analyses with overarching strategic goals across diverse market\nenvironments, leading to fragmented workflows and reduced collaboration across\norganizational levels. This paper introduces BusiAgent, a novel multi-agent\nframework leveraging LLMs for advanced decision-making in complex corporate\nenvironments. BusiAgent integrates three core innovations: an extended\nContinuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a\ngeneralized entropy measure to optimize collaborative efficiency, and a\nmulti-level Stackelberg game to handle hierarchical decision processes.\nAdditionally, contextual Thompson sampling is employed for prompt optimization,\nsupported by a comprehensive quality assurance system to mitigate errors.\nExtensive empirical evaluations across diverse business scenarios validate\nBusiAgent's efficacy, demonstrating its capacity to generate coherent,\nclient-focused solutions that smoothly integrate granular insights with\nhigh-level strategy, significantly outperforming established approaches in both\nsolution quality and user satisfaction. By fusing cutting-edge AI technologies\nwith deep business insights, BusiAgent marks a substantial step forward in\nAI-driven enterprise decision-making, empowering organizations to navigate\ncomplex business landscapes more effectively.", "AI": {"tldr": "BusiAgent is a multi-agent framework using LLMs for enterprise decision-making, integrating an extended CTMDP, a generalized entropy measure, and a multi-level Stackelberg game, with contextual Thompson sampling and QA, achieving superior solution quality and user satisfaction across diverse business scenarios.", "motivation": "Current approaches struggle to reconcile detailed operational analyses with strategic goals across diverse market environments, leading to fragmented workflows and reduced cross-level collaboration.", "method": "Three core innovations: (1) an extended Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling; (2) a generalized entropy measure to optimize collaborative efficiency; (3) a multi-level Stackelberg game to handle hierarchical decision processes. Additional components include contextual Thompson sampling for prompt optimization and a comprehensive quality assurance system to mitigate errors.", "result": "Empirical evaluations across diverse business scenarios show BusiAgent can generate coherent, client-focused solutions that integrate granular insights with high-level strategy, significantly outperforming established approaches in both solution quality and user satisfaction.", "conclusion": "BusiAgent represents a substantial advancement in AI-driven enterprise decision-making, enabling organizations to navigate complex business landscapes more effectively."}}
{"id": "2508.15141", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.15141", "abs": "https://arxiv.org/abs/2508.15141", "authors": ["Wenxuan Bao", "Vincent Bindschaedler"], "title": "Towards Reliable and Generalizable Differentially Private Machine Learning (Extended Version)", "comment": "This paper is published at ACSAC 2024. This is the extended version\n  that includes an overview of the relevant literature. We open-source our\n  codebase at: https://github.com/wenxuan-Bao/Reliable-and-Generalizable-DPML", "summary": "There is a flurry of recent research papers proposing novel differentially\nprivate machine learning (DPML) techniques. These papers claim to achieve new\nstate-of-the-art (SoTA) results and offer empirical results as validation.\nHowever, there is no consensus on which techniques are most effective or if\nthey genuinely meet their stated claims. Complicating matters, heterogeneity in\ncodebases, datasets, methodologies, and model architectures make direct\ncomparisons of different approaches challenging.\n  In this paper, we conduct a reproducibility and replicability (R+R)\nexperiment on 11 different SoTA DPML techniques from the recent research\nliterature. Results of our investigation are varied: while some methods stand\nup to scrutiny, others falter when tested outside their initial experimental\nconditions. We also discuss challenges unique to the reproducibility of DPML,\nincluding additional randomness due to DP noise, and how to address them.\nFinally, we derive insights and best practices to obtain scientifically valid\nand reliable results.", "AI": {"tldr": "An R+R study assessing 11 state-of-the-art differentially private ML techniques. Findings are mixed: some methods reproduce, others fail outside initial conditions. DP-specific randomness adds variability. The paper offers best-practice guidelines for scientifically valid DPML evaluation.", "motivation": "DPML literature reports SoTA results but lacks consensus on which techniques are genuinely reliable due to heterogeneity in codebases, datasets, methodologies, and architectures. A systematic reproducibility and replicability assessment is needed.", "method": "Conduct a reproducibility and replicability (R+R) experiment on 11 recent SoTA DPML techniques from the literature. Reimplement and evaluate them across broader conditions beyond their original experiments, accounting for extra randomness introduced by DP noise, and analyze challenges unique to DPML reproducibility.", "result": "The results are mixed: some DPML techniques hold up under re-evaluation, while others falter outside their original experimental conditions. DP noise adds extra randomness, complicating direct comparisons and replication. The study surfaces variability due to codebase heterogeneity and methodological differences.", "conclusion": "Provides insights and best-practice guidelines to obtain scientifically valid and reliable results in DPML. Highlights DP-specific reproducibility challenges and proposes recommendations for robust evaluation, benchmarking, and reporting to improve reliability in DPML research."}}
{"id": "2508.15298", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15298", "abs": "https://arxiv.org/abs/2508.15298", "authors": ["Darya Taratynova", "Alya Almsouti", "Beknur Kalmakhanbet", "Numan Saeed", "Mohammad Yaqub"], "title": "TPA: Temporal Prompt Alignment for Fetal Congenital Heart Defect Classification", "comment": null, "summary": "Congenital heart defect (CHD) detection in ultrasound videos is hindered by\nimage noise and probe positioning variability. While automated methods can\nreduce operator dependence, current machine learning approaches often neglect\ntemporal information, limit themselves to binary classification, and do not\naccount for prediction calibration. We propose Temporal Prompt Alignment (TPA),\na method leveraging foundation image-text model and prompt-aware contrastive\nlearning to classify fetal CHD on cardiac ultrasound videos. TPA extracts\nfeatures from each frame of video subclips using an image encoder, aggregates\nthem with a trainable temporal extractor to capture heart motion, and aligns\nthe video representation with class-specific text prompts via a margin-hinge\ncontrastive loss. To enhance calibration for clinical reliability, we introduce\na Conditional Variational Autoencoder Style Modulation (CVAESM) module, which\nlearns a latent style vector to modulate embeddings and quantifies\nclassification uncertainty. Evaluated on a private dataset for CHD detection\nand on a large public dataset, EchoNet-Dynamic, for systolic dysfunction, TPA\nachieves state-of-the-art macro F1 scores of 85.40% for CHD diagnosis, while\nalso reducing expected calibration error by 5.38% and adaptive ECE by 6.8%. On\nEchoNet-Dynamic's three-class task, it boosts macro F1 by 4.73% (from 53.89% to\n58.62%). Temporal Prompt Alignment (TPA) is a framework for fetal congenital\nheart defect (CHD) classification in ultrasound videos that integrates temporal\nmodeling, prompt-aware contrastive learning, and uncertainty quantification.", "AI": {"tldr": "Temporal Prompt Alignment (TPA) integrates temporal modeling, prompt-aware contrastive learning, and uncertainty quantification to classify fetal CHD in ultrasound videos, achieving state-of-the-art accuracy and improved calibration.", "motivation": "Image noise and probe positioning variability hinder CHD detection; existing ML approaches underutilize temporal information, are often binary, and lack reliable calibration. A temporally-aware, calibrated, multi-class approach is needed for ultrasound video CHD classification.", "method": "Extract frame-level features from video subclips with an image encoder; employ a trainable temporal extractor to capture heart motion; align video representations with class-specific text prompts using a margin-hinge contrastive loss; incorporate a Conditional Variational Autoencoder Style Modulation (CVAESM) that learns a latent style vector to modulate embeddings and quantify prediction uncertainty; evaluate on a private CHD dataset and EchoNet-Dynamic for systolic dysfunction.", "result": "TPA achieves macro F1 of 85.40% for CHD diagnosis; reduces expected calibration error (ECE) by 5.38% and adaptive ECE by 6.8%; on EchoNet-Dynamic's three-class task, macro F1 improves from 53.89% to 58.62% (4.73-point gain).", "conclusion": "TPA demonstrates that combining temporal modeling, prompt-aware contrastive learning, and uncertainty quantification yields improved diagnostic performance and better calibration in ultrasound video CHD classification."}}
{"id": "2508.15507", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15507", "abs": "https://arxiv.org/abs/2508.15507", "authors": ["Yekun Zhu", "Guang Chen", "Chengjun Mao"], "title": "Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning", "comment": null, "summary": "Large Language Models (LLMs) with chains-of-thought have demonstrated strong\nperformance on an increasing range of tasks, particularly those involving\ncomplex logical reasoning. However, excessively long chains can lead to\noverthinking, causing computational waste and slower responses. This raises a\nquestion: can LLMs dynamically adjust the length of their reasoning processes\nbased on task complexity? To address this, we propose the Think in Blocks\nframework, which enables adaptive reasoning-from zero to deep reasoning-by\npartitioning the reasoning process into a tunable number of blocks. Our main\ncontributions are: (1) Establishing an explicit block-structured paradigm in\nwhich the model first predicts an integer reasoning budget-the number of\nblocks-and then partitions its reasoning accordingly; (2) Training an adaptive\nmodel through a three-stage pipeline-Supervised Fine-Tuning, reward-guided\nDirect Preference Optimization, and Reinforcement Learning-that adjusts its\nreasoning depth to problem difficulty; (3) Exploiting the explicit block count\nto dynamically control reasoning depth at inference time, allowing flexible\nadjustment of chain-of-thought length during deployment.", "AI": {"tldr": "Adaptive chain-of-thought via Think in Blocks: a block-based budgeted reasoning framework for LLMs, with a three-stage training pipeline to match reasoning depth to task difficulty and enable dynamic inference-time control.", "motivation": "Long chain-of-thoughts are computationally expensive and slow; there is a need to dynamically adjust reasoning depth to task complexity and budget.", "method": "Introduce a block-structured paradigm where the model first predicts an integer reasoning budget (number of blocks) and then partitions its reasoning accordingly. Train adaptively via a three-stage pipeline: Supervised Fine-Tuning (SFT), reward-guided Direct Preference Optimization (DPO), and Reinforcement Learning (RL). During inference, use the explicit block count to control reasoning depth and dynamically adjust chain-of-thought length.", "result": "Proposes and formalizes the Think in Blocks framework along with a three-stage training pipeline (SFT, reward-guided DPO, RL) to enable adaptive reasoning depth and dynamic inference-time control of chain-of-thought length.", "conclusion": "An explicit block-budget mechanism provides a controllable handle to balance reasoning depth and efficiency, enabling LLMs to adapt their reasoning to task difficulty and deployment constraints."}}
{"id": "2508.15149", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15149", "abs": "https://arxiv.org/abs/2508.15149", "authors": ["Minh Tran", "Jeffery C. Chan", "Min Li Huang", "Maya Kansara", "John P. Grady", "Christine E. Napier", "Subotheni Thavaneswaran", "Mandy L. Ballinger", "David M. Thomas", "Frank P. Lin"], "title": "A Robust BERT-Based Deep Learning Model for Automated Cancer Type Extraction from Unstructured Pathology Reports", "comment": null, "summary": "The accurate extraction of clinical information from electronic medical\nrecords is particularly critical to clinical research but require much trained\nexpertise and manual labor. In this study we developed a robust system for\nautomated extraction of the specific cancer types for the purpose of supporting\nprecision oncology research. from pathology reports using a fine-tuned RoBERTa\nmodel. This model significantly outperformed the baseline model and a Large\nLanguage Model, Mistral 7B, achieving F1_Bertscore 0.98 and overall exact match\nof 80.61%. This fine-tuning approach demonstrates the potential for scalability\nthat can integrate seamlessly into the molecular tumour board process.\nFine-tuning domain-specific models for precision tasks in oncology, may pave\nthe way for more efficient and accurate clinical information extraction.", "AI": {"tldr": "Fine-tuning a RoBERTa model on pathology reports improves automated extraction of cancer type information for precision oncology; achieves F1-Bertscore 0.98 and 80.61% exact match, outperforming a baseline and Mistral 7B, with potential for scalable integration into molecular tumor boards.", "motivation": "Clinical information extraction from electronic medical records is labor-intensive and requires expert curation. There is a need for scalable, accurate NLP methods to support precision oncology research and decision-making.", "method": "Fine-tune a domain-specific RoBERTa model on pathology reports to extract cancer types. Evaluate against a baseline model and the Mistral 7B large language model, reporting F1-Bertscore and exact-match metrics.", "result": "The RoBERTa-based model achieved F1_Bertscore of 0.98 and exact-match accuracy of 80.61%, outperforming both the baseline model and the Mistral 7B LLM.", "conclusion": "Domain-specific fine-tuning for oncology information extraction can yield highly accurate, scalable solutions that integrate into workflows such as molecular tumor boards, advancing efficient data extraction for precision medicine."}}
{"id": "2508.15299", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15299", "abs": "https://arxiv.org/abs/2508.15299", "authors": ["Ryunosuke Hayashi", "Kohei Torimi", "Rokuto Nagata", "Kazuma Ikeda", "Ozora Sako", "Taichi Nakamura", "Masaki Tani", "Yoshimitsu Aoki", "Kentaro Yoshioka"], "title": "BasketLiDAR: The First LiDAR-Camera Multimodal Dataset for Professional Basketball MOT", "comment": "Accepted to MMSports", "summary": "Real-time 3D trajectory player tracking in sports plays a crucial role in\ntactical analysis, performance evaluation, and enhancing spectator experience.\nTraditional systems rely on multi-camera setups, but are constrained by the\ninherently two-dimensional nature of video data and the need for complex 3D\nreconstruction processing, making real-time analysis challenging. Basketball,\nin particular, represents one of the most difficult scenarios in the MOT field,\nas ten players move rapidly and complexly within a confined court space, with\nfrequent occlusions caused by intense physical contact.\n  To address these challenges, this paper constructs BasketLiDAR, the first\nmultimodal dataset in the sports MOT field that combines LiDAR point clouds\nwith synchronized multi-view camera footage in a professional basketball\nenvironment, and proposes a novel MOT framework that simultaneously achieves\nimproved tracking accuracy and reduced computational cost. The BasketLiDAR\ndataset contains a total of 4,445 frames and 3,105 player IDs, with fully\nsynchronized IDs between three LiDAR sensors and three multi-view cameras. We\nrecorded 5-on-5 and 3-on-3 game data from actual professional basketball\nplayers, providing complete 3D positional information and ID annotations for\neach player. Based on this dataset, we developed a novel MOT algorithm that\nleverages LiDAR's high-precision 3D spatial information. The proposed method\nconsists of a real-time tracking pipeline using LiDAR alone and a multimodal\ntracking pipeline that fuses LiDAR and camera data. Experimental results\ndemonstrate that our approach achieves real-time operation, which was difficult\nwith conventional camera-only methods, while achieving superior tracking\nperformance even under occlusion conditions. The dataset is available upon\nrequest at: https://sites.google.com/keio.jp/keio-csg/projects/basket-lidar", "AI": {"tldr": "BasketLiDAR introduces the first multimodal basketball MOT dataset (BasketLiDAR) combining LiDAR with synchronized multi-view cameras, and a real-time MOT framework for basketball that uses LiDAR alone or fusion with cameras to achieve real-time performance and robust tracking under occlusions; dataset includes 4,445 frames and 3,105 IDs with synchronized IDs across three LiDARs and three cameras; results show real-time operation and improved tracking, especially under occlusion.", "motivation": "Real-time 3D trajectory tracking in sports is challenging due to the inherent 2D nature of video data, heavy occlusions, and the need for accurate 3D reconstruction; basketball is a particularly difficult MOT scenario with rapid, dense player motion.", "method": "Develop BasketLiDAR dataset with synchronized LiDAR point clouds and multi-view camera footage in professional basketball; propose a novel MOT framework with two pipelines: (1) a real-time LiDAR-only tracking pipeline; (2) a multimodal LiDAR-camera fused pipeline; ensure synchronized IDs across three LiDARs and three cameras; evaluate on 5-on-5 and 3-on-3 game data; provide complete 3D positions and IDs for each player.", "result": "The approach achieves real-time operation and superior tracking performance under occlusion, surpassing camera-only methods; the dataset with 4,445 frames and 3,105 IDs is provided by request.", "conclusion": "BasketLiDAR is the first multimodal dataset in sports MOT and enables real-time, robust 3D tracking for basketball; the framework reduces computational costs and improves occlusion handling, enabling advances in tactical analysis, performance evaluation, and spectator experience; dataset availability facilitates future research."}}
{"id": "2508.15510", "categories": ["cs.AI", "I.2.11; I.2.0; J.4; K.4.0; I.2.6"], "pdf": "https://arxiv.org/pdf/2508.15510", "abs": "https://arxiv.org/abs/2508.15510", "authors": ["Filippo Tonini", "Lukas Galke"], "title": "Super-additive Cooperation in Language Model Agents", "comment": "FAIEMA 2025", "summary": "With the prospect of autonomous artificial intelligence (AI) agents, studying\ntheir tendency for cooperative behavior becomes an increasingly relevant topic.\nThis study is inspired by the super-additive cooperation theory, where the\ncombined effects of repeated interactions and inter-group rivalry have been\nargued to be the cause for cooperative tendencies found in humans. We devised a\nvirtual tournament where language model agents, grouped into teams, face each\nother in a Prisoner's Dilemma game. By simulating both internal team dynamics\nand external competition, we discovered that this blend substantially boosts\nboth overall and initial, one-shot cooperation levels (the tendency to\ncooperate in one-off interactions). This research provides a novel framework\nfor large language models to strategize and act in complex social scenarios and\noffers evidence for how intergroup competition can, counter-intuitively, result\nin more cooperative behavior. These insights are crucial for designing future\nmulti-agent AI systems that can effectively work together and better align with\nhuman values. Source code is available at\nhttps://github.com/pippot/Superadditive-cooperation-LLMs.", "AI": {"tldr": "A study uses team-based language-model agents in a Prisoner's Dilemma tournament to show that intergroup competition enhances both overall and one-shot cooperation; it offers a framework for cooperative multi-agent AI and provides code.", "motivation": "To understand whether autonomous AI can exhibit and improve cooperative behavior, motivated by super-additive cooperation theory that repeats interactions and rivalry foster cooperation.", "method": "Simulated tournament with language-model agents organized into teams; agents play Prisoner's Dilemma in repeated rounds; analysis of internal team dynamics and external competition on cooperation levels.", "result": "Intergroup competition combined with repeated interactions significantly increases cooperation, including in one-shot (one-off) interactions; evidence supporting the theory.", "conclusion": "Proposes a framework for designing multi-agent AI that can act cooperatively in social contexts and align with human values; source code available."}}
{"id": "2508.15182", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15182", "abs": "https://arxiv.org/abs/2508.15182", "authors": ["Xiangman Li", "Xiaodong Wu", "Qi Li", "Jianbing Ni", "Rongxing Lu"], "title": "SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks", "comment": null, "summary": "Jailbreak attacks pose a serious threat to the safety of Large Language\nModels (LLMs) by crafting adversarial prompts that bypass alignment mechanisms,\ncausing the models to produce harmful, restricted, or biased content. In this\npaper, we propose SafeLLM, a novel unlearning-based defense framework that\nunlearn the harmful knowledge from LLMs while preserving linguistic fluency and\ngeneral capabilities. SafeLLM employs a three-stage pipeline: (1) dynamic\nunsafe output detection using a hybrid approach that integrates external\nclassifiers with model-internal evaluations; (2) token-level harmful content\ntracing through feedforward network (FFN) activations to localize harmful\nknowledge; and (3) constrained optimization to suppress unsafe behavior without\ndegrading overall model quality. SafeLLM achieves targeted and irreversible\nforgetting by identifying and neutralizing FFN substructures responsible for\nharmful generation pathways. Extensive experiments on prominent LLMs (Vicuna,\nLLaMA, and GPT-J) across multiple jailbreak benchmarks show that SafeLLM\nsubstantially reduces attack success rates while maintaining high\ngeneral-purpose performance. Compared to standard defense methods such as\nsupervised fine-tuning and direct preference optimization, SafeLLM offers\nstronger safety guarantees, more precise control over harmful behavior, and\ngreater robustness to unseen attacks. Moreover, SafeLLM maintains the general\nperformance after the harmful knowledge unlearned. These results highlight\nunlearning as a promising direction for scalable and effective LLM safety.", "AI": {"tldr": "SafeLLM is an unlearning-based defense against jailbreaks that detects unsafe outputs, traces harmful knowledge to FFN activations, and applies constrained optimization to forget harmful substructures, preserving general language abilities across Vicuna, LLaMA, and GPT-J. It outperforms standard defenses and remains robust to unseen attacks.", "motivation": "Jailbreak prompts threaten LLM safety by bypassing alignment. There is a need to irreversibly forget harmful knowledge while preserving fluency and general capabilities, offering scalable safety improvements beyond conventional fine-tuning or PPO objectives.", "method": "Three-stage pipeline: (1) dynamic unsafe output detection using a hybrid approach that combines external classifiers with model-internal evaluations; (2) token-level tracing of harmful content through FFN activations to locate responsible knowledge; (3) constrained optimization to suppress unsafe behavior and neutralize identified FFN substructures, achieving targeted forgetting without degrading general performance.", "result": "Empirical evaluations on Vicuna, LLaMA, and GPT-J across multiple jailbreak benchmarks show substantial reductions in attack success rates while maintaining high general-purpose performance. SafeLLM offers stronger safety guarantees, more precise control over harmful behavior, and robustness to unseen attacks compared to standard defenses like supervised fine-tuning or direct preference optimization.", "conclusion": "Unlearning-based approaches are a promising direction for scalable and effective LLM safety, with SafeLLM demonstrating targeted, irreversible forgetting of harmful knowledge while preserving linguistic fluency and general capabilities."}}
{"id": "2508.15313", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15313", "abs": "https://arxiv.org/abs/2508.15313", "authors": ["Wutao Liu", "YiDan Wang", "Pan Gao"], "title": "First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection", "comment": null, "summary": "Camouflaged object detection (COD) poses a significant challenge in computer\nvision due to the high similarity between objects and their backgrounds.\nExisting approaches often rely on heavy training and large computational\nresources. While foundation models such as the Segment Anything Model (SAM)\noffer strong generalization, they still struggle to handle COD tasks without\nfine-tuning and require high-quality prompts to yield good performance.\nHowever, generating such prompts manually is costly and inefficient. To address\nthese challenges, we propose \\textbf{First RAG, Second SEG (RAG-SEG)}, a\ntraining-free paradigm that decouples COD into two stages: Retrieval-Augmented\nGeneration (RAG) for generating coarse masks as prompts, followed by SAM-based\nsegmentation (SEG) for refinement. RAG-SEG constructs a compact retrieval\ndatabase via unsupervised clustering, enabling fast and effective feature\nretrieval. During inference, the retrieved features produce pseudo-labels that\nguide precise mask generation using SAM2. Our method eliminates the need for\nconventional training while maintaining competitive performance. Extensive\nexperiments on benchmark COD datasets demonstrate that RAG-SEG performs on par\nwith or surpasses state-of-the-art methods. Notably, all experiments are\nconducted on a \\textbf{personal laptop}, highlighting the computational\nefficiency and practicality of our approach. We present further analysis in the\nAppendix, covering limitations, salient object detection extension, and\npossible improvements.", "AI": {"tldr": "A training-free COD method that uses Retrieval-Augmented Generation to create coarse prompt masks, refined by SAM-based segmentation (SAM2), enabling competitive performance on camouflaged object detection using a personal laptop.", "motivation": "Camouflaged object detection is hard due to high similarity between objects and background. Traditional methods rely on heavy training and large compute; even foundation models like SAM need fine-tuning or high-quality prompts. There is a need for a lightweight, training-free approach that reduces computational demands.", "method": "A two-stage framework: (1) Retrieval-Augmented Generation (RAG) builds a compact retrieval database via unsupervised clustering and uses retrieved features to generate pseudo-labels (coarse masks) as prompts; (2) SAM-based segmentation (SEG) refines these prompts to produce precise masks (SAM2). The approach is training-free and aims for efficiency on standard hardware.", "result": "Extensive experiments on benchmark COD datasets show that RAG-SEG achieves performance on par with or better than state-of-the-art methods while running on a personal laptop. The method demonstrates computational efficiency and practicality, with additional analysis in the Appendix addressing limitations, extension to salient object detection, and potential improvements.", "conclusion": "RAG-SEG offers a practical, training-free COD solution by decoupling retrieval-based prompt generation from SAM-based refinement, achieving competitive accuracy with reduced computational burden and broad potential for extension to related vision tasks."}}
{"id": "2508.15548", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15548", "abs": "https://arxiv.org/abs/2508.15548", "authors": ["Jiayi Song", "Rui Wan", "Lipeng Ma", "Weidong Yang", "Qingyuan Zhou", "Yixuan Li", "Ben Fei"], "title": "DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks", "comment": null, "summary": "This work enhances the ability of large language models (LLMs) to perform\ncomplex reasoning in 3D scenes. Recent work has addressed the 3D situated\nreasoning task by invoking tool usage through large language models. Large\nlanguage models call tools via APIs and integrate the generated programs\nthrough a chain of thought to solve problems based on the program results.\nHowever, due to the simplicity of the questions in the dataset, the generated\nprogram reasoning chains are relatively short. To solve this main challenge, in\nthis paper, we introduce DeepThink3D to enhance the tool usage of LLMs in\ncomplex 3D situated reasoning tasks. Our work proposes a combinatorial and\niterative evolutionary approach on the SQA3D benchmark to generate more complex\nquestions. Building on this foundation, we fine-tune the large language model\nto make it more proficient in using 3D tools. By employing Direct Preference\nOptimization (DPO), we directly optimize the toolchain strategies generated by\nmodels, thereby enhancing their accuracy in complex tasks.", "AI": {"tldr": "DeepThink3D enhances LLM 3D reasoning by generating harder questions via an evolutionary process on SQA3D, then fine-tuning with DPO to improve tool usage.", "motivation": "3D situated reasoning tasks currently yield short chain-of-thought; need richer multi-step reasoning and better 3D tool usage.", "method": "Combinatorial and iterative evolutionary generation of complex questions on SQA3D; fine-tune LLMs for 3D tool usage; apply Direct Preference Optimization to optimize toolchain strategies.", "result": "Demonstrates improved accuracy on complex 3D reasoning tasks (via tool usage) according to abstract.", "conclusion": "DeepThink3D effectively enhances LLM tool usage for 3D reasoning through data-driven question complexity, targeted fine-tuning, and DPO."}}
{"id": "2508.15193", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15193", "abs": "https://arxiv.org/abs/2508.15193", "authors": ["Brodie Oldfield", "Ziqi Xu", "Sevvandi Kandanaarachchi"], "title": "Revisiting Pre-processing Group Fairness: A Modular Benchmarking Framework", "comment": "This paper has been accepted to the 34th ACM International Conference\n  on Information and Knowledge Management (CIKM 2025), Resource Track", "summary": "As machine learning systems become increasingly integrated into high-stakes\ndecision-making processes, ensuring fairness in algorithmic outcomes has become\na critical concern. Methods to mitigate bias typically fall into three\ncategories: pre-processing, in-processing, and post-processing. While\nsignificant attention has been devoted to the latter two, pre-processing\nmethods, which operate at the data level and offer advantages such as\nmodel-agnosticism and improved privacy compliance, have received comparatively\nless focus and lack standardised evaluation tools. In this work, we introduce\nFairPrep, an extensible and modular benchmarking framework designed to evaluate\nfairness-aware pre-processing techniques on tabular datasets. Built on the\nAIF360 platform, FairPrep allows seamless integration of datasets, fairness\ninterventions, and predictive models. It features a batch-processing interface\nthat enables efficient experimentation and automatic reporting of fairness and\nutility metrics. By offering standardised pipelines and supporting reproducible\nevaluations, FairPrep fills a critical gap in the fairness benchmarking\nlandscape and provides a practical foundation for advancing data-level fairness\nresearch.", "AI": {"tldr": "FairPrep is a modular, extensible benchmarking framework for fairness-aware pre-processing on tabular data, built on AIF360, enabling standardized, reproducible evaluation of fairness interventions and utility across datasets and models.", "motivation": "As ML systems are increasingly used in high-stakes decisions, bias in outcomes is a critical concern. Pre-processing methods, despite advantages like model-agnosticism and privacy benefits, have received less attention and lack standardized evaluation tools. There is a need for a unified benchmark to advance data-level fairness research.", "method": "Develop FairPrep as an extensible framework on top of AIF360; modular design to integrate datasets, fairness interventions, and predictive models; batch-processing interface for efficient experimentation; automatic reporting of fairness and utility metrics; standardized pipelines to enable reproducible evaluations.", "result": "Introduction of a new benchmarking framework that standardizes evaluation of fairness-aware pre-processing on tabular data, enabling efficient experimentation, reproducible reporting, and a practical foundation for advancing data-level fairness research.", "conclusion": "FairPrep addresses a key gap in fairness benchmarking by providing a practical, reproducible platform for evaluating pre-processing fairness techniques and supporting data-level bias mitigation research."}}
{"id": "2508.15314", "categories": ["cs.CV", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2508.15314", "abs": "https://arxiv.org/abs/2508.15314", "authors": ["Naen Xu", "Jinghuai Zhang", "Changjiang Li", "Zhi Chen", "Chunyi Zhou", "Qingming Li", "Tianyu Du", "Shouling Ji"], "title": "VideoEraser: Concept Erasure in Text-to-Video Diffusion Models", "comment": "To appear in the 2025 Conference on Empirical Methods in Natural\n  Language Processing (EMNLP)", "summary": "The rapid growth of text-to-video (T2V) diffusion models has raised concerns\nabout privacy, copyright, and safety due to their potential misuse in\ngenerating harmful or misleading content. These models are often trained on\nnumerous datasets, including unauthorized personal identities, artistic\ncreations, and harmful materials, which can lead to uncontrolled production and\ndistribution of such content. To address this, we propose VideoEraser, a\ntraining-free framework that prevents T2V diffusion models from generating\nvideos with undesirable concepts, even when explicitly prompted with those\nconcepts. Designed as a plug-and-play module, VideoEraser can seamlessly\nintegrate with representative T2V diffusion models via a two-stage process:\nSelective Prompt Embedding Adjustment (SPEA) and Adversarial-Resilient Noise\nGuidance (ARNG). We conduct extensive evaluations across four tasks, including\nobject erasure, artistic style erasure, celebrity erasure, and explicit content\nerasure. Experimental results show that VideoEraser consistently outperforms\nprior methods regarding efficacy, integrity, fidelity, robustness, and\ngeneralizability. Notably, VideoEraser achieves state-of-the-art performance in\nsuppressing undesirable content during T2V generation, reducing it by 46% on\naverage across four tasks compared to baselines.", "AI": {"tldr": "VideoEraser is a training-free, plug-and-play framework that uses SPEA and ARNG to suppress undesirable concepts in text-to-video diffusion models, achieving a 46% average reduction of problematic content across four erasure tasks.", "motivation": "The rapid rise of text-to-video diffusion models raises privacy, copyright, and safety concerns due to training on unauthorised personal identities, artistic works, and harmful materials, risking uncontrolled generation and distribution.", "method": "A two-stage approach: (1) Selective Prompt Embedding Adjustment (SPEA) to modify prompts to avoid undesired concepts, and (2) Adversarial-Resilient Noise Guidance (ARNG) to guide diffusion outputs away from undesired content. The framework is training-free and plug-and-play with representative T2V diffusion models.", "result": "Extensive evaluations across four tasks\u2014object erasure, artistic style erasure, celebrity erasure, and explicit content erasure\u2014show VideoEraser outperforms baselines in efficacy, integrity, fidelity, robustness, and generalizability, achieving an average 46% reduction of undesirable content across tasks.", "conclusion": "VideoEraser provides an effective, generalizable safety layer for T2V diffusion models without retraining, enabling safer deployment. The approach demonstrates strong practical potential for mitigating misuse in video generation."}}
{"id": "2508.15588", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15588", "abs": "https://arxiv.org/abs/2508.15588", "authors": ["Ahmed Nasir", "Abdelhafid Zenati"], "title": "A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification", "comment": null, "summary": "The application of reinforcement learning to safety-critical systems is\nlimited by the lack of formal methods for verifying the robustness and safety\nof learned policies. This paper introduces a novel framework that addresses\nthis gap by analyzing the combination of an RL agent and its environment as a\ndiscrete-time autonomous dynamical system. By leveraging tools from dynamical\nsystems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we\nidentify and visualize Lagrangian Coherent Structures (LCS) that act as the\nhidden \"skeleton\" governing the system's behavior. We demonstrate that\nrepelling LCS function as safety barriers around unsafe regions, while\nattracting LCS reveal the system's convergence properties and potential failure\nmodes, such as unintended \"trap\" states. To move beyond qualitative\nvisualization, we introduce a suite of quantitative metrics, Mean Boundary\nRepulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and\nTemporally-Aware Spurious Attractor Strength (TASAS), to formally measure a\npolicy's safety margin and robustness. We further provide a method for deriving\nlocal stability guarantees and extend the analysis to handle model uncertainty.\nThrough experiments in both discrete and continuous control environments, we\nshow that this framework provides a comprehensive and interpretable assessment\nof policy behavior, successfully identifying critical flaws in policies that\nappear successful based on reward alone.", "AI": {"tldr": "A framework using Finite-Time Lyapunov Exponents (FTLE) and Lagrangian Coherent Structures (LCS) to analyze RL policies as discrete-time dynamical systems, introducing metrics (MBR, ASAS, TASAS) for safety/robustness and providing local stability guarantees under model uncertainty; demonstrated in discrete and continuous control tasks to reveal flaws not seen by reward signals.", "motivation": "There is a lack of formal methods to verify the robustness and safety of learned policies in safety-critical systems. The work proposes an interpretable dynamical-systems-based analysis to bridge this gap and guide safer RL deployments.", "method": "Model the RL agent-environment interaction as a discrete-time autonomous dynamical system. Compute FTLE fields to identify LCS, with repelling LCS serving as safety barriers and attracting LCS indicating convergence or potential failure modes. Introduce quantitative metrics (MBR, ASAS, TASAS), derive local stability guarantees, and extend the framework to account for model uncertainty. Validate on both discrete and continuous control tasks.", "result": "The framework yields a comprehensive, interpretable assessment of policy behavior, successfully identifying critical flaws that reward-based evaluation misses, and provides quantitative safety/robustness measures across diverse control environments.", "conclusion": "The proposed dynamical-systems analysis offers a formal, interpretable approach to evaluating RL policies for safety and robustness, enabling detection of unsafe regions and failure modes and guiding improvements under uncertainty."}}
{"id": "2508.15198", "categories": ["cs.LG", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2508.15198", "abs": "https://arxiv.org/abs/2508.15198", "authors": ["Jizu Huang", "Rukang You", "Tao Zhou"], "title": "Frequency-adaptive tensor neural networks for high-dimensional multi-scale problems", "comment": null, "summary": "Tensor neural networks (TNNs) have demonstrated their superiority in solving\nhigh-dimensional problems. However, similar to conventional neural networks,\nTNNs are also influenced by the Frequency Principle, which limits their ability\nto accurately capture high-frequency features of the solution. In this work, we\nanalyze the training dynamics of TNNs by Fourier analysis and enhance their\nexpressivity for high-dimensional multi-scale problems by incorporating random\nFourier features. Leveraging the inherent tensor structure of TNNs, we further\npropose a novel approach to extract frequency features of high-dimensional\nfunctions by performing the Discrete Fourier Transform to one-dimensional\ncomponent functions. This strategy effectively mitigates the curse of\ndimensionality. Building on this idea, we propose a frequency-adaptive TNNs\nalgorithm, which significantly improves the ability of TNNs in solving complex\nmulti-scale problems. Extensive numerical experiments are performed to validate\nthe effectiveness and robustness of the proposed frequency-adaptive TNNs\nalgorithm.", "AI": {"tldr": "A frequency-adaptive tensor neural network (TNN) framework is proposed to enhance high-frequency feature capture in high-dimensional multi-scale problems by combining Fourier analysis, random Fourier features, and DFT-based frequency extraction along tensor components, addressing the curse of dimensionality and improving robustness as validated by extensive experiments.", "motivation": "TNNs, like conventional neural networks, suffer from the Frequency Principle, hindering accurate recovery of high-frequency solution features in high-dimensional, multi-scale problems. The work aims to enhance expressivity and training dynamics by leveraging Fourier techniques and the tensor structure.", "method": "1) Analyze TNN training dynamics via Fourier analysis. 2) Introduce random Fourier features to boost high-frequency representation. 3) Exploit tensor structure to extract frequency features by applying the Discrete Fourier Transform to one-dimensional component functions, mitigating dimensionality curse. 4) Propose a frequency-adaptive TNN algorithm built on these ideas. 5) Validate with extensive numerical experiments.", "result": "The proposed framework improves the ability of TNNs to capture high-frequency components in high-dimensional problems, reduces the curse of dimensionality, and demonstrates robustness and effectiveness through extensive numerical experiments.", "conclusion": "Frequency-adaptive TNNs significantly enhance expressivity and performance for complex multi-scale, high-dimensional problems, offering a practical and robust approach validated by numerical studies."}}
{"id": "2508.15336", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15336", "abs": "https://arxiv.org/abs/2508.15336", "authors": ["Subhasis Dasgupta", "Preetam Saha", "Agniva Roy", "Jaydip Sen"], "title": "Predicting Road Crossing Behaviour using Pose Detection and Sequence Modelling", "comment": "This is a pre-print version of the original paper accepted in the\n  IEEE conference INDISCON 2025. It contains 8 figures and 1 table. The length\n  of the paper is 7 pages", "summary": "The world is constantly moving towards AI based systems and autonomous\nvehicles are now reality in different parts of the world. These vehicles\nrequire sensors and cameras to detect objects and maneuver according to that.\nIt becomes important to for such vehicles to also predict from a distant if a\nperson is about to cross a road or not. The current study focused on predicting\nthe intent of crossing the road by pedestrians in an experimental setup. The\nstudy involved working with deep learning models to predict poses and sequence\nmodelling for temporal predictions. The study analysed three different sequence\nmodelling to understand the prediction behaviour and it was found out that GRU\nwas better in predicting the intent compared to LSTM model but 1D CNN was the\nbest model in terms of speed. The study involved video analysis, and the output\nof pose detection model was integrated later on to sequence modelling\ntechniques for an end-to-end deep learning framework for predicting road\ncrossing intents.", "AI": {"tldr": "GRU-based sequence modeling better predicts pedestrian crossing intent from pose sequences than LSTM, while 1D CNN provides faster inference; an end-to-end video\u2192pose\u2192prediction framework is feasible.", "motivation": "Autonomous vehicles require early and reliable prediction of pedestrians' crossing intentions to ensure safety and smooth navigation.", "method": "Experimental study comparing three sequence models (GRU, LSTM, and 1D CNN) on pose-detection outputs derived from video, forming an end-to-end framework from video to crossing-prediction.", "result": "GRU outperforms LSTM in predicting crossing intent; 1D CNN offers the fastest inference time; integrated pipeline from video to pose to sequence modeling is feasible.", "conclusion": "The study shows that the choice of sequence model significantly affects prediction performance, with GRU providing better accuracy than LSTM and 1D CNN offering speed advantages; an end-to-end video-to-pose-to-prediction framework is viable for predicting road-crossing intents in autonomous driving systems."}}
{"id": "2508.15610", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15610", "abs": "https://arxiv.org/abs/2508.15610", "authors": ["Alfio Gliozzo", "Naweed Khan", "Christodoulos Constantinides", "Nandana Mihindukulasooriya", "Nahuel Defosse", "Junkyu Lee"], "title": "Transduction is All You Need for Structured Data Workflows", "comment": "32 pages, 8 figures", "summary": "This paper introduces Agentics, a modular framework for building agent-based\nsystems capable of structured reasoning and compositional generalization over\ncomplex data. Designed with research and practical applications in mind,\nAgentics offers a novel perspective on working with data and AI workflows. In\nthis framework, agents are abstracted from the logical flow and they are used\ninternally to the data type to enable logical transduction among data. Agentics\nencourages AI developers to focus on modeling data rather than crafting\nprompts, enabling a declarative language in which data types are provided by\nLLMs and composed through logical transduction, which is executed by LLMs when\ntypes are connected. We provide empirical evidence demonstrating the\napplicability of this framework across domain-specific multiple-choice question\nanswering, semantic parsing for text-to-SQL, and automated prompt optimization\ntasks, achieving state-of-the-art accuracy or improved scalability without\nsacrificing performance. The open-source implementation is available at\n\\texttt{https://github.com/IBM/agentics}.", "AI": {"tldr": "Agentics is a modular framework that uses internal agents to enable structured, transductive reasoning over data types defined by LLMs, shifting focus from prompts to data modeling for scalable, compositional AI.", "motivation": "To enable structured reasoning and compositional generalization in AI systems while reducing reliance on prompt engineering, by treating data types as first-class, connected via logical transduction.", "method": "Proposes Agentics, a declarative framework where agents are abstracted from the logical flow and operate inside data types to perform logical transduction among data; data types are provided by LLMs and connected to form workflows, with LLMs executing the transduction.", "result": "Empirical evidence across domains\u2014domain-specific multiple-choice QA, text-to-SQL semantic parsing, and automated prompt optimization\u2014showing state-of-the-art accuracy or improved scalability without performance loss; open-source implementation available.", "conclusion": "Agentics offers a novel perspective that emphasizes data modeling over prompt crafting, enabling structured, compositional reasoning; the approach is practical and scalable, with community-accessible software."}}
{"id": "2508.15215", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15215", "abs": "https://arxiv.org/abs/2508.15215", "authors": ["Benjamin Wei Hao Chin", "Yuin Torng Yew", "Haocheng Wu", "Lanxin Liang", "Chow Khuen Chan", "Norita Mohd Zain", "Siti Balqis Samdin", "Sim Kuan Goh"], "title": "SleepDIFFormer: Sleep Stage Classification via Multivariate Differential Transformer", "comment": "8 Pages", "summary": "Classification of sleep stages is essential for assessing sleep quality and\ndiagnosing sleep disorders such as insomnia. However, manual inspection of EEG\ncharacteristics for each stage is time-consuming and prone to human error.\nAlthough machine learning and deep learning methods have been actively\ndeveloped, they continue to face challenges from the non-stationarity and\nvariability of electroencephalography (EEG) and electrooculography (EOG)\nsignals, often leading to poor generalization on unseen datasets. This research\nproposed a Sleep Stage Classification method by developing Multivariate\nDifferential Transformer (SleepDIFFormer) for joint EEG and EOG representation\nlearning. Specifically, SleepDIFFormer was developed to process EEG and EOG\nsignals using our Multivariate Differential Transformer Architecture (MDTA) for\ntime series, trained with cross-domain alignment. Our method mitigated spatial\nand temporal attention noise while learning a domain-invariant joint EEG-EOG\nrepresentation through feature distribution alignment, thereby enabling\ngeneralization to unseen target datasets. Empirically, we evaluated our method\non five different sleep staging datasets and compared it with existing\napproaches, achieving state-of-the-art performance. We also conducted thorough\nablation analyses of SleepDIFFormer and interpreted the differential attention\nweights, highlighting their relevance to characteristic sleep EEG patterns.\nThese findings have implications for advancing automated sleep stage\nclassification and its application to sleep quality assessment. Our source code\nis publicly available at https://github.com/Ben1001409/SleepDIFFormer", "AI": {"tldr": "Introduces SleepDIFFormer, a multivariate differential transformer for joint EEG-EOG sleep-stage classification with cross-domain alignment, achieving state-of-the-art results across five datasets and offering interpretable differential attention.", "motivation": "Manual EEG/EOG sleep staging is time-consuming and error-prone, and existing ML/DL models struggle to generalize due to non-stationarity and variability across datasets and subjects. A joint EEG-EOG representation with domain-invariant features could improve generalization to unseen data.", "method": "Proposes Multivariate Differential Transformer Architecture (MDTA) and SleepDIFFormer for time-series EEG and EOG inputs. Uses cross-domain alignment to learn a domain-invariant joint representation, mitigates spatial/temporal attention noise, and performs feature distribution alignment. Includes ablation studies and interpretation of differential attention weights. Code is released publicly.", "result": "Evaluated on five sleep staging datasets, achieving state-of-the-art performance. Ablation analyses confirm the contribution of the differential attention mechanism and the importance of the learned joint EEG-EOG representations for accurate sleep stage classification.", "conclusion": "SleepDIFFormer generalizes well to unseen datasets and advances automated sleep stage classification, with potential for improved sleep quality assessment. Public code enables replication and adaptation."}}
{"id": "2508.15353", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15353", "abs": "https://arxiv.org/abs/2508.15353", "authors": ["Olga Matykina", "Dmitry Yudin"], "title": "RCDINO: Enhancing Radar-Camera 3D Object Detection with DINOv2 Semantic Features", "comment": "Accepted for publication in Optical Memory and Neural Networks, 2025", "summary": "Three-dimensional object detection is essential for autonomous driving and\nrobotics, relying on effective fusion of multimodal data from cameras and\nradar. This work proposes RCDINO, a multimodal transformer-based model that\nenhances visual backbone features by fusing them with semantically rich\nrepresentations from the pretrained DINOv2 foundation model. This approach\nenriches visual representations and improves the model's detection performance\nwhile preserving compatibility with the baseline architecture. Experiments on\nthe nuScenes dataset demonstrate that RCDINO achieves state-of-the-art\nperformance among radar-camera models, with 56.4 NDS and 48.1 mAP. Our\nimplementation is available at https://github.com/OlgaMatykina/RCDINO.", "AI": {"tldr": "RCDINO fuses radar with DINOv2-based semantic features to boost 3D object detection, achieving state-of-the-art radar-camera results on nuScenes (56.4 NDS, 48.1 mAP) while staying compatible with standard architectures.", "motivation": "Need for robust multimodal fusion in 3D detection for autonomous systems; leveraging large pretrained vision models (DINOv2) to enrich visual features from cameras before fusion with radar.", "method": "A multimodal transformer-based model that enriches visual backbone features by injecting semantically rich DINOv2 representations and fusing with radar data, preserving baseline architecture compatibility.", "result": "On nuScenes, achieves 56.4 NDS and 48.1 mAP, state-of-the-art among radar-camera models; code at GitHub.", "conclusion": "Demonstrates the effectiveness of combining pretrained semantic representations with multimodal fusion for improved radar-camera 3D detection; maintains compatibility and provides open-source implementation."}}
{"id": "2508.15630", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15630", "abs": "https://arxiv.org/abs/2508.15630", "authors": ["Meera Ray", "Christopher L. Dancy"], "title": "Adapting A Vector-Symbolic Memory for Lisp ACT-R", "comment": "6 pages. 5 figures. Submitted and accepted to the 23rd International\n  Conference on Cognitive Modeling (ICCM 2025)", "summary": "Holographic Declarative Memory (HDM) is a vector-symbolic alternative to\nACT-R's Declarative Memory (DM) system that can bring advantages such as\nscalability and architecturally defined similarity between DM chunks. We\nadapted HDM to work with the most comprehensive and widely-used implementation\nof ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with\nHDM without major changes. With this adaptation of HDM, we have developed\nvector-based versions of common ACT-R functions, set up a text processing\npipeline to add the contents of large documents to ACT-R memory, and most\nsignificantly created a useful and novel mechanism to retrieve an entire chunk\nof memory based on a request using only vector representations of tokens.\nPreliminary results indicate that we can maintain vector-symbolic advantages of\nHDM (e.g., chunk recall without storing the actual chunk and other advantages\nwith scaling) while also extending it so that previous ACT-R models may work\nwith the system with little (or potentially no) modifications within the actual\nprocedural and declarative memory portions of a model. As a part of iterative\nimprovement of this newly translated holographic declarative memory module, we\nwill continue to explore better time-context representations for vectors to\nimprove the module's ability to reconstruct chunks during recall. To more fully\ntest this translated HDM module, we also plan to develop decision-making models\nthat use instance-based learning (IBL) theory, which is a useful application of\nHDM given the advantages of the system.", "AI": {"tldr": "HDM is adapted to Lisp ACT-R to enable vector-based declarative memory compatible with existing ACT-R models; a new vector-based retrieval mechanism and text ingestion pipeline are developed; preliminary results show preserved vector-symbolic advantages and compatibility, with future work on time-context representations and IBL-based decision making.", "motivation": "To combine the scalability and vector-symbolic benefits of Holographic Declarative Memory (HDM) with the widely-used ACT-R Declarative Memory, enabling existing ACT-R models to run with HDM with minimal changes and improving chunk retrieval using vector representations.", "method": "Translate HDM into Lisp ACT-R, create vector-based ACT-R memory operations, build a text processing pipeline to load large documents into memory, and implement a retrieval mechanism that can fetch an entire chunk using only token vectors. Plan to explore time-context vector representations and to develop decision-making models based on instance-based learning (IBL) to test HDM applicability.", "result": "Preliminary results indicate that vector-symbolic advantages of HDM (e.g., chunk recall without storing the actual chunk and benefits with scaling) are maintained, while enabling previous ACT-R models to operate with HDM with minimal modifications to their memory components. A working vector-based retrieval of chunks from tokens has been created.", "conclusion": "The translated HDM module shows promise as a drop-in memory component for ACT-R, preserving HDM benefits and enabling broader usability. Future work will focus on improving time-context representations for better chunk reconstruction during recall and developing IBL-based decision-making models to test HDM in practical cognitive tasks."}}
{"id": "2508.15217", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2508.15217", "abs": "https://arxiv.org/abs/2508.15217", "authors": ["Sishuo Chen", "Zhangming Chan", "Xiang-Rong Sheng", "Lei Zhang", "Sheng Chen", "Chenghuan Hou", "Han Zhu", "Jian Xu", "Bo Zheng"], "title": "See Beyond a Single View: Multi-Attribution Learning Leads to Better Conversion Rate Prediction", "comment": "Accepted at CIKM 2025", "summary": "Conversion rate (CVR) prediction is a core component of online advertising\nsystems, where the attribution mechanisms-rules for allocating conversion\ncredit across user touchpoints-fundamentally determine label generation and\nmodel optimization. While many industrial platforms support diverse attribution\nmechanisms (e.g., First-Click, Last-Click, Linear, and Data-Driven Multi-Touch\nAttribution), conventional approaches restrict model training to labels from a\nsingle production-critical attribution mechanism, discarding complementary\nsignals in alternative attribution perspectives.\n  To address this limitation, we propose a novel Multi-Attribution Learning\n(MAL) framework for CVR prediction that integrates signals from multiple\nattribution perspectives to better capture the underlying patterns driving user\nconversions. Specifically, MAL is a joint learning framework consisting of two\ncore components: the Attribution Knowledge Aggregator (AKA) and the Primary\nTarget Predictor (PTP). AKA is implemented as a multi-task learner that\nintegrates knowledge extracted from diverse attribution labels. PTP, in\ncontrast, focuses on the task of generating well-calibrated conversion\nprobabilities that align with the system-optimized attribution metric (e.g.,\nCVR under the Last-Click attribution), ensuring direct compatibility with\nindustrial deployment requirements. Additionally, we propose CAT, a novel\ntraining strategy that leverages the Cartesian product of all attribution label\ncombinations to generate enriched supervision signals. This design\nsubstantially enhances the performance of the attribution knowledge aggregator.\nEmpirical evaluations demonstrate the superiority of MAL over\nsingle-attribution learning baselines, achieving +0.51% GAUC improvement on\noffline metrics. Online experiments demonstrate that MAL achieved a +2.6%\nincrease in ROI (Return on Investment).", "AI": {"tldr": "Introduces Multi-Attribution Learning (MAL) for CVR prediction that jointly leverages multiple attribution signals to improve model performance and deployment compatibility.", "motivation": "Single-attribution labels waste complementary information from other attribution perspectives; industrial systems rely on a specific attribution metric, but integrating multiple signals can better capture conversion patterns and improve label quality.", "method": "MAL comprises two components: (1) Attribution Knowledge Aggregator (AKA) as a multi-task learner that fuses knowledge from diverse attribution labels; (2) Primary Target Predictor (PTP) that produces well-calibrated CVR aligned with the system attribution metric. A training strategy CAT uses the Cartesian product of all attribution label combinations to provide enriched supervision for the aggregator.", "result": "Offline GAUC improved by +0.51% over single-attribution baselines; Online ROI increased by +2.6%.", "conclusion": "MAL effectively leverages multi-attribution signals to enhance CVR prediction and aligns training with industrial attribution metrics, offering gains in both offline and online evaluations over traditional single-attribution models."}}
{"id": "2508.15360", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15360", "abs": "https://arxiv.org/abs/2508.15360", "authors": ["Chenhui Gou", "Ziyu Ma", "Zicheng Duan", "Haoyu He", "Feng Chen", "Akide Liu", "Bohan Zhuang", "Jianfei Cai", "Hamid Rezatofighi"], "title": "An Empirical Study on How Video-LLMs Answer Video Questions", "comment": null, "summary": "Taking advantage of large-scale data and pretrained language models, Video\nLarge Language Models (Video-LLMs) have shown strong capabilities in answering\nvideo questions. However, most existing efforts focus on improving performance,\nwith limited attention to understanding their internal mechanisms. This paper\naims to bridge this gap through a systematic empirical study. To interpret\nexisting VideoLLMs, we adopt attention knockouts as our primary analytical tool\nand design three variants: Video Temporal Knockout, Video Spatial Knockout, and\nLanguage-to-Video Knockout. Then, we apply these three knockouts on different\nnumbers of layers (window of layers). By carefully controlling the window of\nlayers and types of knockouts, we provide two settings: a global setting and a\nfine-grained setting. Our study reveals three key findings: (1) Global setting\nindicates Video information extraction primarily occurs in early layers,\nforming a clear two-stage process -- lower layers focus on perceptual encoding,\nwhile higher layers handle abstract reasoning; (2) In the fine-grained setting,\ncertain intermediate layers exert an outsized impact on video question\nanswering, acting as critical outliers, whereas most other layers contribute\nminimally; (3) In both settings, we observe that spatial-temporal modeling\nrelies more on language-guided retrieval than on intra- and inter-frame\nself-attention among video tokens, despite the latter's high computational\ncost. Finally, we demonstrate that these insights can be leveraged to reduce\nattention computation in Video-LLMs. To our knowledge, this is the first work\nto systematically uncover how Video-LLMs internally process and understand\nvideo content, offering interpretability and efficiency perspectives for future\nresearch.", "AI": {"tldr": "Video-LLMs are analyzed via three attention knockout variants across layer windows to uncover internal mechanisms, revealing a two-stage early perceptual encoding followed by higher-level reasoning, with critical outlier layers in the middle, and a strong reliance on language-guided retrieval for spatial-temporal modeling; insights enable reduced attention computation.", "motivation": "Understand the internal workings of Video-LLMs beyond performance gains, enabling interpretability and efficiency.", "method": "Three knockout variants (Video Temporal Knockout, Video Spatial Knockout, Language-to-Video Knockout) applied over different layer windows; global and fine-grained settings to study information flow and layer importance.", "result": "Global setting: early layers handle perceptual encoding; two-stage processing. Fine-grained setting: some intermediate layers act as outsized critical outliers. Spatial-temporal modeling relies more on language-guided retrieval than on self-attention among video tokens. Findings can guide reduction of attention computation.", "conclusion": "First systematic study of internal processing in Video-LLMs; provides interpretability and efficiency implications for future Video-LLM research."}}
{"id": "2508.15652", "categories": ["cs.AI", "cs.IT", "cs.LG", "cs.MA", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15652", "abs": "https://arxiv.org/abs/2508.15652", "authors": ["Ardian Selmonaj", "Miroslav Strupl", "Oleg Szehr", "Alessandro Antonucci"], "title": "Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning", "comment": "European Conference on Artificial Intelligence (ECAI) 2025", "summary": "To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is\ncrucial to understand individual agent behaviors within a team. While prior\nwork typically evaluates overall team performance based on explicit reward\nsignals or learned value functions, it is unclear how to infer agent\ncontributions in the absence of any value feedback. In this work, we\ninvestigate whether meaningful insights into agent behaviors can be extracted\nthat are consistent with the underlying value functions, solely by analyzing\nthe policy distribution. Inspired by the phenomenon that intelligent agents\ntend to pursue convergent instrumental values, which generally increase the\nlikelihood of task success, we introduce Intended Cooperation Values (ICVs), a\nmethod based on information-theoretic Shapley values for quantifying each\nagent's causal influence on their co-players' instrumental empowerment.\nSpecifically, ICVs measure an agent's action effect on its teammates' policies\nby assessing their decision uncertainty and preference alignment. The analysis\nacross cooperative and competitive MARL environments reveals the extent to\nwhich agents adopt similar or diverse strategies. By comparing action effects\nbetween policies and value functions, our method identifies which agent\nbehaviors are beneficial to team success, either by fostering deterministic\ndecisions or by preserving flexibility for future action choices. Our proposed\nmethod offers novel insights into cooperation dynamics and enhances\nexplainability in MARL systems.", "AI": {"tldr": "ICVs quantify each agent's causal influence on teammates' instrumental empowerment using information-theoretic Shapley values, enabling analysis of cooperative and competitive MARL from policy distributions even without value feedback.", "motivation": "To understand individual contributions and cooperation dynamics in MARL when explicit value signals are unavailable.", "method": "Compute Intended Cooperation Values (ICVs) via information-theoretic Shapley values, measuring how an agent's actions affect teammates' decision uncertainty and preference alignment; compare policy-derived effects with value-function signals; analyze across cooperative and competitive settings.", "result": "Demonstrates how agents converge on similar or diverse strategies; identifies which behaviors promote deterministic decisions or preserve flexibility; shows alignment between policy-level influence and value-based success signals.", "conclusion": "ICVs provide a principled, explainable metric of inter-agent influence in MARL that complements value-based evaluation and offers insights into cooperation dynamics."}}
{"id": "2508.15220", "categories": ["cs.LG", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2508.15220", "abs": "https://arxiv.org/abs/2508.15220", "authors": ["Aniruddha Joshi", "Supratik Chakraborty", "S Akshay", "Shetal Shah", "Hazem Torfah", "Sanjit Seshia"], "title": "Locally Pareto-Optimal Interpretations for Black-Box Machine Learning Models", "comment": "This work has been accepted at ATVA'25", "summary": "Creating meaningful interpretations for black-box machine learning models\ninvolves balancing two often conflicting objectives: accuracy and\nexplainability. Exploring the trade-off between these objectives is essential\nfor developing trustworthy interpretations. While many techniques for\nmulti-objective interpretation synthesis have been developed, they typically\nlack formal guarantees on the Pareto-optimality of the results. Methods that do\nprovide such guarantees, on the other hand, often face severe scalability\nlimitations when exploring the Pareto-optimal space. To address this, we\ndevelop a framework based on local optimality guarantees that enables more\nscalable synthesis of interpretations. Specifically, we consider the problem of\nsynthesizing a set of Pareto-optimal interpretations with local optimality\nguarantees, within the immediate neighborhood of each solution. Our approach\nbegins with a multi-objective learning or search technique, such as\nMulti-Objective Monte Carlo Tree Search, to generate a best-effort set of\nPareto-optimal candidates with respect to accuracy and explainability. We then\nverify local optimality for each candidate as a Boolean satisfiability problem,\nwhich we solve using a SAT solver. We demonstrate the efficacy of our approach\non a set of benchmarks, comparing it against previous methods for exploring the\nPareto-optimal front of interpretations. In particular, we show that our\napproach yields interpretations that closely match those synthesized by methods\noffering global guarantees.", "AI": {"tldr": "A scalable framework for Pareto-optimal interpretations with local guarantees, integrating multi-objective search (e.g., MO-MCTS) with SAT-based local optimality checks to approximate globally optimal trade-offs between accuracy and explainability.", "motivation": "Explainable AI requires balancing accuracy and interpretability; existing multi-objective methods either lack formal Pareto guarantees or are computationally intractable for exploring the Pareto front. This work aims to provide scalable, provable local optimality guarantees in the space of interpretations.", "method": "1) Generate a set of Pareto-optimal interpretation candidates using a multi-objective learning/search technique (e.g., Multi-Objective Monte Carlo Tree Search). 2) For each candidate, verify local optimality by encoding it as a Boolean satisfiability problem and solving with a SAT solver. 3) Benchmark against prior Pareto-front methods to assess coverage and scalability.", "result": "The approach yields interpretation candidates that closely match globally guaranteed methods while offering improved scalability; empirical results on benchmarks show competitive or superior Pareto-front coverage with reduced computational overhead compared to full guarantees.", "conclusion": "Local-optimality guarantees, combined with scalable search, enable practical, near-globally Pareto-optimal interpretations for black-box models, balancing accuracy and explainability without prohibitive computational cost."}}
{"id": "2508.15367", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15367", "abs": "https://arxiv.org/abs/2508.15367", "authors": ["Jacinto Colan", "Ana Davila", "Yasuhisa Hasegawa"], "title": "Transfer learning optimization based on evolutionary selective fine tuning", "comment": "Presented at the Workshop artiFicial And bio-inspIred netwoRked\n  intelliGence foR cOnstrained aUtoNomous Devices (FAIRGROUND). 2025\n  International Joint Conference on Neural Networks (IJCNN)", "summary": "Deep learning has shown substantial progress in image analysis. However, the\ncomputational demands of large, fully trained models remain a consideration.\nTransfer learning offers a strategy for adapting pre-trained models to new\ntasks. Traditional fine-tuning often involves updating all model parameters,\nwhich can potentially lead to overfitting and higher computational costs. This\npaper introduces BioTune, an evolutionary adaptive fine-tuning technique that\nselectively fine-tunes layers to enhance transfer learning efficiency. BioTune\nemploys an evolutionary algorithm to identify a focused set of layers for\nfine-tuning, aiming to optimize model performance on a given target task.\nEvaluation across nine image classification datasets from various domains\nindicates that BioTune achieves competitive or improved accuracy and efficiency\ncompared to existing fine-tuning methods such as AutoRGN and LoRA. By\nconcentrating the fine-tuning process on a subset of relevant layers, BioTune\nreduces the number of trainable parameters, potentially leading to decreased\ncomputational cost and facilitating more efficient transfer learning across\ndiverse data characteristics and distributions.", "AI": {"tldr": "BioTune is an evolutionary adaptive fine-tuning method that selectively fine-tunes a subset of layers in a pretrained model using an evolutionary algorithm, aiming to improve transfer learning efficiency. It achieves competitive or better accuracy with fewer trainable parameters across nine image classification datasets, outperforming methods like AutoRGN and LoRA.", "motivation": "To reduce computational cost and overfitting in fine-tuning large pretrained vision models by identifying which layers to adjust for a given target task.", "method": "An evolutionary algorithm searches for an optimal subset of layers to fine-tune. The model is fine-tuned only on the selected layers, yielding improved efficiency and comparable or better accuracy relative to full fine-tuning and other methods.", "result": "BioTune achieves competitive or improved accuracy and efficiency across nine diverse image classification datasets, with fewer trainable parameters than full fine-tuning and existing methods like AutoRGN and LoRA.", "conclusion": "Selective, evolutionary fine-tuning of a subset of layers can enhance transfer learning efficiency without sacrificing performance, enabling more scalable adaptation of large pretrained models to diverse tasks."}}
{"id": "2508.15680", "categories": ["cs.AI", "cs.HC", "I.2.6; I.2.11; K.4.1; K.6.0"], "pdf": "https://arxiv.org/pdf/2508.15680", "abs": "https://arxiv.org/abs/2508.15680", "authors": ["Mark Cote", "Susana Aires"], "title": "Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle", "comment": "15 pages, 3 figures, Presented at IAIL 2025 - Imagining the AI\n  Landscape after the AI Act, 4th International Workshop on Imagining the AI\n  Landscape After the AI Act, The fourth International Conference on Hybrid\n  Human-Artificial Intelligence", "summary": "This paper argues that a techno-philosophical reading of the EU AI Act\nprovides insight into the long-term dynamics of data in AI systems,\nspecifically, how the lifecycle from ingestion to deployment generates\nrecursive value chains that challenge existing frameworks for Responsible AI.\nWe introduce a conceptual tool to frame the AI pipeline, spanning data,\ntraining regimes, architectures, feature stores, and transfer learning. Using\ncross-disciplinary methods, we develop a technically grounded and\nphilosophically coherent analysis of regulatory blind spots. Our central claim\nis that what remains absent from policymaking is an account of the dynamic of\nbecoming that underpins both the technical operation and economic logic of AI.\nTo address this, we advance a formal reading of AI inspired by Simondonian\nphilosophy of technology, reworking his concept of individuation to model the\nAI lifecycle, including the pre-individual milieu, individuation, and\nindividuated AI. To translate these ideas, we introduce futurity: the\nself-reinforcing lifecycle of AI, where more data enhances performance, deepens\npersonalisation, and expands application domains. Futurity highlights the\nrecursively generative, non-rivalrous nature of data, underpinned by\ninfrastructures like feature stores that enable feedback, adaptation, and\ntemporal recursion. Our intervention foregrounds escalating power asymmetries,\nparticularly the tech oligarchy whose infrastructures of capture, training, and\ndeployment concentrate value and decision-making. We argue that effective\nregulation must address these infrastructural and temporal dynamics, and\npropose measures including lifecycle audits, temporal traceability, feedback\naccountability, recursion transparency, and a right to contest recursive reuse.", "AI": {"tldr": "A techno-philosophical reading of the EU AI Act using a Simondon-inspired model of AI lifecycles, highlighting regulatory blind spots and proposing tools to govern data-centric futurity and recursive reuse.", "motivation": "Policy frameworks struggle to capture the dynamic, infrastructural temporality of data-driven AI systems and the power asymmetries embedded in data infrastructures. The paper aims to bridge philosophy, engineering, and law to sharpen regulatory insight.", "method": "Cross-disciplinary approach combining philosophy of technology (Simondon), analysis of AI data pipelines (data, training regimes, architectures, feature stores, transfer learning), and regulatory critique to build a formal reading of AI lifecycle.", "result": "Develops a Simondonian account of the AI lifecycle (pre-individual milieu, individuation, individuated AI) and introduces the concept of futurity to describe the self-reinforcing data-feedback loop. Identifies regulatory blind spots and proposes measures: lifecycle audits, temporal traceability, feedback accountability, recursion transparency, and a right to contest recursive reuse.", "conclusion": "Regulation must address infrastructural and temporal dynamics driving data-centric AI, with governance tools that monitor feedback loops, data reuse, and recursivity to mitigate power concentration in tech infrastructures."}}
{"id": "2508.15225", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2508.15225", "abs": "https://arxiv.org/abs/2508.15225", "authors": ["Yi Yuan", "Joseph Van Duyn", "Runze Yan", "Zhuoyi Huang", "Sulaiman Vesal", "Sergey Plis", "Xiao Hu", "Gloria Hyunjung Kwak", "Ran Xiao", "Alex Fedorov"], "title": "Learning ECG Representations via Poly-Window Contrastive Learning", "comment": "This work has been accepted for publication in IEEE-EMBS\n  International Conference on Biomedical and Health Informatics 2025. The final\n  published version will be available via IEEE Xplore", "summary": "Electrocardiogram (ECG) analysis is foundational for cardiovascular disease\ndiagnosis, yet the performance of deep learning models is often constrained by\nlimited access to annotated data. Self-supervised contrastive learning has\nemerged as a powerful approach for learning robust ECG representations from\nunlabeled signals. However, most existing methods generate only pairwise\naugmented views and fail to leverage the rich temporal structure of ECG\nrecordings. In this work, we present a poly-window contrastive learning\nframework. We extract multiple temporal windows from each ECG instance to\nconstruct positive pairs and maximize their agreement via statistics. Inspired\nby the principle of slow feature analysis, our approach explicitly encourages\nthe model to learn temporally invariant and physiologically meaningful features\nthat persist across time. We validate our approach through extensive\nexperiments and ablation studies on the PTB-XL dataset. Our results demonstrate\nthat poly-window contrastive learning consistently outperforms conventional\ntwo-view methods in multi-label superclass classification, achieving higher\nAUROC (0.891 vs. 0.888) and F1 scores (0.680 vs. 0.679) while requiring up to\nfour times fewer pre-training epochs (32 vs. 128) and 14.8% in total wall clock\npre-training time reduction. Despite processing multiple windows per sample, we\nachieve a significant reduction in the number of training epochs and total\ncomputation time, making our method practical for training foundational models.\nThrough extensive ablations, we identify optimal design choices and demonstrate\nrobustness across various hyperparameters. These findings establish poly-window\ncontrastive learning as a highly efficient and scalable paradigm for automated\nECG analysis and provide a promising general framework for self-supervised\nrepresentation learning in biomedical time-series data.", "AI": {"tldr": "Poly-window contrastive learning for ECG: leverages multiple temporal windows to learn temporally invariant representations, achieving modest accuracy gains but substantial efficiency improvements, suggesting scalability for foundation-model pretraining on biomedical time-series.", "motivation": "ECG datasets often have limited labeled data; existing self-supervised methods mostly use two augmented views and do not exploit ECGs' rich temporal structure. A method that leverages multi-window temporal context could learn more robust, physiologically meaningful features with less labeled data.", "method": "Construct multiple temporal windows from each ECG instance to form positive pairs. Use a contrastive objective that maximizes agreement across windows via statistics, inspired by slow feature analysis to encourage temporally invariant representations. Conduct extensive ablations and evaluate on PTB-XL, reporting multi-label superclass performance and training efficiency.", "result": "On PTB-XL, poly-window contrastive learning achieves AUROC 0.891 and F1 0.680, surpassing the two-view baseline (0.888 AUROC, 0.679 F1). The method trains with up to four times fewer pre-training epochs (32 vs 128) and reduces total wall-clock pre-training time by 14.8%. Ablations show robustness across hyperparameters and identify critical design choices.", "conclusion": "Poly-window contrastive learning is an efficient, scalable paradigm for self-supervised ECG analysis and offers a promising general framework for self-supervised representation learning in biomedical time-series data, enabling practical foundation-model pretraining."}}
{"id": "2508.15372", "categories": ["cs.CV", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2508.15372", "abs": "https://arxiv.org/abs/2508.15372", "authors": ["Xinshuang Liu", "Runfa Blark Li", "Keito Suzuki", "Truong Nguyen"], "title": "Image-Conditioned 3D Gaussian Splat Quantization", "comment": null, "summary": "3D Gaussian Splatting (3DGS) has attracted considerable attention for\nenabling high-quality real-time rendering. Although 3DGS compression methods\nhave been proposed for deployment on storage-constrained devices, two\nlimitations hinder archival use: (1) they compress medium-scale scenes only to\nthe megabyte range, which remains impractical for large-scale scenes or\nextensive scene collections; and (2) they lack mechanisms to accommodate scene\nchanges after long-term archival. To address these limitations, we propose an\nImage-Conditioned Gaussian Splat Quantizer (ICGS-Quantizer) that substantially\nenhances compression efficiency and provides adaptability to scene changes\nafter archiving. ICGS-Quantizer improves quantization efficiency by jointly\nexploiting inter-Gaussian and inter-attribute correlations and by using shared\ncodebooks across all training scenes, which are then fixed and applied to\npreviously unseen test scenes, eliminating the overhead of per-scene codebooks.\nThis approach effectively reduces the storage requirements for 3DGS to the\nkilobyte range while preserving visual fidelity. To enable adaptability to\npost-archival scene changes, ICGS-Quantizer conditions scene decoding on images\ncaptured at decoding time. The encoding, quantization, and decoding processes\nare trained jointly, ensuring that the codes, which are quantized\nrepresentations of the scene, are effective for conditional decoding. We\nevaluate ICGS-Quantizer on 3D scene compression and 3D scene updating.\nExperimental results show that ICGS-Quantizer consistently outperforms\nstate-of-the-art methods in compression efficiency and adaptability to scene\nchanges. Our code, model, and data will be publicly available on GitHub.", "AI": {"tldr": "ICGS-Quantizer enables ultra-compressed 3D Gaussian Splatting with image-conditioned decoding and shared codebooks, achieving kilobyte storage and better adaptability than current methods.", "motivation": "To overcome megabyte-scale limitations for large-scale 3DGS and lack of mechanisms to adapt archives to post-archival scene changes.", "method": "Jointly trains encoding, quantization, and decoding of 3DGS using inter-Gaussian/inter-attribute correlations; uses shared codebooks across training scenes; decoding is conditioned on decoding-time images; per-scene codebooks are avoided; codes are learned to be effective for conditional decoding.", "result": "Achieves storage reduction to kilobyte range while preserving visual fidelity; outperforms state-of-the-art in compression efficiency and adaptability; validated on 3D scene compression and updating; code/data will be released on GitHub.", "conclusion": "ICGS-Quantizer offers a scalable, adaptable solution for archival 3DGS that supports large scenes and changes over time, with practical deployment via shared codebooks and image-conditioned decoding."}}
{"id": "2508.15690", "categories": ["cs.AI", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.15690", "abs": "https://arxiv.org/abs/2508.15690", "authors": ["Abhigya Verma", "Sriram Puttagunta", "Seganrasan Subramanian", "Sravan Ramachandran"], "title": "GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning", "comment": "23 pages, 9 tables, 3 figures", "summary": "GRAFT is a structured multimodal benchmark for evaluating models on\ninstruction-following, visual reasoning, and visual-textual alignment tasks. It\nfeatures programmatically generated charts and synthetically rendered tables,\ncreated with Python visualization libraries to ensure control over data\nsemantics, structure, and clarity. Each GRAFT instance pairs a chart or table\nimage with a systematically generated, multi-step analytical question based\nsolely on visual content. Answers are provided in structured formats such as\nJSON or YAML, supporting consistent evaluation of both reasoning and output\nformat. The benchmark introduces a taxonomy of reasoning types including\ncomparison, trend identification, ranking, aggregation, proportion estimation,\nand anomaly detection to enable comprehensive assessment. Reference answers\nfollow strict factual and formatting guidelines for precise, aspect-based\nevaluation. GRAFT offers a unified, scalable framework for fine-grained\nbenchmarking of multimodal models on visually grounded, structured reasoning\ntasks, setting a new evaluation standard in this field.", "AI": {"tldr": "GRAFT is a structured multimodal benchmark for evaluating models on instruction-following and structured visual reasoning, using programmatically generated charts/tables paired with multi-step, visual-content questions answered in JSON/YAML to enable precise, aspect-based evaluation.", "motivation": "There is a need for fine-grained, reproducible evaluation of multimodal models that can handle instruction-following, visual reasoning, and visual-textual alignment, with controlled data semantics and strict output formats to assess reasoning processes, not just final answers.", "method": "Create a dataset of programmatically generated charts and synthetic tables using Python visualization libraries. Each image is paired with a systematically generated, multi-step analytical question based on the visual content. Answers are provided in structured formats (JSON/YAML), with a taxonomy of reasoning types (comparison, trend, ranking, aggregation, proportion, anomaly) and strict reference answer guidelines for precise evaluation.", "result": "The paper (abstract) presents GRAFT as a unified, scalable framework for fine-grained benchmarking of multimodal models on visually grounded, structured reasoning tasks, aiming to set a new evaluation standard in the field. It emphasizes controlled data generation, structured answers, and aspect-based evaluation.", "conclusion": "GRAFT offers a comprehensive, reproducible benchmark design that enables rigorous testing of multimodal models\u2019 reasoning and output formatting on visually grounded tasks, advancing the evaluation standards in multimodal AI."}}
{"id": "2508.15260", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15260", "abs": "https://arxiv.org/abs/2508.15260", "authors": ["Yichao Fu", "Xuewei Wang", "Yuandong Tian", "Jiawei Zhao"], "title": "Deep Think with Confidence", "comment": null, "summary": "Large Language Models (LLMs) have shown great potential in reasoning tasks\nthrough test-time scaling methods like self-consistency with majority voting.\nHowever, this approach often leads to diminishing returns in accuracy and high\ncomputational overhead. To address these challenges, we introduce Deep Think\nwith Confidence (DeepConf), a simple yet powerful method that enhances both\nreasoning efficiency and performance at test time. DeepConf leverages\nmodel-internal confidence signals to dynamically filter out low-quality\nreasoning traces during or after generation. It requires no additional model\ntraining or hyperparameter tuning and can be seamlessly integrated into\nexisting serving frameworks. We evaluate DeepConf across a variety of reasoning\ntasks and the latest open-source models, including Qwen 3 and GPT-OSS series.\nNotably, on challenging benchmarks such as AIME 2025, DeepConf@512 achieves up\nto 99.9% accuracy and reduces generated tokens by up to 84.7% compared to full\nparallel thinking.", "AI": {"tldr": "DeepThink with Confidence (DeepConf) uses model-internal confidence signals to filter out low-quality reasoning traces at test time, improving accuracy and reducing token usage without any training or hyperparameter tuning.", "motivation": "Self-consistency and test-time reasoning ensembles can boost accuracy but suffer from diminishing returns and high computational cost. A lightweight, deployable method is needed to improve reasoning efficiency and performance.", "method": "DeepConf dynamically filters reasoning traces based on internal confidence signals during or after generation. It requires no additional model training or hyperparameter tuning and can be integrated into existing serving frameworks by discarding traces deemed low quality.", "result": "On challenging benchmarks and models (e.g., AIME 2025, Qwen 3, GPT-OSS), DeepConf achieves up to 99.9% accuracy and reduces generated tokens by up to 84.7% compared to full parallel thinking.", "conclusion": "DeepConf offers a simple yet effective mechanism to boost reasoning performance while cutting computational cost, enabling production-friendly deployment without extra training."}}
{"id": "2508.15376", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15376", "abs": "https://arxiv.org/abs/2508.15376", "authors": ["Cong Wang", "Xianda Guo", "Wenbo Xu", "Wei Tian", "Ruiqi Song", "Chenming Zhang", "Lingxi Li", "Long Chen"], "title": "DriveSplat: Decoupled Driving Scene Reconstruction with Geometry-enhanced Partitioned Neural Gaussians", "comment": null, "summary": "In the realm of driving scenarios, the presence of rapidly moving vehicles,\npedestrians in motion, and large-scale static backgrounds poses significant\nchallenges for 3D scene reconstruction. Recent methods based on 3D Gaussian\nSplatting address the motion blur problem by decoupling dynamic and static\ncomponents within the scene. However, these decoupling strategies overlook\nbackground optimization with adequate geometry relationships and rely solely on\nfitting each training view by adding Gaussians. Therefore, these models exhibit\nlimited robustness in rendering novel views and lack an accurate geometric\nrepresentation. To address the above issues, we introduce DriveSplat, a\nhigh-quality reconstruction method for driving scenarios based on neural\nGaussian representations with dynamic-static decoupling. To better accommodate\nthe predominantly linear motion patterns of driving viewpoints, a region-wise\nvoxel initialization scheme is employed, which partitions the scene into near,\nmiddle, and far regions to enhance close-range detail representation.\nDeformable neural Gaussians are introduced to model non-rigid dynamic actors,\nwhose parameters are temporally adjusted by a learnable deformation network.\nThe entire framework is further supervised by depth and normal priors from\npre-trained models, improving the accuracy of geometric structures. Our method\nhas been rigorously evaluated on the Waymo and KITTI datasets, demonstrating\nstate-of-the-art performance in novel-view synthesis for driving scenarios.", "AI": {"tldr": "DriveSplat introduces neural Gaussian representations with dynamic-static decoupling and region-wise initialization for driving scenes, using deformable Gaussians and depth/normal priors to improve geometry and novel-view synthesis, achieving state-of-the-art results on Waymo and KITTI.", "motivation": "Driving scenarios contain fast-moving dynamic objects with a dominant static background, which challenges 3D reconstruction. Existing decode- and fitting-based Gaussian methods decouple dynamics but neglect robust background geometry and rely on per-view fitting, limiting rendering quality and geometric accuracy.", "method": "Propose DriveSplat: a neural Gaussian representation with dynamic-static decoupling. Use region-wise voxel initialization (near, middle, far) to reflect mostly linear motion in driving viewpoints. Introduce deformable neural Gaussians to model non-rigid dynamic actors, with a learnable deformation network. Supervise geometry with depth and normal priors from pre-trained models to improve structure accuracy.", "result": "Evaluations on Waymo and KITTI datasets show state-of-the-art performance in novel-view synthesis for driving scenes.", "conclusion": "DriveSplat improves geometric accuracy and rendering robustness for driving scenarios by combining dynamic-static decoupling, region-aware initialization, deformable Gaussians, and geometric priors, demonstrating strong performance on standard driving benchmarks."}}
{"id": "2508.15693", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15693", "abs": "https://arxiv.org/abs/2508.15693", "authors": ["Wilka Carvalho", "Vikram Goddla", "Ishaan Sinha", "Hoon Shin", "Kunal Jha"], "title": "NiceWebRL: a Python library for human subject experiments with reinforcement learning environments", "comment": null, "summary": "We present NiceWebRL, a research tool that enables researchers to use machine\nreinforcement learning (RL) environments for online human subject experiments.\nNiceWebRL is a Python library that allows any Jax-based environment to be\ntransformed into an online interface, supporting both single-agent and\nmulti-agent environments. As such, NiceWebRL enables AI researchers to compare\ntheir algorithms to human performance, cognitive scientists to test ML\nalgorithms as theories for human cognition, and multi-agent researchers to\ndevelop algorithms for human-AI collaboration. We showcase NiceWebRL with 3\ncase studies that demonstrate its potential to help develop Human-like AI,\nHuman-compatible AI, and Human-assistive AI. In the first case study\n(Human-like AI), NiceWebRL enables the development of a novel RL model of\ncognition. Here, NiceWebRL facilitates testing this model against human\nparticipants in both a grid world and Craftax, a 2D Minecraft domain. In our\nsecond case study (Human-compatible AI), NiceWebRL enables the development of a\nnovel multi-agent RL algorithm that can generalize to human partners in the\nOvercooked domain. Finally, in our third case study (Human-assistive AI), we\nshow how NiceWebRL can allow researchers to study how an LLM can assist humans\non complex tasks in XLand-Minigrid, an environment with millions of\nhierarchical tasks. The library is available at\nhttps://github.com/KempnerInstitute/nicewebrl.", "AI": {"tldr": "NiceWebRL is a Python library that turns Jax RL environments into online human-subject experiment interfaces, enabling AI-human comparisons and human-centered AI research, demonstrated via three case studies; source at GitHub.", "motivation": "To enable AI researchers to compare algorithms with human performance, cognitive scientists to test ML as theories of cognition, and multi-agent researchers to study human\u2013AI collaboration.", "method": "Provide an open-source NiceWebRL library that transforms any Jax-based RL environment into an online interface, supporting single- and multi-agent setups, with three case studies across grid world/Craftax, Overcooked, and XLand-Minigrid to illustrate human-like, human-compatible, and human-assistive AI scenarios.", "result": "Three case studies demonstrate the tool's potential: (1) a novel RL model of cognition tested against human participants in grid world and Craftax; (2) a novel multi-agent RL algorithm generalizing to human partners in Overcooked; (3) exploration of LLM-assisted human performance in complex tasks in XLand-Minigrid; library is open-source at GitHub.", "conclusion": "NiceWebRL provides a bridge between RL environments and online human experiments, enabling human-centered AI research, with an open-source release for the community."}}
{"id": "2508.15291", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15291", "abs": "https://arxiv.org/abs/2508.15291", "authors": ["Haji Gul", "Abul Ghani Naim", "Ajaz Ahmad Bhat"], "title": "Evaluating Knowledge Graph Complexity via Semantic, Spectral, and Structural Metrics for Link Prediction", "comment": null, "summary": "Understanding dataset complexity is fundamental to evaluating and comparing\nlink prediction models on knowledge graphs (KGs). While the Cumulative Spectral\nGradient (CSG) metric, derived from probabilistic divergence between classes\nwithin a spectral clustering framework, has been proposed as a classifier\nagnostic complexity metric purportedly scaling with class cardinality and\ncorrelating with downstream performance, it has not been evaluated in KG\nsettings so far. In this work, we critically examine CSG in the context of\nmulti relational link prediction, incorporating semantic representations via\ntransformer derived embeddings. Contrary to prior claims, we find that CSG is\nhighly sensitive to parametrisation and does not robustly scale with the number\nof classes. Moreover, it exhibits weak or inconsistent correlation with\nstandard performance metrics such as Mean Reciprocal Rank (MRR) and Hit@1. To\ndeepen the analysis, we introduce and benchmark a set of structural and\nsemantic KG complexity metrics. Our findings reveal that global and local\nrelational ambiguity captured via Relation Entropy, node level Maximum Relation\nDiversity, and Relation Type Cardinality exhibit strong inverse correlations\nwith MRR and Hit@1, suggesting these as more faithful indicators of task\ndifficulty. Conversely, graph connectivity measures such as Average Degree,\nDegree Entropy, PageRank, and Eigenvector Centrality correlate positively with\nHit@10. Our results demonstrate that CSGs purported stability and\ngeneralization predictive power fail to hold in link prediction settings and\nunderscore the need for more stable, interpretable, and task-aligned measures\nof dataset complexity in knowledge driven learning.", "AI": {"tldr": "CSG is not a robust complexity metric for KG link prediction; it lacks stability and correlates poorly with performance; semantic/structural metrics like Relation Entropy and Degree measures better reflect task difficulty.", "motivation": "Assess applicability of CSG to knowledge graphs and link prediction; identify more stable, interpretable complexity measures.", "method": "Evaluate CSG with transformer-based embeddings on multi-relational link prediction; benchmark against a suite of structural and semantic KG complexity metrics; analyze correlations with MRR, Hit@1, Hit@10.", "result": "CSG is highly sensitive to parameterization and does not scale with class count; weak/inconsistent correlation with MRR/Hit@1. Relation Entropy, Maximum Relation Diversity, and Relation Type Cardinality show strong inverse correlations with MRR/Hit@1. Graph connectivity metrics correlate positively with Hit@10.", "conclusion": "CSG's claimed stability and predictive power do not hold for KG link prediction; preferable to rely on stable, interpretable, task-aligned complexity metrics for KG datasets."}}
{"id": "2508.15387", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15387", "abs": "https://arxiv.org/abs/2508.15387", "authors": ["Ruizhuo Song", "Beiming Yuan"], "title": "DIO: Refining Mutual Information and Causal Chain to Enhance Machine Abstract Reasoning Ability", "comment": "15 pages, 9 figures, 8 tables", "summary": "Despite the outstanding performance of current deep learning models across\nvarious domains, their fundamental bottleneck in abstract reasoning remains\nunresolved. To address this challenge, the academic community has introduced\nRaven's Progressive Matrices (RPM) problems as an authoritative benchmark for\nevaluating the abstract reasoning capabilities of deep learning algorithms,\nwith a focus on core intelligence dimensions such as abstract reasoning,\npattern recognition, and complex problem-solving. Therefore, this paper centers\non solving RPM problems, aiming to contribute to enhancing the abstract\nreasoning abilities of machine intelligence. Firstly, this paper adopts a\n``causal chain modeling'' perspective to systematically analyze the complete\ncausal chain in RPM tasks: image $\\rightarrow$ abstract attributes\n$\\rightarrow$ progressive attribute patterns $\\rightarrow$ pattern consistency\n$\\rightarrow$ correct answer. Based on this analysis, the network architecture\nof the baseline model DIO is designed. However, experiments reveal that the\noptimization objective formulated for DIO, namely maximizing the variational\nlower bound of mutual information between the context and the correct option,\nfails to enable the model to genuinely acquire the predefined human reasoning\nlogic. This is attributed to two main reasons: the tightness of the lower bound\nsignificantly impacts the effectiveness of mutual information maximization, and\nmutual information, as a statistical measure, does not capture the causal\nrelationship between subjects and objects. To overcome these limitations, this\npaper progressively proposes three improvement methods:", "AI": {"tldr": "A study on solving Raven's Progressive Matrices (RPM) using causal-chain analysis, showing that the DIO baseline's mutual-information objective fails to capture human-like abstract reasoning and proposing three progressive improvements.", "motivation": "RPMs are a benchmark for abstract reasoning in deep learning; current models struggle with abstract reasoning tasks. MI-based objectives and lower-bound tightness hinder learning of true causal reasoning, and MI does not inherently capture subject\u2013object causality.", "method": "Adopts a causal-chain modeling perspective: image -> abstract attributes -> progressive attribute patterns -> pattern consistency -> correct answer; designs the DIO baseline network; analyzes why the MI objective (maximizing the variational lower bound of mutual information) fails to enforce human-like reasoning; introduces three progressive improvement methods.", "result": "Experiments indicate that maximizing the variational lower bound of MI does not induce the intended human-like reasoning due to tight lower-bound issues and the inadequacy of MI to encode causal relations. The paper therefore proposes three improvement methods to address these limitations.", "conclusion": "The work highlights a gap between statistical MI-based optimization and causal reasoning in RPM tasks and outlines three steps to realign deep models with human-like abstract reasoning capabilities."}}
{"id": "2508.15734", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15734", "abs": "https://arxiv.org/abs/2508.15734", "authors": ["Cooper Elsworth", "Keguo Huang", "David Patterson", "Ian Schneider", "Robert Sedivy", "Savannah Goodman", "Ben Townsend", "Parthasarathy Ranganathan", "Jeff Dean", "Amin Vahdat", "Ben Gomes", "James Manyika"], "title": "Measuring the environmental impact of delivering AI at Google Scale", "comment": null, "summary": "The transformative power of AI is undeniable - but as user adoption\naccelerates, so does the need to understand and mitigate the environmental\nimpact of AI serving. However, no studies have measured AI serving\nenvironmental metrics in a production environment. This paper addresses this\ngap by proposing and executing a comprehensive methodology for measuring the\nenergy usage, carbon emissions, and water consumption of AI inference workloads\nin a large-scale, AI production environment. Our approach accounts for the full\nstack of AI serving infrastructure - including active AI accelerator power,\nhost system energy, idle machine capacity, and data center energy overhead.\nThrough detailed instrumentation of Google's AI infrastructure for serving the\nGemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24\nWh of energy - a figure substantially lower than many public estimates. We also\nshow that Google's software efficiency efforts and clean energy procurement\nhave driven a 33x reduction in energy consumption and a 44x reduction in carbon\nfootprint for the median Gemini Apps text prompt over one year. We identify\nthat the median Gemini Apps text prompt uses less energy than watching nine\nseconds of television (0.24 Wh) and consumes the equivalent of five drops of\nwater (0.26 mL). While these impacts are low compared to other daily\nactivities, reducing the environmental impact of AI serving continues to\nwarrant important attention. Towards this objective, we propose that a\ncomprehensive measurement of AI serving environmental metrics is critical for\naccurately comparing models, and to properly incentivize efficiency gains\nacross the full AI serving stack.", "AI": {"tldr": "A production-scale method to quantify AI inference environmental metrics, reporting low per-prompt energy and major efficiency gains, and advocating standardized metrics for AI serving.", "motivation": "As AI adoption expands, measuring environmental impact in production is essential; prior work lacks production-environment metrics.", "method": "Instrument and measure energy use across the full AI serving stack (accelerator power, host energy, idle capacity, data center overhead) in Google's Gemini AI serving deployments; compute energy, carbon, and water metrics for inference prompts.", "result": "Median Gemini Apps text prompt consumes 0.24 Wh; 33x reduction in energy and 44x reduction in carbon footprint over one year due to efficiency and clean energy; per-prompt energy is lower than watching nine seconds of TV and equivalent to five drops of water; underscores the feasibility of measuring environmental metrics in production.", "conclusion": "Comprehensive environmental metrics are essential for fair model comparisons and to incentivize efficiency across the AI serving stack; propose standardized measurement practices for AI serving environments."}}
{"id": "2508.15317", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15317", "abs": "https://arxiv.org/abs/2508.15317", "authors": ["Zhaorui Tan", "Yijie Hu", "Xi Yang", "Qiufeng Wang", "Anh Nguyen", "Kaizhu Huang"], "title": "Saving for the future: Enhancing generalization via partial logic regularization", "comment": null, "summary": "Generalization remains a significant challenge in visual classification\ntasks, particularly in handling unknown classes in real-world applications.\nExisting research focuses on the class discovery paradigm, which tends to favor\nknown classes, and the incremental learning paradigm, which suffers from\ncatastrophic forgetting. Recent approaches such as the L-Reg technique employ\nlogic-based regularization to enhance generalization but are bound by the\nnecessity of fully defined logical formulas, limiting flexibility for unknown\nclasses. This paper introduces PL-Reg, a novel partial-logic regularization\nterm that allows models to reserve space for undefined logic formulas,\nimproving adaptability to unknown classes. Specifically, we formally\ndemonstrate that tasks involving unknown classes can be effectively explained\nusing partial logic. We also prove that methods based on partial logic lead to\nimproved generalization. We validate PL-Reg through extensive experiments on\nGeneralized Category Discovery, Multi-Domain Generalized Category Discovery,\nand long-tailed Class Incremental Learning tasks, demonstrating consistent\nperformance improvements. Our results highlight the effectiveness of partial\nlogic in tackling challenges related to unknown classes.", "AI": {"tldr": "Introduces PL-Reg, a partial-logic regularization term that reserves space for undefined logic, enabling better generalization to unknown classes; provides theoretical justification and demonstrates empirical gains across Generalized Category Discovery, Multi-Domain Generalized Category Discovery, and long-tailed class incremental learning.", "motivation": "Generalization in visual classification with unknown classes remains a significant challenge. Existing paradigms: class discovery tends to favor known classes, while incremental learning suffers from catastrophic forgetting. L-Reg regularization requires fully defined logical formulas, which reduces flexibility for unknown classes. A more flexible reasoning framework is needed to accommodate unknowns.", "method": "Propose PL-Reg, a partial-logic regularization term that allows models to reserve space for undefined logic formulas. Formally demonstrate that tasks involving unknown classes can be explained using partial logic. Prove that methods based on partial logic improve generalization. Validate PL-Reg through experiments on Generalized Category Discovery (GCD), Multi-Domain Generalized Category Discovery (MD-GCD), and long-tailed Class Incremental Learning tasks.", "result": "The paper provides formal arguments showing that partial logic can explain unknown-class tasks and improve generalization. Empirically, PL-Reg yields consistent performance improvements across GCD, MD-GCD, and long-tailed class incremental learning tasks.", "conclusion": "Partial logic is effective for tackling challenges related to unknown classes. PL-Reg offers flexible regularization that improves adaptability and generalization in visual classification under unknown-class scenarios."}}
{"id": "2508.15389", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15389", "abs": "https://arxiv.org/abs/2508.15389", "authors": ["Wenrui Li", "Wei Han", "Liang-Jian Deng", "Ruiqin Xiong", "Xiaopeng Fan"], "title": "Spiking Variational Graph Representation Inference for Video Summarization", "comment": "Accepted by IEEE TIP", "summary": "With the rise of short video content, efficient video summarization\ntechniques for extracting key information have become crucial. However,\nexisting methods struggle to capture the global temporal dependencies and\nmaintain the semantic coherence of video content. Additionally, these methods\nare also influenced by noise during multi-channel feature fusion. We propose a\nSpiking Variational Graph (SpiVG) Network, which enhances information density\nand reduces computational complexity. First, we design a keyframe extractor\nbased on Spiking Neural Networks (SNN), leveraging the event-driven computation\nmechanism of SNNs to learn keyframe features autonomously. To enable\nfine-grained and adaptable reasoning across video frames, we introduce a\nDynamic Aggregation Graph Reasoner, which decouples contextual object\nconsistency from semantic perspective coherence. We present a Variational\nInference Reconstruction Module to address uncertainty and noise arising during\nmulti-channel feature fusion. In this module, we employ Evidence Lower Bound\nOptimization (ELBO) to capture the latent structure of multi-channel feature\ndistributions, using posterior distribution regularization to reduce\noverfitting. Experimental results show that SpiVG surpasses existing methods\nacross multiple datasets such as SumMe, TVSum, VideoXum, and QFVS. Our codes\nand pre-trained models are available at https://github.com/liwrui/SpiVG.", "AI": {"tldr": "Proposes SpiVG: a Spiking Variational Graph network for video summarization that uses SNN-based keyframe extraction, dynamic graph reasoning, and variational reconstruction to handle global temporal dependencies and noise in multi-channel features, achieving state-of-the-art performance on SumMe, TVSum, VideoXum, QFVS.", "motivation": "Current video summarization methods struggle to capture global temporal dependencies and are sensitive to noise during multi-channel feature fusion, limiting semantic coherence and efficiency.", "method": "Keyframe extractor based on Spiking Neural Networks for autonomous keyframe learning; Dynamic Aggregation Graph Reasoner for fine-grained contextual reasoning separating object consistency from semantic coherence; Variational Inference Reconstruction Module using ELBO and posterior regularization to model latent multi-channel feature distributions and mitigate noise.", "result": "SpiVG outperforms existing methods on multiple datasets (SumMe, TVSum, VideoXum, QFVS); code and pre-trained models are publicly available.", "conclusion": "SpiVG demonstrates improved information density and reduced computational complexity for video summarization, with robust performance across datasets and a modular framework that addresses global temporal dependencies and noisy multi-channel fusion."}}
{"id": "2508.15748", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15748", "abs": "https://arxiv.org/abs/2508.15748", "authors": ["Emma Rath", "Stuart Armstrong", "Rebecca Gorman"], "title": "Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots", "comment": null, "summary": "The development of parasocial relationships with AI agents has severe, and in\nsome cases, tragic effects for human well-being. Yet preventing such dynamics\nis challenging: parasocial cues often emerge gradually in private\nconversations, and not all forms of emotional engagement are inherently\nharmful. We address this challenge by introducing a simple response evaluation\nframework, created by repurposing a state-of-the-art language model, that\nevaluates ongoing conversations for parasocial cues in real time. To test the\nfeasibility of this approach, we constructed a small synthetic dataset of\nthirty dialogues spanning parasocial, sycophantic, and neutral conversations.\nIterative evaluation with five stage testing successfully identified all\nparasocial conversations while avoiding false positives under a tolerant\nunanimity rule, with detection typically occurring within the first few\nexchanges. These findings provide preliminary evidence that evaluation agents\ncan provide a viable solution for the prevention of parasocial relations.", "AI": {"tldr": "Real-time parasocial cue detection using a repurposed LLM. Tested on a tiny synthetic dataset; achieved early, comprehensive identification of parasocial conversations with tolerant unanimity and no false positives under that rule\u2014suggesting viability, not yet generalizable.", "motivation": "Parasocial relationships with AI can harm well-being and are hard to prevent because cues emerge gradually and emotional engagement isn\u2019t always harmful. A lightweight evaluation framework aims to monitor ongoing chats in real time to flag parasocial cues and prevent harmful dynamics.", "method": "A simple response-evaluation framework repurposing a state-of-the-art language model to assess ongoing conversations for parasocial cues in real time. Evaluated on a small synthetic dataset of 30 dialogues (parasocial, sycophantic, neutral). Five-stage iterative testing with a tolerant unanimity rule to minimize false positives, with detection typically within the first few exchanges.", "result": "All parasocial dialogues were identified; no false positives under the tolerant unanimity rule; detection occurred within the first few exchanges in most cases. Provides preliminary evidence that evaluation agents can help prevent parasocial relations.", "conclusion": "The findings offer preliminary support that an evaluation-agent approach can be a viable solution for preventing parasocial relations, though further work is needed to assess generalizability and real-world performance."}}
{"id": "2508.15364", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15364", "abs": "https://arxiv.org/abs/2508.15364", "authors": ["Saleh Afzoon", "Amin Beheshti", "Nabi Rezvani", "Farshad Khunjush", "Usman Naseem", "John McMahon", "Zahra Fathollahi", "Mahdieh Labani", "Wathiq Mansoor", "Xuyun Zhang"], "title": "ExBigBang: A Dynamic Approach for Explainable Persona Classification through Contextualized Hybrid Transformer Analysis", "comment": null, "summary": "In user-centric design, persona development plays a vital role in\nunderstanding user behaviour, capturing needs, segmenting audiences, and\nguiding design decisions. However, the growing complexity of user interactions\ncalls for a more contextualized approach to ensure designs align with real user\nneeds. While earlier studies have advanced persona classification by modelling\nuser behaviour, capturing contextual information, especially by integrating\ntextual and tabular data, remains a key challenge. These models also often lack\nexplainability, leaving their predictions difficult to interpret or justify. To\naddress these limitations, we present ExBigBang (Explainable BigBang), a hybrid\ntext-tabular approach that uses transformer-based architectures to model rich\ncontextual features for persona classification. ExBigBang incorporates\nmetadata, domain knowledge, and user profiling to embed deeper context into\npredictions. Through a cyclical process of user profiling and classification,\nour approach dynamically updates to reflect evolving user behaviours.\nExperiments on a benchmark persona classification dataset demonstrate the\nrobustness of our model. An ablation study confirms the benefits of combining\ntext and tabular data, while Explainable AI techniques shed light on the\nrationale behind the model's predictions.", "AI": {"tldr": "ExBigBang is a hybrid text-tabular transformer model for explainable persona classification that integrates metadata, domain knowledge, and user profiling in a cyclical profiling-classification process to capture evolving user contexts and improve interpretability.", "motivation": "To overcome limitations in persona modeling: insufficient context, poor integration of textual and tabular data, lack of explainability, and static representations that fail to reflect evolving user behaviors in user-centric design.", "method": "A hybrid text-tabular transformer architecture (ExBigBang) that fuses textual and tabular features, incorporating metadata, domain knowledge, and user profiling. It uses a cyclical process of user profiling and classification to update predictions and applies Explainable AI techniques to illuminate decisions; evaluated via ablation studies on a benchmark persona dataset.", "result": "The model demonstrates robustness on a benchmark dataset. Ablation studies show that combining text and tabular data improves performance, and Explainable AI techniques provide insight into the model\u2019s predictions.", "conclusion": "ExBigBang offers an explainable, context-rich approach to persona classification that dynamically updates with user behavior, showing the value of integrating text and tabular data for personalized design decisions."}}
{"id": "2508.15404", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15404", "abs": "https://arxiv.org/abs/2508.15404", "authors": ["Anthony Bisulco", "Rahul Ramesh", "Randall Balestriero", "Pratik Chaudhari"], "title": "From Linearity to Non-Linearity: How Masked Autoencoders Capture Spatial Correlations", "comment": null, "summary": "Masked Autoencoders (MAEs) have emerged as a powerful pretraining technique\nfor vision foundation models. Despite their effectiveness, they require\nextensive hyperparameter tuning (masking ratio, patch size, encoder/decoder\nlayers) when applied to novel datasets. While prior theoretical works have\nanalyzed MAEs in terms of their attention patterns and hierarchical latent\nvariable models, the connection between MAE hyperparameters and performance on\ndownstream tasks is relatively unexplored. This work investigates how MAEs\nlearn spatial correlations in the input image. We analytically derive the\nfeatures learned by a linear MAE and show that masking ratio and patch size can\nbe used to select for features that capture short- and long-range spatial\ncorrelations. We extend this analysis to non-linear MAEs to show that MAE\nrepresentations adapt to spatial correlations in the dataset, beyond\nsecond-order statistics. Finally, we discuss some insights on how to select MAE\nhyper-parameters in practice.", "AI": {"tldr": "MAEs' hyperparameters shape the spatial scale of learned features: linear MAEs reveal how masking ratio and patch size bias toward short- vs long-range correlations; nonlinear MAEs adapt to spatial statistics beyond second-order; provides practical hyperparameter guidance.", "motivation": "To understand how MAE hyperparameters influence the kinds of spatial correlations learned and how this affects downstream performance, bridging theory and practical tuning.", "method": "The authors analytically derive feature learning in a linear MAE to relate masking ratio and patch size to captured spatial correlations; they extend the analysis to non-linear MAEs to show adaptation to dataset spatial statistics beyond second-order.", "result": "Masking ratio and patch size selectively promote features that capture short- and long-range spatial correlations; nonlinear MAEs adapt representations to the dataset's spatial statistics beyond second-order; implications for hyperparameter selection.", "conclusion": "The study provides actionable insights for choosing MAE hyperparameters by aligning them with the desired spatial correlation structure in the data, reducing trial-and-error in practice."}}
{"id": "2508.15757", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.15757", "abs": "https://arxiv.org/abs/2508.15757", "authors": ["Yuxing Lu", "Yucheng Hu", "Nan Sun", "Xukai Zhao"], "title": "Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback", "comment": "9 pages, 4 figures, 4 tables", "summary": "Configuration optimization remains a critical bottleneck in machine learning,\nrequiring coordinated tuning across model architecture, training strategy,\nfeature engineering, and hyperparameters. Traditional approaches treat these\ndimensions independently and lack interpretability, while recent automated\nmethods struggle with dynamic adaptability and semantic reasoning about\noptimization decisions. We introduce Language-Guided Tuning (LGT), a novel\nframework that employs multi-agent Large Language Models to intelligently\noptimize configurations through natural language reasoning. We apply textual\ngradients - qualitative feedback signals that complement numerical optimization\nby providing semantic understanding of training dynamics and configuration\ninterdependencies. LGT coordinates three specialized agents: an Advisor that\nproposes configuration changes, an Evaluator that assesses progress, and an\nOptimizer that refines the decision-making process, creating a self-improving\nfeedback loop. Through comprehensive evaluation on six diverse datasets, LGT\ndemonstrates substantial improvements over traditional optimization methods,\nachieving performance gains while maintaining high interpretability.", "AI": {"tldr": "Language-Guided Tuning (LGT) uses a three-agent LLM framework with textual gradients to semantically guide configuration optimization, delivering interpretable improvements over traditional methods across six datasets.", "motivation": "Configuration optimization in ML spans architecture, training strategy, feature engineering, and hyperparameters. Traditional approaches treat these dimensions separately and lack interpretability, while existing automated methods struggle with dynamic adaptability and semantic understanding of interdependencies.", "method": "A three-agent framework where an Advisor proposes changes, an Evaluator assesses progress, and an Optimizer refines decisions, all guided by natural language reasoning and qualitative textual gradients. This creates a self-improving feedback loop. Evaluation is conducted on six diverse datasets.", "result": "LGT achieves substantial improvements over traditional optimization methods and preserves high interpretability, demonstrating effective coordination among agents and meaningful semantic signals.", "conclusion": "Language-Guided Tuning introduces an interpretable, semantically-guided optimization paradigm that leverages multi-agent LLMs and textual gradients to coordinate configuration search and adaptation."}}
{"id": "2508.15369", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15369", "abs": "https://arxiv.org/abs/2508.15369", "authors": ["Yonathan Guttel", "Orit Moradov", "Nachi Lieder", "Asnat Greenstein-Messica"], "title": "Enhancing Forecasting with a 2D Time Series Approach for Cohort-Based Data", "comment": "Accepted at IEEE CiFer Companion 2025. 5 pages, 3 figures, 2 tables", "summary": "This paper introduces a novel two-dimensional (2D) time series forecasting\nmodel that integrates cohort behavior over time, addressing challenges in small\ndata environments. We demonstrate its efficacy using multiple real-world\ndatasets, showcasing superior performance in accuracy and adaptability compared\nto reference models. The approach offers valuable insights for strategic\ndecision-making across industries facing financial and marketing forecasting\nchallenges.", "AI": {"tldr": "Introduces a 2D time-series forecasting model that embeds cohort dynamics to boost performance in small data contexts; validated on real datasets with improved accuracy and adaptability over baselines, with potential strategic use in finance/marketing.", "motivation": "Hard forecasting in small datasets and domains where cohort effects influence outcomes; need methods that leverage cross-sectional cohort structure to improve accuracy and decision support.", "method": "Proposes a 2D representation that integrates cohort behavior over time; trains on multiple real-world datasets; compares against reference models to demonstrate performance gains; emphasis on small-data applicability; details not provided in abstract.", "result": "Demonstrates superior accuracy and adaptability across several real-world datasets relative to baselines; shows practical usefulness for strategic decision-making.", "conclusion": "The approach offers valuable insights for decision-making in industries with financial and marketing forecasting challenges; suggests broader applicability and potential impact, while prompting further exploration into cohort definition and model specifics."}}
{"id": "2508.15415", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15415", "abs": "https://arxiv.org/abs/2508.15415", "authors": ["Dengyan Luo", "Yanping Xiang", "Hu Wang", "Luping Ji. Shuai Li", "Mao Ye"], "title": "Bidirectional Temporal Information Propagation for Moving Infrared Small Target Detection", "comment": null, "summary": "Moving infrared small target detection is broadly adopted in infrared search\nand track systems, and has attracted considerable research focus in recent\nyears. The existing learning-based multi-frame methods mainly aggregate the\ninformation of adjacent frames in a sliding window fashion to assist the\ndetection of the current frame. However, the sliding-window-based methods do\nnot consider joint optimization of the entire video clip and ignore the global\ntemporal information outside the sliding window, resulting in redundant\ncomputation and sub-optimal performance. In this paper, we propose a\nBidirectional temporal information propagation method for moving InfraRed small\ntarget Detection, dubbed BIRD. The bidirectional propagation strategy\nsimultaneously utilizes local temporal information of adjacent frames and\nglobal temporal information of past and future frames in a recursive fashion.\nSpecifically, in the forward and backward propagation branches, we first design\na Local Temporal Motion Fusion (LTMF) module to model local spatio-temporal\ndependency between a target frame and its two adjacent frames. Then, a Global\nTemporal Motion Fusion (GTMF) module is developed to further aggregate the\nglobal propagation feature with the local fusion feature. Finally, the\nbidirectional aggregated features are fused and input into the detection head\nfor detection. In addition, the entire video clip is jointly optimized by the\ntraditional detection loss and the additional Spatio-Temporal Fusion (STF)\nloss. Extensive experiments demonstrate that the proposed BIRD method not only\nachieves the state-of-the-art performance but also shows a fast inference\nspeed.", "AI": {"tldr": "Bidirectional temporal propagation (BIRD) for moving infrared small target detection; uses Local Temporal Motion Fusion (LTMF) and Global Temporal Motion Fusion (GTMF) in forward/backward branches and an STF loss; achieves state-of-the-art performance with fast inference.", "motivation": "Sliding-window multi-frame approaches ignore global temporal information and can incur redundant computation; joint optimization over the entire video could improve both accuracy and efficiency.", "method": "Introduce LTMF to model local spatio-temporal dependencies between a frame and its two neighbors, followed by GTMF to integrate global propagation features; run in both forward and backward propagation branches; fuse bidirectional features and feed to detection head; train with standard detection loss plus Spatio-Temporal Fusion (STF) loss for joint optimization over the video clip.", "result": "Empirical results indicate state-of-the-art detection accuracy and fast inference speed.", "conclusion": "BIRD effectively leverages both local and global temporal information, outperforming sliding-window methods and offering a computationally efficient solution for infrared small target detection."}}
{"id": "2507.23341", "categories": ["cs.CV", "cs.AI", "68T45, 68T07", "I.4.8; I.4.9; I.5.4"], "pdf": "https://arxiv.org/pdf/2507.23341", "abs": "https://arxiv.org/abs/2507.23341", "authors": ["Ahmet Can \u00d6merciko\u011flu", "Mustafa Mansur Y\u00f6n\u00fcg\u00fcl", "Pakize Erdo\u011fmu\u015f"], "title": "The Impact of Image Resolution on Face Detection: A Comparative Analysis of MTCNN, YOLOv XI and YOLOv XII models", "comment": "6 pages, 5 figures, 4 tables", "summary": "Face detection is a crucial component in many AI-driven applications such as\nsurveillance, biometric authentication, and human-computer interaction.\nHowever, real-world conditions like low-resolution imagery present significant\nchallenges that degrade detection performance. In this study, we systematically\ninvestigate the impact of input resolution on the accuracy and robustness of\nthree prominent deep learning-based face detectors: YOLOv11, YOLOv12, and\nMTCNN. Using the WIDER FACE dataset, we conduct extensive evaluations across\nmultiple image resolutions (160x160, 320x320, and 640x640) and assess each\nmodel's performance using metrics such as precision, recall, mAP50, mAP50-95,\nand inference time. Results indicate that YOLOv11 outperforms YOLOv12 and MTCNN\nin terms of detection accuracy, especially at higher resolutions, while YOLOv12\nexhibits slightly better recall. MTCNN, although competitive in landmark\nlocalization, lags in real-time inference speed. Our findings provide\nactionable insights for selecting resolution-aware face detection models\nsuitable for varying operational constraints.", "AI": {"tldr": "Resolution profoundly affects face detector performance; YOLOv11 achieves the best accuracy at larger input sizes, YOLOv12 shows a slight edge in recall, and MTCNN provides strong landmark localization but is slower for real-time use.", "motivation": "To understand how input resolution impacts accuracy and robustness of leading deep learning-based face detectors, guiding model choice under real-world constraints.", "method": "Systematic evaluation on the WIDER FACE dataset across three detectors (YOLOv11, YOLOv12, MTCNN) and three input resolutions (160x160, 320x320, 640x640), using metrics such as precision, recall, mAP50, mAP50-95, and inference time.", "result": "YOLOv11 generally outperforms YOLOv12 and MTCNN in detection accuracy, especially at higher resolutions; YOLOv12 shows slightly better recall; MTCNN is competitive for landmark localization but trails in real-time inference speed.", "conclusion": "The study offers actionable guidance for selecting resolution-aware face detectors under varying operational constraints and highlights the importance of aligning input resolution with the desired accuracy-speed tradeoffs."}}
{"id": "2508.15374", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2508.15374", "abs": "https://arxiv.org/abs/2508.15374", "authors": ["Omri Ben-Dov", "Samira Samadi", "Amartya Sanyal", "Alexandru \u0162ifrea"], "title": "Fairness for the People, by the People: Minority Collective Action", "comment": null, "summary": "Machine learning models often preserve biases present in training data,\nleading to unfair treatment of certain minority groups. Despite an array of\nexisting firm-side bias mitigation techniques, they typically incur utility\ncosts and require organizational buy-in. Recognizing that many models rely on\nuser-contributed data, end-users can induce fairness through the framework of\nAlgorithmic Collective Action, where a coordinated minority group strategically\nrelabels its own data to enhance fairness, without altering the firm's training\nprocess. We propose three practical, model-agnostic methods to approximate\nideal relabeling and validate them on real-world datasets. Our findings show\nthat a subgroup of the minority can substantially reduce unfairness with a\nsmall impact on the overall prediction error.", "AI": {"tldr": "Coordinated minority relabeling within Algorithmic Collective Action can meaningfully reduce unfairness with modest accuracy loss, demonstrated via three practical, model-agnostic relabeling approximations tested on real-world datasets.", "motivation": "ML bias persists from training data and is costly for firms to mitigate; end-user data offers a low-friction fairness lever. The idea of Algorithmic Collective Action enables minority groups to improve fairness by relabeling their own data without changing the firm's training pipeline, potentially reducing unfairness with minimal utility loss.", "method": "The paper proposes three practical, model-agnostic methods to approximate ideal relabeling. These approaches operate on user-contributed data and do not require changes to the firm's training process. They are evaluated via simulations/experiments on real-world datasets to assess their impact on fairness metrics and overall accuracy.", "result": "A subgroup of the minority can substantially reduce unfairness with a small impact on overall prediction error, as validated by experiments on real-world datasets.", "conclusion": "End-user coordinated relabeling (Algorithmic Collective Action) is a viable, model-agnostic avenue for fairness improvement that complements firm-side interventions. It offers a low-overhead path for minority groups to influence model fairness, though practical deployment must consider ethical, privacy, and governance considerations."}}
{"id": "2508.15431", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15431", "abs": "https://arxiv.org/abs/2508.15431", "authors": ["Danish Zia Baig", "Mohsin Kamal"], "title": "A Curated Dataset and Deep Learning Approach for Minor Dent Detection in Vehicles", "comment": null, "summary": "Conventional car damage inspection techniques are labor-intensive, manual,\nand frequently overlook tiny surface imperfections like microscopic dents.\nMachine learning provides an innovative solution to the increasing demand for\nquicker and more precise inspection methods. The paper uses the YOLOv8 object\nrecognition framework to provide a deep learning-based solution for\nautomatically detecting microscopic surface flaws, notably tiny dents, on car\nexteriors. Traditional automotive damage inspection procedures are manual,\ntime-consuming, and frequently unreliable at detecting tiny flaws. To solve\nthis, a bespoke dataset containing annotated photos of car surfaces under\nvarious lighting circumstances, angles, and textures was created. To improve\nrobustness, the YOLOv8m model and its customized variants, YOLOv8m-t4 and\nYOLOv8m-t42, were trained employing real-time data augmentation approaches.\nExperimental results show that the technique has excellent detection accuracy\nand low inference latency, making it suited for real-time applications such as\nautomated insurance evaluations and automobile inspections. Evaluation\nparameters such as mean Average Precision (mAP), precision, recall, and\nF1-score verified the model's efficacy. With a precision of 0.86, recall of\n0.84, and F1-score of 0.85, the YOLOv8m-t42 model outperformed the YOLOv8m-t4\nmodel (precision: 0.81, recall: 0.79, F1-score: 0.80) in identifying\nmicroscopic surface defects. With a little reduced mAP@0.5:0.95 of 0.20, the\nmAP@0.5 for YOLOv8m-t42 stabilized at 0.60. Furthermore, YOLOv8m-t42's PR curve\narea was 0.88, suggesting more consistent performance than YOLOv8m-t4 (0.82).\nYOLOv8m-t42 has greater accuracy and is more appropriate for practical dent\ndetection applications, even though its convergence is slower.", "AI": {"tldr": "YOLOv8m-t42 detects microscopic car surface dents with high precision/recall and real-time performance, outperforming YOLOv8m-t4 despite longer convergence.", "motivation": "Automate and speed up car damage inspection to detect tiny surface flaws that manual methods miss.", "method": "Create a bespoke annotated dataset of car surfaces under varying lighting, angles, and textures; train YOLOv8m and variants YOLOv8m-t4 and YOLOv8m-t42 with real-time data augmentation; evaluate using mAP, precision, recall, F1; compare models; report PR curves.", "result": "YOLOv8m-t42 achieved precision 0.86, recall 0.84, F1 0.85; YOLOv8m-t4 achieved 0.81, 0.79, 0.80; mAP@0.5:0.95 reduced to 0.20 but stabilized at 0.60 for YOLOv8m-t42; PR area 0.88 vs 0.82; overall better accuracy and robustness; suitable for real-time dent detection.", "conclusion": "YOLOv8m-t42 provides higher accuracy and robustness for microscopic dent detection in real-world conditions, making it more appropriate for practical deployment though it converges more slowly."}}
{"id": "2508.15378", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15378", "abs": "https://arxiv.org/abs/2508.15378", "authors": ["Haodi Zhong", "Liuxin Zou", "Di Wang", "Bo Wang", "Zhenxing Niu", "Quan Wang"], "title": "EvoFormer: Learning Dynamic Graph-Level Representations with Structural and Temporal Bias Correction", "comment": null, "summary": "Dynamic graph-level embedding aims to capture structural evolution in\nnetworks, which is essential for modeling real-world scenarios. However,\nexisting methods face two critical yet under-explored issues: Structural Visit\nBias, where random walk sampling disproportionately emphasizes high-degree\nnodes, leading to redundant and noisy structural representations; and Abrupt\nEvolution Blindness, the failure to effectively detect sudden structural\nchanges due to rigid or overly simplistic temporal modeling strategies,\nresulting in inconsistent temporal embeddings. To overcome these challenges, we\npropose EvoFormer, an evolution-aware Transformer framework tailored for\ndynamic graph-level representation learning. To mitigate Structural Visit Bias,\nEvoFormer introduces a Structure-Aware Transformer Module that incorporates\npositional encoding based on node structural roles, allowing the model to\nglobally differentiate and accurately represent node structures. To overcome\nAbrupt Evolution Blindness, EvoFormer employs an Evolution-Sensitive Temporal\nModule, which explicitly models temporal evolution through a sequential\nthree-step strategy: (I) Random Walk Timestamp Classification, generating\ninitial timestamp-aware graph-level embeddings; (II) Graph-Level Temporal\nSegmentation, partitioning the graph stream into segments reflecting\nstructurally coherent periods; and (III) Segment-Aware Temporal Self-Attention\ncombined with an Edge Evolution Prediction task, enabling the model to\nprecisely capture segment boundaries and perceive structural evolution trends,\neffectively adapting to rapid temporal shifts. Extensive evaluations on five\nbenchmark datasets confirm that EvoFormer achieves state-of-the-art performance\nin graph similarity ranking, temporal anomaly detection, and temporal\nsegmentation tasks, validating its effectiveness in correcting structural and\ntemporal biases.", "AI": {"tldr": "EvoFormer proposes an evolution-aware Transformer to tackle Structural Visit Bias and Abrupt Evolution Blindness in dynamic graphs, using a Structure-Aware Transformer and an Evolution-Sensitive Temporal Module with a three-step process, achieving state-of-the-art results on five datasets for graph similarity, anomaly detection, and segmentation.", "motivation": "Two critical issues in dynamic graph learning: (1) Structural Visit Bias from random-walk sampling that over-emphasizes high-degree nodes, leading to redundant/noisy structural representations; (2) Abrupt Evolution Blindness due to rigid temporal modeling that fails to detect sudden structural changes, causing inconsistent temporal embeddings.", "method": "An evolution-aware Transformer framework (EvoFormer) with: (A) Structure-Aware Transformer Module that uses position encoding based on node structural roles to globally differentiate node structures; (B) Evolution-Sensitive Temporal Module employing a three-step process: (I) Random Walk Timestamp Classification to produce timestamp-aware graph embeddings; (II) Graph-Level Temporal Segmentation to partition the graph stream into structurally coherent segments; (III) Segment-Aware Temporal Self-Attention plus an Edge Evolution Prediction task to capture segment boundaries and evolution trends.", "result": "Extensive evaluations on five benchmark datasets show state-of-the-art performance in graph similarity ranking, temporal anomaly detection, and temporal segmentation tasks, demonstrating EvoFormer\u2019s effectiveness in correcting structural and temporal biases.", "conclusion": "EvoFormer effectively mitigates both Structural Visit Bias and Abrupt Evolution Blindness, delivering robust dynamic graph-level representations and strong performance across tasks that require capturing structural evolution."}}
{"id": "2508.15439", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15439", "abs": "https://arxiv.org/abs/2508.15439", "authors": ["Yogesh Kumar", "Uday Agarwal", "Manish Gupta", "Anand Mishra"], "title": "Aligning Moments in Time using Video Queries", "comment": "11 pages, 4 figures", "summary": "Video-to-video moment retrieval (Vid2VidMR) is the task of localizing unseen\nevents or moments in a target video using a query video. This task poses\nseveral challenges, such as the need for semantic frame-level alignment and\nmodeling complex dependencies between query and target videos. To tackle this\nchallenging problem, we introduce MATR (Moment Alignment TRansformer), a\ntransformer-based model designed to capture semantic context as well as the\ntemporal details necessary for precise moment localization. MATR conditions\ntarget video representations on query video features using dual-stage sequence\nalignment that encodes the required correlations and dependencies. These\nrepresentations are then used to guide foreground/background classification and\nboundary prediction heads, enabling the model to accurately identify moments in\nthe target video that semantically match with the query video. Additionally, to\nprovide a strong task-specific initialization for MATR, we propose a\nself-supervised pre-training technique that involves training the model to\nlocalize random clips within videos. Extensive experiments demonstrate that\nMATR achieves notable performance improvements of 13.1% in R@1 and 8.1% in mIoU\non an absolute scale compared to state-of-the-art methods on the popular\nActivityNet-VRL dataset. Additionally, on our newly proposed dataset,\nSportsMoments, MATR shows a 14.7% gain in R@1 and a 14.4% gain in mIoU on an\nabsolute scale over strong baselines.", "AI": {"tldr": "Introduces MATR, a transformer-based Vid2VidMR model with dual-stage alignment and self-supervised pretraining, achieving major gains on ActivityNet-VRL and SportsMoments.", "motivation": "The task requires precise semantic frame-level alignment and modeling of complex dependencies between query and target videos; existing methods struggle with boundary precision and contextual reasoning.", "method": "MATR uses a transformer that conditions target video representations on query features through dual-stage sequence alignment to capture correlations; includes foreground/background classification and boundary prediction heads; equipped with self-supervised pretraining by localizing random clips within videos.", "result": "Achieves significant gains: 13.1% R@1 and 8.1% mIoU on ActivityNet-VRL; 14.7% R@1 and 14.4% mIoU on SportsMoments, versus strong baselines.", "conclusion": "MATR effectively models semantic context and temporal details for precise moment localization; self-supervised pretraining provides strong initialization and substantial performance gains across datasets."}}
{"id": "2508.15392", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2508.15392", "abs": "https://arxiv.org/abs/2508.15392", "authors": ["Chenghao Zhang", "Qingqing Long", "Ludi Wang", "Wenjuan Cui", "Jianjun Yu", "Yi Du"], "title": "CITE: A Comprehensive Benchmark for Heterogeneous Text-Attributed Graphs on Catalytic Materials", "comment": "23 pages, 4 figures,", "summary": "Text-attributed graphs(TAGs) are pervasive in real-world systems,where each\nnode carries its own textual features. In many cases these graphs are\ninherently heterogeneous, containing multiple node types and diverse edge\ntypes. Despite the ubiquity of such heterogeneous TAGs, there remains a lack of\nlarge-scale benchmark datasets. This shortage has become a critical bottleneck,\nhindering the development and fair comparison of representation learning\nmethods on heterogeneous text-attributed graphs. In this paper, we introduce\nCITE - Catalytic Information Textual Entities Graph, the first and largest\nheterogeneous text-attributed citation graph benchmark for catalytic materials.\nCITE comprises over 438K nodes and 1.2M edges, spanning four relation types. In\naddition, we establish standardized evaluation procedures and conduct extensive\nbenchmarking on the node classification task, as well as ablation experiments\non the heterogeneous and textual properties of CITE. We compare four classes of\nlearning paradigms, including homogeneous graph models, heterogeneous graph\nmodels, LLM(Large Language Model)-centric models, and LLM+Graph models. In a\nnutshell, we provide (i) an overview of the CITE dataset, (ii) standardized\nevaluation protocols, and (iii) baseline and ablation experiments across\ndiverse modeling paradigms.", "AI": {"tldr": "A new large-scale benchmark CITE for heterogeneous text-attributed graphs (TAGs) in catalytic materials.", "motivation": "Addresses the gap of lacking large-scale benchmarks for heterogeneous text-attributed graphs and the need for standardized evaluation and fair comparison of representation learning methods.", "method": "Construct CITE dataset with 438K nodes, 1.2M edges across four relation types; include textual features for nodes; establish standardized evaluation protocols; benchmark across four learning paradigms: homogeneous GMs, heterogeneous GMs, LLM-centric models, and LLM+Graph models; perform node classification and ablations.", "result": "Introduces CITE as the first and largest heterogeneous text-attributed citation graph benchmark for catalytic materials; provides standardized evaluation procedures; conducts extensive benchmarking and ablation across heterogeneous/textual properties and four modeling paradigms.", "conclusion": "CITE enables fair comparison and progress in heterogeneous TAGs by providing a large benchmark dataset, protocols, and baseline/ablation analyses for node classification across four modeling paradigms."}}
{"id": "2508.15457", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15457", "abs": "https://arxiv.org/abs/2508.15457", "authors": ["Zongqi He", "Hanmin Li", "Kin-Chung Chan", "Yushen Zuo", "Hao Xie", "Zhe Xiao", "Jun Xiao", "Kin-Man Lam"], "title": "Enhancing Novel View Synthesis from extremely sparse views with SfM-free 3D Gaussian Splatting Framework", "comment": "13 pages, 4 figures", "summary": "3D Gaussian Splatting (3DGS) has demonstrated remarkable real-time\nperformance in novel view synthesis, yet its effectiveness relies heavily on\ndense multi-view inputs with precisely known camera poses, which are rarely\navailable in real-world scenarios. When input views become extremely sparse,\nthe Structure-from-Motion (SfM) method that 3DGS depends on for initialization\nfails to accurately reconstruct the 3D geometric structures of scenes,\nresulting in degraded rendering quality. In this paper, we propose a novel\nSfM-free 3DGS-based method that jointly estimates camera poses and reconstructs\n3D scenes from extremely sparse-view inputs. Specifically, instead of SfM, we\npropose a dense stereo module to progressively estimates camera pose\ninformation and reconstructs a global dense point cloud for initialization. To\naddress the inherent problem of information scarcity in extremely sparse-view\nsettings, we propose a coherent view interpolation module that interpolates\ncamera poses based on training view pairs and generates viewpoint-consistent\ncontent as additional supervision signals for training. Furthermore, we\nintroduce multi-scale Laplacian consistent regularization and adaptive\nspatial-aware multi-scale geometry regularization to enhance the quality of\ngeometrical structures and rendered content. Experiments show that our method\nsignificantly outperforms other state-of-the-art 3DGS-based approaches,\nachieving a remarkable 2.75dB improvement in PSNR under extremely sparse-view\nconditions (using only 2 training views). The images synthesized by our method\nexhibit minimal distortion while preserving rich high-frequency details,\nresulting in superior visual quality compared to existing techniques.", "AI": {"tldr": "An SfM-free 3D Gaussian Splatting framework for extremely sparse views that jointly estimates camera poses and reconstructs 3D scenes, using a dense stereo module for initialization, a coherent view interpolation module for supervision, and multi-scale regularization to boost geometry and rendering quality, achieving state-of-the-art results with as few as two training views.", "motivation": "3D Gaussian Splatting (3DGS) typically needs dense multi-view inputs with accurate camera poses; when views are extremely sparse, SfM-based initialization fails, leading to poor geometry and rendering. There is a need for an SfM-free approach that can operate under extreme sparsity.", "method": "Introduce a dense stereo module to progressively estimate camera poses and build a global dense point cloud for initialization. Employ a coherent view interpolation module to generate viewpoint-consistent supervision signals from training view pairs. Apply multi-scale Laplacian consistent regularization and adaptive spatial-aware multi-scale geometry regularization to improve geometric fidelity and render quality.", "result": "The method significantly outperforms state-of-the-art 3DGS-based approaches under extremely sparse views, achieving a 2.75dB PSNR improvement using only 2 training views, with minimal distortion and preserved high-frequency details in rendered images.", "conclusion": "An SfM-free 3DGS framework can robustly handle extremely sparse-view scenarios by jointly estimating poses and reconstructing scenes, supported by coherent view supervision and strong multi-scale geometry regularization, leading to superior visual quality and quantitative performance."}}
{"id": "2508.15393", "categories": ["cs.LG", "68T05", "I.2.6; I.5.3"], "pdf": "https://arxiv.org/pdf/2508.15393", "abs": "https://arxiv.org/abs/2508.15393", "authors": ["Miha O\u017ebot", "Igor \u0160krjanc"], "title": "Federated Learning based on Self-Evolving Gaussian Clustering", "comment": "5 pages, in slovenian language, 3 figures. Published in the\n  Proceedings of the 33rd International Electrotechnical and Computer Science\n  Conference (ERK 2024), Portoroz, Slovenia, pp. 240-243. Indexed in COBISS\n  (COBISS.SI-ID 212879107). Official version available at\n  https://erk.fe.uni-lj.si/2024/papers/ozbot_federativno_ucenje.pdf", "summary": "In this study, we present an Evolving Fuzzy System within the context of\nFederated Learning, which adapts dynamically with the addition of new clusters\nand therefore does not require the number of clusters to be selected apriori.\nUnlike traditional methods, Federated Learning allows models to be trained\nlocally on clients' devices, sharing only the model parameters with a central\nserver instead of the data. Our method, implemented using PyTorch, was tested\non clustering and classification tasks. The results show that our approach\noutperforms established classification methods on several well-known UCI\ndatasets. While computationally intensive due to overlap condition\ncalculations, the proposed method demonstrates significant advantages in\ndecentralized data processing.", "AI": {"tldr": "An evolving fuzzy system integrated with federated learning that dynamically grows clusters, removing the need for a predefined cluster count and enabling decentralized clustering/classification; it outperforms several standard classifiers on UCI datasets, at the cost of higher computational overhead due to overlap calculations.", "motivation": "To enable adaptive, privacy-preserving clustering and classification in federated settings without fixing the model structure in advance, leveraging edge-local training and parameter sharing.", "method": "Proposes an evolving fuzzy system within a federated learning framework. The system adds clusters dynamically as data arrives, removing the need to predefine the number of clusters. Implemented in PyTorch and evaluated on clustering and classification tasks. Local training on clients with model parameter sharing to a central server. Overlap condition calculations contribute to computational load.", "result": "The approach outperforms established classification methods on several well-known UCI datasets, demonstrating strong performance in decentralized data settings and validating the method's effectiveness for FL-based fuzzy systems.", "conclusion": "Dynamic, evolving fuzzy systems within federated learning offer clear advantages for decentralized data processing and adaptive modeling, enabling improved classification and clustering without a priori structure, albeit with notable computational intensity due to overlap calculations."}}
{"id": "2508.15476", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15476", "abs": "https://arxiv.org/abs/2508.15476", "authors": ["Chengqi Dong", "Fenghe Tang", "Rongge Mao", "Xinpei Gao", "S. Kevin Zhou"], "title": "LGMSNet: Thinning a medical image segmentation model via dual-level multiscale fusion", "comment": "Accepted by ECAI 2025", "summary": "Medical image segmentation plays a pivotal role in disease diagnosis and\ntreatment planning, particularly in resource-constrained clinical settings\nwhere lightweight and generalizable models are urgently needed. However,\nexisting lightweight models often compromise performance for efficiency and\nrarely adopt computationally expensive attention mechanisms, severely\nrestricting their global contextual perception capabilities. Additionally,\ncurrent architectures neglect the channel redundancy issue under the same\nconvolutional kernels in medical imaging, which hinders effective feature\nextraction. To address these challenges, we propose LGMSNet, a novel\nlightweight framework based on local and global dual multiscale that achieves\nstate-of-the-art performance with minimal computational overhead. LGMSNet\nemploys heterogeneous intra-layer kernels to extract local high-frequency\ninformation while mitigating channel redundancy. In addition, the model\nintegrates sparse transformer-convolutional hybrid branches to capture\nlow-frequency global information. Extensive experiments across six public\ndatasets demonstrate LGMSNet's superiority over existing state-of-the-art\nmethods. In particular, LGMSNet maintains exceptional performance in zero-shot\ngeneralization tests on four unseen datasets, underscoring its potential for\nreal-world deployment in resource-limited medical scenarios. The whole project\ncode is in https://github.com/cq-dong/LGMSNet.", "AI": {"tldr": "LGMSNet is a lightweight, local-global dual multiscale segmentation framework that uses heterogeneous intra-layer kernels and sparse transformer-convolution branches to achieve state-of-the-art accuracy with low computational cost, including strong zero-shot generalization.", "motivation": "Resource-constrained clinical settings require efficient, accurate segmentation models. Existing lightweight models often sacrifice performance and rarely leverage attention mechanisms, while channel redundancy under identical convolutions impedes effective feature extraction.", "method": "LGMSNet introduces a local-global dual multiscale design with heterogeneous intra-layer kernels to extract local high-frequency information and mitigate channel redundancy, plus sparse transformer-convolution branches to capture global information.", "result": "Outperforms existing state-of-the-art methods on six public datasets and demonstrates strong zero-shot generalization on four unseen datasets; code is publicly available.", "conclusion": "LGMSNet shows strong potential for real-world deployment in resource-limited medical imaging and offers a viable path for combining efficiency with global context awareness."}}
{"id": "2508.15394", "categories": ["cs.LG", "cs.AI", "cs.NA", "math.NA", "47-08, 65F45, 65Y10, 68T07, 68T20"], "pdf": "https://arxiv.org/pdf/2508.15394", "abs": "https://arxiv.org/abs/2508.15394", "authors": ["Jun Choi", "Chang-Ock Lee", "Minam Moon"], "title": "Hybrid Least Squares/Gradient Descent Methods for DeepONets", "comment": null, "summary": "We propose an efficient hybrid least squares/gradient descent method to\naccelerate DeepONet training. Since the output of DeepONet can be viewed as\nlinear with respect to the last layer parameters of the branch network, these\nparameters can be optimized using a least squares (LS) solve, and the remaining\nhidden layer parameters are updated by means of gradient descent form. However,\nbuilding the LS system for all possible combinations of branch and trunk inputs\nyields a prohibitively large linear problem that is infeasible to solve\ndirectly. To address this issue, our method decomposes the large LS system into\ntwo smaller, more manageable subproblems $\\unicode{x2014}$ one for the branch\nnetwork and one for the trunk network $\\unicode{x2014}$ and solves them\nseparately. This method is generalized to a broader type of $L^2$ loss with a\nregularization term for the last layer parameters, including the case of\nunsupervised learning with physics-informed loss.", "AI": {"tldr": "A hybrid LS/gradient-descent optimization is proposed to accelerate DeepONet training by exploiting the linearity of the last-layer branch parameters, solving a least-squares (LS) subproblem for them while updating the remaining parameters via gradient descent. The LS system is split into two smaller subproblems\u2014one for the branch network and one for the trunk network\u2014making the approach scalable. The framework generalizes to broader L2 losses with regularization on the last layer and extends to physics-informed (unsupervised) losses.", "motivation": "Training DeepONet can be computationally expensive due to large LS systems when optimizing the last-layer branch parameters. There is a need for scalable optimization that preserves the benefits of LS optimization while integrating with gradient-based updates for other parameters.", "method": "Decompose the large LS system into two smaller LS problems corresponding to the branch and trunk networks and solve them separately, while keeping the remaining hidden-layer parameters updated via gradient descent. The approach is generalized to L2 loss with regularization on the last layer parameters and supports physics-informed unsupervised losses.", "result": "The method achieves computational efficiency by reducing the size of the LS problems and enables faster training of DeepONet. It remains applicable to a broader class of L2 loss formulations, including regularized and physics-informed (unsupervised) losses.", "conclusion": "A scalable hybrid optimization framework is proposed for DeepONet that leverages LS for the last-layer branch parameters and gradient-based updates for other parameters, with a decomposition into branch/trunk subproblems and applicability to regularized and physics-informed L2 losses."}}
{"id": "2508.15500", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15500", "abs": "https://arxiv.org/abs/2508.15500", "authors": ["Fulden Ece U\u011fur", "Rafael Redondo", "Albert Barreiro", "Stefan Hristov", "Roger Mar\u00ed"], "title": "MExECON: Multi-view Extended Explicit Clothed humans Optimized via Normal integration", "comment": null, "summary": "This work presents MExECON, a novel pipeline for 3D reconstruction of clothed\nhuman avatars from sparse multi-view RGB images. Building on the single-view\nmethod ECON, MExECON extends its capabilities to leverage multiple viewpoints,\nimproving geometry and body pose estimation. At the core of the pipeline is the\nproposed Joint Multi-view Body Optimization (JMBO) algorithm, which fits a\nsingle SMPL-X body model jointly across all input views, enforcing multi-view\nconsistency. The optimized body model serves as a low-frequency prior that\nguides the subsequent surface reconstruction, where geometric details are added\nvia normal map integration. MExECON integrates normal maps from both front and\nback views to accurately capture fine-grained surface details such as clothing\nfolds and hairstyles. All multi-view gains are achieved without requiring any\nnetwork re-training. Experimental results show that MExECON consistently\nimproves fidelity over the single-view baseline and achieves competitive\nperformance compared to modern few-shot 3D reconstruction methods.", "AI": {"tldr": "MExECON introduces a multi-view 3D reconstruction pipeline for clothed human avatars by jointly fitting a single SMPL-X model across views and refining with normal maps, achieving better fidelity without retraining and competitive few-shot performance.", "motivation": "Single-view methods struggle with geometry, pose accuracy, and clothing detail; leveraging multiple views can enforce multi-view consistency and provide richer surface information while avoiding extensive network retraining.", "method": "Joint Multi-view Body Optimization (JMBO) fits one SMPL-X body model across all input views to enforce cross-view consistency, uses this body as a low-frequency prior to guide surface reconstruction, and adds fine details via normal map integration from front and back views without retraining networks.", "result": "Experiments show MExECON improves fidelity over the single-view ECON baseline and is competitive with modern few-shot 3D reconstruction methods.", "conclusion": "Multi-view optimization combined with normal-map-based detail integration yields higher-quality clothed human avatars without requiring additional training, validating the approach against single-view baselines and few-shot methods."}}
{"id": "2508.15413", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15413", "abs": "https://arxiv.org/abs/2508.15413", "authors": ["Pixi Kang", "Julian Moosmann", "Mengxi Liu", "Bo Zhou", "Michele Magno", "Paul Lukowicz", "Sizhen Bian"], "title": "Bridging Generalization and Personalization in Wearable Human Activity Recognition via On-Device Few-Shot Learning", "comment": null, "summary": "Human Activity Recognition (HAR) using wearable devices has advanced\nsignificantly in recent years, yet its generalization remains limited when\nmodels are deployed to new users. This degradation in performance is primarily\ndue to user-induced concept drift (UICD), highlighting the importance of\nefficient personalization. In this paper, we present a hybrid framework that\nfirst generalizes across users and then rapidly adapts to individual users\nusing few-shot learning directly on-device. By updating only the classifier\nlayer with user-specific data, our method achieves robust personalization with\nminimal computational and memory overhead. We implement this framework on the\nenergy-efficient RISC-V-based GAP9 microcontroller and validate it across three\ndiverse HAR scenarios: RecGym, QVAR-Gesture, and Ultrasound-Gesture.\nPost-deployment adaptation yields consistent accuracy improvements of 3.73\\%,\n17.38\\%, and 3.70\\% respectively. These results confirm that fast, lightweight,\nand effective personalization is feasible on embedded platforms, paving the way\nfor scalable and user-aware HAR systems in the wild\n\\footnote{https://github.com/kangpx/onlineTiny2023}.", "AI": {"tldr": "Hybrid few-shot on-device personalization for HAR: generalizes across users and then rapidly adapts to individuals by updating only the classifier layer, implemented on GAP9, yielding notable accuracy gains across three HAR tasks.", "motivation": "Generalization across users is hampered by user-induced concept drift, necessitating efficient, low-overhead personalization on embedded devices.", "method": "A hybrid framework that first generalizes across users and then performs rapid on-device adaptation using few-shot learning by updating solely the classifier layer with user-specific data.", "result": "Post-deployment adaptation yields accuracy improvements of 3.73%, 17.38%, and 3.70% on RecGym, QVAR-Gesture, and Ultrasound-Gesture respectively, confirming fast, lightweight personalization on embedded platforms.", "conclusion": "Fast, lightweight, and effective personalization for HAR is feasible on embedded systems, enabling scalable, user-aware HAR in real-world settings."}}
{"id": "2508.15505", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15505", "abs": "https://arxiv.org/abs/2508.15505", "authors": ["Mengyu Wang", "Zhenyu Liu", "Kun Li", "Yu Wang", "Yuwei Wang", "Yanyan Wei", "Fei Wang"], "title": "Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion", "comment": "Accepted by IEEE Transactions on Multimedia", "summary": "Multimodal Image Fusion (MMIF) aims to integrate complementary information\nfrom different imaging modalities to overcome the limitations of individual\nsensors. It enhances image quality and facilitates downstream applications such\nas remote sensing, medical diagnostics, and robotics. Despite significant\nadvancements, current MMIF methods still face challenges such as modality\nmisalignment, high-frequency detail destruction, and task-specific limitations.\nTo address these challenges, we propose AdaSFFuse, a novel framework for\ntask-generalized MMIF through adaptive cross-domain co-fusion learning.\nAdaSFFuse introduces two key innovations: the Adaptive Approximate Wavelet\nTransform (AdaWAT) for frequency decoupling, and the Spatial-Frequency Mamba\nBlocks for efficient multimodal fusion. AdaWAT adaptively separates the high-\nand low-frequency components of multimodal images from different scenes,\nenabling fine-grained extraction and alignment of distinct frequency\ncharacteristics for each modality. The Spatial-Frequency Mamba Blocks\nfacilitate cross-domain fusion in both spatial and frequency domains, enhancing\nthis process. These blocks dynamically adjust through learnable mappings to\nensure robust fusion across diverse modalities. By combining these components,\nAdaSFFuse improves the alignment and integration of multimodal features,\nreduces frequency loss, and preserves critical details. Extensive experiments\non four MMIF tasks -- Infrared-Visible Image Fusion (IVF), Multi-Focus Image\nFusion (MFF), Multi-Exposure Image Fusion (MEF), and Medical Image Fusion (MIF)\n-- demonstrate AdaSFFuse's superior fusion performance, ensuring both low\ncomputational cost and a compact network, offering a strong balance between\nperformance and efficiency. The code will be publicly available at\nhttps://github.com/Zhen-yu-Liu/AdaSFFuse.", "AI": {"tldr": "AdaSFFuse is a task-general multimodal image fusion framework that uses adaptive wavelet-based frequency decoupling (AdaWAT) and Spatial-Frequency Mamba Blocks to robustly fuse diverse modalities across spatial and frequency domains, achieving superior results with low computation on IVF, MFF, MEF, and MIF.", "motivation": "Current MMIF approaches suffer from modality misalignment, loss of high-frequency details, and task-specific limitations, motivating a general, efficient fusion framework that can adapt across domains and modalities.", "method": "AdaSFFuse introduces Adaptive Approximate Wavelet Transform (AdaWAT) to adaptively decouple frequency components per modality and scene, plus Spatial-Frequency Mamba Blocks that fuse features across spatial and frequency domains using learnable mappings for robust cross-domain fusion.", "result": "Extensive experiments on four MMIF tasks (IVF, MFF, MEF, MIF) show superior fusion performance with low computational cost and a compact network, validating robustness and efficiency.", "conclusion": "AdaSFFuse achieves improved alignment and integration of multimodal features, mitigates frequency loss, and preserves detail across diverse MMIF tasks, offering a strong performance\u2013efficiency balance and generalizability, with code to be released."}}
{"id": "2508.15444", "categories": ["cs.LG", "68T05, 62H30, 62H20", "I.2.6; I.5.3"], "pdf": "https://arxiv.org/pdf/2508.15444", "abs": "https://arxiv.org/abs/2508.15444", "authors": ["Miha O\u017ebot", "Igor \u0160krjanc"], "title": "Measures of Overlapping Multivariate Gaussian Clusters in Unsupervised Online Learning", "comment": "5 pages, in Slovenian language. 2 figures. Accepted for the 33rd\n  International Electrotechnical and Computer Science Conference ERK 2024\n  (Portoroz, Slovenia, 26-27 Sep 2024). Conference PDF:\n  https://erk.fe.uni-lj.si/2024/papers/ozbot(mere_prekrivanja).pdf", "summary": "In this paper, we propose a new measure for detecting overlap in multivariate\nGaussian clusters. The aim of online learning from data streams is to create\nclustering, classification, or regression models that can adapt over time based\non the conceptual drift of streaming data. In the case of clustering, this can\nresult in a large number of clusters that may overlap and should be merged.\nCommonly used distribution dissimilarity measures are not adequate for\ndetermining overlapping clusters in the context of online learning from\nstreaming data due to their inability to account for all shapes of clusters and\ntheir high computational demands. Our proposed dissimilarity measure is\nspecifically designed to detect overlap rather than dissimilarity and can be\ncomputed faster compared to existing measures. Our method is several times\nfaster than compared methods and is capable of detecting overlapping clusters\nwhile avoiding the merging of orthogonal clusters.", "AI": {"tldr": "A fast, overlap-focused dissimilarity measure for multivariate Gaussian clusters in online streaming, enabling efficient merging of overlapping clusters while avoiding merging orthogonal ones.", "motivation": "Online learning from data streams requires adaptive clustering as concepts drift; in clustering, many clusters may overlap and should be merged. Traditional distribution dissimilarity measures fail to capture all cluster shapes and are computationally expensive, hindering real-time updating.", "method": "Introduce a new dissimilarity measure designed specifically to detect overlap (not general dissimilarity) between multivariate Gaussian clusters; optimized for speed to suit streaming data; ensures overlapping clusters are detected and orthogonal clusters are not merged.", "result": "The proposed measure is several times faster than existing methods and successfully detects overlapping clusters while avoiding undesirable merges of orthogonal clusters.", "conclusion": "The overlap-detection measure improves online clustering for streaming data by providing a fast, shape-aware criterion that supports effective model adaptation with lower computational costs."}}
{"id": "2508.15529", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15529", "abs": "https://arxiv.org/abs/2508.15529", "authors": ["Kaiyuan Tan", "Yingying Shen", "Haohui Zhu", "Zhiwei Zhan", "Shan Zhao", "Mingfei Tu", "Hongcheng Luo", "Haiyang Sun", "Bing Wang", "Guang Chen", "Hangjun Ye"], "title": "ExtraGS: Geometric-Aware Trajectory Extrapolation with Uncertainty-Guided Generative Priors", "comment": null, "summary": "Synthesizing extrapolated views from recorded driving logs is critical for\nsimulating driving scenes for autonomous driving vehicles, yet it remains a\nchallenging task. Recent methods leverage generative priors as pseudo ground\ntruth, but often lead to poor geometric consistency and over-smoothed\nrenderings. To address these limitations, we propose ExtraGS, a holistic\nframework for trajectory extrapolation that integrates both geometric and\ngenerative priors. At the core of ExtraGS is a novel Road Surface Gaussian(RSG)\nrepresentation based on a hybrid Gaussian-Signed Distance Function (SDF)\ndesign, and Far Field Gaussians (FFG) that use learnable scaling factors to\nefficiently handle distant objects. Furthermore, we develop a self-supervised\nuncertainty estimation framework based on spherical harmonics that enables\nselective integration of generative priors only where extrapolation artifacts\noccur. Extensive experiments on multiple datasets, diverse multi-camera setups,\nand various generative priors demonstrate that ExtraGS significantly enhances\nthe realism and geometric consistency of extrapolated views, while preserving\nhigh fidelity along the original trajectory.", "AI": {"tldr": "ExtraGS introduces a holistic extrapolation framework that fuses geometric priors with generative priors for extrapolated driving views. It uses Road Surface Gaussian (RSG) built on a hybrid Gaussian-SDF representation and Far Field Gaussians (FFG) with learnable scaling, plus self-supervised uncertainty via spherical harmonics to selectively apply priors. Demonstrates improved realism and geometric consistency across datasets and setups while preserving fidelity on the original trajectory.", "motivation": "Current extrapolated driving view methods rely on generative priors, which can produce geometrically inconsistent and over-smoothed results. There is a need to consistently integrate geometric cues with generative priors to synthesize realistic, artifact-free extrapolated views.", "method": "Introduce Road Surface Gaussian (RSG) using a hybrid Gaussian-SDF representation to model road surfaces; implement Far Field Gaussians (FFG) with learnable scaling to efficiently handle distant objects; develop a self-supervised uncertainty estimation framework based on spherical harmonics to identify extrapolation artifacts and selectively fuse generative priors only where needed.", "result": "Extensive experiments across multiple datasets and multi-camera configurations show that ExtraGS improves realism and geometric consistency of extrapolated views and preserves high fidelity along the original trajectory when using diverse generative priors.", "conclusion": "ExtraGS demonstrates that integrating geometric priors, a novel RSG/FFG representation, and uncertainty-guided selective use of generative priors yields more realistic and geometrically coherent extrapolated driving views without sacrificing fidelity on the original path."}}
{"id": "2508.15449", "categories": ["cs.LG", "cs.AI", "68T07", "I.2.6"], "pdf": "https://arxiv.org/pdf/2508.15449", "abs": "https://arxiv.org/abs/2508.15449", "authors": ["Chengcan Wu", "Zeming Wei", "Huanran Chen", "Yinpeng Dong", "Meng Sun"], "title": "Reliable Unlearning Harmful Information in LLMs with Metamorphosis Representation Projection", "comment": "10 pages, 9 figures, Under review as a full paper at AAAI 2026. A\n  preliminary version is under review at the NeurIPS 2025 Workshop on Reliable\n  ML from Unreliable Data", "summary": "While Large Language Models (LLMs) have demonstrated impressive performance\nin various domains and tasks, concerns about their safety are becoming\nincreasingly severe. In particular, since models may store unsafe knowledge\ninternally, machine unlearning has emerged as a representative paradigm to\nensure model safety. Existing approaches employ various training techniques,\nsuch as gradient ascent and negative preference optimization, in attempts to\neliminate the influence of undesired data on target models. However, these\nmethods merely suppress the activation of undesired data through parametric\ntraining without completely eradicating its informational traces within the\nmodel. This fundamental limitation makes it difficult to achieve effective\ncontinuous unlearning, rendering these methods vulnerable to relearning\nattacks. To overcome these challenges, we propose a Metamorphosis\nRepresentation Projection (MRP) approach that pioneers the application of\nirreversible projection properties to machine unlearning. By implementing\nprojective transformations in the hidden state space of specific network\nlayers, our method effectively eliminates harmful information while preserving\nuseful knowledge. Experimental results demonstrate that our approach enables\neffective continuous unlearning and successfully defends against relearning\nattacks, achieving state-of-the-art performance in unlearning effectiveness\nwhile preserving natural performance. Our code is available in\nhttps://github.com/ChengcanWu/MRP.", "AI": {"tldr": "A new unlearning approach (MRP) uses irreversible projections in hidden layers to erase harmful knowledge in LLMs, enabling continuous unlearning and resistance to relearning, with state-of-the-art unlearning and preserved performance; code released.", "motivation": "Safety concerns: LLMs can store unsafe knowledge; existing retraining methods suppress signals but do not erase traces, enabling relearning; need genuine unlearning.", "method": "Metamorphosis Representation Projection (MRP) implements irreversible projective transformations in selected network layers' hidden state space to remove harmful information while preserving useful knowledge, enabling continuous unlearning and defense against relearning.", "result": "Experiments show effective continuous unlearning and defense against relearning, achieving state-of-the-art unlearning effectiveness with minimal loss in natural performance.", "conclusion": "MRP provides a novel, effective approach to machine unlearning via irreversible projections; code available."}}
{"id": "2508.15535", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15535", "abs": "https://arxiv.org/abs/2508.15535", "authors": ["Guotao Liang", "Juncheng Hu", "Ximing Xing", "Jing Zhang", "Qian Yu"], "title": "Multi-Object Sketch Animation with Grouping and Motion Trajectory Priors", "comment": "Accepted by ACM MM 2025", "summary": "We introduce GroupSketch, a novel method for vector sketch animation that\neffectively handles multi-object interactions and complex motions. Existing\napproaches struggle with these scenarios, either being limited to single-object\ncases or suffering from temporal inconsistency and poor generalization. To\naddress these limitations, our method adopts a two-stage pipeline comprising\nMotion Initialization and Motion Refinement. In the first stage, the input\nsketch is interactively divided into semantic groups and key frames are\ndefined, enabling the generation of a coarse animation via interpolation. In\nthe second stage, we propose a Group-based Displacement Network (GDN), which\nrefines the coarse animation by predicting group-specific displacement fields,\nleveraging priors from a text-to-video model. GDN further incorporates\nspecialized modules, such as Context-conditioned Feature Enhancement (CCFE), to\nimprove temporal consistency. Extensive experiments demonstrate that our\napproach significantly outperforms existing methods in generating high-quality,\ntemporally consistent animations for complex, multi-object sketches, thus\nexpanding the practical applications of sketch animation.", "AI": {"tldr": "A two-stage GroupSketch framework using interactive grouping and a Group-based Displacement Network to animate multi-object sketches with improved temporal consistency.", "motivation": "Existing sketch animation approaches are limited to single-object scenarios or suffer from temporal instability and poor generalization when handling multiple interacting objects.", "method": "Two-stage pipeline: Stage 1 Motion Initialization \u2014 interactive division of input into semantic groups and keyframe-based interpolation to generate a coarse animation. Stage 2 Motion Refinement \u2014 Group-based Displacement Network (GDN) predicts group-specific displacement fields to refine the coarse animation, enhanced by Context-conditioned Feature Enhancement (CCFE) and leveraging priors from a text-to-video model to improve temporal consistency.", "result": "Experimental results show substantial improvements over baselines in producing high-quality, temporally consistent animations for complex, multi-object sketches, validating the effectiveness and generalization of the approach.", "conclusion": "GroupSketch broadens practical applications of vector sketch animation by robustly handling multi-object interactions and complex motion, thanks to the two-stage design and GDN with CCFE."}}
{"id": "2508.15451", "categories": ["cs.LG", "cs.AI", "cs.ET", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2508.15451", "abs": "https://arxiv.org/abs/2508.15451", "authors": ["H. I. Nurdin", "C. A. Nijhuis"], "title": "A Solvable Molecular Switch Model for Stable Temporal Information Processing", "comment": "21 pages, 6 figures, submitted for publication. Comments are welcome", "summary": "This paper studies an input-driven one-state differential equation model\ninitially developed for an experimentally demonstrated dynamic molecular switch\nthat switches like synapses in the brain do. The linear-in-the-state and\nnonlinear-in-the-input model is exactly solvable, and it is shown that it also\npossesses mathematical properties of convergence and fading memory that enable\nstable processing of time-varying inputs by nonlinear dynamical systems. Thus,\nthe model exhibits the co-existence of biologically-inspired behavior and\ndesirable mathematical properties for stable learning on sequential data. The\nresults give theoretical support for the use of the dynamic molecular switches\nas computational units in deep cascaded/layered feedforward and recurrent\narchitectures as well as other more general structures for neuromorphic\ncomputing. They could also inspire more general exactly solvable models that\ncan be fitted to emulate arbitrary physical devices which can mimic\nbrain-inspired behaviour and perform stable computation on input signals.", "AI": {"tldr": "An input-driven, exactly solvable one-state differential equation model shows convergent fading-memory dynamics, enabling stable, brain-inspired computation for neuromorphic architectures.", "motivation": "Provide a mathematically tractable model with biologically-inspired switching behavior to enable stable learning on sequential data and to justify using such switches as computational units in deep and recurrent networks.", "method": "A linear-in-state, nonlinear-in-input differential equation is analyzed; it is exactly solvable, and its dynamical properties (convergence and fading memory) are studied to assess its suitability for processing time-varying inputs.", "result": "The model exhibits convergence and fading memory, supporting stable processing of time-varying inputs; it coexists with biologically-inspired switching behavior and mathematical properties that make it suitable for stable learning in layered and recurrent architectures; it could be fitted to emulate physical devices mimicking brain-like behavior.", "conclusion": "The work provides theoretical support for using dynamic molecular switches as computational units in neuromorphic computing and suggests avenues for exact-solvable models that can emulate physical devices performing stable brain-inspired computation."}}
{"id": "2508.15537", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15537", "abs": "https://arxiv.org/abs/2508.15537", "authors": ["Chang Liu", "Yang Xu", "Tamas Sziranyi"], "title": "D3FNet: A Differential Attention Fusion Network for Fine-Grained Road Structure Extraction in Remote Perception Systems", "comment": "10 pages, 6 figures, International Conference on Computer Vision,\n  ICCV 2025 (DriveX) paper id 5", "summary": "Extracting narrow roads from high-resolution remote sensing imagery remains a\nsignificant challenge due to their limited width, fragmented topology, and\nfrequent occlusions. To address these issues, we propose D3FNet, a Dilated\nDual-Stream Differential Attention Fusion Network designed for fine-grained\nroad structure segmentation in remote perception systems. Built upon the\nencoder-decoder backbone of D-LinkNet, D3FNet introduces three key\ninnovations:(1) a Differential Attention Dilation Extraction (DADE) module that\nenhances subtle road features while suppressing background noise at the\nbottleneck; (2) a Dual-stream Decoding Fusion Mechanism (DDFM) that integrates\noriginal and attention-modulated features to balance spatial precision with\nsemantic context; and (3) a multi-scale dilation strategy (rates 1, 3, 5, 9)\nthat mitigates gridding artifacts and improves continuity in narrow road\nprediction. Unlike conventional models that overfit to generic road widths,\nD3FNet specifically targets fine-grained, occluded, and low-contrast road\nsegments. Extensive experiments on the DeepGlobe and CHN6-CUG benchmarks show\nthat D3FNet achieves superior IoU and recall on challenging road regions,\noutperforming state-of-the-art baselines. Ablation studies further verify the\ncomplementary synergy of attention-guided encoding and dual-path decoding.\nThese results confirm D3FNet as a robust solution for fine-grained narrow road\nextraction in complex remote and cooperative perception scenarios.", "AI": {"tldr": "D3FNet presents a dilated, dual-stream attention-based network for fine-grained, narrow road segmentation, achieving state-of-the-art IoU and recall on challenging benchmarks by integrating differential attention dilation, dual-path decoding, and multi-scale dilations.", "motivation": "Narrow, occluded, and low-contrast roads pose significant segmentation challenges in high-resolution remote sensing, requiring fine-grained feature discrimination and robust connectivity, beyond traditional road segmentation models.", "method": "Introduces three core innovations built on D-LinkNet: (1) Differential Attention Dilation Extraction (DADE) at the bottleneck to enhance subtle road signals while suppressing background; (2) Dual-stream Decoding Fusion Mechanism (DDFM) that fuses original and attention-modulated features for precise spatial detail and strong semantic context; (3) a multi-scale dilation scheme with rates 1, 3, 5, 9 to reduce gridding artifacts and improve continuity of narrow roads.", "result": "On DeepGlobe and CHN6-CUG benchmarks, D3FNet achieves superior IoU and recall on challenging road regions, outperforming state-of-the-art baselines; ablation studies confirm the complementary effects of attention-guided encoding and dual-path decoding.", "conclusion": "D3FNet provides a robust solution for fine-grained, narrow road extraction in complex remote sensing and cooperative perception contexts, effectively handling occlusions, low contrast, and fragmented road topology."}}
{"id": "2508.15454", "categories": ["cs.LG", "cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2508.15454", "abs": "https://arxiv.org/abs/2508.15454", "authors": ["Saar Tzour-Shaday", "Dana Drachsler Cohen"], "title": "Mini-Batch Robustness Verification of Deep Neural Networks", "comment": "30 pages, 12 figures, conference OOPSLA 2025", "summary": "Neural network image classifiers are ubiquitous in many safety-critical\napplications. However, they are susceptible to adversarial attacks. To\nunderstand their robustness to attacks, many local robustness verifiers have\nbeen proposed to analyze $\\epsilon$-balls of inputs. Yet, existing verifiers\nintroduce a long analysis time or lose too much precision, making them less\neffective for a large set of inputs. In this work, we propose a new approach to\nlocal robustness: group local robustness verification. The key idea is to\nleverage the similarity of the network computations of certain $\\epsilon$-balls\nto reduce the overall analysis time. We propose BaVerLy, a sound and complete\nverifier that boosts the local robustness verification of a set of\n$\\epsilon$-balls by dynamically constructing and verifying mini-batches.\nBaVerLy adaptively identifies successful mini-batch sizes, accordingly\nconstructs mini-batches of $\\epsilon$-balls that have similar network\ncomputations, and verifies them jointly. If a mini-batch is verified, all\n$\\epsilon$-balls are proven robust. Otherwise, one $\\epsilon$-ball is suspected\nas not being robust, guiding the refinement. In the latter case, BaVerLy\nleverages the analysis results to expedite the analysis of that $\\epsilon$-ball\nas well as the other $\\epsilon$-balls in the batch. We evaluate BaVerLy on\nfully connected and convolutional networks for MNIST and CIFAR-10. Results show\nthat BaVerLy scales the common one by one verification by 2.3x on average and\nup to 4.1x, in which case it reduces the total analysis time from 24 hours to 6\nhours.", "AI": {"tldr": "BaVerLy introduces group-local robustness verification by batching epsilon-ball inputs that share similar network computations. It is sound and complete, and speeds up local robustness analysis by adaptively forming mini-batches; achieves significant speedups (avg 2.3x, up to 4.1x) reducing analysis time from 24h to 6h on MNIST/CIFAR-10 networks.", "motivation": "Existing local robustness verifiers for epsilon-balls are either slow or lose precision, limiting scalability to large input sets. There is a need to leverage redundancies in network computations across nearby inputs to accelerate verification.", "method": "BaVerLy adaptively constructs mini-batches of epsilon-balls with similar network computations and verifies them jointly. If a mini-batch passes, all epsilon-balls are robust. If not, one or more epsilon-balls are suspected and refined; results from the batch guide faster verification of the suspect and others. The verifier is designed to be sound and complete, and evaluated on fully connected and convolutional networks for MNIST and CIFAR-10.", "result": "Empirical evaluation shows a 2.3x average speedup over one-by-one verification, with up to 4.1x improvement. Total analysis time reduced from 24 hours to 6 hours in the reported experiments.", "conclusion": "Grouping epsilon-balls into adaptively sized, similarity-based mini-batches is an effective strategy to accelerate local robustness verification without sacrificing correctness, making scalable robustness analysis feasible for standard datasets and architectures."}}
{"id": "2508.15568", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15568", "abs": "https://arxiv.org/abs/2508.15568", "authors": ["Youjia Zhang", "Youngeun Kim", "Young-Geun Choi", "Hongyeob Kim", "Huiling Liu", "Sungeun Hong"], "title": "Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment", "comment": null, "summary": "Test-time adaptation (TTA) enhances the zero-shot robustness under\ndistribution shifts by leveraging unlabeled test data during inference. Despite\nnotable advances, several challenges still limit its broader applicability.\nFirst, most methods rely on backpropagation or iterative optimization, which\nlimits scalability and hinders real-time deployment. Second, they lack explicit\nmodeling of class-conditional feature distributions. This modeling is crucial\nfor producing reliable decision boundaries and calibrated predictions, but it\nremains underexplored due to the lack of both source data and supervision at\ntest time. In this paper, we propose ADAPT, an Advanced Distribution-Aware and\nbackPropagation-free Test-time adaptation method. We reframe TTA as a Gaussian\nprobabilistic inference task by modeling class-conditional likelihoods using\ngradually updated class means and a shared covariance matrix. This enables\nclosed-form, training-free inference. To correct potential likelihood bias, we\nintroduce lightweight regularization guided by CLIP priors and a historical\nknowledge bank. ADAPT requires no source data, no gradient updates, and no full\naccess to target data, supporting both online and transductive settings.\nExtensive experiments across diverse benchmarks demonstrate that our method\nachieves state-of-the-art performance under a wide range of distribution shifts\nwith superior scalability and robustness.", "AI": {"tldr": "ADAPT is a backpropagation-free test-time adaptation method that models class-conditional Gaussian likelihoods with gradually updated class means and a shared covariance, enabling closed-form inference without source data or gradient updates, guided by CLIP priors and a historical knowledge bank; reports state-of-the-art results and scalable robustness across distribution shifts.", "motivation": "Current TTA approaches largely rely on backpropagation or iterative optimization, which hurts scalability and real-time deployment. There is a shortage of explicit modeling of class-conditional feature distributions, which is essential for calibrated predictions, especially when source data and test-time supervision are unavailable.", "method": "Formulate TTA as Gaussian probabilistic inference by representing class-conditional likelihoods with means updated over time and a shared covariance. This yields closed-form, training-free inference. Regularize to mitigate likelihood bias using CLIP-based priors and a historical knowledge bank. No source data, no gradient updates, and no full access to target data; suitable for online and transductive settings.", "result": "Extensive experiments across diverse benchmarks indicate state-of-the-art performance under distribution shifts, with improved scalability and robustness.", "conclusion": "ADAPT delivers a scalable, backprop-free TTA framework that leverages Gaussian probabilistic modeling and external priors to produce calibrated, reliable predictions without source data, enabling effective deployment in real-time and restricted-access scenarios."}}
{"id": "2508.15480", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15480", "abs": "https://arxiv.org/abs/2508.15480", "authors": ["Jianhui Wang", "Wenyu Zhu", "Bowen Gao", "Xin Hong", "Ya-Qin Zhang", "Wei-Ying Ma", "Yanyan Lan"], "title": "Learning Protein-Ligand Binding in Hyperbolic Space", "comment": null, "summary": "Protein-ligand binding prediction is central to virtual screening and\naffinity ranking, two fundamental tasks in drug discovery. While recent\nretrieval-based methods embed ligands and protein pockets into Euclidean space\nfor similarity-based search, the geometry of Euclidean embeddings often fails\nto capture the hierarchical structure and fine-grained affinity variations\nintrinsic to molecular interactions. In this work, we propose HypSeek, a\nhyperbolic representation learning framework that embeds ligands, protein\npockets, and sequences into Lorentz-model hyperbolic space. By leveraging the\nexponential geometry and negative curvature of hyperbolic space, HypSeek\nenables expressive, affinity-sensitive embeddings that can effectively model\nboth global activity and subtle functional differences-particularly in\nchallenging cases such as activity cliffs, where structurally similar ligands\nexhibit large affinity gaps. Our mode unifies virtual screening and affinity\nranking in a single framework, introducing a protein-guided three-tower\narchitecture to enhance representational structure. HypSeek improves early\nenrichment in virtual screening on DUD-E from 42.63 to 51.44 (+20.7%) and\naffinity ranking correlation on JACS from 0.5774 to 0.7239 (+25.4%),\ndemonstrating the benefits of hyperbolic geometry across both tasks and\nhighlighting its potential as a powerful inductive bias for protein-ligand\nmodeling.", "AI": {"tldr": "HypSeek uses Lorentz-model hyperbolic embeddings to jointly model ligands, pockets, and sequences for protein-ligand tasks, yielding better early enrichment and affinity ranking, especially for activity cliffs.", "motivation": "Euclidean embeddings struggle to capture hierarchical relationships and subtle affinity variations in protein-ligand interactions; hyperbolic space offers negative curvature and exponential geometry to encode hierarchy and fine-grained differences.", "method": "A hyperbolic representation learning framework, HypSeek, embedding ligands, protein pockets, and sequences into Lorentz-model hyperbolic space, with a protein-guided three-tower architecture to unify virtual screening and affinity ranking; leverages hyperbolic geometry to produce affinity-sensitive embeddings.", "result": "On DUD-E, early enrichment improves from 42.63 to 51.44 (+20.7%). On JACS, affinity ranking correlation improves from 0.5774 to 0.7239 (+25.4%).", "conclusion": "Hyperbolic geometry provides a powerful inductive bias for protein-ligand modeling, effectively capturing hierarchical and subtle affinity variations and enabling unified tasks in a single framework."}}
{"id": "2508.15582", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15582", "abs": "https://arxiv.org/abs/2508.15582", "authors": ["Sumit Kumar Dam", "Mrityunjoy Gain", "Eui-Nam Huh", "Choong Seon Hong"], "title": "High-Frequency First: A Two-Stage Approach for Improving Image INR", "comment": "Paper on INR; 4 figures, 8 pages", "summary": "Implicit Neural Representations (INRs) have emerged as a powerful alternative\nto traditional pixel-based formats by modeling images as continuous functions\nover spatial coordinates. A key challenge, however, lies in the spectral bias\nof neural networks, which tend to favor low-frequency components while\nstruggling to capture high-frequency (HF) details such as sharp edges and fine\ntextures. While prior approaches have addressed this limitation through\narchitectural modifications or specialized activation functions, we propose an\northogonal direction by directly guiding the training process. Specifically, we\nintroduce a two-stage training strategy where a neighbor-aware soft mask\nadaptively assigns higher weights to pixels with strong local variations,\nencouraging early focus on fine details. The model then transitions to\nfull-image training. Experimental results show that our approach consistently\nimproves reconstruction quality and complements existing INR methods. As a\npioneering attempt to assign frequency-aware importance to pixels in image INR,\nour work offers a new avenue for mitigating the spectral bias problem.", "AI": {"tldr": "A two-stage training strategy for implicit neural representations that uses a neighbor-aware soft mask to overweight high-frequency, locally varying pixels, encouraging early focus on fine details and improving reconstruction quality while complementing existing INR methods.", "motivation": "Neural networks exhibit a spectral bias that favors low-frequency components, hindering high-frequency detail capture in implicit neural representations (INRs). Prior fixes focused on architecture or activations; this work seeks to steer training to emphasize high-frequency content.", "method": "Train INRs in two stages: (1) apply a neighbor-aware soft mask that assigns higher weights to pixels with strong local variation to promote early focus on fine details, and (2) switch to full-image training to finalize optimization. The mask adaptively weights pixels during training.", "result": "Empirical results show consistent improvements in reconstruction quality and indicate the approach complements existing INR methods. It is a pioneering attempt to incorporate frequency-aware pixel importance into image INR.", "conclusion": "Training-time pixel weighting offers a new avenue to mitigate spectral bias in INRs, suggesting broader applicability for improving high-frequency content capture in implicit representations."}}
{"id": "2508.15499", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15499", "abs": "https://arxiv.org/abs/2508.15499", "authors": ["Jiahua Lu", "Huaxiao Liu", "Shuotong Bai", "Junjie Xu", "Renqiang Luo", "Enyan Dai"], "title": "Let's Grow an Unbiased Community: Guiding the Fairness of Graphs via New Links", "comment": null, "summary": "Graph Neural Networks (GNNs) have achieved remarkable success across diverse\napplications. However, due to the biases in the graph structures, graph neural\nnetworks face significant challenges in fairness. Although the original user\ngraph structure is generally biased, it is promising to guide these existing\nstructures toward unbiased ones by introducing new links. The fairness guidance\nvia new links could foster unbiased communities, thereby enhancing fairness in\ndownstream applications. To address this issue, we propose a novel framework\nnamed FairGuide. Specifically, to ensure fairness in downstream tasks trained\non fairness-guided graphs, we introduce a differentiable community detection\ntask as a pseudo downstream task. Our theoretical analysis further demonstrates\nthat optimizing fairness within this pseudo task effectively enhances\nstructural fairness, promoting fairness generalization across diverse\ndownstream applications. Moreover, FairGuide employs an effective strategy\nwhich leverages meta-gradients derived from the fairness-guidance objective to\nidentify new links that significantly enhance structural fairness. Extensive\nexperimental results demonstrate the effectiveness and generalizability of our\nproposed method across a variety of graph-based fairness tasks.", "AI": {"tldr": "FairGuide proposes a fairness-guided graph augmentation framework that adds links to graphs to improve structural fairness for downstream tasks, guided by a differentiable pseudo-task of community detection and meta-gradients to select links.", "motivation": "Graph data biases cause unfair outcomes; enabling guided augmentation to steer the structure toward fairness can improve downstream fairness and generalization.", "method": "Introduce a differentiable community detection pseudo-task; use meta-gradients from the fairness objective to identify new links; provide theoretical analysis showing fairness generalization; apply meta-learning for link suggestions; experiment across graph-based fairness tasks.", "result": "Empirical results demonstrate effectiveness and generalizability across multiple fairness tasks on graphs.", "conclusion": "FairGuide effectively enhances structural fairness and fairness generalization by learning to add links via meta-gradient-guided optimization on a differentiable pseudo-task."}}
{"id": "2508.15613", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15613", "abs": "https://arxiv.org/abs/2508.15613", "authors": ["Ivo Ivanov", "Carsten Markgraf"], "title": "Fast globally optimal Truncated Least Squares point cloud registration with fixed rotation axis", "comment": null, "summary": "Recent results showed that point cloud registration with given\ncorrespondences can be made robust to outlier rates of up to 95\\% using the\ntruncated least squares (TLS) formulation. However, solving this combinatorial\noptimization problem to global optimality is challenging. Provably globally\noptimal approaches using semidefinite programming (SDP) relaxations take\nhundreds of seconds for 100 points. In this paper, we propose a novel linear\ntime convex relaxation as well as a contractor method to speed up Branch and\nBound (BnB). Our solver can register two 3D point clouds with 100 points to\nprovable global optimality in less than half a second when the axis of rotation\nis provided. Although it currently cannot solve the full 6DoF problem, it is\ntwo orders of magnitude faster than the state-of-the-art SDP solver STRIDE when\nsolving the rotation-only TLS problem. In addition to providing a formal proof\nfor global optimality, we present empirical evidence of global optimality using\nadversarial instances with local minimas close to the global minimum.", "AI": {"tldr": "A fast linear-time convex relaxation and a contractor accelerate provably global TLS-based point-cloud registration with outliers, achieving global optimality for 2x3D registration (rotation given) in under 0.5s and greatly exceeding SDP-based methods; full 6DoF remains open.", "motivation": "Global optimality in truncated least squares (TLS) for point-cloud registration with high outlier rates is computationally expensive with semidefinite programming (SDP). There is a need for faster, provably optimal approaches that scale to practical problem sizes.", "method": "Introduce a linear-time convex relaxation and a contractor method to accelerate Branch-and-Bound (BnB). When the rotation axis is provided, the method regresses two 3D point clouds with 100 points to provable global optimality in under 0.5 seconds; benchmarked against the SDP solver STRIDE for the rotation-only TLS problem. The work also provides a formal proof of global optimality and empirical adversarial tests.", "result": "Registration of 100 points with a known rotation axis reaches provable global optimality in under 0.5s. The approach is ~100\u00d7 faster than STRIDE for rotation-only TLS and offers a formal global-optimality guarantee. It demonstrates empirical evidence of global optimality via adversarial instances with near-global minima.", "conclusion": "The paper delivers a fast, provably globally optimal approach for rotation-only TLS point-cloud registration, significantly accelerating over SDP-based methods; full 6DoF remains unresolved, but the method shows strong potential and theoretical validation."}}
{"id": "2508.15509", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2508.15509", "abs": "https://arxiv.org/abs/2508.15509", "authors": ["Xiaoxing Ren", "Nicola Bastianello", "Karl H. Johansson", "Thomas Parisini"], "title": "Jointly Computation- and Communication-Efficient Distributed Learning", "comment": "To be presented at 2025 IEEE Conference on Decision and Control", "summary": "We address distributed learning problems over undirected networks.\nSpecifically, we focus on designing a novel ADMM-based algorithm that is\njointly computation- and communication-efficient. Our design guarantees\ncomputational efficiency by allowing agents to use stochastic gradients during\nlocal training. Moreover, communication efficiency is achieved as follows: i)\nthe agents perform multiple training epochs between communication rounds, and\nii) compressed transmissions are used. We prove exact linear convergence of the\nalgorithm in the strongly convex setting. We corroborate our theoretical\nresults by numerical comparisons with state of the art techniques on a\nclassification task.", "AI": {"tldr": "An ADMM-based distributed learning algorithm for undirected networks that is computation- and communication-efficient through stochastic local updates, multi-epoch communication, and gradient compression, with a linear convergence guarantee for strongly convex problems and empirical validation on classification tasks.", "motivation": "To overcome efficiency bottlenecks in distributed learning by reducing both computation and communication costs without sacrificing convergence guarantees.", "method": "An ADMM-based framework enabling stochastic gradients in local updates, allowing several training epochs between communications, and employing compressed communication. Theoretical analysis proves exact linear convergence in the strongly convex setting. Empirical comparisons against state-of-the-art baselines on a classification task are provided.", "result": "Proves exact linear convergence for strongly convex objectives and demonstrates competitive or superior empirical performance against leading methods on classification benchmarks.", "conclusion": "The method achieves joint computation- and communication-efficiency with provable convergence, making it suitable for distributed networks; potential extensions include non-convex objectives and other compression schemes."}}
{"id": "2508.15629", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15629", "abs": "https://arxiv.org/abs/2508.15629", "authors": ["Hao Chen", "Fang Qiu", "Li An", "Douglas Stow", "Eve Bohnett", "Haitao Lyu", "Shuang Tian"], "title": "Multi-perspective monitoring of wildlife and human activities from camera traps and drones with deep learning models", "comment": null, "summary": "Wildlife and human activities are key components of landscape systems.\nUnderstanding their spatial distribution is essential for evaluating human\nwildlife interactions and informing effective conservation planning.\nMultiperspective monitoring of wildlife and human activities by combining\ncamera traps and drone imagery. Capturing the spatial patterns of their\ndistributions, which allows the identification of the overlap of their activity\nzones and the assessment of the degree of human wildlife conflict. The study\nwas conducted in Chitwan National Park (CNP), Nepal, and adjacent regions.\nImages collected by visible and nearinfrared camera traps and thermal infrared\ndrones from February to July 2022 were processed to create training and testing\ndatasets, which were used to build deep learning models to automatic identify\nwildlife and human activities. Drone collected thermal imagery was used for\ndetecting targets to provide a multiple monitoring perspective. Spatial pattern\nanalysis was performed to identify animal and resident activity hotspots and\ndelineation potential human wildlife conflict zones. Among the deep learning\nmodels tested, YOLOv11s achieved the highest performance with a precision of\n96.2%, recall of 92.3%, mAP50 of 96.7%, and mAP50 of 81.3%, making it the most\neffective for detecting objects in camera trap imagery. Drone based thermal\nimagery, analyzed with an enhanced Faster RCNN model, added a complementary\naerial viewpoint for camera trap detections. Spatial pattern analysis\nidentified clear hotspots for both wildlife and human activities and their\noverlapping patterns within certain areas in the CNP and buffer zones\nindicating potential conflict. This study reveals human wildlife conflicts\nwithin the conserved landscape. Integrating multiperspective monitoring with\nautomated object detection enhances wildlife surveillance and landscape\nmanagement.", "AI": {"tldr": "A multiperspective monitoring framework uses camera traps and drone imagery with deep learning to map wildlife and human activity distributions, identify overlaps, and locate human\u2013wildlife conflict zones in Chitwan National Park, Nepal.", "motivation": "To understand the spatial distribution of wildlife and human activities for evaluating human\u2013wildlife interactions and informing conservation planning and conflict mitigation, using complementary sensing modalities and automated detection.", "method": "Field data were collected Feb\u2013Jul 2022 in CNP and surrounding areas using visible/near-infrared camera traps and thermal infrared drones. Datasets were built for training/testing deep learning models to automatically identify wildlife and human activities. Drone thermal imagery provided an aerial perspective. YOLOv11s was evaluated and achieved top performance; an enhanced Faster RCNN was applied to drone data. Spatial pattern analysis identified wildlife and human activity hotspots and overlapping zones to delineate potential conflict.", "result": "YOLOv11s achieved precision 96.2%, recall 92.3%, and mAP50 values of 96.7% (camera-trap imagery) and 81.3% (drone-thermal detections). Drone-based thermal imagery analyzed with an enhanced Faster RCNN offered a complementary aerial viewpoint. Spatial analysis revealed clear hotspots for wildlife and human activities with overlapping areas indicating potential conflict.", "conclusion": "Integrating multiperspective monitoring with automated object detection enhances wildlife surveillance and landscape management, enabling identification of hotspots and potential conflict zones to inform conservation planning."}}
{"id": "2508.15523", "categories": ["cs.LG", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2508.15523", "abs": "https://arxiv.org/abs/2508.15523", "authors": ["Salman Habib", "Remi Chou", "Taejoon Kim"], "title": "Stabilization of Perturbed Loss Function: Differential Privacy without Gradient Noise", "comment": "under review", "summary": "We propose SPOF (Stabilization of Perturbed Loss Function), a differentially\nprivate training mechanism intended for multi-user local differential privacy\n(LDP). SPOF perturbs a stabilized Taylor expanded polynomial approximation of a\nmodel's training loss function, where each user's data is privatized by\ncalibrated noise added to the coefficients of the polynomial. Unlike\ngradient-based mechanisms such as differentially private stochastic gradient\ndescent (DP-SGD), SPOF does not require injecting noise into the gradients of\nthe loss function, which improves both computational efficiency and stability.\nThis formulation naturally supports simultaneous privacy guarantees across all\nusers. Moreover, SPOF exhibits robustness to environmental noise during\ntraining, maintaining stable performance even when user inputs are corrupted.\nWe compare SPOF with a multi-user extension of DP-SGD, evaluating both methods\nin a wireless body area network (WBAN) scenario involving heterogeneous user\ndata and stochastic channel noise from body sensors. Our results show that SPOF\nachieves, on average, up to 3.5% higher reconstruction accuracy and reduces\nmean training time by up to 57.2% compared to DP-SGD, demonstrating superior\nprivacy-utility trade-offs in multi-user environments.", "AI": {"tldr": "SPOF is a multi-user LDP training method that perturbs coefficients of a stabilized Taylor expansion of the loss, avoiding gradient noise; it improves efficiency and stability and shows better privacy-utility than DP-SGD in WBAN scenarios.", "motivation": "Address efficiency, stability, and privacy challenges in multi-user LDP training; gradient-based DP-SGD injects gradient noise which can hinder performance and stability, especially under noisy inputs; a method enabling simultaneous privacy guarantees with robustness is needed.", "method": "Construct a stabilized Taylor expansion of the training loss into a polynomial and privatize by adding calibrated noise to its coefficients for each user. No gradient perturbation is performed. The approach is evaluated in a multi-user WBAN setting with heterogeneous data and channel noise, comparing against a multi-user DP-SGD baseline and analyzing reconstruction accuracy and training time.", "result": "SPOF achieves up to 3.5% higher reconstruction accuracy and up to 57.2% shorter training time on average than multi-user DP-SGD in the tested WBAN scenario.", "conclusion": "SPOF offers efficient, stable, and robust multi-user LDP training with simultaneous privacy guarantees and favorable privacy-utility trade-offs, outperforming gradient-noise methods under realistic noisy conditions."}}
{"id": "2508.15641", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15641", "abs": "https://arxiv.org/abs/2508.15641", "authors": ["Pengcheng Fang", "Yuxia Chen", "Rui Guo"], "title": "When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding", "comment": null, "summary": "Understanding videos requires more than answering open ended questions, it\ndemands the ability to pinpoint when events occur and how entities interact\nacross time. While recent Video LLMs have achieved remarkable progress in\nholistic reasoning, they remain coarse in temporal perception: timestamps are\nencoded only implicitly, frame level features are weak in capturing continuity,\nand language vision alignment often drifts from the entities of interest. In\nthis paper, we present Grounded VideoDiT, a Video LLM designed to overcome\nthese limitations by introducing three key innovations. First, a Diffusion\nTemporal Latent (DTL) encoder enhances boundary sensitivity and maintains\ntemporal consistency. Second, object grounded representations explicitly bind\nquery entities to localized visual evidence, strengthening alignment. Third, a\nmixed token scheme with discrete temporal tokens provides explicit timestamp\nmodeling, enabling fine grained temporal reasoning. Together, these designs\nequip Grounded VideoDiT with robust grounding capabilities, as validated by\nstate of the art results on Charades STA, NExT GQA, and multiple VideoQA\nbenchmarks.", "AI": {"tldr": "Grounded VideoDiT introduces three innovations\u2014DTL encoder, object-grounded representations, and discrete temporal tokens\u2014that improve temporal grounding and entity alignment in Video LLMs, achieving state-of-the-art results on Charades STA, NExT GQA, and various VideoQA benchmarks.", "motivation": "Current Video LLMs struggle with precise temporal localization and entity-level grounding: timestamps are implicit, frame-level continuity is weak, and language\u2013vision alignment can drift away from queried entities. This paper targets robust temporal grounding and entity binding.", "method": "1) Diffusion Temporal Latent (DTL) encoder for sharper temporal boundaries and consistency. 2) Object-grounded representations that bind query entities to localized visual evidence. 3) Mixed token scheme with discrete temporal tokens for explicit timestamp modeling to enable fine-grained temporal reasoning.", "result": "Achieves state-of-the-art results on Charades STA, NExT GQA, and multiple VideoQA benchmarks, demonstrating improved grounding robustness and temporal understanding.", "conclusion": "Grounded VideoDiT advances temporal grounding and entity alignment in Video LLMs, enabling precise timestamped reasoning and robust grounding across diverse video QA tasks."}}
{"id": "2508.15550", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15550", "abs": "https://arxiv.org/abs/2508.15550", "authors": ["Khaled M. A. Alghtus", "Ayad Gannan", "Khalid M. Alhajri", "Ali L. A. Al Jubouri", "Hassan A. I. Al-Janahi"], "title": "AI-Powered Machine Learning Approaches for Fault Diagnosis in Industrial Pumps", "comment": null, "summary": "This study presents a practical approach for early fault detection in\nindustrial pump systems using real-world sensor data from a large-scale\nvertical centrifugal pump operating in a demanding marine environment. Five key\noperational parameters were monitored: vibration, temperature, flow rate,\npressure, and electrical current. A dual-threshold labeling method was applied,\ncombining fixed engineering limits with adaptive thresholds calculated as the\n95th percentile of historical sensor values. To address the rarity of\ndocumented failures, synthetic fault signals were injected into the data using\ndomain-specific rules, simulating critical alerts within plausible operating\nranges. Three machine learning classifiers - Random Forest, Extreme Gradient\nBoosting (XGBoost), and Support Vector Machine (SVM) - were trained to\ndistinguish between normal operation, early warnings, and critical alerts.\nResults showed that Random Forest and XGBoost models achieved high accuracy\nacross all classes, including minority cases representing rare or emerging\nfaults, while the SVM model exhibited lower sensitivity to anomalies. Visual\nanalyses, including grouped confusion matrices and time-series plots, indicated\nthat the proposed hybrid method provides robust detection capabilities. The\nframework is scalable, interpretable, and suitable for real-time industrial\ndeployment, supporting proactive maintenance decisions before failures occur.\nFurthermore, it can be adapted to other machinery with similar sensor\narchitectures, highlighting its potential as a scalable solution for predictive\nmaintenance in complex systems.", "AI": {"tldr": "Hybrid fault detection for industrial pumps using five sensor streams, dual-threshold labeling, and synthetic faults; RF and XGBoost outperform SVM, enabling real-time predictive maintenance.", "motivation": "Address early fault detection in large-scale, harsh marine pump environments with limited real-world failure instances by leveraging synthetic faults and multiple classifiers for robust, scalable monitoring.", "method": "Collects vibration, temperature, flow, pressure, and current data; labels via fixed limits plus adaptive 95th percentile thresholds; injects domain-informed synthetic faults to simulate rare/ emerging faults; trains RF, XGBoost, and SVM to classify normal, early warning, and critical states; evaluates with confusion matrices and time-series visualizations.", "result": "RF and XGBoost achieve high accuracy across all classes, including minority fault cases; SVM shows lower sensitivity to anomalies; the framework is scalable, interpretable, and suitable for real-time deployment; batch demonstrates potential adaptability to other machinery.", "conclusion": "The proposed hybrid labeling plus ensemble learning approach provides robust early fault detection and a scalable predictive maintenance solution for complex systems, with applicability to other equipment sharing similar sensor architectures."}}
{"id": "2508.15646", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15646", "abs": "https://arxiv.org/abs/2508.15646", "authors": ["Swann Emilien C\u00e9leste Destouches", "Jesse Lahaye", "Laurent Valentin Jospin", "Jan Skaloud"], "title": "Weakly-Supervised Learning for Tree Instances Segmentation in Airborne Lidar Point Clouds", "comment": "8 pages, 9 figures", "summary": "Tree instance segmentation of airborne laser scanning (ALS) data is of utmost\nimportance for forest monitoring, but remains challenging due to variations in\nthe data caused by factors such as sensor resolution, vegetation state at\nacquisition time, terrain characteristics, etc. Moreover, obtaining a\nsufficient amount of precisely labeled data to train fully supervised instance\nsegmentation methods is expensive. To address these challenges, we propose a\nweakly supervised approach where labels of an initial segmentation result\nobtained either by a non-finetuned model or a closed form algorithm are\nprovided as a quality rating by a human operator. The labels produced during\nthe quality assessment are then used to train a rating model, whose task is to\nclassify a segmentation output into the same classes as specified by the human\noperator. Finally, the segmentation model is finetuned using feedback from the\nrating model. This in turn improves the original segmentation model by 34\\% in\nterms of correctly identified tree instances while considerably reducing the\nnumber of non-tree instances predicted. Challenges still remain in data over\nsparsely forested regions characterized by small trees (less than two meters in\nheight) or within complex surroundings containing shrubs, boulders, etc. which\ncan be confused as trees where the performance of the proposed method is\nreduced.", "AI": {"tldr": "Weakly supervised ALS tree instance segmentation: human-rated quality signals guide a rating model to fine-tune an initial segmentation, yielding 34% more correctly identified tree instances and fewer non-tree predictions, but struggles with small trees and cluttered surroundings.", "motivation": "Reduce labeling burden and data variability challenges in tree instance segmentation from airborne laser scanning by leveraging human quality judgments to supervise learning without requiring fully labeled instance masks.", "method": "1) Start from an initial segmentation produced by a non-finetuned model or a closed-form algorithm. 2) A human operator provides quality ratings for these segmentations. 3) Train a rating model to classify segmentations into the same class labels as used by humans. 4) Finetune the segmentation model using feedback from the rating model. 5) Evaluate improvements in tree instance identification.", "result": "The approach improves correctly identified tree instances by about 34% and reduces non-tree predictions, demonstrating gains from weak supervision. However, performance degrades in sparsely forested regions with very small trees (<2 m) or in complex surroundings containing shrubs or boulders that can be confused with trees.", "conclusion": "Weakly supervised learning via quality-rated feedback can substantially boost segmentation performance while reducing labeling costs, but additional work is needed to address challenging data regimes such as small trees and clutter."}}
{"id": "2508.15569", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15569", "abs": "https://arxiv.org/abs/2508.15569", "authors": ["Xin Du", "Sikun Yang", "Wouter Duivesteijn", "Mykola Pechenizkiy"], "title": "Conformalized Exceptional Model Mining: Telling Where Your Model Performs (Not) Well", "comment": "Accepted by ECML-PKDD", "summary": "Understanding the nuanced performance of machine learning models is essential\nfor responsible deployment, especially in high-stakes domains like healthcare\nand finance. This paper introduces a novel framework, Conformalized Exceptional\nModel Mining, which combines the rigor of Conformal Prediction with the\nexplanatory power of Exceptional Model Mining (EMM). The proposed framework\nidentifies cohesive subgroups within data where model performance deviates\nexceptionally, highlighting regions of both high confidence and high\nuncertainty. We develop a new model class, mSMoPE (multiplex Soft Model\nPerformance Evaluation), which quantifies uncertainty through conformal\nprediction's rigorous coverage guarantees. By defining a new quality measure,\nRelative Average Uncertainty Loss (RAUL), our framework isolates subgroups with\nexceptional performance patterns in multi-class classification and regression\ntasks. Experimental results across diverse datasets demonstrate the framework's\neffectiveness in uncovering interpretable subgroups that provide critical\ninsights into model behavior. This work lays the groundwork for enhancing model\ninterpretability and reliability, advancing the state-of-the-art in explainable\nAI and uncertainty quantification.", "AI": {"tldr": "Introduces Conformalized Exceptional Model Mining (CEMM): a framework that fuses Conformal Prediction with Exceptional Model Mining to locate cohesive data subgroups where model performance deviates, aided by a new mSMoPE model class and Relative Average Uncertainty Loss (RAUL); demonstrates interpretability and uncertainty benefits across tasks.", "motivation": "To understand and quantify nuanced model performance for responsible deployment in high-stakes domains (e.g., healthcare and finance) by identifying subgroups with exceptional or anomalous performance and providing rigorous uncertainty guarantees.", "method": "Develop the Conformalized Exceptional Model Mining framework. Integrate Conformal Prediction with Exceptional Model Mining (EMM). Introduce mSMoPE (multiplex Soft Model Performance Evaluation) to quantify uncertainty with conformal coverage guarantees. Define Relative Average Uncertainty Loss (RAUL) as a quality metric. Apply the framework to multi-class classification and regression to discover cohesive subgroups with distinct performance patterns.", "result": "Empirically identifies interpretable subgroups that reveal critical insights into model behavior. Subgroups exhibit regions of high confidence and high uncertainty, with conformal guarantees supporting reliability. The approach demonstrates effectiveness across diverse datasets and tasks (classification and regression), advancing explainable AI and uncertainty quantification.", "conclusion": "Lays groundwork for enhanced interpretability and reliability in ML models, contributing to the state-of-the-art in explainable AI and uncertainty quantification and supporting safer deployment in high-stakes settings."}}
{"id": "2508.15650", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15650", "abs": "https://arxiv.org/abs/2508.15650", "authors": ["Shuchao Pang", "Zhenghan Chen", "Shen Zhang", "Liming Lu", "Siyuan Liang", "Anan Du", "Yongbin Zhou"], "title": "Towards a 3D Transfer-based Black-box Attack via Critical Feature Guidance", "comment": "11 pages, 6 figures", "summary": "Deep neural networks for 3D point clouds have been demonstrated to be\nvulnerable to adversarial examples. Previous 3D adversarial attack methods\noften exploit certain information about the target models, such as model\nparameters or outputs, to generate adversarial point clouds. However, in\nrealistic scenarios, it is challenging to obtain any information about the\ntarget models under conditions of absolute security. Therefore, we focus on\ntransfer-based attacks, where generating adversarial point clouds does not\nrequire any information about the target models. Based on our observation that\nthe critical features used for point cloud classification are consistent across\ndifferent DNN architectures, we propose CFG, a novel transfer-based black-box\nattack method that improves the transferability of adversarial point clouds via\nthe proposed Critical Feature Guidance. Specifically, our method regularizes\nthe search of adversarial point clouds by computing the importance of the\nextracted features, prioritizing the corruption of critical features that are\nlikely to be adopted by diverse architectures. Further, we explicitly constrain\nthe maximum deviation extent of the generated adversarial point clouds in the\nloss function to ensure their imperceptibility. Extensive experiments conducted\non the ModelNet40 and ScanObjectNN benchmark datasets demonstrate that the\nproposed CFG outperforms the state-of-the-art attack methods by a large margin.", "AI": {"tldr": "A transfer-based black-box attack (CFG) boosts adversarial success on 3D point clouds by focusing on features that are crucial across network architectures, while constraining perturbations for imperceptibility; it outperforms prior attacks on ModelNet40 and ScanObjectNN.", "motivation": "In real-world settings, attacker has no access to target model parameters or outputs. Since critical features for classification appear consistent across DNN architectures, exploiting these features should transfer better across models.", "method": "Critical Feature Guidance (CFG): compute feature importance across extracted features, regularize the adversarial point-cloud search to favor corrupting critical features shared by diverse architectures, and enforce a maximum perturbation constraint within the loss to maintain imperceptibility.", "result": "CFG significantly improves transferability and outperforms state-of-the-art transfer-based attack methods on ModelNet40 and ScanObjectNN datasets.", "conclusion": "CFG demonstrates that cross-architecture-consistent critical features can be effectively exploited to enhance transfer-based black-box attacks on 3D point clouds, highlighting a potential robustness gap and guiding defense considerations."}}
{"id": "2508.15593", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15593", "abs": "https://arxiv.org/abs/2508.15593", "authors": ["Ortal Senouf", "Antoine Wehenkel", "C\u00e9dric Vincent-Cuaz", "Emmanuel Abb\u00e9", "Pascal Frossard"], "title": "Inductive Domain Transfer In Misspecified Simulation-Based Inference", "comment": null, "summary": "Simulation-based inference (SBI) is a statistical inference approach for\nestimating latent parameters of a physical system when the likelihood is\nintractable but simulations are available. In practice, SBI is often hindered\nby model misspecification--the mismatch between simulated and real-world\nobservations caused by inherent modeling simplifications. RoPE, a recent SBI\napproach, addresses this challenge through a two-stage domain transfer process\nthat combines semi-supervised calibration with optimal transport (OT)-based\ndistribution alignment. However, RoPE operates in a fully transductive setting,\nrequiring access to a batch of test samples at inference time, which limits\nscalability and generalization. We propose here a fully inductive and amortized\nSBI framework that integrates calibration and distributional alignment into a\nsingle, end-to-end trainable model. Our method leverages mini-batch OT with a\nclosed-form coupling to align real and simulated observations that correspond\nto the same latent parameters, using both paired calibration data and unpaired\nsamples. A conditional normalizing flow is then trained to approximate the\nOT-induced posterior, enabling efficient inference without simulation access at\ntest time. Across a range of synthetic and real-world benchmarks--including\ncomplex medical biomarker estimation--our approach matches or surpasses the\nperformance of RoPE, as well as other standard SBI and non-SBI estimators,\nwhile offering improved scalability and applicability in challenging,\nmisspecified environments.", "AI": {"tldr": "A fully inductive, amortized SBI framework that unifies calibration and optimal-transport (OT) based distribution alignment via mini-batch OT with a closed-form coupling. It uses both paired calibration data and unpaired samples to train an end-to-end model, then employs a conditional normalizing flow to approximate the OT-induced posterior for efficient, test-time inference without simulations. It matches or exceeds RoPE and standard SBI/non-SBI methods across synthetic and real benchmarks, including medical biomarker estimation, with improved scalability in misspecified settings.", "motivation": "SBI struggles with misspecification between simulations and real observations. RoPE addresses this via a two-stage, transductive domain-transfer but requires access to test-time data batches, hindering scalability and generalization. A fully inductive, amortized approach that integrates calibration and distribution alignment aims to enable scalable, test-time-efficient inference under misspecification.", "method": "Integrate calibration and distributional alignment into a single end-to-end trainable model. Use mini-batch optimal transport with a closed-form coupling to align real and simulated observations that correspond to the same latent parameters, leveraging both paired calibration data and unpaired samples. Train a conditional normalizing flow to approximate the OT-induced posterior, enabling efficient inference without simulating at test time.", "result": "Empirically, the method matches or surpasses RoPE and standard SBI and non-SBI estimators across a range of synthetic and real-world benchmarks, including complex medical biomarker estimation, with improved scalability and applicability in misspecified environments.", "conclusion": "The proposed inductive, amortized SBI framework delivers scalable, test-time efficient posterior inference by integrating calibration and distribution alignment in an end-to-end model and using a conditional flow to represent the OT-induced posterior. It broadens applicability to misspecified settings and avoids the need for simulation during testing."}}
{"id": "2508.15653", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15653", "abs": "https://arxiv.org/abs/2508.15653", "authors": ["Ziyang Yan", "Ruikai Li", "Zhiyong Cui", "Bohan Li", "Han Jiang", "Yilong Ren", "Aoyong Li", "Zhenning Li", "Sijia Wen", "Haiyang Yu"], "title": "MapKD: Unlocking Prior Knowledge with Cross-Modal Distillation for Efficient Online HD Map Construction", "comment": null, "summary": "Online HD map construction is a fundamental task in autonomous driving\nsystems, aiming to acquire semantic information of map elements around the ego\nvehicle based on real-time sensor inputs. Recently, several approaches have\nachieved promising results by incorporating offline priors such as SD maps and\nHD maps or by fusing multi-modal data. However, these methods depend on stale\noffline maps and multi-modal sensor suites, resulting in avoidable\ncomputational overhead at inference. To address these limitations, we employ a\nknowledge distillation strategy to transfer knowledge from multimodal models\nwith prior knowledge to an efficient, low-cost, and vision-centric student\nmodel. Specifically, we propose MapKD, a novel multi-level cross-modal\nknowledge distillation framework with an innovative Teacher-Coach-Student (TCS)\nparadigm. This framework consists of: (1) a camera-LiDAR fusion model with\nSD/HD map priors serving as the teacher; (2) a vision-centric coach model with\nprior knowledge and simulated LiDAR to bridge the cross-modal knowledge\ntransfer gap; and (3) a lightweight vision-based student model. Additionally,\nwe introduce two targeted knowledge distillation strategies: Token-Guided 2D\nPatch Distillation (TGPD) for bird's eye view feature alignment and Masked\nSemantic Response Distillation (MSRD) for semantic learning guidance. Extensive\nexperiments on the challenging nuScenes dataset demonstrate that MapKD improves\nthe student model by +6.68 mIoU and +10.94 mAP while simultaneously\naccelerating inference speed. The code is available\nat:https://github.com/2004yan/MapKD2026.", "AI": {"tldr": "MapKD introduces a teacher-coach-student distillation framework to enable a light-weight vision-centric model for online HD map construction by transferring knowledge from multimodal models with map priors, using TGPD and MSRD; achieves significant performance gains and faster inference on nuScenes.", "motivation": "Reduce reliance on stale offline SD/HD maps and heavy multi-modal sensor chains; lower computational overhead while preserving accuracy by distilling knowledge into a vision-only student; bridge cross-modal gaps with a coach and simulated LiDAR.", "method": "Multi-level cross-modal distillation (Teacher-Coach-Student). Teacher: camera-LiDAR fusion model with SD/HD map priors. Coach: vision-centric model with priors and simulated LiDAR to bridge transfer gap. Student: lightweight vision-based model. Two distillation strategies: Token-Guided 2D Patch Distillation (TGPD) for BEV feature alignment; Masked Semantic Response Distillation (MSRD) for semantic guidance.", "result": "On nuScenes, the student model gains +6.68 mIoU and +10.94 mAP, while inference speed is accelerated. Code available at the provided GitHub link.", "conclusion": "MapKD effectively transfers rich, multi-modal knowledge into a compact vision-only model for online HD map construction, reducing reliance on offline maps and heavy sensors while delivering competitive accuracy and speed. This approach shows promise for real-time autonomous driving and paves the way for further cross-modal distillation research."}}
{"id": "2508.15612", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15612", "abs": "https://arxiv.org/abs/2508.15612", "authors": ["Charu Karakkaparambil James", "Waleed Mustafa", "Marius Kloft", "Sophie Fellenz"], "title": "Continual Neural Topic Model", "comment": null, "summary": "In continual learning, our aim is to learn a new task without forgetting what\nwas learned previously. In topic models, this translates to learning new topic\nmodels without forgetting previously learned topics. Previous work either\nconsidered Dynamic Topic Models (DTMs), which learn the evolution of topics\nbased on the entire training corpus at once, or Online Topic Models, which are\nupdated continuously based on new data but do not have long-term memory. To\nfill this gap, we propose the Continual Neural Topic Model (CoNTM), which\ncontinuously learns topic models at subsequent time steps without forgetting\nwhat was previously learned. This is achieved using a global prior distribution\nthat is continuously updated. In our experiments, CoNTM consistently\noutperformed the dynamic topic model in terms of topic quality and predictive\nperplexity while being able to capture topic changes online. The analysis\nreveals that CoNTM can learn more diverse topics and better capture temporal\nchanges than existing methods.", "AI": {"tldr": "CoNTM is a Continual Neural Topic Model that learns topics over time without forgetting, by maintaining a continuously updated global prior; it outperforms Dynamic Topic Models in topic quality and perplexity and captures online topic changes, with more diverse topics and better temporal modeling.", "motivation": "To address forgetting in continual topic modeling and fill the gap between Dynamic Topic Models (which use the whole corpus) and Online Topic Models (which lack long-term memory) by enabling online adaptation with memory of past topics.", "method": "Introduce CoNTM, a continual learning approach that updates a global prior across time steps to retain previously learned topics while incorporating new data; operates as a neural topic model with online updates.", "result": "CoNTM consistently outperforms DTMs in topic quality and predictive perplexity; it can track topic evolution online and discovers more diverse topics and better temporal changes than existing methods.", "conclusion": "CoNTM provides a viable solution for continual topic modeling, achieving online adaptability without forgetting and improving both quality and diversity of topics while capturing temporal dynamics."}}
{"id": "2508.15672", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2508.15672", "abs": "https://arxiv.org/abs/2508.15672", "authors": ["Franz Hanke", "Antonia Bieringer", "Olaf Wysocki", "Boris Jutzi"], "title": "CM2LoD3: Reconstructing LoD3 Building Models Using Semantic Conflict Maps", "comment": "This paper was accepted for the 20th 3D GeoInfo & 9th Smart Data\n  Smart Cities Conference", "summary": "Detailed 3D building models are crucial for urban planning, digital twins,\nand disaster management applications. While Level of Detail 1 (LoD)1 and LoD2\nbuilding models are widely available, they lack detailed facade elements\nessential for advanced urban analysis. In contrast, LoD3 models address this\nlimitation by incorporating facade elements such as windows, doors, and\nunderpasses. However, their generation has traditionally required manual\nmodeling, making large-scale adoption challenging. In this contribution,\nCM2LoD3, we present a novel method for reconstructing LoD3 building models\nleveraging Conflict Maps (CMs) obtained from ray-to-model-prior analysis.\nUnlike previous works, we concentrate on semantically segmenting real-world CMs\nwith synthetically generated CMs from our developed Semantic Conflict Map\nGenerator (SCMG). We also observe that additional segmentation of textured\nmodels can be fused with CMs using confidence scores to further increase\nsegmentation performance and thus increase 3D reconstruction accuracy.\nExperimental results demonstrate the effectiveness of our CM2LoD3 method in\nsegmenting and reconstructing building openings, with the 61% performance with\nuncertainty-aware fusion of segmented building textures. This research\ncontributes to the advancement of automated LoD3 model reconstruction, paving\nthe way for scalable and efficient 3D city modeling. Our project is available:\nhttps://github.com/InFraHank/CM2LoD3", "AI": {"tldr": "CM2LoD3 introduces an automated LoD3 building reconstruction by segmenting Conflict Maps (CMs) generated from ray-to-model-prior analysis, using a Semantic Conflict Map Generator (SCMG) to train on synthetic CMs and optionally fuse textured model segmentation with CMs via confidence scores to improve accuracy, achieving 61% segmentation performance with uncertainty-aware texture fusion.", "motivation": "LoD3 models provide facade details (windows, doors, openings) missing in LoD1/LoD2 but are costly to produce manually, hindering scalable, automated large-scale 3D city modeling for urban planning, digital twins, and disaster management.", "method": "The approach, CM2LoD3, reconstructs LoD3 buildings by leveraging Conflict Maps (CMs) from ray-to-model-prior analysis. It semantically segments real-world CMs and synthetically generated CMs from a Semantic Conflict Map Generator (SCMG). It further fuses segmentation of textured models with CMs using confidence scores to boost segmentation performance, leading to improved reconstruction of building openings.", "result": "Experimental results demonstrate effective segmentation and reconstruction of building openings, with a reported 61% performance when fusing textured-model segmentation with CM-based segmentation under uncertainty-aware fusion.", "conclusion": "CM2LoD3 advances automated LoD3 model reconstruction, enabling scalable and efficient 3D city modeling by combining CM-based segmentation with texture fusion, moving towards automated, large-scale LoD3 reconstruction."}}
{"id": "2508.15633", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15633", "abs": "https://arxiv.org/abs/2508.15633", "authors": ["Wei Herng Choong", "Jixing Liu", "Ching-Yu Kao", "Philip Sperl"], "title": "GRASPED: Graph Anomaly Detection using Autoencoder with Spectral Encoder and Decoder (Full Version)", "comment": "Full version of the paper accepted for publication at the European\n  Conference on Artificial Intelligence (ECAI 2025)", "summary": "Graph machine learning has been widely explored in various domains, such as\ncommunity detection, transaction analysis, and recommendation systems. In these\napplications, anomaly detection plays an important role. Recently, studies have\nshown that anomalies on graphs induce spectral shifts. Some supervised methods\nhave improved the utilization of such spectral domain information. However,\nthey remain limited by the scarcity of labeled data due to the nature of\nanomalies. On the other hand, existing unsupervised learning approaches\npredominantly rely on spatial information or only employ low-pass filters,\nthereby losing the capacity for multi-band analysis. In this paper, we propose\nGraph Autoencoder with Spectral Encoder and Spectral Decoder (GRASPED) for node\nanomaly detection. Our unsupervised learning model features an encoder based on\nGraph Wavelet Convolution, along with structural and attribute decoders. The\nGraph Wavelet Convolution-based encoder, combined with a Wiener Graph\nDeconvolution-based decoder, exhibits bandpass filter characteristics that\ncapture global and local graph information at multiple scales. This design\nallows for a learning-based reconstruction of node attributes, effectively\ncapturing anomaly information. Extensive experiments on several real-world\ngraph anomaly detection datasets demonstrate that GRASPED outperforms current\nstate-of-the-art models.", "AI": {"tldr": "Unsupervised graph anomaly detection using spectral encoder/decoder with graph wavelets and Wiener deconvolution, achieving state-of-the-art results.", "motivation": "Anomalies on graphs induce spectral shifts and labeled anomalies are scarce, so leverage multi-band spectral information for unsupervised detection.", "method": "Graph Wavelet Convolution-based encoder combined with a Wiener Graph Deconvolution-based decoder, with structural and attribute decoders; learns to reconstruct node attributes to capture anomalies across multiple scales (bandpass-like behavior).", "result": "GRASPED outperforms current state-of-the-art models on real-world graph anomaly detection datasets according to extensive experiments.", "conclusion": "A spectral, multi-band approach using wavelet-based encoding and deconvolution effectively captures both global and local information for unsupervised node anomaly detection and reconstruction."}}
{"id": "2508.15688", "categories": ["cs.CV", "I.4.10"], "pdf": "https://arxiv.org/pdf/2508.15688", "abs": "https://arxiv.org/abs/2508.15688", "authors": ["Yongju Jia", "Jiarui Ma", "Xiangxian Li", "Baiqiao Zhang", "Xianhui Cao", "Juan Liu", "Yulong Bian"], "title": "LLM-empowered Dynamic Prompt Routing for Vision-Language Models Tuning under Long-Tailed Distributions", "comment": "accepted by EMNLP 2025", "summary": "Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated\nimpressive capability in visual tasks, but their fine-tuning often suffers from\nbias in class-imbalanced scene. Recent works have introduced large language\nmodels (LLMs) to enhance VLM fine-tuning with supplementing semantic\ninformation. However, they often overlook inherent class imbalance in VLMs'\npre-training, which may lead to bias accumulation in downstream tasks. To\naddress this problem, this paper proposes a Multi-dimensional Dynamic Prompt\nRouting (MDPR) framework. MDPR constructs a comprehensive knowledge base for\nclasses, spanning five visual-semantic dimensions. During fine-tuning, the\ndynamic routing mechanism aligns global visual classes, retrieves optimal\nprompts, and balances fine-grained semantics, yielding stable predictions\nthrough logits fusion. Extensive experiments on long-tailed benchmarks,\nincluding CIFAR-LT, ImageNet-LT, and Places-LT, demonstrate that MDPR achieves\ncomparable results with current SOTA methods. Ablation studies further confirm\nthe effectiveness of our semantic library for tail classes, and show that our\ndynamic routing incurs minimal computational overhead, making MDPR a flexible\nand efficient enhancement for VLM fine-tuning under data imbalance.", "AI": {"tldr": "MDPR introduces a multi-dimensional dynamic prompt routing framework to mitigate class-imbalance bias in vision-language model fine-tuning by building a five-dimensional semantic knowledge base and routing prompts via dynamic alignment and logits fusion, achieving competitive long-tailed performance with low overhead.", "motivation": "Long-tailed class distributions and pretraining biases hamper VLM fine-tuning; existing LLM-enhanced methods often ignore inherent class imbalance, risking biased downstream performance.", "method": "Construct a five-dimensional visual-semantic knowledge base for classes; during fine-tuning, apply a dynamic routing mechanism that aligns global class representations, retrieves optimal prompts, balances fine-grained semantics, and fuses logits to yield stable predictions.", "result": "MDPR achieves results comparable to SOTA on CIFAR-LT, ImageNet-LT, and Places-LT; ablation studies show semantic library benefits for tail classes; dynamic routing incurs minimal computational overhead.", "conclusion": "MDPR provides a flexible and efficient enhancement for VLM fine-tuning under data imbalance, addressing pretraining bias and improving tail-class stability through multi-dimensional dynamic prompt routing."}}
{"id": "2508.15637", "categories": ["cs.LG", "cs.CL", "stat.AP"], "pdf": "https://arxiv.org/pdf/2508.15637", "abs": "https://arxiv.org/abs/2508.15637", "authors": ["Lucas Gautheron", "Evan Kidd", "Anton Malko", "Marvin Lavechin", "Alejandrina Cristia"], "title": "Classification errors distort findings in automated speech processing: examples and solutions from child-development research", "comment": null, "summary": "With the advent of wearable recorders, scientists are increasingly turning to\nautomated methods of analysis of audio and video data in order to measure\nchildren's experience, behavior, and outcomes, with a sizable literature\nemploying long-form audio-recordings to study language acquisition. While\nnumerous articles report on the accuracy and reliability of the most popular\nautomated classifiers, less has been written on the downstream effects of\nclassification errors on measurements and statistical inferences (e.g., the\nestimate of correlations and effect sizes in regressions). This paper proposes\na Bayesian approach to study the effects of algorithmic errors on key\nscientific questions, including the effect of siblings on children's language\nexperience and the association between children's production and their input.\nIn both the most commonly used \\gls{lena}, and an open-source alternative (the\nVoice Type Classifier from the ACLEW system), we find that classification\nerrors can significantly distort estimates. For instance, automated annotations\nunderestimated the negative effect of siblings on adult input by 20--80\\%,\npotentially placing it below statistical significance thresholds. We further\nshow that a Bayesian calibration approach for recovering unbiased estimates of\neffect sizes can be effective and insightful, but does not provide a fool-proof\nsolution. Both the issue reported and our solution may apply to any classifier\ninvolving event detection and classification with non-zero error rates.", "AI": {"tldr": "Automated audio classifiers used in child language studies introduce non-negligible errors that bias downstream inferences; a Bayesian calibration approach can recover more accurate effect sizes but is not foolproof.", "motivation": "As wearable recorders yield long-form audio data, researchers increasingly rely on automated classifiers; understanding how misclassification affects correlations and regression estimates is critical.", "method": "Evaluate LENA and the ACLEW Voice Type Classifier on long-form data; quantify impact of misclassification on key effects (e.g., siblings\u2019 effect on adult input; association between child production and input); develop a Bayesian calibration framework to adjust effect-size estimates for classifier error; compare bias and uncertainty.", "result": "Classification errors significantly distort estimates (e.g., underestimating the negative impact of siblings by 20\u201380%); Bayesian calibration can recover unbiased estimates but cannot guarantee perfect correction; errors in event-detection classifiers propagate to inferences.", "conclusion": "Measurement error in automated classifiers materially affects scientific conclusions; calibration-based corrections are useful but not foolproof; the approach is broadly applicable to any classifier with non-zero error rates."}}
{"id": "2508.15717", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15717", "abs": "https://arxiv.org/abs/2508.15717", "authors": ["Yanlai Yang", "Zhuokai Zhao", "Satya Narayan Shukla", "Aashu Singh", "Shlok Kumar Mishra", "Lizhu Zhang", "Mengye Ren"], "title": "StreamMem: Query-Agnostic KV Cache Memory for Streaming Video Understanding", "comment": "15 pages, 3 figures", "summary": "Multimodal large language models (MLLMs) have made significant progress in\nvisual-language reasoning, but their ability to efficiently handle long videos\nremains limited. Despite recent advances in long-context MLLMs, storing and\nattending to the key-value (KV) cache for long visual contexts incurs\nsubstantial memory and computational overhead. Existing visual compression\nmethods require either encoding the entire visual context before compression or\nhaving access to the questions in advance, which is impractical for long video\nunderstanding and multi-turn conversational settings. In this work, we propose\nStreamMem, a query-agnostic KV cache memory mechanism for streaming video\nunderstanding. Specifically, StreamMem encodes new video frames in a streaming\nmanner, compressing the KV cache using attention scores between visual tokens\nand generic query tokens, while maintaining a fixed-size KV memory to enable\nefficient question answering (QA) in memory-constrained, long-video scenarios.\nEvaluation on three long video understanding and two streaming video question\nanswering benchmarks shows that StreamMem achieves state-of-the-art performance\nin query-agnostic KV cache compression and is competitive with query-aware\ncompression approaches.", "AI": {"tldr": "StreamMem introduces a query-agnostic, fixed-size KV cache for streaming video understanding, compressing the KV via attention between visual tokens and generic query tokens, enabling memory-efficient long-video QA without prior knowledge of questions; achieves state-of-the-art compression for this setting and is competitive with query-aware methods across benchmarks.", "motivation": "Long video understanding in multimodal LLMs is hindered by the need to store and attend to large visual context using KV caches. Existing visual compression either requires encoding the entire context upfront or access to the questions in advance, which is impractical for streaming long videos and multi-turn dialog.", "method": "Propose StreamMem: a streaming, query-agnostic KV cache mechanism. It encodes new video frames as they arrive and compresses the KV cache by leveraging attention scores between visual tokens and generic query tokens, while preserving a fixed-size memory structure suitable for memory-constrained, long-video QA.", "result": "Empirical evaluation on three long video understanding benchmarks and two streaming video QA benchmarks shows that StreamMem achieves state-of-the-art performance in query-agnostic KV cache compression and is competitive with query-aware compression approaches.", "conclusion": "StreamMem enables efficient, memory-safe long-video understanding in streaming settings by providing a fixed-size, query-agnostic KV cache with attention-based compression, delivering strong performance gains and practicality for long-context MLLMs."}}
{"id": "2508.15642", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15642", "abs": "https://arxiv.org/abs/2508.15642", "authors": ["Ruihan Zhang", "Jun Sun"], "title": "Correct-By-Construction: Certified Individual Fairness through Neural Network Training", "comment": null, "summary": "Fairness in machine learning is more important than ever as ethical concerns\ncontinue to grow. Individual fairness demands that individuals differing only\nin sensitive attributes receive the same outcomes. However, commonly used\nmachine learning algorithms often fail to achieve such fairness. To improve\nindividual fairness, various training methods have been developed, such as\nincorporating fairness constraints as optimisation objectives. While these\nmethods have demonstrated empirical effectiveness, they lack formal guarantees\nof fairness. Existing approaches that aim to provide fairness guarantees\nprimarily rely on verification techniques, which can sometimes fail to produce\ndefinitive results. Moreover, verification alone does not actively enhance\nindividual fairness during training. To address this limitation, we propose a\nnovel framework that formally guarantees individual fairness throughout\ntraining. Our approach consists of two parts, i.e., (1) provably fair\ninitialisation that ensures the model starts in a fair state, and (2) a\nfairness-preserving training algorithm that maintains fairness as the model\nlearns. A key element of our method is the use of randomised response\nmechanisms, which protect sensitive attributes while maintaining fairness\nguarantees. We formally prove that this mechanism sustains individual fairness\nthroughout the training process. Experimental evaluations confirm that our\napproach is effective, i.e., producing models that are empirically fair and\naccurate. Furthermore, our approach is much more efficient than the alternative\napproach based on certified training (which requires neural network\nverification during training).", "AI": {"tldr": "Proposes a training framework that provides formal guarantees of individual fairness during training via provably fair initialization and a fairness-preserving training algorithm using randomized response; claims empirical fairness/accuracy and improved efficiency over verification-based training.", "motivation": "Address lack of formal fairness guarantees in ML training; verification-based methods are insufficient for active fairness during training; need guarantees and efficiency.", "method": "Two-part approach: (1) provably fair initialization; (2) fairness-preserving training algorithm leveraging randomized response mechanisms to protect sensitive attributes while preserving fairness; formal proofs that fairness is maintained during training.", "result": "Empirical results show models are empirically fair and accurate; method is more efficient than certified training that relies on neural network verification during training.", "conclusion": "A practical framework achieving provable individual fairness throughout training with better efficiency compared to verification-heavy approaches."}}
{"id": "2508.15720", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15720", "abs": "https://arxiv.org/abs/2508.15720", "authors": ["Zhiheng Liu", "Xueqing Deng", "Shoufa Chen", "Angtian Wang", "Qiushan Guo", "Mingfei Han", "Zeyue Xue", "Mengzhao Chen", "Ping Luo", "Linjie Yang"], "title": "WorldWeaver: Generating Long-Horizon Video Worlds via Rich Perception", "comment": "Project page: https://johanan528.github.io/worldweaver_web/", "summary": "Generative video modeling has made significant strides, yet ensuring\nstructural and temporal consistency over long sequences remains a challenge.\nCurrent methods predominantly rely on RGB signals, leading to accumulated\nerrors in object structure and motion over extended durations. To address these\nissues, we introduce WorldWeaver, a robust framework for long video generation\nthat jointly models RGB frames and perceptual conditions within a unified\nlong-horizon modeling scheme. Our training framework offers three key\nadvantages. First, by jointly predicting perceptual conditions and color\ninformation from a unified representation, it significantly enhances temporal\nconsistency and motion dynamics. Second, by leveraging depth cues, which we\nobserve to be more resistant to drift than RGB, we construct a memory bank that\npreserves clearer contextual information, improving quality in long-horizon\nvideo generation. Third, we employ segmented noise scheduling for training\nprediction groups, which further mitigates drift and reduces computational\ncost. Extensive experiments on both diffusion- and rectified flow-based models\ndemonstrate the effectiveness of WorldWeaver in reducing temporal drift and\nimproving the fidelity of generated videos.", "AI": {"tldr": "WorldWeaver is a long-horizon video-generation framework that jointly models RGB frames and perceptual conditions, uses a depth-based memory bank to curb drift, and employs segmented noise scheduling to improve temporal consistency and efficiency.", "motivation": "To address persistent temporal drift and structural errors in long videos produced by RGB-only generative models, which accumulate errors over time.", "method": "A unified representation that jointly predicts perceptual conditions and color from a single model, a depth-enabled memory bank to preserve contextual information, and segmented noise scheduling during training for prediction groups; applicable to both diffusion- and rectified-flow-based video models.", "result": "Demonstrates reduced temporal drift and higher fidelity in long-horizon video generation across diffusion and rectified-flow frameworks, with clearer motion dynamics and more stable object structure over extended sequences.", "conclusion": "WorldWeaver provides a robust, memory-augmented, multi-modal approach for stable long video synthesis, improving temporal consistency and quality while reducing computational cost."}}
{"id": "2508.15659", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15659", "abs": "https://arxiv.org/abs/2508.15659", "authors": ["C\u00e9sar Ali Ojeda Marin", "Wilhelm Huisinga", "Purity Kavwele", "Niklas Hartung"], "title": "Amortized In-Context Mixed Effect Transformer Models: A Zero-Shot Approach for Pharmacokinetics", "comment": null, "summary": "Accurate dose-response forecasting under sparse sampling is central to\nprecision pharmacotherapy. We present the Amortized In-Context Mixed-Effect\nTransformer (AICMET) model, a transformer-based latent-variable framework that\nunifies mechanistic compartmental priors with amortized in-context Bayesian\ninference. AICMET is pre-trained on hundreds of thousands of synthetic\npharmacokinetic trajectories with Ornstein-Uhlenbeck priors over the parameters\nof compartment models, endowing the model with strong inductive biases and\nenabling zero-shot adaptation to new compounds. At inference time, the decoder\nconditions on the collective context of previously profiled trial participants,\ngenerating calibrated posterior predictions for newly enrolled patients after a\nfew early drug concentration measurements. This capability collapses\ntraditional model-development cycles from weeks to hours while preserving some\ndegree of expert modelling. Experiments across public datasets show that AICMET\nattains state-of-the-art predictive accuracy and faithfully quantifies\ninter-patient variability -- outperforming both nonlinear mixed-effects\nbaselines and recent neural ODE variants. Our results highlight the feasibility\nof transformer-based, population-aware neural architectures as offering a new\nalternative for bespoke pharmacokinetic modeling pipelines, charting a path\ntoward truly population-aware personalized dosing regimens.", "AI": {"tldr": "AICMET is a transformer-based latent-variable PK model using Ornstein-Uhlenbeck priors and amortized Bayesian inference to enable fast, calibrated predictions for new patients with sparse data.", "motivation": "Accurate dose-response forecasting under sparse sampling; reduce model-development cycles; integrate mechanistic priors with population-level inference.", "method": "Pre-train on hundreds of thousands of synthetic PK trajectories with Ornstein-Uhlenbeck priors; transformer-based latent-variable architecture; amortized in-context Bayesian inference; decoder conditions on context from previously profiled participants; zero-shot adaptation to new compounds.", "result": "State-of-the-art predictive accuracy; well-calibrated inter-patient variability; outperforms nonlinear mixed-effects baselines and neural ODE variants.", "conclusion": "Shows feasibility of population-aware, transformer-based PK models for personalized dosing, enabling faster, bespoke dosing pipelines and truly population-aware regimens."}}
{"id": "2508.15751", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15751", "abs": "https://arxiv.org/abs/2508.15751", "authors": ["Xueyuan Li", "Can Cui", "Ruining Deng", "Yucheng Tang", "Quan Liu", "Tianyuan Yao", "Shunxing Bao", "Naweed Chowdhury", "Haichun Yang", "Yuankai Huo"], "title": "Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered All-in-SAM Model", "comment": "25 pages, 3 figures, accepted by Journal of Medical Imaging", "summary": "Purpose: Recent developments in computational pathology have been driven by\nadvances in Vision Foundation Models, particularly the Segment Anything Model\n(SAM). This model facilitates nuclei segmentation through two primary methods:\nprompt-based zero-shot segmentation and the use of cell-specific SAM models for\ndirect segmentation. These approaches enable effective segmentation across a\nrange of nuclei and cells. However, general vision foundation models often face\nchallenges with fine-grained semantic segmentation, such as identifying\nspecific nuclei subtypes or particular cells. Approach: In this paper, we\npropose the molecular-empowered All-in-SAM Model to advance computational\npathology by leveraging the capabilities of vision foundation models. This\nmodel incorporates a full-stack approach, focusing on: (1) annotation-engaging\nlay annotators through molecular-empowered learning to reduce the need for\ndetailed pixel-level annotations, (2) learning-adapting the SAM model to\nemphasize specific semantics, which utilizes its strong generalizability with\nSAM adapter, and (3) refinement-enhancing segmentation accuracy by integrating\nMolecular-Oriented Corrective Learning (MOCL). Results: Experimental results\nfrom both in-house and public datasets show that the All-in-SAM model\nsignificantly improves cell classification performance, even when faced with\nvarying annotation quality. Conclusions: Our approach not only reduces the\nworkload for annotators but also extends the accessibility of precise\nbiomedical image analysis to resource-limited settings, thereby advancing\nmedical diagnostics and automating pathology image analysis.", "AI": {"tldr": "All-in-SAM combines Segment Anything Model with molecular-powered learning to enable annotation-friendly, semantic-focused nuclei segmentation and cell classification, using a SAM adapter and MOCL to improve accuracy and generalizability, especially under limited pixel-level annotations.", "motivation": "General vision foundation models struggle with fine-grained semantic segmentation in pathology. The paper aims to bridge this gap by injecting molecular-level guidance and adaptive customization into SAM, reducing annotation burden and improving segmentation/classification in nuclei/cells.", "method": "A full-stack approach: (1) annotation-engaging lay annotators via molecular-empowered learning to reduce pixel-level labeling; (2) learning-adapting SAM to emphasize specific semantics using a SAM adapter; (3) refinement-enhancing segmentation via Molecular-Oriented Corrective Learning (MOCL). Evaluated on in-house and public datasets for cell classification performance.", "result": "Experimental results show significant improvements in cell classification across datasets, with robustness to varying annotation quality, demonstrating improved accuracy and generalization.", "conclusion": "The approach lowers annotation workload, extends access to precise biomedical image analysis in resource-limited settings, and advances automated pathology image analysis."}}
{"id": "2508.15676", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.15676", "abs": "https://arxiv.org/abs/2508.15676", "authors": ["Elif Konyar", "Mostafa Reisi Gahrooei", "Kamran Paynabar"], "title": "Tensorized Multi-Task Learning for Personalized Modeling of Heterogeneous Individuals with High-Dimensional Data", "comment": null, "summary": "Effective modeling of heterogeneous subpopulations presents a significant\nchallenge due to variations in individual characteristics and behaviors. This\npaper proposes a novel approach to address this issue through multi-task\nlearning (MTL) and low-rank tensor decomposition techniques. Our MTL approach\naims to enhance personalized modeling by leveraging shared structures among\nsimilar tasks while accounting for distinct subpopulation-specific variations.\nWe introduce a framework where low-rank decomposition decomposes the collection\nof task model parameters into a low-rank structure that captures commonalities\nand variations across tasks and subpopulations. This approach allows for\nefficient learning of personalized models by sharing knowledge between similar\ntasks while preserving the unique characteristics of each subpopulation.\nExperimental results in simulation and case study datasets demonstrate the\nsuperior performance of the proposed method compared to several benchmarks,\nparticularly in scenarios with high variability among subpopulations. The\nproposed framework not only improves prediction accuracy but also enhances\ninterpretability by revealing underlying patterns that contribute to the\npersonalization of models.", "AI": {"tldr": "A multi-task learning framework augmented with low-rank tensor decomposition to model heterogeneous subpopulations. It shares information across similar tasks while preserving subpopulation-specific variations, achieving improved accuracy and interpretability.", "motivation": "Heterogeneous subpopulations introduce high variability, making it difficult to train accurate personalized models. A method that captures both shared structure and subpopulation-specific differences can improve performance and interpretability.", "method": "Proposes a framework where task model parameters are decomposed into a low-rank tensor structure via low-rank decomposition within a multi-task learning setup. This captures commonalities across tasks while preserving subpopulation-specific variations, enabling efficient knowledge sharing. Evaluation includes simulations and case-study datasets.", "result": "Shows superior predictive performance compared to benchmarks, particularly when subpopulation variability is high. Also reports enhanced interpretability by revealing underlying patterns that drive personalization.", "conclusion": "The framework effectively models heterogeneity in subpopulations, enabling efficient learning of personalized models through shared representations while retaining unique subpopulation characteristics and offering interpretable insights."}}
{"id": "2508.15761", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15761", "abs": "https://arxiv.org/abs/2508.15761", "authors": ["Yifu Zhang", "Hao Yang", "Yuqi Zhang", "Yifei Hu", "Fengda Zhu", "Chuang Lin", "Xiaofeng Mei", "Yi Jiang", "Zehuan Yuan", "Bingyue Peng"], "title": "Waver: Wave Your Way to Lifelike Video Generation", "comment": null, "summary": "We present Waver, a high-performance foundation model for unified image and\nvideo generation. Waver can directly generate videos with durations ranging\nfrom 5 to 10 seconds at a native resolution of 720p, which are subsequently\nupscaled to 1080p. The model simultaneously supports text-to-video (T2V),\nimage-to-video (I2V), and text-to-image (T2I) generation within a single,\nintegrated framework. We introduce a Hybrid Stream DiT architecture to enhance\nmodality alignment and accelerate training convergence. To ensure training data\nquality, we establish a comprehensive data curation pipeline and manually\nannotate and train an MLLM-based video quality model to filter for the\nhighest-quality samples. Furthermore, we provide detailed training and\ninference recipes to facilitate the generation of high-quality videos. Building\non these contributions, Waver excels at capturing complex motion, achieving\nsuperior motion amplitude and temporal consistency in video synthesis. Notably,\nit ranks among the Top 3 on both the T2V and I2V leaderboards at Artificial\nAnalysis (data as of 2025-07-30 10:00 GMT+8), consistently outperforming\nexisting open-source models and matching or surpassing state-of-the-art\ncommercial solutions. We hope this technical report will help the community\nmore efficiently train high-quality video generation models and accelerate\nprogress in video generation technologies. Official page:\nhttps://github.com/FoundationVision/Waver.", "AI": {"tldr": "Waver is a unified, high\u2011performance foundation model for image and video generation that supports T2V, I2V, and T2I. It can generate 5\u201310 s videos at 720p (upscaled to 1080p), uses a Hybrid Stream DiT architecture, and employs a data curation pipeline plus an MLLM\u2011based video quality filter. It achieves strong motion and temporal consistency, ranks Top 3 on T2V and I2V leaderboards, and ships open\u2011source resources and recipes.", "motivation": "There is a need for a single, efficient framework that can coherently handle image and video generation across multiple modalities (T2V, I2V, T2I) with high motion quality and temporal stability. Improving data quality, alignment across modalities, and providing practical training/inference guidance can accelerate progress in video generation and democratize access to high-quality models.", "method": "Introduce Waver with Hybrid Stream DiT architecture to improve modality alignment and faster training. Build a comprehensive data curation pipeline and train an MLLM-based video quality model to filter high-quality samples. Provide detailed training and inference recipes. Generate 5\u201310 s 720p videos (upscaled to 1080p) and support T2V, I2V, and T2I in a unified framework.", "result": "Waver demonstrates strong motion capture and temporal consistency in video synthesis. It ranks among the Top 3 on both T2V and I2V leaderboards at Artificial Analysis (data current to 2025-07-30 10:00 GMT+8), outperforming existing open-source models and matching or surpassing certain commercial solutions.", "conclusion": "The report contributes a practical, high\u2011quality, unified approach to video generation, including novel architecture, curation and quality-filtering methods, and actionable training/inference guidance aimed at advancing the field and lowering barriers to high\u2011quality video generation research."}}
{"id": "2508.15679", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15679", "abs": "https://arxiv.org/abs/2508.15679", "authors": ["Eric Ye", "Ren Tao", "Natasha Jaques"], "title": "An Efficient Open World Environment for Multi-Agent Social Learning", "comment": null, "summary": "Many challenges remain before AI agents can be deployed in real-world\nenvironments. However, one virtue of such environments is that they are\ninherently multi-agent and contain human experts. Using advanced social\nintelligence in such an environment can help an AI agent learn adaptive skills\nand behaviors that a known expert exhibits. While social intelligence could\naccelerate training, it is currently difficult to study due to the lack of\nopen-ended multi-agent environments. In this work, we present an environment in\nwhich multiple self-interested agents can pursue complex and independent goals,\nreflective of real world challenges. This environment will enable research into\nthe development of socially intelligent AI agents in open-ended multi-agent\nsettings, where agents may be implicitly incentivized to cooperate to defeat\ncommon enemies, build and share tools, and achieve long horizon goals. In this\nwork, we investigate the impact on agent performance due to social learning in\nthe presence of experts and implicit cooperation such as emergent collaborative\ntool use, and whether agents can benefit from either cooperation or competition\nin this environment.", "AI": {"tldr": "Proposes an open-ended, multi-agent environment to study social learning, cooperation, and competition among self-interested agents with expert roles.", "motivation": "Real-world AI deployment is inherently multi-agent and human-influenced; current lack of open-ended environments hampers study of social intelligence.", "method": "Create an environment with multiple self-interested agents pursuing independent goals; enable emergent collaboration via shared tools, cooperation against common enemies, and long-horizon planning; assess how social learning in the presence of experts affects performance.", "result": "No empirical results reported; focuses on introducing the framework and outlining potential investigations into social learning, cooperation vs competition, and tool use.", "conclusion": "The environment enables research into socially intelligent AI in open-ended multi-agent settings, exploring whether cooperation or competition and expert guidance yield performance gains."}}
{"id": "2508.15767", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15767", "abs": "https://arxiv.org/abs/2508.15767", "authors": ["Jinhyung Park", "Javier Romero", "Shunsuke Saito", "Fabian Prada", "Takaaki Shiratori", "Yichen Xu", "Federica Bogo", "Shoou-I Yu", "Kris Kitani", "Rawal Khirodkar"], "title": "ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling", "comment": "ICCV 2025; Website: https://jindapark.github.io/projects/atlas/", "summary": "Parametric body models offer expressive 3D representation of humans across a\nwide range of poses, shapes, and facial expressions, typically derived by\nlearning a basis over registered 3D meshes. However, existing human mesh\nmodeling approaches struggle to capture detailed variations across diverse body\nposes and shapes, largely due to limited training data diversity and\nrestrictive modeling assumptions. Moreover, the common paradigm first optimizes\nthe external body surface using a linear basis, then regresses internal\nskeletal joints from surface vertices. This approach introduces problematic\ndependencies between internal skeleton and outer soft tissue, limiting direct\ncontrol over body height and bone lengths. To address these issues, we present\nATLAS, a high-fidelity body model learned from 600k high-resolution scans\ncaptured using 240 synchronized cameras. Unlike previous methods, we explicitly\ndecouple the shape and skeleton bases by grounding our mesh representation in\nthe human skeleton. This decoupling enables enhanced shape expressivity,\nfine-grained customization of body attributes, and keypoint fitting independent\nof external soft-tissue characteristics. ATLAS outperforms existing methods by\nfitting unseen subjects in diverse poses more accurately, and quantitative\nevaluations show that our non-linear pose correctives more effectively capture\ncomplex poses compared to linear models.", "AI": {"tldr": "ATLAS is a high-fidelity 3D human body model grounded in the skeleton, learned from 600k high-resolution scans (240 synchronized cameras). It decouples shape and skeleton bases for greater expressivity and controllability, employing non-linear pose correctives that outperform linear models in capturing complex poses.", "motivation": "Prevailing parametric body models rely on limited data diversity and linear bases, and couple outer soft tissue with an internal skeleton. This entanglement hampers accurate pose/shape modeling and prevents independent control of body height and bone lengths. A decoupled, skeleton-grounded representation is needed for higher fidelity and controllability.", "method": "Explicitly decouple shape and skeleton bases by grounding the mesh representation in the human skeleton. Train on 600k high-resolution scans from 240 synchronized cameras. Use non-linear pose correctives to better capture complex poses, allowing keypoint fitting independent of external soft-tissue characteristics.", "result": "ATLAS achieves more accurate fits for unseen subjects across diverse poses than prior methods. Quantitative results show non-linear pose correctives better capture complex poses than linear models, and the decoupled representation yields enhanced shape expressivity and controllable body attributes.", "conclusion": "ATLAS provides a more accurate, controllable, and expressive body model by decoupling shape and skeleton, enabling independent control of height and bone lengths and improved pose modeling through non-linear corrections."}}
{"id": "2508.15695", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15695", "abs": "https://arxiv.org/abs/2508.15695", "authors": ["Qifeng Hu", "Shamsulhaq Basir", "Inanc Senocak"], "title": "Conditionally adaptive augmented Lagrangian method for physics-informed learning of forward and inverse problems using artificial neural networks", "comment": "37 pages, 23 figures", "summary": "We present several advances to the physics and equality constrained\nartificial neural networks (PECANN) framework that substantially improve its\ncapability to learn solutions of canonical partial differential equations\n(PDEs). First, we generalize the augmented Lagrangian method (ALM) to support\nmultiple independent penalty parameters, enabling simultaneous enforcement of\nheterogeneous constraints. Second, we reformulate pointwise constraint\nenforcement and Lagrange multipliers as expectations over constraint terms,\nreducing memory overhead and permitting efficient mini-batch training. Third,\nto address PDEs with oscillatory, multi-scale features, we incorporate Fourier\nfeature mappings and show that a single mapping suffices where multiple\nmappings or more costly architectures were required in related methods. Fourth,\nwe introduce a time-windowing strategy for long-time evolution in which the\nterminal state of each window is enforced as an initial-condition constraint\nfor the next, ensuring continuity without discrete time models. Crucially, we\npropose a conditionally adaptive penalty update (CAPU) strategy for ALM, which\npreserves the principle that larger constraint violations incur stronger\npenalties. CAPU accelerates the growth of Lagrange multipliers for selectively\nchallenging constraints, enhancing constraint enforcement during training. We\ndemonstrate the effectiveness of PECANN-CAPU on problems including the\ntransonic rarefaction problem, reversible advection of a passive by a vortex,\nhigh-wavenumber Helmholtz and Poisson equations, and inverse identification of\nspatially varying heat sources. Comparisons with established methods and recent\nKolmogorov-Arnold network approaches show that PECANN-CAPU achieves competitive\naccuracy across all cases. Collectively, these advances improve PECANN's\nrobustness, efficiency, and applicability to demanding problems in scientific\ncomputing.", "AI": {"tldr": "PECANN-CAPU enhances physics-constrained neural PDE solvers by (1) multi-penalty augmented Lagrangian enforcement, (2) expectation-based constraint terms for memory-efficient mini-batching, (3) Fourier feature mappings for oscillatory/multi-scale problems, (4) time-windowing for stable long-time evolution, and (5) a conditional adaptive penalty update (CAPU). These advances improve robustness, efficiency, and applicability, achieving competitive accuracy across challenging PDEs.", "motivation": "To advance PECANN for solving canonical PDEs by improving constraint enforcement, handling multi-scale and long-time dynamics, and reducing memory usage, thereby broadening robustness and applicability in scientific computing.", "method": "1) Generalize augmented Lagrangian method (ALM) to support multiple independent penalty parameters for heterogeneous constraints. 2) Reformulate pointwise constraints and Lagrange multipliers as expectations over constraint terms to reduce memory overhead and enable efficient mini-batch training. 3) Use Fourier feature mappings to address oscillatory/multi-scale PDEs, with a single mapping sufficing in this setting. 4) Introduce a time-windowing strategy for long-time evolution, treating the end state of one window as the initial condition for the next to ensure continuity without discrete time models. 5) Propose a conditionally adaptive penalty update (CAPU) that increases penalties preferentially for challenging constraints. 6) Empirically validate PECANN-CAPU on transonic rarefaction, reversible advection of a passive vortex, high-wavenumber Helmholtz and Poisson equations, and inverse spatially varying heat sources; compare against established methods and Kolmogorov\u2013Arnold network variants.", "result": "PECANN-CAPU delivers competitive accuracy across diverse PDE problems, with improved constraint enforcement efficiency, reduced memory usage, and robust performance on high-frequency and long-time problems. CAPU accelerates multiplier growth for difficult constraints, enhancing training effectiveness; a single Fourier feature mapping suffices for the tested problems, simplifying model design; time-windowing enables stable long-time integration without explicit time-stepping networks.", "conclusion": "Together, these advances substantially boost PECANN's robustness, efficiency, and applicability to demanding scientific computing tasks, bringing it closer to parity with or superiority over established neural-PDE methods and related architectures."}}
{"id": "2508.15769", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15769", "abs": "https://arxiv.org/abs/2508.15769", "authors": ["Yanxu Meng", "Haoning Wu", "Ya Zhang", "Weidi Xie"], "title": "SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass", "comment": "Technical Report; Project Page: https://mengmouxu.github.io/SceneGen", "summary": "3D content generation has recently attracted significant research interest\ndue to its applications in VR/AR and embodied AI. In this work, we address the\nchallenging task of synthesizing multiple 3D assets within a single scene\nimage. Concretely, our contributions are fourfold: (i) we present SceneGen, a\nnovel framework that takes a scene image and corresponding object masks as\ninput, simultaneously producing multiple 3D assets with geometry and texture.\nNotably, SceneGen operates with no need for optimization or asset retrieval;\n(ii) we introduce a novel feature aggregation module that integrates local and\nglobal scene information from visual and geometric encoders within the feature\nextraction module. Coupled with a position head, this enables the generation of\n3D assets and their relative spatial positions in a single feedforward pass;\n(iii) we demonstrate SceneGen's direct extensibility to multi-image input\nscenarios. Despite being trained solely on single-image inputs, our\narchitectural design enables improved generation performance with multi-image\ninputs; and (iv) extensive quantitative and qualitative evaluations confirm the\nefficiency and robust generation abilities of our approach. We believe this\nparadigm offers a novel solution for high-quality 3D content generation,\npotentially advancing its practical applications in downstream tasks. The code\nand model will be publicly available at: https://mengmouxu.github.io/SceneGen.", "AI": {"tldr": "SceneGen is a single-pass, optimization-free framework that generates multiple 3D assets with geometry and texture from a single scene image and object masks, featuring a novel feature aggregation module and a position head; extendable to multi-image inputs.", "motivation": "Efficiently synthesize multiple 3D assets within a scene for VR/AR and embodied AI, addressing scalability and spatial consistency without heavy optimization or asset retrieval.", "method": "Propose SceneGen architecture: input scene image and masks; feature aggregation module combining local/global cues from visual and geometric encoders; position head for relative asset placement; end-to-end feedforward generation of assets and their locations; trained on single-image data; can extend to multi-image inputs at inference.", "result": "Quantitative and qualitative evaluations show efficiency and robust generation; improved results when using multi-image inputs; code and model will be released publicly.", "conclusion": "Offers a new paradigm for high-quality 3D content generation with potential practical impact on downstream tasks."}}
{"id": "2508.15697", "categories": ["cs.LG", "quant-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2508.15697", "abs": "https://arxiv.org/abs/2508.15697", "authors": ["Abdelmoula El-Yazizi", "Yaroslav Koshka"], "title": "Investigation of D-Wave quantum annealing for training Restricted Boltzmann Machines and mitigating catastrophic forgetting", "comment": "26 pages, 5 figures", "summary": "Modest statistical differences between the sampling performances of the\nD-Wave quantum annealer (QA) and the classical Markov Chain Monte Carlo (MCMC),\nwhen applied to Restricted Boltzmann Machines (RBMs), are explored to explain,\nand possibly address, the absence of significant and consistent improvements in\nRBM trainability when the D-Wave sampling was used in previous investigations.\nA novel hybrid sampling approach, combining the classical and the QA\ncontributions, is investigated as a promising way to benefit from the modest\ndifferences between the two sampling methods. No improvements in the RBM\ntraining are achieved in this work, thereby suggesting that the differences\nbetween the QA-based and MCMC sampling, mainly found in the medium-to-low\nprobability regions of the distribution, which are less important for the\nquality of the sample, are insufficient to benefit the training. Difficulties\nin achieving sufficiently high quality of embedding RBMs into the lattice of\nthe newer generation of D-Wave hardware could be further complicating the task.\nOn the other hand, the ability to generate samples of sufficient variety from\nlower-probability parts of the distribution has a potential to benefit other\nmachine learning applications, such as the mitigation of catastrophic\nforgetting (CF) during incremental learning. The feasibility of using\nQA-generated patterns of desirable classes for CF mitigation by the generative\nreplay is demonstrated in this work for the first time. While the efficiency of\nthe CF mitigation using the D-Wave QA was comparable to that of the classical\nmitigation, both the speed of generating a large number of distinct desirable\npatterns and the potential for further improvement make this approach promising\nfor a variety of challenging machine learning applications.", "AI": {"tldr": "The D-Wave quantum annealer (QA) and classical MCMC show only modest performance differences for RBM sampling, failing to improve RBM training; a hybrid approach also fails to yield gains. However, QA sampling may provide diverse low-probability patterns useful for other tasks like mitigating catastrophic forgetting (CF) in incremental learning, and could be beneficial with future hardware improvements.", "motivation": "To determine whether QA sampling offers training benefits for RBMs, understand the source of any lack of improvement, and explore whether hybrid QA-classical sampling or QA-generated patterns could enhance other learning tasks (e.g., CF mitigation) despite limited RBM training gains.", "method": "Empirically compare D-Wave QA sampling with classical MCMC for RBMs, experiment with a hybrid approach combining QA and classical samples, evaluate RBM training performance, and assess CF mitigation via generative replay using QA-generated patterns; discuss embedding challenges on newer D-Wave hardware.", "result": "RBM training shows no improvements from QA sampling or the hybrid approach. The modest differences between QA and MCMC, especially in medium-to-low probability regions (less impactful for sample quality), do not translate into training benefits. Embedding RBMs onto newer D-Wave hardware may pose additional obstacles. However, QA-generated diverse samples in low-probability regions could benefit other tasks, notably CF mitigation through generative replay, with QA performing comparably to classical methods but offering faster generation of many distinct patterns.", "conclusion": "QA-based sampling differences from MCMC are insufficient to boost RBM training under current hardware and methods, likely due to embedding and distribution-focus limitations. Nevertheless, QA can yield valuable, diverse samples in low-probability regions that may aid tasks like CF mitigation, and future hardware or methodological advances could unlock broader benefits."}}
{"id": "2508.15772", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2508.15772", "abs": "https://arxiv.org/abs/2508.15772", "authors": ["Qingyang Mao", "Qi Cai", "Yehao Li", "Yingwei Pan", "Mingyue Cheng", "Ting Yao", "Qi Liu", "Tao Mei"], "title": "Visual Autoregressive Modeling for Instruction-Guided Image Editing", "comment": "Source codes and models are available at\n  https://github.com/HiDream-ai/VAREdit", "summary": "Recent advances in diffusion models have brought remarkable visual fidelity\nto instruction-guided image editing. However, their global denoising process\ninherently entangles the edited region with the entire image context, leading\nto unintended spurious modifications and compromised adherence to editing\ninstructions. In contrast, autoregressive models offer a distinct paradigm by\nformulating image synthesis as a sequential process over discrete visual\ntokens. Their causal and compositional mechanism naturally circumvents the\nadherence challenges of diffusion-based methods. In this paper, we present\nVAREdit, a visual autoregressive (VAR) framework that reframes image editing as\na next-scale prediction problem. Conditioned on source image features and text\ninstructions, VAREdit generates multi-scale target features to achieve precise\nedits. A core challenge in this paradigm is how to effectively condition the\nsource image tokens. We observe that finest-scale source features cannot\neffectively guide the prediction of coarser target features. To bridge this\ngap, we introduce a Scale-Aligned Reference (SAR) module, which injects\nscale-matched conditioning information into the first self-attention layer.\nVAREdit demonstrates significant advancements in both editing adherence and\nefficiency. On standard benchmarks, it outperforms leading diffusion-based\nmethods by 30\\%+ higher GPT-Balance score. Moreover, it completes a\n$512\\times512$ editing in 1.2 seconds, making it 2.2$\\times$ faster than the\nsimilarly sized UltraEdit. The models are available at\nhttps://github.com/HiDream-ai/VAREdit.", "AI": {"tldr": "VAREdit reframes image editing as a next-scale prediction task in a visual autoregressive (VAR) framework, using a Scale-Aligned Reference (SAR) to condition coarse target features on source image tokens. It achieves better editing adherence and speed than diffusion-based methods, with a 512\u00d7512 edit in 1.2s and 2.2\u00d7 speedup over UltraEdit.", "motivation": "Diffusion-based editing often entangles edited regions with global image context, causing spurious changes and weak adherence to editing instructions. Autoregressive image modeling offers causal, compositional advantages but requires effective cross-scale conditioning to guide coarse-to-fine predictions.", "method": "VAREdit treats editing as next-scale feature prediction conditioned on source image features and text. It introduces Scale-Aligned Reference (SAR), injecting scale-matched conditioning into the first self-attention layer to bridge guidance from fine source features to coarser target features, enabling accurate edits across scales.", "result": "On standard benchmarks, VAREdit outperforms leading diffusion-based editors by 30%+ GPT-Balance score. It edits 512\u00d7512 images in about 1.2 seconds, 2.2\u00d7 faster than a similarly sized UltraEdit. Code is available at the project link.", "conclusion": "VAREdit demonstrates that a visual autoregressive approach with scale-aligned conditioning can surpass diffusion-based editors in both fidelity to editing instructions and efficiency, offering a compelling alternative for efficient, precise image editing."}}
{"id": "2508.15706", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15706", "abs": "https://arxiv.org/abs/2508.15706", "authors": ["Amir Sarfi", "Benjamin Th\u00e9rien", "Joel Lidin", "Eugene Belilovsky"], "title": "Communication Efficient LLM Pre-training with SparseLoCo", "comment": "15 pages, 9 tables, 2 figures", "summary": "Communication-efficient distributed training algorithms have received\nconsiderable interest recently due to their benefits for training Large\nLanguage Models (LLMs) in bandwidth-constrained settings, such as across data\ncenters and over the internet. Despite reducing communication frequency, these\nmethods still typically require communicating a full copy of the model's\ngradients-resulting in a communication bottleneck even for cross-datacenter\nlinks. Furthermore, they can slightly degrade performance compared to a naive\nAdamW DDP baseline. While quantization and error feedback are often applied to\nreduce the pseudo-gradient's size, in the context of LLM pre-training, existing\napproaches have been unable to additionally leverage sparsification and have\nobtained limited quantization. In this work, we introduce SparseLoCo, a\ncommunication-efficient training algorithm for LLMs that effectively leverages\nTop-k sparsification and quantization to reach extreme compression ratios of up\nto 1-3% sparsity and 2-bit quantization while outperforming full-precision\nDiLoCo. Our key observations are that outer momentum can be locally\napproximated by an error feedback combined with aggressive sparsity and that\nsparse aggregation can actually improve model performance. We empirically\ndemonstrate in a range of communication-constrained LLM training settings that\nSparseLoCo provides significant benefits in both performance and communication\ncost.", "AI": {"tldr": "SparseLoCo is a distributed training method for LLM pre-training that combines Top-k gradient sparsification, 2-bit quantization, error feedback, and sparse aggregation to dramatically reduce communication while delivering or improving model performance compared to full-precision DiLoCo.", "motivation": "Communication bottlenecks in cross-datacenter and bandwidth-constrained LLM pre-training. Prior methods either reduce communication frequency with full gradients or use quantization alone, and cannot effectively combine sparsity with quantization or exploit error feedback and sparse aggregation to maintain performance.", "method": "Introduce SparseLoCo: apply Top-k sparsification to gradients, 2-bit quantization, and an error-feedback loop, with sparse gradient aggregation. Local outer momentum is approximated via error feedback, and sparsity/aggregation are designed to improve performance while achieving extreme compression (as low as 1-3% density) with 2-bit quantization.", "result": "Extensive experiments in communication-constrained LLM training show significant gains in both model performance and communication cost. SparseLoCo achieves extreme compression (1-3% density with 2-bit quantization) and outperforms full-precision DiLoCo.", "conclusion": "SparseLoCo demonstrates that aggressive sparsification combined with coarse quantization, when paired with error feedback and sparse aggregation, can yield substantial communication savings and even improve performance in LLM pre-training over strong baselines like DiLoCo."}}
{"id": "2508.15773", "categories": ["cs.CV", "cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.15773", "abs": "https://arxiv.org/abs/2508.15773", "authors": ["Gaurav Parmar", "Or Patashnik", "Daniil Ostashev", "Kuan-Chieh Wang", "Kfir Aberman", "Srinivasa Narasimhan", "Jun-Yan Zhu"], "title": "Scaling Group Inference for Diverse and High-Quality Generation", "comment": "Project website: https://www.cs.cmu.edu/~group-inference, GitHub:\n  https://github.com/GaParmar/group-inference", "summary": "Generative models typically sample outputs independently, and recent\ninference-time guidance and scaling algorithms focus on improving the quality\nof individual samples. However, in real-world applications, users are often\npresented with a set of multiple images (e.g., 4-8) for each prompt, where\nindependent sampling tends to lead to redundant results, limiting user choices\nand hindering idea exploration. In this work, we introduce a scalable group\ninference method that improves both the diversity and quality of a group of\nsamples. We formulate group inference as a quadratic integer assignment\nproblem: candidate outputs are modeled as graph nodes, and a subset is selected\nto optimize sample quality (unary term) while maximizing group diversity\n(binary term). To substantially improve runtime efficiency, we progressively\nprune the candidate set using intermediate predictions, allowing our method to\nscale up to large candidate sets. Extensive experiments show that our method\nsignificantly improves group diversity and quality compared to independent\nsampling baselines and recent inference algorithms. Our framework generalizes\nacross a wide range of tasks, including text-to-image, image-to-image, image\nprompting, and video generation, enabling generative models to treat multiple\noutputs as cohesive groups rather than independent samples.", "AI": {"tldr": "A scalable group inference method for generative models that jointly selects high-quality, diverse groups of outputs by formulating candidate outputs as graph nodes in a quadratic assignment problem, with progressive pruning to scale to large candidate sets; applicable across text-to-image, image-to-image, prompting, and video generation.", "motivation": "In real applications, users often view multiple outputs per prompt. Independent sampling yields redundant results and limited exploration. Existing inference-time guidance focuses on single-sample quality and does not optimize a coherent group. There is a need for a scalable method to jointly optimize a diverse, high-quality group of outputs.", "method": "Model candidates as graph nodes and formulate subset selection as a quadratic integer programming problem. The unary term captures individual sample quality, while the binary term encourages diversity across the selected group. To scale, progressively prune the candidate set using intermediate predictions, enabling handling of large candidate pools. The framework is designed to be plug-and-play across different generative modalities.", "result": "Empirical evaluations show that the proposed method improves both group diversity and quality compared to independent sampling baselines and recent inference algorithms. The approach generalizes across tasks such as text-to-image, image-to-image, image prompting, and video generation, demonstrating the ability to treat multiple outputs as a cohesive group rather than independent samples.", "conclusion": "The group inference method offers a scalable, effective solution for producing diverse, high-quality groups of outputs from generative models. By jointly optimizing quality and diversity with scalable pruning, it enhances user choice and exploration across multiple modalities."}}
{"id": "2508.15719", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15719", "abs": "https://arxiv.org/abs/2508.15719", "authors": ["Mohammed Elmusrati"], "title": "Tutorial on the Probabilistic Unification of Estimation Theory, Machine Learning, and Generative AI", "comment": null, "summary": "Extracting meaning from uncertain, noisy data is a fundamental problem across\ntime series analysis, pattern recognition, and language modeling. This survey\npresents a unified mathematical framework that connects classical estimation\ntheory, statistical inference, and modern machine learning, including deep\nlearning and large language models. By analyzing how techniques such as maximum\nlikelihood estimation, Bayesian inference, and attention mechanisms address\nuncertainty, the paper illustrates that many AI methods are rooted in shared\nprobabilistic principles. Through illustrative scenarios including system\nidentification, image classification, and language generation, we show how\nincreasingly complex models build upon these foundations to tackle practical\nchallenges like overfitting, data sparsity, and interpretability. In other\nwords, the work demonstrates that maximum likelihood, MAP estimation, Bayesian\nclassification, and deep learning all represent different facets of a shared\ngoal: inferring hidden causes from noisy and/or biased observations. It serves\nas both a theoretical synthesis and a practical guide for students and\nresearchers navigating the evolving landscape of machine learning.", "AI": {"tldr": "A survey unifying estimation theory, Bayesian inference, and modern ML, showing that ML methods (MLE, MAP, Bayesian classifiers, deep learning) share probabilistic foundations for inferring hidden causes from noisy data, with practical guidance and illustrative scenarios.", "motivation": "Address uncertainty in noisy data across domains and provide a cohesive theoretical framework that connects classical statistics with modern machine learning, aiding understanding and navigation of the evolving ML landscape.", "method": "Conceptual synthesis that ties together maximum likelihood estimation, Bayesian inference, and attention mechanisms; explains how these techniques address uncertainty and overfitting; supports the synthesis with illustrative scenarios (system identification, image classification, language generation).", "result": "Demonstrates that diverse AI methods are rooted in shared probabilistic principles; clarifies the connections among MLE, MAP, Bayesian classification, and deep learning; discusses practical challenges such as overfitting, data sparsity, and interpretability within this unified view.", "conclusion": "Provides a theoretical synthesis and practical guide for students and researchers, arguing that different ML methods are facets of a single goal: inferring hidden causes from noisy/biased observations."}}
{"id": "2508.15774", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15774", "abs": "https://arxiv.org/abs/2508.15774", "authors": ["Haonan Qiu", "Ning Yu", "Ziqi Huang", "Paul Debevec", "Ziwei Liu"], "title": "CineScale: Free Lunch in High-Resolution Cinematic Visual Generation", "comment": "CineScale is an extended work of FreeScale (ICCV 2025). Project Page:\n  https://eyeline-labs.github.io/CineScale/, Code Repo:\n  https://github.com/Eyeline-Labs/CineScale", "summary": "Visual diffusion models achieve remarkable progress, yet they are typically\ntrained at limited resolutions due to the lack of high-resolution data and\nconstrained computation resources, hampering their ability to generate\nhigh-fidelity images or videos at higher resolutions. Recent efforts have\nexplored tuning-free strategies to exhibit the untapped potential\nhigher-resolution visual generation of pre-trained models. However, these\nmethods are still prone to producing low-quality visual content with repetitive\npatterns. The key obstacle lies in the inevitable increase in high-frequency\ninformation when the model generates visual content exceeding its training\nresolution, leading to undesirable repetitive patterns deriving from the\naccumulated errors. In this work, we propose CineScale, a novel inference\nparadigm to enable higher-resolution visual generation. To tackle the various\nissues introduced by the two types of video generation architectures, we\npropose dedicated variants tailored to each. Unlike existing baseline methods\nthat are confined to high-resolution T2I and T2V generation, CineScale broadens\nthe scope by enabling high-resolution I2V and V2V synthesis, built atop\nstate-of-the-art open-source video generation frameworks. Extensive experiments\nvalidate the superiority of our paradigm in extending the capabilities of\nhigher-resolution visual generation for both image and video models.\nRemarkably, our approach enables 8k image generation without any fine-tuning,\nand achieves 4k video generation with only minimal LoRA fine-tuning. Generated\nvideo samples are available at our website:\nhttps://eyeline-labs.github.io/CineScale/.", "AI": {"tldr": "CineScale enables higher-resolution visual generation for diffusion-models without fine-tuning, with variants for image-to-video, video-to-video generation and LoRA-assisted tuning; achieves 8k image generation without fine-tuning and 4k video with minimal LoRA fine-tuning, validated by experiments.", "motivation": "High-resolution generation is hampered by training-resolution limits, data scarcity, and computation; existing tuning-free approaches still produce artifacts and repetitive patterns due to high-frequency information when generating beyond training resolution.", "method": "CineScale is an inference paradigm with dedicated variants for different video generation architectures. It supports high-resolution I2V and V2V synthesis on top of open-source frameworks, designed to tackle high-frequency info and error accumulation by adjusting inference-time strategy rather than model fine-tuning.", "result": "Extensive experiments show superiority in extending high-resolution generation capabilities for both image and video models; 8k images without fine-tuning; 4k videos with minimal LoRA fine-tuning; samples available online.", "conclusion": "CineScale broadens the scope of high-resolution generation for image and video diffusion models without heavy fine-tuning, mitigating high-frequency artifacts and enabling state-of-the-art high-res outputs across I2V, V2V, T2I/T2V tasks."}}
{"id": "2508.15737", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15737", "abs": "https://arxiv.org/abs/2508.15737", "authors": ["Joonas J\u00e4rve", "Karl Kaspar Haavel", "Meelis Kull"], "title": "Probability Density from Latent Diffusion Models for Out-of-Distribution Detection", "comment": "ECAI 2025", "summary": "Despite rapid advances in AI, safety remains the main bottleneck to deploying\nmachine-learning systems. A critical safety component is out-of-distribution\ndetection: given an input, decide whether it comes from the same distribution\nas the training data. In generative models, the most natural OOD score is the\ndata likelihood. Actually, under the assumption of uniformly distributed OOD\ndata, the likelihood is even the optimal OOD detector, as we show in this work.\nHowever, earlier work reported that likelihood often fails in practice, raising\ndoubts about its usefulness. We explore whether, in practice, the\nrepresentation space also suffers from the inability to learn good density\nestimation for OOD detection, or if it is merely a problem of the pixel space\ntypically used in generative models. To test this, we trained a Variational\nDiffusion Model not on images, but on the representation space of a pre-trained\nResNet-18 to assess the performance of our likelihood-based detector in\ncomparison to state-of-the-art methods from the OpenOOD suite.", "AI": {"tldr": "Likelihood can be the optimal OOD detector under a uniform-OOD assumption, but empirical failures have sparked doubt; this work tests whether using representation-space density estimation helps by training a Variational Diffusion Model on ResNet-18 features and comparing to OpenOOD baselines.", "motivation": "Safety-critical task: robust OOD detection for ML systems; to reconcile theory that likelihood is optimal with practice where it fails; test representation-space density estimation vs pixel-space.", "method": "Train a Variational Diffusion Model on the representation space of a pre-trained ResNet-18; evaluate the performance of a likelihood-based OOD detector in this space and compare it to state-of-the-art OpenOOD methods.", "result": "Abstract does not report empirical results; it states an aim to assess performance; thus no concrete results are given.", "conclusion": "Conclusion not stated in the abstract; the work aims to determine whether representation-space density estimation improves likelihood-based OOD detection relative to OpenOOD baselines."}}
{"id": "2508.15763", "categories": ["cs.LG", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2508.15763", "abs": "https://arxiv.org/abs/2508.15763", "authors": ["Lei Bai", "Zhongrui Cai", "Maosong Cao", "Weihan Cao", "Chiyu Chen", "Haojiong Chen", "Kai Chen", "Pengcheng Chen", "Ying Chen", "Yongkang Chen", "Yu Cheng", "Yu Cheng", "Pei Chu", "Tao Chu", "Erfei Cui", "Ganqu Cui", "Long Cui", "Ziyun Cui", "Nianchen Deng", "Ning Ding", "Nanqin Dong", "Peijie Dong", "Shihan Dou", "Sinan Du", "Haodong Duan", "Caihua Fan", "Ben Gao", "Changjiang Gao", "Jianfei Gao", "Songyang Gao", "Yang Gao", "Zhangwei Gao", "Jiaye Ge", "Qiming Ge", "Lixin Gu", "Yuzhe Gu", "Aijia Guo", "Qipeng Guo", "Xu Guo", "Conghui He", "Junjun He", "Yili Hong", "Siyuan Hou", "Caiyu Hu", "Hanglei Hu", "Jucheng Hu", "Ming Hu", "Zhouqi Hua", "Haian Huang", "Junhao Huang", "Xu Huang", "Zixian Huang", "Zhe Jiang", "Lingkai Kong", "Linyang Li", "Peiji Li", "Pengze Li", "Shuaibin Li", "Tianbin Li", "Wei Li", "Yuqiang Li", "Dahua Lin", "Junyao Lin", "Tianyi Lin", "Zhishan Lin", "Hongwei Liu", "Jiangning Liu", "Jiyao Liu", "Junnan Liu", "Kai Liu", "Kaiwen Liu", "Kuikun Liu", "Shichun Liu", "Shudong Liu", "Wei Liu", "Xinyao Liu", "Yuhong Liu", "Zhan Liu", "Yinquan Lu", "Haijun Lv", "Hongxia Lv", "Huijie Lv", "Qidang Lv", "Ying Lv", "Chengqi Lyu", "Chenglong Ma", "Jianpeng Ma", "Ren Ma", "Runmin Ma", "Runyuan Ma", "Xinzhu Ma", "Yichuan Ma", "Zihan Ma", "Sixuan Mi", "Junzhi Ning", "Wenchang Ning", "Xinle Pang", "Jiahui Peng", "Runyu Peng", "Yu Qiao", "Jiantao Qiu", "Xiaoye Qu", "Yuan Qu", "Yuchen Ren", "Fukai Shang", "Wenqi Shao", "Junhao Shen", "Shuaike Shen", "Chunfeng Song", "Demin Song", "Diping Song", "Chenlin Su", "Weijie Su", "Weigao Sun", "Yu Sun", "Qian Tan", "Cheng Tang", "Huanze Tang", "Kexian Tang", "Shixiang Tang", "Jian Tong", "Aoran Wang", "Bin Wang", "Dong Wang", "Lintao Wang", "Rui Wang", "Weiyun Wang", "Wenhai Wang", "Yi Wang", "Ziyi Wang", "Ling-I Wu", "Wen Wu", "Yue Wu", "Zijian Wu", "Linchen Xiao", "Shuhao Xing", "Chao Xu", "Huihui Xu", "Jun Xu", "Ruiliang Xu", "Wanghan Xu", "GanLin Yang", "Yuming Yang", "Haochen Ye", "Jin Ye", "Shenglong Ye", "Jia Yu", "Jiashuo Yu", "Jing Yu", "Fei Yuan", "Bo Zhang", "Chao Zhang", "Chen Zhang", "Hongjie Zhang", "Jin Zhang", "Qiaosheng Zhang", "Qiuyinzhe Zhang", "Songyang Zhang", "Taolin Zhang", "Wenlong Zhang", "Wenwei Zhang", "Yechen Zhang", "Ziyang Zhang", "Haiteng Zhao", "Qian Zhao", "Xiangyu Zhao", "Xiangyu Zhao", "Bowen Zhou", "Dongzhan Zhou", "Peiheng Zhou", "Yuhao Zhou", "Yunhua Zhou", "Dongsheng Zhu", "Lin Zhu", "Yicheng Zou"], "title": "Intern-S1: A Scientific Multimodal Foundation Model", "comment": null, "summary": "In recent years, a plethora of open-source foundation models have emerged,\nachieving remarkable progress in some widely attended fields, with performance\nbeing quite close to that of closed-source models. However, in high-value but\nmore challenging scientific professional fields, either the fields still rely\non expert models, or the progress of general foundation models lags\nsignificantly compared to those in popular areas, far from sufficient for\ntransforming scientific research and leaving substantial gap between\nopen-source models and closed-source models in these scientific domains. To\nmitigate this gap and explore a step further toward Artificial General\nIntelligence (AGI), we introduce Intern-S1, a specialized generalist equipped\nwith general understanding and reasoning capabilities with expertise to analyze\nmultiple science modal data. Intern-S1 is a multimodal Mixture-of-Experts (MoE)\nmodel with 28 billion activated parameters and 241 billion total parameters,\ncontinually pre-trained on 5T tokens, including over 2.5T tokens from\nscientific domains. In the post-training stage, Intern-S1 undergoes offline and\nthen online reinforcement learning (RL) in InternBootCamp, where we propose\nMixture-of-Rewards (MoR) to synergize the RL training on more than 1000 tasks\nsimultaneously. Through integrated innovations in algorithms, data, and\ntraining systems, Intern-S1 achieved top-tier performance in online RL\ntraining.On comprehensive evaluation benchmarks, Intern-S1 demonstrates\ncompetitive performance on general reasoning tasks among open-source models and\nsignificantly outperforms open-source models in scientific domains, surpassing\nclosed-source state-of-the-art models in professional tasks, such as molecular\nsynthesis planning, reaction condition prediction, predicting thermodynamic\nstabilities for crystals. Our models are available at\nhttps://huggingface.co/internlm/Intern-S1.", "AI": {"tldr": "Intern-S1 is a 28B activated-parameters, 241B total-parameter multimodal MoE model designed as a specialized generalist with strong science reasoning and multimodal capabilities. Trained on 5T tokens (over 2.5T scientific tokens), it uses offline and online reinforcement learning (InternBootCamp) with Mixture-of-Rewards to tackle 1000+ tasks. It achieves competitive general reasoning among open-source models, markedly outperforms them in scientific domains, and surpasses closed-source SOTA in professional chemistry and materials tasks; the model is available at HuggingFace.", "motivation": "Address the gap between open-source foundation models and closed-source models in high-value scientific domains, advancing toward AGI by building a specialized generalist capable of analyzing multiple science modalities.", "method": "A multimodal Mixture-of-Experts (MoE) model with 28B activated parameters (241B total), continually pre-trained on 5T tokens including over 2.5T from scientific domains; after pretraining, offline RL followed by online RL in InternBootCamp, introducing Mixture-of-Rewards (MoR) to coordinate RL training across more than 1000 tasks.", "result": "Intern-S1 achieves top-tier performance in online RL training; competitive general reasoning among open-source models; significantly outperforms open-source models in scientific domains and surpasses closed-source SOTA in professional tasks such as molecular synthesis planning, reaction condition prediction, and predicting thermodynamic stabilities for crystals.", "conclusion": "Intern-S1 demonstrates the viability of specialized generalist models to narrow the gap between open- and closed-source models in scientific domains and moves toward AGI-like capabilities; the model is publicly available at HuggingFace."}}
{"id": "2508.15764", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2508.15764", "abs": "https://arxiv.org/abs/2508.15764", "authors": ["Kiarash Kazari", "Ezzeldin Shereen", "Gy\u00f6rgy D\u00e1n"], "title": "Distributed Detection of Adversarial Attacks in Multi-Agent Reinforcement Learning with Continuous Action Space", "comment": "Accepted for publication at ECAI 2025", "summary": "We address the problem of detecting adversarial attacks against cooperative\nmulti-agent reinforcement learning with continuous action space. We propose a\ndecentralized detector that relies solely on the local observations of the\nagents and makes use of a statistical characterization of the normal behavior\nof observable agents. The proposed detector utilizes deep neural networks to\napproximate the normal behavior of agents as parametric multivariate Gaussian\ndistributions. Based on the predicted density functions, we define a normality\nscore and provide a characterization of its mean and variance. This\ncharacterization allows us to employ a two-sided CUSUM procedure for detecting\ndeviations of the normality score from its mean, serving as a detector of\nanomalous behavior in real-time. We evaluate our scheme on various multi-agent\nPettingZoo benchmarks against different state-of-the-art attack methods, and\nour results demonstrate the effectiveness of our method in detecting impactful\nadversarial attacks. Particularly, it outperforms the discrete counterpart by\nachieving AUC-ROC scores of over 0.95 against the most impactful attacks in all\nevaluated environments.", "AI": {"tldr": "A decentralized detector using local observations to model normal agent behavior as parametric multivariate Gaussians, with a two-sided CUSUM on a normality score, detecting adversarial attacks in cooperative MARL with continuous actions; achieves high AUC-ROC (>0.95) on PettingZoo benchmarks.", "motivation": "Detect and mitigate adversarial attacks in cooperative multi-agent reinforcement learning with continuous action spaces using only local observations and a statistical normality model to enable real-time anomaly detection.", "method": "Train deep neural networks to approximate normal behavior as parametric multivariate Gaussian distributions from local observations. Define a normality score from predicted densities, derive its mean and variance analytically, and apply a two-sided CUSUM to detect deviations for real-time anomaly detection. Evaluate on PettingZoo benchmarks against state-of-the-art attack methods.", "result": "The method effectively detects impactful adversarial attacks, outperforming the discrete counterpart with AUC-ROC scores over 0.95 across all evaluated environments.", "conclusion": "A decentralized, observation-only detector based on probabilistic normality modeling and CUSUM is effective for real-time detection of adversarial behavior in cooperative MARL with continuous actions, offering strong performance gains over discrete baselines."}}
{"id": "2508.15766", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.15766", "abs": "https://arxiv.org/abs/2508.15766", "authors": ["Jaeha Lee", "Gio Huh", "Ning Su", "Tony Yue YU"], "title": "Discovering Hidden Algebraic Structures via Transformers with Rank-Aware Beam GRPO", "comment": null, "summary": "Recent efforts have extended the capabilities of transformers in logical\nreasoning and symbolic computations. In this work, we investigate their\ncapacity for non-linear latent pattern discovery in the context of functional\ndecomposition, focusing on the challenging algebraic task of multivariate\npolynomial decomposition. This problem, with widespread applications in science\nand engineering, is proved to be NP-hard, and demands both precision and\ninsight. Our contributions are threefold: First, we develop a synthetic data\ngeneration pipeline providing fine-grained control over problem complexity.\nSecond, we train transformer models via supervised learning and evaluate them\nacross four key dimensions involving scaling behavior and generalizability.\nThird, we propose Beam Grouped Relative Policy Optimization (BGRPO), a\nrank-aware reinforcement learning method suitable for hard algebraic problems.\nFinetuning with BGRPO improves accuracy while reducing beam width by up to\nhalf, resulting in approximately 75% lower inference compute. Additionally, our\nmodel demonstrates competitive performance in polynomial simplification,\noutperforming Mathematica in various cases.", "AI": {"tldr": "Transformers are applied to non-linear latent pattern discovery in multivariate polynomial decomposition, introducing a synthetic data pipeline, supervised training, and a Beam Grouped Relative Policy Optimization (BGRPO) reinforcement learning method to improve accuracy and reduce compute, with competitive polynomial simplification performance against Mathematica.", "motivation": "Tackle an NP-hard algebraic task (multivariate polynomial decomposition) and push transformer-based models to perform precise, insight-driven symbolic reasoning and generalize to larger problem classes.", "method": "1) Build a synthetic data generation pipeline with controllable complexity for polynomial decomposition. 2) Train transformer models via supervised learning and evaluate scaling and generalization across multiple dimensions. 3) Propose Beam Grouped Relative Policy Optimization (BGRPO), a rank-aware reinforcement learning method to guide search in hard algebraic problems; fine-tuning with BGRPO reduces beam width and inference compute. 4) Demonstrate improved accuracy and competitive polynomial simplification performance, including outperforming Mathematica in several cases.", "result": "BGRPO-based fine-tuning yields higher accuracy while halving the required beam width, leading to about 75% lower inference compute. The approach also shows competitive performance in polynomial simplification, outperforming Mathematica in diverse instances.", "conclusion": "Transformer-based approaches can effectively address non-linear latent patterns in algebraic tasks like multivariate polynomial decomposition. The BGRPO method provides an effective, compute-efficient search strategy for hard symbolic problems and demonstrates strong potential for automated algebraic reasoning across science and engineering."}}
